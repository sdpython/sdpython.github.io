{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Export with dynamic dimensions in ``{0,1}``\n\nThe first version of :func:`torch.export.export` did not support\nany tensor with a dimension equal to 0, 1 if the dimension was expected\nto be dynamic. The latest versions offers more options. Let's check it works.\nThe experiments consists in exporting the model with different sets of inputs\nand checking the exported models works with all set of inputs.\n\n## Available input sets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import itertools\nfrom tqdm import tqdm\nimport numpy as np\nimport pandas\nimport torch\nfrom onnx_diagnostic import doc\nfrom onnx_diagnostic.helpers import max_diff, string_type\nfrom onnx_diagnostic.helpers.torch_helper import torch_deepcopy\nfrom onnx_diagnostic.torch_models.hghub.model_inputs import get_untrained_model_with_inputs\nfrom onnx_diagnostic.torch_export_patches.patch_inputs import use_dyn_not_str\nfrom onnx_diagnostic.torch_export_patches import (\n    torch_export_patches,\n    register_additional_serialization_functions,\n)\n\n\ndata = get_untrained_model_with_inputs(\"arnir0/Tiny-LLM\", add_second_input=True)\nmodel, dynamic_shapes = data[\"model\"], data[\"dynamic_shapes\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The trained model can be obtained with:\n\n```python\nMODEL_NAME = \"arnir0/Tiny-LLM\"\ntokenizer = transformers.AutoTokenizer.from_pretrained(MODEL_NAME)\nmodel = transformers.AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "input_sets = {k: v for k, v in data.items() if k.startswith(\"inputs\")}\n\nfor k, v in input_sets.items():\n    print(f\"{k:20}: {string_type(v, with_shape=True)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The dynamic shapes are:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(f\"dynamic_shapes: {string_type(dynamic_shapes)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dynamic_shapes = use_dyn_not_str(dynamic_shapes)\nprint(f\"dynamic_shapes: {string_type(dynamic_shapes)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's check they all work and compute the expected values.\nWe use deepcopy because caches are usually modified inplace.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "expected = {}\nfor k, v in input_sets.items():\n    expected[k] = model(**torch_deepcopy(v))\n    print(f\"{k:20}: {string_type(expected[k], with_shape=True)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export with options\n\nWe try to export with the following options:\n\n- cache registration: register cache serialization with\n  :func:`onnx_diagnostic.torch_export_patches.register_additional_serialization_functions`\n\n- oblivious: an option to remove some the exception raises by the exporter\n\n- rt: see ``prefer_deferred_runtime_asserts_over_guards`` in :func:`torch.export.export`\n\n- cache_patch: patches the model before exporting with\n  :func:`onnx_diagnostic.torch_export_patches.torch_export_patches`\n\nSome function first.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def export_model(\n    model,\n    dynamic_shapes,\n    inputs,\n    cache=False,\n    oblivious=False,\n    rt=False,\n    cache_patch=False,\n    strict=False,\n):\n    if cache and not cache_patch:\n        with register_additional_serialization_functions(patch_transformers=True):\n            return export_model(\n                model, dynamic_shapes, inputs, oblivious=oblivious, rt=rt, strict=strict\n            )\n    if cache_patch:\n        with torch_export_patches(\n            patch_torch=cache_patch in (\"all\", \"torch\", True, 1),\n            patch_transformers=cache_patch in (\"all\", \"transformers\", True, 1),\n        ):\n            return export_model(\n                model, dynamic_shapes, inputs, oblivious=oblivious, rt=rt, strict=strict\n            )\n    if oblivious:\n        with torch.fx.experimental._config.patch(backed_size_oblivious=True):\n            return export_model(model, dynamic_shapes, inputs, rt=rt, strict=strict)\n    return torch.export.export(\n        model,\n        (),\n        inputs,\n        dynamic_shapes=dynamic_shapes,\n        strict=strict,\n        prefer_deferred_runtime_asserts_over_guards=rt,\n    )\n\n\ndef try_export_model(\n    model,\n    dynamic_shapes,\n    inputs,\n    cache=False,\n    oblivious=False,\n    rt=False,\n    cache_patch=False,\n    strict=False,\n):\n    try:\n        return export_model(\n            model,\n            dynamic_shapes,\n            inputs,\n            cache=cache,\n            oblivious=oblivious,\n            rt=rt,\n            cache_patch=cache_patch,\n            strict=strict,\n        )\n    except Exception as e:\n        return e\n\n\ndef validation(ep, input_sets, expected):\n    mod = ep.module()\n    for k, v in input_sets.items():\n        try:\n            got = mod(**torch_deepcopy(v))\n        except Exception as e:\n            yield k, e\n            continue\n        yield k, max_diff(expected[k], got, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The main loop\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "results = []\n\npossibilities = [*[[0, 1] for _ in range(5)], list(input_sets)]\npossibilities[1] = [0, \"all\", \"torch\", \"transformers\"]\nwith tqdm(list(itertools.product(*possibilities))) as pbar:\n    for cache, cache_patch, strict, oblivious, rt, inputs in pbar:\n        if cache_patch and not cache:\n            # patches include caches.\n            continue\n        kwargs = dict(\n            cache=cache, cache_patch=cache_patch, strict=strict, oblivious=oblivious, rt=rt\n        )\n        legend = \"-\".join(\n            (k if isinstance(v, int) else f\"{k}:{v}\") for k, v in kwargs.items() if v\n        )\n        legend = f\"{legend}/{inputs}\"\n        pbar.set_description(f\"{legend} EXPORT\")\n\n        # export\n        ep = try_export_model(\n            model, dynamic_shapes, torch_deepcopy(input_sets[inputs]), **kwargs\n        )\n        if isinstance(ep, Exception):\n            obs = {\n                **kwargs,\n                \"export_with\": inputs,\n                \"EXPORT\": 0,\n                \"ERR-EXPORT\": str(ep).split(\"\\n\")[0],\n            }\n            results.append(obs)\n            continue\n\n        pbar.set_description(f\"{legend} VALIDATE\")\n        common = {**kwargs, \"export_with\": inputs, \"EXPORT\": 1}\n        for inp, res in validation(ep, input_sets, expected):\n            if isinstance(res, Exception):\n                obs = {\n                    **common,\n                    \"run_with\": inp,\n                    \"ERR-RUN\": str(res).split(\"\\n\")[0],\n                    \"WORKS\": 0,\n                }\n            else:\n                obs = {\n                    **common,\n                    \"run_with\": inp,\n                    \"WORKS\": int(~np.isnan(res[\"abs\"]) and res[\"abs\"] < 1e-3),\n                }\n            results.append(obs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's save the results.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df = pandas.DataFrame(results)\ndf.to_excel(\"plot_export_tiny_llm_dim01.xlsx\")\ndf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "no_export = df[df.EXPORT == 0]\nno_export.to_excel(\"plot_export_tiny_llm_dim01.no_export.xlsx\")\nno_export"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The validation failures.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "invalid = df[(df.EXPORT == 1) & (df.WORKS == 0)].pivot(\n    index=[\"cache\", \"cache_patch\", \"strict\", \"oblivious\", \"rt\", \"export_with\"],\n    columns=[\"run_with\"],\n    values=[\"WORKS\", \"ERR-RUN\"],\n)\ninvalid.to_excel(\"plot_export_tiny_llm_dim01.invalid.xlsx\")\ninvalid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "success = df[(df.EXPORT == 1) & (df.WORKS == 1)].pivot(\n    index=[\"cache\", \"cache_patch\", \"strict\", \"oblivious\", \"rt\", \"export_with\"],\n    columns=[\"run_with\"],\n    values=[\"WORKS\"],\n)\nsuccess.to_excel(\"plot_export_tiny_llm_dim01.success.xlsx\")\nsuccess"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you have any error, then look at example\n`l-plot-tiny-llm-export-patched`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "doc.plot_legend(\"Tiny-LLM\\nexport with\\ndimension in {0,1}\", \"torch.export.export\", \"tomato\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}