{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Export with DynamicCache and dynamic shapes\n\nEvery LLMs implemented in :epkg:`transformers` use cache.\nOne of the most used is :class:`transformers.cache_utils.DynamicCache`.\nThe cache size is dynamic to cope with the growing context.\nThe example shows a tool which determines the dynamic shapes\nfor :func:`torch.export.export` based on a set of valid inputs.\n\n## DynamicCache\n\n:func:`torch.export.export` serializes caches and any custom class\nif these serialization functions are provided with is the case for\n:class:`transformers.cache_utils.DynamicCache` and ``transformers>=4.50``.\nThe dynamic shapes must be provided following the serialized form.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pprint\nimport torch\nfrom onnx_diagnostic import doc\nfrom onnx_diagnostic.ext_test_case import has_transformers\nfrom onnx_diagnostic.helpers import string_type\nfrom onnx_diagnostic.helpers.cache_helper import (\n    flatten_unflatten_for_dynamic_shapes,\n    make_dynamic_cache,\n)\nfrom onnx_diagnostic.export import ModelInputs\nfrom onnx_diagnostic.torch_export_patches import torch_export_patches\n\n\nclass Model(torch.nn.Module):\n    def forward(self, cache, z):\n        return (\n            z\n            + cache.key_cache[0]\n            + cache.key_cache[1]\n            + cache.value_cache[0]\n            + cache.value_cache[1]\n        )\n\n\nmodel = Model()\n\nn_layers = 2\nbsize, nheads, slen, dim = 2, 4, 3, 7\ncache = make_dynamic_cache(\n    [\n        (torch.randn(bsize, nheads, slen, dim), torch.randn(bsize, nheads, slen, dim))\n        for i in range(n_layers)\n    ]\n)\nz = torch.randn((1, 1, 1, 7))\nmodel(cache, z)  # to check it works."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The cache looks like this:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(string_type(cache, with_shape=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cache2 = make_dynamic_cache(\n    [\n        (\n            torch.randn(bsize + 1, nheads, slen + 1, dim + 1),\n            torch.randn(bsize + 1, nheads, slen + 1, dim + 1),\n        )\n        for i in range(n_layers)\n    ]\n)\ninputs = [\n    (cache, z),\n    (cache2, torch.randn((1, 1, 1, 8))),\n]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And the second set of inputs looks like:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(string_type(inputs[1], with_shape=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Guess the dynamic shapes\n\nThe following tool can be used to guess the dynamic shapes\nthe way :func:`torch.export.export` expects them.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mi = ModelInputs(Model(), inputs)\nds = mi.guess_dynamic_shapes()\n\npprint.pprint(ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And finally the export.\nThe export is simple if ``transformers>=4.50``, otherwise,\ntransformers needs to be patched.\n:func:`onnx_diagnostic.torch_export_patches.torch_export_patches`\nregisters functions to serialize ``DynamicCache``. This one is modified to make\nthe shape inference implemented in :epkg:`torch` happy.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if has_transformers(\"4.50\"):\n    ep = torch.export.export(model, inputs[0], dynamic_shapes=ds[0], strict=False)\nelse:\n    with torch_export_patches(patch_transformers=True) as modificator:\n        ep = torch.export.export(\n            model, modificator(inputs[0]), dynamic_shapes=ds[0], strict=False\n        )\nprint(ep)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Do we need to guess?\n\nFunction :func:`onnx_diagnostic.helpers.string_type` is using\nthe serialization functions to print out the DynamicCache the was\n:func:`torch.export.export` expects them.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(string_type(cache, with_shape=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can also use function\n:func:`onnx_diagnostic.helpers.cache_helper.flatten_unflatten_for_dynamic_shapes`\nto show a DynamicCache restructured the way :func:`torch.export.export` expects\nit to be without the custom class.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(string_type(flatten_unflatten_for_dynamic_shapes(cache), with_shape=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This code works for any custom class if it was registered\nwith :func:`torch.utils._pytree.register_pytree_node`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "doc.plot_legend(\"dynamic shapes\\nfor DynamicCache\", \"torch.export.export\", \"tomato\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}