
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_recipes/plot_export_cond.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_recipes_plot_export_cond.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_recipes_plot_export_cond.py:


.. _l-plot-export-cond:

Export a model with a control flow (If)
=======================================

Control flow cannot be exported with a change.
The code of the model can be changed or patched
to introduce function :func:`torch.cond`.

A model with a test
+++++++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 14-19

.. code-block:: Python


    import torch
    from onnx_diagnostic import doc
    from onnx_diagnostic.torch_export_patches import torch_export_rewrite








.. GENERATED FROM PYTHON SOURCE LINES 20-21

We define a model with a control flow (-> graph break)

.. GENERATED FROM PYTHON SOURCE LINES 21-47

.. code-block:: Python



    class ForwardWithControlFlowTest(torch.nn.Module):
        def forward(self, x):
            if x.sum():
                return x * 2
            else:
                return -x


    class ModelWithControlFlow(torch.nn.Module):
        def __init__(self):
            super().__init__()
            self.mlp = torch.nn.Sequential(
                torch.nn.Linear(3, 2),
                torch.nn.Linear(2, 1),
                ForwardWithControlFlowTest(),
            )

        def forward(self, x):
            out = self.mlp(x)
            return out


    model = ModelWithControlFlow()








.. GENERATED FROM PYTHON SOURCE LINES 48-49

Let's check it runs.

.. GENERATED FROM PYTHON SOURCE LINES 49-52

.. code-block:: Python

    x = torch.randn(1, 3)
    model(x)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    tensor([[-0.5394]], grad_fn=<MulBackward0>)



.. GENERATED FROM PYTHON SOURCE LINES 53-54

As expected, it does not export.

.. GENERATED FROM PYTHON SOURCE LINES 54-61

.. code-block:: Python

    try:
        torch.export.export(model, (x,))
        raise AssertionError("This export should failed unless pytorch now supports this model.")
    except Exception as e:
        print(e)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none




    def forward(self, arg0_1: "f32[2, 3]", arg1_1: "f32[2]", arg2_1: "f32[1, 2]", arg3_1: "f32[1]", arg4_1: "f32[1, 3]"):
        # File: /home/xadupre/vv/this312/lib/python3.12/site-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)
        linear: "f32[1, 2]" = torch.ops.aten.linear.default(arg4_1, arg0_1, arg1_1);  arg4_1 = arg0_1 = arg1_1 = None
        linear_1: "f32[1, 1]" = torch.ops.aten.linear.default(linear, arg2_1, arg3_1);  linear = arg2_1 = arg3_1 = None
    
        # File: /home/xadupre/github/onnx-diagnostic/_doc/recipes/plot_export_cond.py:25 in forward, code: if x.sum():
        sum_1: "f32[]" = torch.ops.aten.sum.default(linear_1);  linear_1 = None
        ne: "b8[]" = torch.ops.aten.ne.Scalar(sum_1, 0);  sum_1 = None
        item: "Sym(Eq(u0, 1))" = torch.ops.aten.item.default(ne);  ne = item = None
    



    def forward(self, arg0_1: "f32[2, 3]", arg1_1: "f32[2]", arg2_1: "f32[1, 2]", arg3_1: "f32[1]", arg4_1: "f32[1, 3]"):
        # File: /home/xadupre/vv/this312/lib/python3.12/site-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)
        linear: "f32[1, 2]" = torch.ops.aten.linear.default(arg4_1, arg0_1, arg1_1);  arg4_1 = arg0_1 = arg1_1 = None
        linear_1: "f32[1, 1]" = torch.ops.aten.linear.default(linear, arg2_1, arg3_1);  linear = arg2_1 = arg3_1 = None
    
        # File: /home/xadupre/github/onnx-diagnostic/_doc/recipes/plot_export_cond.py:25 in forward, code: if x.sum():
        sum_1: "f32[]" = torch.ops.aten.sum.default(linear_1);  linear_1 = None
        ne: "b8[]" = torch.ops.aten.ne.Scalar(sum_1, 0);  sum_1 = None
        item: "Sym(Eq(u0, 1))" = torch.ops.aten.item.default(ne);  ne = item = None
    
    Could not guard on data-dependent expression Eq(u0, 1) (unhinted: Eq(u0, 1)).  (Size-like symbols: none)

    consider using data-dependent friendly APIs such as guard_or_false, guard_or_true and statically_known_true.
    Caused by: (_export/non_strict_utils.py:1159 in __torch_function__)
    For more information, run with TORCH_LOGS="dynamic"
    For extended logs when we create symbols, also add TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL="u0"
    If you suspect the guard was triggered from C++, add TORCHDYNAMO_EXTENDED_DEBUG_CPP=1
    For more debugging help, see https://docs.google.com/document/d/1HSuTTVvYH1pTew89Rtpeu84Ht3nQEFTYhAX3Ypa_xJs/edit?usp=sharing

    For C++ stack trace, run with TORCHDYNAMO_EXTENDED_DEBUG_CPP=1

    The following call raised this error:
      File "/home/xadupre/github/onnx-diagnostic/_doc/recipes/plot_export_cond.py", line 25, in forward
        if x.sum():


    The error above occurred when calling torch.export.export. If you would like to view some more information about this error, and get a list of all other errors that may occur in your export call, you can replace your `export()` call with `draft_export()`.




.. GENERATED FROM PYTHON SOURCE LINES 62-66

Suggested Patch
+++++++++++++++

Let's avoid the graph break by replacing the forward.

.. GENERATED FROM PYTHON SOURCE LINES 66-84

.. code-block:: Python



    def new_forward(x):
        def identity2(x):
            return x * 2

        def neg(x):
            return -x

        return torch.cond(x.sum() > 0, identity2, neg, (x,))


    print("the list of submodules")
    for name, mod in model.named_modules():
        print(name, type(mod))
        if isinstance(mod, ForwardWithControlFlowTest):
            mod.forward = new_forward





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    the list of submodules
     <class '__main__.ModelWithControlFlow'>
    mlp <class 'torch.nn.modules.container.Sequential'>
    mlp.0 <class 'torch.nn.modules.linear.Linear'>
    mlp.1 <class 'torch.nn.modules.linear.Linear'>
    mlp.2 <class '__main__.ForwardWithControlFlowTest'>




.. GENERATED FROM PYTHON SOURCE LINES 85-86

Let's see what the fx graph looks like.

.. GENERATED FROM PYTHON SOURCE LINES 86-90

.. code-block:: Python


    ep = torch.export.export(model, (x,))
    print(ep.graph)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    graph():
        %p_mlp_0_weight : [num_users=1] = placeholder[target=p_mlp_0_weight]
        %p_mlp_0_bias : [num_users=1] = placeholder[target=p_mlp_0_bias]
        %p_mlp_1_weight : [num_users=1] = placeholder[target=p_mlp_1_weight]
        %p_mlp_1_bias : [num_users=1] = placeholder[target=p_mlp_1_bias]
        %x : [num_users=1] = placeholder[target=x]
        %linear : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%x, %p_mlp_0_weight, %p_mlp_0_bias), kwargs = {})
        %linear_1 : [num_users=2] = call_function[target=torch.ops.aten.linear.default](args = (%linear, %p_mlp_1_weight, %p_mlp_1_bias), kwargs = {})
        %sum_1 : [num_users=1] = call_function[target=torch.ops.aten.sum.default](args = (%linear_1,), kwargs = {})
        %gt : [num_users=1] = call_function[target=torch.ops.aten.gt.Scalar](args = (%sum_1, 0), kwargs = {})
        %true_graph_0 : [num_users=1] = get_attr[target=true_graph_0]
        %false_graph_0 : [num_users=1] = get_attr[target=false_graph_0]
        %cond : [num_users=1] = call_function[target=torch.ops.higher_order.cond](args = (%gt, %true_graph_0, %false_graph_0, (%linear_1,)), kwargs = {})
        %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%cond, 0), kwargs = {})
        return (getitem,)




.. GENERATED FROM PYTHON SOURCE LINES 91-103

Automated Rewrite of the Control Flow
+++++++++++++++++++++++++++++++++++++

Functions :func:`torch_export_rewrite
<onnx_diagnostic.torch_export_patches.torch_export_rewrite>`
or :func:`torch_export_patches <onnx_diagnostic.torch_export_patches.torch_export_patches>`
can automatically rewrite a method of a class or a function,
the method to rewrite is specified parameter ``rewrite``.
It is experimental. The function contains options to
rewrite one test but not another one already supported by the exporter.
It may give a first version of the rewritten code if only a manual
rewriting can make the model exportable.

.. GENERATED FROM PYTHON SOURCE LINES 103-107

.. code-block:: Python


    with torch_export_rewrite(rewrite=[ForwardWithControlFlowTest.forward], verbose=2) as f:
        ep = torch.export.export(model, (x,))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [torch_export_rewrite] rewrites method ForwardWithControlFlowTest.forward
    [transform_method] -- source -- <function ForwardWithControlFlowTest.forward at 0x7fecac529bc0>

        def forward(self, x):
            if x.sum():
                return x * 2
            else:
                return -x


    [transform_method] --
    [transform_method] -- new code --

    def forward(self, x):

        def branch_cond_then_1(x):
            return x * 2

        def branch_cond_else_1(x):
            return -x
        return torch.cond(x.sum(), branch_cond_then_1, branch_cond_else_1, [x])

    [transform_method] --
    [torch_export_rewrite] restored method ForwardWithControlFlowTest.forward




.. GENERATED FROM PYTHON SOURCE LINES 108-109

This gives:

.. GENERATED FROM PYTHON SOURCE LINES 109-112

.. code-block:: Python


    print(ep.graph)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    graph():
        %p_mlp_0_weight : [num_users=1] = placeholder[target=p_mlp_0_weight]
        %p_mlp_0_bias : [num_users=1] = placeholder[target=p_mlp_0_bias]
        %p_mlp_1_weight : [num_users=1] = placeholder[target=p_mlp_1_weight]
        %p_mlp_1_bias : [num_users=1] = placeholder[target=p_mlp_1_bias]
        %x : [num_users=1] = placeholder[target=x]
        %linear : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%x, %p_mlp_0_weight, %p_mlp_0_bias), kwargs = {})
        %linear_1 : [num_users=2] = call_function[target=torch.ops.aten.linear.default](args = (%linear, %p_mlp_1_weight, %p_mlp_1_bias), kwargs = {})
        %sum_1 : [num_users=1] = call_function[target=torch.ops.aten.sum.default](args = (%linear_1,), kwargs = {})
        %gt : [num_users=1] = call_function[target=torch.ops.aten.gt.Scalar](args = (%sum_1, 0), kwargs = {})
        %true_graph_0 : [num_users=1] = get_attr[target=true_graph_0]
        %false_graph_0 : [num_users=1] = get_attr[target=false_graph_0]
        %cond : [num_users=1] = call_function[target=torch.ops.higher_order.cond](args = (%gt, %true_graph_0, %false_graph_0, (%linear_1,)), kwargs = {})
        %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%cond, 0), kwargs = {})
        return (getitem,)




.. GENERATED FROM PYTHON SOURCE LINES 113-115

.. code-block:: Python


    doc.plot_legend("If -> torch.cond", "torch.export.export", "yellowgreen")



.. image-sg:: /auto_recipes/images/sphx_glr_plot_export_cond_001.png
   :alt: plot export cond
   :srcset: /auto_recipes/images/sphx_glr_plot_export_cond_001.png
   :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 2.107 seconds)


.. _sphx_glr_download_auto_recipes_plot_export_cond.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_export_cond.ipynb <plot_export_cond.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_export_cond.py <plot_export_cond.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_export_cond.zip <plot_export_cond.zip>`


.. include:: plot_export_cond.recommendations


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
