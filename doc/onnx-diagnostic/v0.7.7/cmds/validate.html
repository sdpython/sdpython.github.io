<!doctype html>
<html class="no-js" lang="en" data-content_root="../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="Examples Gallery" href="../auto_examples/index.html" /><link rel="prev" title="-m onnx_diagnostic config … prints the config for a model id" href="config.html" />
        <link rel="prefetch" href="../_static/logo.png" as="image" />

    <!-- Generated with Sphinx 8.1.3 and Furo 2025.07.19 -->
        <title>-m onnx_diagnostic validate … validate a model id - onnx-diagnostic 0.7.7 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=25af2a20" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css?v=7f9a90b1" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css?v=4ae1632d" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=8dab3a3b" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=a7360d90" />
    
    


<style>
  body {
    --color-code-background: #eeffcc;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #2b2b2b;
  --color-code-foreground: #f8f8f2;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #2b2b2b;
  --color-code-foreground: #f8f8f2;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">onnx-diagnostic 0.7.7 documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="../_static/logo.png" alt="Logo"/>
  </div>
  
  <span class="sidebar-brand-text">onnx-diagnostic 0.7.7 documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Contents</span></p>
<ul class="current">
<li class="toctree-l1 has-children"><a class="reference internal" href="../patches.html">Patches Explained</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of Patches Explained</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../status/index.html">Exporter Status</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of Exporter Status</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../status/exported_program_dynamic.html">Exported Programs with Dynamic Shapes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../status/exporter_dynamic.html">Exported ONNX with Dynamic Shapes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../status/patches_coverage.html">Coverage of the Patches</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api/index.html">API of onnx_diagnostic</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of API of onnx_diagnostic</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/export/index.html">onnx_diagnostic.export</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of onnx_diagnostic.export</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/export/dynamic_shapes.html">onnx_diagnostic.export.dynamic_shapes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/export/shape_helper.html">onnx_diagnostic.export.shape_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/export/validate.html">onnx_diagnostic.export.validate</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/helpers/index.html">onnx_diagnostic.helpers</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of onnx_diagnostic.helpers</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/helpers/args_helper.html">onnx_diagnostic.helpers.args_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/helpers/bench_run.html">onnx_diagnostic.helpers.bench_run</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/helpers/cache_helper.html">onnx_diagnostic.helpers.cache_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/helpers/config_helper.html">onnx_diagnostic.helpers.config_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/helpers/doc_helper.html">onnx_diagnostic.helpers.doc_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/helpers/graph_helper.html">onnx_diagnostic.helpers.graph_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/helpers/helper.html">onnx_diagnostic.helpers.helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/helpers/_log_helper.html">onnx_diagnostic.helpers._log_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/helpers/log_helper.html">onnx_diagnostic.helpers.log_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/helpers/memory_peak.html">onnx_diagnostic.helpers.memory_peak</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/helpers/mini_onnx_builder.html">onnx_diagnostic.helpers.mini_onnx_builder</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/helpers/model_builder_helper.html">onnx_diagnostic.helpers.model_builder_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/helpers/onnx_helper.html">onnx_diagnostic.helpers.onnx_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/helpers/ort_session.html">onnx_diagnostic.helpers.ort_session</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/helpers/rt_helper.html">onnx_diagnostic.helpers.rt_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/helpers/torch_helper.html">onnx_diagnostic.helpers.torch_helper</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/reference/index.html">onnx_diagnostic.reference</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle navigation of onnx_diagnostic.reference</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/reference/ops/index.html">onnx_diagnostic.reference.ops</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle navigation of onnx_diagnostic.reference.ops</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_add_add_mul_mul.html">onnx_diagnostic.reference.ops.op_add_add_mul_mul</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_average_pool_grad.html">onnx_diagnostic.reference.ops.op_average_pool_grad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_cast_like.html">onnx_diagnostic.reference.ops.op_cast_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_complex.html">onnx_diagnostic.reference.ops.op_complex</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_concat.html">onnx_diagnostic.reference.ops.op_concat</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_constant_of_shape.html">onnx_diagnostic.reference.ops.op_constant_of_shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_fused_matmul.html">onnx_diagnostic.reference.ops.op_fused_matmul</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_gather_grad.html">onnx_diagnostic.reference.ops.op_gather_grad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_memcpy_host.html">onnx_diagnostic.reference.ops.op_memcpy_host</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_mul_sigmoid.html">onnx_diagnostic.reference.ops.op_mul_sigmoid</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_negxplus1.html">onnx_diagnostic.reference.ops.op_negxplus1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_quick_gelu.html">onnx_diagnostic.reference.ops.op_quick_gelu</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_replace_zero.html">onnx_diagnostic.reference.ops.op_replace_zero</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_rotary.html">onnx_diagnostic.reference.ops.op_rotary</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_qlinear_average_pool.html">onnx_diagnostic.reference.ops.op_qlinear_average_pool</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_qlinear_conv.html">onnx_diagnostic.reference.ops.op_qlinear_conv</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_scatter_elements.html">onnx_diagnostic.reference.ops.op_scatter_elements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_scatternd_of_shape.html">onnx_diagnostic.reference.ops.op_scatternd_of_shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_simplified_layer_normalization.html">onnx_diagnostic.reference.ops.op_simplified_layer_normalization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_skip_layer_normalization.html">onnx_diagnostic.reference.ops.op_skip_layer_normalization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_slice.html">onnx_diagnostic.reference.ops.op_slice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_transpose_cast.html">onnx_diagnostic.reference.ops.op_transpose_cast</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_tri_matrix.html">onnx_diagnostic.reference.ops.op_tri_matrix</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/reference/torch_ops/index.html">onnx_diagnostic.reference.torch_ops</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle navigation of onnx_diagnostic.reference.torch_ops</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/torch_ops/access_ops.html">onnx_diagnostic.reference.torch_ops.access_ops</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/torch_ops/binary_ops.html">onnx_diagnostic.reference.torch_ops.binary_ops</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/torch_ops/controlflow_ops.html">onnx_diagnostic.reference.torch_ops.controlflow_ops</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/torch_ops/generator_ops.html">onnx_diagnostic.reference.torch_ops.generator_ops</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/torch_ops/nn_ops.html">onnx_diagnostic.reference.torch_ops.nn_ops</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/torch_ops/other_ops.html">onnx_diagnostic.reference.torch_ops.other_ops</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/torch_ops/reduce_ops.html">onnx_diagnostic.reference.torch_ops.reduce_ops</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/torch_ops/sequence_ops.html">onnx_diagnostic.reference.torch_ops.sequence_ops</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/torch_ops/shape_ops.html">onnx_diagnostic.reference.torch_ops.shape_ops</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/torch_ops/unary_ops.html">onnx_diagnostic.reference.torch_ops.unary_ops</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api/reference/evaluator.html">onnx_diagnostic.reference.evaluator</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/reference/quantized_tensor.html">onnx_diagnostic.reference.quantized_tensor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/reference/ort_evaluator.html">onnx_diagnostic.reference.ort_evaluator</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/reference/report_results_comparison.html">onnx_diagnostic.reference.report_results_comparison</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/reference/torch_evaluator.html">onnx_diagnostic.reference.torch_evaluator</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/tasks/index.html">onnx_diagnostic.tasks</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle navigation of onnx_diagnostic.tasks</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/tasks/automatic_speech_recognition.html">onnx_diagnostic.tasks.automatic_speech_recognition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/tasks/fill_mask.html">onnx_diagnostic.tasks.fill_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/tasks/feature_extraction.html">onnx_diagnostic.tasks.feature_extraction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/tasks/image_classification.html">onnx_diagnostic.tasks.image_classification</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/tasks/image_text_to_text.html">onnx_diagnostic.export.image_text_to_text</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/tasks/mixture_of_expert.html">onnx_diagnostic.tasks.mixture_of_expert</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/tasks/object_detection.html">onnx_diagnostic.tasks.object_detection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/tasks/sentence_similarity.html">onnx_diagnostic.tasks.sentence_similarity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/tasks/summarization.html">onnx_diagnostic.tasks.summarization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/tasks/text_classification.html">onnx_diagnostic.tasks.text_classification</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/tasks/text_generation.html">onnx_diagnostic.tasks.text_generation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/tasks/text_to_image.html">onnx_diagnostic.tasks.text_to_image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/tasks/text2text_generation.html">onnx_diagnostic.tasks.text2text_generation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/tasks/zero_shot_image_classification.html">onnx_diagnostic.tasks.zero_shot_image_classification</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/torch_export_patches/index.html">onnx_diagnostic.torch_export_patches</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle navigation of onnx_diagnostic.torch_export_patches</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/torch_export_patches/eval/index.html">onnx_diagnostic.torch_export_patches.eval</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><div class="visually-hidden">Toggle navigation of onnx_diagnostic.torch_export_patches.eval</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/torch_export_patches/eval/model_cases.html">onnx_diagnostic.torch_export_patches.eval.model_cases</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_export_patches/onnx_export_errors.html">onnx_diagnostic.torch_export_patches.onnx_export_errors</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_export_patches/onnx_export_serialization.html">onnx_diagnostic.torch_export_patches.onnx_export_serialization</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/torch_export_patches/patches/index.html">onnx_diagnostic.torch_export_patches.patches</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><div class="visually-hidden">Toggle navigation of onnx_diagnostic.torch_export_patches.patches</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/torch_export_patches/patches/patch_torch.html">onnx_diagnostic.torch_export_patches.patches.patch_torch</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/torch_export_patches/patches/patch_transformers.html">onnx_diagnostic.torch_export_patches.patches.patch_transformers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_export_patches/patch_expressions.html">onnx_diagnostic.torch_export_patches.patch_expressions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_export_patches/patch_inputs.html">onnx_diagnostic.torch_export_patches.patch_inputs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_export_patches/patch_module.html">onnx_diagnostic.torch_export_patches.patch_module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_export_patches/patch_module_helper.html">onnx_diagnostic.torch_export_patches.patch_module_helper</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/torch_export_patches/serialization/index.html">onnx_diagnostic.torch_export_patches.serialization</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" role="switch" type="checkbox"/><label for="toctree-checkbox-13"><div class="visually-hidden">Toggle navigation of onnx_diagnostic.torch_export_patches.serialization</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/torch_export_patches/serialization/diffusers_impl.html">onnx_diagnostic.torch_export_patches.serialization.diffusers_impl</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/torch_export_patches/serialization/transformers_impl.html">onnx_diagnostic.torch_export_patches.serialization.transformers_impl</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/torch_models/index.html">onnx_diagnostic.torch_models</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" role="switch" type="checkbox"/><label for="toctree-checkbox-14"><div class="visually-hidden">Toggle navigation of onnx_diagnostic.torch_models</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/torch_models/hghub/index.html">onnx_diagnostic.torch_models.hghub</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" role="switch" type="checkbox"/><label for="toctree-checkbox-15"><div class="visually-hidden">Toggle navigation of onnx_diagnostic.torch_models.hghub</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/torch_models/hghub/hub_api.html">onnx_diagnostic.torch_models.hghub.hub_api</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/torch_models/hghub/hub_data.html">onnx_diagnostic.torch_models.hghub.hub_data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/torch_models/hghub/model_inputs.html">onnx_diagnostic.torch_models.hghub.model_inputs</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_models/llms.html">onnx_diagnostic.torch_models.llms</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_models/validate.html">onnx_diagnostic.torch_models.validate</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/torch_onnx/index.html">onnx_diagnostic.torch_onnx</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" role="switch" type="checkbox"/><label for="toctree-checkbox-16"><div class="visually-hidden">Toggle navigation of onnx_diagnostic.torch_onnx</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_onnx/runtime_info.html">onnx_diagnostic.torch_onnx.runtime_info</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_onnx/sbs.html">onnx_diagnostic.torch_onnx.sbs</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api/api.html">onnx_diagnostic.api</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/ext_test_case.html">onnx_diagnostic.ext_test_case</a></li>
</ul>
</li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="index.html">Command Lines</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" role="switch" type="checkbox"/><label for="toctree-checkbox-17"><div class="visually-hidden">Toggle navigation of Command Lines</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="config.html">-m onnx_diagnostic config … prints the config for a model id</a></li>
<li class="toctree-l2 current current-page"><a class="current reference internal" href="#">-m onnx_diagnostic validate … validate a model id</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../auto_examples/index.html">Examples Gallery</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" role="switch" type="checkbox"/><label for="toctree-checkbox-18"><div class="visually-hidden">Toggle navigation of Examples Gallery</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_dump_intermediate_results.html">Dumps intermediate results of a torch model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_export_with_args_kwargs.html">Dynamic Shapes for <code class="docutils literal notranslate"><span class="pre">*args</span></code>, <code class="docutils literal notranslate"><span class="pre">**kwargs</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_export_tiny_llm_patched.html">Export Tiny-LLM with patches</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_export_tiny_phi2.html">Export microsoft/phi-2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_export_with_dynamic_cache.html">Export with DynamicCache and guessed dynamic shapes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_export_locate_issue.html">Find and fix an export issue due to dynamic shapes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_failing_model_extract.html">Find where a model is failing by running submodels</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_failing_reference_evaluator.html">Intermediate results with (ONNX) ReferenceEvaluator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_failing_onnxruntime_evaluator.html">Intermediate results with onnxruntime</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_export_tiny_llm.html">Steel method forward to guess inputs and dynamic shapes (with Tiny-LLM)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_export_hub_codellama.html">Test the export on untrained models</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../auto_recipes/index.html">Common Export Issues</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" role="switch" type="checkbox"/><label for="toctree-checkbox-19"><div class="visually-hidden">Toggle navigation of Common Export Issues</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../auto_recipes/plot_export_dim1.html">0, 1, 2 for a Dynamic Dimension in the dummy example to export a model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_recipes/plot_dynamic_shapes_what.html">Builds dynamic shapes from any input</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_recipes/plot_dynamic_shapes_max.html">Cannot export <code class="docutils literal notranslate"><span class="pre">torch.sym_max(x.shape[0],</span> <span class="pre">y.shape[0])</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_recipes/plot_dynamic_shapes_python_int.html">Do not use python int with dynamic shapes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_recipes/plot_export_cond.html">Export a model with a control flow (If)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_recipes/plot_dynamic_shapes_nonzero.html">Half certain nonzero</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_recipes/plot_dynamic_shapes_json.html">JSON returns list when the original dynamic shapes are list or tuple</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_recipes/plot_export_with_dynamic.html">Use DYNAMIC or AUTO when exporting if dynamic shapes has constraints</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../auto_technical/index.html">Technical Details</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" role="switch" type="checkbox"/><label for="toctree-checkbox-20"><div class="visually-hidden">Toggle navigation of Technical Details</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../auto_technical/plot_layer_norm_discrepancies.html">LayerNormalization implementation cannot be exchanged</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_technical/plot_parallelized_reduction.html">Reproducible Parallelized Reduction is difficult</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">More</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="../_sources/cmds/validate.rst" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="m-onnx-diagnostic-validate-validate-a-model-id">
<span id="l-cmd-validate"></span><h1>-m onnx_diagnostic validate … validate a model id<a class="headerlink" href="#m-onnx-diagnostic-validate-validate-a-model-id" title="Link to this heading">¶</a></h1>
<p>The command line is a wrapper around function
<a class="reference internal" href="../api/torch_models/validate.html#onnx_diagnostic.torch_models.validate.validate_model" title="onnx_diagnostic.torch_models.validate.validate_model"><code class="xref py py-func docutils literal notranslate"><span class="pre">onnx_diagnostic.torch_models.validate.validate_model()</span></code></a>.</p>
<section id="description">
<h2>Description<a class="headerlink" href="#description" title="Link to this heading">¶</a></h2>
<p>The command lines validate a model id
available on <a class="reference external" href="https://huggingface.co/docs/hub/en/index">HuggingFace</a> but not only.
It creates dummy inputs, runs the models on them,
exports the model, measures the discrepancies…</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    usage: validate [-h] [-m MID] [-t TASK] [-e EXPORT] [--opt OPT] [-r | --run | --no-run] [-q | --quiet | --no-quiet] [--patch [PATCH ...]] [--rewrite | --no-rewrite]
                    [--stop-if-static STOP_IF_STATIC] [--same-as-trained | --no-same-as-trained] [--trained | --no-trained] [--inputs2 INPUTS2] [--runtime {onnxruntime,torch,ref}]
                    [-o DUMP_FOLDER] [--drop DROP] [--opset OPSET] [--subfolder SUBFOLDER] [--ortfusiontype ORTFUSIONTYPE] [-v VERBOSE] [--dtype DTYPE] [--device DEVICE] [--iop [KEY=VALUE ...]]
                    [--mop [KEY=VALUE ...]] [--repeat REPEAT] [--warmup WARMUP] [--outnames OUTNAMES]
    
    Prints out dummy inputs for a particular task or a model id.
    If both mid and task are empty, the command line displays the list
    of supported tasks.
    
    options:
      -h, --help            show this help message and exit
      -m MID, --mid MID     model id, usually &lt;author&gt;/&lt;name&gt;
      -t TASK, --task TASK  force the task to use
      -e EXPORT, --export EXPORT
                            export the model with this exporter
      --opt OPT             optimization to apply after the export
      -r, --run, --no-run   Runs the model to check it runs.
      -q, --quiet, --no-quiet
                            Catches exception, reports them in the summary.
      --patch [PATCH ...]   Applies patches before exporting, it can be a boolean to enable to disable the patches or be more finetuned. It is possible to disable patch for torch by adding --patch &quot;patch_sympy=False&quot; --patch &quot;patch_torch=False&quot;, default is True.
      --rewrite, --no-rewrite
                            Applies rewrite before exporting.
      --stop-if-static STOP_IF_STATIC
                            Raises an exception if a dynamic dimension becomes static.
      --same-as-trained, --no-same-as-trained
                            Validates a model identical to the trained model but not trained.
      --trained, --no-trained
                            Validates the trained model (requires downloading).
      --inputs2 INPUTS2     Validates the model on a second set of inputs
                            to check the exported model supports dynamism. The values is used as an increment to the first set of inputs. A high value may trick a different behavior in the model and missed by the exporter.
      --runtime {onnxruntime,torch,ref}
                            onnx runtime to use, `onnxruntime` by default
      -o DUMP_FOLDER, --dump-folder DUMP_FOLDER
                            A folder is created to dumps statistics,
                            exported program, onnx...
      --drop DROP           Drops the following inputs names, it should be a list
                            with comma separated values, example:
                            --drop position_ids
      --opset OPSET         onnx opset to use, 18 by default
      --subfolder SUBFOLDER
                            Subfolder where to find the model and the configuration.
      --ortfusiontype ORTFUSIONTYPE
                            Applies onnxruntime fusion, this parameter should contain the
                            model type or multiple values separated by `|`. `ALL` can be used
                            to run them all.
      -v VERBOSE, --verbose VERBOSE
                            verbosity
      --dtype DTYPE         Changes dtype if necessary.
      --device DEVICE       Changes the device if necessary.
      --iop [KEY=VALUE ...]
                            Additional input options, use to change the defaultinputs use to export, example:
                              --iop cls_cache=SlidingWindowCache
                              --iop cls_cache=StaticCache
      --mop [KEY=VALUE ...]
                            Additional model options, use to change some parameters of the model, example:
                              --mop attn_implementation=sdpa --mop attn_implementation=eager
                              --mop &quot;rope_scaling={&#39;rope_type&#39;: &#39;dynamic&#39;, &#39;factor&#39;: 10.0}&quot;
      --repeat REPEAT       number of times to run the model to measures inference time
      --warmup WARMUP       number of times to run the model to do warmup
      --outnames OUTNAMES   This comma separated list defines the output names the onnx exporter should use.
    
    If the model id is specified, one untrained version of it is instantiated.
    Examples:
    
    python -m onnx_diagnostic validate -m microsoft/Phi-4-mini-reasoning \
        --run -v 1 -o dump_test --no-quiet --repeat 2 --warmup 2 \
        --dtype float16 --device cuda --patch --export onnx-dynamo --opt ir
    
    python -m onnx_diagnostic validate -m microsoft/Phi-4-mini-reasoning \
        --run -v 1 -o dump_test --no-quiet --repeat 2 --warmup 2 \
        --dtype float16 --device cuda --patch --export custom --opt default
    
    python -m onnx_diagnostic validate -m microsoft/Phi-4-mini-reasoning \
        --run -v 1 -o dump_test --no-quiet --repeat 2 --warmup 2 \
        --dtype float16 --device cuda --export modelbuilder
    
    position_ids is usually not needed, they can be removed by adding:
    
    --drop position_ids
    
    The behaviour may be modified compare the original configuration,
    the following argument can be rope_scaling to dynamic:
    
    --mop &quot;rope_scaling={&#39;rope_type&#39;: &#39;dynamic&#39;, &#39;factor&#39;: 10.0}&quot;&quot;
</pre></div>
</div>
</section>
<section id="get-the-list-of-supported-tasks">
<h2>Get the list of supported tasks<a class="headerlink" href="#get-the-list-of-supported-tasks" title="Link to this heading">¶</a></h2>
<p>The task are the same defined by <a class="reference external" href="https://huggingface.co/docs/hub/en/index">HuggingFace</a>.
The tool only supports a subset of them.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">onnx_diagnostic</span> <span class="n">validate</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="o">--</span> <span class="nb">list</span> <span class="n">of</span> <span class="n">supported</span> <span class="n">tasks</span><span class="p">:</span>
    <span class="n">MoE</span>
    <span class="n">automatic</span><span class="o">-</span><span class="n">speech</span><span class="o">-</span><span class="n">recognition</span>
    <span class="n">feature</span><span class="o">-</span><span class="n">extraction</span>
    <span class="n">fill</span><span class="o">-</span><span class="n">mask</span>
    <span class="n">image</span><span class="o">-</span><span class="n">classification</span>
    <span class="n">image</span><span class="o">-</span><span class="n">text</span><span class="o">-</span><span class="n">to</span><span class="o">-</span><span class="n">text</span>
    <span class="n">mask</span><span class="o">-</span><span class="n">generation</span>
    <span class="nb">object</span><span class="o">-</span><span class="n">detection</span>
    <span class="n">sentence</span><span class="o">-</span><span class="n">similarity</span>
    <span class="n">summarization</span>
    <span class="n">text</span><span class="o">-</span><span class="n">classification</span>
    <span class="n">text</span><span class="o">-</span><span class="n">generation</span>
    <span class="n">text</span><span class="o">-</span><span class="n">to</span><span class="o">-</span><span class="n">image</span>
    <span class="n">text2text</span><span class="o">-</span><span class="n">generation</span>
    <span class="n">zero</span><span class="o">-</span><span class="n">shot</span><span class="o">-</span><span class="n">image</span><span class="o">-</span><span class="n">classification</span>
</pre></div>
</div>
</section>
<section id="get-the-default-inputs-for-a-specific-task">
<h2>Get the default inputs for a specific task<a class="headerlink" href="#get-the-default-inputs-for-a-specific-task" title="Link to this heading">¶</a></h2>
<p>This returns the dummy inputs for a specific task.
There may be too many inputs. Only those the forward method
defines are kept.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">onnx_diagnostic</span> <span class="n">validate</span> <span class="o">-</span><span class="n">t</span> <span class="n">text</span><span class="o">-</span><span class="n">generation</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="o">--</span> <span class="n">inputs</span>
      <span class="o">+</span> <span class="n">input_ids</span>       <span class="p">:</span> <span class="n">T7s2x3</span>
      <span class="o">+</span> <span class="n">attention_mask</span>  <span class="p">:</span> <span class="n">T7s2x33</span>
      <span class="o">+</span> <span class="n">position_ids</span>    <span class="p">:</span> <span class="n">T7s2x3</span>
      <span class="o">+</span> <span class="n">past_key_values</span> <span class="p">:</span> <span class="n">DynamicCache</span><span class="p">(</span><span class="n">key_cache</span><span class="o">=</span><span class="c1">#4[T1s2x24x30x16,T1s2x24x30x16,T1s2x24x30x16,T1s2x24x30x16], value_cache=#4[T1s2x24x30x16,T1s2x24x30x16,T1s2x24x30x16,T1s2x24x30x16])</span>
    <span class="o">--</span> <span class="n">dynamic_shapes</span>
      <span class="o">+</span> <span class="n">input_ids</span>       <span class="p">:</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span><span class="n">Dim</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span><span class="mi">1</span><span class="p">:</span><span class="n">DYN</span><span class="p">(</span><span class="n">seq_length</span><span class="p">)}</span>
      <span class="o">+</span> <span class="n">attention_mask</span>  <span class="p">:</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span><span class="n">Dim</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span><span class="mi">1</span><span class="p">:</span><span class="n">DYN</span><span class="p">(</span><span class="n">cache</span><span class="o">+</span><span class="n">seq</span><span class="p">)}</span>
      <span class="o">+</span> <span class="n">position_ids</span>    <span class="p">:</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span><span class="n">Dim</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span><span class="mi">1</span><span class="p">:</span><span class="n">DYN</span><span class="p">(</span><span class="n">cache</span><span class="o">+</span><span class="n">seq</span><span class="p">)}</span>
      <span class="o">+</span> <span class="n">past_key_values</span> <span class="p">:</span> <span class="c1">#2[#4[{0:Dim(batch),2:DYN(cache_length)},{0:Dim(batch),2:DYN(cache_length)},{0:Dim(batch),2:DYN(cache_length)},{0:Dim(batch),2:DYN(cache_length)}],#4[{0:Dim(batch),2:DYN(cache_length)},{0:Dim(batch),2:DYN(cache_length)},{0:Dim(batch),2:DYN(cache_length)},{0:Dim(batch),2:DYN(cache_length)}]]</span>
</pre></div>
</div>
</section>
<section id="validate-dummy-inputs-for-a-model">
<h2>Validate dummy inputs for a model<a class="headerlink" href="#validate-dummy-inputs-for-a-model" title="Link to this heading">¶</a></h2>
<p>The dummy inputs may not work for this model and this task.
The following command line checks that. It is no use to export
if this fails.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">onnx_diagnostic</span> <span class="n">validate</span> <span class="o">-</span><span class="n">m</span> <span class="n">arnir0</span><span class="o">/</span><span class="n">Tiny</span><span class="o">-</span><span class="n">LLM</span> <span class="o">--</span><span class="n">run</span> <span class="o">-</span><span class="n">v</span> <span class="mi">1</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="n">validate</span> <span class="n">model</span> <span class="nb">id</span> <span class="s1">&#39;arnir0/Tiny-LLM&#39;</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="n">patch</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="n">get</span> <span class="n">dummy</span> <span class="n">inputs</span> <span class="k">with</span> <span class="n">input_options</span><span class="o">=</span><span class="kc">None</span><span class="o">...</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="n">rewrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">patch_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;patch_transformers&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span> <span class="s1">&#39;patch_diffusers&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span> <span class="s1">&#39;patch&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">},</span> <span class="n">stop_if_static</span><span class="o">=</span><span class="mi">0</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="n">exporter</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">optimization</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="n">dump_folder</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="n">output_names</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">[</span><span class="n">get_untrained_model_with_inputs</span><span class="p">]</span> <span class="n">model_id</span><span class="o">=</span><span class="s1">&#39;arnir0/Tiny-LLM&#39;</span>
    <span class="p">[</span><span class="n">get_untrained_model_with_inputs</span><span class="p">]</span> <span class="n">use</span> <span class="n">preinstalled</span> <span class="s1">&#39;arnir0/Tiny-LLM&#39;</span>
    <span class="p">[</span><span class="n">get_untrained_model_with_inputs</span><span class="p">]</span> <span class="n">architectures</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;LlamaForCausalLM&#39;</span><span class="p">]</span>
    <span class="p">[</span><span class="n">get_untrained_model_with_inputs</span><span class="p">]</span> <span class="bp">cls</span><span class="o">=</span><span class="s1">&#39;LlamaConfig&#39;</span>
    <span class="p">[</span><span class="n">get_untrained_model_with_inputs</span><span class="p">]</span> <span class="n">task</span><span class="o">=</span><span class="s1">&#39;text-generation&#39;</span>
    <span class="p">[</span><span class="n">get_untrained_model_with_inputs</span><span class="p">]</span> <span class="n">default</span> <span class="n">config</span><span class="o">.</span><span class="n">_attn_implementation</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">[</span><span class="n">get_untrained_model_with_inputs</span><span class="p">]</span> <span class="n">use</span> <span class="n">fct</span><span class="o">=&lt;</span><span class="n">function</span> <span class="n">get_inputs</span> <span class="n">at</span> <span class="mh">0x726e5d185b20</span><span class="o">&gt;</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="o">--</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="n">task</span><span class="o">=</span><span class="n">text</span><span class="o">-</span><span class="n">generation</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="n">size</span><span class="o">=</span><span class="mf">49.549072265625</span> <span class="n">Mb</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="n">n_weights</span><span class="o">=</span><span class="mf">12.988992</span> <span class="n">millions</span> <span class="n">parameters</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="o">+</span><span class="n">INPUT</span> <span class="n">input_ids</span><span class="o">=</span><span class="n">T7s2x3</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="o">+</span><span class="n">INPUT</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">T7s2x33</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="o">+</span><span class="n">INPUT</span> <span class="n">position_ids</span><span class="o">=</span><span class="n">T7s2x3</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="o">+</span><span class="n">INPUT</span> <span class="n">past_key_values</span><span class="o">=</span><span class="n">DynamicCache</span><span class="p">(</span><span class="n">key_cache</span><span class="o">=</span><span class="c1">#1[T1s2x1x30x96], value_cache=#1[T1s2x1x30x96])</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="o">+</span><span class="n">SHAPE</span> <span class="n">input_ids</span><span class="o">=</span><span class="p">{</span><span class="mi">0</span><span class="p">:</span><span class="n">Dim</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span><span class="mi">1</span><span class="p">:</span><span class="n">DYN</span><span class="p">(</span><span class="n">seq_length</span><span class="p">)}</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="o">+</span><span class="n">SHAPE</span> <span class="n">attention_mask</span><span class="o">=</span><span class="p">{</span><span class="mi">0</span><span class="p">:</span><span class="n">Dim</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span><span class="mi">1</span><span class="p">:</span><span class="n">DYN</span><span class="p">(</span><span class="n">cache</span><span class="o">+</span><span class="n">seq</span><span class="p">)}</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="o">+</span><span class="n">SHAPE</span> <span class="n">position_ids</span><span class="o">=</span><span class="p">{</span><span class="mi">0</span><span class="p">:</span><span class="n">Dim</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span><span class="mi">1</span><span class="p">:</span><span class="n">DYN</span><span class="p">(</span><span class="n">cache</span><span class="o">+</span><span class="n">seq</span><span class="p">)}</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="o">+</span><span class="n">SHAPE</span> <span class="n">past_key_values</span><span class="o">=</span><span class="c1">#2[#1[{0:Dim(batch),2:DYN(cache_length)}],#1[{0:Dim(batch),2:DYN(cache_length)}]]</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="o">--</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="o">--</span> <span class="n">run</span> <span class="n">the</span> <span class="n">model</span> <span class="n">inputs</span><span class="o">=</span><span class="s1">&#39;inputs&#39;</span><span class="o">...</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="n">inputs</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">input_ids</span><span class="p">:</span><span class="n">T7s2x3</span><span class="p">,</span><span class="n">attention_mask</span><span class="p">:</span><span class="n">T7s2x33</span><span class="p">,</span><span class="n">position_ids</span><span class="p">:</span><span class="n">T7s2x3</span><span class="p">,</span><span class="n">past_key_values</span><span class="p">:</span><span class="n">DynamicCache</span><span class="p">(</span><span class="n">key_cache</span><span class="o">=</span><span class="c1">#1[T1s2x1x30x96], value_cache=#1[T1s2x1x30x96]))</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="n">done</span> <span class="p">([</span><span class="n">run</span><span class="p">])</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="o">--</span> <span class="n">run</span> <span class="n">the</span> <span class="n">model</span> <span class="n">inputs</span><span class="o">=</span><span class="s1">&#39;inputs2&#39;</span><span class="o">...</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="n">inputs2</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">input_ids</span><span class="p">:</span><span class="n">T7s3x4</span><span class="p">,</span><span class="n">attention_mask</span><span class="p">:</span><span class="n">T7s3x35</span><span class="p">,</span><span class="n">position_ids</span><span class="p">:</span><span class="n">T7s3x4</span><span class="p">,</span><span class="n">past_key_values</span><span class="p">:</span><span class="n">DynamicCache</span><span class="p">(</span><span class="n">key_cache</span><span class="o">=</span><span class="c1">#1[T1s3x1x31x96], value_cache=#1[T1s3x1x31x96]))</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="n">done</span> <span class="p">([</span><span class="n">run2</span><span class="p">])</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="o">--</span> <span class="n">done</span> <span class="p">(</span><span class="n">final</span><span class="p">)</span>
    
    <span class="o">--</span> <span class="n">summary</span> <span class="o">--</span>
    <span class="p">:</span><span class="n">model_class</span><span class="p">,</span><span class="n">LlamaForCausalLM</span><span class="p">;</span>
    <span class="p">:</span><span class="n">model_config</span><span class="p">,{</span><span class="s1">&#39;vocab_size&#39;</span><span class="p">:</span><span class="mi">32000</span><span class="p">,</span><span class="s1">&#39;max_position_embeddings&#39;</span><span class="p">:</span><span class="mi">1024</span><span class="p">,</span><span class="s1">&#39;hidden_size&#39;</span><span class="p">:</span><span class="mi">192</span><span class="p">,</span><span class="s1">&#39;intermediate_size&#39;</span><span class="p">:</span><span class="mi">1024</span><span class="p">,</span><span class="s1">&#39;num_hidden_layers&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;num_attention_heads&#39;</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span><span class="s1">&#39;num_key_value_heads&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;hidden_act&#39;</span><span class="p">:</span><span class="s1">&#39;silu&#39;</span><span class="p">,</span><span class="s1">&#39;initializer_range&#39;</span><span class="p">:</span><span class="mf">0.02</span><span class="p">,</span><span class="s1">&#39;rms_norm_eps&#39;</span><span class="p">:</span><span class="mf">1e-05</span><span class="p">,</span><span class="s1">&#39;pretraining_tp&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;use_cache&#39;</span><span class="p">:</span><span class="kc">True</span><span class="p">,</span><span class="s1">&#39;rope_theta&#39;</span><span class="p">:</span><span class="mf">10000.0</span><span class="p">,</span><span class="s1">&#39;rope_scaling&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;attention_bias&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span><span class="s1">&#39;attention_dropout&#39;</span><span class="p">:</span><span class="mf">0.0</span><span class="p">,</span><span class="s1">&#39;mlp_bias&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span><span class="s1">&#39;head_dim&#39;</span><span class="p">:</span><span class="mi">96</span><span class="p">,</span><span class="s1">&#39;return_dict&#39;</span><span class="p">:</span><span class="kc">True</span><span class="p">,</span><span class="s1">&#39;output_hidden_states&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span><span class="s1">&#39;torchscript&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span><span class="s1">&#39;dtype&#39;</span><span class="p">:</span><span class="s1">&#39;float32&#39;</span><span class="p">,</span><span class="s1">&#39;pruned_heads&#39;</span><span class="p">:{},</span><span class="s1">&#39;tie_word_embeddings&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span><span class="s1">&#39;chunk_size_feed_forward&#39;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="s1">&#39;is_encoder_decoder&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span><span class="s1">&#39;is_decoder&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span><span class="s1">&#39;cross_attention_hidden_size&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;add_cross_attention&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span><span class="s1">&#39;tie_encoder_decoder&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span><span class="s1">&#39;architectures&#39;</span><span class="p">:[</span><span class="s1">&#39;LlamaForCausalLM&#39;</span><span class="p">],</span><span class="s1">&#39;finetuning_task&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;id2label&#39;</span><span class="p">:{</span><span class="mi">0</span><span class="p">:</span><span class="s1">&#39;LABEL_0&#39;</span><span class="p">,</span><span class="mi">1</span><span class="p">:</span><span class="s1">&#39;LABEL_1&#39;</span><span class="p">},</span><span class="s1">&#39;label2id&#39;</span><span class="p">:{</span><span class="s1">&#39;LABEL_0&#39;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="s1">&#39;LABEL_1&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">},</span><span class="s1">&#39;task_specific_params&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;problem_type&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;tokenizer_class&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;prefix&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;bos_token_id&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;pad_token_id&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;eos_token_id&#39;</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span><span class="s1">&#39;sep_token_id&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;decoder_start_token_id&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;max_length&#39;</span><span class="p">:</span><span class="mi">20</span><span class="p">,</span><span class="s1">&#39;min_length&#39;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="s1">&#39;do_sample&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span><span class="s1">&#39;early_stopping&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span><span class="s1">&#39;num_beams&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;num_beam_groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;diversity_penalty&#39;</span><span class="p">:</span><span class="mf">0.0</span><span class="p">,</span><span class="s1">&#39;temperature&#39;</span><span class="p">:</span><span class="mf">1.0</span><span class="p">,</span><span class="s1">&#39;top_k&#39;</span><span class="p">:</span><span class="mi">50</span><span class="p">,</span><span class="s1">&#39;top_p&#39;</span><span class="p">:</span><span class="mf">1.0</span><span class="p">,</span><span class="s1">&#39;typical_p&#39;</span><span class="p">:</span><span class="mf">1.0</span><span class="p">,</span><span class="s1">&#39;repetition_penalty&#39;</span><span class="p">:</span><span class="mf">1.0</span><span class="p">,</span><span class="s1">&#39;length_penalty&#39;</span><span class="p">:</span><span class="mf">1.0</span><span class="p">,</span><span class="s1">&#39;no_repeat_ngram_size&#39;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="s1">&#39;encoder_no_repeat_ngram_size&#39;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="s1">&#39;bad_words_ids&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;num_return_sequences&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;output_scores&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span><span class="s1">&#39;return_dict_in_generate&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span><span class="s1">&#39;forced_bos_token_id&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;forced_eos_token_id&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;remove_invalid_values&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span><span class="s1">&#39;exponential_decay_length_penalty&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;suppress_tokens&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;begin_suppress_tokens&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;_name_or_path&#39;</span><span class="p">:</span><span class="s1">&#39;&#39;</span><span class="p">,</span><span class="s1">&#39;transformers_version&#39;</span><span class="p">:</span><span class="s1">&#39;4.56.0.dev0&#39;</span><span class="p">,</span><span class="s1">&#39;model_type&#39;</span><span class="p">:</span><span class="s1">&#39;llama&#39;</span><span class="p">,</span><span class="s1">&#39;tf_legacy_loss&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span><span class="s1">&#39;use_bfloat16&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span><span class="s1">&#39;subfolder&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;output_attentions&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">};</span>
    <span class="p">:</span><span class="n">model_config_class</span><span class="p">,</span><span class="n">LlamaConfig</span><span class="p">;</span>
    <span class="p">:</span><span class="n">model_file</span><span class="p">,</span><span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">xadupre</span><span class="o">/</span><span class="n">github</span><span class="o">/</span><span class="n">transformers</span><span class="o">/</span><span class="n">src</span><span class="o">/</span><span class="n">transformers</span><span class="o">/</span><span class="n">models</span><span class="o">/</span><span class="n">llama</span><span class="o">/</span><span class="n">modeling_llama</span><span class="o">.</span><span class="n">py</span><span class="p">;</span>
    <span class="p">:</span><span class="n">model_id</span><span class="p">,</span><span class="n">arnir0</span><span class="o">/</span><span class="n">Tiny</span><span class="o">-</span><span class="n">LLM</span><span class="p">;</span>
    <span class="p">:</span><span class="n">model_inputs</span><span class="p">,</span><span class="nb">dict</span><span class="p">(</span><span class="n">input_ids</span><span class="p">:</span><span class="n">T7s2x3</span><span class="p">,</span><span class="n">attention_mask</span><span class="p">:</span><span class="n">T7s2x33</span><span class="p">,</span><span class="n">position_ids</span><span class="p">:</span><span class="n">T7s2x3</span><span class="p">,</span><span class="n">past_key_values</span><span class="p">:</span><span class="n">DynamicCache</span><span class="p">(</span><span class="n">key_cache</span><span class="o">=</span><span class="c1">#1[T1s2x1x30x96], value_cache=#1[T1s2x1x30x96]));</span>
    <span class="p">:</span><span class="n">model_inputs_options</span><span class="p">,;</span>
    <span class="p">:</span><span class="n">model_module</span><span class="p">,</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">llama</span><span class="o">.</span><span class="n">modeling_llama</span><span class="p">;</span>
    <span class="p">:</span><span class="n">model_nweights</span><span class="p">,</span><span class="mi">12988992</span><span class="p">;</span>
    <span class="p">:</span><span class="n">model_shapes</span><span class="p">,</span><span class="nb">dict</span><span class="p">(</span><span class="n">input_ids</span><span class="p">:{</span><span class="mi">0</span><span class="p">:</span><span class="n">Dim</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span><span class="mi">1</span><span class="p">:</span><span class="n">DYN</span><span class="p">(</span><span class="n">seq_length</span><span class="p">)},</span><span class="n">attention_mask</span><span class="p">:{</span><span class="mi">0</span><span class="p">:</span><span class="n">Dim</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span><span class="mi">1</span><span class="p">:</span><span class="n">DYN</span><span class="p">(</span><span class="n">cache</span><span class="o">+</span><span class="n">seq</span><span class="p">)},</span><span class="n">position_ids</span><span class="p">:{</span><span class="mi">0</span><span class="p">:</span><span class="n">Dim</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span><span class="mi">1</span><span class="p">:</span><span class="n">DYN</span><span class="p">(</span><span class="n">cache</span><span class="o">+</span><span class="n">seq</span><span class="p">)},</span><span class="n">past_key_values</span><span class="p">:</span><span class="c1">#2[#1[{0:Dim(batch),2:DYN(cache_length)}],#1[{0:Dim(batch),2:DYN(cache_length)}]]);</span>
    <span class="p">:</span><span class="n">model_size</span><span class="p">,</span><span class="mi">51955968</span><span class="p">;</span>
    <span class="p">:</span><span class="n">model_subfolder</span><span class="p">,;</span>
    <span class="p">:</span><span class="n">model_task</span><span class="p">,</span><span class="n">text</span><span class="o">-</span><span class="n">generation</span><span class="p">;</span>
    <span class="p">:</span><span class="n">run_expected</span><span class="p">,</span><span class="n">CausalLMOutputWithPast</span><span class="p">(</span><span class="n">logits</span><span class="p">:</span><span class="n">T1s2x3x32000</span><span class="p">,</span><span class="n">past_key_values</span><span class="p">:</span><span class="n">DynamicCache</span><span class="p">(</span><span class="n">key_cache</span><span class="o">=</span><span class="c1">#1[T1s2x1x33x96], value_cache=#1[T1s2x1x33x96]));</span>
    <span class="p">:</span><span class="n">run_expected2</span><span class="p">,</span><span class="n">CausalLMOutputWithPast</span><span class="p">(</span><span class="n">logits</span><span class="p">:</span><span class="n">T1s3x4x32000</span><span class="p">,</span><span class="n">past_key_values</span><span class="p">:</span><span class="n">DynamicCache</span><span class="p">(</span><span class="n">key_cache</span><span class="o">=</span><span class="c1">#1[T1s3x1x35x96], value_cache=#1[T1s3x1x35x96]));</span>
    <span class="p">:</span><span class="n">time_create</span><span class="p">,</span><span class="mf">0.16615501700107416</span><span class="p">;</span>
    <span class="p">:</span><span class="n">time_run</span><span class="p">,</span><span class="mf">0.04875091000030807</span><span class="p">;</span>
    <span class="p">:</span><span class="n">time_run2</span><span class="p">,</span><span class="mf">0.026418173998536076</span><span class="p">;</span>
    <span class="p">:</span><span class="n">version_date</span><span class="p">,</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">27</span><span class="n">T17</span><span class="p">:</span><span class="mi">08</span><span class="p">:</span><span class="mi">23</span><span class="p">;</span>
    <span class="p">:</span><span class="n">version_device</span><span class="p">,;</span>
    <span class="p">:</span><span class="n">version_do_run</span><span class="p">,</span><span class="kc">True</span><span class="p">;</span>
    <span class="p">:</span><span class="n">version_drop_inputs</span><span class="p">,[];</span>
    <span class="p">:</span><span class="n">version_dtype</span><span class="p">,;</span>
    <span class="p">:</span><span class="n">version_dump_folder</span><span class="p">,;</span>
    <span class="p">:</span><span class="n">version_exporter</span><span class="p">,;</span>
    <span class="p">:</span><span class="n">version_inputs2</span><span class="p">,</span><span class="mi">1</span><span class="p">;</span>
    <span class="p">:</span><span class="n">version_model_id</span><span class="p">,</span><span class="n">arnir0</span><span class="o">/</span><span class="n">Tiny</span><span class="o">-</span><span class="n">LLM</span><span class="p">;</span>
    <span class="p">:</span><span class="n">version_numpy</span><span class="p">,</span><span class="mf">2.3.2</span><span class="p">;</span>
    <span class="p">:</span><span class="n">version_onnx</span><span class="p">,</span><span class="mf">1.20.0</span><span class="p">;</span>
    <span class="p">:</span><span class="n">version_onnx_diagnostic</span><span class="p">,</span><span class="mf">0.7.7</span><span class="p">;</span>
    <span class="p">:</span><span class="n">version_onnx_ir</span><span class="p">,</span><span class="mf">0.1.8</span><span class="p">;</span>
    <span class="p">:</span><span class="n">version_onnxruntime</span><span class="p">,</span><span class="mf">1.23.0</span><span class="p">;</span>
    <span class="p">:</span><span class="n">version_onnxscript</span><span class="p">,</span><span class="mf">0.3.0</span><span class="o">.</span><span class="n">dev20250301</span><span class="p">;</span>
    <span class="p">:</span><span class="n">version_opset</span><span class="p">,</span><span class="mi">18</span><span class="p">;</span>
    <span class="p">:</span><span class="n">version_optimization</span><span class="p">,;</span>
    <span class="p">:</span><span class="n">version_ortfusiontype</span><span class="p">,;</span>
    <span class="p">:</span><span class="n">version_patch</span><span class="p">,</span><span class="kc">True</span><span class="p">;</span>
    <span class="p">:</span><span class="n">version_patch_kwargs</span><span class="p">,{</span><span class="s1">&#39;patch_transformers&#39;</span><span class="p">:</span><span class="kc">True</span><span class="p">,</span><span class="s1">&#39;patch_diffusers&#39;</span><span class="p">:</span><span class="kc">True</span><span class="p">,</span><span class="s1">&#39;patch&#39;</span><span class="p">:</span><span class="kc">True</span><span class="p">};</span>
    <span class="p">:</span><span class="n">version_quiet</span><span class="p">,</span><span class="kc">False</span><span class="p">;</span>
    <span class="p">:</span><span class="n">version_rewrite</span><span class="p">,</span><span class="kc">True</span><span class="p">;</span>
    <span class="p">:</span><span class="n">version_runtime</span><span class="p">,</span><span class="n">onnxruntime</span><span class="p">;</span>
    <span class="p">:</span><span class="n">version_same_as_pretrained</span><span class="p">,</span><span class="kc">False</span><span class="p">;</span>
    <span class="p">:</span><span class="n">version_scipy</span><span class="p">,</span><span class="mf">1.16.1</span><span class="p">;</span>
    <span class="p">:</span><span class="n">version_stop_if_static</span><span class="p">,</span><span class="mi">0</span><span class="p">;</span>
    <span class="p">:</span><span class="n">version_torch</span><span class="p">,</span><span class="mf">2.9.0</span><span class="o">.</span><span class="n">dev20250820</span><span class="o">+</span><span class="n">cu126</span><span class="p">;</span>
    <span class="p">:</span><span class="n">version_transformers</span><span class="p">,</span><span class="mf">4.56.0</span><span class="o">.</span><span class="n">dev0</span><span class="p">;</span>
    <span class="p">:</span><span class="n">version_use_pretrained</span><span class="p">,</span><span class="kc">False</span><span class="p">;</span>
</pre></div>
</div>
</section>
<section id="validate-and-export-a-model">
<h2>Validate and export a model<a class="headerlink" href="#validate-and-export-a-model" title="Link to this heading">¶</a></h2>
<p>Exports a model given the task. Checks for discrepancies as well.
The latency given are just for one run. It tells how long the benchmark
runs but it is far from the latency measure we can get by running multiple times
the same model.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">onnx_diagnostic</span> <span class="n">validate</span> <span class="o">-</span><span class="n">m</span> <span class="n">arnir0</span><span class="o">/</span><span class="n">Tiny</span><span class="o">-</span><span class="n">LLM</span> <span class="o">--</span><span class="n">run</span> <span class="o">-</span><span class="n">v</span> <span class="mi">1</span> <span class="o">--</span><span class="n">export</span> <span class="n">export</span><span class="o">-</span><span class="n">nostrict</span> <span class="o">-</span><span class="n">o</span> <span class="n">dump_models</span> <span class="o">--</span><span class="n">patch</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="n">dump</span> <span class="n">into</span> <span class="s1">&#39;arnir0_Tiny-LLM-export-nostrict&#39;</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="n">validate</span> <span class="n">model</span> <span class="nb">id</span> <span class="s1">&#39;arnir0/Tiny-LLM&#39;</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="n">patch</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="n">get</span> <span class="n">dummy</span> <span class="n">inputs</span> <span class="k">with</span> <span class="n">input_options</span><span class="o">=</span><span class="kc">None</span><span class="o">...</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="n">rewrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">patch_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;patch_transformers&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span> <span class="s1">&#39;patch_diffusers&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span> <span class="s1">&#39;patch&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">},</span> <span class="n">stop_if_static</span><span class="o">=</span><span class="mi">0</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="n">exporter</span><span class="o">=</span><span class="s1">&#39;export-nostrict&#39;</span><span class="p">,</span> <span class="n">optimization</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="n">dump_folder</span><span class="o">=</span><span class="s1">&#39;dump_models/arnir0_Tiny-LLM-export-nostrict&#39;</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="n">output_names</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">[</span><span class="n">get_untrained_model_with_inputs</span><span class="p">]</span> <span class="n">model_id</span><span class="o">=</span><span class="s1">&#39;arnir0/Tiny-LLM&#39;</span>
    <span class="p">[</span><span class="n">get_untrained_model_with_inputs</span><span class="p">]</span> <span class="n">use</span> <span class="n">preinstalled</span> <span class="s1">&#39;arnir0/Tiny-LLM&#39;</span>
    <span class="p">[</span><span class="n">get_untrained_model_with_inputs</span><span class="p">]</span> <span class="n">architectures</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;LlamaForCausalLM&#39;</span><span class="p">]</span>
    <span class="p">[</span><span class="n">get_untrained_model_with_inputs</span><span class="p">]</span> <span class="bp">cls</span><span class="o">=</span><span class="s1">&#39;LlamaConfig&#39;</span>
    <span class="p">[</span><span class="n">get_untrained_model_with_inputs</span><span class="p">]</span> <span class="n">task</span><span class="o">=</span><span class="s1">&#39;text-generation&#39;</span>
    <span class="p">[</span><span class="n">get_untrained_model_with_inputs</span><span class="p">]</span> <span class="n">default</span> <span class="n">config</span><span class="o">.</span><span class="n">_attn_implementation</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">[</span><span class="n">get_untrained_model_with_inputs</span><span class="p">]</span> <span class="n">use</span> <span class="n">fct</span><span class="o">=&lt;</span><span class="n">function</span> <span class="n">get_inputs</span> <span class="n">at</span> <span class="mh">0x726e5d185b20</span><span class="o">&gt;</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="o">--</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="n">task</span><span class="o">=</span><span class="n">text</span><span class="o">-</span><span class="n">generation</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="n">size</span><span class="o">=</span><span class="mf">49.549072265625</span> <span class="n">Mb</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="n">n_weights</span><span class="o">=</span><span class="mf">12.988992</span> <span class="n">millions</span> <span class="n">parameters</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="o">+</span><span class="n">INPUT</span> <span class="n">input_ids</span><span class="o">=</span><span class="n">T7s2x3</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="o">+</span><span class="n">INPUT</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">T7s2x33</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="o">+</span><span class="n">INPUT</span> <span class="n">position_ids</span><span class="o">=</span><span class="n">T7s2x3</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="o">+</span><span class="n">INPUT</span> <span class="n">past_key_values</span><span class="o">=</span><span class="n">DynamicCache</span><span class="p">(</span><span class="n">key_cache</span><span class="o">=</span><span class="c1">#1[T1s2x1x30x96], value_cache=#1[T1s2x1x30x96])</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="o">+</span><span class="n">SHAPE</span> <span class="n">input_ids</span><span class="o">=</span><span class="p">{</span><span class="mi">0</span><span class="p">:</span><span class="n">Dim</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span><span class="mi">1</span><span class="p">:</span><span class="n">DYN</span><span class="p">(</span><span class="n">seq_length</span><span class="p">)}</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="o">+</span><span class="n">SHAPE</span> <span class="n">attention_mask</span><span class="o">=</span><span class="p">{</span><span class="mi">0</span><span class="p">:</span><span class="n">Dim</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span><span class="mi">1</span><span class="p">:</span><span class="n">DYN</span><span class="p">(</span><span class="n">cache</span><span class="o">+</span><span class="n">seq</span><span class="p">)}</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="o">+</span><span class="n">SHAPE</span> <span class="n">position_ids</span><span class="o">=</span><span class="p">{</span><span class="mi">0</span><span class="p">:</span><span class="n">Dim</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span><span class="mi">1</span><span class="p">:</span><span class="n">DYN</span><span class="p">(</span><span class="n">cache</span><span class="o">+</span><span class="n">seq</span><span class="p">)}</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="o">+</span><span class="n">SHAPE</span> <span class="n">past_key_values</span><span class="o">=</span><span class="c1">#2[#1[{0:Dim(batch),2:DYN(cache_length)}],#1[{0:Dim(batch),2:DYN(cache_length)}]]</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="o">--</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="o">--</span> <span class="n">run</span> <span class="n">the</span> <span class="n">model</span> <span class="n">inputs</span><span class="o">=</span><span class="s1">&#39;inputs&#39;</span><span class="o">...</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="n">inputs</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">input_ids</span><span class="p">:</span><span class="n">T7s2x3</span><span class="p">,</span><span class="n">attention_mask</span><span class="p">:</span><span class="n">T7s2x33</span><span class="p">,</span><span class="n">position_ids</span><span class="p">:</span><span class="n">T7s2x3</span><span class="p">,</span><span class="n">past_key_values</span><span class="p">:</span><span class="n">DynamicCache</span><span class="p">(</span><span class="n">key_cache</span><span class="o">=</span><span class="c1">#1[T1s2x1x30x96], value_cache=#1[T1s2x1x30x96]))</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="n">done</span> <span class="p">([</span><span class="n">run</span><span class="p">])</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="o">--</span> <span class="n">run</span> <span class="n">the</span> <span class="n">model</span> <span class="n">inputs</span><span class="o">=</span><span class="s1">&#39;inputs2&#39;</span><span class="o">...</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="n">inputs2</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">input_ids</span><span class="p">:</span><span class="n">T7s3x4</span><span class="p">,</span><span class="n">attention_mask</span><span class="p">:</span><span class="n">T7s3x35</span><span class="p">,</span><span class="n">position_ids</span><span class="p">:</span><span class="n">T7s3x4</span><span class="p">,</span><span class="n">past_key_values</span><span class="p">:</span><span class="n">DynamicCache</span><span class="p">(</span><span class="n">key_cache</span><span class="o">=</span><span class="c1">#1[T1s3x1x31x96], value_cache=#1[T1s3x1x31x96]))</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="n">done</span> <span class="p">([</span><span class="n">run2</span><span class="p">])</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="o">--</span> <span class="n">export</span> <span class="n">the</span> <span class="n">model</span> <span class="k">with</span> <span class="s1">&#39;export-nostrict&#39;</span><span class="p">,</span> <span class="n">optimization</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="n">applies</span> <span class="n">patches</span> <span class="n">before</span> <span class="n">exporting</span> <span class="n">stop_if_static</span><span class="o">=</span><span class="mi">0</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="n">run</span> <span class="n">patched</span> <span class="n">model</span><span class="o">...</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="n">patched</span> <span class="n">inputs</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">input_ids</span><span class="p">:</span><span class="n">T7s2x3</span><span class="p">,</span><span class="n">attention_mask</span><span class="p">:</span><span class="n">T7s2x33</span><span class="p">,</span><span class="n">position_ids</span><span class="p">:</span><span class="n">T7s2x3</span><span class="p">,</span><span class="n">past_key_values</span><span class="p">:</span><span class="n">DynamicCache</span><span class="p">(</span><span class="n">key_cache</span><span class="o">=</span><span class="c1">#1[T1s2x1x30x96], value_cache=#1[T1s2x1x30x96]))</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="n">done</span> <span class="p">(</span><span class="n">patched</span> <span class="n">run</span><span class="p">)</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="n">patched</span> <span class="n">discrepancies</span><span class="o">=</span><span class="nb">abs</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">rel</span><span class="o">=</span><span class="mi">0</span>
    <span class="p">[</span><span class="n">call_torch_export_export</span><span class="p">]</span> <span class="n">exporter</span><span class="o">=</span><span class="s1">&#39;export-nostrict&#39;</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">optimization</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">[</span><span class="n">call_torch_export_export</span><span class="p">]</span> <span class="n">args</span><span class="o">=</span><span class="p">()</span>
    <span class="p">[</span><span class="n">call_torch_export_export</span><span class="p">]</span> <span class="n">kwargs</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">input_ids</span><span class="p">:</span><span class="n">T7s2x3</span><span class="p">,</span><span class="n">attention_mask</span><span class="p">:</span><span class="n">T7s2x33</span><span class="p">,</span><span class="n">position_ids</span><span class="p">:</span><span class="n">T7s2x3</span><span class="p">,</span><span class="n">past_key_values</span><span class="p">:</span><span class="n">DynamicCache</span><span class="p">(</span><span class="n">key_cache</span><span class="o">=</span><span class="c1">#1[T1s2x1x30x96], value_cache=#1[T1s2x1x30x96]))</span>
    <span class="p">[</span><span class="n">call_torch_export_export</span><span class="p">]</span> <span class="n">dynamic_shapes</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">input_ids</span><span class="p">:{</span><span class="mi">0</span><span class="p">:</span><span class="n">Dim</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span><span class="mi">1</span><span class="p">:</span><span class="n">DYN</span><span class="p">(</span><span class="n">seq_length</span><span class="p">)},</span><span class="n">attention_mask</span><span class="p">:{</span><span class="mi">0</span><span class="p">:</span><span class="n">Dim</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span><span class="mi">1</span><span class="p">:</span><span class="n">DYN</span><span class="p">(</span><span class="n">cache</span><span class="o">+</span><span class="n">seq</span><span class="p">)},</span><span class="n">position_ids</span><span class="p">:{</span><span class="mi">0</span><span class="p">:</span><span class="n">Dim</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span><span class="mi">1</span><span class="p">:</span><span class="n">DYN</span><span class="p">(</span><span class="n">cache</span><span class="o">+</span><span class="n">seq</span><span class="p">)},</span><span class="n">past_key_values</span><span class="p">:</span><span class="c1">#2[#1[{0:Dim(batch),2:DYN(cache_length)}],#1[{0:Dim(batch),2:DYN(cache_length)}]])</span>
    <span class="p">[</span><span class="n">call_torch_export_export</span><span class="p">]</span> <span class="n">dynamic_shapes_export_export</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">input_ids</span><span class="p">:{</span><span class="mi">0</span><span class="p">:</span><span class="n">Dim</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span><span class="mi">1</span><span class="p">:</span><span class="n">DYNAMIC</span><span class="p">},</span><span class="n">attention_mask</span><span class="p">:{</span><span class="mi">0</span><span class="p">:</span><span class="n">Dim</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span><span class="mi">1</span><span class="p">:</span><span class="n">DYNAMIC</span><span class="p">},</span><span class="n">position_ids</span><span class="p">:{</span><span class="mi">0</span><span class="p">:</span><span class="n">Dim</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span><span class="mi">1</span><span class="p">:</span><span class="n">DYNAMIC</span><span class="p">},</span><span class="n">past_key_values</span><span class="p">:</span><span class="c1">#2[#1[{0:Dim(batch),2:DYNAMIC}],#1[{0:Dim(batch),2:DYNAMIC}]])</span>
    <span class="p">[</span><span class="n">call_torch_export_export</span><span class="p">]</span> <span class="n">export</span><span class="o">...</span>
    <span class="p">[</span><span class="n">call_torch_export_export</span><span class="p">]</span> <span class="n">done</span> <span class="p">(</span><span class="n">export</span><span class="p">)</span> <span class="k">with</span> <span class="mi">140</span> <span class="n">nodes</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="n">run</span> <span class="n">exported</span> <span class="n">model</span><span class="o">...</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="n">patched</span> <span class="n">inputs</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">input_ids</span><span class="p">:</span><span class="n">T7s2x3</span><span class="p">,</span><span class="n">attention_mask</span><span class="p">:</span><span class="n">T7s2x33</span><span class="p">,</span><span class="n">position_ids</span><span class="p">:</span><span class="n">T7s2x3</span><span class="p">,</span><span class="n">past_key_values</span><span class="p">:</span><span class="n">DynamicCache</span><span class="p">(</span><span class="n">key_cache</span><span class="o">=</span><span class="c1">#1[T1s2x1x30x96], value_cache=#1[T1s2x1x30x96]))</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="n">done</span> <span class="p">(</span><span class="n">exported</span> <span class="n">run</span><span class="p">)</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="n">exported</span> <span class="n">discrepancies</span><span class="o">=</span><span class="nb">abs</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">rel</span><span class="o">=</span><span class="mi">0</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="o">--</span> <span class="n">dumps</span> <span class="n">exported</span> <span class="n">program</span> <span class="ow">in</span> <span class="s1">&#39;dump_models/arnir0_Tiny-LLM-export-nostrict&#39;</span><span class="o">...</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="n">done</span> <span class="p">(</span><span class="n">dump</span> <span class="n">ep</span><span class="p">)</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="n">dumps</span> <span class="n">statistics</span> <span class="ow">in</span> <span class="s1">&#39;dump_models/arnir0_Tiny-LLM-export-nostrict&#39;</span><span class="o">...</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="n">done</span> <span class="p">(</span><span class="n">dump</span><span class="p">)</span>
    <span class="p">[</span><span class="n">validate_model</span><span class="p">]</span> <span class="o">--</span> <span class="n">done</span> <span class="p">(</span><span class="n">final</span><span class="p">)</span>
    
    <span class="o">--</span> <span class="n">summary</span> <span class="o">--</span>
    <span class="p">:</span><span class="n">disc_exported_abs</span><span class="p">,</span><span class="mi">0</span><span class="p">;</span>
    <span class="p">:</span><span class="n">disc_exported_dnan</span><span class="p">,</span><span class="mi">0</span><span class="p">;</span>
    <span class="p">:</span><span class="n">disc_exported_n</span><span class="p">,</span><span class="mf">204672.0</span><span class="p">;</span>
    <span class="p">:</span><span class="n">disc_exported_rel</span><span class="p">,</span><span class="mi">0</span><span class="p">;</span>
    <span class="p">:</span><span class="n">disc_exported_sum</span><span class="p">,</span><span class="mf">0.0</span><span class="p">;</span>
    <span class="p">:</span><span class="n">disc_patched_abs</span><span class="p">,</span><span class="mi">0</span><span class="p">;</span>
    <span class="p">:</span><span class="n">disc_patched_dnan</span><span class="p">,</span><span class="mi">0</span><span class="p">;</span>
    <span class="p">:</span><span class="n">disc_patched_n</span><span class="p">,</span><span class="mf">204672.0</span><span class="p">;</span>
    <span class="p">:</span><span class="n">disc_patched_rel</span><span class="p">,</span><span class="mi">0</span><span class="p">;</span>
    <span class="p">:</span><span class="n">disc_patched_sum</span><span class="p">,</span><span class="mf">0.0</span><span class="p">;</span>
    <span class="p">:</span><span class="n">dump_folder</span><span class="p">,</span><span class="n">dump_models</span><span class="o">/</span><span class="n">arnir0_Tiny</span><span class="o">-</span><span class="n">LLM</span><span class="o">-</span><span class="n">export</span><span class="o">-</span><span class="n">nostrict</span><span class="p">;</span>
    <span class="p">:</span><span class="n">dump_folder_name</span><span class="p">,</span><span class="n">arnir0_Tiny</span><span class="o">-</span><span class="n">LLM</span><span class="o">-</span><span class="n">export</span><span class="o">-</span><span class="n">nostrict</span><span class="p">;</span>
    <span class="p">:</span><span class="n">export_args</span><span class="p">,();</span>
    <span class="p">:</span><span class="n">export_dynamic_shapes</span><span class="p">,</span><span class="nb">dict</span><span class="p">(</span><span class="n">input_ids</span><span class="p">:{</span><span class="mi">0</span><span class="p">:</span><span class="n">Dim</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span><span class="mi">1</span><span class="p">:</span><span class="n">DYN</span><span class="p">(</span><span class="n">seq_length</span><span class="p">)},</span><span class="n">attention_mask</span><span class="p">:{</span><span class="mi">0</span><span class="p">:</span><span class="n">Dim</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span><span class="mi">1</span><span class="p">:</span><span class="n">DYN</span><span class="p">(</span><span class="n">cache</span><span class="o">+</span><span class="n">seq</span><span class="p">)},</span><span class="n">position_ids</span><span class="p">:{</span><span class="mi">0</span><span class="p">:</span><span class="n">Dim</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span><span class="mi">1</span><span class="p">:</span><span class="n">DYN</span><span class="p">(</span><span class="n">cache</span><span class="o">+</span><span class="n">seq</span><span class="p">)},</span><span class="n">past_key_values</span><span class="p">:</span><span class="c1">#2[#1[{0:Dim(batch),2:DYN(cache_length)}],#1[{0:Dim(batch),2:DYN(cache_length)}]]);</span>
    <span class="p">:</span><span class="n">export_dynamic_shapes_export_export</span><span class="p">,</span><span class="nb">dict</span><span class="p">(</span><span class="n">input_ids</span><span class="p">:{</span><span class="mi">0</span><span class="p">:</span><span class="n">Dim</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span><span class="mi">1</span><span class="p">:</span><span class="n">DYNAMIC</span><span class="p">},</span><span class="n">attention_mask</span><span class="p">:{</span><span class="mi">0</span><span class="p">:</span><span class="n">Dim</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span><span class="mi">1</span><span class="p">:</span><span class="n">DYNAMIC</span><span class="p">},</span><span class="n">position_ids</span><span class="p">:{</span><span class="mi">0</span><span class="p">:</span><span class="n">Dim</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span><span class="mi">1</span><span class="p">:</span><span class="n">DYNAMIC</span><span class="p">},</span><span class="n">past_key_values</span><span class="p">:</span><span class="c1">#2[#1[{0:Dim(batch),2:DYNAMIC}],#1[{0:Dim(batch),2:DYNAMIC}]]);</span>
    <span class="p">:</span><span class="n">export_exporter</span><span class="p">,</span><span class="n">export</span><span class="o">-</span><span class="n">nostrict</span><span class="p">;</span>
    <span class="p">:</span><span class="n">export_graph_nodes</span><span class="p">,</span><span class="mi">140</span><span class="p">;</span>
    <span class="p">:</span><span class="n">export_kwargs</span><span class="p">,</span><span class="nb">dict</span><span class="p">(</span><span class="n">input_ids</span><span class="p">:</span><span class="n">T7s2x3</span><span class="p">,</span><span class="n">attention_mask</span><span class="p">:</span><span class="n">T7s2x33</span><span class="p">,</span><span class="n">position_ids</span><span class="p">:</span><span class="n">T7s2x3</span><span class="p">,</span><span class="n">past_key_values</span><span class="p">:</span><span class="n">DynamicCache</span><span class="p">(</span><span class="n">key_cache</span><span class="o">=</span><span class="c1">#1[T1s2x1x30x96], value_cache=#1[T1s2x1x30x96]));</span>
    <span class="p">:</span><span class="n">export_optimization</span><span class="p">,;</span>
    <span class="p">:</span><span class="n">export_strict</span><span class="p">,</span><span class="kc">False</span><span class="p">;</span>
    <span class="p">:</span><span class="n">model_class</span><span class="p">,</span><span class="n">LlamaForCausalLM</span><span class="p">;</span>
    <span class="p">:</span><span class="n">model_config</span><span class="p">,{</span><span class="s1">&#39;vocab_size&#39;</span><span class="p">:</span><span class="mi">32000</span><span class="p">,</span><span class="s1">&#39;max_position_embeddings&#39;</span><span class="p">:</span><span class="mi">1024</span><span class="p">,</span><span class="s1">&#39;hidden_size&#39;</span><span class="p">:</span><span class="mi">192</span><span class="p">,</span><span class="s1">&#39;intermediate_size&#39;</span><span class="p">:</span><span class="mi">1024</span><span class="p">,</span><span class="s1">&#39;num_hidden_layers&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;num_attention_heads&#39;</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span><span class="s1">&#39;num_key_value_heads&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;hidden_act&#39;</span><span class="p">:</span><span class="s1">&#39;silu&#39;</span><span class="p">,</span><span class="s1">&#39;initializer_range&#39;</span><span class="p">:</span><span class="mf">0.02</span><span class="p">,</span><span class="s1">&#39;rms_norm_eps&#39;</span><span class="p">:</span><span class="mf">1e-05</span><span class="p">,</span><span class="s1">&#39;pretraining_tp&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;use_cache&#39;</span><span class="p">:</span><span class="kc">True</span><span class="p">,</span><span class="s1">&#39;rope_theta&#39;</span><span class="p">:</span><span class="mf">10000.0</span><span class="p">,</span><span class="s1">&#39;rope_scaling&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;attention_bias&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span><span class="s1">&#39;attention_dropout&#39;</span><span class="p">:</span><span class="mf">0.0</span><span class="p">,</span><span class="s1">&#39;mlp_bias&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span><span class="s1">&#39;head_dim&#39;</span><span class="p">:</span><span class="mi">96</span><span class="p">,</span><span class="s1">&#39;return_dict&#39;</span><span class="p">:</span><span class="kc">True</span><span class="p">,</span><span class="s1">&#39;output_hidden_states&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span><span class="s1">&#39;torchscript&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span><span class="s1">&#39;dtype&#39;</span><span class="p">:</span><span class="s1">&#39;float32&#39;</span><span class="p">,</span><span class="s1">&#39;pruned_heads&#39;</span><span class="p">:{},</span><span class="s1">&#39;tie_word_embeddings&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span><span class="s1">&#39;chunk_size_feed_forward&#39;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="s1">&#39;is_encoder_decoder&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span><span class="s1">&#39;is_decoder&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span><span class="s1">&#39;cross_attention_hidden_size&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;add_cross_attention&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span><span class="s1">&#39;tie_encoder_decoder&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span><span class="s1">&#39;architectures&#39;</span><span class="p">:[</span><span class="s1">&#39;LlamaForCausalLM&#39;</span><span class="p">],</span><span class="s1">&#39;finetuning_task&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;id2label&#39;</span><span class="p">:{</span><span class="mi">0</span><span class="p">:</span><span class="s1">&#39;LABEL_0&#39;</span><span class="p">,</span><span class="mi">1</span><span class="p">:</span><span class="s1">&#39;LABEL_1&#39;</span><span class="p">},</span><span class="s1">&#39;label2id&#39;</span><span class="p">:{</span><span class="s1">&#39;LABEL_0&#39;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="s1">&#39;LABEL_1&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">},</span><span class="s1">&#39;task_specific_params&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;problem_type&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;tokenizer_class&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;prefix&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;bos_token_id&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;pad_token_id&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;eos_token_id&#39;</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span><span class="s1">&#39;sep_token_id&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;decoder_start_token_id&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;max_length&#39;</span><span class="p">:</span><span class="mi">20</span><span class="p">,</span><span class="s1">&#39;min_length&#39;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="s1">&#39;do_sample&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span><span class="s1">&#39;early_stopping&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span><span class="s1">&#39;num_beams&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;num_beam_groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;diversity_penalty&#39;</span><span class="p">:</span><span class="mf">0.0</span><span class="p">,</span><span class="s1">&#39;temperature&#39;</span><span class="p">:</span><span class="mf">1.0</span><span class="p">,</span><span class="s1">&#39;top_k&#39;</span><span class="p">:</span><span class="mi">50</span><span class="p">,</span><span class="s1">&#39;top_p&#39;</span><span class="p">:</span><span class="mf">1.0</span><span class="p">,</span><span class="s1">&#39;typical_p&#39;</span><span class="p">:</span><span class="mf">1.0</span><span class="p">,</span><span class="s1">&#39;repetition_penalty&#39;</span><span class="p">:</span><span class="mf">1.0</span><span class="p">,</span><span class="s1">&#39;length_penalty&#39;</span><span class="p">:</span><span class="mf">1.0</span><span class="p">,</span><span class="s1">&#39;no_repeat_ngram_size&#39;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="s1">&#39;encoder_no_repeat_ngram_size&#39;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="s1">&#39;bad_words_ids&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;num_return_sequences&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;output_scores&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span><span class="s1">&#39;return_dict_in_generate&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span><span class="s1">&#39;forced_bos_token_id&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;forced_eos_token_id&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;remove_invalid_values&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span><span class="s1">&#39;exponential_decay_length_penalty&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;suppress_tokens&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;begin_suppress_tokens&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;_name_or_path&#39;</span><span class="p">:</span><span class="s1">&#39;&#39;</span><span class="p">,</span><span class="s1">&#39;transformers_version&#39;</span><span class="p">:</span><span class="s1">&#39;4.56.0.dev0&#39;</span><span class="p">,</span><span class="s1">&#39;model_type&#39;</span><span class="p">:</span><span class="s1">&#39;llama&#39;</span><span class="p">,</span><span class="s1">&#39;tf_legacy_loss&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span><span class="s1">&#39;use_bfloat16&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span><span class="s1">&#39;subfolder&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;output_attentions&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">};</span>
    <span class="p">:</span><span class="n">model_config_class</span><span class="p">,</span><span class="n">LlamaConfig</span><span class="p">;</span>
    <span class="p">:</span><span class="n">model_file</span><span class="p">,</span><span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">xadupre</span><span class="o">/</span><span class="n">github</span><span class="o">/</span><span class="n">transformers</span><span class="o">/</span><span class="n">src</span><span class="o">/</span><span class="n">transformers</span><span class="o">/</span><span class="n">models</span><span class="o">/</span><span class="n">llama</span><span class="o">/</span><span class="n">modeling_llama</span><span class="o">.</span><span class="n">py</span><span class="p">;</span>
    <span class="p">:</span><span class="n">model_id</span><span class="p">,</span><span class="n">arnir0</span><span class="o">/</span><span class="n">Tiny</span><span class="o">-</span><span class="n">LLM</span><span class="p">;</span>
    <span class="p">:</span><span class="n">model_inputs</span><span class="p">,</span><span class="nb">dict</span><span class="p">(</span><span class="n">input_ids</span><span class="p">:</span><span class="n">T7s2x3</span><span class="p">,</span><span class="n">attention_mask</span><span class="p">:</span><span class="n">T7s2x33</span><span class="p">,</span><span class="n">position_ids</span><span class="p">:</span><span class="n">T7s2x3</span><span class="p">,</span><span class="n">past_key_values</span><span class="p">:</span><span class="n">DynamicCache</span><span class="p">(</span><span class="n">key_cache</span><span class="o">=</span><span class="c1">#1[T1s2x1x30x96], value_cache=#1[T1s2x1x30x96]));</span>
    <span class="p">:</span><span class="n">model_inputs_options</span><span class="p">,;</span>
    <span class="p">:</span><span class="n">model_module</span><span class="p">,</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">llama</span><span class="o">.</span><span class="n">modeling_llama</span><span class="p">;</span>
    <span class="p">:</span><span class="n">model_nweights</span><span class="p">,</span><span class="mi">12988992</span><span class="p">;</span>
    <span class="p">:</span><span class="n">model_shapes</span><span class="p">,</span><span class="nb">dict</span><span class="p">(</span><span class="n">input_ids</span><span class="p">:{</span><span class="mi">0</span><span class="p">:</span><span class="n">Dim</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span><span class="mi">1</span><span class="p">:</span><span class="n">DYN</span><span class="p">(</span><span class="n">seq_length</span><span class="p">)},</span><span class="n">attention_mask</span><span class="p">:{</span><span class="mi">0</span><span class="p">:</span><span class="n">Dim</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span><span class="mi">1</span><span class="p">:</span><span class="n">DYN</span><span class="p">(</span><span class="n">cache</span><span class="o">+</span><span class="n">seq</span><span class="p">)},</span><span class="n">position_ids</span><span class="p">:{</span><span class="mi">0</span><span class="p">:</span><span class="n">Dim</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span><span class="mi">1</span><span class="p">:</span><span class="n">DYN</span><span class="p">(</span><span class="n">cache</span><span class="o">+</span><span class="n">seq</span><span class="p">)},</span><span class="n">past_key_values</span><span class="p">:</span><span class="c1">#2[#1[{0:Dim(batch),2:DYN(cache_length)}],#1[{0:Dim(batch),2:DYN(cache_length)}]]);</span>
    <span class="p">:</span><span class="n">model_size</span><span class="p">,</span><span class="mi">51955968</span><span class="p">;</span>
    <span class="p">:</span><span class="n">model_subfolder</span><span class="p">,;</span>
    <span class="p">:</span><span class="n">model_task</span><span class="p">,</span><span class="n">text</span><span class="o">-</span><span class="n">generation</span><span class="p">;</span>
    <span class="p">:</span><span class="n">run_expected</span><span class="p">,</span><span class="n">CausalLMOutputWithPast</span><span class="p">(</span><span class="n">logits</span><span class="p">:</span><span class="n">T1s2x3x32000</span><span class="p">,</span><span class="n">past_key_values</span><span class="p">:</span><span class="n">DynamicCache</span><span class="p">(</span><span class="n">key_cache</span><span class="o">=</span><span class="c1">#1[T1s2x1x33x96], value_cache=#1[T1s2x1x33x96]));</span>
    <span class="p">:</span><span class="n">run_expected2</span><span class="p">,</span><span class="n">CausalLMOutputWithPast</span><span class="p">(</span><span class="n">logits</span><span class="p">:</span><span class="n">T1s3x4x32000</span><span class="p">,</span><span class="n">past_key_values</span><span class="p">:</span><span class="n">DynamicCache</span><span class="p">(</span><span class="n">key_cache</span><span class="o">=</span><span class="c1">#1[T1s3x1x35x96], value_cache=#1[T1s3x1x35x96]));</span>
    <span class="p">:</span><span class="n">time_create</span><span class="p">,</span><span class="mf">0.20015871599935053</span><span class="p">;</span>
    <span class="p">:</span><span class="n">time_export_export</span><span class="p">,</span><span class="mf">1.790458003999447</span><span class="p">;</span>
    <span class="p">:</span><span class="n">time_run</span><span class="p">,</span><span class="mf">0.009992467999836663</span><span class="p">;</span>
    <span class="p">:</span><span class="n">time_run2</span><span class="p">,</span><span class="mf">0.009186837000015657</span><span class="p">;</span>
    <span class="p">:</span><span class="n">time_run_exported</span><span class="p">,</span><span class="mf">0.014633524000601028</span><span class="p">;</span>
    <span class="p">:</span><span class="n">time_run_patched</span><span class="p">,</span><span class="mf">0.003768320000745007</span><span class="p">;</span>
    <span class="p">:</span><span class="n">version_date</span><span class="p">,</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">27</span><span class="n">T17</span><span class="p">:</span><span class="mi">08</span><span class="p">:</span><span class="mi">23</span><span class="p">;</span>
    <span class="p">:</span><span class="n">version_device</span><span class="p">,;</span>
    <span class="p">:</span><span class="n">version_do_run</span><span class="p">,</span><span class="kc">True</span><span class="p">;</span>
    <span class="p">:</span><span class="n">version_drop_inputs</span><span class="p">,[];</span>
    <span class="p">:</span><span class="n">version_dtype</span><span class="p">,;</span>
    <span class="p">:</span><span class="n">version_dump_folder</span><span class="p">,</span><span class="n">dump_models</span><span class="p">;</span>
    <span class="p">:</span><span class="n">version_exporter</span><span class="p">,</span><span class="n">export</span><span class="o">-</span><span class="n">nostrict</span><span class="p">;</span>
    <span class="p">:</span><span class="n">version_inputs2</span><span class="p">,</span><span class="mi">1</span><span class="p">;</span>
    <span class="p">:</span><span class="n">version_model_id</span><span class="p">,</span><span class="n">arnir0</span><span class="o">/</span><span class="n">Tiny</span><span class="o">-</span><span class="n">LLM</span><span class="p">;</span>
    <span class="p">:</span><span class="n">version_numpy</span><span class="p">,</span><span class="mf">2.3.2</span><span class="p">;</span>
    <span class="p">:</span><span class="n">version_onnx</span><span class="p">,</span><span class="mf">1.20.0</span><span class="p">;</span>
    <span class="p">:</span><span class="n">version_onnx_diagnostic</span><span class="p">,</span><span class="mf">0.7.7</span><span class="p">;</span>
    <span class="p">:</span><span class="n">version_onnx_ir</span><span class="p">,</span><span class="mf">0.1.8</span><span class="p">;</span>
    <span class="p">:</span><span class="n">version_onnxruntime</span><span class="p">,</span><span class="mf">1.23.0</span><span class="p">;</span>
    <span class="p">:</span><span class="n">version_onnxscript</span><span class="p">,</span><span class="mf">0.3.0</span><span class="o">.</span><span class="n">dev20250301</span><span class="p">;</span>
    <span class="p">:</span><span class="n">version_opset</span><span class="p">,</span><span class="mi">18</span><span class="p">;</span>
    <span class="p">:</span><span class="n">version_optimization</span><span class="p">,;</span>
    <span class="p">:</span><span class="n">version_ortfusiontype</span><span class="p">,;</span>
    <span class="p">:</span><span class="n">version_patch</span><span class="p">,</span><span class="kc">True</span><span class="p">;</span>
    <span class="p">:</span><span class="n">version_patch_kwargs</span><span class="p">,{</span><span class="s1">&#39;patch_transformers&#39;</span><span class="p">:</span><span class="kc">True</span><span class="p">,</span><span class="s1">&#39;patch_diffusers&#39;</span><span class="p">:</span><span class="kc">True</span><span class="p">,</span><span class="s1">&#39;patch&#39;</span><span class="p">:</span><span class="kc">True</span><span class="p">};</span>
    <span class="p">:</span><span class="n">version_quiet</span><span class="p">,</span><span class="kc">False</span><span class="p">;</span>
    <span class="p">:</span><span class="n">version_rewrite</span><span class="p">,</span><span class="kc">True</span><span class="p">;</span>
    <span class="p">:</span><span class="n">version_runtime</span><span class="p">,</span><span class="n">onnxruntime</span><span class="p">;</span>
    <span class="p">:</span><span class="n">version_same_as_pretrained</span><span class="p">,</span><span class="kc">False</span><span class="p">;</span>
    <span class="p">:</span><span class="n">version_scipy</span><span class="p">,</span><span class="mf">1.16.1</span><span class="p">;</span>
    <span class="p">:</span><span class="n">version_stop_if_static</span><span class="p">,</span><span class="mi">0</span><span class="p">;</span>
    <span class="p">:</span><span class="n">version_torch</span><span class="p">,</span><span class="mf">2.9.0</span><span class="o">.</span><span class="n">dev20250820</span><span class="o">+</span><span class="n">cu126</span><span class="p">;</span>
    <span class="p">:</span><span class="n">version_transformers</span><span class="p">,</span><span class="mf">4.56.0</span><span class="o">.</span><span class="n">dev0</span><span class="p">;</span>
    <span class="p">:</span><span class="n">version_use_pretrained</span><span class="p">,</span><span class="kc">False</span><span class="p">;</span>
</pre></div>
</div>
</section>
<section id="validate-onnx-discrepancies">
<h2>Validate ONNX discrepancies<a class="headerlink" href="#validate-onnx-discrepancies" title="Link to this heading">¶</a></h2>
<p>Let’s export with ONNX this time and checks for discrepancies.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">onnx_diagnostic</span> <span class="n">validate</span> <span class="o">-</span><span class="n">m</span> <span class="n">arnir0</span><span class="o">/</span><span class="n">Tiny</span><span class="o">-</span><span class="n">LLM</span> <span class="o">--</span><span class="n">run</span> <span class="o">-</span><span class="n">v</span> <span class="mi">1</span> <span class="o">--</span><span class="n">export</span> <span class="n">onnx</span><span class="o">-</span><span class="n">dynamo</span> <span class="o">-</span><span class="n">o</span> <span class="n">dump_models</span> <span class="o">--</span><span class="n">patch</span> <span class="o">--</span><span class="n">opt</span> <span class="n">ir</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    [validate_model] dump into &#39;arnir0_Tiny-LLM-onnx-dynamo-ir&#39;
    [validate_model] validate model id &#39;arnir0/Tiny-LLM&#39;
    [validate_model] patch=True
    [validate_model] get dummy inputs with input_options=None...
    [validate_model] rewrite=True, patch_kwargs={&#39;patch_transformers&#39;: True, &#39;patch_diffusers&#39;: True, &#39;patch&#39;: True}, stop_if_static=0
    [validate_model] exporter=&#39;onnx-dynamo&#39;, optimization=&#39;ir&#39;
    [validate_model] dump_folder=&#39;dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir&#39;
    [validate_model] output_names=None
    [get_untrained_model_with_inputs] model_id=&#39;arnir0/Tiny-LLM&#39;
    [get_untrained_model_with_inputs] use preinstalled &#39;arnir0/Tiny-LLM&#39;
    [get_untrained_model_with_inputs] architectures=[&#39;LlamaForCausalLM&#39;]
    [get_untrained_model_with_inputs] cls=&#39;LlamaConfig&#39;
    [get_untrained_model_with_inputs] task=&#39;text-generation&#39;
    [get_untrained_model_with_inputs] default config._attn_implementation=None
    [get_untrained_model_with_inputs] use fct=&lt;function get_inputs at 0x726e5d185b20&gt;
    [validate_model] --
    [validate_model] task=text-generation
    [validate_model] size=49.549072265625 Mb
    [validate_model] n_weights=12.988992 millions parameters
    [validate_model] +INPUT input_ids=T7s2x3
    [validate_model] +INPUT attention_mask=T7s2x33
    [validate_model] +INPUT position_ids=T7s2x3
    [validate_model] +INPUT past_key_values=DynamicCache(key_cache=#1[T1s2x1x30x96], value_cache=#1[T1s2x1x30x96])
    [validate_model] +SHAPE input_ids={0:Dim(batch),1:DYN(seq_length)}
    [validate_model] +SHAPE attention_mask={0:Dim(batch),1:DYN(cache+seq)}
    [validate_model] +SHAPE position_ids={0:Dim(batch),1:DYN(cache+seq)}
    [validate_model] +SHAPE past_key_values=#2[#1[{0:Dim(batch),2:DYN(cache_length)}],#1[{0:Dim(batch),2:DYN(cache_length)}]]
    [validate_model] --
    [validate_model] -- run the model inputs=&#39;inputs&#39;...
    [validate_model] inputs=dict(input_ids:T7s2x3,attention_mask:T7s2x33,position_ids:T7s2x3,past_key_values:DynamicCache(key_cache=#1[T1s2x1x30x96], value_cache=#1[T1s2x1x30x96]))
    [validate_model] done ([run])
    [validate_model] -- run the model inputs=&#39;inputs2&#39;...
    [validate_model] inputs2=dict(input_ids:T7s3x4,attention_mask:T7s3x35,position_ids:T7s3x4,past_key_values:DynamicCache(key_cache=#1[T1s3x1x31x96], value_cache=#1[T1s3x1x31x96]))
    [validate_model] done ([run2])
    [validate_model] -- export the model with &#39;onnx-dynamo&#39;, optimization=&#39;ir&#39;
    [validate_model] applies patches before exporting stop_if_static=0
    [validate_model] run patched model...
    [validate_model] patched inputs=dict(input_ids:T7s2x3,attention_mask:T7s2x33,position_ids:T7s2x3,past_key_values:DynamicCache(key_cache=#1[T1s2x1x30x96], value_cache=#1[T1s2x1x30x96]))
    [validate_model] done (patched run)
    [validate_model] patched discrepancies=abs=0, rel=0
    [call_torch_export_onnx] exporter=&#39;onnx-dynamo&#39;, optimization=&#39;ir&#39;
    [call_torch_export_onnx] args=()
    [call_torch_export_onnx] kwargs=dict(input_ids:T7s2x3,attention_mask:T7s2x33,position_ids:T7s2x3,past_key_values:DynamicCache(key_cache=#1[T1s2x1x30x96], value_cache=#1[T1s2x1x30x96]))
    [call_torch_export_onnx] dynamic_shapes=dict(input_ids:{0:Dim(batch),1:DYN(seq_length)},attention_mask:{0:Dim(batch),1:DYN(cache+seq)},position_ids:{0:Dim(batch),1:DYN(cache+seq)},past_key_values:#2[#1[{0:Dim(batch),2:DYN(cache_length)}],#1[{0:Dim(batch),2:DYN(cache_length)}]])
    [call_torch_export_onnx] export...
    [call_torch_export_onnx] export_export_kwargs=dict(dynamo:bool,dynamic_shapes:dict(input_ids:{0:Dim(batch),1:DYN(seq_length)},attention_mask:{0:Dim(batch),1:DYN(cache+seq)},position_ids:{0:Dim(batch),1:DYN(cache+seq)},past_key_values:#2[#1[{0:Dim(batch),2:DYN(cache_length)}],#1[{0:Dim(batch),2:DYN(cache_length)}]]),opset_version:int)
    [torch.onnx] Obtain model graph for `LlamaForCausalLM([...]` with `torch.export.export(..., strict=False)`...
    [_catch_produce_guards_and_solve_constraints] ERROR: produce_guards_and_solve_constraints failed, use SKIP_SOLVE_CONSTRAINTS=0 to avoid skipping
    fake_mode=&lt;torch._subclasses.fake_tensor.FakeTensorMode object at 0x726e2f288dd0&gt;
    dynamic_shapes={&#39;input_ids&#39;: {0: Dim(&#39;batch&#39;, min=1, max=1024), 1: _DimHint(type=&lt;_DimHintType.DYNAMIC: 3&gt;, min=None, max=None, _factory=True)}, &#39;attention_mask&#39;: {0: Dim(&#39;batch&#39;, min=1, max=1024), 1: _DimHint(type=&lt;_DimHintType.DYNAMIC: 3&gt;, min=None, max=None, _factory=True)}, &#39;position_ids&#39;: {0: Dim(&#39;batch&#39;, min=1, max=1024), 1: _DimHint(type=&lt;_DimHintType.DYNAMIC: 3&gt;, min=None, max=None, _factory=True)}, &#39;past_key_values&#39;: [[{0: Dim(&#39;batch&#39;, min=1, max=1024), 2: _DimHint(type=&lt;_DimHintType.DYNAMIC: 3&gt;, min=None, max=None, _factory=True)}], [{0: Dim(&#39;batch&#39;, min=1, max=1024), 2: _DimHint(type=&lt;_DimHintType.DYNAMIC: 3&gt;, min=None, max=None, _factory=True)}]]}
    equalities_inputs=EqualityConstraint(warn_only=False, source_pairs=[(TensorPropertySource(base=LocalSource(local_name=&#39;attention_mask&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0), TensorPropertySource(base=LocalSource(local_name=&#39;input_ids&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0)), (TensorPropertySource(base=LocalSource(local_name=&#39;position_ids&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0), TensorPropertySource(base=LocalSource(local_name=&#39;input_ids&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0)), (TensorPropertySource(base=GetItemSource(base=GetItemSource(base=LocalSource(local_name=&#39;past_key_values&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), index=&#39;key_cache&#39;, index_is_slice=False), index=0, index_is_slice=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0), TensorPropertySource(base=LocalSource(local_name=&#39;input_ids&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0)), (TensorPropertySource(base=GetItemSource(base=GetItemSource(base=LocalSource(local_name=&#39;past_key_values&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), index=&#39;value_cache&#39;, index_is_slice=False), index=0, index_is_slice=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0), TensorPropertySource(base=LocalSource(local_name=&#39;input_ids&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0))], derived_equalities=[], phantom_symbols=[], relaxed_sources={TensorPropertySource(base=LocalSource(local_name=&#39;attention_mask&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=1), TensorPropertySource(base=LocalSource(local_name=&#39;input_ids&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=1), TensorPropertySource(base=GetItemSource(base=GetItemSource(base=LocalSource(local_name=&#39;past_key_values&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), index=&#39;value_cache&#39;, index_is_slice=False), index=0, index_is_slice=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=2), TensorPropertySource(base=LocalSource(local_name=&#39;position_ids&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=1), TensorPropertySource(base=GetItemSource(base=GetItemSource(base=LocalSource(local_name=&#39;past_key_values&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), index=&#39;key_cache&#39;, index_is_slice=False), index=0, index_is_slice=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=2)}, _parents={TensorPropertySource(base=LocalSource(local_name=&#39;attention_mask&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0): TensorPropertySource(base=LocalSource(local_name=&#39;input_ids&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0), TensorPropertySource(base=LocalSource(local_name=&#39;position_ids&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0): TensorPropertySource(base=LocalSource(local_name=&#39;input_ids&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0), TensorPropertySource(base=GetItemSource(base=GetItemSource(base=LocalSource(local_name=&#39;past_key_values&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), index=&#39;key_cache&#39;, index_is_slice=False), index=0, index_is_slice=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0): TensorPropertySource(base=LocalSource(local_name=&#39;input_ids&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0), TensorPropertySource(base=GetItemSource(base=GetItemSource(base=LocalSource(local_name=&#39;past_key_values&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), index=&#39;value_cache&#39;, index_is_slice=False), index=0, index_is_slice=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0): TensorPropertySource(base=LocalSource(local_name=&#39;input_ids&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0)}, _defs={})
    original_signature=(input_ids: Optional[torch.LongTensor] = None, attention_mask: Optional[torch.Tensor] = None, position_ids: Optional[torch.LongTensor] = None, past_key_values: Optional[transformers.cache_utils.Cache] = None, inputs_embeds: Optional[torch.FloatTensor] = None, labels: Optional[torch.LongTensor] = None, use_cache: Optional[bool] = None, cache_position: Optional[torch.LongTensor] = None, logits_to_keep: Union[int, torch.Tensor] = 0, **kwargs: Unpack[transformers.utils.generic.TransformersKwargs]) -&gt; transformers.modeling_outputs.CausalLMOutputWithPast
    kwargs={}
    exc=Constraints violated (batch)! For more information, run with TORCH_LOGS=&quot;+dynamic&quot;.
      - Not all values of batch = L[&#39;input_ids&#39;].size()[0] in the specified range batch &lt;= 1024 satisfy the generated guard L[&#39;input_ids&#39;].size()[0] != 1.
    gm=&lt;lambda&gt;()
    
    
    
    def forward(self, arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1, arg6_1, arg7_1, arg8_1, arg9_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1):
        sym_size_int = torch.ops.aten.sym_size.int(arg16_1, 0)
        empty = torch.ops.aten.empty.memory_format([sym_size_int, 1, 0, 96], dtype = torch.float32, device = device(type=&#39;cpu&#39;), pin_memory = False)
        empty_1 = torch.ops.aten.empty.memory_format([sym_size_int, 1, 0, 96], dtype = torch.float32, device = device(type=&#39;cpu&#39;), pin_memory = False)
        cat = torch.ops.aten.cat.default([empty, arg16_1], -2);  empty = arg16_1 = None
        cat_1 = torch.ops.aten.cat.default([empty_1, arg17_1], -2);  empty_1 = arg17_1 = None
        embedding = torch.ops.aten.embedding.default(arg0_1, arg13_1);  arg0_1 = None
        sym_size_int_1 = torch.ops.aten.sym_size.int(cat, 2)
        sym_size_int_2 = torch.ops.aten.sym_size.int(arg13_1, 1)
        add = sym_size_int_1 + sym_size_int_2
        arange = torch.ops.aten.arange.start(sym_size_int_1, add, device = device(type=&#39;cpu&#39;), pin_memory = False);  add = None
        to = torch.ops.aten.to.device(arg14_1, device(type=&#39;cpu&#39;), torch.bool);  arg14_1 = None
        sym_size_int_3 = torch.ops.aten.sym_size.int(arange, 0)
        add_1 = sym_size_int_3 + sym_size_int_1;  sym_size_int_1 = None
        arange_1 = torch.ops.aten.arange.default(add_1, device = device(type=&#39;cpu&#39;), pin_memory = False);  add_1 = None
        add_ = torch.ops.aten.add_.Tensor(arange_1, 0)
        sym_size_int_5 = torch.ops.aten.sym_size.int(arg13_1, 0);  arg13_1 = None
        arange_2 = torch.ops.aten.arange.default(sym_size_int_5, device = device(type=&#39;cpu&#39;), pin_memory = False)
        arange_3 = torch.ops.aten.arange.default(1, device = device(type=&#39;cpu&#39;), pin_memory = False)
        sym_size_int_6 = torch.ops.aten.sym_size.int(arange_2, 0)
        sym_size_int_7 = torch.ops.aten.sym_size.int(arange_1, 0);  arange_1 = None
        reshape = torch.ops.aten.reshape.default(arange_2, [-1, 1, 1, 1]);  arange_2 = None
        reshape_1 = torch.ops.aten.reshape.default(arange_3, [1, -1, 1, 1]);  arange_3 = None
        reshape_2 = torch.ops.aten.reshape.default(arange, [1, 1, -1, 1]);  arange = None
        reshape_3 = torch.ops.aten.reshape.default(add_, [1, 1, 1, -1]);  add_ = None
        expand = torch.ops.aten.expand.default(reshape, [sym_size_int_6, 1, sym_size_int_3, sym_size_int_7]);  reshape = None
        expand_1 = torch.ops.aten.expand.default(reshape_1, [sym_size_int_6, 1, sym_size_int_3, sym_size_int_7]);  reshape_1 = expand_1 = None
        expand_2 = torch.ops.aten.expand.default(reshape_2, [sym_size_int_6, 1, sym_size_int_3, sym_size_int_7]);  reshape_2 = None
        expand_3 = torch.ops.aten.expand.default(reshape_3, [sym_size_int_6, 1, sym_size_int_3, sym_size_int_7]);  reshape_3 = sym_size_int_6 = sym_size_int_3 = sym_size_int_7 = None
        new_ones = torch.ops.aten.new_ones.default(expand_2, [], dtype = torch.bool, pin_memory = False)
        le = torch.ops.aten.le.Tensor(expand_3, expand_2);  expand_2 = None
        to_1 = torch.ops.aten.to.dtype_layout(le, dtype = torch.bool, layout = torch.strided, device = device(type=&#39;cpu&#39;));  le = None
        and_1 = torch.ops.aten.__and__.Tensor(new_ones, to_1);  new_ones = to_1 = None
        index = torch.ops.aten.index.Tensor(to, [expand, expand_3]);  to = expand = expand_3 = None
        to_2 = torch.ops.aten.to.dtype_layout(index, dtype = torch.bool, layout = torch.strided, device = device(type=&#39;cpu&#39;));  index = None
        and_2 = torch.ops.aten.__and__.Tensor(and_1, to_2);  and_1 = to_2 = None
        _set_grad_enabled = torch._C._set_grad_enabled(False);  _set_grad_enabled = None
        unsqueeze = torch.ops.aten.unsqueeze.default(arg12_1, 0);  arg12_1 = None
        unsqueeze_1 = torch.ops.aten.unsqueeze.default(unsqueeze, 2);  unsqueeze = None
        to_3 = torch.ops.aten.to.dtype(unsqueeze_1, torch.float32);  unsqueeze_1 = None
        sym_size_int_8 = torch.ops.aten.sym_size.int(arg15_1, 0)
        expand_4 = torch.ops.aten.expand.default(to_3, [sym_size_int_8, -1, 1]);  to_3 = sym_size_int_8 = None
        to_4 = torch.ops.aten.to.dtype_layout(expand_4, dtype = torch.float32, layout = torch.strided, device = device(type=&#39;cpu&#39;));  expand_4 = None
        unsqueeze_2 = torch.ops.aten.unsqueeze.default(arg15_1, 1);  arg15_1 = None
        slice_1 = torch.ops.aten.slice.Tensor(unsqueeze_2, 2, 0, 9223372036854775807);  unsqueeze_2 = None
        to_5 = torch.ops.aten.to.dtype(slice_1, torch.float32);  slice_1 = None
        _enter_autocast = torch.amp.autocast_mode._enter_autocast(&#39;cpu&#39;, torch.bfloat16, False, False)
        to_6 = torch.ops.aten.to.dtype(to_4, torch.float32);  to_4 = None
        to_7 = torch.ops.aten.to.dtype(to_5, torch.float32);  to_5 = None
        matmul = torch.ops.aten.matmul.default(to_6, to_7);  to_6 = to_7 = None
        transpose = torch.ops.aten.transpose.int(matmul, 1, 2);  matmul = None
        cat_2 = torch.ops.aten.cat.default([transpose, transpose], -1);  transpose = None
        cos = torch.ops.aten.cos.default(cat_2)
        mul = torch.ops.aten.mul.Tensor(cos, 1.0);  cos = None
        sin = torch.ops.aten.sin.default(cat_2);  cat_2 = None
        mul_1 = torch.ops.aten.mul.Tensor(sin, 1.0);  sin = None
        _exit_autocast = torch.amp.autocast_mode._exit_autocast(_enter_autocast);  _enter_autocast = _exit_autocast = None
        to_8 = torch.ops.aten.to.dtype(mul, torch.float32);  mul = None
        to_9 = torch.ops.aten.to.dtype(mul_1, torch.float32);  mul_1 = None
        _set_grad_enabled_1 = torch._C._set_grad_enabled(True);  _set_grad_enabled_1 = None
        to_10 = torch.ops.aten.to.dtype(embedding, torch.float32);  embedding = None
        pow_1 = torch.ops.aten.pow.Tensor_Scalar(to_10, 2)
        mean = torch.ops.aten.mean.dim(pow_1, [-1], True);  pow_1 = None
        add_3 = torch.ops.aten.add.Tensor(mean, 1e-05);  mean = None
        rsqrt = torch.ops.aten.rsqrt.default(add_3);  add_3 = None
        mul_2 = torch.ops.aten.mul.Tensor(to_10, rsqrt);  rsqrt = None
        to_11 = torch.ops.aten.to.dtype(mul_2, torch.float32);  mul_2 = None
        mul_3 = torch.ops.aten.mul.Tensor(arg8_1, to_11);  arg8_1 = to_11 = None
        linear = torch.ops.aten.linear.default(mul_3, arg1_1);  arg1_1 = None
        view = torch.ops.aten.view.default(linear, [sym_size_int_5, sym_size_int_2, -1, 96]);  linear = None
        transpose_1 = torch.ops.aten.transpose.int(view, 1, 2);  view = None
        linear_1 = torch.ops.aten.linear.default(mul_3, arg2_1);  arg2_1 = None
        view_1 = torch.ops.aten.view.default(linear_1, [sym_size_int_5, sym_size_int_2, -1, 96]);  linear_1 = None
        transpose_2 = torch.ops.aten.transpose.int(view_1, 1, 2);  view_1 = None
        linear_2 = torch.ops.aten.linear.default(mul_3, arg3_1);  mul_3 = arg3_1 = None
        view_2 = torch.ops.aten.view.default(linear_2, [sym_size_int_5, sym_size_int_2, -1, 96]);  linear_2 = None
        transpose_3 = torch.ops.aten.transpose.int(view_2, 1, 2);  view_2 = None
        unsqueeze_3 = torch.ops.aten.unsqueeze.default(to_8, 1);  to_8 = None
        unsqueeze_4 = torch.ops.aten.unsqueeze.default(to_9, 1);  to_9 = None
        mul_4 = torch.ops.aten.mul.Tensor(transpose_1, unsqueeze_3)
        slice_2 = torch.ops.aten.slice.Tensor(transpose_1, 3, 0, 48)
        slice_3 = torch.ops.aten.slice.Tensor(transpose_1, 3, 48, 9223372036854775807);  transpose_1 = None
        neg = torch.ops.aten.neg.default(slice_3);  slice_3 = None
        cat_3 = torch.ops.aten.cat.default([neg, slice_2], -1);  neg = slice_2 = None
        mul_5 = torch.ops.aten.mul.Tensor(cat_3, unsqueeze_4);  cat_3 = None
        add_4 = torch.ops.aten.add.Tensor(mul_4, mul_5);  mul_4 = mul_5 = None
        mul_6 = torch.ops.aten.mul.Tensor(transpose_2, unsqueeze_3);  unsqueeze_3 = None
        slice_4 = torch.ops.aten.slice.Tensor(transpose_2, 3, 0, 48)
        slice_5 = torch.ops.aten.slice.Tensor(transpose_2, 3, 48, 9223372036854775807);  transpose_2 = None
        neg_1 = torch.ops.aten.neg.default(slice_5);  slice_5 = None
        cat_4 = torch.ops.aten.cat.default([neg_1, slice_4], -1);  neg_1 = slice_4 = None
        mul_7 = torch.ops.aten.mul.Tensor(cat_4, unsqueeze_4);  cat_4 = unsqueeze_4 = None
        add_5 = torch.ops.aten.add.Tensor(mul_6, mul_7);  mul_6 = mul_7 = None
        cat_5 = torch.ops.aten.cat.default([cat, add_5], -2);  cat = add_5 = None
        cat_6 = torch.ops.aten.cat.default([cat_1, transpose_3], -2);  cat_1 = transpose_3 = None
        unsqueeze_5 = torch.ops.aten.unsqueeze.default(cat_5, 2)
        sym_size_int_10 = torch.ops.aten.sym_size.int(cat_5, 2)
        slice_6 = torch.ops.aten.slice.Tensor(unsqueeze_5, 3, 0, 9223372036854775807);  unsqueeze_5 = None
        expand_5 = torch.ops.aten.expand.default(slice_6, [sym_size_int, 1, 2, sym_size_int_10, 96]);  slice_6 = None
        reshape_4 = torch.ops.aten.reshape.default(expand_5, [sym_size_int, 2, sym_size_int_10, 96]);  expand_5 = None
        unsqueeze_6 = torch.ops.aten.unsqueeze.default(cat_6, 2)
        sym_size_int_11 = torch.ops.aten.sym_size.int(cat_6, 2)
        slice_7 = torch.ops.aten.slice.Tensor(unsqueeze_6, 3, 0, 9223372036854775807);  unsqueeze_6 = None
        expand_6 = torch.ops.aten.expand.default(slice_7, [sym_size_int, 1, 2, sym_size_int_11, 96]);  slice_7 = None
        reshape_5 = torch.ops.aten.reshape.default(expand_6, [sym_size_int, 2, sym_size_int_11, 96]);  expand_6 = sym_size_int = sym_size_int_11 = None
        slice_8 = torch.ops.aten.slice.Tensor(and_2, 3, None, sym_size_int_10);  and_2 = sym_size_int_10 = None
        scaled_dot_product_attention = torch.ops.aten.scaled_dot_product_attention.default(add_4, reshape_4, reshape_5, slice_8, scale = 0.10206207261596575);  add_4 = reshape_4 = reshape_5 = slice_8 = None
        transpose_4 = torch.ops.aten.transpose.int(scaled_dot_product_attention, 1, 2);  scaled_dot_product_attention = None
        reshape_6 = torch.ops.aten.reshape.default(transpose_4, [sym_size_int_5, sym_size_int_2, -1]);  transpose_4 = sym_size_int_5 = sym_size_int_2 = None
        linear_3 = torch.ops.aten.linear.default(reshape_6, arg4_1);  reshape_6 = arg4_1 = None
        add_6 = torch.ops.aten.add.Tensor(to_10, linear_3);  to_10 = linear_3 = None
        to_12 = torch.ops.aten.to.dtype(add_6, torch.float32);  add_6 = None
        pow_2 = torch.ops.aten.pow.Tensor_Scalar(to_12, 2)
        mean_1 = torch.ops.aten.mean.dim(pow_2, [-1], True);  pow_2 = None
        add_7 = torch.ops.aten.add.Tensor(mean_1, 1e-05);  mean_1 = None
        rsqrt_1 = torch.ops.aten.rsqrt.default(add_7);  add_7 = None
        mul_16 = torch.ops.aten.mul.Tensor(to_12, rsqrt_1);  rsqrt_1 = None
        to_13 = torch.ops.aten.to.dtype(mul_16, torch.float32);  mul_16 = None
        mul_17 = torch.ops.aten.mul.Tensor(arg9_1, to_13);  arg9_1 = to_13 = None
        linear_4 = torch.ops.aten.linear.default(mul_17, arg5_1);  arg5_1 = None
        silu = torch.ops.aten.silu.default(linear_4);  linear_4 = None
        linear_5 = torch.ops.aten.linear.default(mul_17, arg6_1);  mul_17 = arg6_1 = None
        mul_18 = torch.ops.aten.mul.Tensor(silu, linear_5);  silu = linear_5 = None
        linear_6 = torch.ops.aten.linear.default(mul_18, arg7_1);  mul_18 = arg7_1 = None
        add_8 = torch.ops.aten.add.Tensor(to_12, linear_6);  to_12 = linear_6 = None
        to_14 = torch.ops.aten.to.dtype(add_8, torch.float32);  add_8 = None
        pow_3 = torch.ops.aten.pow.Tensor_Scalar(to_14, 2)
        mean_2 = torch.ops.aten.mean.dim(pow_3, [-1], True);  pow_3 = None
        add_9 = torch.ops.aten.add.Tensor(mean_2, 1e-05);  mean_2 = None
        rsqrt_2 = torch.ops.aten.rsqrt.default(add_9);  add_9 = None
        mul_19 = torch.ops.aten.mul.Tensor(to_14, rsqrt_2);  to_14 = rsqrt_2 = None
        to_15 = torch.ops.aten.to.dtype(mul_19, torch.float32);  mul_19 = None
        mul_20 = torch.ops.aten.mul.Tensor(arg10_1, to_15);  arg10_1 = to_15 = None
        slice_9 = torch.ops.aten.slice.Tensor(mul_20, 1, 0, 9223372036854775807);  mul_20 = None
        linear_7 = torch.ops.aten.linear.default(slice_9, arg11_1);  slice_9 = arg11_1 = None
        return (linear_7, cat_5, cat_6)
        
    # To see more debug info, please use `graph_module.print_readable()`
    [torch.onnx] Obtain model graph for `LlamaForCausalLM([...]` with `torch.export.export(..., strict=False)`... ✅
    [torch.onnx] Run decomposition...
    [torch.onnx] Run decomposition... ✅
    [torch.onnx] Translate the graph into ONNX...
    [torch.onnx] Translate the graph into ONNX... ✅
    ~/vv/this312/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_dynamic_shapes.py:264: UserWarning: # The axis name: batch will not be used, since it shares the same shape constraints with another axis: batch.
      warnings.warn(
    ~/vv/this312/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_dynamic_shapes.py:264: UserWarning: # The axis name: batch will not be used, since it shares the same shape constraints with another axis: batch.
      warnings.warn(
    ~/vv/this312/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_dynamic_shapes.py:264: UserWarning: # The axis name: cache+seq will not be used, since it shares the same shape constraints with another axis: seq_length.
      warnings.warn(
    ~/vv/this312/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_dynamic_shapes.py:264: UserWarning: # The axis name: batch will not be used, since it shares the same shape constraints with another axis: batch.
      warnings.warn(
    ~/vv/this312/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_dynamic_shapes.py:264: UserWarning: # The axis name: batch will not be used, since it shares the same shape constraints with another axis: batch.
      warnings.warn(
    Applied 35 of general pattern rewrite rules.
    [call_torch_export_onnx] done (export)
    [call_torch_export_onnx] starts optimization=&#39;ir&#39;...
    [call_torch_export_onnx] done (optimization)
    [validate_model] dumps onnx program in &#39;dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir&#39;...
    [validate_model] done (dump onnx) in 0.15125025599991204
    [validate_model] dumps statistics in &#39;dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir&#39;...
    [validate_model] done (dump)
    [validate_onnx_model] verify onnx model with providers [&#39;CPUExecutionProvider&#39;]..., flavour=None
    [validate_onnx_model] done (ort_session) flavour=None
    [validate_onnx_model] -- make_feeds for &#39;inputs&#39;...
    [validate_onnx_model] inputs=dict(input_ids:T7s2x3,attention_mask:T7s2x33,position_ids:T7s2x3,past_key_values:DynamicCache(key_cache=#1[T1s2x1x30x96], value_cache=#1[T1s2x1x30x96]))
    [validate_onnx_model] ort inputs=dict(input_ids:A7s2x3,attention_mask:A7s2x33,position_ids:A7s2x3,past_key_values_key_cache_0:A1s2x1x30x96,past_key_values_value_cache_0:A1s2x1x30x96)
    [validate_onnx_model] done (make_feeds)
    [validate_onnx_model] run session...
    [validate_onnx_model] done (run)
    [validate_onnx_model] got=#3[A1s2x3x32000,A1s2x1x33x96,A1s2x1x33x96]
    [validate_onnx_model] discrepancies=abs=8.046627044677734e-07, rel=0.00029397114747102115, n=204672.0
    [validate_onnx_model] -- make_feeds for &#39;inputs2&#39;...
    [validate_onnx_model] inputs=dict(input_ids:T7s3x4,attention_mask:T7s3x35,position_ids:T7s3x4,past_key_values:DynamicCache(key_cache=#1[T1s3x1x31x96], value_cache=#1[T1s3x1x31x96]))
    [validate_onnx_model] ort inputs=dict(input_ids:A7s3x4,attention_mask:A7s3x35,position_ids:A7s3x4,past_key_values_key_cache_0:A1s3x1x31x96,past_key_values_value_cache_0:A1s3x1x31x96)
    [validate_onnx_model] done (make_feeds)
    [validate_onnx_model] run session...
    [validate_onnx_model] done (run)
    [validate_onnx_model] got=#3[A1s3x4x32000,A1s3x1x35x96,A1s3x1x35x96]
    [validate_onnx_model] discrepancies=abs=8.344650268554688e-07, rel=0.0003824267790890117, n=404160.0
    [validate_model] -- done (final)
    
    -- summary --
    :disc_onnx_ort_run2_abs,8.344650268554688e-07;
    :disc_onnx_ort_run2_dnan,0;
    :disc_onnx_ort_run2_n,404160.0;
    :disc_onnx_ort_run2_rel,0.0003824267790890117;
    :disc_onnx_ort_run2_sum,0.03882712602421634;
    :disc_onnx_ort_run_abs,8.046627044677734e-07;
    :disc_onnx_ort_run_dnan,0;
    :disc_onnx_ort_run_n,204672.0;
    :disc_onnx_ort_run_rel,0.00029397114747102115;
    :disc_onnx_ort_run_sum,0.019302217995800675;
    :disc_patched_abs,0;
    :disc_patched_dnan,0;
    :disc_patched_n,204672.0;
    :disc_patched_rel,0;
    :disc_patched_sum,0.0;
    :dump_folder,dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir;
    :dump_folder_name,arnir0_Tiny-LLM-onnx-dynamo-ir;
    :export_args,();
    :export_dynamo,True;
    :export_exporter,onnx-dynamo;
    :export_kwargs,dict(input_ids:T7s2x3,attention_mask:T7s2x33,position_ids:T7s2x3,past_key_values:DynamicCache(key_cache=#1[T1s2x1x30x96], value_cache=#1[T1s2x1x30x96]));
    :export_opset,18;
    :export_optimization,ir;
    :model_class,LlamaForCausalLM;
    :model_config,{&#39;vocab_size&#39;:32000,&#39;max_position_embeddings&#39;:1024,&#39;hidden_size&#39;:192,&#39;intermediate_size&#39;:1024,&#39;num_hidden_layers&#39;:1,&#39;num_attention_heads&#39;:2,&#39;num_key_value_heads&#39;:1,&#39;hidden_act&#39;:&#39;silu&#39;,&#39;initializer_range&#39;:0.02,&#39;rms_norm_eps&#39;:1e-05,&#39;pretraining_tp&#39;:1,&#39;use_cache&#39;:True,&#39;rope_theta&#39;:10000.0,&#39;rope_scaling&#39;:None,&#39;attention_bias&#39;:False,&#39;attention_dropout&#39;:0.0,&#39;mlp_bias&#39;:False,&#39;head_dim&#39;:96,&#39;return_dict&#39;:True,&#39;output_hidden_states&#39;:False,&#39;torchscript&#39;:False,&#39;dtype&#39;:&#39;float32&#39;,&#39;pruned_heads&#39;:{},&#39;tie_word_embeddings&#39;:False,&#39;chunk_size_feed_forward&#39;:0,&#39;is_encoder_decoder&#39;:False,&#39;is_decoder&#39;:False,&#39;cross_attention_hidden_size&#39;:None,&#39;add_cross_attention&#39;:False,&#39;tie_encoder_decoder&#39;:False,&#39;architectures&#39;:[&#39;LlamaForCausalLM&#39;],&#39;finetuning_task&#39;:None,&#39;id2label&#39;:{0:&#39;LABEL_0&#39;,1:&#39;LABEL_1&#39;},&#39;label2id&#39;:{&#39;LABEL_0&#39;:0,&#39;LABEL_1&#39;:1},&#39;task_specific_params&#39;:None,&#39;problem_type&#39;:None,&#39;tokenizer_class&#39;:None,&#39;prefix&#39;:None,&#39;bos_token_id&#39;:1,&#39;pad_token_id&#39;:None,&#39;eos_token_id&#39;:2,&#39;sep_token_id&#39;:None,&#39;decoder_start_token_id&#39;:None,&#39;max_length&#39;:20,&#39;min_length&#39;:0,&#39;do_sample&#39;:False,&#39;early_stopping&#39;:False,&#39;num_beams&#39;:1,&#39;num_beam_groups&#39;:1,&#39;diversity_penalty&#39;:0.0,&#39;temperature&#39;:1.0,&#39;top_k&#39;:50,&#39;top_p&#39;:1.0,&#39;typical_p&#39;:1.0,&#39;repetition_penalty&#39;:1.0,&#39;length_penalty&#39;:1.0,&#39;no_repeat_ngram_size&#39;:0,&#39;encoder_no_repeat_ngram_size&#39;:0,&#39;bad_words_ids&#39;:None,&#39;num_return_sequences&#39;:1,&#39;output_scores&#39;:False,&#39;return_dict_in_generate&#39;:False,&#39;forced_bos_token_id&#39;:None,&#39;forced_eos_token_id&#39;:None,&#39;remove_invalid_values&#39;:False,&#39;exponential_decay_length_penalty&#39;:None,&#39;suppress_tokens&#39;:None,&#39;begin_suppress_tokens&#39;:None,&#39;_name_or_path&#39;:&#39;&#39;,&#39;transformers_version&#39;:&#39;4.56.0.dev0&#39;,&#39;model_type&#39;:&#39;llama&#39;,&#39;tf_legacy_loss&#39;:False,&#39;use_bfloat16&#39;:False,&#39;subfolder&#39;:None,&#39;output_attentions&#39;:False};
    :model_config_class,LlamaConfig;
    :model_file,~/github/transformers/src/transformers/models/llama/modeling_llama.py;
    :model_id,arnir0/Tiny-LLM;
    :model_inputs,dict(input_ids:T7s2x3,attention_mask:T7s2x33,position_ids:T7s2x3,past_key_values:DynamicCache(key_cache=#1[T1s2x1x30x96], value_cache=#1[T1s2x1x30x96]));
    :model_inputs_options,;
    :model_module,transformers.models.llama.modeling_llama;
    :model_nweights,12988992;
    :model_shapes,dict(input_ids:{0:Dim(batch),1:DYN(seq_length)},attention_mask:{0:Dim(batch),1:DYN(cache+seq)},position_ids:{0:Dim(batch),1:DYN(cache+seq)},past_key_values:#2[#1[{0:Dim(batch),2:DYN(cache_length)}],#1[{0:Dim(batch),2:DYN(cache_length)}]]);
    :model_size,51955968;
    :model_subfolder,;
    :model_task,text-generation;
    :onnx_filename,dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir/arnir0_Tiny-LLM-onnx-dynamo-ir.onnx;
    :onnx_ort_inputs,dict(input_ids:A7s2x3,attention_mask:A7s2x33,position_ids:A7s2x3,past_key_values_key_cache_0:A1s2x1x30x96,past_key_values_value_cache_0:A1s2x1x30x96);
    :onnx_ort_inputs2,dict(input_ids:A7s3x4,attention_mask:A7s3x35,position_ids:A7s3x4,past_key_values_key_cache_0:A1s3x1x31x96,past_key_values_value_cache_0:A1s3x1x31x96);
    :onnx_size,204345;
    :run_expected,CausalLMOutputWithPast(logits:T1s2x3x32000,past_key_values:DynamicCache(key_cache=#1[T1s2x1x33x96], value_cache=#1[T1s2x1x33x96]));
    :run_expected2,CausalLMOutputWithPast(logits:T1s3x4x32000,past_key_values:DynamicCache(key_cache=#1[T1s3x1x35x96], value_cache=#1[T1s3x1x35x96]));
    :run_feeds_inputs,dict(input_ids:A7s2x3,attention_mask:A7s2x33,position_ids:A7s2x3,past_key_values_key_cache_0:A1s2x1x30x96,past_key_values_value_cache_0:A1s2x1x30x96);
    :run_feeds_inputs2,dict(input_ids:A7s3x4,attention_mask:A7s3x35,position_ids:A7s3x4,past_key_values_key_cache_0:A1s3x1x31x96,past_key_values_value_cache_0:A1s3x1x31x96);
    :run_output_inputs,#3[A1s2x3x32000,A1s2x1x33x96,A1s2x1x33x96];
    :run_output_inputs2,#3[A1s3x4x32000,A1s3x1x35x96,A1s3x1x35x96];
    :time_create,0.15212773500024923;
    :time_create_onnx_ort,0.050103256000511465;
    :time_export_onnx,7.234299549001662;
    :time_export_onnx_opt_ir,0.04470971100090537;
    :time_onnx_save,0.15125025599991204;
    :time_run,0.012062527999660233;
    :time_run2,0.009683688998848083;
    :time_run_onnx_ort,0.008159883000189438;
    :time_run_onnx_ort2,0.002132023000740446;
    :time_run_patched,0.008518315999026527;
    :version_date,2025-08-27T17:08:26;
    :version_device,;
    :version_do_run,True;
    :version_drop_inputs,[];
    :version_dtype,;
    :version_dump_folder,dump_models;
    :version_exporter,onnx-dynamo;
    :version_inputs2,1;
    :version_model_id,arnir0/Tiny-LLM;
    :version_numpy,2.3.2;
    :version_onnx,1.20.0;
    :version_onnx_diagnostic,0.7.7;
    :version_onnx_ir,0.1.8;
    :version_onnxruntime,1.23.0;
    :version_onnxscript,0.3.0.dev20250301;
    :version_opset,18;
    :version_optimization,ir;
    :version_ortfusiontype,;
    :version_patch,True;
    :version_patch_kwargs,{&#39;patch_transformers&#39;:True,&#39;patch_diffusers&#39;:True,&#39;patch&#39;:True};
    :version_quiet,False;
    :version_rewrite,True;
    :version_runtime,onnxruntime;
    :version_same_as_pretrained,False;
    :version_scipy,1.16.1;
    :version_stop_if_static,0;
    :version_torch,2.9.0.dev20250820+cu126;
    :version_transformers,4.56.0.dev0;
    :version_use_pretrained,False;
</pre></div>
</div>
</section>
<section id="run-onnxruntime-fusions">
<h2>Run onnxruntime fusions<a class="headerlink" href="#run-onnxruntime-fusions" title="Link to this heading">¶</a></h2>
<p>This option runs <a class="reference external" href="https://onnxruntime.ai/docs/performance/transformers-optimization.html">transformers optimizations</a>
implemented in <a class="reference external" href="https://onnxruntime.ai/">onnxruntime</a>. The list of supported <code class="docutils literal notranslate"><span class="pre">model_type</span></code> can be found in the documentation
of function <a class="reference internal" href="../api/torch_models/validate.html#onnx_diagnostic.torch_models.validate.run_ort_fusion" title="onnx_diagnostic.torch_models.validate.run_ort_fusion"><code class="xref py py-func docutils literal notranslate"><span class="pre">onnx_diagnostic.torch_models.validate.run_ort_fusion()</span></code></a>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">onnx_diagnostic</span> <span class="n">validate</span> <span class="o">-</span><span class="n">m</span> <span class="n">arnir0</span><span class="o">/</span><span class="n">Tiny</span><span class="o">-</span><span class="n">LLM</span> <span class="o">--</span><span class="n">run</span> <span class="o">-</span><span class="n">v</span> <span class="mi">1</span> <span class="o">--</span><span class="n">export</span> <span class="n">onnx</span><span class="o">-</span><span class="n">dynamo</span> <span class="o">-</span><span class="n">o</span> <span class="n">dump_models</span> <span class="o">--</span><span class="n">patch</span> <span class="o">--</span><span class="n">opt</span> <span class="n">ir</span> <span class="o">--</span><span class="n">ortfusiontype</span> <span class="n">ALL</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    [validate_model] dump into &#39;arnir0_Tiny-LLM-onnx-dynamo-ir&#39;
    [validate_model] validate model id &#39;arnir0/Tiny-LLM&#39;
    [validate_model] patch=True
    [validate_model] get dummy inputs with input_options=None...
    [validate_model] rewrite=True, patch_kwargs={&#39;patch_transformers&#39;: True, &#39;patch_diffusers&#39;: True, &#39;patch&#39;: True}, stop_if_static=0
    [validate_model] exporter=&#39;onnx-dynamo&#39;, optimization=&#39;ir&#39;
    [validate_model] dump_folder=&#39;dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir&#39;
    [validate_model] output_names=None
    [get_untrained_model_with_inputs] model_id=&#39;arnir0/Tiny-LLM&#39;
    [get_untrained_model_with_inputs] use preinstalled &#39;arnir0/Tiny-LLM&#39;
    [get_untrained_model_with_inputs] architectures=[&#39;LlamaForCausalLM&#39;]
    [get_untrained_model_with_inputs] cls=&#39;LlamaConfig&#39;
    [get_untrained_model_with_inputs] task=&#39;text-generation&#39;
    [get_untrained_model_with_inputs] default config._attn_implementation=None
    [get_untrained_model_with_inputs] use fct=&lt;function get_inputs at 0x726e5d185b20&gt;
    [validate_model] --
    [validate_model] task=text-generation
    [validate_model] size=49.549072265625 Mb
    [validate_model] n_weights=12.988992 millions parameters
    [validate_model] +INPUT input_ids=T7s2x3
    [validate_model] +INPUT attention_mask=T7s2x33
    [validate_model] +INPUT position_ids=T7s2x3
    [validate_model] +INPUT past_key_values=DynamicCache(key_cache=#1[T1s2x1x30x96], value_cache=#1[T1s2x1x30x96])
    [validate_model] +SHAPE input_ids={0:Dim(batch),1:DYN(seq_length)}
    [validate_model] +SHAPE attention_mask={0:Dim(batch),1:DYN(cache+seq)}
    [validate_model] +SHAPE position_ids={0:Dim(batch),1:DYN(cache+seq)}
    [validate_model] +SHAPE past_key_values=#2[#1[{0:Dim(batch),2:DYN(cache_length)}],#1[{0:Dim(batch),2:DYN(cache_length)}]]
    [validate_model] --
    [validate_model] -- run the model inputs=&#39;inputs&#39;...
    [validate_model] inputs=dict(input_ids:T7s2x3,attention_mask:T7s2x33,position_ids:T7s2x3,past_key_values:DynamicCache(key_cache=#1[T1s2x1x30x96], value_cache=#1[T1s2x1x30x96]))
    [validate_model] done ([run])
    [validate_model] -- run the model inputs=&#39;inputs2&#39;...
    [validate_model] inputs2=dict(input_ids:T7s3x4,attention_mask:T7s3x35,position_ids:T7s3x4,past_key_values:DynamicCache(key_cache=#1[T1s3x1x31x96], value_cache=#1[T1s3x1x31x96]))
    [validate_model] done ([run2])
    [validate_model] -- export the model with &#39;onnx-dynamo&#39;, optimization=&#39;ir&#39;
    [validate_model] applies patches before exporting stop_if_static=0
    [validate_model] run patched model...
    [validate_model] patched inputs=dict(input_ids:T7s2x3,attention_mask:T7s2x33,position_ids:T7s2x3,past_key_values:DynamicCache(key_cache=#1[T1s2x1x30x96], value_cache=#1[T1s2x1x30x96]))
    [validate_model] done (patched run)
    [validate_model] patched discrepancies=abs=0, rel=0
    [call_torch_export_onnx] exporter=&#39;onnx-dynamo&#39;, optimization=&#39;ir&#39;
    [call_torch_export_onnx] args=()
    [call_torch_export_onnx] kwargs=dict(input_ids:T7s2x3,attention_mask:T7s2x33,position_ids:T7s2x3,past_key_values:DynamicCache(key_cache=#1[T1s2x1x30x96], value_cache=#1[T1s2x1x30x96]))
    [call_torch_export_onnx] dynamic_shapes=dict(input_ids:{0:Dim(batch),1:DYN(seq_length)},attention_mask:{0:Dim(batch),1:DYN(cache+seq)},position_ids:{0:Dim(batch),1:DYN(cache+seq)},past_key_values:#2[#1[{0:Dim(batch),2:DYN(cache_length)}],#1[{0:Dim(batch),2:DYN(cache_length)}]])
    [call_torch_export_onnx] export...
    [call_torch_export_onnx] export_export_kwargs=dict(dynamo:bool,dynamic_shapes:dict(input_ids:{0:Dim(batch),1:DYN(seq_length)},attention_mask:{0:Dim(batch),1:DYN(cache+seq)},position_ids:{0:Dim(batch),1:DYN(cache+seq)},past_key_values:#2[#1[{0:Dim(batch),2:DYN(cache_length)}],#1[{0:Dim(batch),2:DYN(cache_length)}]]),opset_version:int)
    [torch.onnx] Obtain model graph for `LlamaForCausalLM([...]` with `torch.export.export(..., strict=False)`...
    [_catch_produce_guards_and_solve_constraints] ERROR: produce_guards_and_solve_constraints failed, use SKIP_SOLVE_CONSTRAINTS=0 to avoid skipping
    fake_mode=&lt;torch._subclasses.fake_tensor.FakeTensorMode object at 0x726e2d7765d0&gt;
    dynamic_shapes={&#39;input_ids&#39;: {0: Dim(&#39;batch&#39;, min=1, max=1024), 1: _DimHint(type=&lt;_DimHintType.DYNAMIC: 3&gt;, min=None, max=None, _factory=True)}, &#39;attention_mask&#39;: {0: Dim(&#39;batch&#39;, min=1, max=1024), 1: _DimHint(type=&lt;_DimHintType.DYNAMIC: 3&gt;, min=None, max=None, _factory=True)}, &#39;position_ids&#39;: {0: Dim(&#39;batch&#39;, min=1, max=1024), 1: _DimHint(type=&lt;_DimHintType.DYNAMIC: 3&gt;, min=None, max=None, _factory=True)}, &#39;past_key_values&#39;: [[{0: Dim(&#39;batch&#39;, min=1, max=1024), 2: _DimHint(type=&lt;_DimHintType.DYNAMIC: 3&gt;, min=None, max=None, _factory=True)}], [{0: Dim(&#39;batch&#39;, min=1, max=1024), 2: _DimHint(type=&lt;_DimHintType.DYNAMIC: 3&gt;, min=None, max=None, _factory=True)}]]}
    equalities_inputs=EqualityConstraint(warn_only=False, source_pairs=[(TensorPropertySource(base=LocalSource(local_name=&#39;attention_mask&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0), TensorPropertySource(base=LocalSource(local_name=&#39;input_ids&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0)), (TensorPropertySource(base=LocalSource(local_name=&#39;position_ids&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0), TensorPropertySource(base=LocalSource(local_name=&#39;input_ids&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0)), (TensorPropertySource(base=GetItemSource(base=GetItemSource(base=LocalSource(local_name=&#39;past_key_values&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), index=&#39;key_cache&#39;, index_is_slice=False), index=0, index_is_slice=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0), TensorPropertySource(base=LocalSource(local_name=&#39;input_ids&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0)), (TensorPropertySource(base=GetItemSource(base=GetItemSource(base=LocalSource(local_name=&#39;past_key_values&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), index=&#39;value_cache&#39;, index_is_slice=False), index=0, index_is_slice=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0), TensorPropertySource(base=LocalSource(local_name=&#39;input_ids&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0))], derived_equalities=[], phantom_symbols=[], relaxed_sources={TensorPropertySource(base=LocalSource(local_name=&#39;attention_mask&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=1), TensorPropertySource(base=LocalSource(local_name=&#39;input_ids&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=1), TensorPropertySource(base=GetItemSource(base=GetItemSource(base=LocalSource(local_name=&#39;past_key_values&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), index=&#39;value_cache&#39;, index_is_slice=False), index=0, index_is_slice=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=2), TensorPropertySource(base=LocalSource(local_name=&#39;position_ids&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=1), TensorPropertySource(base=GetItemSource(base=GetItemSource(base=LocalSource(local_name=&#39;past_key_values&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), index=&#39;key_cache&#39;, index_is_slice=False), index=0, index_is_slice=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=2)}, _parents={TensorPropertySource(base=LocalSource(local_name=&#39;attention_mask&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0): TensorPropertySource(base=LocalSource(local_name=&#39;input_ids&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0), TensorPropertySource(base=LocalSource(local_name=&#39;position_ids&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0): TensorPropertySource(base=LocalSource(local_name=&#39;input_ids&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0), TensorPropertySource(base=GetItemSource(base=GetItemSource(base=LocalSource(local_name=&#39;past_key_values&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), index=&#39;key_cache&#39;, index_is_slice=False), index=0, index_is_slice=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0): TensorPropertySource(base=LocalSource(local_name=&#39;input_ids&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0), TensorPropertySource(base=GetItemSource(base=GetItemSource(base=LocalSource(local_name=&#39;past_key_values&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), index=&#39;value_cache&#39;, index_is_slice=False), index=0, index_is_slice=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0): TensorPropertySource(base=LocalSource(local_name=&#39;input_ids&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0)}, _defs={})
    original_signature=(input_ids: Optional[torch.LongTensor] = None, attention_mask: Optional[torch.Tensor] = None, position_ids: Optional[torch.LongTensor] = None, past_key_values: Optional[transformers.cache_utils.Cache] = None, inputs_embeds: Optional[torch.FloatTensor] = None, labels: Optional[torch.LongTensor] = None, use_cache: Optional[bool] = None, cache_position: Optional[torch.LongTensor] = None, logits_to_keep: Union[int, torch.Tensor] = 0, **kwargs: Unpack[transformers.utils.generic.TransformersKwargs]) -&gt; transformers.modeling_outputs.CausalLMOutputWithPast
    kwargs={}
    exc=Constraints violated (batch)! For more information, run with TORCH_LOGS=&quot;+dynamic&quot;.
      - Not all values of batch = L[&#39;input_ids&#39;].size()[0] in the specified range batch &lt;= 1024 satisfy the generated guard L[&#39;input_ids&#39;].size()[0] != 1.
    gm=&lt;lambda&gt;()
    
    
    
    def forward(self, arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1, arg6_1, arg7_1, arg8_1, arg9_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1):
        sym_size_int = torch.ops.aten.sym_size.int(arg16_1, 0)
        empty = torch.ops.aten.empty.memory_format([sym_size_int, 1, 0, 96], dtype = torch.float32, device = device(type=&#39;cpu&#39;), pin_memory = False)
        empty_1 = torch.ops.aten.empty.memory_format([sym_size_int, 1, 0, 96], dtype = torch.float32, device = device(type=&#39;cpu&#39;), pin_memory = False)
        cat = torch.ops.aten.cat.default([empty, arg16_1], -2);  empty = arg16_1 = None
        cat_1 = torch.ops.aten.cat.default([empty_1, arg17_1], -2);  empty_1 = arg17_1 = None
        embedding = torch.ops.aten.embedding.default(arg0_1, arg13_1);  arg0_1 = None
        sym_size_int_1 = torch.ops.aten.sym_size.int(cat, 2)
        sym_size_int_2 = torch.ops.aten.sym_size.int(arg13_1, 1)
        add = sym_size_int_1 + sym_size_int_2
        arange = torch.ops.aten.arange.start(sym_size_int_1, add, device = device(type=&#39;cpu&#39;), pin_memory = False);  add = None
        to = torch.ops.aten.to.device(arg14_1, device(type=&#39;cpu&#39;), torch.bool);  arg14_1 = None
        sym_size_int_3 = torch.ops.aten.sym_size.int(arange, 0)
        add_1 = sym_size_int_3 + sym_size_int_1;  sym_size_int_1 = None
        arange_1 = torch.ops.aten.arange.default(add_1, device = device(type=&#39;cpu&#39;), pin_memory = False);  add_1 = None
        add_ = torch.ops.aten.add_.Tensor(arange_1, 0)
        sym_size_int_5 = torch.ops.aten.sym_size.int(arg13_1, 0);  arg13_1 = None
        arange_2 = torch.ops.aten.arange.default(sym_size_int_5, device = device(type=&#39;cpu&#39;), pin_memory = False)
        arange_3 = torch.ops.aten.arange.default(1, device = device(type=&#39;cpu&#39;), pin_memory = False)
        sym_size_int_6 = torch.ops.aten.sym_size.int(arange_2, 0)
        sym_size_int_7 = torch.ops.aten.sym_size.int(arange_1, 0);  arange_1 = None
        reshape = torch.ops.aten.reshape.default(arange_2, [-1, 1, 1, 1]);  arange_2 = None
        reshape_1 = torch.ops.aten.reshape.default(arange_3, [1, -1, 1, 1]);  arange_3 = None
        reshape_2 = torch.ops.aten.reshape.default(arange, [1, 1, -1, 1]);  arange = None
        reshape_3 = torch.ops.aten.reshape.default(add_, [1, 1, 1, -1]);  add_ = None
        expand = torch.ops.aten.expand.default(reshape, [sym_size_int_6, 1, sym_size_int_3, sym_size_int_7]);  reshape = None
        expand_1 = torch.ops.aten.expand.default(reshape_1, [sym_size_int_6, 1, sym_size_int_3, sym_size_int_7]);  reshape_1 = expand_1 = None
        expand_2 = torch.ops.aten.expand.default(reshape_2, [sym_size_int_6, 1, sym_size_int_3, sym_size_int_7]);  reshape_2 = None
        expand_3 = torch.ops.aten.expand.default(reshape_3, [sym_size_int_6, 1, sym_size_int_3, sym_size_int_7]);  reshape_3 = sym_size_int_6 = sym_size_int_3 = sym_size_int_7 = None
        new_ones = torch.ops.aten.new_ones.default(expand_2, [], dtype = torch.bool, pin_memory = False)
        le = torch.ops.aten.le.Tensor(expand_3, expand_2);  expand_2 = None
        to_1 = torch.ops.aten.to.dtype_layout(le, dtype = torch.bool, layout = torch.strided, device = device(type=&#39;cpu&#39;));  le = None
        and_1 = torch.ops.aten.__and__.Tensor(new_ones, to_1);  new_ones = to_1 = None
        index = torch.ops.aten.index.Tensor(to, [expand, expand_3]);  to = expand = expand_3 = None
        to_2 = torch.ops.aten.to.dtype_layout(index, dtype = torch.bool, layout = torch.strided, device = device(type=&#39;cpu&#39;));  index = None
        and_2 = torch.ops.aten.__and__.Tensor(and_1, to_2);  and_1 = to_2 = None
        _set_grad_enabled = torch._C._set_grad_enabled(False);  _set_grad_enabled = None
        unsqueeze = torch.ops.aten.unsqueeze.default(arg12_1, 0);  arg12_1 = None
        unsqueeze_1 = torch.ops.aten.unsqueeze.default(unsqueeze, 2);  unsqueeze = None
        to_3 = torch.ops.aten.to.dtype(unsqueeze_1, torch.float32);  unsqueeze_1 = None
        sym_size_int_8 = torch.ops.aten.sym_size.int(arg15_1, 0)
        expand_4 = torch.ops.aten.expand.default(to_3, [sym_size_int_8, -1, 1]);  to_3 = sym_size_int_8 = None
        to_4 = torch.ops.aten.to.dtype_layout(expand_4, dtype = torch.float32, layout = torch.strided, device = device(type=&#39;cpu&#39;));  expand_4 = None
        unsqueeze_2 = torch.ops.aten.unsqueeze.default(arg15_1, 1);  arg15_1 = None
        slice_1 = torch.ops.aten.slice.Tensor(unsqueeze_2, 2, 0, 9223372036854775807);  unsqueeze_2 = None
        to_5 = torch.ops.aten.to.dtype(slice_1, torch.float32);  slice_1 = None
        _enter_autocast = torch.amp.autocast_mode._enter_autocast(&#39;cpu&#39;, torch.bfloat16, False, False)
        to_6 = torch.ops.aten.to.dtype(to_4, torch.float32);  to_4 = None
        to_7 = torch.ops.aten.to.dtype(to_5, torch.float32);  to_5 = None
        matmul = torch.ops.aten.matmul.default(to_6, to_7);  to_6 = to_7 = None
        transpose = torch.ops.aten.transpose.int(matmul, 1, 2);  matmul = None
        cat_2 = torch.ops.aten.cat.default([transpose, transpose], -1);  transpose = None
        cos = torch.ops.aten.cos.default(cat_2)
        mul = torch.ops.aten.mul.Tensor(cos, 1.0);  cos = None
        sin = torch.ops.aten.sin.default(cat_2);  cat_2 = None
        mul_1 = torch.ops.aten.mul.Tensor(sin, 1.0);  sin = None
        _exit_autocast = torch.amp.autocast_mode._exit_autocast(_enter_autocast);  _enter_autocast = _exit_autocast = None
        to_8 = torch.ops.aten.to.dtype(mul, torch.float32);  mul = None
        to_9 = torch.ops.aten.to.dtype(mul_1, torch.float32);  mul_1 = None
        _set_grad_enabled_1 = torch._C._set_grad_enabled(True);  _set_grad_enabled_1 = None
        to_10 = torch.ops.aten.to.dtype(embedding, torch.float32);  embedding = None
        pow_1 = torch.ops.aten.pow.Tensor_Scalar(to_10, 2)
        mean = torch.ops.aten.mean.dim(pow_1, [-1], True);  pow_1 = None
        add_3 = torch.ops.aten.add.Tensor(mean, 1e-05);  mean = None
        rsqrt = torch.ops.aten.rsqrt.default(add_3);  add_3 = None
        mul_2 = torch.ops.aten.mul.Tensor(to_10, rsqrt);  rsqrt = None
        to_11 = torch.ops.aten.to.dtype(mul_2, torch.float32);  mul_2 = None
        mul_3 = torch.ops.aten.mul.Tensor(arg8_1, to_11);  arg8_1 = to_11 = None
        linear = torch.ops.aten.linear.default(mul_3, arg1_1);  arg1_1 = None
        view = torch.ops.aten.view.default(linear, [sym_size_int_5, sym_size_int_2, -1, 96]);  linear = None
        transpose_1 = torch.ops.aten.transpose.int(view, 1, 2);  view = None
        linear_1 = torch.ops.aten.linear.default(mul_3, arg2_1);  arg2_1 = None
        view_1 = torch.ops.aten.view.default(linear_1, [sym_size_int_5, sym_size_int_2, -1, 96]);  linear_1 = None
        transpose_2 = torch.ops.aten.transpose.int(view_1, 1, 2);  view_1 = None
        linear_2 = torch.ops.aten.linear.default(mul_3, arg3_1);  mul_3 = arg3_1 = None
        view_2 = torch.ops.aten.view.default(linear_2, [sym_size_int_5, sym_size_int_2, -1, 96]);  linear_2 = None
        transpose_3 = torch.ops.aten.transpose.int(view_2, 1, 2);  view_2 = None
        unsqueeze_3 = torch.ops.aten.unsqueeze.default(to_8, 1);  to_8 = None
        unsqueeze_4 = torch.ops.aten.unsqueeze.default(to_9, 1);  to_9 = None
        mul_4 = torch.ops.aten.mul.Tensor(transpose_1, unsqueeze_3)
        slice_2 = torch.ops.aten.slice.Tensor(transpose_1, 3, 0, 48)
        slice_3 = torch.ops.aten.slice.Tensor(transpose_1, 3, 48, 9223372036854775807);  transpose_1 = None
        neg = torch.ops.aten.neg.default(slice_3);  slice_3 = None
        cat_3 = torch.ops.aten.cat.default([neg, slice_2], -1);  neg = slice_2 = None
        mul_5 = torch.ops.aten.mul.Tensor(cat_3, unsqueeze_4);  cat_3 = None
        add_4 = torch.ops.aten.add.Tensor(mul_4, mul_5);  mul_4 = mul_5 = None
        mul_6 = torch.ops.aten.mul.Tensor(transpose_2, unsqueeze_3);  unsqueeze_3 = None
        slice_4 = torch.ops.aten.slice.Tensor(transpose_2, 3, 0, 48)
        slice_5 = torch.ops.aten.slice.Tensor(transpose_2, 3, 48, 9223372036854775807);  transpose_2 = None
        neg_1 = torch.ops.aten.neg.default(slice_5);  slice_5 = None
        cat_4 = torch.ops.aten.cat.default([neg_1, slice_4], -1);  neg_1 = slice_4 = None
        mul_7 = torch.ops.aten.mul.Tensor(cat_4, unsqueeze_4);  cat_4 = unsqueeze_4 = None
        add_5 = torch.ops.aten.add.Tensor(mul_6, mul_7);  mul_6 = mul_7 = None
        cat_5 = torch.ops.aten.cat.default([cat, add_5], -2);  cat = add_5 = None
        cat_6 = torch.ops.aten.cat.default([cat_1, transpose_3], -2);  cat_1 = transpose_3 = None
        unsqueeze_5 = torch.ops.aten.unsqueeze.default(cat_5, 2)
        sym_size_int_10 = torch.ops.aten.sym_size.int(cat_5, 2)
        slice_6 = torch.ops.aten.slice.Tensor(unsqueeze_5, 3, 0, 9223372036854775807);  unsqueeze_5 = None
        expand_5 = torch.ops.aten.expand.default(slice_6, [sym_size_int, 1, 2, sym_size_int_10, 96]);  slice_6 = None
        reshape_4 = torch.ops.aten.reshape.default(expand_5, [sym_size_int, 2, sym_size_int_10, 96]);  expand_5 = None
        unsqueeze_6 = torch.ops.aten.unsqueeze.default(cat_6, 2)
        sym_size_int_11 = torch.ops.aten.sym_size.int(cat_6, 2)
        slice_7 = torch.ops.aten.slice.Tensor(unsqueeze_6, 3, 0, 9223372036854775807);  unsqueeze_6 = None
        expand_6 = torch.ops.aten.expand.default(slice_7, [sym_size_int, 1, 2, sym_size_int_11, 96]);  slice_7 = None
        reshape_5 = torch.ops.aten.reshape.default(expand_6, [sym_size_int, 2, sym_size_int_11, 96]);  expand_6 = sym_size_int = sym_size_int_11 = None
        slice_8 = torch.ops.aten.slice.Tensor(and_2, 3, None, sym_size_int_10);  and_2 = sym_size_int_10 = None
        scaled_dot_product_attention = torch.ops.aten.scaled_dot_product_attention.default(add_4, reshape_4, reshape_5, slice_8, scale = 0.10206207261596575);  add_4 = reshape_4 = reshape_5 = slice_8 = None
        transpose_4 = torch.ops.aten.transpose.int(scaled_dot_product_attention, 1, 2);  scaled_dot_product_attention = None
        reshape_6 = torch.ops.aten.reshape.default(transpose_4, [sym_size_int_5, sym_size_int_2, -1]);  transpose_4 = sym_size_int_5 = sym_size_int_2 = None
        linear_3 = torch.ops.aten.linear.default(reshape_6, arg4_1);  reshape_6 = arg4_1 = None
        add_6 = torch.ops.aten.add.Tensor(to_10, linear_3);  to_10 = linear_3 = None
        to_12 = torch.ops.aten.to.dtype(add_6, torch.float32);  add_6 = None
        pow_2 = torch.ops.aten.pow.Tensor_Scalar(to_12, 2)
        mean_1 = torch.ops.aten.mean.dim(pow_2, [-1], True);  pow_2 = None
        add_7 = torch.ops.aten.add.Tensor(mean_1, 1e-05);  mean_1 = None
        rsqrt_1 = torch.ops.aten.rsqrt.default(add_7);  add_7 = None
        mul_16 = torch.ops.aten.mul.Tensor(to_12, rsqrt_1);  rsqrt_1 = None
        to_13 = torch.ops.aten.to.dtype(mul_16, torch.float32);  mul_16 = None
        mul_17 = torch.ops.aten.mul.Tensor(arg9_1, to_13);  arg9_1 = to_13 = None
        linear_4 = torch.ops.aten.linear.default(mul_17, arg5_1);  arg5_1 = None
        silu = torch.ops.aten.silu.default(linear_4);  linear_4 = None
        linear_5 = torch.ops.aten.linear.default(mul_17, arg6_1);  mul_17 = arg6_1 = None
        mul_18 = torch.ops.aten.mul.Tensor(silu, linear_5);  silu = linear_5 = None
        linear_6 = torch.ops.aten.linear.default(mul_18, arg7_1);  mul_18 = arg7_1 = None
        add_8 = torch.ops.aten.add.Tensor(to_12, linear_6);  to_12 = linear_6 = None
        to_14 = torch.ops.aten.to.dtype(add_8, torch.float32);  add_8 = None
        pow_3 = torch.ops.aten.pow.Tensor_Scalar(to_14, 2)
        mean_2 = torch.ops.aten.mean.dim(pow_3, [-1], True);  pow_3 = None
        add_9 = torch.ops.aten.add.Tensor(mean_2, 1e-05);  mean_2 = None
        rsqrt_2 = torch.ops.aten.rsqrt.default(add_9);  add_9 = None
        mul_19 = torch.ops.aten.mul.Tensor(to_14, rsqrt_2);  to_14 = rsqrt_2 = None
        to_15 = torch.ops.aten.to.dtype(mul_19, torch.float32);  mul_19 = None
        mul_20 = torch.ops.aten.mul.Tensor(arg10_1, to_15);  arg10_1 = to_15 = None
        slice_9 = torch.ops.aten.slice.Tensor(mul_20, 1, 0, 9223372036854775807);  mul_20 = None
        linear_7 = torch.ops.aten.linear.default(slice_9, arg11_1);  slice_9 = arg11_1 = None
        return (linear_7, cat_5, cat_6)
        
    # To see more debug info, please use `graph_module.print_readable()`
    [torch.onnx] Obtain model graph for `LlamaForCausalLM([...]` with `torch.export.export(..., strict=False)`... ✅
    [torch.onnx] Run decomposition...
    [torch.onnx] Run decomposition... ✅
    [torch.onnx] Translate the graph into ONNX...
    [torch.onnx] Translate the graph into ONNX... ✅
    ~/vv/this312/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_dynamic_shapes.py:264: UserWarning: # The axis name: batch will not be used, since it shares the same shape constraints with another axis: batch.
      warnings.warn(
    ~/vv/this312/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_dynamic_shapes.py:264: UserWarning: # The axis name: batch will not be used, since it shares the same shape constraints with another axis: batch.
      warnings.warn(
    ~/vv/this312/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_dynamic_shapes.py:264: UserWarning: # The axis name: cache+seq will not be used, since it shares the same shape constraints with another axis: seq_length.
      warnings.warn(
    ~/vv/this312/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_dynamic_shapes.py:264: UserWarning: # The axis name: batch will not be used, since it shares the same shape constraints with another axis: batch.
      warnings.warn(
    ~/vv/this312/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_dynamic_shapes.py:264: UserWarning: # The axis name: batch will not be used, since it shares the same shape constraints with another axis: batch.
      warnings.warn(
    Applied 35 of general pattern rewrite rules.
    [call_torch_export_onnx] done (export)
    [call_torch_export_onnx] starts optimization=&#39;ir&#39;...
    [call_torch_export_onnx] done (optimization)
    [validate_model] dumps onnx program in &#39;dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir&#39;...
    [validate_model] done (dump onnx) in 0.26968359500096994
    [validate_model] dumps statistics in &#39;dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir&#39;...
    [validate_model] done (dump)
    [validate_onnx_model] verify onnx model with providers [&#39;CPUExecutionProvider&#39;]..., flavour=None
    [validate_onnx_model] done (ort_session) flavour=None
    [validate_onnx_model] -- make_feeds for &#39;inputs&#39;...
    [validate_onnx_model] inputs=dict(input_ids:T7s2x3,attention_mask:T7s2x33,position_ids:T7s2x3,past_key_values:DynamicCache(key_cache=#1[T1s2x1x30x96], value_cache=#1[T1s2x1x30x96]))
    [validate_onnx_model] ort inputs=dict(input_ids:A7s2x3,attention_mask:A7s2x33,position_ids:A7s2x3,past_key_values_key_cache_0:A1s2x1x30x96,past_key_values_value_cache_0:A1s2x1x30x96)
    [validate_onnx_model] done (make_feeds)
    [validate_onnx_model] run session...
    [validate_onnx_model] done (run)
    [validate_onnx_model] got=#3[A1s2x3x32000,A1s2x1x33x96,A1s2x1x33x96]
    [validate_onnx_model] discrepancies=abs=7.450580596923828e-07, rel=0.00027354017262003796, n=204672.0
    [validate_onnx_model] -- make_feeds for &#39;inputs2&#39;...
    [validate_onnx_model] inputs=dict(input_ids:T7s3x4,attention_mask:T7s3x35,position_ids:T7s3x4,past_key_values:DynamicCache(key_cache=#1[T1s3x1x31x96], value_cache=#1[T1s3x1x31x96]))
    [validate_onnx_model] ort inputs=dict(input_ids:A7s3x4,attention_mask:A7s3x35,position_ids:A7s3x4,past_key_values_key_cache_0:A1s3x1x31x96,past_key_values_value_cache_0:A1s3x1x31x96)
    [validate_onnx_model] done (make_feeds)
    [validate_onnx_model] run session...
    [validate_onnx_model] done (run)
    [validate_onnx_model] got=#3[A1s3x4x32000,A1s3x1x35x96,A1s3x1x35x96]
    [validate_onnx_model] discrepancies=abs=8.344650268554688e-07, rel=0.0003063333051545333, n=404160.0
    [validate_model] run onnxruntime fusion for &#39;bart&#39;
    failed in shape inference &lt;class &#39;AssertionError&#39;&gt;
    [validate_model] done &#39;bart&#39; in 0.20830882399968687, saved into &#39;dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir/arnir0_Tiny-LLM-onnx-dynamo-ir.ort.bart.onnx&#39;
    [validate_onnx_model] verify onnx model with providers [&#39;CPUExecutionProvider&#39;]..., flavour=&#39;ortbart&#39;
    [validate_onnx_model] done (ort_session) flavour=&#39;ortbart&#39;
    [validate_onnx_model] -- make_feeds for &#39;inputs&#39;...
    [validate_onnx_model] inputs=dict(input_ids:T7s2x3,attention_mask:T7s2x33,position_ids:T7s2x3,past_key_values:DynamicCache(key_cache=#1[T1s2x1x30x96], value_cache=#1[T1s2x1x30x96]))
    [validate_onnx_model] ort inputs=dict(input_ids:A7s2x3,attention_mask:A7s2x33,position_ids:A7s2x3,past_key_values_key_cache_0:A1s2x1x30x96,past_key_values_value_cache_0:A1s2x1x30x96)
    [validate_onnx_model] done (make_feeds)
    [validate_onnx_model] run session...
    [validate_onnx_model] done (run)
    [validate_onnx_model] got=#3[A1s2x3x32000,A1s2x1x33x96,A1s2x1x33x96]
    [validate_onnx_model] discrepancies=abs=8.344650268554688e-07, rel=0.0004247389736828931, n=204672.0
    [validate_onnx_model] -- make_feeds for &#39;inputs2&#39;...
    [validate_onnx_model] inputs=dict(input_ids:T7s3x4,attention_mask:T7s3x35,position_ids:T7s3x4,past_key_values:DynamicCache(key_cache=#1[T1s3x1x31x96], value_cache=#1[T1s3x1x31x96]))
    [validate_onnx_model] ort inputs=dict(input_ids:A7s3x4,attention_mask:A7s3x35,position_ids:A7s3x4,past_key_values_key_cache_0:A1s3x1x31x96,past_key_values_value_cache_0:A1s3x1x31x96)
    [validate_onnx_model] done (make_feeds)
    [validate_onnx_model] run session...
    [validate_onnx_model] done (run)
    [validate_onnx_model] got=#3[A1s3x4x32000,A1s3x1x35x96,A1s3x1x35x96]
    [validate_onnx_model] discrepancies=abs=8.344650268554688e-07, rel=0.00036102609604184355, n=404160.0
    [validate_model] run onnxruntime fusion for &#39;bert&#39;
    failed in shape inference &lt;class &#39;AssertionError&#39;&gt;
    [validate_model] done &#39;bert&#39; in 0.26940306600045005, saved into &#39;dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir/arnir0_Tiny-LLM-onnx-dynamo-ir.ort.bert.onnx&#39;
    [validate_onnx_model] verify onnx model with providers [&#39;CPUExecutionProvider&#39;]..., flavour=&#39;ortbert&#39;
    [validate_onnx_model] done (ort_session) flavour=&#39;ortbert&#39;
    [validate_onnx_model] -- make_feeds for &#39;inputs&#39;...
    [validate_onnx_model] inputs=dict(input_ids:T7s2x3,attention_mask:T7s2x33,position_ids:T7s2x3,past_key_values:DynamicCache(key_cache=#1[T1s2x1x30x96], value_cache=#1[T1s2x1x30x96]))
    [validate_onnx_model] ort inputs=dict(input_ids:A7s2x3,attention_mask:A7s2x33,position_ids:A7s2x3,past_key_values_key_cache_0:A1s2x1x30x96,past_key_values_value_cache_0:A1s2x1x30x96)
    [validate_onnx_model] done (make_feeds)
    [validate_onnx_model] run session...
    [validate_onnx_model] done (run)
    [validate_onnx_model] got=#3[A1s2x3x32000,A1s2x1x33x96,A1s2x1x33x96]
    [validate_onnx_model] discrepancies=abs=8.344650268554688e-07, rel=0.0004247389736828931, n=204672.0
    [validate_onnx_model] -- make_feeds for &#39;inputs2&#39;...
    [validate_onnx_model] inputs=dict(input_ids:T7s3x4,attention_mask:T7s3x35,position_ids:T7s3x4,past_key_values:DynamicCache(key_cache=#1[T1s3x1x31x96], value_cache=#1[T1s3x1x31x96]))
    [validate_onnx_model] ort inputs=dict(input_ids:A7s3x4,attention_mask:A7s3x35,position_ids:A7s3x4,past_key_values_key_cache_0:A1s3x1x31x96,past_key_values_value_cache_0:A1s3x1x31x96)
    [validate_onnx_model] done (make_feeds)
    [validate_onnx_model] run session...
    [validate_onnx_model] done (run)
    [validate_onnx_model] got=#3[A1s3x4x32000,A1s3x1x35x96,A1s3x1x35x96]
    [validate_onnx_model] discrepancies=abs=8.344650268554688e-07, rel=0.00036102609604184355, n=404160.0
    [validate_model] run onnxruntime fusion for &#39;bert_keras&#39;
    failed in shape inference &lt;class &#39;AssertionError&#39;&gt;
    [validate_model] done &#39;bert_keras&#39; in 0.27563871500024106, saved into &#39;dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir/arnir0_Tiny-LLM-onnx-dynamo-ir.ort.bert_keras.onnx&#39;
    [validate_onnx_model] verify onnx model with providers [&#39;CPUExecutionProvider&#39;]..., flavour=&#39;ortbert_keras&#39;
    [validate_onnx_model] done (ort_session) flavour=&#39;ortbert_keras&#39;
    [validate_onnx_model] -- make_feeds for &#39;inputs&#39;...
    [validate_onnx_model] inputs=dict(input_ids:T7s2x3,attention_mask:T7s2x33,position_ids:T7s2x3,past_key_values:DynamicCache(key_cache=#1[T1s2x1x30x96], value_cache=#1[T1s2x1x30x96]))
    [validate_onnx_model] ort inputs=dict(input_ids:A7s2x3,attention_mask:A7s2x33,position_ids:A7s2x3,past_key_values_key_cache_0:A1s2x1x30x96,past_key_values_value_cache_0:A1s2x1x30x96)
    [validate_onnx_model] done (make_feeds)
    [validate_onnx_model] run session...
    [validate_onnx_model] done (run)
    [validate_onnx_model] got=#3[A1s2x3x32000,A1s2x1x33x96,A1s2x1x33x96]
    [validate_onnx_model] discrepancies=abs=8.344650268554688e-07, rel=0.0004247389736828931, n=204672.0
    [validate_onnx_model] -- make_feeds for &#39;inputs2&#39;...
    [validate_onnx_model] inputs=dict(input_ids:T7s3x4,attention_mask:T7s3x35,position_ids:T7s3x4,past_key_values:DynamicCache(key_cache=#1[T1s3x1x31x96], value_cache=#1[T1s3x1x31x96]))
    [validate_onnx_model] ort inputs=dict(input_ids:A7s3x4,attention_mask:A7s3x35,position_ids:A7s3x4,past_key_values_key_cache_0:A1s3x1x31x96,past_key_values_value_cache_0:A1s3x1x31x96)
    [validate_onnx_model] done (make_feeds)
    [validate_onnx_model] run session...
    [validate_onnx_model] done (run)
    [validate_onnx_model] got=#3[A1s3x4x32000,A1s3x1x35x96,A1s3x1x35x96]
    [validate_onnx_model] discrepancies=abs=8.344650268554688e-07, rel=0.00036102609604184355, n=404160.0
    [validate_model] run onnxruntime fusion for &#39;bert_tf&#39;
    failed in shape inference &lt;class &#39;AssertionError&#39;&gt;
    [validate_model] done &#39;bert_tf&#39; in 0.2212624780004262, saved into &#39;dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir/arnir0_Tiny-LLM-onnx-dynamo-ir.ort.bert_tf.onnx&#39;
    [validate_onnx_model] verify onnx model with providers [&#39;CPUExecutionProvider&#39;]..., flavour=&#39;ortbert_tf&#39;
    [validate_onnx_model] done (ort_session) flavour=&#39;ortbert_tf&#39;
    [validate_onnx_model] -- make_feeds for &#39;inputs&#39;...
    [validate_onnx_model] inputs=dict(input_ids:T7s2x3,attention_mask:T7s2x33,position_ids:T7s2x3,past_key_values:DynamicCache(key_cache=#1[T1s2x1x30x96], value_cache=#1[T1s2x1x30x96]))
    [validate_onnx_model] ort inputs=dict(input_ids:A7s2x3,attention_mask:A7s2x33,position_ids:A7s2x3,past_key_values_key_cache_0:A1s2x1x30x96,past_key_values_value_cache_0:A1s2x1x30x96)
    [validate_onnx_model] done (make_feeds)
    [validate_onnx_model] run session...
    [validate_onnx_model] done (run)
    [validate_onnx_model] got=#3[A1s2x3x32000,A1s2x1x33x96,A1s2x1x33x96]
    [validate_onnx_model] discrepancies=abs=8.344650268554688e-07, rel=0.0004247389736828931, n=204672.0
    [validate_onnx_model] -- make_feeds for &#39;inputs2&#39;...
    [validate_onnx_model] inputs=dict(input_ids:T7s3x4,attention_mask:T7s3x35,position_ids:T7s3x4,past_key_values:DynamicCache(key_cache=#1[T1s3x1x31x96], value_cache=#1[T1s3x1x31x96]))
    [validate_onnx_model] ort inputs=dict(input_ids:A7s3x4,attention_mask:A7s3x35,position_ids:A7s3x4,past_key_values_key_cache_0:A1s3x1x31x96,past_key_values_value_cache_0:A1s3x1x31x96)
    [validate_onnx_model] done (make_feeds)
    [validate_onnx_model] run session...
    [validate_onnx_model] done (run)
    [validate_onnx_model] got=#3[A1s3x4x32000,A1s3x1x35x96,A1s3x1x35x96]
    [validate_onnx_model] discrepancies=abs=8.344650268554688e-07, rel=0.00036102609604184355, n=404160.0
    [validate_model] run onnxruntime fusion for &#39;clip&#39;
    failed in shape inference &lt;class &#39;AssertionError&#39;&gt;
    [validate_model] done &#39;clip&#39; in 0.3054245700004685, saved into &#39;dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir/arnir0_Tiny-LLM-onnx-dynamo-ir.ort.clip.onnx&#39;
    [validate_onnx_model] verify onnx model with providers [&#39;CPUExecutionProvider&#39;]..., flavour=&#39;ortclip&#39;
    [validate_onnx_model] done (ort_session) flavour=&#39;ortclip&#39;
    [validate_onnx_model] -- make_feeds for &#39;inputs&#39;...
    [validate_onnx_model] inputs=dict(input_ids:T7s2x3,attention_mask:T7s2x33,position_ids:T7s2x3,past_key_values:DynamicCache(key_cache=#1[T1s2x1x30x96], value_cache=#1[T1s2x1x30x96]))
    [validate_onnx_model] ort inputs=dict(input_ids:A7s2x3,attention_mask:A7s2x33,position_ids:A7s2x3,past_key_values_key_cache_0:A1s2x1x30x96,past_key_values_value_cache_0:A1s2x1x30x96)
    [validate_onnx_model] done (make_feeds)
    [validate_onnx_model] run session...
    [validate_onnx_model] done (run)
    [validate_onnx_model] got=#3[A1s2x3x32000,A1s2x1x33x96,A1s2x1x33x96]
    [validate_onnx_model] discrepancies=abs=8.344650268554688e-07, rel=0.0004247389736828931, n=204672.0
    [validate_onnx_model] -- make_feeds for &#39;inputs2&#39;...
    [validate_onnx_model] inputs=dict(input_ids:T7s3x4,attention_mask:T7s3x35,position_ids:T7s3x4,past_key_values:DynamicCache(key_cache=#1[T1s3x1x31x96], value_cache=#1[T1s3x1x31x96]))
    [validate_onnx_model] ort inputs=dict(input_ids:A7s3x4,attention_mask:A7s3x35,position_ids:A7s3x4,past_key_values_key_cache_0:A1s3x1x31x96,past_key_values_value_cache_0:A1s3x1x31x96)
    [validate_onnx_model] done (make_feeds)
    [validate_onnx_model] run session...
    [validate_onnx_model] done (run)
    [validate_onnx_model] got=#3[A1s3x4x32000,A1s3x1x35x96,A1s3x1x35x96]
    [validate_onnx_model] discrepancies=abs=8.344650268554688e-07, rel=0.00036102609604184355, n=404160.0
    [validate_model] run onnxruntime fusion for &#39;conformer&#39;
    failed in shape inference &lt;class &#39;AssertionError&#39;&gt;
    [validate_model] done &#39;conformer&#39; in 0.2323375810010475, saved into &#39;dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir/arnir0_Tiny-LLM-onnx-dynamo-ir.ort.conformer.onnx&#39;
    [validate_onnx_model] verify onnx model with providers [&#39;CPUExecutionProvider&#39;]..., flavour=&#39;ortconformer&#39;
    [validate_onnx_model] done (ort_session) flavour=&#39;ortconformer&#39;
    [validate_onnx_model] -- make_feeds for &#39;inputs&#39;...
    [validate_onnx_model] inputs=dict(input_ids:T7s2x3,attention_mask:T7s2x33,position_ids:T7s2x3,past_key_values:DynamicCache(key_cache=#1[T1s2x1x30x96], value_cache=#1[T1s2x1x30x96]))
    [validate_onnx_model] ort inputs=dict(input_ids:A7s2x3,attention_mask:A7s2x33,position_ids:A7s2x3,past_key_values_key_cache_0:A1s2x1x30x96,past_key_values_value_cache_0:A1s2x1x30x96)
    [validate_onnx_model] done (make_feeds)
    [validate_onnx_model] run session...
    [validate_onnx_model] done (run)
    [validate_onnx_model] got=#3[A1s2x3x32000,A1s2x1x33x96,A1s2x1x33x96]
    [validate_onnx_model] discrepancies=abs=8.344650268554688e-07, rel=0.0004247389736828931, n=204672.0
    [validate_onnx_model] -- make_feeds for &#39;inputs2&#39;...
    [validate_onnx_model] inputs=dict(input_ids:T7s3x4,attention_mask:T7s3x35,position_ids:T7s3x4,past_key_values:DynamicCache(key_cache=#1[T1s3x1x31x96], value_cache=#1[T1s3x1x31x96]))
    [validate_onnx_model] ort inputs=dict(input_ids:A7s3x4,attention_mask:A7s3x35,position_ids:A7s3x4,past_key_values_key_cache_0:A1s3x1x31x96,past_key_values_value_cache_0:A1s3x1x31x96)
    [validate_onnx_model] done (make_feeds)
    [validate_onnx_model] run session...
    [validate_onnx_model] done (run)
    [validate_onnx_model] got=#3[A1s3x4x32000,A1s3x1x35x96,A1s3x1x35x96]
    [validate_onnx_model] discrepancies=abs=8.344650268554688e-07, rel=0.00036102609604184355, n=404160.0
    [validate_model] run onnxruntime fusion for &#39;gpt2&#39;
    failed in shape inference &lt;class &#39;AssertionError&#39;&gt;
    [validate_model] done &#39;gpt2&#39; in 0.24990340099975583, saved into &#39;dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir/arnir0_Tiny-LLM-onnx-dynamo-ir.ort.gpt2.onnx&#39;
    [validate_onnx_model] verify onnx model with providers [&#39;CPUExecutionProvider&#39;]..., flavour=&#39;ortgpt2&#39;
    [validate_onnx_model] done (ort_session) flavour=&#39;ortgpt2&#39;
    [validate_onnx_model] -- make_feeds for &#39;inputs&#39;...
    [validate_onnx_model] inputs=dict(input_ids:T7s2x3,attention_mask:T7s2x33,position_ids:T7s2x3,past_key_values:DynamicCache(key_cache=#1[T1s2x1x30x96], value_cache=#1[T1s2x1x30x96]))
    [validate_onnx_model] ort inputs=dict(input_ids:A7s2x3,attention_mask:A7s2x33,position_ids:A7s2x3,past_key_values_key_cache_0:A1s2x1x30x96,past_key_values_value_cache_0:A1s2x1x30x96)
    [validate_onnx_model] done (make_feeds)
    [validate_onnx_model] run session...
    [validate_onnx_model] done (run)
    [validate_onnx_model] got=#3[A1s2x3x32000,A1s2x1x33x96,A1s2x1x33x96]
    [validate_onnx_model] discrepancies=abs=8.344650268554688e-07, rel=0.0004247389736828931, n=204672.0
    [validate_onnx_model] -- make_feeds for &#39;inputs2&#39;...
    [validate_onnx_model] inputs=dict(input_ids:T7s3x4,attention_mask:T7s3x35,position_ids:T7s3x4,past_key_values:DynamicCache(key_cache=#1[T1s3x1x31x96], value_cache=#1[T1s3x1x31x96]))
    [validate_onnx_model] ort inputs=dict(input_ids:A7s3x4,attention_mask:A7s3x35,position_ids:A7s3x4,past_key_values_key_cache_0:A1s3x1x31x96,past_key_values_value_cache_0:A1s3x1x31x96)
    [validate_onnx_model] done (make_feeds)
    [validate_onnx_model] run session...
    [validate_onnx_model] done (run)
    [validate_onnx_model] got=#3[A1s3x4x32000,A1s3x1x35x96,A1s3x1x35x96]
    [validate_onnx_model] discrepancies=abs=8.344650268554688e-07, rel=0.00036102609604184355, n=404160.0
    [validate_model] run onnxruntime fusion for &#39;gpt2_tf&#39;
    failed in shape inference &lt;class &#39;AssertionError&#39;&gt;
    [validate_model] done &#39;gpt2_tf&#39; in 0.30343909399925906, saved into &#39;dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir/arnir0_Tiny-LLM-onnx-dynamo-ir.ort.gpt2_tf.onnx&#39;
    [validate_onnx_model] verify onnx model with providers [&#39;CPUExecutionProvider&#39;]..., flavour=&#39;ortgpt2_tf&#39;
    [validate_onnx_model] done (ort_session) flavour=&#39;ortgpt2_tf&#39;
    [validate_onnx_model] -- make_feeds for &#39;inputs&#39;...
    [validate_onnx_model] inputs=dict(input_ids:T7s2x3,attention_mask:T7s2x33,position_ids:T7s2x3,past_key_values:DynamicCache(key_cache=#1[T1s2x1x30x96], value_cache=#1[T1s2x1x30x96]))
    [validate_onnx_model] ort inputs=dict(input_ids:A7s2x3,attention_mask:A7s2x33,position_ids:A7s2x3,past_key_values_key_cache_0:A1s2x1x30x96,past_key_values_value_cache_0:A1s2x1x30x96)
    [validate_onnx_model] done (make_feeds)
    [validate_onnx_model] run session...
    [validate_onnx_model] done (run)
    [validate_onnx_model] got=#3[A1s2x3x32000,A1s2x1x33x96,A1s2x1x33x96]
    [validate_onnx_model] discrepancies=abs=8.344650268554688e-07, rel=0.0004247389736828931, n=204672.0
    [validate_onnx_model] -- make_feeds for &#39;inputs2&#39;...
    [validate_onnx_model] inputs=dict(input_ids:T7s3x4,attention_mask:T7s3x35,position_ids:T7s3x4,past_key_values:DynamicCache(key_cache=#1[T1s3x1x31x96], value_cache=#1[T1s3x1x31x96]))
    [validate_onnx_model] ort inputs=dict(input_ids:A7s3x4,attention_mask:A7s3x35,position_ids:A7s3x4,past_key_values_key_cache_0:A1s3x1x31x96,past_key_values_value_cache_0:A1s3x1x31x96)
    [validate_onnx_model] done (make_feeds)
    [validate_onnx_model] run session...
    [validate_onnx_model] done (run)
    [validate_onnx_model] got=#3[A1s3x4x32000,A1s3x1x35x96,A1s3x1x35x96]
    [validate_onnx_model] discrepancies=abs=8.344650268554688e-07, rel=0.00036102609604184355, n=404160.0
    [validate_model] run onnxruntime fusion for &#39;gpt_neox&#39;
    failed in shape inference &lt;class &#39;AssertionError&#39;&gt;
    [validate_model] done &#39;gpt_neox&#39; in 0.2219563679991552, saved into &#39;dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir/arnir0_Tiny-LLM-onnx-dynamo-ir.ort.gpt_neox.onnx&#39;
    [validate_onnx_model] verify onnx model with providers [&#39;CPUExecutionProvider&#39;]..., flavour=&#39;ortgpt_neox&#39;
    [validate_onnx_model] done (ort_session) flavour=&#39;ortgpt_neox&#39;
    [validate_onnx_model] -- make_feeds for &#39;inputs&#39;...
    [validate_onnx_model] inputs=dict(input_ids:T7s2x3,attention_mask:T7s2x33,position_ids:T7s2x3,past_key_values:DynamicCache(key_cache=#1[T1s2x1x30x96], value_cache=#1[T1s2x1x30x96]))
    [validate_onnx_model] ort inputs=dict(input_ids:A7s2x3,attention_mask:A7s2x33,position_ids:A7s2x3,past_key_values_key_cache_0:A1s2x1x30x96,past_key_values_value_cache_0:A1s2x1x30x96)
    [validate_onnx_model] done (make_feeds)
    [validate_onnx_model] run session...
    [validate_onnx_model] done (run)
    [validate_onnx_model] got=#3[A1s2x3x32000,A1s2x1x33x96,A1s2x1x33x96]
    [validate_onnx_model] discrepancies=abs=8.344650268554688e-07, rel=0.0004247389736828931, n=204672.0
    [validate_onnx_model] -- make_feeds for &#39;inputs2&#39;...
    [validate_onnx_model] inputs=dict(input_ids:T7s3x4,attention_mask:T7s3x35,position_ids:T7s3x4,past_key_values:DynamicCache(key_cache=#1[T1s3x1x31x96], value_cache=#1[T1s3x1x31x96]))
    [validate_onnx_model] ort inputs=dict(input_ids:A7s3x4,attention_mask:A7s3x35,position_ids:A7s3x4,past_key_values_key_cache_0:A1s3x1x31x96,past_key_values_value_cache_0:A1s3x1x31x96)
    [validate_onnx_model] done (make_feeds)
    [validate_onnx_model] run session...
    [validate_onnx_model] done (run)
    [validate_onnx_model] got=#3[A1s3x4x32000,A1s3x1x35x96,A1s3x1x35x96]
    [validate_onnx_model] discrepancies=abs=8.344650268554688e-07, rel=0.00036102609604184355, n=404160.0
    [validate_model] run onnxruntime fusion for &#39;mmdit&#39;
    
fusion:   0%|          | 0/5 [00:00&lt;?, ?it/s]failed in shape inference &lt;class &#39;AssertionError&#39;&gt;
    
                                             
The optimized model requires LayerNormalization with broadcast support. Please use onnxruntime-gpu&gt;=1.21 for inference.
    
fusion:  20%|##        | 1/5 [00:00&lt;00:00, 11.22it/s]
                                                     
Fused SimplifiedLayerNormalization: 3
    
fusion:  20%|##        | 1/5 [00:00&lt;00:00, 10.93it/s]
                                                     
opset version: 18
    
fusion: 100%|##########| 5/5 [00:00&lt;00:00, 49.89it/s]
fusion: 100%|##########| 5/5 [00:00&lt;00:00, 49.80it/s]
    [validate_model] done &#39;mmdit&#39; in 0.2987801479994232, saved into &#39;dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir/arnir0_Tiny-LLM-onnx-dynamo-ir.ort.mmdit.onnx&#39;
    [validate_onnx_model] verify onnx model with providers [&#39;CPUExecutionProvider&#39;]..., flavour=&#39;ortmmdit&#39;
    [validate_onnx_model] done (ort_session) flavour=&#39;ortmmdit&#39;
    [validate_onnx_model] -- make_feeds for &#39;inputs&#39;...
    [validate_onnx_model] inputs=dict(input_ids:T7s2x3,attention_mask:T7s2x33,position_ids:T7s2x3,past_key_values:DynamicCache(key_cache=#1[T1s2x1x30x96], value_cache=#1[T1s2x1x30x96]))
    [validate_onnx_model] ort inputs=dict(input_ids:A7s2x3,attention_mask:A7s2x33,position_ids:A7s2x3,past_key_values_key_cache_0:A1s2x1x30x96,past_key_values_value_cache_0:A1s2x1x30x96)
    [validate_onnx_model] done (make_feeds)
    [validate_onnx_model] run session...
    [validate_onnx_model] done (run)
    [validate_onnx_model] got=#3[A1s2x3x32000,A1s2x1x33x96,A1s2x1x33x96]
    [validate_onnx_model] discrepancies=abs=8.344650268554688e-07, rel=0.0004247389736828931, n=204672.0
    [validate_onnx_model] -- make_feeds for &#39;inputs2&#39;...
    [validate_onnx_model] inputs=dict(input_ids:T7s3x4,attention_mask:T7s3x35,position_ids:T7s3x4,past_key_values:DynamicCache(key_cache=#1[T1s3x1x31x96], value_cache=#1[T1s3x1x31x96]))
    [validate_onnx_model] ort inputs=dict(input_ids:A7s3x4,attention_mask:A7s3x35,position_ids:A7s3x4,past_key_values_key_cache_0:A1s3x1x31x96,past_key_values_value_cache_0:A1s3x1x31x96)
    [validate_onnx_model] done (make_feeds)
    [validate_onnx_model] run session...
    [validate_onnx_model] done (run)
    [validate_onnx_model] got=#3[A1s3x4x32000,A1s3x1x35x96,A1s3x1x35x96]
    [validate_onnx_model] discrepancies=abs=8.344650268554688e-07, rel=0.00036102609604184355, n=404160.0
    [validate_model] run onnxruntime fusion for &#39;phi&#39;
    [validate_model] done &#39;phi&#39; in 0.022397999000531854, saved into &#39;dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir/arnir0_Tiny-LLM-onnx-dynamo-ir.ort.phi.onnx&#39;
    [validate_onnx_model] missing &#39;dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir/arnir0_Tiny-LLM-onnx-dynamo-ir.ort.phi.onnx&#39;
    [validate_model] run onnxruntime fusion for &#39;sam2&#39;
    
sam2 fusion:   0%|          | 0/12 [00:00&lt;?, ?it/s]failed in shape inference &lt;class &#39;AssertionError&#39;&gt;
    
                                                   
symbolic shape inference disabled or failed.
    
sam2 fusion:  50%|#####     | 6/12 [00:00&lt;00:00, 211.89it/s]
                                                            
opset version: 18
    
sam2 fusion: 100%|##########| 12/12 [00:00&lt;00:00, 354.49it/s]
sam2 fusion: 100%|##########| 12/12 [00:00&lt;00:00, 352.58it/s]
    [validate_model] done &#39;sam2&#39; in 0.14555706299870508, saved into &#39;dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir/arnir0_Tiny-LLM-onnx-dynamo-ir.ort.sam2.onnx&#39;
    [validate_onnx_model] verify onnx model with providers [&#39;CPUExecutionProvider&#39;]..., flavour=&#39;ortsam2&#39;
    [validate_onnx_model] done (ort_session) flavour=&#39;ortsam2&#39;
    [validate_onnx_model] -- make_feeds for &#39;inputs&#39;...
    [validate_onnx_model] inputs=dict(input_ids:T7s2x3,attention_mask:T7s2x33,position_ids:T7s2x3,past_key_values:DynamicCache(key_cache=#1[T1s2x1x30x96], value_cache=#1[T1s2x1x30x96]))
    [validate_onnx_model] ort inputs=dict(input_ids:A7s2x3,attention_mask:A7s2x33,position_ids:A7s2x3,past_key_values_key_cache_0:A1s2x1x30x96,past_key_values_value_cache_0:A1s2x1x30x96)
    [validate_onnx_model] done (make_feeds)
    [validate_onnx_model] run session...
    [validate_onnx_model] done (run)
    [validate_onnx_model] got=#3[A1s2x3x32000,A1s2x1x33x96,A1s2x1x33x96]
    [validate_onnx_model] discrepancies=abs=7.450580596923828e-07, rel=0.00027354017262003796, n=204672.0
    [validate_onnx_model] -- make_feeds for &#39;inputs2&#39;...
    [validate_onnx_model] inputs=dict(input_ids:T7s3x4,attention_mask:T7s3x35,position_ids:T7s3x4,past_key_values:DynamicCache(key_cache=#1[T1s3x1x31x96], value_cache=#1[T1s3x1x31x96]))
    [validate_onnx_model] ort inputs=dict(input_ids:A7s3x4,attention_mask:A7s3x35,position_ids:A7s3x4,past_key_values_key_cache_0:A1s3x1x31x96,past_key_values_value_cache_0:A1s3x1x31x96)
    [validate_onnx_model] done (make_feeds)
    [validate_onnx_model] run session...
    [validate_onnx_model] done (run)
    [validate_onnx_model] got=#3[A1s3x4x32000,A1s3x1x35x96,A1s3x1x35x96]
    [validate_onnx_model] discrepancies=abs=8.344650268554688e-07, rel=0.0003063333051545333, n=404160.0
    [validate_model] run onnxruntime fusion for &#39;swin&#39;
    failed in shape inference &lt;class &#39;AssertionError&#39;&gt;
    [validate_model] done &#39;swin&#39; in 0.15037079700050526, saved into &#39;dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir/arnir0_Tiny-LLM-onnx-dynamo-ir.ort.swin.onnx&#39;
    [validate_onnx_model] verify onnx model with providers [&#39;CPUExecutionProvider&#39;]..., flavour=&#39;ortswin&#39;
    [validate_onnx_model] done (ort_session) flavour=&#39;ortswin&#39;
    [validate_onnx_model] -- make_feeds for &#39;inputs&#39;...
    [validate_onnx_model] inputs=dict(input_ids:T7s2x3,attention_mask:T7s2x33,position_ids:T7s2x3,past_key_values:DynamicCache(key_cache=#1[T1s2x1x30x96], value_cache=#1[T1s2x1x30x96]))
    [validate_onnx_model] ort inputs=dict(input_ids:A7s2x3,attention_mask:A7s2x33,position_ids:A7s2x3,past_key_values_key_cache_0:A1s2x1x30x96,past_key_values_value_cache_0:A1s2x1x30x96)
    [validate_onnx_model] done (make_feeds)
    [validate_onnx_model] run session...
    [validate_onnx_model] done (run)
    [validate_onnx_model] got=#3[A1s2x3x32000,A1s2x1x33x96,A1s2x1x33x96]
    [validate_onnx_model] discrepancies=abs=8.344650268554688e-07, rel=0.0004247389736828931, n=204672.0
    [validate_onnx_model] -- make_feeds for &#39;inputs2&#39;...
    [validate_onnx_model] inputs=dict(input_ids:T7s3x4,attention_mask:T7s3x35,position_ids:T7s3x4,past_key_values:DynamicCache(key_cache=#1[T1s3x1x31x96], value_cache=#1[T1s3x1x31x96]))
    [validate_onnx_model] ort inputs=dict(input_ids:A7s3x4,attention_mask:A7s3x35,position_ids:A7s3x4,past_key_values_key_cache_0:A1s3x1x31x96,past_key_values_value_cache_0:A1s3x1x31x96)
    [validate_onnx_model] done (make_feeds)
    [validate_onnx_model] run session...
    [validate_onnx_model] done (run)
    [validate_onnx_model] got=#3[A1s3x4x32000,A1s3x1x35x96,A1s3x1x35x96]
    [validate_onnx_model] discrepancies=abs=8.344650268554688e-07, rel=0.00036102609604184355, n=404160.0
    [validate_model] run onnxruntime fusion for &#39;t5&#39;
    failed in shape inference &lt;class &#39;AssertionError&#39;&gt;
    [validate_model] done &#39;t5&#39; in 0.1526649110001017, saved into &#39;dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir/arnir0_Tiny-LLM-onnx-dynamo-ir.ort.t5.onnx&#39;
    [validate_onnx_model] verify onnx model with providers [&#39;CPUExecutionProvider&#39;]..., flavour=&#39;ortt5&#39;
    [validate_onnx_model] done (ort_session) flavour=&#39;ortt5&#39;
    [validate_onnx_model] -- make_feeds for &#39;inputs&#39;...
    [validate_onnx_model] inputs=dict(input_ids:T7s2x3,attention_mask:T7s2x33,position_ids:T7s2x3,past_key_values:DynamicCache(key_cache=#1[T1s2x1x30x96], value_cache=#1[T1s2x1x30x96]))
    [validate_onnx_model] ort inputs=dict(input_ids:A7s2x3,attention_mask:A7s2x33,position_ids:A7s2x3,past_key_values_key_cache_0:A1s2x1x30x96,past_key_values_value_cache_0:A1s2x1x30x96)
    [validate_onnx_model] done (make_feeds)
    [validate_onnx_model] run session...
    [validate_onnx_model] done (run)
    [validate_onnx_model] got=#3[A1s2x3x32000,A1s2x1x33x96,A1s2x1x33x96]
    [validate_onnx_model] discrepancies=abs=8.344650268554688e-07, rel=0.0004247389736828931, n=204672.0
    [validate_onnx_model] -- make_feeds for &#39;inputs2&#39;...
    [validate_onnx_model] inputs=dict(input_ids:T7s3x4,attention_mask:T7s3x35,position_ids:T7s3x4,past_key_values:DynamicCache(key_cache=#1[T1s3x1x31x96], value_cache=#1[T1s3x1x31x96]))
    [validate_onnx_model] ort inputs=dict(input_ids:A7s3x4,attention_mask:A7s3x35,position_ids:A7s3x4,past_key_values_key_cache_0:A1s3x1x31x96,past_key_values_value_cache_0:A1s3x1x31x96)
    [validate_onnx_model] done (make_feeds)
    [validate_onnx_model] run session...
    [validate_onnx_model] done (run)
    [validate_onnx_model] got=#3[A1s3x4x32000,A1s3x1x35x96,A1s3x1x35x96]
    [validate_onnx_model] discrepancies=abs=8.344650268554688e-07, rel=0.00036102609604184355, n=404160.0
    [validate_model] run onnxruntime fusion for &#39;tnlr&#39;
    failed in shape inference &lt;class &#39;AssertionError&#39;&gt;
    [validate_model] done &#39;tnlr&#39; in 0.13871947199913848, saved into &#39;dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir/arnir0_Tiny-LLM-onnx-dynamo-ir.ort.tnlr.onnx&#39;
    [validate_onnx_model] verify onnx model with providers [&#39;CPUExecutionProvider&#39;]..., flavour=&#39;orttnlr&#39;
    [validate_onnx_model] done (ort_session) flavour=&#39;orttnlr&#39;
    [validate_onnx_model] -- make_feeds for &#39;inputs&#39;...
    [validate_onnx_model] inputs=dict(input_ids:T7s2x3,attention_mask:T7s2x33,position_ids:T7s2x3,past_key_values:DynamicCache(key_cache=#1[T1s2x1x30x96], value_cache=#1[T1s2x1x30x96]))
    [validate_onnx_model] ort inputs=dict(input_ids:A7s2x3,attention_mask:A7s2x33,position_ids:A7s2x3,past_key_values_key_cache_0:A1s2x1x30x96,past_key_values_value_cache_0:A1s2x1x30x96)
    [validate_onnx_model] done (make_feeds)
    [validate_onnx_model] run session...
    [validate_onnx_model] done (run)
    [validate_onnx_model] got=#3[A1s2x3x32000,A1s2x1x33x96,A1s2x1x33x96]
    [validate_onnx_model] discrepancies=abs=8.344650268554688e-07, rel=0.0004247389736828931, n=204672.0
    [validate_onnx_model] -- make_feeds for &#39;inputs2&#39;...
    [validate_onnx_model] inputs=dict(input_ids:T7s3x4,attention_mask:T7s3x35,position_ids:T7s3x4,past_key_values:DynamicCache(key_cache=#1[T1s3x1x31x96], value_cache=#1[T1s3x1x31x96]))
    [validate_onnx_model] ort inputs=dict(input_ids:A7s3x4,attention_mask:A7s3x35,position_ids:A7s3x4,past_key_values_key_cache_0:A1s3x1x31x96,past_key_values_value_cache_0:A1s3x1x31x96)
    [validate_onnx_model] done (make_feeds)
    [validate_onnx_model] run session...
    [validate_onnx_model] done (run)
    [validate_onnx_model] got=#3[A1s3x4x32000,A1s3x1x35x96,A1s3x1x35x96]
    [validate_onnx_model] discrepancies=abs=8.344650268554688e-07, rel=0.00036102609604184355, n=404160.0
    [validate_model] run onnxruntime fusion for &#39;unet&#39;
    
fusion:   0%|          | 0/18 [00:00&lt;?, ?it/s]failed in shape inference &lt;class &#39;AssertionError&#39;&gt;
    
                                              
symbolic shape inference disabled or failed.
    
fusion:  50%|#####     | 9/18 [00:00&lt;00:00, 278.80it/s]
                                                       
SkipGroupNorm fusion will be skipped since symbolic shape inference disabled or failed.
    
fusion:  67%|######6   | 12/18 [00:00&lt;00:00, 349.53it/s]
                                                        
opset version: 18
    
fusion: 100%|##########| 18/18 [00:00&lt;00:00, 429.29it/s]
fusion: 100%|##########| 18/18 [00:00&lt;00:00, 427.13it/s]
    [validate_model] done &#39;unet&#39; in 0.13775665299908724, saved into &#39;dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir/arnir0_Tiny-LLM-onnx-dynamo-ir.ort.unet.onnx&#39;
    [validate_onnx_model] verify onnx model with providers [&#39;CPUExecutionProvider&#39;]..., flavour=&#39;ortunet&#39;
    [validate_onnx_model] done (ort_session) flavour=&#39;ortunet&#39;
    [validate_onnx_model] -- make_feeds for &#39;inputs&#39;...
    [validate_onnx_model] inputs=dict(input_ids:T7s2x3,attention_mask:T7s2x33,position_ids:T7s2x3,past_key_values:DynamicCache(key_cache=#1[T1s2x1x30x96], value_cache=#1[T1s2x1x30x96]))
    [validate_onnx_model] ort inputs=dict(input_ids:A7s2x3,attention_mask:A7s2x33,position_ids:A7s2x3,past_key_values_key_cache_0:A1s2x1x30x96,past_key_values_value_cache_0:A1s2x1x30x96)
    [validate_onnx_model] done (make_feeds)
    [validate_onnx_model] run session...
    [validate_onnx_model] done (run)
    [validate_onnx_model] got=#3[A1s2x3x32000,A1s2x1x33x96,A1s2x1x33x96]
    [validate_onnx_model] discrepancies=abs=7.450580596923828e-07, rel=0.00027354017262003796, n=204672.0
    [validate_onnx_model] -- make_feeds for &#39;inputs2&#39;...
    [validate_onnx_model] inputs=dict(input_ids:T7s3x4,attention_mask:T7s3x35,position_ids:T7s3x4,past_key_values:DynamicCache(key_cache=#1[T1s3x1x31x96], value_cache=#1[T1s3x1x31x96]))
    [validate_onnx_model] ort inputs=dict(input_ids:A7s3x4,attention_mask:A7s3x35,position_ids:A7s3x4,past_key_values_key_cache_0:A1s3x1x31x96,past_key_values_value_cache_0:A1s3x1x31x96)
    [validate_onnx_model] done (make_feeds)
    [validate_onnx_model] run session...
    [validate_onnx_model] done (run)
    [validate_onnx_model] got=#3[A1s3x4x32000,A1s3x1x35x96,A1s3x1x35x96]
    [validate_onnx_model] discrepancies=abs=8.344650268554688e-07, rel=0.0003063333051545333, n=404160.0
    [validate_model] run onnxruntime fusion for &#39;vae&#39;
    
fusion:   0%|          | 0/18 [00:00&lt;?, ?it/s]failed in shape inference &lt;class &#39;AssertionError&#39;&gt;
    
                                              
symbolic shape inference disabled or failed.
    
fusion:  50%|#####     | 9/18 [00:00&lt;00:00, 228.14it/s]
                                                       
SkipGroupNorm fusion will be skipped since symbolic shape inference disabled or failed.
    
fusion:  67%|######6   | 12/18 [00:00&lt;00:00, 295.22it/s]
                                                        
opset version: 18
    
fusion: 100%|##########| 18/18 [00:00&lt;00:00, 398.81it/s]
fusion: 100%|##########| 18/18 [00:00&lt;00:00, 397.81it/s]
    [validate_model] done &#39;vae&#39; in 0.15772798799844168, saved into &#39;dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir/arnir0_Tiny-LLM-onnx-dynamo-ir.ort.vae.onnx&#39;
    [validate_onnx_model] verify onnx model with providers [&#39;CPUExecutionProvider&#39;]..., flavour=&#39;ortvae&#39;
    [validate_onnx_model] done (ort_session) flavour=&#39;ortvae&#39;
    [validate_onnx_model] -- make_feeds for &#39;inputs&#39;...
    [validate_onnx_model] inputs=dict(input_ids:T7s2x3,attention_mask:T7s2x33,position_ids:T7s2x3,past_key_values:DynamicCache(key_cache=#1[T1s2x1x30x96], value_cache=#1[T1s2x1x30x96]))
    [validate_onnx_model] ort inputs=dict(input_ids:A7s2x3,attention_mask:A7s2x33,position_ids:A7s2x3,past_key_values_key_cache_0:A1s2x1x30x96,past_key_values_value_cache_0:A1s2x1x30x96)
    [validate_onnx_model] done (make_feeds)
    [validate_onnx_model] run session...
    [validate_onnx_model] done (run)
    [validate_onnx_model] got=#3[A1s2x3x32000,A1s2x1x33x96,A1s2x1x33x96]
    [validate_onnx_model] discrepancies=abs=7.450580596923828e-07, rel=0.00027354017262003796, n=204672.0
    [validate_onnx_model] -- make_feeds for &#39;inputs2&#39;...
    [validate_onnx_model] inputs=dict(input_ids:T7s3x4,attention_mask:T7s3x35,position_ids:T7s3x4,past_key_values:DynamicCache(key_cache=#1[T1s3x1x31x96], value_cache=#1[T1s3x1x31x96]))
    [validate_onnx_model] ort inputs=dict(input_ids:A7s3x4,attention_mask:A7s3x35,position_ids:A7s3x4,past_key_values_key_cache_0:A1s3x1x31x96,past_key_values_value_cache_0:A1s3x1x31x96)
    [validate_onnx_model] done (make_feeds)
    [validate_onnx_model] run session...
    [validate_onnx_model] done (run)
    [validate_onnx_model] got=#3[A1s3x4x32000,A1s3x1x35x96,A1s3x1x35x96]
    [validate_onnx_model] discrepancies=abs=8.344650268554688e-07, rel=0.0003063333051545333, n=404160.0
    [validate_model] run onnxruntime fusion for &#39;vit&#39;
    failed in shape inference &lt;class &#39;AssertionError&#39;&gt;
    [validate_model] done &#39;vit&#39; in 0.2868474709994189, saved into &#39;dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir/arnir0_Tiny-LLM-onnx-dynamo-ir.ort.vit.onnx&#39;
    [validate_onnx_model] verify onnx model with providers [&#39;CPUExecutionProvider&#39;]..., flavour=&#39;ortvit&#39;
    [validate_onnx_model] done (ort_session) flavour=&#39;ortvit&#39;
    [validate_onnx_model] -- make_feeds for &#39;inputs&#39;...
    [validate_onnx_model] inputs=dict(input_ids:T7s2x3,attention_mask:T7s2x33,position_ids:T7s2x3,past_key_values:DynamicCache(key_cache=#1[T1s2x1x30x96], value_cache=#1[T1s2x1x30x96]))
    [validate_onnx_model] ort inputs=dict(input_ids:A7s2x3,attention_mask:A7s2x33,position_ids:A7s2x3,past_key_values_key_cache_0:A1s2x1x30x96,past_key_values_value_cache_0:A1s2x1x30x96)
    [validate_onnx_model] done (make_feeds)
    [validate_onnx_model] run session...
    [validate_onnx_model] done (run)
    [validate_onnx_model] got=#3[A1s2x3x32000,A1s2x1x33x96,A1s2x1x33x96]
    [validate_onnx_model] discrepancies=abs=8.344650268554688e-07, rel=0.0004247389736828931, n=204672.0
    [validate_onnx_model] -- make_feeds for &#39;inputs2&#39;...
    [validate_onnx_model] inputs=dict(input_ids:T7s3x4,attention_mask:T7s3x35,position_ids:T7s3x4,past_key_values:DynamicCache(key_cache=#1[T1s3x1x31x96], value_cache=#1[T1s3x1x31x96]))
    [validate_onnx_model] ort inputs=dict(input_ids:A7s3x4,attention_mask:A7s3x35,position_ids:A7s3x4,past_key_values_key_cache_0:A1s3x1x31x96,past_key_values_value_cache_0:A1s3x1x31x96)
    [validate_onnx_model] done (make_feeds)
    [validate_onnx_model] run session...
    [validate_onnx_model] done (run)
    [validate_onnx_model] got=#3[A1s3x4x32000,A1s3x1x35x96,A1s3x1x35x96]
    [validate_onnx_model] discrepancies=abs=8.344650268554688e-07, rel=0.00036102609604184355, n=404160.0
    [validate_model] -- done (final)
    
    -- summary --
    :ERR_onnx_missing_ortphi,FileNotFoundError(&#39;dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir/arnir0_Tiny-LLM-onnx-dynamo-ir.ort.phi.onnx&#39;);
    :ERR_opt_ort_phi,&#39;method&#39; object is not iterable;
    :disc_onnx_ort_run2_abs,8.344650268554688e-07;
    :disc_onnx_ort_run2_abs_ortbart,8.344650268554688e-07;
    :disc_onnx_ort_run2_abs_ortbert,8.344650268554688e-07;
    :disc_onnx_ort_run2_abs_ortbert_keras,8.344650268554688e-07;
    :disc_onnx_ort_run2_abs_ortbert_tf,8.344650268554688e-07;
    :disc_onnx_ort_run2_abs_ortclip,8.344650268554688e-07;
    :disc_onnx_ort_run2_abs_ortconformer,8.344650268554688e-07;
    :disc_onnx_ort_run2_abs_ortgpt2,8.344650268554688e-07;
    :disc_onnx_ort_run2_abs_ortgpt2_tf,8.344650268554688e-07;
    :disc_onnx_ort_run2_abs_ortgpt_neox,8.344650268554688e-07;
    :disc_onnx_ort_run2_abs_ortmmdit,8.344650268554688e-07;
    :disc_onnx_ort_run2_abs_ortsam2,8.344650268554688e-07;
    :disc_onnx_ort_run2_abs_ortswin,8.344650268554688e-07;
    :disc_onnx_ort_run2_abs_ortt5,8.344650268554688e-07;
    :disc_onnx_ort_run2_abs_orttnlr,8.344650268554688e-07;
    :disc_onnx_ort_run2_abs_ortunet,8.344650268554688e-07;
    :disc_onnx_ort_run2_abs_ortvae,8.344650268554688e-07;
    :disc_onnx_ort_run2_abs_ortvit,8.344650268554688e-07;
    :disc_onnx_ort_run2_dnan,0;
    :disc_onnx_ort_run2_dnan_ortbart,0;
    :disc_onnx_ort_run2_dnan_ortbert,0;
    :disc_onnx_ort_run2_dnan_ortbert_keras,0;
    :disc_onnx_ort_run2_dnan_ortbert_tf,0;
    :disc_onnx_ort_run2_dnan_ortclip,0;
    :disc_onnx_ort_run2_dnan_ortconformer,0;
    :disc_onnx_ort_run2_dnan_ortgpt2,0;
    :disc_onnx_ort_run2_dnan_ortgpt2_tf,0;
    :disc_onnx_ort_run2_dnan_ortgpt_neox,0;
    :disc_onnx_ort_run2_dnan_ortmmdit,0;
    :disc_onnx_ort_run2_dnan_ortsam2,0;
    :disc_onnx_ort_run2_dnan_ortswin,0;
    :disc_onnx_ort_run2_dnan_ortt5,0;
    :disc_onnx_ort_run2_dnan_orttnlr,0;
    :disc_onnx_ort_run2_dnan_ortunet,0;
    :disc_onnx_ort_run2_dnan_ortvae,0;
    :disc_onnx_ort_run2_dnan_ortvit,0;
    :disc_onnx_ort_run2_n,404160.0;
    :disc_onnx_ort_run2_n_ortbart,404160.0;
    :disc_onnx_ort_run2_n_ortbert,404160.0;
    :disc_onnx_ort_run2_n_ortbert_keras,404160.0;
    :disc_onnx_ort_run2_n_ortbert_tf,404160.0;
    :disc_onnx_ort_run2_n_ortclip,404160.0;
    :disc_onnx_ort_run2_n_ortconformer,404160.0;
    :disc_onnx_ort_run2_n_ortgpt2,404160.0;
    :disc_onnx_ort_run2_n_ortgpt2_tf,404160.0;
    :disc_onnx_ort_run2_n_ortgpt_neox,404160.0;
    :disc_onnx_ort_run2_n_ortmmdit,404160.0;
    :disc_onnx_ort_run2_n_ortsam2,404160.0;
    :disc_onnx_ort_run2_n_ortswin,404160.0;
    :disc_onnx_ort_run2_n_ortt5,404160.0;
    :disc_onnx_ort_run2_n_orttnlr,404160.0;
    :disc_onnx_ort_run2_n_ortunet,404160.0;
    :disc_onnx_ort_run2_n_ortvae,404160.0;
    :disc_onnx_ort_run2_n_ortvit,404160.0;
    :disc_onnx_ort_run2_rel,0.0003063333051545333;
    :disc_onnx_ort_run2_rel_ortbart,0.00036102609604184355;
    :disc_onnx_ort_run2_rel_ortbert,0.00036102609604184355;
    :disc_onnx_ort_run2_rel_ortbert_keras,0.00036102609604184355;
    :disc_onnx_ort_run2_rel_ortbert_tf,0.00036102609604184355;
    :disc_onnx_ort_run2_rel_ortclip,0.00036102609604184355;
    :disc_onnx_ort_run2_rel_ortconformer,0.00036102609604184355;
    :disc_onnx_ort_run2_rel_ortgpt2,0.00036102609604184355;
    :disc_onnx_ort_run2_rel_ortgpt2_tf,0.00036102609604184355;
    :disc_onnx_ort_run2_rel_ortgpt_neox,0.00036102609604184355;
    :disc_onnx_ort_run2_rel_ortmmdit,0.00036102609604184355;
    :disc_onnx_ort_run2_rel_ortsam2,0.0003063333051545333;
    :disc_onnx_ort_run2_rel_ortswin,0.00036102609604184355;
    :disc_onnx_ort_run2_rel_ortt5,0.00036102609604184355;
    :disc_onnx_ort_run2_rel_orttnlr,0.00036102609604184355;
    :disc_onnx_ort_run2_rel_ortunet,0.0003063333051545333;
    :disc_onnx_ort_run2_rel_ortvae,0.0003063333051545333;
    :disc_onnx_ort_run2_rel_ortvit,0.00036102609604184355;
    :disc_onnx_ort_run2_sum,0.037360749839990604;
    :disc_onnx_ort_run2_sum_ortbart,0.040791127634633995;
    :disc_onnx_ort_run2_sum_ortbert,0.040791127634633995;
    :disc_onnx_ort_run2_sum_ortbert_keras,0.040791127634633995;
    :disc_onnx_ort_run2_sum_ortbert_tf,0.040791127634633995;
    :disc_onnx_ort_run2_sum_ortclip,0.040791127634633995;
    :disc_onnx_ort_run2_sum_ortconformer,0.040791127634633995;
    :disc_onnx_ort_run2_sum_ortgpt2,0.040791127634633995;
    :disc_onnx_ort_run2_sum_ortgpt2_tf,0.040791127634633995;
    :disc_onnx_ort_run2_sum_ortgpt_neox,0.040791127634633995;
    :disc_onnx_ort_run2_sum_ortmmdit,0.040791127634633995;
    :disc_onnx_ort_run2_sum_ortsam2,0.037360749839990604;
    :disc_onnx_ort_run2_sum_ortswin,0.040791127634633995;
    :disc_onnx_ort_run2_sum_ortt5,0.040791127634633995;
    :disc_onnx_ort_run2_sum_orttnlr,0.040791127634633995;
    :disc_onnx_ort_run2_sum_ortunet,0.037360749839990604;
    :disc_onnx_ort_run2_sum_ortvae,0.037360749839990604;
    :disc_onnx_ort_run2_sum_ortvit,0.040791127634633995;
    :disc_onnx_ort_run_abs,7.450580596923828e-07;
    :disc_onnx_ort_run_abs_ortbart,8.344650268554688e-07;
    :disc_onnx_ort_run_abs_ortbert,8.344650268554688e-07;
    :disc_onnx_ort_run_abs_ortbert_keras,8.344650268554688e-07;
    :disc_onnx_ort_run_abs_ortbert_tf,8.344650268554688e-07;
    :disc_onnx_ort_run_abs_ortclip,8.344650268554688e-07;
    :disc_onnx_ort_run_abs_ortconformer,8.344650268554688e-07;
    :disc_onnx_ort_run_abs_ortgpt2,8.344650268554688e-07;
    :disc_onnx_ort_run_abs_ortgpt2_tf,8.344650268554688e-07;
    :disc_onnx_ort_run_abs_ortgpt_neox,8.344650268554688e-07;
    :disc_onnx_ort_run_abs_ortmmdit,8.344650268554688e-07;
    :disc_onnx_ort_run_abs_ortsam2,7.450580596923828e-07;
    :disc_onnx_ort_run_abs_ortswin,8.344650268554688e-07;
    :disc_onnx_ort_run_abs_ortt5,8.344650268554688e-07;
    :disc_onnx_ort_run_abs_orttnlr,8.344650268554688e-07;
    :disc_onnx_ort_run_abs_ortunet,7.450580596923828e-07;
    :disc_onnx_ort_run_abs_ortvae,7.450580596923828e-07;
    :disc_onnx_ort_run_abs_ortvit,8.344650268554688e-07;
    :disc_onnx_ort_run_dnan,0;
    :disc_onnx_ort_run_dnan_ortbart,0;
    :disc_onnx_ort_run_dnan_ortbert,0;
    :disc_onnx_ort_run_dnan_ortbert_keras,0;
    :disc_onnx_ort_run_dnan_ortbert_tf,0;
    :disc_onnx_ort_run_dnan_ortclip,0;
    :disc_onnx_ort_run_dnan_ortconformer,0;
    :disc_onnx_ort_run_dnan_ortgpt2,0;
    :disc_onnx_ort_run_dnan_ortgpt2_tf,0;
    :disc_onnx_ort_run_dnan_ortgpt_neox,0;
    :disc_onnx_ort_run_dnan_ortmmdit,0;
    :disc_onnx_ort_run_dnan_ortsam2,0;
    :disc_onnx_ort_run_dnan_ortswin,0;
    :disc_onnx_ort_run_dnan_ortt5,0;
    :disc_onnx_ort_run_dnan_orttnlr,0;
    :disc_onnx_ort_run_dnan_ortunet,0;
    :disc_onnx_ort_run_dnan_ortvae,0;
    :disc_onnx_ort_run_dnan_ortvit,0;
    :disc_onnx_ort_run_n,204672.0;
    :disc_onnx_ort_run_n_ortbart,204672.0;
    :disc_onnx_ort_run_n_ortbert,204672.0;
    :disc_onnx_ort_run_n_ortbert_keras,204672.0;
    :disc_onnx_ort_run_n_ortbert_tf,204672.0;
    :disc_onnx_ort_run_n_ortclip,204672.0;
    :disc_onnx_ort_run_n_ortconformer,204672.0;
    :disc_onnx_ort_run_n_ortgpt2,204672.0;
    :disc_onnx_ort_run_n_ortgpt2_tf,204672.0;
    :disc_onnx_ort_run_n_ortgpt_neox,204672.0;
    :disc_onnx_ort_run_n_ortmmdit,204672.0;
    :disc_onnx_ort_run_n_ortsam2,204672.0;
    :disc_onnx_ort_run_n_ortswin,204672.0;
    :disc_onnx_ort_run_n_ortt5,204672.0;
    :disc_onnx_ort_run_n_orttnlr,204672.0;
    :disc_onnx_ort_run_n_ortunet,204672.0;
    :disc_onnx_ort_run_n_ortvae,204672.0;
    :disc_onnx_ort_run_n_ortvit,204672.0;
    :disc_onnx_ort_run_rel,0.00027354017262003796;
    :disc_onnx_ort_run_rel_ortbart,0.0004247389736828931;
    :disc_onnx_ort_run_rel_ortbert,0.0004247389736828931;
    :disc_onnx_ort_run_rel_ortbert_keras,0.0004247389736828931;
    :disc_onnx_ort_run_rel_ortbert_tf,0.0004247389736828931;
    :disc_onnx_ort_run_rel_ortclip,0.0004247389736828931;
    :disc_onnx_ort_run_rel_ortconformer,0.0004247389736828931;
    :disc_onnx_ort_run_rel_ortgpt2,0.0004247389736828931;
    :disc_onnx_ort_run_rel_ortgpt2_tf,0.0004247389736828931;
    :disc_onnx_ort_run_rel_ortgpt_neox,0.0004247389736828931;
    :disc_onnx_ort_run_rel_ortmmdit,0.0004247389736828931;
    :disc_onnx_ort_run_rel_ortsam2,0.00027354017262003796;
    :disc_onnx_ort_run_rel_ortswin,0.0004247389736828931;
    :disc_onnx_ort_run_rel_ortt5,0.0004247389736828931;
    :disc_onnx_ort_run_rel_orttnlr,0.0004247389736828931;
    :disc_onnx_ort_run_rel_ortunet,0.00027354017262003796;
    :disc_onnx_ort_run_rel_ortvae,0.00027354017262003796;
    :disc_onnx_ort_run_rel_ortvit,0.0004247389736828931;
    :disc_onnx_ort_run_sum,0.018449280611321228;
    :disc_onnx_ort_run_sum_ortbart,0.01927947461263102;
    :disc_onnx_ort_run_sum_ortbert,0.01927947461263102;
    :disc_onnx_ort_run_sum_ortbert_keras,0.01927947461263102;
    :disc_onnx_ort_run_sum_ortbert_tf,0.01927947461263102;
    :disc_onnx_ort_run_sum_ortclip,0.01927947461263102;
    :disc_onnx_ort_run_sum_ortconformer,0.01927947461263102;
    :disc_onnx_ort_run_sum_ortgpt2,0.01927947461263102;
    :disc_onnx_ort_run_sum_ortgpt2_tf,0.01927947461263102;
    :disc_onnx_ort_run_sum_ortgpt_neox,0.01927947461263102;
    :disc_onnx_ort_run_sum_ortmmdit,0.01927947461263102;
    :disc_onnx_ort_run_sum_ortsam2,0.018449280611321228;
    :disc_onnx_ort_run_sum_ortswin,0.01927947461263102;
    :disc_onnx_ort_run_sum_ortt5,0.01927947461263102;
    :disc_onnx_ort_run_sum_orttnlr,0.01927947461263102;
    :disc_onnx_ort_run_sum_ortunet,0.018449280611321228;
    :disc_onnx_ort_run_sum_ortvae,0.018449280611321228;
    :disc_onnx_ort_run_sum_ortvit,0.01927947461263102;
    :disc_patched_abs,0;
    :disc_patched_dnan,0;
    :disc_patched_n,204672.0;
    :disc_patched_rel,0;
    :disc_patched_sum,0.0;
    :dump_folder,dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir;
    :dump_folder_name,arnir0_Tiny-LLM-onnx-dynamo-ir;
    :export_args,();
    :export_dynamo,True;
    :export_exporter,onnx-dynamo;
    :export_kwargs,dict(input_ids:T7s2x3,attention_mask:T7s2x33,position_ids:T7s2x3,past_key_values:DynamicCache(key_cache=#1[T1s2x1x30x96], value_cache=#1[T1s2x1x30x96]));
    :export_opset,18;
    :export_optimization,ir;
    :model_class,LlamaForCausalLM;
    :model_config,{&#39;vocab_size&#39;:32000,&#39;max_position_embeddings&#39;:1024,&#39;hidden_size&#39;:192,&#39;intermediate_size&#39;:1024,&#39;num_hidden_layers&#39;:1,&#39;num_attention_heads&#39;:2,&#39;num_key_value_heads&#39;:1,&#39;hidden_act&#39;:&#39;silu&#39;,&#39;initializer_range&#39;:0.02,&#39;rms_norm_eps&#39;:1e-05,&#39;pretraining_tp&#39;:1,&#39;use_cache&#39;:True,&#39;rope_theta&#39;:10000.0,&#39;rope_scaling&#39;:None,&#39;attention_bias&#39;:False,&#39;attention_dropout&#39;:0.0,&#39;mlp_bias&#39;:False,&#39;head_dim&#39;:96,&#39;return_dict&#39;:True,&#39;output_hidden_states&#39;:False,&#39;torchscript&#39;:False,&#39;dtype&#39;:&#39;float32&#39;,&#39;pruned_heads&#39;:{},&#39;tie_word_embeddings&#39;:False,&#39;chunk_size_feed_forward&#39;:0,&#39;is_encoder_decoder&#39;:False,&#39;is_decoder&#39;:False,&#39;cross_attention_hidden_size&#39;:None,&#39;add_cross_attention&#39;:False,&#39;tie_encoder_decoder&#39;:False,&#39;architectures&#39;:[&#39;LlamaForCausalLM&#39;],&#39;finetuning_task&#39;:None,&#39;id2label&#39;:{0:&#39;LABEL_0&#39;,1:&#39;LABEL_1&#39;},&#39;label2id&#39;:{&#39;LABEL_0&#39;:0,&#39;LABEL_1&#39;:1},&#39;task_specific_params&#39;:None,&#39;problem_type&#39;:None,&#39;tokenizer_class&#39;:None,&#39;prefix&#39;:None,&#39;bos_token_id&#39;:1,&#39;pad_token_id&#39;:None,&#39;eos_token_id&#39;:2,&#39;sep_token_id&#39;:None,&#39;decoder_start_token_id&#39;:None,&#39;max_length&#39;:20,&#39;min_length&#39;:0,&#39;do_sample&#39;:False,&#39;early_stopping&#39;:False,&#39;num_beams&#39;:1,&#39;num_beam_groups&#39;:1,&#39;diversity_penalty&#39;:0.0,&#39;temperature&#39;:1.0,&#39;top_k&#39;:50,&#39;top_p&#39;:1.0,&#39;typical_p&#39;:1.0,&#39;repetition_penalty&#39;:1.0,&#39;length_penalty&#39;:1.0,&#39;no_repeat_ngram_size&#39;:0,&#39;encoder_no_repeat_ngram_size&#39;:0,&#39;bad_words_ids&#39;:None,&#39;num_return_sequences&#39;:1,&#39;output_scores&#39;:False,&#39;return_dict_in_generate&#39;:False,&#39;forced_bos_token_id&#39;:None,&#39;forced_eos_token_id&#39;:None,&#39;remove_invalid_values&#39;:False,&#39;exponential_decay_length_penalty&#39;:None,&#39;suppress_tokens&#39;:None,&#39;begin_suppress_tokens&#39;:None,&#39;_name_or_path&#39;:&#39;&#39;,&#39;transformers_version&#39;:&#39;4.56.0.dev0&#39;,&#39;model_type&#39;:&#39;llama&#39;,&#39;tf_legacy_loss&#39;:False,&#39;use_bfloat16&#39;:False,&#39;subfolder&#39;:None,&#39;output_attentions&#39;:False};
    :model_config_class,LlamaConfig;
    :model_file,~/github/transformers/src/transformers/models/llama/modeling_llama.py;
    :model_id,arnir0/Tiny-LLM;
    :model_inputs,dict(input_ids:T7s2x3,attention_mask:T7s2x33,position_ids:T7s2x3,past_key_values:DynamicCache(key_cache=#1[T1s2x1x30x96], value_cache=#1[T1s2x1x30x96]));
    :model_inputs_options,;
    :model_module,transformers.models.llama.modeling_llama;
    :model_nweights,12988992;
    :model_shapes,dict(input_ids:{0:Dim(batch),1:DYN(seq_length)},attention_mask:{0:Dim(batch),1:DYN(cache+seq)},position_ids:{0:Dim(batch),1:DYN(cache+seq)},past_key_values:#2[#1[{0:Dim(batch),2:DYN(cache_length)}],#1[{0:Dim(batch),2:DYN(cache_length)}]]);
    :model_size,51955968;
    :model_subfolder,;
    :model_task,text-generation;
    :onnx_filename,dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir/arnir0_Tiny-LLM-onnx-dynamo-ir.onnx;
    :onnx_filename_ortbart,dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir/arnir0_Tiny-LLM-onnx-dynamo-ir.ort.bart.onnx;
    :onnx_filename_ortbert,dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir/arnir0_Tiny-LLM-onnx-dynamo-ir.ort.bert.onnx;
    :onnx_filename_ortbert_keras,dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir/arnir0_Tiny-LLM-onnx-dynamo-ir.ort.bert_keras.onnx;
    :onnx_filename_ortbert_tf,dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir/arnir0_Tiny-LLM-onnx-dynamo-ir.ort.bert_tf.onnx;
    :onnx_filename_ortclip,dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir/arnir0_Tiny-LLM-onnx-dynamo-ir.ort.clip.onnx;
    :onnx_filename_ortconformer,dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir/arnir0_Tiny-LLM-onnx-dynamo-ir.ort.conformer.onnx;
    :onnx_filename_ortgpt2,dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir/arnir0_Tiny-LLM-onnx-dynamo-ir.ort.gpt2.onnx;
    :onnx_filename_ortgpt2_tf,dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir/arnir0_Tiny-LLM-onnx-dynamo-ir.ort.gpt2_tf.onnx;
    :onnx_filename_ortgpt_neox,dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir/arnir0_Tiny-LLM-onnx-dynamo-ir.ort.gpt_neox.onnx;
    :onnx_filename_ortmmdit,dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir/arnir0_Tiny-LLM-onnx-dynamo-ir.ort.mmdit.onnx;
    :onnx_filename_ortsam2,dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir/arnir0_Tiny-LLM-onnx-dynamo-ir.ort.sam2.onnx;
    :onnx_filename_ortswin,dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir/arnir0_Tiny-LLM-onnx-dynamo-ir.ort.swin.onnx;
    :onnx_filename_ortt5,dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir/arnir0_Tiny-LLM-onnx-dynamo-ir.ort.t5.onnx;
    :onnx_filename_orttnlr,dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir/arnir0_Tiny-LLM-onnx-dynamo-ir.ort.tnlr.onnx;
    :onnx_filename_ortunet,dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir/arnir0_Tiny-LLM-onnx-dynamo-ir.ort.unet.onnx;
    :onnx_filename_ortvae,dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir/arnir0_Tiny-LLM-onnx-dynamo-ir.ort.vae.onnx;
    :onnx_filename_ortvit,dump_models/arnir0_Tiny-LLM-onnx-dynamo-ir/arnir0_Tiny-LLM-onnx-dynamo-ir.ort.vit.onnx;
    :onnx_ort_inputs,dict(input_ids:A7s2x3,attention_mask:A7s2x33,position_ids:A7s2x3,past_key_values_key_cache_0:A1s2x1x30x96,past_key_values_value_cache_0:A1s2x1x30x96);
    :onnx_ort_inputs2,dict(input_ids:A7s3x4,attention_mask:A7s3x35,position_ids:A7s3x4,past_key_values_key_cache_0:A1s3x1x31x96,past_key_values_value_cache_0:A1s3x1x31x96);
    :onnx_ort_inputs2_ortbart,dict(input_ids:A7s3x4,attention_mask:A7s3x35,position_ids:A7s3x4,past_key_values_key_cache_0:A1s3x1x31x96,past_key_values_value_cache_0:A1s3x1x31x96);
    :onnx_ort_inputs2_ortbert,dict(input_ids:A7s3x4,attention_mask:A7s3x35,position_ids:A7s3x4,past_key_values_key_cache_0:A1s3x1x31x96,past_key_values_value_cache_0:A1s3x1x31x96);
    :onnx_ort_inputs2_ortbert_keras,dict(input_ids:A7s3x4,attention_mask:A7s3x35,position_ids:A7s3x4,past_key_values_key_cache_0:A1s3x1x31x96,past_key_values_value_cache_0:A1s3x1x31x96);
    :onnx_ort_inputs2_ortbert_tf,dict(input_ids:A7s3x4,attention_mask:A7s3x35,position_ids:A7s3x4,past_key_values_key_cache_0:A1s3x1x31x96,past_key_values_value_cache_0:A1s3x1x31x96);
    :onnx_ort_inputs2_ortclip,dict(input_ids:A7s3x4,attention_mask:A7s3x35,position_ids:A7s3x4,past_key_values_key_cache_0:A1s3x1x31x96,past_key_values_value_cache_0:A1s3x1x31x96);
    :onnx_ort_inputs2_ortconformer,dict(input_ids:A7s3x4,attention_mask:A7s3x35,position_ids:A7s3x4,past_key_values_key_cache_0:A1s3x1x31x96,past_key_values_value_cache_0:A1s3x1x31x96);
    :onnx_ort_inputs2_ortgpt2,dict(input_ids:A7s3x4,attention_mask:A7s3x35,position_ids:A7s3x4,past_key_values_key_cache_0:A1s3x1x31x96,past_key_values_value_cache_0:A1s3x1x31x96);
    :onnx_ort_inputs2_ortgpt2_tf,dict(input_ids:A7s3x4,attention_mask:A7s3x35,position_ids:A7s3x4,past_key_values_key_cache_0:A1s3x1x31x96,past_key_values_value_cache_0:A1s3x1x31x96);
    :onnx_ort_inputs2_ortgpt_neox,dict(input_ids:A7s3x4,attention_mask:A7s3x35,position_ids:A7s3x4,past_key_values_key_cache_0:A1s3x1x31x96,past_key_values_value_cache_0:A1s3x1x31x96);
    :onnx_ort_inputs2_ortmmdit,dict(input_ids:A7s3x4,attention_mask:A7s3x35,position_ids:A7s3x4,past_key_values_key_cache_0:A1s3x1x31x96,past_key_values_value_cache_0:A1s3x1x31x96);
    :onnx_ort_inputs2_ortsam2,dict(input_ids:A7s3x4,attention_mask:A7s3x35,position_ids:A7s3x4,past_key_values_key_cache_0:A1s3x1x31x96,past_key_values_value_cache_0:A1s3x1x31x96);
    :onnx_ort_inputs2_ortswin,dict(input_ids:A7s3x4,attention_mask:A7s3x35,position_ids:A7s3x4,past_key_values_key_cache_0:A1s3x1x31x96,past_key_values_value_cache_0:A1s3x1x31x96);
    :onnx_ort_inputs2_ortt5,dict(input_ids:A7s3x4,attention_mask:A7s3x35,position_ids:A7s3x4,past_key_values_key_cache_0:A1s3x1x31x96,past_key_values_value_cache_0:A1s3x1x31x96);
    :onnx_ort_inputs2_orttnlr,dict(input_ids:A7s3x4,attention_mask:A7s3x35,position_ids:A7s3x4,past_key_values_key_cache_0:A1s3x1x31x96,past_key_values_value_cache_0:A1s3x1x31x96);
    :onnx_ort_inputs2_ortunet,dict(input_ids:A7s3x4,attention_mask:A7s3x35,position_ids:A7s3x4,past_key_values_key_cache_0:A1s3x1x31x96,past_key_values_value_cache_0:A1s3x1x31x96);
    :onnx_ort_inputs2_ortvae,dict(input_ids:A7s3x4,attention_mask:A7s3x35,position_ids:A7s3x4,past_key_values_key_cache_0:A1s3x1x31x96,past_key_values_value_cache_0:A1s3x1x31x96);
    :onnx_ort_inputs2_ortvit,dict(input_ids:A7s3x4,attention_mask:A7s3x35,position_ids:A7s3x4,past_key_values_key_cache_0:A1s3x1x31x96,past_key_values_value_cache_0:A1s3x1x31x96);
    :onnx_ort_inputs_ortbart,dict(input_ids:A7s2x3,attention_mask:A7s2x33,position_ids:A7s2x3,past_key_values_key_cache_0:A1s2x1x30x96,past_key_values_value_cache_0:A1s2x1x30x96);
    :onnx_ort_inputs_ortbert,dict(input_ids:A7s2x3,attention_mask:A7s2x33,position_ids:A7s2x3,past_key_values_key_cache_0:A1s2x1x30x96,past_key_values_value_cache_0:A1s2x1x30x96);
    :onnx_ort_inputs_ortbert_keras,dict(input_ids:A7s2x3,attention_mask:A7s2x33,position_ids:A7s2x3,past_key_values_key_cache_0:A1s2x1x30x96,past_key_values_value_cache_0:A1s2x1x30x96);
    :onnx_ort_inputs_ortbert_tf,dict(input_ids:A7s2x3,attention_mask:A7s2x33,position_ids:A7s2x3,past_key_values_key_cache_0:A1s2x1x30x96,past_key_values_value_cache_0:A1s2x1x30x96);
    :onnx_ort_inputs_ortclip,dict(input_ids:A7s2x3,attention_mask:A7s2x33,position_ids:A7s2x3,past_key_values_key_cache_0:A1s2x1x30x96,past_key_values_value_cache_0:A1s2x1x30x96);
    :onnx_ort_inputs_ortconformer,dict(input_ids:A7s2x3,attention_mask:A7s2x33,position_ids:A7s2x3,past_key_values_key_cache_0:A1s2x1x30x96,past_key_values_value_cache_0:A1s2x1x30x96);
    :onnx_ort_inputs_ortgpt2,dict(input_ids:A7s2x3,attention_mask:A7s2x33,position_ids:A7s2x3,past_key_values_key_cache_0:A1s2x1x30x96,past_key_values_value_cache_0:A1s2x1x30x96);
    :onnx_ort_inputs_ortgpt2_tf,dict(input_ids:A7s2x3,attention_mask:A7s2x33,position_ids:A7s2x3,past_key_values_key_cache_0:A1s2x1x30x96,past_key_values_value_cache_0:A1s2x1x30x96);
    :onnx_ort_inputs_ortgpt_neox,dict(input_ids:A7s2x3,attention_mask:A7s2x33,position_ids:A7s2x3,past_key_values_key_cache_0:A1s2x1x30x96,past_key_values_value_cache_0:A1s2x1x30x96);
    :onnx_ort_inputs_ortmmdit,dict(input_ids:A7s2x3,attention_mask:A7s2x33,position_ids:A7s2x3,past_key_values_key_cache_0:A1s2x1x30x96,past_key_values_value_cache_0:A1s2x1x30x96);
    :onnx_ort_inputs_ortsam2,dict(input_ids:A7s2x3,attention_mask:A7s2x33,position_ids:A7s2x3,past_key_values_key_cache_0:A1s2x1x30x96,past_key_values_value_cache_0:A1s2x1x30x96);
    :onnx_ort_inputs_ortswin,dict(input_ids:A7s2x3,attention_mask:A7s2x33,position_ids:A7s2x3,past_key_values_key_cache_0:A1s2x1x30x96,past_key_values_value_cache_0:A1s2x1x30x96);
    :onnx_ort_inputs_ortt5,dict(input_ids:A7s2x3,attention_mask:A7s2x33,position_ids:A7s2x3,past_key_values_key_cache_0:A1s2x1x30x96,past_key_values_value_cache_0:A1s2x1x30x96);
    :onnx_ort_inputs_orttnlr,dict(input_ids:A7s2x3,attention_mask:A7s2x33,position_ids:A7s2x3,past_key_values_key_cache_0:A1s2x1x30x96,past_key_values_value_cache_0:A1s2x1x30x96);
    :onnx_ort_inputs_ortunet,dict(input_ids:A7s2x3,attention_mask:A7s2x33,position_ids:A7s2x3,past_key_values_key_cache_0:A1s2x1x30x96,past_key_values_value_cache_0:A1s2x1x30x96);
    :onnx_ort_inputs_ortvae,dict(input_ids:A7s2x3,attention_mask:A7s2x33,position_ids:A7s2x3,past_key_values_key_cache_0:A1s2x1x30x96,past_key_values_value_cache_0:A1s2x1x30x96);
    :onnx_ort_inputs_ortvit,dict(input_ids:A7s2x3,attention_mask:A7s2x33,position_ids:A7s2x3,past_key_values_key_cache_0:A1s2x1x30x96,past_key_values_value_cache_0:A1s2x1x30x96);
    :onnx_size,204345;
    :onnx_size_ortbart,173811;
    :onnx_size_ortbert,173811;
    :onnx_size_ortbert_keras,173868;
    :onnx_size_ortbert_tf,173840;
    :onnx_size_ortclip,173811;
    :onnx_size_ortconformer,173857;
    :onnx_size_ortgpt2,173811;
    :onnx_size_ortgpt2_tf,173838;
    :onnx_size_ortgpt_neox,173847;
    :onnx_size_ortmmdit,173820;
    :onnx_size_ortsam2,205125;
    :onnx_size_ortswin,173811;
    :onnx_size_ortt5,173793;
    :onnx_size_orttnlr,173811;
    :onnx_size_ortunet,205125;
    :onnx_size_ortvae,205116;
    :onnx_size_ortvit,173802;
    :opt_ort_bart_delta_node,-18;
    :opt_ort_bart_duration,0.09899726600087888;
    :opt_ort_bart_duration_save,0.06224587200085807;
    :opt_ort_bart_n_nodes1,134;
    :opt_ort_bart_n_nodes2,116;
    :opt_ort_bert_delta_node,-18;
    :opt_ort_bert_duration,0.11427381799876457;
    :opt_ort_bert_duration_save,0.06705120300102863;
    :opt_ort_bert_keras_delta_node,-18;
    :opt_ort_bert_keras_duration,0.07921109400012938;
    :opt_ort_bert_keras_duration_save,0.08345457399991574;
    :opt_ort_bert_keras_n_nodes1,134;
    :opt_ort_bert_keras_n_nodes2,116;
    :opt_ort_bert_n_nodes1,134;
    :opt_ort_bert_n_nodes2,116;
    :opt_ort_bert_tf_delta_node,-18;
    :opt_ort_bert_tf_duration,0.08564825300163648;
    :opt_ort_bert_tf_duration_save,0.05464550899887399;
    :opt_ort_bert_tf_n_nodes1,134;
    :opt_ort_bert_tf_n_nodes2,116;
    :opt_ort_clip_delta_node,-18;
    :opt_ort_clip_duration,0.11919729299916071;
    :opt_ort_clip_duration_save,0.07214596300036646;
    :opt_ort_clip_n_nodes1,134;
    :opt_ort_clip_n_nodes2,116;
    :opt_ort_conformer_delta_node,-18;
    :opt_ort_conformer_duration,0.08376180199957162;
    :opt_ort_conformer_duration_save,0.06496977399910975;
    :opt_ort_conformer_n_nodes1,134;
    :opt_ort_conformer_n_nodes2,116;
    :opt_ort_gpt2_delta_node,-18;
    :opt_ort_gpt2_duration,0.11758374000055483;
    :opt_ort_gpt2_duration_save,0.06024150299890607;
    :opt_ort_gpt2_n_nodes1,134;
    :opt_ort_gpt2_n_nodes2,116;
    :opt_ort_gpt2_tf_delta_node,-18;
    :opt_ort_gpt2_tf_duration,0.1268735680005193;
    :opt_ort_gpt2_tf_duration_save,0.07472950100054732;
    :opt_ort_gpt2_tf_n_nodes1,134;
    :opt_ort_gpt2_tf_n_nodes2,116;
    :opt_ort_gpt_neox_delta_node,-18;
    :opt_ort_gpt_neox_duration,0.09460733400010213;
    :opt_ort_gpt_neox_duration_save,0.060930384999664966;
    :opt_ort_gpt_neox_n_nodes1,134;
    :opt_ort_gpt_neox_n_nodes2,116;
    :opt_ort_mmdit_delta_node,-18;
    :opt_ort_mmdit_duration,0.12561429100060195;
    :opt_ort_mmdit_duration_save,0.057056035000641714;
    :opt_ort_mmdit_n_nodes1,134;
    :opt_ort_mmdit_n_nodes2,116;
    :opt_ort_phi_duration,0.000299528999676113;
    :opt_ort_sam2_delta_node,0;
    :opt_ort_sam2_duration,0.04566408000027877;
    :opt_ort_sam2_duration_save,0.07459294200089062;
    :opt_ort_sam2_n_nodes1,134;
    :opt_ort_sam2_n_nodes2,134;
    :opt_ort_swin_delta_node,-18;
    :opt_ort_swin_duration,0.049752971999623696;
    :opt_ort_swin_duration_save,0.08567862199925003;
    :opt_ort_swin_n_nodes1,134;
    :opt_ort_swin_n_nodes2,116;
    :opt_ort_t5_delta_node,-18;
    :opt_ort_t5_duration,0.04692302599869436;
    :opt_ort_t5_duration_save,0.07905687899983604;
    :opt_ort_t5_n_nodes1,134;
    :opt_ort_t5_n_nodes2,116;
    :opt_ort_tnlr_delta_node,-18;
    :opt_ort_tnlr_duration,0.03601181400154019;
    :opt_ort_tnlr_duration_save,0.08779363000030571;
    :opt_ort_tnlr_n_nodes1,134;
    :opt_ort_tnlr_n_nodes2,116;
    :opt_ort_unet_delta_node,0;
    :opt_ort_unet_duration,0.051656841998919845;
    :opt_ort_unet_duration_save,0.07134037400101079;
    :opt_ort_unet_n_nodes1,134;
    :opt_ort_unet_n_nodes2,134;
    :opt_ort_vae_delta_node,0;
    :opt_ort_vae_duration,0.0537087539996719;
    :opt_ort_vae_duration_save,0.08020333400054369;
    :opt_ort_vae_n_nodes1,134;
    :opt_ort_vae_n_nodes2,134;
    :opt_ort_vit_delta_node,-18;
    :opt_ort_vit_duration,0.1162545749994024;
    :opt_ort_vit_duration_save,0.0759659430004831;
    :opt_ort_vit_n_nodes1,134;
    :opt_ort_vit_n_nodes2,116;
    :run_expected,CausalLMOutputWithPast(logits:T1s2x3x32000,past_key_values:DynamicCache(key_cache=#1[T1s2x1x33x96], value_cache=#1[T1s2x1x33x96]));
    :run_expected2,CausalLMOutputWithPast(logits:T1s3x4x32000,past_key_values:DynamicCache(key_cache=#1[T1s3x1x35x96], value_cache=#1[T1s3x1x35x96]));
    :run_feeds_inputs,dict(input_ids:A7s2x3,attention_mask:A7s2x33,position_ids:A7s2x3,past_key_values_key_cache_0:A1s2x1x30x96,past_key_values_value_cache_0:A1s2x1x30x96);
    :run_feeds_inputs2,dict(input_ids:A7s3x4,attention_mask:A7s3x35,position_ids:A7s3x4,past_key_values_key_cache_0:A1s3x1x31x96,past_key_values_value_cache_0:A1s3x1x31x96);
    :run_output_inputs,#3[A1s2x3x32000,A1s2x1x33x96,A1s2x1x33x96];
    :run_output_inputs2,#3[A1s3x4x32000,A1s3x1x35x96,A1s3x1x35x96];
    :time_create,0.13043155599916645;
    :time_create_onnx_ort,0.03687587800050096;
    :time_create_onnx_ort_ortbart,0.029774127000564476;
    :time_create_onnx_ort_ortbert,0.03293975900123769;
    :time_create_onnx_ort_ortbert_keras,0.030709955000929767;
    :time_create_onnx_ort_ortbert_tf,0.05855054600033327;
    :time_create_onnx_ort_ortclip,0.039513326999440324;
    :time_create_onnx_ort_ortconformer,0.04696819599848823;
    :time_create_onnx_ort_ortgpt2,0.03718896899954416;
    :time_create_onnx_ort_ortgpt2_tf,0.0383205829984945;
    :time_create_onnx_ort_ortgpt_neox,0.06802177899953676;
    :time_create_onnx_ort_ortmmdit,0.050380042999677244;
    :time_create_onnx_ort_ortsam2,0.054810667999845464;
    :time_create_onnx_ort_ortswin,0.06564367600003607;
    :time_create_onnx_ort_ortt5,0.03528055199967639;
    :time_create_onnx_ort_orttnlr,0.02894865099915478;
    :time_create_onnx_ort_ortunet,0.030569902999559417;
    :time_create_onnx_ort_ortvae,0.06063975399956689;
    :time_create_onnx_ort_ortvit,0.033138623999548145;
    :time_export_onnx,6.9328553219984315;
    :time_export_onnx_opt_ir,0.053772010000102455;
    :time_onnx_save,0.26968359500096994;
    :time_ortfusion_ortbart,0.20830882399968687;
    :time_ortfusion_ortbert,0.26940306600045005;
    :time_ortfusion_ortbert_keras,0.27563871500024106;
    :time_ortfusion_ortbert_tf,0.2212624780004262;
    :time_ortfusion_ortclip,0.3054245700004685;
    :time_ortfusion_ortconformer,0.2323375810010475;
    :time_ortfusion_ortgpt2,0.24990340099975583;
    :time_ortfusion_ortgpt2_tf,0.30343909399925906;
    :time_ortfusion_ortgpt_neox,0.2219563679991552;
    :time_ortfusion_ortmmdit,0.2987801479994232;
    :time_ortfusion_ortphi,0.022397999000531854;
    :time_ortfusion_ortsam2,0.14555706299870508;
    :time_ortfusion_ortswin,0.15037079700050526;
    :time_ortfusion_ortt5,0.1526649110001017;
    :time_ortfusion_orttnlr,0.13871947199913848;
    :time_ortfusion_ortunet,0.13775665299908724;
    :time_ortfusion_ortvae,0.15772798799844168;
    :time_ortfusion_ortvit,0.2868474709994189;
    :time_run,0.015697179000198958;
    :time_run2,0.025493414999800734;
    :time_run_onnx_ort,0.0019326829988131067;
    :time_run_onnx_ort2,0.0021378870005719364;
    :time_run_onnx_ort2_ortbart,0.009951333000572049;
    :time_run_onnx_ort2_ortbert,0.002560373999585863;
    :time_run_onnx_ort2_ortbert_keras,0.0027044340004067635;
    :time_run_onnx_ort2_ortbert_tf,0.0034478590005164733;
    :time_run_onnx_ort2_ortclip,0.002298619001521729;
    :time_run_onnx_ort2_ortconformer,0.00813833200118097;
    :time_run_onnx_ort2_ortgpt2,0.002527812001062557;
    :time_run_onnx_ort2_ortgpt2_tf,0.0021786209999845596;
    :time_run_onnx_ort2_ortgpt_neox,0.002349907001189422;
    :time_run_onnx_ort2_ortmmdit,0.005631908999930602;
    :time_run_onnx_ort2_ortsam2,0.005076429000837379;
    :time_run_onnx_ort2_ortswin,0.015455577000466292;
    :time_run_onnx_ort2_ortt5,0.002844454000296537;
    :time_run_onnx_ort2_orttnlr,0.003999888000180363;
    :time_run_onnx_ort2_ortunet,0.004999580998628517;
    :time_run_onnx_ort2_ortvae,0.004442308001671336;
    :time_run_onnx_ort2_ortvit,0.0030644479993497953;
    :time_run_onnx_ort_ortbart,0.003036991000044509;
    :time_run_onnx_ort_ortbert,0.0024984219999169;
    :time_run_onnx_ort_ortbert_keras,0.001992705998418387;
    :time_run_onnx_ort_ortbert_tf,0.0028049930006091017;
    :time_run_onnx_ort_ortclip,0.0025185779995808844;
    :time_run_onnx_ort_ortconformer,0.0034222040012537036;
    :time_run_onnx_ort_ortgpt2,0.002344845999687095;
    :time_run_onnx_ort_ortgpt2_tf,0.0018748250004136935;
    :time_run_onnx_ort_ortgpt_neox,0.003187795000485494;
    :time_run_onnx_ort_ortmmdit,0.011193055999683565;
    :time_run_onnx_ort_ortsam2,0.005388905001382227;
    :time_run_onnx_ort_ortswin,0.010517578000872163;
    :time_run_onnx_ort_ortt5,0.003151558999888948;
    :time_run_onnx_ort_orttnlr,0.0029032330003246898;
    :time_run_onnx_ort_ortunet,0.005167968000023393;
    :time_run_onnx_ort_ortvae,0.002564708998761489;
    :time_run_onnx_ort_ortvit,0.00192625800082169;
    :time_run_patched,0.01793804299995827;
    :version_date,2025-08-27T17:08:34;
    :version_device,;
    :version_do_run,True;
    :version_drop_inputs,[];
    :version_dtype,;
    :version_dump_folder,dump_models;
    :version_exporter,onnx-dynamo;
    :version_inputs2,1;
    :version_model_id,arnir0/Tiny-LLM;
    :version_numpy,2.3.2;
    :version_onnx,1.20.0;
    :version_onnx_diagnostic,0.7.7;
    :version_onnx_ir,0.1.8;
    :version_onnxruntime,1.23.0;
    :version_onnxscript,0.3.0.dev20250301;
    :version_opset,18;
    :version_optimization,ir;
    :version_ortbart_hidden_size,192;
    :version_ortbart_num_attention_heads,2;
    :version_ortbert_hidden_size,192;
    :version_ortbert_keras_hidden_size,192;
    :version_ortbert_keras_num_attention_heads,2;
    :version_ortbert_num_attention_heads,2;
    :version_ortbert_tf_hidden_size,192;
    :version_ortbert_tf_num_attention_heads,2;
    :version_ortclip_hidden_size,192;
    :version_ortclip_num_attention_heads,2;
    :version_ortconformer_hidden_size,192;
    :version_ortconformer_num_attention_heads,2;
    :version_ortfusiontype,ALL;
    :version_ortgpt2_hidden_size,192;
    :version_ortgpt2_num_attention_heads,2;
    :version_ortgpt2_tf_hidden_size,192;
    :version_ortgpt2_tf_num_attention_heads,2;
    :version_ortgpt_neox_hidden_size,192;
    :version_ortgpt_neox_num_attention_heads,2;
    :version_ortmmdit_hidden_size,192;
    :version_ortmmdit_num_attention_heads,2;
    :version_ortphi_hidden_size,192;
    :version_ortphi_num_attention_heads,2;
    :version_ortsam2_hidden_size,192;
    :version_ortsam2_num_attention_heads,2;
    :version_ortswin_hidden_size,192;
    :version_ortswin_num_attention_heads,2;
    :version_ortt5_hidden_size,192;
    :version_ortt5_num_attention_heads,2;
    :version_orttnlr_hidden_size,192;
    :version_orttnlr_num_attention_heads,2;
    :version_ortunet_hidden_size,192;
    :version_ortunet_num_attention_heads,2;
    :version_ortvae_hidden_size,192;
    :version_ortvae_num_attention_heads,2;
    :version_ortvit_hidden_size,192;
    :version_ortvit_num_attention_heads,2;
    :version_patch,True;
    :version_patch_kwargs,{&#39;patch_transformers&#39;:True,&#39;patch_diffusers&#39;:True,&#39;patch&#39;:True};
    :version_quiet,False;
    :version_rewrite,True;
    :version_runtime,onnxruntime;
    :version_same_as_pretrained,False;
    :version_scipy,1.16.1;
    :version_stop_if_static,0;
    :version_torch,2.9.0.dev20250820+cu126;
    :version_transformers,4.56.0.dev0;
    :version_use_pretrained,False;
</pre></div>
</div>
</section>
<section id="sdpa-or-eager-implementation-or-use-a-staticcache">
<h2>Sdpa or Eager implementation or Use a StaticCache<a class="headerlink" href="#sdpa-or-eager-implementation-or-use-a-staticcache" title="Link to this heading">¶</a></h2>
<p>Add <code class="docutils literal notranslate"><span class="pre">--mop</span> <span class="pre">cache_implementation=static</span> <span class="pre">--iop</span> <span class="pre">cls_cache=StaticCache</span></code> to use a StaticCache instead of a DynamicCache (default).
Add <code class="docutils literal notranslate"><span class="pre">--mop</span> <span class="pre">attn_implementation=eager</span></code> to explicitly select eager implementation for attention.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>-m<span class="w"> </span>onnx_diagnostic<span class="w"> </span>validate<span class="w"> </span><span class="se">\</span>
<span class="w">            </span>-m<span class="w"> </span>google/gemma-2b<span class="w"> </span><span class="se">\</span>
<span class="w">            </span>--run<span class="w"> </span><span class="se">\</span>
<span class="w">            </span>-v<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">            </span>--export<span class="w"> </span>custom<span class="w"> </span><span class="se">\</span>
<span class="w">            </span>-o<span class="w"> </span>dump_test<span class="w"> </span><span class="se">\</span>
<span class="w">            </span>--dtype<span class="w"> </span>float16<span class="w"> </span><span class="se">\</span>
<span class="w">            </span>--device<span class="w"> </span>cpu<span class="w"> </span><span class="se">\</span>
<span class="w">            </span>--patch<span class="w"> </span><span class="se">\</span>
<span class="w">            </span>--no-quiet<span class="w"> </span><span class="se">\</span>
<span class="w">            </span>--opt<span class="w"> </span>default<span class="w"> </span><span class="se">\</span>
<span class="w">            </span>--rewrite<span class="w"> </span><span class="se">\</span>
<span class="w">            </span>--mop<span class="w"> </span><span class="nv">attn_implementation</span><span class="o">=</span>eager<span class="w"> </span><span class="se">\</span>
<span class="w">            </span>--mop<span class="w"> </span><span class="nv">cache_implementation</span><span class="o">=</span>static<span class="w"> </span><span class="se">\</span>
<span class="w">            </span>--iop<span class="w"> </span><span class="nv">cls_cache</span><span class="o">=</span>StaticCache
</pre></div>
</div>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="../auto_examples/index.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Examples Gallery</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="config.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">-m onnx_diagnostic config … prints the config for a model id</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2025
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">-m onnx_diagnostic validate … validate a model id</a><ul>
<li><a class="reference internal" href="#description">Description</a></li>
<li><a class="reference internal" href="#get-the-list-of-supported-tasks">Get the list of supported tasks</a></li>
<li><a class="reference internal" href="#get-the-default-inputs-for-a-specific-task">Get the default inputs for a specific task</a></li>
<li><a class="reference internal" href="#validate-dummy-inputs-for-a-model">Validate dummy inputs for a model</a></li>
<li><a class="reference internal" href="#validate-and-export-a-model">Validate and export a model</a></li>
<li><a class="reference internal" href="#validate-onnx-discrepancies">Validate ONNX discrepancies</a></li>
<li><a class="reference internal" href="#run-onnxruntime-fusions">Run onnxruntime fusions</a></li>
<li><a class="reference internal" href="#sdpa-or-eager-implementation-or-use-a-staticcache">Sdpa or Eager implementation or Use a StaticCache</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../_static/documentation_options.js?v=53394b71"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/furo.js?v=46bd48cc"></script>
    </body>
</html>