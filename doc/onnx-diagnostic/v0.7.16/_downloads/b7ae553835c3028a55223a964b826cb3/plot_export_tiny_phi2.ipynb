{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Export microsoft/phi-2\n\nThis function exports an smaller untrained model with the same architecture.\nIt is faster than the pretrained model.\nWhen this works, the untrained model can be replaced by the trained one.\n\n:epkg:`microsoft/phi-2` is not a big model but still quite big\nwhen it comes to write unittests. Function\n:func:`onnx_diagnostic.torch_models.hghub.get_untrained_model_with_inputs`\ncan be used to create a reduced untrained version of a model coming from\n:epkg:`HuggingFace`. It downloads the configuration from the website\nbut creates a dummy model with 1 or 2 hidden layers in order to reduce\nthe size and get a fast execution. The goal is usually to test\nthe export or to compare performance. The relevance does not matter.\n\n## Create the dummy model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import copy\nimport pprint\nimport warnings\nimport torch\nimport onnxruntime\nfrom onnx_diagnostic import doc\nfrom onnx_diagnostic.helpers import max_diff, string_diff, string_type\nfrom onnx_diagnostic.helpers.cache_helper import is_cache_dynamic_registered\nfrom onnx_diagnostic.helpers.rt_helper import make_feeds\nfrom onnx_diagnostic.torch_export_patches import torch_export_patches\nfrom onnx_diagnostic.torch_export_patches.patch_inputs import use_dyn_not_str\nfrom onnx_diagnostic.torch_models.hghub import (\n    get_untrained_model_with_inputs,\n)\n\nwarnings.simplefilter(\"ignore\")\n\n# another tiny id: arnir0/Tiny-LLM\ndata = get_untrained_model_with_inputs(\"microsoft/phi-2\")\nuntrained_model, inputs, dynamic_shapes, config, size, n_weights = (\n    data[\"model\"],\n    data[\"inputs\"],\n    data[\"dynamic_shapes\"],\n    data[\"configuration\"],\n    data[\"size\"],\n    data[\"n_weights\"],\n)\n\nprint(f\"model {size / 2**20:1.1f} Mb with {n_weights // 1000} thousands of parameters.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The original model has 2.7 billion parameters. It was divided by more than 10.\nHowever, it can still be used with\n``get_untrained_model_with_inputs(\"microsoft/phi-2\", same_as_pretrained=True)``.\nLet's see the configuration.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Inputs:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(string_type(inputs, with_shape=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With min/max values.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(string_type(inputs, with_shape=True, with_min_max=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And the dynamic shapes\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pprint.pprint(dynamic_shapes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We execute the model to produce expected outputs.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "expected = untrained_model(**copy.deepcopy(inputs))\nprint(f\"expected: {string_type(expected, with_shape=True, with_min_max=True)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export to fx.Graph\n\n:func:`torch.export.export` is the first step before converting\na model into ONNX. The inputs are duplicated (with ``copy.deepcopy``)\nbecause the model may modify them inline (a cache for example).\nShapes may not match on the second call with the modified inputs.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "with torch_export_patches(patch_transformers=True):\n\n    # Two unnecessary steps but useful in case of an error\n    # We check the cache is registered.\n    assert is_cache_dynamic_registered()\n\n    # We check there is no discrepancies when the cache is applied.\n    d = max_diff(expected, untrained_model(**copy.deepcopy(inputs)))\n    assert (\n        d[\"abs\"] < 1e-5\n    ), f\"The model with patches produces different outputs: {string_diff(d)}\"\n\n    # Then we export: the only import line in this section.\n    ep = torch.export.export(\n        untrained_model,\n        (),\n        kwargs=copy.deepcopy(inputs),\n        dynamic_shapes=use_dyn_not_str(dynamic_shapes),\n        strict=False,  # mandatory for torch==2.6\n    )\n\n    # We check the exported program produces the same results as well.\n    # This step is again unnecessary.\n    d = max_diff(expected, ep.module()(**copy.deepcopy(inputs)))\n    assert d[\"abs\"] < 1e-5, f\"The exported model different outputs: {string_diff(d)}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export to ONNX\n\nThe export works. We can export to ONNX now\n:func:`torch.onnx.export`.\nPatches are still needed because the export\napplies :meth:`torch.export.ExportedProgram.run_decompositions`\nmay export local pieces of the model again.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "with torch_export_patches(patch_transformers=True):\n    epo = torch.onnx.export(\n        ep, (), kwargs=copy.deepcopy(inputs), dynamic_shapes=dynamic_shapes\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can save it.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "epo.save(\"plot_export_tiny_phi2.onnx\", external_data=True)\n\n# Or directly get the :class:`onnx.ModelProto`.\nonx = epo.model_proto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Discrepancies\n\nThe we check the conversion to ONNX.\nLet's make sure the ONNX model produces the same outputs.\nIt takes flatten inputs.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "feeds = make_feeds(onx, copy.deepcopy(inputs), use_numpy=True, copy=True)\n\nprint(f\"torch inputs: {string_type(inputs)}\")\nprint(f\"onxrt inputs: {string_type(feeds)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then create a :class:`onnxruntime.InferenceSession`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sess = onnxruntime.InferenceSession(\n    onx.SerializeToString(), providers=[\"CPUExecutionProvider\"]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's run.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "got = sess.run(None, feeds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And finally the discrepancies.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "diff = max_diff(expected, got, flatten=True)\nprint(f\"onnx discrepancies: {string_diff(diff)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It looks good.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "doc.plot_legend(\"export\\nuntrained smaller\\nmicrosoft/phi-2\", \"torch.onnx.export\", \"orange\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Possible Issues\n\n### Unknown task\n\nFunction :func:`onnx_diagnostic.torch_models.hghub.get_untrained_model_with_inputs`\nis unabl to guess a task associated to the model.\nA different set of dummy inputs is defined for every task.\nThe user needs to explicitly give that information to the function.\nTasks are the same as the one defined by\n[HuggingFace/models](https://huggingface.co/models).\n\n### Inputs are incorrect\n\nExample `l-plot-tiny-llm-export` explains\nhow to retrieve that information. If you cannot guess the dynamic\nshapes - a cache can be tricky sometimes, follow example\n`l-plot-export-with-args-kwargs`.\n\n### DynamicCache or any other cache cannot be exported\n\nThat's the role of :func:`onnx_diagnostic.torch_export_patches.torch_export_patches`.\nIt registers the necessary information into pytorch to make the export\nwork with these. Its need should slowly disappear until :epkg:`transformers`\nincludes the serialization functions.\n\n### Control Flow\n\nEvery mixture of models goes through a control flow (a test).\nIt also happens when a cache is truncated. The code of the model\nneeds to be changed. See example `l-plot-export-cond`.\nLoops are not supported yet.\n\n### Issue with dynamic shapes\n\nExample `l-plot-dynamic-shapes-python-int` gives one reason\nthis process may fail but that's not the only one.\nExample `l-plot-export-locale-issue` gives an way to locate\nthe cause but that does not cover all the possible causes.\nRaising an issue on github would be the recommended option\nuntil it is fixed.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}