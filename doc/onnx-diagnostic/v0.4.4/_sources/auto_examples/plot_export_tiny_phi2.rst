
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_export_tiny_phi2.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_plot_export_tiny_phi2.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_export_tiny_phi2.py:


.. _l-plot-export_tiny_phi2:

Untrained microsoft/phi-2
=========================

:epkg:`microsoft/phi-2` is not a big models but still quite big
when it comes to write unittest. Function
:func:`onnx_diagnostic.torch_models.hghub.get_untrained_model_with_inputs`
can be used to create a reduced untrained version of a model coming from
:epkg:`HuggingFace`. It downloads the configuration from the website
but creates a dummy model with 1 or 2 hidden layers in order to reduce
the size and get a fast execution. The goal is usually to test
the export or to compare performance. The relevance does not matter.

Create the dummy model
++++++++++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 19-49

.. code-block:: Python


    import copy
    import pprint
    import warnings
    import torch
    import onnxruntime
    from onnx_diagnostic import doc
    from onnx_diagnostic.helpers import max_diff, string_diff, string_type
    from onnx_diagnostic.helpers.cache_helper import is_cache_dynamic_registered
    from onnx_diagnostic.helpers.rt_helper import make_feeds
    from onnx_diagnostic.torch_export_patches import torch_export_patches
    from onnx_diagnostic.torch_export_patches.patch_inputs import use_dyn_not_str
    from onnx_diagnostic.torch_models.hghub import (
        get_untrained_model_with_inputs,
    )

    warnings.simplefilter("ignore")

    # another tiny id: arnir0/Tiny-LLM
    data = get_untrained_model_with_inputs("microsoft/phi-2")
    untrained_model, inputs, dynamic_shapes, config, size, n_weights = (
        data["model"],
        data["inputs"],
        data["dynamic_shapes"],
        data["configuration"],
        data["size"],
        data["n_weights"],
    )

    print(f"model {size / 2**20:1.3f} Mb with {n_weights // 1000} mille parameters.")




.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    model 432.330 Mb with 113332 mille parameters.




.. GENERATED FROM PYTHON SOURCE LINES 50-52

The original model has 2.7 billion parameters. It was divided by more than 10.
Let's see the configuration.

.. GENERATED FROM PYTHON SOURCE LINES 52-55

.. code-block:: Python

    print(config)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    PhiConfig {
      "_attn_implementation_autoset": true,
      "architectures": [
        "PhiForCausalLM"
      ],
      "attention_dropout": 0.0,
      "bos_token_id": 50256,
      "embd_pdrop": 0.0,
      "eos_token_id": 50256,
      "head_dim": 80,
      "hidden_act": "gelu_new",
      "hidden_size": 768,
      "initializer_range": 0.02,
      "intermediate_size": 6144,
      "layer_norm_eps": 1e-05,
      "max_position_embeddings": 2048,
      "model_type": "phi",
      "num_attention_heads": 32,
      "num_hidden_layers": 2,
      "num_key_value_heads": 32,
      "partial_rotary_factor": 0.4,
      "qk_layernorm": false,
      "resid_pdrop": 0.1,
      "rope_scaling": null,
      "rope_theta": 10000.0,
      "tie_word_embeddings": false,
      "torch_dtype": "float16",
      "transformers_version": "4.52.0.dev0",
      "use_cache": true,
      "vocab_size": 51200
    }





.. GENERATED FROM PYTHON SOURCE LINES 56-57

Inputs:

.. GENERATED FROM PYTHON SOURCE LINES 57-60

.. code-block:: Python


    print(string_type(inputs, with_shape=True))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    dict(input_ids:T7s2x3,attention_mask:T7s2x33,position_ids:T7s2x3,past_key_values:DynamicCache(key_cache=#2[T1s2x32x30x80,T1s2x32x30x80], value_cache=#2[T1s2x32x30x80,T1s2x32x30x80]))




.. GENERATED FROM PYTHON SOURCE LINES 61-62

With min/max values.

.. GENERATED FROM PYTHON SOURCE LINES 62-64

.. code-block:: Python

    print(string_type(inputs, with_shape=True, with_min_max=True))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    dict(input_ids:T7s2x3[4819,40948:A25144.0],attention_mask:T7s2x33[1,1:A1.0],position_ids:T7s2x3[30,32:A31.0],past_key_values:DynamicCache(key_cache=#2[T1s2x32x30x80[-4.3719329833984375,4.214013576507568:A-0.0034454566145567817],T1s2x32x30x80[-4.354637145996094,4.101736545562744:A0.00048715437119101424]], value_cache=#2[T1s2x32x30x80[-4.58950662612915,4.415571689605713:A-0.0011134230908122892],T1s2x32x30x80[-4.650355815887451,4.465639591217041:A-0.002472064368367359]]))




.. GENERATED FROM PYTHON SOURCE LINES 65-66

And the dynamic shapes

.. GENERATED FROM PYTHON SOURCE LINES 66-68

.. code-block:: Python

    pprint.pprint(dynamic_shapes)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    {'attention_mask': {0: Dim('batch', min=1, max=1024), 1: 'cache+seq'},
     'input_ids': {0: Dim('batch', min=1, max=1024), 1: 'seq_length'},
     'past_key_values': [[{0: Dim('batch', min=1, max=1024), 2: 'cache_length'},
                          {0: Dim('batch', min=1, max=1024), 2: 'cache_length'}],
                         [{0: Dim('batch', min=1, max=1024), 2: 'cache_length'},
                          {0: Dim('batch', min=1, max=1024), 2: 'cache_length'}]],
     'position_ids': {0: Dim('batch', min=1, max=1024), 1: 'cache+seq'}}




.. GENERATED FROM PYTHON SOURCE LINES 69-70

We execute the model to produce expected outputs.

.. GENERATED FROM PYTHON SOURCE LINES 70-74

.. code-block:: Python

    expected = untrained_model(**copy.deepcopy(inputs))
    print(f"expected: {string_type(expected, with_shape=True, with_min_max=True)}")






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    expected: CausalLMOutputWithPast(logits:T1s2x3x51200[-2.479748487472534,2.470858573913574:A-0.0015045551299974135],past_key_values:DynamicCache(key_cache=#2[T1s2x32x33x80[-4.3719329833984375,4.214013576507568:A-0.0032215617116300786],T1s2x32x33x80[-4.354637145996094,4.101736545562744:A0.00041614267573929735]], value_cache=#2[T1s2x32x33x80[-4.58950662612915,4.415571689605713:A-0.0012271389566834553],T1s2x32x33x80[-4.650355815887451,4.465639591217041:A-0.002322949412059211]]))




.. GENERATED FROM PYTHON SOURCE LINES 75-77

Export
++++++

.. GENERATED FROM PYTHON SOURCE LINES 77-104

.. code-block:: Python



    with torch_export_patches(patch_transformers=True) as modificator:

        # Unnecessary steps but useful in case of an error
        # We check the cache is registered.
        assert is_cache_dynamic_registered()

        # We check there is no discrepancies when the cache is applied.
        d = max_diff(expected, untrained_model(**copy.deepcopy(inputs)))
        assert (
            d["abs"] < 1e-5
        ), f"The model with patches produces different outputs: {string_diff(d)}"

        # Then we export.
        ep = torch.export.export(
            untrained_model,
            (),
            kwargs=modificator(copy.deepcopy(inputs)),
            dynamic_shapes=use_dyn_not_str(dynamic_shapes),
            strict=False,  # mandatory for torch==2.6
        )

        # We check the exported program produces the same results as well.
        d = max_diff(expected, ep.module()(**copy.deepcopy(inputs)))
        assert d["abs"] < 1e-5, f"The exported model different outputs: {string_diff(d)}"








.. GENERATED FROM PYTHON SOURCE LINES 105-112

Export to ONNX
++++++++++++++

The export works. We can export to ONNX now.
Patches are still needed because the export
applies :meth:`torch.export.ExportedProgram.run_decompositions`
may export local pieces of the model again.

.. GENERATED FROM PYTHON SOURCE LINES 112-118

.. code-block:: Python


    with torch_export_patches(patch_transformers=True):
        epo = torch.onnx.export(
            ep, (), kwargs=copy.deepcopy(inputs), dynamic_shapes=dynamic_shapes, dynamo=True
        )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [torch.onnx] Run decomposition...
    [torch.onnx] Run decomposition... ✅
    [torch.onnx] Translate the graph into ONNX...
    [torch.onnx] Translate the graph into ONNX... ✅
    Applied 53 of general pattern rewrite rules.




.. GENERATED FROM PYTHON SOURCE LINES 119-120

We can save it.

.. GENERATED FROM PYTHON SOURCE LINES 120-126

.. code-block:: Python

    epo.save("plot_export_tiny_phi2.onnx", external_data=True)

    # Or directly get the :class:`onnx.ModelProto`.
    onx = epo.model_proto









.. GENERATED FROM PYTHON SOURCE LINES 127-133

Discrepancies
+++++++++++++

The we check the conversion to ONNX.
Let's make sure the ONNX model produces the same outputs.
It takes flatten inputs.

.. GENERATED FROM PYTHON SOURCE LINES 133-139

.. code-block:: Python


    feeds = make_feeds(onx, copy.deepcopy(inputs), use_numpy=True, copy=True)

    print(f"torch inputs: {string_type(inputs)}")
    print(f"onxrt inputs: {string_type(feeds)}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    torch inputs: dict(input_ids:T7r2,attention_mask:T7r2,position_ids:T7r2,past_key_values:DynamicCache(key_cache=#2[T1r4,T1r4], value_cache=#2[T1r4,T1r4]))
    onxrt inputs: dict(input_ids:A7r2,attention_mask:A7r2,position_ids:A7r2,past_key_values_key_cache_0:A1r4,past_key_values_key_cache_1:A1r4,past_key_values_value_cache_0:A1r4,past_key_values_value_cache_1:A1r4)




.. GENERATED FROM PYTHON SOURCE LINES 140-141

We then create a :class:`onnxruntime.InferenceSession`.

.. GENERATED FROM PYTHON SOURCE LINES 141-146

.. code-block:: Python


    sess = onnxruntime.InferenceSession(
        onx.SerializeToString(), providers=["CPUExecutionProvider"]
    )








.. GENERATED FROM PYTHON SOURCE LINES 147-148

Let's run.

.. GENERATED FROM PYTHON SOURCE LINES 148-150

.. code-block:: Python

    got = sess.run(None, feeds)








.. GENERATED FROM PYTHON SOURCE LINES 151-152

And finally the discrepancies.

.. GENERATED FROM PYTHON SOURCE LINES 152-156

.. code-block:: Python


    diff = max_diff(expected, got, flatten=True)
    print(f"onnx discrepancies: {string_diff(diff)}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    onnx discrepancies: abs=1.8477439880371094e-06, rel=0.0011736251685325742, n=983040.0




.. GENERATED FROM PYTHON SOURCE LINES 157-158

It looks good.

.. GENERATED FROM PYTHON SOURCE LINES 160-161

.. code-block:: Python

    doc.plot_legend("untrained smaller\nmicrosoft/phi-2", "torch.onnx.export", "orange")



.. image-sg:: /auto_examples/images/sphx_glr_plot_export_tiny_phi2_001.png
   :alt: plot export tiny phi2
   :srcset: /auto_examples/images/sphx_glr_plot_export_tiny_phi2_001.png
   :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 11.252 seconds)


.. _sphx_glr_download_auto_examples_plot_export_tiny_phi2.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_export_tiny_phi2.ipynb <plot_export_tiny_phi2.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_export_tiny_phi2.py <plot_export_tiny_phi2.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_export_tiny_phi2.zip <plot_export_tiny_phi2.zip>`


.. include:: plot_export_tiny_phi2.recommendations


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
