:orphan:

Technical Details
=================



.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="torch.export.export makes strict assumption on dynamic shapes to the generic case. Let&#x27;s consider two tensors with only one dimension. x * y allows four configurations:">

.. only:: html

  .. image:: /auto_technical/images/thumb/sphx_glr_plot_broadcast_export_issue_thumb.png
    :alt:

  :doc:`/auto_technical/plot_broadcast_export_issue`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Dynamic Shapes and Broadcasting</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Method generate generates the model answer for a given prompt. Let&#x27;s implement our own to understand better how it works and then apply it to an ONNX model.">

.. only:: html

  .. image:: /auto_technical/images/thumb/sphx_glr_plot_generate_thumb.png
    :alt:

  :doc:`/auto_technical/plot_generate`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">From a LLM to processing a prompt</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Order of computation matters. 1 + 1e-20 - 1 != 1 - 1 + 1e-20 if the precision of the computation is taken into account. What an operator Gemm in onnxruntime, the most simple way to represent a linear neural layer.">

.. only:: html

  .. image:: /auto_technical/images/thumb/sphx_glr_plot_gemm_or_matmul_add_thumb.png
    :alt:

  :doc:`/auto_technical/plot_gemm_or_matmul_add`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Gemm or Matmul + Add</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example applies what was illustrated l-plot-parallelized-reduction, reduction operations are sensitive to parallelization.">

.. only:: html

  .. image:: /auto_technical/images/thumb/sphx_glr_plot_layer_norm_discrepancies_thumb.png
    :alt:

  :doc:`/auto_technical/plot_layer_norm_discrepancies`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">LayerNormalization implementation cannot be exchanged</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="A reduction is a frequent operation with neural networks. It appears in layer normalization, softmax... Because of the float precision, the result of the computation changes based on the order of the elements. The following examples show the variation based on different hypothesis on the vector distribution. We consider a vector X = (x_1, ..., x_n). It computes the average:">

.. only:: html

  .. image:: /auto_technical/images/thumb/sphx_glr_plot_parallelized_reduction_thumb.png
    :alt:

  :doc:`/auto_technical/plot_parallelized_reduction`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Reproducible Parallelized Reduction is difficult</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>


.. toctree::
   :hidden:

   /auto_technical/plot_broadcast_export_issue
   /auto_technical/plot_generate
   /auto_technical/plot_gemm_or_matmul_add
   /auto_technical/plot_layer_norm_discrepancies
   /auto_technical/plot_parallelized_reduction


.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-gallery

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download all examples in Python source code: auto_technical_python.zip </auto_technical/auto_technical_python.zip>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download all examples in Jupyter notebooks: auto_technical_jupyter.zip </auto_technical/auto_technical_jupyter.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
