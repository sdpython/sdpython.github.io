
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_dump_intermediate_results.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_plot_dump_intermediate_results.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_dump_intermediate_results.py:


.. _l-plot-intermediate-results:

Dumps intermediate results of a torch model
===========================================

Looking for discrepancies is quickly annoying. Discrepancies
come from two results obtained with the same models
implemented in two different ways, :epkg:`pytorch` and :epkg:`onnx`.
Models are big so where do they come from? That's the
unavoidable question. Unless there is an obvious reason,
the only way is to compare intermediate outputs alon the computation.
The first step into that direction is to dump the intermediate results
coming from :epkg:`pytorch`.
We use :func:`onnx_diagnostic.helpers.torch_helper.steal_forward` for that.

A simple LLM Model
++++++++++++++++++

See :func:`onnx_diagnostic.helpers.torch_helper.dummy_llm`
for its definition. It is mostly used for unit test or example.

.. GENERATED FROM PYTHON SOURCE LINES 24-41

.. code-block:: Python


    import onnx
    import torch
    from onnx_array_api.plotting.graphviz_helper import plot_dot
    from onnx_diagnostic import doc
    from onnx_diagnostic.helpers import string_type
    from onnx_diagnostic.helpers.torch_helper import dummy_llm
    from onnx_diagnostic.helpers.mini_onnx_builder import create_input_tensors_from_onnx_model
    from onnx_diagnostic.helpers.torch_helper import steal_forward


    model, inputs, ds = dummy_llm(dynamic_shapes=True)

    print(f"type(model)={type(model)}")
    print(f"inputs={string_type(inputs, with_shape=True)}")
    print(f"ds={string_type(ds, with_shape=True)}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    type(model)=<class 'onnx_diagnostic.helpers.torch_helper.dummy_llm.<locals>.LLM'>
    inputs=(T7s2x30,)
    ds=dict(input_ids:{0:Dim(batch),1:Dim(length)})




.. GENERATED FROM PYTHON SOURCE LINES 42-43

It contains the following submodules.

.. GENERATED FROM PYTHON SOURCE LINES 43-47

.. code-block:: Python


    for name, mod in model.named_modules():
        print(f"- {name}: {type(mod)}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    - : <class 'onnx_diagnostic.helpers.torch_helper.dummy_llm.<locals>.LLM'>
    - embedding: <class 'onnx_diagnostic.helpers.torch_helper.dummy_llm.<locals>.Embedding'>
    - embedding.embedding: <class 'torch.nn.modules.sparse.Embedding'>
    - embedding.pe: <class 'torch.nn.modules.sparse.Embedding'>
    - decoder: <class 'onnx_diagnostic.helpers.torch_helper.dummy_llm.<locals>.DecoderLayer'>
    - decoder.attention: <class 'onnx_diagnostic.helpers.torch_helper.dummy_llm.<locals>.MultiAttentionBlock'>
    - decoder.attention.attention: <class 'torch.nn.modules.container.ModuleList'>
    - decoder.attention.attention.0: <class 'onnx_diagnostic.helpers.torch_helper.dummy_llm.<locals>.AttentionBlock'>
    - decoder.attention.attention.0.query: <class 'torch.nn.modules.linear.Linear'>
    - decoder.attention.attention.0.key: <class 'torch.nn.modules.linear.Linear'>
    - decoder.attention.attention.0.value: <class 'torch.nn.modules.linear.Linear'>
    - decoder.attention.attention.1: <class 'onnx_diagnostic.helpers.torch_helper.dummy_llm.<locals>.AttentionBlock'>
    - decoder.attention.attention.1.query: <class 'torch.nn.modules.linear.Linear'>
    - decoder.attention.attention.1.key: <class 'torch.nn.modules.linear.Linear'>
    - decoder.attention.attention.1.value: <class 'torch.nn.modules.linear.Linear'>
    - decoder.attention.linear: <class 'torch.nn.modules.linear.Linear'>
    - decoder.feed_forward: <class 'onnx_diagnostic.helpers.torch_helper.dummy_llm.<locals>.FeedForward'>
    - decoder.feed_forward.linear_1: <class 'torch.nn.modules.linear.Linear'>
    - decoder.feed_forward.relu: <class 'torch.nn.modules.activation.ReLU'>
    - decoder.feed_forward.linear_2: <class 'torch.nn.modules.linear.Linear'>
    - decoder.norm_1: <class 'torch.nn.modules.normalization.LayerNorm'>
    - decoder.norm_2: <class 'torch.nn.modules.normalization.LayerNorm'>




.. GENERATED FROM PYTHON SOURCE LINES 48-54

Steal and dump the output of submodules
+++++++++++++++++++++++++++++++++++++++

The following context spies on the intermediate results
for the following module and submodules. It stores
in one onnx file all the input/output for those.

.. GENERATED FROM PYTHON SOURCE LINES 54-71

.. code-block:: Python


    with steal_forward(
        [
            ("model", model),
            ("model.decoder", model.decoder),
            ("model.decoder.attention", model.decoder.attention),
            ("model.decoder.feed_forward", model.decoder.feed_forward),
            ("model.decoder.norm_1", model.decoder.norm_1),
            ("model.decoder.norm_2", model.decoder.norm_2),
        ],
        dump_file="plot_dump_intermediate_results.inputs.onnx",
        verbose=1,
        storage_limit=2**28,
    ):
        model(*inputs)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    +model -- stolen forward for class LLM -- iteration 0
      <- args=(T7s2x30,) --- kwargs={}
    +model.decoder -- stolen forward for class DecoderLayer -- iteration 0
      <- args=(T1s2x30x16,) --- kwargs={}
    +model.decoder.norm_1 -- stolen forward for class LayerNorm -- iteration 0
      <- args=(T1s2x30x16,) --- kwargs={}
      -> T1s2x30x16
    -model.decoder.norm_1.
    -- stores key=('model.decoder.norm_1', 0), size 3Kb -- T1s2x30x16
    +model.decoder.attention -- stolen forward for class MultiAttentionBlock -- iteration 0
      <- args=(T1s2x30x16,) --- kwargs={}
      -> T1s2x30x16
    -model.decoder.attention.
    -- stores key=('model.decoder.attention', 0), size 3Kb -- T1s2x30x16
    +model.decoder.norm_2 -- stolen forward for class LayerNorm -- iteration 0
      <- args=(T1s2x30x16,) --- kwargs={}
      -> T1s2x30x16
    -model.decoder.norm_2.
    -- stores key=('model.decoder.norm_2', 0), size 3Kb -- T1s2x30x16
    +model.decoder.feed_forward -- stolen forward for class FeedForward -- iteration 0
      <- args=(T1s2x30x16,) --- kwargs={}
      -> T1s2x30x16
    -model.decoder.feed_forward.
    -- stores key=('model.decoder.feed_forward', 0), size 3Kb -- T1s2x30x16
      -> T1s2x30x16
    -model.decoder.
    -- stores key=('model.decoder', 0), size 3Kb -- T1s2x30x16
      -> T1s2x30x16
    -model.
    -- stores key=('model', 0), size 3Kb -- T1s2x30x16
    -- gather stored 12 objects, size=0 Mb
    -- dumps stored objects
    -- done dump stored objects




.. GENERATED FROM PYTHON SOURCE LINES 72-81

Restores saved inputs/outputs
+++++++++++++++++++++++++++++

All the intermediate tensors were saved in one unique onnx model,
every tensor is stored in a constant node.
The model can be run with any runtime to restore the inputs
and function :func:`create_input_tensors_from_onnx_model
<onnx_diagnostic.helpers.mini_onnx_builder.create_input_tensors_from_onnx_model>`
can restore their names.

.. GENERATED FROM PYTHON SOURCE LINES 81-88

.. code-block:: Python


    saved_tensors = create_input_tensors_from_onnx_model(
        "plot_dump_intermediate_results.inputs.onnx"
    )
    for k, v in saved_tensors.items():
        print(f"{k} -- {string_type(v, with_shape=True)}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    ('model', 0, 'I') -- ((T7s2x30,),{})
    ('model.decoder', 0, 'I') -- ((T1s2x30x16,),{})
    ('model.decoder.norm_1', 0, 'I') -- ((T1s2x30x16,),{})
    ('model.decoder.norm_1', 0, 'O') -- T1s2x30x16
    ('model.decoder.attention', 0, 'I') -- ((T1s2x30x16,),{})
    ('model.decoder.attention', 0, 'O') -- T1s2x30x16
    ('model.decoder.norm_2', 0, 'I') -- ((T1s2x30x16,),{})
    ('model.decoder.norm_2', 0, 'O') -- T1s2x30x16
    ('model.decoder.feed_forward', 0, 'I') -- ((T1s2x30x16,),{})
    ('model.decoder.feed_forward', 0, 'O') -- T1s2x30x16
    ('model.decoder', 0, 'O') -- T1s2x30x16
    ('model', 0, 'O') -- T1s2x30x16




.. GENERATED FROM PYTHON SOURCE LINES 89-113

Let's explained the naming convention.

::

   ('model.decoder.norm_2', 0, 'I') -- ((T1s2x30x16,),{})
               |            |   |
               |            |   +--> input, the format is args, kwargs
               |            |
               |            +--> iteration, 0 means the first time the execution
               |                 went through that module
               |                 it is possible to call multiple times,
               |                 the model to store more
               |
               +--> the name given to function steal_forward

The same goes for output except ``'I'`` is replaced by ``'O'``.

::

   ('model.decoder.norm_2', 0, 'O') -- T1s2x30x16

This trick can be used to compare intermediate results coming
from pytorch to any other implementation of the same model
as long as it is possible to map the stored inputs/outputs.

.. GENERATED FROM PYTHON SOURCE LINES 115-121

Conversion to ONNX
++++++++++++++++++

The difficult point is to be able to map the saved intermediate
results to intermediate results in ONNX.
Let's create the ONNX model.

.. GENERATED FROM PYTHON SOURCE LINES 121-126

.. code-block:: Python


    epo = torch.onnx.export(model, inputs, dynamic_shapes=ds, dynamo=True)
    epo.optimize()
    epo.save("plot_dump_intermediate_results.onnx")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [torch.onnx] Obtain model graph for `LLM([...]` with `torch.export.export(..., strict=False)`...
    [torch.onnx] Obtain model graph for `LLM([...]` with `torch.export.export(..., strict=False)`... âœ…
    [torch.onnx] Run decomposition...
    [torch.onnx] Run decomposition... âœ…
    [torch.onnx] Translate the graph into ONNX...
    [torch.onnx] Translate the graph into ONNX... âœ…
    Applied 4 of general pattern rewrite rules.




.. GENERATED FROM PYTHON SOURCE LINES 127-128

It looks like the following.

.. GENERATED FROM PYTHON SOURCE LINES 128-131

.. code-block:: Python

    onx = onnx.load("plot_dump_intermediate_results.onnx")
    plot_dot(onx)




.. image-sg:: /auto_examples/images/sphx_glr_plot_dump_intermediate_results_001.png
   :alt: plot dump intermediate results
   :srcset: /auto_examples/images/sphx_glr_plot_dump_intermediate_results_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 132-133

.. code-block:: Python

    doc.plot_legend("steal and dump\nintermediate\nresults", "steal_forward", "blue")



.. image-sg:: /auto_examples/images/sphx_glr_plot_dump_intermediate_results_002.png
   :alt: plot dump intermediate results
   :srcset: /auto_examples/images/sphx_glr_plot_dump_intermediate_results_002.png
   :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 14.179 seconds)


.. _sphx_glr_download_auto_examples_plot_dump_intermediate_results.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_dump_intermediate_results.ipynb <plot_dump_intermediate_results.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_dump_intermediate_results.py <plot_dump_intermediate_results.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_dump_intermediate_results.zip <plot_dump_intermediate_results.zip>`


.. include:: plot_dump_intermediate_results.recommendations


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
