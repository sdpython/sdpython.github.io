
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_export_tiny_phi2.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_plot_export_tiny_phi2.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_export_tiny_phi2.py:


.. _l-plot-export_tiny_phi2:

Untrained microsoft/phi-2
=========================

:epkg:`microsoft/phi-2` is not a big models but still quite big
when it comes to write unittest. Function
:func:`onnx_diagnostic.torch_models.hghub.get_untrained_model_with_inputs`
can be used to create a reduced untrained version of a model coming from
:epkg:`HuggingFace`. It downloads the configuration from the website
but creates a dummy model with 1 or 2 hidden layers in order to reduce
the size and get a fast execution. The goal is usually to test
the export or to compare performance. The relevance does not matter.

Create the dummy model
++++++++++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 19-48

.. code-block:: Python


    import copy
    import pprint
    import warnings
    import torch
    import onnxruntime
    from onnx_diagnostic import doc
    from onnx_diagnostic.helpers import max_diff, string_diff, string_type
    from onnx_diagnostic.helpers.cache_helper import is_cache_dynamic_registered
    from onnx_diagnostic.helpers.ort_session import make_feeds
    from onnx_diagnostic.torch_export_patches import bypass_export_some_errors
    from onnx_diagnostic.torch_models.hghub import (
        get_untrained_model_with_inputs,
    )

    warnings.simplefilter("ignore")

    # another tiny id: arnir0/Tiny-LLM
    data = get_untrained_model_with_inputs("microsoft/phi-2")
    untrained_model, inputs, dynamic_shapes, config, size, n_weights = (
        data["model"],
        data["inputs"],
        data["dynamic_shapes"],
        data["configuration"],
        data["size"],
        data["n_weights"],
    )

    print(f"model {size / 2**20:1.3f} Mb with {n_weights // 1000} mille parameters.")




.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    model 432.330 Mb with 113332 mille parameters.




.. GENERATED FROM PYTHON SOURCE LINES 49-51

The original model has 2.7 billion parameters. It was divided by more than 10.
Let's see the configuration.

.. GENERATED FROM PYTHON SOURCE LINES 51-54

.. code-block:: Python

    print(config)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    PhiConfig {
      "_attn_implementation_autoset": true,
      "architectures": [
        "PhiForCausalLM"
      ],
      "attention_dropout": 0.0,
      "bos_token_id": 50256,
      "embd_pdrop": 0.0,
      "eos_token_id": 50256,
      "head_dim": 80,
      "hidden_act": "gelu_new",
      "hidden_size": 768,
      "initializer_range": 0.02,
      "intermediate_size": 6144,
      "layer_norm_eps": 1e-05,
      "max_position_embeddings": 2048,
      "model_type": "phi",
      "num_attention_heads": 32,
      "num_hidden_layers": 2,
      "num_key_value_heads": 32,
      "partial_rotary_factor": 0.4,
      "qk_layernorm": false,
      "resid_pdrop": 0.1,
      "rope_scaling": null,
      "rope_theta": 10000.0,
      "tie_word_embeddings": false,
      "torch_dtype": "float16",
      "transformers_version": "4.51.0.dev0",
      "use_cache": true,
      "vocab_size": 51200
    }





.. GENERATED FROM PYTHON SOURCE LINES 55-56

Inputs:

.. GENERATED FROM PYTHON SOURCE LINES 56-59

.. code-block:: Python


    print(string_type(inputs, with_shape=True))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    dict(input_ids:T7s2x3,attention_mask:T7s2x33,position_ids:T7s2x3,past_key_values:DynamicCache(key_cache=#2[T1s2x32x30x80,T1s2x32x30x80], value_cache=#2[T1s2x32x30x80,T1s2x32x30x80]))




.. GENERATED FROM PYTHON SOURCE LINES 60-61

With min/max values.

.. GENERATED FROM PYTHON SOURCE LINES 61-63

.. code-block:: Python

    print(string_type(inputs, with_shape=True, with_min_max=True))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    dict(input_ids:T7s2x3[4169,41586:A24195.666666666668],attention_mask:T7s2x33[1,1:A1.0],position_ids:T7s2x3[30,32:A31.0],past_key_values:DynamicCache(key_cache=#2[T1s2x32x30x80[-4.250247001647949,4.296894073486328:A0.00039666472688185903],T1s2x32x30x80[-4.584534645080566,4.687620162963867:A0.000881607897973394]], value_cache=#2[T1s2x32x30x80[-4.445925712585449,4.611501693725586:A-0.007746423489871968],T1s2x32x30x80[-4.628787517547607,4.660802841186523:A0.0030252687874702624]]))




.. GENERATED FROM PYTHON SOURCE LINES 64-65

And the dynamic shapes

.. GENERATED FROM PYTHON SOURCE LINES 65-67

.. code-block:: Python

    pprint.pprint(dynamic_shapes)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    {'attention_mask': {0: <class 'onnx_diagnostic.torch_models.hghub.model_inputs.batch'>,
                        1: _DimHint(type=<_DimHintType.DYNAMIC: 3>)},
     'input_ids': {0: <class 'onnx_diagnostic.torch_models.hghub.model_inputs.batch'>,
                   1: <class 'onnx_diagnostic.torch_models.hghub.model_inputs.seq_length'>},
     'past_key_values': [[{0: <class 'onnx_diagnostic.torch_models.hghub.model_inputs.batch'>,
                           2: <class 'onnx_diagnostic.torch_models.hghub.model_inputs.cache_length'>},
                          {0: <class 'onnx_diagnostic.torch_models.hghub.model_inputs.batch'>,
                           2: <class 'onnx_diagnostic.torch_models.hghub.model_inputs.cache_length'>}],
                         [{0: <class 'onnx_diagnostic.torch_models.hghub.model_inputs.batch'>,
                           2: <class 'onnx_diagnostic.torch_models.hghub.model_inputs.cache_length'>},
                          {0: <class 'onnx_diagnostic.torch_models.hghub.model_inputs.batch'>,
                           2: <class 'onnx_diagnostic.torch_models.hghub.model_inputs.cache_length'>}]],
     'position_ids': {0: <class 'onnx_diagnostic.torch_models.hghub.model_inputs.batch'>,
                      1: _DimHint(type=<_DimHintType.DYNAMIC: 3>)}}




.. GENERATED FROM PYTHON SOURCE LINES 68-69

We execute the model to produce expected outputs.

.. GENERATED FROM PYTHON SOURCE LINES 69-73

.. code-block:: Python

    expected = untrained_model(**copy.deepcopy(inputs))
    print(f"expected: {string_type(expected, with_shape=True, with_min_max=True)}")






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    expected: dict(logits:T1s2x3x51200[-2.3363828659057617,2.3946869373321533:A0.0014542278057812533],past_key_values:DynamicCache(key_cache=#2[T1s2x32x33x80[-4.250247001647949,4.296894073486328:A0.000191058535003111],T1s2x32x33x80[-4.584534645080566,4.687620162963867:A0.0002568543326058364]], value_cache=#2[T1s2x32x33x80[-4.445925712585449,4.611501693725586:A-0.007276355170857727],T1s2x32x33x80[-4.628787517547607,4.660802841186523:A0.0036349890182309982]]))




.. GENERATED FROM PYTHON SOURCE LINES 74-76

Export
++++++

.. GENERATED FROM PYTHON SOURCE LINES 76-103

.. code-block:: Python



    with bypass_export_some_errors(patch_transformers=True) as modificator:

        # Unnecessary steps but useful in case of an error
        # We check the cache is registered.
        assert is_cache_dynamic_registered()

        # We check there is no discrepancies when the cache is applied.
        d = max_diff(expected, untrained_model(**copy.deepcopy(inputs)))
        assert (
            d["abs"] < 1e-5
        ), f"The model with patches produces different outputs: {string_diff(d)}"

        # Then we export.
        ep = torch.export.export(
            untrained_model,
            (),
            kwargs=modificator(copy.deepcopy(inputs)),
            dynamic_shapes=dynamic_shapes,
            strict=False,  # mandatory for torch==2.6
        )

        # We check the exported program produces the same results as well.
        d = max_diff(expected, ep.module()(**copy.deepcopy(inputs)))
        assert d["abs"] < 1e-5, f"The exported model different outputs: {string_diff(d)}"








.. GENERATED FROM PYTHON SOURCE LINES 104-111

Export to ONNX
++++++++++++++

The export works. We can export to ONNX now.
Patches are still needed because the export
applies :meth:`torch.export.ExportedProgram.run_decompositions`
may export local pieces of the model again.

.. GENERATED FROM PYTHON SOURCE LINES 111-117

.. code-block:: Python


    with bypass_export_some_errors(patch_transformers=True):
        epo = torch.onnx.export(
            ep, (), kwargs=copy.deepcopy(inputs), dynamic_shapes=dynamic_shapes, dynamo=True
        )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [torch.onnx] Run decomposition...
    [torch.onnx] Run decomposition... ✅
    [torch.onnx] Translate the graph into ONNX...
    [torch.onnx] Translate the graph into ONNX... ✅
    Applied 53 of general pattern rewrite rules.




.. GENERATED FROM PYTHON SOURCE LINES 118-119

We can save it.

.. GENERATED FROM PYTHON SOURCE LINES 119-125

.. code-block:: Python

    epo.save("plot_export_tiny_phi2.onnx", external_data=True)

    # Or directly get the :class:`onnx.ModelProto`.
    onx = epo.model_proto









.. GENERATED FROM PYTHON SOURCE LINES 126-132

Discrepancies
+++++++++++++

The we check the conversion to ONNX.
Let's make sure the ONNX model produces the same outputs.
It takes flatten inputs.

.. GENERATED FROM PYTHON SOURCE LINES 132-138

.. code-block:: Python


    feeds = make_feeds(onx, copy.deepcopy(inputs), use_numpy=True, copy=True)

    print(f"torch inputs: {string_type(inputs)}")
    print(f"onxrt inputs: {string_type(feeds)}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    torch inputs: dict(input_ids:T7r2,attention_mask:T7r2,position_ids:T7r2,past_key_values:DynamicCache(key_cache=#2[T1r4,T1r4], value_cache=#2[T1r4,T1r4]))
    onxrt inputs: dict(input_ids:A7r2,attention_mask:A7r2,position_ids:A7r2,past_key_values_key_cache_0:A1r4,past_key_values_key_cache_1:A1r4,past_key_values_value_cache_0:A1r4,past_key_values_value_cache_1:A1r4)




.. GENERATED FROM PYTHON SOURCE LINES 139-140

We then create a :class:`onnxruntime.InferenceSession`.

.. GENERATED FROM PYTHON SOURCE LINES 140-145

.. code-block:: Python


    sess = onnxruntime.InferenceSession(
        onx.SerializeToString(), providers=["CPUExecutionProvider"]
    )








.. GENERATED FROM PYTHON SOURCE LINES 146-147

Let's run.

.. GENERATED FROM PYTHON SOURCE LINES 147-149

.. code-block:: Python

    got = sess.run(None, feeds)








.. GENERATED FROM PYTHON SOURCE LINES 150-151

And finally the discrepancies.

.. GENERATED FROM PYTHON SOURCE LINES 151-155

.. code-block:: Python


    diff = max_diff(expected, got, flatten=True)
    print(f"onnx discrepancies: {string_diff(diff)}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    onnx discrepancies: abs=2.086162567138672e-06, rel=0.0008807701056327913, n=983040.0




.. GENERATED FROM PYTHON SOURCE LINES 156-157

It looks good.

.. GENERATED FROM PYTHON SOURCE LINES 159-160

.. code-block:: Python

    doc.plot_legend("untrained smaller\nmicrosoft/phi-2", "torch.onnx.export", "orange")



.. image-sg:: /auto_examples/images/sphx_glr_plot_export_tiny_phi2_001.png
   :alt: plot export tiny phi2
   :srcset: /auto_examples/images/sphx_glr_plot_export_tiny_phi2_001.png
   :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 23.712 seconds)


.. _sphx_glr_download_auto_examples_plot_export_tiny_phi2.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_export_tiny_phi2.ipynb <plot_export_tiny_phi2.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_export_tiny_phi2.py <plot_export_tiny_phi2.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_export_tiny_phi2.zip <plot_export_tiny_phi2.zip>`


.. include:: plot_export_tiny_phi2.recommendations


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
