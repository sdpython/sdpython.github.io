
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_final/plot_export_tiny_llm_method_generate.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_final_plot_export_tiny_llm_method_generate.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_final_plot_export_tiny_llm_method_generate.py:


.. _l-plot-tiny-llm-export-method-generate:

Export a LLM through method generate (with Tiny-LLM)
====================================================

The main issue when exporting a LLM is the example on HuggingFace is
based on method generate but we only need to export the forward method.
Example :ref:`l-plot-tiny-llm-export` gives details on how to guess
dummy inputs and dynamic shapes to do so.
Let's see how to simplify that.

Dummy Example
+++++++++++++

Let's use the example provided on
`arnir0/Tiny-LLM <https://huggingface.co/arnir0/Tiny-LLM>`_.

.. GENERATED FROM PYTHON SOURCE LINES 19-65

.. code-block:: Python


    import pandas
    from transformers import AutoModelForCausalLM, AutoTokenizer
    from onnx_diagnostic import doc
    from onnx_diagnostic.export.api import method_to_onnx

    MODEL_NAME = "arnir0/Tiny-LLM"
    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
    model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)


    def generate_text(
        prompt,
        model,
        tokenizer,
        max_length=50,
        temperature=1,
        top_k=50,
        top_p=0.95,
        do_sample=False,
    ):
        inputs = tokenizer(prompt, return_tensors="pt")
        input_ids = inputs["input_ids"]
        attention_mask = inputs["attention_mask"]

        outputs = model.generate(
            input_ids=input_ids,
            attention_mask=attention_mask,
            max_length=max_length,
            temperature=temperature,
            top_k=top_k,
            top_p=top_p,
            do_sample=do_sample,
        )

        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)
        return generated_text


    # Define your prompt
    prompt = "Continue: it rains, what should I do?"
    generated_text = generate_text(prompt, model, tokenizer)
    print("-----------------")
    print(generated_text)
    print("-----------------")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Loading weights:   0%|          | 0/12 [00:00<?, ?it/s]    Loading weights:   8%|▊         | 1/12 [00:00<00:00, 3905.31it/s, Materializing param=lm_head.weight]    Loading weights:   8%|▊         | 1/12 [00:00<00:00, 1848.53it/s, Materializing param=lm_head.weight]    Loading weights:  17%|█▋        | 2/12 [00:00<00:00, 733.21it/s, Materializing param=model.embed_tokens.weight]    Loading weights:  17%|█▋        | 2/12 [00:00<00:00, 676.28it/s, Materializing param=model.embed_tokens.weight]    Loading weights:  25%|██▌       | 3/12 [00:00<00:00, 840.15it/s, Materializing param=model.layers.0.input_layernorm.weight]    Loading weights:  25%|██▌       | 3/12 [00:00<00:00, 805.98it/s, Materializing param=model.layers.0.input_layernorm.weight]    Loading weights:  33%|███▎      | 4/12 [00:00<00:00, 955.80it/s, Materializing param=model.layers.0.mlp.down_proj.weight]      Loading weights:  33%|███▎      | 4/12 [00:00<00:00, 922.84it/s, Materializing param=model.layers.0.mlp.down_proj.weight]    Loading weights:  42%|████▏     | 5/12 [00:00<00:00, 901.38it/s, Materializing param=model.layers.0.mlp.gate_proj.weight]    Loading weights:  42%|████▏     | 5/12 [00:00<00:00, 867.78it/s, Materializing param=model.layers.0.mlp.gate_proj.weight]    Loading weights:  50%|█████     | 6/12 [00:00<00:00, 1003.22it/s, Materializing param=model.layers.0.mlp.up_proj.weight]     Loading weights:  50%|█████     | 6/12 [00:00<00:00, 988.25it/s, Materializing param=model.layers.0.mlp.up_proj.weight]     Loading weights:  58%|█████▊    | 7/12 [00:00<00:00, 1117.03it/s, Materializing param=model.layers.0.post_attention_layernorm.weight]    Loading weights:  58%|█████▊    | 7/12 [00:00<00:00, 1102.36it/s, Materializing param=model.layers.0.post_attention_layernorm.weight]    Loading weights:  67%|██████▋   | 8/12 [00:00<00:00, 1083.59it/s, Materializing param=model.layers.0.self_attn.k_proj.weight]            Loading weights:  67%|██████▋   | 8/12 [00:00<00:00, 1063.53it/s, Materializing param=model.layers.0.self_attn.k_proj.weight]    Loading weights:  75%|███████▌  | 9/12 [00:00<00:00, 965.81it/s, Materializing param=model.layers.0.self_attn.o_proj.weight]     Loading weights:  75%|███████▌  | 9/12 [00:00<00:00, 952.94it/s, Materializing param=model.layers.0.self_attn.o_proj.weight]    Loading weights:  83%|████████▎ | 10/12 [00:00<00:00, 984.56it/s, Materializing param=model.layers.0.self_attn.q_proj.weight]    Loading weights:  83%|████████▎ | 10/12 [00:00<00:00, 971.76it/s, Materializing param=model.layers.0.self_attn.q_proj.weight]    Loading weights:  92%|█████████▏| 11/12 [00:00<00:00, 1055.46it/s, Materializing param=model.layers.0.self_attn.v_proj.weight]    Loading weights:  92%|█████████▏| 11/12 [00:00<00:00, 1047.84it/s, Materializing param=model.layers.0.self_attn.v_proj.weight]    Loading weights: 100%|██████████| 12/12 [00:00<00:00, 1128.54it/s, Materializing param=model.norm.weight]                         Loading weights: 100%|██████████| 12/12 [00:00<00:00, 1120.50it/s, Materializing param=model.norm.weight]    Loading weights: 100%|██████████| 12/12 [00:00<00:00, 1106.75it/s, Materializing param=model.norm.weight]
    -----------------
    Continue: it rains, what should I do?
    I have a lot of people who are in the world. I have a lot of people who are in the world, and I have a lot of people who are in the world
    -----------------




.. GENERATED FROM PYTHON SOURCE LINES 66-76

Replace forward method
++++++++++++++++++++++

We now modify the model to export the model by replacing the forward method.
We still call method ``generate`` but this one will call a different function
created by :func:`onnx_diagnostic.export.api.method_to_onnx`.
This one captured the inputs of the forward method, 2 calls are needed or
at least, 3 are recommended for LLMs as the first call does not contain any cache.
If the default settings do not work, ``skip_kwargs_names`` and ``dynamic_shapes``
can be changed to remove some undesired inputs or add more dynamic dimensions.

.. GENERATED FROM PYTHON SOURCE LINES 76-103

.. code-block:: Python


    filename = "plot_export_tiny_llm_method_generate.custom.onnx"
    forward_replacement = method_to_onnx(
        model,
        method_name="forward",  # default value
        exporter="custom",  # onnx-dynamo to use the official exporter
        filename=filename,  # onnx file to create
        patch_kwargs=dict(patch_transformers=True),  # patches before eporting
        # to see the progress, it is recommended on the first try to see
        # how to set ``skip_kwargs_names`` and ``dynamic_shapes`` if it is needed
        verbose=1,
        # triggers the ONNX conversion after 3 calls to forward method,
        # the onnx version is triggered with the last one,
        # the others are used to infer the dynamic shapes if they are not
        # specified below
        convert_after_n_calls=3,
        # The input used in the example has a batch size equal to 1, all
        # inputs going through method forward will have the same batch size.
        # To force the dynamism of this dimension, we need to indicate
        # which inputs have a batch size.
        dynamic_batch_for={"input_ids", "attention_mask", "past_key_values"},
        # Earlier versions of pytorch did not accept a dynamic batch size equal to 1,
        # this last parameter can be added to expand some inputs if the batch size is 1.
        # The exporter should work without.
        expand_batch_for={"input_ids", "attention_mask", "past_key_values"},
    )








.. GENERATED FROM PYTHON SOURCE LINES 104-127

dynamic shapes can be inferred from at least two calls to the forward method,
3 is better for LLMs (first call is prefill, cache is missing),
you can see the inference results with ``verbose=1``.
If the value is not the expected one (to change the names for example),
They can be overwritten.

.. code-block:: python

  dynamic_shapes={
      "cache_position": {0: "sequence_length"},
      "past_key_values": [
          {0: "batch_size", 2: "past_sequence_length"},
          {0: "batch_size", 2: "past_sequence_length"},
      ],
      "input_ids": {0: "batch_size", 1: "sequence_length"},
      "attention_mask": {0: "batch_size", 1: "total_sequence_length"},
  }

Finally, we need to replace the forward method.
As ``forward_replacement`` is a module of type
:class:`onnx_diagnostic.export.api.WrapperToExportMethodToOnnx`,
a lambda function must be used to avoid this one to be
included as a submodule (and create an infinite loop).

.. GENERATED FROM PYTHON SOURCE LINES 127-132

.. code-block:: Python


    print(f"type(forward_replacement)={type(forward_replacement)}")
    model.forward = lambda *args, **kwargs: forward_replacement(*args, **kwargs)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    type(forward_replacement)=<class 'onnx_diagnostic.export.api.WrapperToExportMethodToOnnx'>




.. GENERATED FROM PYTHON SOURCE LINES 133-136

Let's call generate again. The conversion is triggered after
``convert_after_n_calls=3`` calls to the method forward,
which exactly what the method generate is doing.

.. GENERATED FROM PYTHON SOURCE LINES 136-139

.. code-block:: Python

    generated_text = generate_text(prompt, model, tokenizer)
    print(generated_text)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [method_to_onnx] input[0]: ((),dict(input_ids:T7s1x13,attention_mask:T7s1x13,cache_position:T7s13))
    [method_to_onnx] input[1]: ((),dict(input_ids:T7s1x1,attention_mask:T7s1x14,past_key_values:DynamicCache(key_cache=#1[T1s1x1x13x96], value_cache=#1[T1s1x1x13x96]),cache_position:T7s1))
    [method_to_onnx] input[2]: ((),dict(input_ids:T7s1x1,attention_mask:T7s1x15,past_key_values:DynamicCache(key_cache=#1[T1s1x1x14x96], value_cache=#1[T1s1x1x14x96]),cache_position:T7s1))
    [method_to_onnx] save 3 inputs in 'plot_export_tiny_llm_method_generate.custom.inputs.pt'
    [method_to_onnx] guess_dynamic_shapes=((),dict(input_ids:{1:DYNAMIC},attention_mask:{1:DYNAMIC},past_key_values:#2[{2:DYNAMIC},{2:DYNAMIC}],cache_position:{0:DYNAMIC}))
    [method_to_onnx.rename_dynamic_shapes] apply pattern shapes 'LLM.text'
    [method_to_onnx] dynamic_batch_for={'input_ids', 'past_key_values', 'attention_mask'}
    [method_to_onnx] dynamic_shapes with batch=((), {'input_ids': {0: 'batch', 1: 'seqlength'}, 'attention_mask': {0: 'batch', 1: 'totallength'}, 'past_key_values': [{0: 'batch', 2: 'pastlength'}, {0: 'batch', 2: 'pastlength'}], 'cache_position': {0: 'seqlength'}})
    [method_to_onnx] export args=()
    [method_to_onnx] export kwargs=dict(input_ids:T7s2x1,attention_mask:T7s2x15,past_key_values:DynamicCache(key_cache=#1[T1s2x1x14x96], value_cache=#1[T1s2x1x14x96]),cache_position:T7s1)
    [method_to_onnx] dynamic_shapes=((),dict(input_ids:{0:DYN(batch),1:DYN(seqlength)},attention_mask:{0:DYN(batch),1:DYN(totallength)},past_key_values:#2[{0:DYN(batch),2:DYN(pastlength)},{0:DYN(batch),2:DYN(pastlength)}],cache_position:{0:DYN(seqlength)}))
    [to_onnx] build the graph module from <class 'onnx_diagnostic.export.api.WrapperToExportMethodToOnnx._convert_method_to_onnx.<locals>.WrapWithExactSignature'>, type(args)=<class 'tuple'>
    [to_onnx] dynamic_shapes={'input_ids': {0: 'batch', 1: 'seqlength'}, 'attention_mask': {0: 'batch', 1: 'totallength'}, 'past_key_values': [{0: 'batch', 2: 'pastlength'}, {0: 'batch', 2: 'pastlength'}], 'cache_position': {0: 'seqlength'}}
    [_make_builder_interpreter] export_options=ExportOptions(aten_as_function=('aten.index_copy.default', 'aten.index_put.default', 'aten.setitem', <built-in function setitem>))
    [_make_builder_interpreter] input args=()
    [_make_builder_interpreter] input kwargs=dict(input_ids:T7r2,attention_mask:T7r2,past_key_values:DynamicCache(key_cache=#1[T1r4], value_cache=#1[T1r4]),cache_position:T7r1)
    [_make_builder_interpreter] dynamic_shapes={'input_ids': {0: 'batch', 1: 'seqlength'}, 'attention_mask': {0: 'batch', 1: 'totallength'}, 'past_key_values': [{0: 'batch', 2: 'pastlength'}, {0: 'batch', 2: 'pastlength'}], 'cache_position': {0: 'seqlength'}}
    [_make_builder_interpreter] same_signature=True, tracing_mode=symbolic
    [ExportOptions.export] ExportOptions(aten_as_function=('aten.index_copy.default', 'aten.index_put.default', 'aten.setitem', <built-in function setitem>)) - torch._dynamo.export 'WrapWithExactSignature'
    [ExportOptions.export] aten_as_function=('aten.index_copy.default', 'aten.index_put.default', 'aten.setitem', <built-in function setitem>)
    [ExportOptions.export] torch_export strict=False, verbose=1
    [ExportOptions.export] dynamic_shapes={'input_ids': {0: 'batch', 1: 'seqlength'}, 'attention_mask': {0: 'batch', 1: 'totallength'}, 'past_key_values': [{0: 'batch', 2: 'pastlength'}, {0: 'batch', 2: 'pastlength'}], 'cache_position': {0: 'seqlength'}}
    [ExportOptions.export] args=()
    [ExportOptions.export] kwargs=dict(input_ids:T7r2,attention_mask:T7r2,past_key_values:DynamicCache(key_cache=#1[T1r4], value_cache=#1[T1r4]),cache_position:T7r1)
    [ExportOptions.export] export start with strict=False...
    [ExportOptions.export] export with backed_size_oblivious=auto
    [torch_export] backed_size_oblivious='auto'
    [torch_export] inferred backed_size_oblivious={'input_ids': {1: 'd=[1]'}, 'cache_position': {0: 'd=[1]'}}
    [torch_export] export starts with backed_size_oblivious={'input_ids': {1: 'd=[1]'}, 'cache_position': {0: 'd=[1]'}}
    [ExportOptions.export] export done in 2.2415495709992683
    [ExportOptions.export] post_process_exported_program with decomposition_table=None
    [ExportOptions.export] remove inplace nodes
    [ExportOptions.export] slices: 7 slices nodes were removed
    [CustomTracer.remove_inplace] starts with 166 nodes (n_inplace_submobules=0)
    [CustomTracer.remove_inplace] S1: 13 inplace nodes
    [CustomTracer.remove_inplace] S2: 7 inplace nodes and 100 iterations
    [CustomTracer.remove_inplace] end with 98 iterations and 137 nodes (n_inplace=7)
    [ExportOptions.export] inplaces: 13 inplaced nodes were removed
    [ExportOptions.export] done remove inplace in 0.004086326000106055, modified=13
    [ExportOptions.export] done with no decomposition in 0.004202844998872024
    [to_onnx] graph module done in 2.2566391650016158 s
    [to_onnx] start creating the onnx nodes
    [to_onnx] interpreter.function_options=FunctionOptions(export_as_function=True, name='*', domain='*', external_threshold=256, move_initializer_to_constant=True, return_initializer=True, merge_allowed=True, rename_allowed=True)
      0%|          | 0/137 [00:00<?, ?it/s]     78%|███████▊  | 107/137 [00:00<00:00, 1057.10it/s]    100%|██████████| 137/137 [00:00<00:00, 1059.39it/s]
    [to_onnx] 199 onnx nodes done in 0.2183332029999292 s
    [to_onnx] start conversion to onnx (before optimization) mask_outputs=[True, True, True]
    [GraphBuilder-HXG.inline_functions] begin inlining graph
    [GraphBuilder-HXG.inline_functions] skip_functions=set()
    [GraphBuilder-HXG._inline_functions_iterations] inline function 'submod_3' domain 'local_functions' [n_replacements=1]
    [GraphBuilder-HXG._inline_functions_iterations] done with 9 new nodes for 'submod_3', 'local_functions'
    [GraphBuilder-HXG.inline_functions] done inlining graph 140657825873792 in 0.005450429998745676
    [GraphBuilder-HXG._add_shape_information] dynamic shapes replacements={'pastlength': 'pastlength', 'seqlength': 'seqlength', 'totallength': 'totallength', 'batch': 'batch', 's61': 'batch', 's67': 'batch', 's43': 'batch', 's72': 'batch', 'batch^s61^batch^s61': 'batch', 's58': 'seqlength', 'Max(s58,s70)': 'seqlength', 's70': 'seqlength', 's53': 'totallength', 's21': 'pastlength', 's44': 'pastlength'}
    [GraphBuilder-HXG.optimize] start with 207 nodes
    [GraphBuilder-HXG.optimize] #patterns=111
    [GraphBuilder-HXG.optimize] start with subgraphs
    [GraphBuilder-HXG.optimize] done with subgraphs
    [GraphBuilderPatternOptimization-HXG.optimize] start with 157 nodes, 35 initializers, 111 patterns, priorities=[0, 1, 2, 3], max_iter=628
    [GraphBuilderPatternOptimization-HXG.optimize] same children={'SameChildrenFromInputPattern', 'SameChildrenPattern'}
    [GraphBuilderPatternOptimization-HXG.optimize] iteration 0: 157 nodes, priority=0
    [GraphBuilderPatternOptimization-HXG.optimize] applies 32 matches, 11*CastPattern, 2*IdentityPattern, 6*ShapeBasedReshapeIsSqueezePattern, 1*ShapeBasedStaticExpandPattern, 3*ShapeBasedEditDistanceReshapePattern, 4*SameChildrenPattern, 2*SqueezeAddPattern, 1*SqueezeUnsqueezePattern, 1*UnsqueezeUnsqueezePattern, 1*FunctionAttentionPattern - time=0.012 | max_time=SoftmaxCrossEntropyLossCastPattern:0.001
    [GraphBuilderPatternOptimization-HXG.optimize] reapply {'SameChildrenPattern'}
    [GraphBuilderPatternOptimization-HXG.optimize] n_added=7, n_removed=9, n_applied=34 applied patterns, 113 nodes left with 2 iterations
    [GraphBuilderPatternOptimization-HXG.optimize] increase priority to 1
    [GraphBuilderPatternOptimization-HXG.optimize] iteration 1: 113 nodes, priority=1
    [GraphBuilderPatternOptimization-HXG.optimize] applies 17 matches, 2*ConcatTwiceUnaryPattern, 1*ConstantToInitializerPattern, 1*ShapeBasedExpandBroadcastPattern, 1*ShapeBasedExpandSwapPattern, 2*SlicesSplitPattern, 1*SqueezeBinaryUnsqueezePattern, 3*SqueezeUnsqueezePattern, 2*SwapUnsqueezeTransposePattern, 1*QuickGeluPattern, 3*SimplifiedLayerNormalizationPattern - time=0.016 | max_time=GeluOrtPattern:0.002
    [GraphBuilderPatternOptimization-HXG.optimize] iteration 2: 90 nodes, priority=1
    [GraphBuilderPatternOptimization-HXG.optimize] applies 9 matches, 2*IdentityPattern, 2*ShapeBasedExpandSwapPattern, 2*FunctionHalfRotaryEmbeddingPattern, 3*SimplifiedLayerNormalizationMulPattern - time=0.019 | max_time=GeluErfPattern:0.004
    [GraphBuilderPatternOptimization-HXG.optimize] iteration 3: 74 nodes, priority=1
    [GraphBuilderPatternOptimization-HXG.optimize] applies 3 matches, 1*ShapeBasedExpandBroadcastPattern, 2*SkipSimplifiedLayerNormalizationPattern - time=0.008 | max_time=ShapeBasedEditDistanceReshapePattern:0.001
    [GraphBuilderPatternOptimization-HXG.optimize] iteration 4: 71 nodes, priority=1
    [GraphBuilderPatternOptimization-HXG.optimize] applies 1 matches, [0]=MatchResult: ShapeBasedConcatExpandPattern replaces ['Concat', 'Expand'] - time=0.009 | max_time=ShapeBasedEditDistanceReshapePattern:0.001
    [GraphBuilderPatternOptimization-HXG.optimize] iteration 5: 71 nodes, priority=1
    [GraphBuilderPatternOptimization-HXG.optimize] increase priority to 2
    [GraphBuilderPatternOptimization-HXG.optimize] iteration 6: 71 nodes, priority=2
    [GraphBuilderPatternOptimization-HXG.optimize] increase priority to 3
    [GraphBuilderPatternOptimization-HXG.optimize] iteration 7: 71 nodes, priority=3
    [GraphBuilderPatternOptimization-HXG.optimize] stops current_priority_index=4, priorities=[0, 1, 2, 3]
    [GraphBuilderPatternOptimization-HXG.optimize] done after 8 iterations with 71 nodes in 0.152
    [OrderOptimization.optimize] ALGO-2
    [OrderOptimization.random_order] -- starts with 71 nodes, 31 initializers
    [OrderOptimization.shape_order] done after in 0.00038820100053271744s with changed=5 scale=20
    [GraphBuilder-HXG.optimize] done with 71 nodes in 0.172
    [GraphBuilder-HXG.to_onnx] make_model 35 inits 12 params
    [GraphBuilder-HXG.time_evaluation_constants_] 0.0011296069988020463
    [GraphBuilder-HXG._build_initializers] start with 35 initializers, large_model=True, external_threshold=1024
    [GraphBuilder-HXG._build_initializers] switch low/high order
    [GraphBuilder-HXG._build_initializers] done in 2.277000021422282e-06s with 31 initializers, 9 large initializers
    [GraphBuilder-HXG._add_shape_information] dynamic shapes replacements={'pastlength': 'pastlength', 'seqlength': 'seqlength', 'totallength': 'totallength', 'batch': 'batch', 's61': 'batch', 's67': 'batch', 's43': 'batch', 's72': 'batch', 'batch^s61^batch^s61': 'batch', 's58': 'seqlength', 'Max(s58,s70)': 'seqlength', 's70': 'seqlength', 's53': 'totallength', 's21': 'pastlength', 's44': 'pastlength'}
    [to_onnx] to_onnx done in 0.1928362759990705s and 71 nodes, 31 initializers, 5 inputs, 3 outputs
    [method_to_onnx] save 3 outputs in 'plot_export_tiny_llm_method_generate.custom.outputs.pt'
    Continue: it rains, what should I do?
    I have a lot of people who are in the world. I have a lot of people who are in the world, and I have a lot of people who are in the world




.. GENERATED FROM PYTHON SOURCE LINES 140-147

We finally need to check the discrepancies.
The exports produced an onnx file and dumped the input and output
of the torch model. We now run the onnx model to check
it produces the same results.
It is done after because the model may not hold twice in memory
(torch and onnxruntime).
verbose=2 shows more information about expected outputs.

.. GENERATED FROM PYTHON SOURCE LINES 147-151

.. code-block:: Python

    data = forward_replacement.check_discrepancies(verbose=1)
    df = pandas.DataFrame(data)
    print(df)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [method_to_onnx.check_discrepancies] register classes [<class 'transformers.modeling_outputs.CausalLMOutputWithPast'>, <class 'transformers.cache_utils.DynamicLayer'>, <class 'transformers.cache_utils.DynamicCache'>]
    [method_to_onnx.check_discrepancies] load 'plot_export_tiny_llm_method_generate.custom.inputs.pt'
    [method_to_onnx.check_discrepancies] load 'plot_export_tiny_llm_method_generate.custom.outputs.pt'
    [method_to_onnx.check_discrepancies] create onnx session 'plot_export_tiny_llm_method_generate.custom.onnx'
    [method_to_onnx.check_discrepancies] input_names=['input_ids', 'attention_mask', 'past_key_values_key_0', 'past_key_values_value_0', 'cache_position']
    [method_to_onnx.check_discrepancies] onnx_shapes=INT64[batch,seqlength], INT64[batch,totallength], FLOAT[batch,1,pastlength,96], FLOAT[batch,1,pastlength,96], INT64[seqlength]
    [method_to_onnx.check_discrepancies] process input 0 #args=0 #kwargs=4
    [method_to_onnx.check_discrepancies] process input 1 #args=0 #kwargs=4
    [method_to_onnx.check_discrepancies] process input 2 #args=0 #kwargs=4
    [method_to_onnx.check_discrepancies] done
            abs       rel       sum         n  dnan  dev  >0.1  >0.01  SUCCESS  index  duration_torch  ort_duration  n_inputs
    0  0.000019  0.004534  0.927152  418496.0     0    0     0      0     True      0        0.002792      1.844142         5
    1  0.000010  0.001035  0.066861   34688.0     0    0     0      0     True      1        0.001525      0.001470         5
    2  0.000011  0.001430  0.064404   34880.0     0    0     0      0     True      2        0.005922      0.001339         5




.. GENERATED FROM PYTHON SOURCE LINES 152-156

Minimal script to export a LLM
++++++++++++++++++++++++++++++

The following lines are a condensed copy with less comments.

.. GENERATED FROM PYTHON SOURCE LINES 156-197

.. code-block:: Python


    # from HuggingFace
    print("----------------")
    MODEL_NAME = "arnir0/Tiny-LLM"
    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
    model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)

    # to export into onnx
    forward_replacement = method_to_onnx(
        model,
        method_name="forward",
        exporter="onnx-dynamo",
        filename="plot_export_tiny_llm_method_generate.dynamo.onnx",
        patch_kwargs=dict(patch_transformers=True),
        verbose=0,
        convert_after_n_calls=3,
        dynamic_batch_for={"input_ids", "attention_mask", "past_key_values"},
    )
    model.forward = lambda *args, **kwargs: forward_replacement(*args, **kwargs)

    # from HuggingFace again
    prompt = "Continue: it rains, what should I do?"
    inputs = tokenizer(prompt, return_tensors="pt")
    outputs = model.generate(
        input_ids=inputs["input_ids"],
        attention_mask=inputs["attention_mask"],
        max_length=100,
        temperature=1,
        top_k=50,
        top_p=0.95,
        do_sample=True,
    )
    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)
    print("prompt answer:", generated_text)

    # to check discrepancies
    data = forward_replacement.check_discrepancies()
    df = pandas.DataFrame(data)
    print(df)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    ----------------
    Loading weights:   0%|          | 0/12 [00:00<?, ?it/s]    Loading weights:   8%|▊         | 1/12 [00:00<00:00, 37786.52it/s, Materializing param=lm_head.weight]    Loading weights:   8%|▊         | 1/12 [00:00<00:00, 7307.15it/s, Materializing param=lm_head.weight]     Loading weights:  17%|█▋        | 2/12 [00:00<00:00, 3182.32it/s, Materializing param=model.embed_tokens.weight]    Loading weights:  17%|█▋        | 2/12 [00:00<00:00, 2058.05it/s, Materializing param=model.embed_tokens.weight]    Loading weights:  25%|██▌       | 3/12 [00:00<00:00, 278.52it/s, Materializing param=model.layers.0.input_layernorm.weight]    Loading weights:  25%|██▌       | 3/12 [00:00<00:00, 268.81it/s, Materializing param=model.layers.0.input_layernorm.weight]    Loading weights:  33%|███▎      | 4/12 [00:00<00:00, 340.38it/s, Materializing param=model.layers.0.mlp.down_proj.weight]      Loading weights:  33%|███▎      | 4/12 [00:00<00:00, 333.44it/s, Materializing param=model.layers.0.mlp.down_proj.weight]    Loading weights:  42%|████▏     | 5/12 [00:00<00:00, 394.26it/s, Materializing param=model.layers.0.mlp.gate_proj.weight]    Loading weights:  42%|████▏     | 5/12 [00:00<00:00, 387.68it/s, Materializing param=model.layers.0.mlp.gate_proj.weight]    Loading weights:  50%|█████     | 6/12 [00:00<00:00, 451.07it/s, Materializing param=model.layers.0.mlp.up_proj.weight]      Loading weights:  50%|█████     | 6/12 [00:00<00:00, 444.59it/s, Materializing param=model.layers.0.mlp.up_proj.weight]    Loading weights:  58%|█████▊    | 7/12 [00:00<00:00, 424.43it/s, Materializing param=model.layers.0.post_attention_layernorm.weight]    Loading weights:  58%|█████▊    | 7/12 [00:00<00:00, 416.14it/s, Materializing param=model.layers.0.post_attention_layernorm.weight]    Loading weights:  67%|██████▋   | 8/12 [00:00<00:00, 463.20it/s, Materializing param=model.layers.0.self_attn.k_proj.weight]            Loading weights:  67%|██████▋   | 8/12 [00:00<00:00, 457.31it/s, Materializing param=model.layers.0.self_attn.k_proj.weight]    Loading weights:  75%|███████▌  | 9/12 [00:00<00:00, 503.45it/s, Materializing param=model.layers.0.self_attn.o_proj.weight]    Loading weights:  75%|███████▌  | 9/12 [00:00<00:00, 497.76it/s, Materializing param=model.layers.0.self_attn.o_proj.weight]    Loading weights:  83%|████████▎ | 10/12 [00:00<00:00, 542.10it/s, Materializing param=model.layers.0.self_attn.q_proj.weight]    Loading weights:  83%|████████▎ | 10/12 [00:00<00:00, 537.25it/s, Materializing param=model.layers.0.self_attn.q_proj.weight]    Loading weights:  92%|█████████▏| 11/12 [00:00<00:00, 580.38it/s, Materializing param=model.layers.0.self_attn.v_proj.weight]    Loading weights:  92%|█████████▏| 11/12 [00:00<00:00, 575.49it/s, Materializing param=model.layers.0.self_attn.v_proj.weight]    Loading weights: 100%|██████████| 12/12 [00:00<00:00, 601.20it/s, Materializing param=model.norm.weight]                         Loading weights: 100%|██████████| 12/12 [00:00<00:00, 593.29it/s, Materializing param=model.norm.weight]    Loading weights: 100%|██████████| 12/12 [00:00<00:00, 581.88it/s, Materializing param=model.norm.weight]
    /home/xadupre/github/onnx-diagnostic/onnx_diagnostic/export/api.py:229: UserWarning: Exporting a model while it is in training mode. Please ensure that this is intended, as it may lead to different behavior during inference. Calling model.eval() before export is recommended.
      epo = torch.onnx.export(
    [torch.onnx] Obtain model graph for `WrapWithExactSignature([...]` with `torch.export.export(..., strict=False)`...
    [torch.onnx] Obtain model graph for `WrapWithExactSignature([...]` with `torch.export.export(..., strict=False)`... ✅
    [torch.onnx] Run decompositions...
    /usr/lib/python3.12/copyreg.py:99: FutureWarning: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.
      return cls.__new__(cls, *args)
    [torch.onnx] Run decompositions... ✅
    [torch.onnx] Translate the graph into ONNX...
    [torch.onnx] Translate the graph into ONNX... ✅
    [torch.onnx] Optimize the ONNX graph...
    Applied 30 of general pattern rewrite rules.
    [torch.onnx] Optimize the ONNX graph... ✅
    /home/xadupre/vv/this312/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_onnx_program.py:462: UserWarning: # The axis name: batch will not be used, since it shares the same shape constraints with another axis: batch.
      rename_mapping = _dynamic_shapes.create_rename_mapping(
    prompt answer: Continue: it rains, what should I do?
    P: No. 1944, 24:27
    2601 000 903 142 063008
            abs       rel       sum         n  dnan  dev  >0.1  >0.01  SUCCESS  index  duration_torch  ort_duration  n_inputs
    0  0.000019  0.004534  0.927152  418496.0     0    0     0      0     True      0        0.021088      0.218453         5
    1  0.000010  0.001035  0.066861   34688.0     0    0     0      0     True      1        0.004563      0.001744         5
    2  0.000020  0.006390  0.197986   34880.0     0    0     0      0     True      2        0.009281      0.001656         5




.. GENERATED FROM PYTHON SOURCE LINES 198-199

.. code-block:: Python

    doc.save_fig(doc.plot_dot(filename), f"{filename}.png", dpi=400)



.. image-sg:: /auto_final/images/sphx_glr_plot_export_tiny_llm_method_generate_001.png
   :alt: plot export tiny llm method generate
   :srcset: /auto_final/images/sphx_glr_plot_export_tiny_llm_method_generate_001.png
   :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 29.277 seconds)


.. _sphx_glr_download_auto_final_plot_export_tiny_llm_method_generate.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_export_tiny_llm_method_generate.ipynb <plot_export_tiny_llm_method_generate.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_export_tiny_llm_method_generate.py <plot_export_tiny_llm_method_generate.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_export_tiny_llm_method_generate.zip <plot_export_tiny_llm_method_generate.zip>`


.. include:: plot_export_tiny_llm_method_generate.recommendations


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
