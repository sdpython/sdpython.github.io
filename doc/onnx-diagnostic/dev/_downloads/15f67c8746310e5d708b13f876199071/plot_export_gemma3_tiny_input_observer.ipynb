{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Export Gemma3 tiny random with InputObserver\n\nThis reuses the recipe introduced by example `l-plot-tiny-llm-export-input-observer`\nfor model [tiny-random/gemma-3](https://huggingface.co/tiny-random/gemma-3).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas\nimport torch\nfrom onnx_diagnostic import doc\nfrom onnx_diagnostic.helpers import string_type\nfrom onnx_diagnostic.export.api import to_onnx\nfrom onnx_diagnostic.torch_export_patches import (\n    register_additional_serialization_functions,\n    torch_export_patches,\n)\nfrom onnx_diagnostic.investigate.input_observer import InputObserver\n\n\nfrom transformers import pipeline\n\nmodel_id = \"tiny-random/gemma-3\"\npipe = pipeline(\n    \"image-text-to-text\",\n    model=model_id,\n    device=\"cpu\",\n    trust_remote_code=True,\n    max_new_tokens=3,\n    dtype=torch.float16,\n)\nmessages = [\n    {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": \"You are a helpful assistant.\"}]},\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\n                \"type\": \"image\",\n                \"url\": \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/p-blog/candy.JPG\",\n            },\n            {\"type\": \"text\", \"text\": \"What animal is on the candy?\"},\n        ],\n    },\n]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The model to observe.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"model type:\", type(pipe.model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Captures inputs and outputs for the model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "observer = InputObserver(\n    missing=dict(pixel_values=torch.empty((0, 3, 896, 896), dtype=torch.float16))\n)\nwith (\n    register_additional_serialization_functions(patch_transformers=True),\n    observer(pipe.model),\n):\n    pipe(text=messages, max_new_tokens=4)\n\n\nprint(f\"{observer.num_obs()} observations stored for encoder.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Exports the model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "kwargs = observer.infer_arguments()\ndynamic_shapes = observer.infer_dynamic_shapes(set_batch_dimension_for=True)\nprint(f\"encoder kwargs={string_type(kwargs, with_shape=True)}\")\nprint(f\"encoder dynamic_shapes={dynamic_shapes}\")\nfor candidate in observer.info.inputs:\n    print(\n        \"   \",\n        candidate,\n        candidate.str_obs(),\n        string_type(candidate.aligned_flat_list, with_shape=True),\n    )\n\n\nfilename = \"plot_export_gemma3_tiny_input_observer.onnx\"\nwith torch_export_patches(patch_transformers=True, patch_torch=True, stop_if_static=2):\n    to_onnx(\n        pipe.model,\n        args=(),\n        filename=filename,\n        kwargs=kwargs,\n        dynamic_shapes=dynamic_shapes,\n        exporter=\"custom\",\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's measure the discrepancies.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data = observer.check_discrepancies(filename, progress_bar=True, atol=1e-2, include_io=True)\ndf = pandas.DataFrame(data)\ndf.to_excel(\"plot_export_gemma3_tiny_input_observer.xlsx\")\nprint(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's show the errors.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for row in data:\n    if not row[\"SUCCESS\"] and \"error\" in row:\n        print(row[\"error\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "doc.save_fig(doc.plot_dot(filename), f\"{filename}.png\", dpi=400)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}