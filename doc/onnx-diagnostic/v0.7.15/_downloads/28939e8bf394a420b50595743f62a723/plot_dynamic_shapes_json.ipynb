{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# JSON returns list when the original dynamic shapes are list or tuple\n\nDynamic shapes given to :func:`torch.export.export` must follow the\nsame semantic. What if we confuse tuple and list when defining the dynamic shapes,\nhow to restore the expected type assuming we know the inputs?\nNot often useful but maybe we will learn more about\n:epkg:`optree`.\n\n## Dynamic Shapes After JSON\n\nJSON format does not make the difference between a list and a tuple.\nSo after serializing to json and restoring, both of them become lists.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import json\nimport pprint\nimport torch\nfrom onnx_diagnostic import doc\nfrom onnx_diagnostic.helpers import string_type\nfrom onnx_diagnostic.helpers.cache_helper import make_dynamic_cache\nfrom onnx_diagnostic.export.shape_helper import all_dynamic_shape_from_inputs\n\nbsize, nheads, slen, dim = 2, 1, 30, 96\n\ninputs = dict(\n    input_mask_position=(\n        torch.randint(15, size=(2, 3), dtype=torch.int64),\n        torch.randint(1, size=(2, 33), dtype=torch.int64),\n        torch.arange(3, dtype=torch.int64),\n    ),\n    past_key_values=make_dynamic_cache(\n        [(torch.randn(bsize, nheads, slen, dim), torch.randn(bsize, nheads, slen, dim))]\n    ),\n)\n\nprint(string_type(inputs, with_shape=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Function :func:`onnx_diagnostic.export.shape_helper.all_dynamic_shape_from_inputs`\nproduces the corresponding dynamic shapes assuming they are all dynamic.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ds = all_dynamic_shape_from_inputs(inputs)\npprint.pprint(ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Converted into JSON.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "json_str = json.dumps(ds, indent=2, ensure_ascii=False)\nprint(json_str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Restoration.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ds2 = json.loads(json_str)\npprint.pprint(ds2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "tuple are replaced by list.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# The trick to restore tuple when expected\n# ++++++++++++++++++++++++++++++++++++++++\n\n\ndef flatten_unflatten_like_dynamic_shapes(obj):\n    if isinstance(obj, torch.Tensor):\n        return obj\n    flat, spec = torch.utils._pytree.tree_flatten(obj)\n    start = 0\n    end = 0\n    subtrees = []\n    for subspec in spec.children_specs:\n        end += subspec.num_leaves\n        value = subspec.unflatten(flat[start:end])\n        value = flatten_unflatten_like_dynamic_shapes(value)\n        subtrees.append(value)\n        start = end\n    if spec.type is dict:\n        # This a dictionary.\n        return dict(zip(spec.context, subtrees))\n    if spec.type is tuple:\n        return tuple(subtrees)\n    if spec.type is list:\n        return list(subtrees)\n    if spec.context:\n        # This is a custom class with attributes.\n        # It is returned as a list.\n        return list(subtrees)\n    raise ValueError(\n        f\"Unable to interpret spec type {spec.type} \"\n        f\"(type is {type(spec.type)}, context is {spec.context}).\"\n    )\n\n\ndef _align(inputs, ds):\n    if isinstance(inputs, torch.Tensor):\n        return ds\n    if isinstance(inputs, tuple):\n        return tuple(_align(o, d) for o, d in zip(inputs, ds))\n    if isinstance(inputs, list):\n        return [_align(o, d) for o, d in zip(inputs, ds)]\n    if isinstance(inputs, dict):\n        return {k: _align(inputs[k], d) for k, d in ds.items()}\n    raise TypeError(f\"Unexpected types inputs is {type(inputs)}, ds is {type(ds)}\")\n\n\ndef fix_dynamic_shapes(inputs, dynamic_shapes):\n    flat_unflat_inputs = flatten_unflatten_like_dynamic_shapes(inputs)\n    return _align(flat_unflat_inputs, dynamic_shapes)\n\n\nfixed_ds = fix_dynamic_shapes(inputs, ds2)\npprint.pprint(fixed_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The code changed tuple into list as expected.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "assert isinstance(ds2[\"input_mask_position\"], list)\nassert isinstance(fixed_ds[\"input_mask_position\"], tuple)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "doc.plot_legend(\"dynamic shapes\\nto json\\nfrom json\", \"torch.export.export\", \"green\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}