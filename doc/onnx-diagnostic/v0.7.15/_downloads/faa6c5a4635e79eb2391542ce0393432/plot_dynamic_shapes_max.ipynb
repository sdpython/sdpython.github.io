{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Cannot export ``torch.sym_max(x.shape[0], y.shape[0])``\n\nThis is related to the following issues:\n[Cannot export torch.sym_max(x.shape[0], y.shape[0])](https://github.com/pytorch/pytorch/issues/150851).\n\nThe algorithm trying to automatically infer shapes after every operator\nin the exported program is something very aggreessive. Here is a case where\nit takes a wrong decision and how to get around it.\n\n**This bug was fixed after 4/24/2025**.\n\n## Wrong Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nfrom onnx_diagnostic import doc\n\n\nclass Model(torch.nn.Module):\n    def forward(self, x, y, fact):\n        s1 = max(x.shape[0], y.shape[0])\n        s2 = max(x.shape[1], y.shape[1])\n        # Shapes cannot be known here.\n        z = torch.zeros((s1, s2), dtype=x.dtype)\n        z[: x.shape[0], : x.shape[1]] = x\n        z[: y.shape[0], : y.shape[1]] += y\n        return z * fact\n\n\nmodel = Model()\nx = torch.arange(6).reshape((2, 3))\ny = torch.arange(6).reshape((3, 2)) * 10\nfact = torch.tensor([[1, 2, 3]], dtype=x.dtype)\nz = model(x, y, fact)\nprint(f\"x.shape={x.shape}, y.shape={y.shape}, z.shape={z.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "DYN = torch.export.Dim.DYNAMIC\n\nep = torch.export.export(\n    model, (x, y, fact), dynamic_shapes=({0: DYN, 1: DYN}, {0: DYN, 1: DYN}, {1: DYN})\n)\nprint(ep)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "But does it really work? Let's print the shapes.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_ep = ep.module()\nez = model_ep(x, y, fact)\nprint(\"case 1:\", z.shape, ez.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Case with different shapes.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x = torch.arange(4).reshape((2, 2))\ny = torch.arange(9).reshape((3, 3))\ntry:\n    ez = model_ep(x, y, fact)\n    print(\"case 2:\", model(x, y, fact).shape, ez.shape)\nexcept Exception as e:\n    print(\"case 2 failed:\", e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It does not even compute. The exported program does not get the correct shape.\n\n## Rewritten Model\n\n``max`` does not get captured, :func:`torch.sym_max` is no better,\n:func:`torch.max` only works on tensors. Nothing really works.\nWe use a trick to introduce new shape the shape inference algorithm\ncannot know. This requires to hide the failing logic in a custom operator.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def make_undefined_dimension(i: int) -> torch.SymInt:\n    \"\"\"\n    Uses for a custom op when a new dimension must be introduced to bypass\n    some verification. The following function creates a dummy output\n    with a dimension based on the content.\n\n    .. code-block:: python\n\n        def symbolic_shape(x, y):\n            return torch.empty(\n                x.shape[0],\n                make_undefined_dimension(min(x.shape[1], y[0])),\n            )\n    \"\"\"\n    t = torch.ones((i * 2,))\n    t[:i] = 0\n    res = torch.nonzero(t).shape[0]\n    return res\n\n\ndef copy_max_dimensions(x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n    shape = torch.max(torch.tensor(x.shape), torch.tensor(y.shape))\n    z = torch.zeros(tuple(shape), dtype=x.dtype)\n    z[0 : x.shape[0], 0 : x.shape[1]] = x[0 : x.shape[0], 0 : x.shape[1]]\n    z[0 : y.shape[0], 0 : y.shape[1]] += y[0 : y.shape[0], 0 : y.shape[1]]\n    return z\n\n\ndef symbolic_shape(x, y):\n    return torch.empty(\n        tuple(\n            make_undefined_dimension(max(x.shape[i], y.shape[i])) for i in range(len(x.shape))\n        ),\n        dtype=x.dtype,\n    )\n\n\ndef register(fct, fct_shape, namespace, fname):\n    schema_str = torch.library.infer_schema(fct, mutates_args=())\n    custom_def = torch.library.CustomOpDef(namespace, fname, schema_str, fct)\n    custom_def.register_kernel(\"cpu\")(fct)\n    custom_def._abstract_fn = fct_shape\n\n\nregister(\n    copy_max_dimensions, lambda x, y: symbolic_shape(x, y), \"mylib\", \"copy_max_dimensions\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now everything is registered. Let's rewrite the model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class RewrittenModel(torch.nn.Module):\n    def forward(self, x, y, fact):\n        z = torch.ops.mylib.copy_max_dimensions(x, y)\n        return z * fact"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And check it works.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rewritten_model = RewrittenModel()\nx = torch.arange(6).reshape((2, 3))\ny = torch.arange(6).reshape((3, 2)) * 10\nz = rewritten_model(x, y, fact)\nprint(f\"x.shape={x.shape}, y.shape={y.shape}, z.shape={z.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export again\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ep = torch.export.export(\n    rewritten_model,\n    (x, y, fact),\n    dynamic_shapes=({0: DYN, 1: DYN}, {0: DYN, 1: DYN}, {1: DYN}),\n)\nprint(ep)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We check it works.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_ep = ep.module()\nez = model_ep(x, y, fact)\nprint(\"case 1:\", z.shape, ez.shape)\n\nx = torch.arange(4).reshape((2, 2))\ny = torch.arange(9).reshape((3, 3))\ntry:\n    ez = model_ep(x, y, fact)\n    print(\"case 2:\", rewritten_model(x, y, fact).shape, ez.shape)\nexcept Exception as e:\n    print(\"case 2 failed:\", e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Final Check on very different dimension\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x = torch.arange(6 * 8).reshape((6, 8))\ny = torch.arange(10 * 4).reshape((10, 4)) * 10\nfact = torch.arange(8).reshape((1, -1))\n\nprint(\"final case:\", rewritten_model(x, y, fact).shape, model_ep(x, y, fact).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is not perfect as we get an exported program but some logic\nis hidden in a custom operator.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "doc.plot_legend(\n    \"Fixed in torch==2.8\\nmax(d1, d2)\\nwith d1, d2\\ndimensions\", \"dynamic shapes\", \"green\"\n)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}