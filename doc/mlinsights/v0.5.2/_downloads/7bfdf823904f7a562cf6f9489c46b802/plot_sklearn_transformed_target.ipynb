{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Transformed Target\n\n[TransformedTargetRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.compose.TransformedTargetRegressor.html)\nproposes a way to modify the target before training. The notebook\nextends the concept to classifiers.\n\n## TransformedTargetRegressor\n\nLet's reuse the example from [Effect of transforming the targets in regression\nmodel](https://scikit-learn.org/stable/auto_examples/compose/plot_transformed_target.html#sphx-glr-auto-examples-compose-plot-transformed-target-py).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pickle\nfrom pickle import PicklingError\nimport numpy\nfrom numpy.random import randn, random\nfrom pandas import DataFrame\nimport matplotlib.pyplot as plt\nfrom sklearn.compose import TransformedTargetRegressor\nfrom sklearn.metrics import accuracy_score, r2_score\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.exceptions import ConvergenceWarning\nfrom sklearn.utils._testing import ignore_warnings\nfrom mlinsights.mlmodel import TransformedTargetRegressor2\nfrom mlinsights.mlmodel import TransformedTargetClassifier2\n\n\nrnd = random((1000, 1))\nrndn = randn(1000)\nX = rnd[:, :1] * 10\ny = rnd[:, 0] * 5 + rndn / 2\ny = numpy.exp((y + abs(y.min())) / 2)\ny_trans = numpy.log1p(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(14, 4))\nax[0].plot(X[:, 0], y, \".\")\nax[0].set_title(\"Exponential target\")\nax[1].plot(X[:, 0], y_trans, \".\")\nax[1].set_title(\"Exponential target transform with log1p\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "reg = LinearRegression()\nreg.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "regr_trans = TransformedTargetRegressor(\n    regressor=LinearRegression(), func=numpy.log1p, inverse_func=numpy.expm1\n)\nregr_trans.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(14, 4))\nax[0].plot(X[:, 0], y, \".\")\nax[0].plot(X[:, 0], reg.predict(X), \".\", label=\"Regular Linear Regression\")\nax[0].set_title(\"LinearRegression\")\nax[1].plot(X[:, 0], y, \".\")\nax[1].plot(\n    X[:, 0], regr_trans.predict(X), \".\", label=\"Linear Regression with modified target\"\n)\nax[1].set_title(\"TransformedTargetRegressor\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## TransformedTargetRegressor2\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Same thing with *mlinsights*.\n\n\nregr_trans2 = TransformedTargetRegressor2(\n    regressor=LinearRegression(), transformer=\"log1p\"\n)\nregr_trans2.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 3, figsize=(14, 4))\nax[0].plot(X[:, 0], y, \".\")\nax[0].plot(X[:, 0], reg.predict(X), \".\", label=\"Regular Linear Regression\")\nax[0].set_title(\"LinearRegression\")\nax[1].plot(X[:, 0], y, \".\")\nax[1].plot(\n    X[:, 0], regr_trans.predict(X), \".\", label=\"Linear Regression with modified target\"\n)\nax[1].set_title(\"TransformedTargetRegressor\")\nax[2].plot(X[:, 0], y, \".\")\nax[2].plot(\n    X[:, 0], regr_trans2.predict(X), \".\", label=\"Linear Regression with modified target\"\n)\nax[2].set_title(\"TransformedTargetRegressor2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It works the same way except the user does not have to specify the\ninverse function.\n\n## Why another?\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "by1 = pickle.dumps(regr_trans)\nby2 = pickle.dumps(regr_trans2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tr1 = pickle.loads(by1)\ntr2 = pickle.loads(by2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "numpy.max(numpy.abs(tr1.predict(X) - tr2.predict(X)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Well, to be honest, I did not expect numpy functions to be pickable.\nLambda functions are not.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "regr_trans3 = TransformedTargetRegressor(\n    regressor=LinearRegression(),\n    func=lambda x: numpy.log1p(x),\n    inverse_func=numpy.expm1,\n)\nregr_trans3.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "try:\n    pickle.dumps(regr_trans3)\nexcept PicklingError as e:\n    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Classifier and classes permutation\n\nOne question I get sometimes from my students is: regression or\nclassification?\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data = load_iris()\nX, y = data.data, data.target\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "reg = LinearRegression()\nreg.fit(X_train, y_train)\nlog = LogisticRegression()\nlog.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "r2_score(y_test, reg.predict(X_test)), r2_score(y_test, log.predict(X_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The accuracy does not work on the regression output as it produces\nfloat.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "try:\n    accuracy_score(y_test, reg.predict(X_test)), accuracy_score(\n        y_test, log.predict(X_test)\n    )\nexcept ValueError as e:\n    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on that figure, a regression model would be better than a\nclassification model on a problem which is known to be a classification\nproblem. Let's play a little bit.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "@ignore_warnings(category=(ConvergenceWarning,))\ndef evaluation():\n    rnd = []\n    perf_reg = []\n    perf_clr = []\n    for rs in range(200):\n        rnd.append(rs)\n        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=rs)\n        reg = LinearRegression()\n        reg.fit(X_train, y_train)\n        log = LogisticRegression()\n        log.fit(X_train, y_train)\n        perf_reg.append(r2_score(y_test, reg.predict(X_test)))\n        perf_clr.append(r2_score(y_test, log.predict(X_test)))\n    return rnd, perf_reg, perf_clr\n\n\nrnd, perf_reg, perf_clr = evaluation()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(12, 4))\nax.plot(rnd, perf_reg, label=\"regression\")\nax.plot(rnd, perf_clr, label=\"classification\")\nax.set_title(\"Comparison between regression and classificaton\\non the same problem\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Difficult to say. Knowing the expected value is an integer. Let's round\nthe prediction made by the regression which is known to be integer.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def float2int(y):\n    return numpy.int32(y + 0.5)\n\n\nfct2float2int = numpy.vectorize(float2int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "@ignore_warnings(category=(ConvergenceWarning,))\ndef evaluation2():\n    rnd = []\n    perf_reg = []\n    perf_clr = []\n    acc_reg = []\n    acc_clr = []\n    for rs in range(50):\n        rnd.append(rs)\n        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=rs)\n        reg = LinearRegression()\n        reg.fit(X_train, y_train)\n        log = LogisticRegression()\n        log.fit(X_train, y_train)\n        perf_reg.append(r2_score(y_test, float2int(reg.predict(X_test))))\n        perf_clr.append(r2_score(y_test, log.predict(X_test)))\n        acc_reg.append(accuracy_score(y_test, float2int(reg.predict(X_test))))\n        acc_clr.append(accuracy_score(y_test, log.predict(X_test)))\n    return (\n        numpy.array(rnd),\n        numpy.array(perf_reg),\n        numpy.array(perf_clr),\n        numpy.array(acc_reg),\n        numpy.array(acc_clr),\n    )\n\n\nrnd2, perf_reg2, perf_clr2, acc_reg2, acc_clr2 = evaluation2()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(14, 4))\nax[0].plot(rnd2, perf_reg2, label=\"regression\")\nax[0].plot(rnd2, perf_clr2, label=\"classification\")\nax[0].set_title(\n    \"Comparison between regression and classificaton\\non the same problem with r2_score\"\n)\nax[1].plot(rnd2, acc_reg2, label=\"regression\")\nax[1].plot(rnd2, acc_clr2, label=\"classification\")\nax[1].set_title(\n    \"Comparison between regression and classificaton\\n\"\n    \"on the same problem with accuracy_score\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pretty visually indecisive.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "numpy.sign(perf_reg2 - perf_clr2).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "numpy.sign(acc_reg2 - acc_clr2).sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As strange as it seems to be, the regression wins on Iris data.\n\nBut... There is always a but\u2026\n\n## The but...\n\nThere is one tiny difference between regression and classification.\nClassification is immune to a permutation of the label.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data = load_iris()\nX, y = data.data, data.target\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "reg = LinearRegression()\nreg.fit(X_train, y_train)\nlog = LogisticRegression()\nlog.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "(\n    r2_score(y_test, fct2float2int(reg.predict(X_test))),\n    r2_score(y_test, log.predict(X_test)),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's permute between 1 and 2.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def permute(y):\n    y2 = y.copy()\n    y2[y == 1] = 2\n    y2[y == 2] = 1\n    return y2\n\n\ny_train_permuted = permute(y_train)\ny_test_permuted = permute(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "regp = LinearRegression()\nregp.fit(X_train, y_train_permuted)\nlogp = LogisticRegression()\nlogp.fit(X_train, y_train_permuted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "(\n    r2_score(y_test_permuted, fct2float2int(regp.predict(X_test))),\n    r2_score(y_test_permuted, logp.predict(X_test)),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The classifer produces almost the same performance, the regressor seems\noff. Let's check that it is just luck.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rows = []\nfor _i in range(10):\n    regpt = TransformedTargetRegressor2(LinearRegression(), transformer=\"permute\")\n    regpt.fit(X_train, y_train)\n    logpt = TransformedTargetClassifier2(\n        LogisticRegression(max_iter=200), transformer=\"permute\"\n    )\n    logpt.fit(X_train, y_train)\n    rows.append(\n        {\n            \"reg_perm\": regpt.transformer_.permutation_,\n            \"reg_score\": r2_score(y_test, fct2float2int(regpt.predict(X_test))),\n            \"log_perm\": logpt.transformer_.permutation_,\n            \"log_score\": r2_score(y_test, logpt.predict(X_test)),\n        }\n    )\n\ndf = DataFrame(rows)\ndf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The classifier produces a constant performance, the regressor is not.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}