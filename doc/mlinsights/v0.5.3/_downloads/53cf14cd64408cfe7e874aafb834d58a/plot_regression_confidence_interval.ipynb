{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Regression with confidence interval\n\nThe notebook computes confidence intervals with\n[bootstrapping](https://en.wikipedia.org/wiki/Bootstrapping_(statistics))\nand [quantile\nregression](https://en.wikipedia.org/wiki/Quantile_regression) on a\nsimple problem.\n\n## Some data\n\nThe data follows the formula:\n$y = \\frac{X}{2} + 2 + \\epsilon_1 + \\eta \\epsilon_2$. Noises\nfollows the laws $\\epsilon_1 \\sim \\mathcal{N}(0, 0.2)$,\n$\\epsilon_2 \\sim \\mathcal{N}(1, 1)$,\n$\\eta \\sim \\mathcal{B}(2, 0.0.5)$. The second part of the noise\nadds some bigger noise but not always.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy\nfrom numpy.random import binomial, rand, randn\nimport pandas\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import (\n    RBF,\n    ConstantKernel as C,\n    WhiteKernel,\n)\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom mlinsights.mlmodel import IntervalRegressor, QuantileLinearRegression\n\n\nN = 200\nX = rand(N, 1) * 2\neps = randn(N, 1) * 0.2\neps2 = randn(N, 1) + 1\nbin = binomial(2, 0.05, size=(N, 1))\ny = (0.5 * X + eps + 2 + eps2 * bin).ravel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(4, 4))\nax.plot(X, y, \".\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Confidence interval with a linear regression\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# The object fits many times the same learner, every training is done on a\n# resampling of the training dataset.\n\n\nlin = IntervalRegressor(LinearRegression())\nlin.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sorted_X = numpy.array(list(sorted(X_test)))\npred = lin.predict(sorted_X)\nbootstrapped_pred = lin.predict_sorted(sorted_X)\nmin_pred = bootstrapped_pred[:, 0]\nmax_pred = bootstrapped_pred[:, bootstrapped_pred.shape[1] - 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(4, 4))\nax.plot(X_test, y_test, \".\", label=\"raw\")\nax.plot(sorted_X, pred, label=\"prediction\")\nax.plot(sorted_X, min_pred, \"--\", label=\"min\")\nax.plot(sorted_X, max_pred, \"--\", label=\"max\")\nax.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Higher confidence interval\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# It is possible to use smaller resample of the training dataset or we can\n# increase the number of resamplings.\n\n\nlin2 = IntervalRegressor(LinearRegression(), alpha=0.3)\nlin2.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "lin3 = IntervalRegressor(LinearRegression(), n_estimators=50)\nlin3.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pred2 = lin2.predict(sorted_X)\nbootstrapped_pred2 = lin2.predict_sorted(sorted_X)\nmin_pred2 = bootstrapped_pred2[:, 0]\nmax_pred2 = bootstrapped_pred2[:, bootstrapped_pred2.shape[1] - 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pred3 = lin3.predict(sorted_X)\nbootstrapped_pred3 = lin3.predict_sorted(sorted_X)\nmin_pred3 = bootstrapped_pred3[:, 0]\nmax_pred3 = bootstrapped_pred3[:, bootstrapped_pred3.shape[1] - 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 3, figsize=(12, 4))\nax[0].plot(X_test, y_test, \".\", label=\"raw\")\nax[0].plot(sorted_X, pred, label=\"prediction\")\nax[0].plot(sorted_X, min_pred, \"--\", label=\"min\")\nax[0].plot(sorted_X, max_pred, \"--\", label=\"max\")\nax[0].legend()\nax[0].set_title(\"alpha=%f\" % lin.alpha)\nax[1].plot(X_test, y_test, \".\", label=\"raw\")\nax[1].plot(sorted_X, pred2, label=\"prediction\")\nax[1].plot(sorted_X, min_pred2, \"--\", label=\"min\")\nax[1].plot(sorted_X, max_pred2, \"--\", label=\"max\")\nax[1].set_title(\"alpha=%f\" % lin2.alpha)\nax[1].legend()\nax[2].plot(X_test, y_test, \".\", label=\"raw\")\nax[2].plot(sorted_X, pred3, label=\"prediction\")\nax[2].plot(sorted_X, min_pred3, \"--\", label=\"min\")\nax[2].plot(sorted_X, max_pred3, \"--\", label=\"max\")\nax[2].set_title(\"n_estimators=%d\" % lin3.n_estimators)\nax[2].legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## With decision trees\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tree = IntervalRegressor(DecisionTreeRegressor(min_samples_leaf=10))\ntree.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pred_tree = tree.predict(sorted_X)\nb_pred_tree = tree.predict_sorted(sorted_X)\nmin_pred_tree = b_pred_tree[:, 0]\nmax_pred_tree = b_pred_tree[:, b_pred_tree.shape[1] - 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(4, 4))\nax.plot(X_test, y_test, \".\", label=\"raw\")\nax.plot(sorted_X, pred_tree, label=\"prediction\")\nax.plot(sorted_X, min_pred_tree, \"--\", label=\"min\")\nax.plot(sorted_X, max_pred_tree, \"--\", label=\"max\")\nax.set_title(\"Interval with trees\")\nax.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In that case, the prediction is very similar to the one a random forest\nwould produce as it is an average of the predictions made by 10 trees.\n\n## Regression quantile\n\nThe last way tries to fit two regressions for quantiles 0.05 and 0.95.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "m = QuantileLinearRegression()\nq1 = QuantileLinearRegression(quantile=0.05)\nq2 = QuantileLinearRegression(quantile=0.95)\nfor model in [m, q1, q2]:\n    model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(4, 4))\nax.plot(X_test, y_test, \".\", label=\"raw\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for label, model in [(\"med\", m), (\"q0.05\", q1), (\"q0.95\", q2)]:\n    p = model.predict(sorted_X)\n    ax.plot(sorted_X, p, label=label)\nax.set_title(\"Quantile Regression\")\nax.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With a non linear model\u2026 but the model *QuantileMLPRegressor* only\nimplements the regression with quantile 0.5.\n\n## With seaborn\n\nIt uses a theoritical way to compute the confidence interval by\ncomputing the confidence interval on the parameters first.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df_train = pandas.DataFrame(dict(X=X_train.ravel(), y=y_train))\ng = sns.jointplot(x=\"X\", y=\"y\", data=df_train, kind=\"reg\", color=\"m\", height=7)\ng.ax_joint.plot(X_test, y_test, \"ro\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## GaussianProcessRegressor\n\nLast option with this example [Gaussian Processes regression: basic\nintroductory\nexample](https://scikit-learn.org/stable/auto_examples/gaussian_process/plot_gpr_noisy_targets.html)\nwhich computes the standard deviation for every prediction. It can then\nbe used to show an interval confidence.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "kernel = C(1.0, (1e-3, 1e3)) * RBF(10, (1e-2, 1e2)) + WhiteKernel()\ngp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9)\ngp.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "y_pred, sigma = gp.predict(sorted_X, return_std=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(12, 4))\nax.plot(X_test, y_test, \".\", label=\"raw\")\nax.plot(sorted_X, y_pred, label=\"prediction\")\nax.plot(sorted_X, y_pred + sigma * 1.96, \"b--\", label=\"q0.95\")\nax.plot(sorted_X, y_pred - sigma * 1.96, \"b--\", label=\"q0.95\")\nax.set_title(\"Confidence intervalle with GaussianProcessRegressor\")\nax.legend()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}