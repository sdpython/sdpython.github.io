{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Traceable n-grams with tf-idf\n\nThe notebook looks into the way n-grams are stored in\n[CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)\nand\n[TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer)\nand how the current storage (<= 0.21) is ambiguous in some cases.\n\n## Example with CountVectorizer\n\n### scikit-learn version\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom mlinsights.mlmodel.sklearn_text import (\n    TraceableCountVectorizer,\n    TraceableTfidfVectorizer,\n)\n\n\ncorpus = numpy.array(\n    [\n        \"This is the first document.\",\n        \"This document is the second document.\",\n        \"Is this the first document?\",\n        \"\",\n    ]\n).reshape((4,))\n\nmod1 = CountVectorizer(ngram_range=(1, 2))\nmod1.fit(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mod1.transform(corpus).todense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mod1.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "corpus = numpy.array(\n    [\n        \"This is the first document.\",\n        \"This document is the second document.\",\n        \"Is this the first document?\",\n        \"\",\n    ]\n).reshape((4,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mod2 = TraceableCountVectorizer(ngram_range=(1, 2))\nmod2.fit(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mod2.transform(corpus).todense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mod2.vocabulary_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The new class does the exact same thing but keeps n-grams in a more\nexplicit form. The original form as a string is sometimes ambiguous as\nnext example shows.\n\n## Funny example with TfidfVectorizer\n\n### scikit-learn version\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "corpus = numpy.array(\n    [\n        \"This is the first document.\",\n        \"This document is the second document.\",\n        \"Is this the first document?\",\n        \"\",\n    ]\n).reshape((4,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mod1 = TfidfVectorizer(ngram_range=(1, 2), token_pattern=\"[a-zA-Z ]{1,4}\")\nmod1.fit(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mod1.transform(corpus).todense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mod1.vocabulary_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### mlinsights version\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mod2 = TraceableTfidfVectorizer(ngram_range=(1, 2), token_pattern=\"[a-zA-Z ]{1,4}\")\nmod2.fit(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mod2.transform(corpus).todense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mod2.vocabulary_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As you can see, the original 30th n-grams ``'t is  the'`` is a little\nbut ambiguous. It is in fact ``('t is', ' the')`` as the\n*TraceableTfidfVectorizer* lets you know. The original form could have\nbeen ``('t', 'is  the')``, ``('t is', '  the')``, ``('t is ', ' the')``,\n``('t is  ', 'the')``, ``('t', 'is  ', 'the')``\\ \u2026 The regular\nexpression gives some insights but not some information which can be\neasily used to guess the right one.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}