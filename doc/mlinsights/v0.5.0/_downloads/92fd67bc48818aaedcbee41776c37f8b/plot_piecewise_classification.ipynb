{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Piecewise classification with scikit-learn predictors\n\nPiecewise regression is easier to understand but the concept can be\nextended to classification. That's what this notebook explores.\n\n\n\n## Iris dataset and first logistic regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport seaborn\nimport numpy\nimport pandas\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.preprocessing import KBinsDiscretizer\nfrom sklearn.metrics import auc, roc_curve\nfrom mlinsights.mlmodel import PiecewiseClassifier\n\niris = datasets.load_iris()\nX = iris.data[:, :2]  # we only take the first two features.\nY = iris.target\nX_train, X_test, y_train, y_test = train_test_split(X, Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def graph(X, Y, model):\n    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n    h = 0.02  # step size in the mesh\n    xx, yy = numpy.meshgrid(\n        numpy.arange(x_min, x_max, h), numpy.arange(y_min, y_max, h)\n    )\n    Z = model.predict(numpy.c_[xx.ravel(), yy.ravel()])\n    Z = Z.reshape(xx.shape)\n\n    # Put the result into a color plot\n    fig, ax = plt.subplots(1, 1, figsize=(4, 3))\n    ax.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n\n    # Plot also the training points\n    ax.scatter(X[:, 0], X[:, 1], c=Y, edgecolors=\"k\", cmap=plt.cm.Paired)\n    ax.set_xlabel(\"Sepal length\")\n    ax.set_ylabel(\"Sepal width\")\n\n    ax.set_xlim(xx.min(), xx.max())\n    ax.set_ylim(yy.min(), yy.max())\n    ax.set_xticks(())\n    ax.set_yticks(())\n    return ax\n\n\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\nax = graph(X_test, y_test, logreg)\nax.set_title(\"LogisticRegression\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Piecewise classication\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dummy = DummyClassifier(strategy=\"most_frequent\")\npiece4 = PiecewiseClassifier(KBinsDiscretizer(n_bins=2), estimator=dummy, verbose=True)\npiece4.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We look into the bucket given to each point.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "bucket = piece4.transform_bins(X_test)\ndf = pandas.DataFrame(X_test, columns=(\"x1\", \"x2\"))\ndf[\"bucket\"] = bucket\ndf[\"label\"] = y_test\ndf = df.set_index(bucket)\ndf.head(n=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ax = seaborn.scatterplot(x=\"x1\", y=\"x2\", hue=\"bucket\", data=df, palette=\"Set1\", s=400)\nseaborn.scatterplot(\n    x=\"x1\", y=\"x2\", hue=\"label\", data=df, palette=\"Set1\", marker=\"o\", ax=ax, s=100\n)\nax.set_title(\"buckets\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see there are four buckets. Two buckets only contains one label. The\ndummy classifier maps every bucket to the most frequent class in the\nbucket.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ax = graph(X_test, y_test, piece4)\nax.set_title(\"Piecewise Classification\\n4 buckets\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can increase the number of buckets.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dummy = DummyClassifier(strategy=\"most_frequent\")\npiece9 = PiecewiseClassifier(KBinsDiscretizer(n_bins=3), estimator=dummy, verbose=True)\npiece9.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ax = graph(X_test, y_test, piece9)\nax.set_title(\"Piecewise Classification\\n9 buckets\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's compute the ROC curve.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_roc_curve(models, X, y):\n    if not isinstance(models, dict):\n        return plot_roc_curve({models.__class__.__name__: models}, X, y)\n\n    ax = None\n    colors = \"bgrcmyk\"\n    for ic, (name, model) in enumerate(models.items()):\n        fpr, tpr, roc_auc = dict(), dict(), dict()\n        nb = len(model.classes_)\n        y_score = model.predict_proba(X)\n        for i in range(nb):\n            c = model.classes_[i]\n            fpr[i], tpr[i], _ = roc_curve(y_test == c, y_score[:, i])\n            roc_auc[i] = auc(fpr[i], tpr[i])\n\n        if ax is None:\n            lw = 2\n            _, ax = plt.subplots(1, nb, figsize=(4 * nb, 4))\n            for i in range(nb):\n                ax[i].plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n        plotname = \"\".join(c for c in name if \"A\" <= c <= \"Z\" or \"0\" <= c <= \"9\")\n        for i in range(nb):\n            ax[i].plot(\n                fpr[i],\n                tpr[i],\n                color=colors[ic],\n                lw=lw,\n                label=\"%0.2f %s\" % (roc_auc[i], plotname),\n            )\n            ax[i].set_title(\"class {}\".format(model.classes_[i]))\n    for k in range(ax.shape[0]):\n        ax[k].legend()\n    return ax\n\n\nplot_roc_curve({\"LR\": logreg, \"P4\": piece4, \"P9\": piece9}, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's use the decision tree to create buckets.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dummy = DummyClassifier(strategy=\"most_frequent\")\npieceT = PiecewiseClassifier(\"tree\", estimator=dummy, verbose=True)\npieceT.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ax = graph(X_test, y_test, pieceT)\nax.set_title(\"Piecewise Classification\\n%d buckets (tree)\" % len(pieceT.estimators_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot_roc_curve({\"LR\": logreg, \"P4\": piece4, \"P9\": piece9, \"DT\": pieceT}, X_test, y_test)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}