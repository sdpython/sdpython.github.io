{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Fuse Tranpose and Cast on CUDA\n\nThis configuration happens in a :epkg:`Llama` model.\n\n::\n\n    output = Cast(Transpose(X), to=FLOAT16)\n\nWhere the shapes are:\n\n* X: 4096,4096\n\n## Transpose + Cast\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from onnx_extended.args import get_parsed_args\n\nscript_args = get_parsed_args(\n    \"plot_op_transpose_2d_cast\",\n    description=__doc__,\n    config=(\n        \"small\",\n        \"small, short optimization (default), \"\n        \"medium for medium sizes, \"\n        \"large for big sizes\",\n        \"llama for a specific case on llama\",\n    ),\n    warmup=3,\n    repeat=5,\n    itype=(10, \"1 or 10 for float or float16\"),\n    expose=\"config,itype,warmup,repeat\",\n)\n\nimport time\nimport numpy as np\nfrom numpy.testing import assert_almost_equal\nfrom pandas import DataFrame\nfrom tqdm import tqdm\nimport onnx.helper as oh\nfrom onnx import TensorProto\nfrom onnx_array_api.plotting.text_plot import onnx_simple_text_plot\n\nitype = script_args.itype\ndtype = np.float32 if itype == TensorProto.FLOAT else np.float16\nconfig = script_args.config\nprint(f\"config={config}\")\nprint(f\"itype={itype}, dtype={dtype}\")\n\nif config == \"small\":\n    sizes = (256, 512, 1024)\nelif config == \"medium\":\n    sizes = (512, 1024, 2048)\nelif config == \"large\":\n    sizes = (1024, 2048, 4096, 8192)\nelif config == \"llama\":\n    sizes = (2048, 4096, 8192)\nelse:\n    try:\n        sizes = list(map(int, config.split(\",\")))\n    except (ValueError, TypeError) as e:\n        raise AssertionError(f\"Unexpected config value {config!r}.\") from e\n\n\ndef get_model(fused=False, itype=TensorProto.FLOAT):\n    iitype = TensorProto.FLOAT if itype == TensorProto.FLOAT16 else TensorProto.FLOAT16\n    suffix = \"32\" if itype == TensorProto.FLOAT else \"16\"\n    if fused:\n        nodes = [\n            oh.make_node(\n                f\"Transpose2DCastFP{suffix}\",\n                [\"X\"],\n                [\"Y\"],\n                domain=\"onnx_extended.ortops.optim.cuda\",\n            )\n        ]\n    else:\n        nodes = [\n            oh.make_node(\"Transpose\", [\"X\"], [\"xt\"], perm=[1, 0]),\n            oh.make_node(\"Cast\", [\"xt\"], [\"Y\"], to=itype),\n        ]\n    model = oh.make_model(\n        oh.make_graph(\n            nodes,\n            \"g\",\n            [oh.make_tensor_value_info(\"X\", iitype, [\"a\", \"b\"])],\n            [oh.make_tensor_value_info(\"Y\", itype, [\"b\", \"a\"])],\n        ),\n        opset_imports=[\n            oh.make_opsetid(\"\", 18),\n            oh.make_opsetid(\"onnx_extended.ortops.optim.cuda\", 1),\n        ],\n        ir_version=9,\n    )\n    return model\n\n\nmodel = get_model(itype=itype)\nprint(onnx_simple_text_plot(model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Models\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def get_session(model):\n    import onnxruntime\n    from onnx_extended.ortops.optim.cuda import get_ort_ext_libs\n\n    if \"CUDAExecutionProvider\" not in onnxruntime.get_available_providers():\n        return None\n\n    opts = onnxruntime.SessionOptions()\n    opts.register_custom_ops_library(get_ort_ext_libs()[0])\n    sess = onnxruntime.InferenceSession(\n        model.SerializeToString(),\n        opts,\n        providers=[\"CUDAExecutionProvider\", \"CPUExecutionProvider\"],\n    )\n    return sess\n\n\nX = np.random.randn(64, 32).astype(\n    np.float16 if itype == TensorProto.FLOAT else np.float32\n)\nfeeds = dict(X=X)\n\nsess1 = get_session(model)\nif sess1 is not None:\n    for k, v in feeds.items():\n        print(k, v.dtype, v.shape)\n    expected = sess1.run(None, feeds)[0]\n    print(expected[:4, :4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Same model but using the fused op.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = get_model(fused=True, itype=itype)\nprint(onnx_simple_text_plot(model))\n\nsess2 = get_session(model)\nif sess2 is not None:\n    got = sess2.run(None, feeds)[0]\n    print(got[:4, :4])\n    assert_almost_equal(expected, got)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Benchmark\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def move_inputs(sess, feeds):\n    from onnxruntime.capi._pybind_state import (\n        SessionIOBinding,\n        OrtDevice as C_OrtDevice,\n        OrtValue as C_OrtValue,\n    )\n\n    input_names = [i.name for i in sess.get_inputs()]\n\n    ort_device = C_OrtDevice(C_OrtDevice.cuda(), C_OrtDevice.default_memory(), 0)\n\n    feed_ort_value = [\n        (name, C_OrtValue.ortvalue_from_numpy(feeds[name], ort_device))\n        for name in input_names\n    ]\n\n    bind = SessionIOBinding(sess._sess)\n    for name, value in feed_ort_value:\n        bind.bind_input(\n            name, ort_device, feeds[name].dtype, value.shape(), value.data_ptr()\n        )\n    for o in sess.get_outputs():\n        bind.bind_output(o.name, ort_device)\n    return bind, feed_ort_value\n\n\ndef benchmark(\n    sess, sizes, config, label, itype, times_col: int = 1, times_indices: int = 1\n):\n\n    data = []\n    for size in tqdm(sizes):\n\n        X = np.random.randn(size, size).astype(\n            np.float16 if itype == TensorProto.FLOAT else np.float32\n        )\n        feeds = dict(X=X)\n        bind, cuda_feeds = move_inputs(sess, feeds)\n\n        begin = time.perf_counter()\n        for i in range(script_args.warmup):\n            # sess.run(None, feeds)\n            sess._sess.run_with_iobinding(bind, None)\n        warmup = time.perf_counter() - begin\n\n        times = []\n        for i in range(script_args.repeat):\n            begin = time.perf_counter()\n            # sess.run(None, feeds)\n            sess._sess.run_with_iobinding(bind, None)\n            times.append(time.perf_counter() - begin)\n\n        npt = np.array(times)\n        obs = dict(\n            warmup=warmup,\n            time=npt.mean(),\n            std=npt.std(),\n            min=npt.min(),\n            max=npt.max(),\n            repeat=script_args.repeat,\n            size=size,\n            label=label,\n        )\n        data.append(obs)\n    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Not Fused.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if sess1 is not None:\n\n    print(f\"sizes={sizes}\")\n\n    data_nd1 = benchmark(sess1, sizes, script_args.config, \"Not Fused\", itype=itype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fused.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if sess2 is not None:\n\n    data_nd2 = benchmark(sess2, sizes, script_args.config, \"Fused\", itype=itype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if sess2 is not None:\n\n    df = DataFrame(data_nd1 + data_nd2)\n    df.to_csv(\"plot_op_transpose_2d_cast_cuda.csv\", index=False)\n    df.to_csv(\"plot_op_transpose_2d_cast_cuda.xlsx\", index=False)\n    print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pivot.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if sess2 is not None:\n\n    pivot = df.pivot(index=\"size\", columns=\"label\", values=\"time\")\n    pivot[\"ratio\"] = pivot[\"Not Fused\"] / pivot[\"Fused\"]\n    print(pivot)\n\n    ax = pivot[[\"Not Fused\", \"Fused\"]].plot(\n        logx=True,\n        logy=True,\n        title=f\"Not Fused/Fused implementation for Transpose + Cast on CUDA\\nitype={itype}\",\n    )\n    ax.get_figure().savefig(\"plot_op_transpose_2d_cast_cuda.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It seems worth it to combine both operators.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}