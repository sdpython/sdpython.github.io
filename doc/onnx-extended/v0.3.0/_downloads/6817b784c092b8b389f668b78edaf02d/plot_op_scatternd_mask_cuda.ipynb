{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Optimizing Masked ScatterND operator on CUDA\n\nHow to parallelize something like the following?\n\n## ScatterND\n\nThis configuration happens in a :epkg:`Llama` model.\n\n::\n\n    gradient = ScatterND(zeros, indices, updates)\n\nWhere the shapes are:\n\n* zeros: 32000x4096\n* indices: 2x1024x1\n* updates: 2x1024x4096\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from onnx_extended.args import get_parsed_args\n\nscript_args = get_parsed_args(\n    \"plot_op_scatternd_mask_cuda\",\n    description=__doc__,\n    config=(\n        \"small\",\n        \"small, short optimization (default), \"\n        \"medium for medium sizes, \"\n        \"large for big sizes\",\n        \"llama for a specific case on llama\",\n    ),\n    warmup=3,\n    repeat=5,\n    itype=(1, \"1 or 10 for float or float16\"),\n    expose=\"config,itype,warmup,repeat\",\n)\n\nimport time\nimport numpy as np\nfrom numpy.testing import assert_almost_equal\nfrom pandas import DataFrame\nfrom tqdm import tqdm\nimport onnx.helper as oh\nimport onnx.numpy_helper as onh\nfrom onnx import TensorProto\nfrom onnx.reference import ReferenceEvaluator\nfrom onnx.reference.op_run import OpRun\nfrom onnx_array_api.plotting.text_plot import onnx_simple_text_plot\n\nitype = script_args.itype\ndtype = np.float32 if itype == TensorProto.FLOAT else np.float16\nconfig = script_args.config\nprint(f\"config={config}\")\nprint(f\"itype={itype}, dtype={dtype}\")\n\nif config == \"small\":\n    sizes = (256, 512, 1024)\nelif config == \"medium\":\n    sizes = (512, 1024, 2048)\nelif config == \"large\":\n    sizes = (1024, 2048, 4096, 6144, 8192)\nelif config == \"llama\":\n    sizes = (16000, 32000)\nelse:\n    try:\n        sizes = list(map(int, config.split(\",\")))\n    except (ValueError, TypeError) as e:\n        raise AssertionError(f\"Unexpected config value {config!r}.\") from e\n\n\ndef get_model(op_type=\"ScatterND\", itype=TensorProto.FLOAT):\n    indices_shape = [\"i\", \"j\", 1]\n    updates_shape = [\"i\", \"j\", \"b\"]\n    dtype = np.float32 if itype == TensorProto.FLOAT else np.float16\n    if op_type == \"ScatterND\":\n        nodes = [\n            oh.make_node(\n                \"ConstantOfShape\",\n                [\"shape\"],\n                [\"data\"],\n                value=onh.from_array(np.array([0], dtype=dtype)),\n            ),\n            oh.make_node(\n                \"Constant\",\n                [],\n                [\"mone\"],\n                value=onh.from_array(np.array([-1], dtype=np.int64)),\n            ),\n            oh.make_node(\"Equal\", [\"indices\", \"mone\"], [\"eq\"]),\n            oh.make_node(\n                \"Constant\",\n                [],\n                [\"zero\"],\n                value=onh.from_array(np.array([0], dtype=dtype)),\n            ),\n            oh.make_node(\"Where\", [\"eq\", \"zero\", \"updates\"], [\"new_updates\"]),\n            oh.make_node(\n                op_type, [\"data\", \"indices\", \"new_updates\"], [\"Y\"], reduction=\"add\"\n            ),\n        ]\n    elif op_type == \"ScatterNDOfShape\":\n        nodes = [\n            oh.make_node(\n                \"Constant\",\n                [],\n                [\"mone\"],\n                value=onh.from_array(np.array([-1], dtype=np.int64)),\n            ),\n            oh.make_node(\"Equal\", [\"indices\", \"mone\"], [\"eq\"]),\n            oh.make_node(\n                \"Constant\",\n                [],\n                [\"zero\"],\n                value=onh.from_array(np.array([0], dtype=dtype)),\n            ),\n            oh.make_node(\"Where\", [\"eq\", \"zero\", \"updates\"], [\"new_updates\"]),\n            oh.make_node(\n                op_type,\n                [\"shape\", \"indices\", \"new_updates\"],\n                [\"Y\"],\n                strategy=\"optimize\",\n                reduction=\"add\",\n                domain=\"onnx_extended.ortops.optim.cuda\",\n            ),\n        ]\n    elif op_type == \"MaskedScatterNDOfShape\":\n        nodes = [\n            oh.make_node(\n                op_type,\n                [\"shape\", \"indices\", \"updates\"],\n                [\"Y\"],\n                maskedValue=-1,\n                reduction=\"add\",\n                domain=\"onnx_extended.ortops.optim.cuda\",\n            ),\n        ]\n    else:\n        raise ValueError(f\"Unkown value for op_type={op_type!r}.\")\n\n    model = oh.make_model(\n        oh.make_graph(\n            nodes,\n            \"g\",\n            [\n                oh.make_tensor_value_info(\"shape\", TensorProto.INT64, [\"s\"]),\n                oh.make_tensor_value_info(\"indices\", TensorProto.INT64, indices_shape),\n                oh.make_tensor_value_info(\"updates\", itype, updates_shape),\n            ],\n            [oh.make_tensor_value_info(\"Y\", itype, [\"a\", \"b\"])],\n        ),\n        opset_imports=[\n            oh.make_opsetid(\"\", 18),\n            oh.make_opsetid(\"onnx_extended.ortops.optim.cuda\", 1),\n        ],\n        ir_version=9,\n    )\n    return model\n\n\nmodel = get_model()\nprint(onnx_simple_text_plot(model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's see the evaluation by the ReferenceEvaluator for the three\nproposed models.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def _scatter_nd_impl(data, indices, updates, reduction=None, verbose=False):  # type: ignore\n    output = np.copy(data)\n    for i in np.ndindex(indices.shape[:-1]):\n        if verbose:\n            print(f\"updates for i={i}, indices={indices[i]}, updates={updates[i]}\")\n        assert reduction == \"add\", f\"not implemented for reduction={reduction!r}\"\n        output[tuple(indices[i])] += updates[i]\n    return output\n\n\nclass ScatterND(OpRun):\n    def _run(self, data, indices, updates, reduction=None, optimize=None):  # type: ignore\n        y = _scatter_nd_impl(data, indices, updates, reduction=reduction, verbose=True)\n        return (y,)\n\n\nclass ScatterNDOfShape(OpRun):\n    op_domain = \"onnx_extended.ortops.optim.cuda\"\n\n    def _run(self, shape, indices, updates, reduction=None, strategy=None):  # type: ignore\n        data = np.zeros(tuple(shape.tolist()), dtype=updates.dtype)\n        y = _scatter_nd_impl(data, indices, updates, reduction=reduction)\n        return (y,)\n\n\nclass MaskedScatterNDOfShape(OpRun):\n    op_domain = \"onnx_extended.ortops.optim.cuda\"\n\n    def _run(self, shape, indices, updates, reduction=None, maskedValue=None):\n        data = np.zeros(shape, dtype=updates.dtype)\n        new_updates = np.where(indices == maskedValue, 0, updates)\n        y = _scatter_nd_impl(data, indices, new_updates, reduction=reduction)\n        return (y,)\n\n\nshape = np.array([5, 7], dtype=np.int64)\nindices = np.ones((2, 10, 1)).astype(np.int64)\nindices[0, ::2, 0] = 3\nindices[1, ::2, 0] = 1\nindices[:, 1::4, 0] = -1\nupdates = np.ones((2, 10, 7)).astype(dtype)\nfeeds = {\"shape\": shape, \"indices\": indices, \"updates\": updates}\nbaseline = None\n\nfor op_type in [\"ScatterND\", \"ScatterNDOfShape\", \"MaskedScatterNDOfShape\"]:\n    print(\"-----------------------------------------------\")\n    print(f\"op_type={op_type}\")\n    model = get_model(op_type)\n    print(onnx_simple_text_plot(model))\n\n    ref = ReferenceEvaluator(\n        model, new_ops=[ScatterND, ScatterNDOfShape, MaskedScatterNDOfShape]\n    )\n    got = ref.run(None, feeds)[0]\n    print(got)\n\n    if baseline is None:\n        baseline = got\n    assert_almost_equal(baseline, got)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With onnxruntime\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def get_session(model):\n    import onnxruntime\n    from onnx_extended.ortops.optim.cuda import get_ort_ext_libs\n\n    if \"CUDAExecutionProvider\" not in onnxruntime.get_available_providers():\n        return None\n\n    opts = onnxruntime.SessionOptions()\n    opts.register_custom_ops_library(get_ort_ext_libs()[0])\n    sess = onnxruntime.InferenceSession(\n        model.SerializeToString(),\n        opts,\n        providers=[\"CUDAExecutionProvider\", \"CPUExecutionProvider\"],\n    )\n    return sess\n\n\nfor op_type in [\"ScatterND\", \"ScatterNDOfShape\", \"MaskedScatterNDOfShape\"]:\n    print(\"-----------------------------------------------\")\n    print(f\"op_type={op_type}\")\n    model = get_model(op_type)\n    print(onnx_simple_text_plot(model))\n\n    sess = get_session(model)\n    if sess is not None:\n        got = ref.run(None, feeds)[0]\n        print(got)\n    else:\n        print(\"onnxruntime is not available.\")\n\n    if baseline is None:\n        baseline = got\n    assert_almost_equal(baseline, got)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Benchmark\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def move_inputs(sess, feeds):\n    from onnxruntime.capi._pybind_state import (\n        SessionIOBinding,\n        OrtDevice as C_OrtDevice,\n        OrtValue as C_OrtValue,\n    )\n\n    input_names = [i.name for i in sess.get_inputs()]\n\n    ort_device = C_OrtDevice(C_OrtDevice.cuda(), C_OrtDevice.default_memory(), 0)\n\n    feed_ort_value = [\n        (name, C_OrtValue.ortvalue_from_numpy(feeds[name], ort_device))\n        for name in input_names\n    ]\n\n    bind = SessionIOBinding(sess._sess)\n    for name, value in feed_ort_value:\n        bind.bind_input(\n            name, ort_device, feeds[name].dtype, value.shape(), value.data_ptr()\n        )\n    for o in sess.get_outputs():\n        bind.bind_output(o.name, ort_device)\n    return bind, feed_ort_value\n\n\ndef benchmark(sizes, config, itype, times_col: int = 1, times_indices: int = 1):\n\n    data = []\n    for size in tqdm(sizes):\n\n        if config == \"llama\":\n            # zeros: 32000x4096\n            # indices: 2x1024x1\n            # updates: 2x1024x4096\n            shape = (32000, 4096)\n            shape_indices = (2, size, 1)\n        else:\n            shape = (size, int(size * times_col))\n            shape_indices = (2, int(size * times_indices), 1)\n        shape_updates = (2, shape_indices[1], shape[-1])\n\n        shape = np.array(shape, dtype=np.int64)\n        indices = np.array(\n            [np.random.randint(-1, shape[0]) for _ in range(np.prod(shape_indices))],\n            dtype=np.int64,\n        ).reshape(shape_indices)\n        updates = np.random.randn(*shape_updates).astype(\n            np.float32 if itype == TensorProto.FLOAT else np.float16\n        )\n        feeds = dict(shape=shape, indices=indices, updates=updates)\n\n        for op_type in [\"ScatterND\", \"ScatterNDOfShape\", \"MaskedScatterNDOfShape\"]:\n            model = get_model(op_type)\n            sess = get_session(model)\n            bind, cuda_feeds = move_inputs(sess, feeds)\n            begin = time.perf_counter()\n            for i in range(script_args.warmup):\n                sess._sess.run_with_iobinding(bind, None)\n            warmup = time.perf_counter() - begin\n\n            times = []\n            for i in range(script_args.repeat):\n                begin = time.perf_counter()\n                # sess.run(None, feeds)\n                sess._sess.run_with_iobinding(bind, None)\n                times.append(time.perf_counter() - begin)\n\n            npt = np.array(times)\n            obs = dict(\n                label=op_type,\n                warmup=warmup,\n                time=npt.mean(),\n                std=npt.std(),\n                min=npt.min(),\n                max=npt.max(),\n                repeat=script_args.repeat,\n                size=size,\n            )\n            data.append(obs)\n    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Benchmark.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if sess is not None:\n\n    print(f\"sizes={sizes}\")\n\n    data_nd = benchmark(sizes, script_args.config, itype=itype, times_col=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if sess is not None:\n\n    df = DataFrame(data_nd)\n    df.to_csv(\"plot_op_scatternd_mask_cuda.csv\", index=False)\n    df.to_csv(\"plot_op_scatternd_mask_cuda.xlsx\", index=False)\n    print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pivot.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if sess is not None:\n\n    pivot = df.pivot(index=\"size\", columns=\"label\", values=\"time\")\n    col = pivot[\"ScatterND\"].copy()\n    print(\"Time\")\n    print(pivot)\n    for c in pivot.columns:\n        pivot[c] = col / pivot[c]\n    print(\"Speed up compare to the onnx standaed.\")\n    print(pivot)\n\n    ax = pivot.plot(\n        logx=True,\n        logy=True,\n        title=f\"Optimization for ScatterND on CUDA\\nitype={itype}\",\n    )\n    ax.get_figure().savefig(\"plot_op_scatternd_mask_cuda.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It requires more test to determine when it is better.\nBut the fused operator with mask seems more efficient in any case\ncompare to the fused operator without mask.\nFor big sizes, ScatterND seems very slow as it is using atomic addition.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}