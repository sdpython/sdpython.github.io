<!doctype html>
<html class="no-js" lang="en" data-content_root="../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="Measuring onnxruntime performance against a cython binding" href="plot_bench_cypy_ort.html" /><link rel="prev" title="Examples Gallery" href="index.html" />
        <link rel="prefetch" href="../_static/logo.png" as="image" />

    <!-- Generated with Sphinx 8.1.3 and Furo 2025.07.19 -->
        <title>Measures loading, saving time for an onnx model in python - onnx-extended 0.5.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=25af2a20" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css?v=7f9a90b1" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css?v=4ae1632d" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=8dab3a3b" />
    
    


<style>
  body {
    --color-code-background: #eeffcc;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #2b2b2b;
  --color-code-foreground: #f8f8f2;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #2b2b2b;
  --color-code-foreground: #f8f8f2;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">onnx-extended 0.5.0 documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="../_static/logo.png" alt="Logo"/>
  </div>
  
  <span class="sidebar-brand-text">onnx-extended 0.5.0 documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Contents</span></p>
<ul class="current">
<li class="toctree-l1 has-children"><a class="reference internal" href="../tutorial/index.html">Tutorial</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of Tutorial</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../tutorial/reference_evaluator.html">CReferenceEvaluator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorial/cython_binding.html">Cython Binding of onnxruntime</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorial/custom_ops.html">Custom Kernels for onnxruntime</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../tutorial/ops.html">Focus on operators optimization</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of Focus on operators optimization</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="plot_op_conv_py_vs_c.html">Using C implementation of operator Conv</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_op_conv_denorm.html">How float format has an impact on speed computation</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_bench_gemm_f8.html">Measuring Gemm performance with different input and output tests</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_bench_gemm_ort.html">Measuring performance about Gemm with onnxruntime</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_profile_gemm_ort.html">Profiles a simple onnx graph including a singleGemm</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_op_einsum.html">Compares implementations of Einsum</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_op_mul_cuda.html">Fusing multiplication operators on CUDA</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_op_tree_ensemble_optim.html">TreeEnsemble optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_op_tree_ensemble_sparse.html">TreeEnsemble, dense, and sparse</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../tutorial/many_tools.html">Many Tools to help investigating issues</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of Many Tools to help investigating issues</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../tutorial/external_data.html">External Data and Big Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tutorial/onnx_manipulations.html">Onnx Manipulations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tutorial/quantize.html">Quantization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tutorial/statistics.html">Statistics</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tutorial/profiling.html">Profiling onnxruntime</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tutorial/ort_debug.html">Debug Intermediate Results</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tutorial/old_version.html">Compare multiple versions of onnxruntime</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tutorial/trees.html">Trees</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../tutorial/build.html">Build from source</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of Build from source</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../tutorial/build_cython.html">Build with cython</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tutorial/build_pybind11.html">Build with pybind11</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tutorial/build_cuda.html">Build with CUDA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tutorial/build_ortext.html">Build with onnxruntime</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tutorial/readings.html">Readings</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../tutorial/parallelization.html">Experiments about parallelization</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of Experiments about parallelization</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="plot_bench_cpu.html">Measuring CPU performance</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../command_lines.html">command lines</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api/index.html">API</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle navigation of API</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../api/check.html">onnx_extended.__init__.py</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/ext_test_case.html">onnx_extended.ext_test_case</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/memory_peak.html">onnx_extended.memory_peak</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/helper.html">onnx_extended.helper</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/onnx2/index.html">onnx2</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle navigation of onnx2</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/onnx2/helper.html">helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/onnx2/io_helper.html">io_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/onnx2/parsing.html">Serializing, Parsing Options</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/onnx2/protos.html">protos</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api/ortcy.html">onnx_extended.ortcy</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/ortops.html">onnx_extended.ortops</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle navigation of onnx_extended.ortops</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/ortops_tutorial_cpu.html">onnx_extended.ortops.tutorial.cpu</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/ortops_tutorial_cuda.html">onnx_extended.ortops.tutorial.cuda</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/ortops_optim_cpu.html">onnx_extended.ortops.optim.cpu</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/ortops_optim_cuda.html">onnx_extended.ortops.optim.cuda</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api/plotting.html">onnx_extended.plotting</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/reference.html">onnx_extended.reference</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/validation.html">validation</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle navigation of validation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/validation_cpu.html">validation.cpu</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/validation_cuda.html">validation.cuda</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/validation_sparse.html">validation.bench_trees</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/validation_trees.html">validation.bench_trees</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/tools.html">tools</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle navigation of tools</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/tools_io.html">onnx_extended.tools.onnx_io</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/tools_einsum.html">onnx_extended.tools.einsum</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/tools_graph.html">onnx_extended.tools.graph</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/tools_graph_transformer.html">onnx_extended.tools.graph.onnx_graph_transformer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/tools_inline.html">onnx_extended.tools.onnx_inline</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/tools_nodes.html">onnx_extended.tools.onnx_nodes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/tools_stats.html">onnx_extended.tools.stats_nodes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/tools_other.html">onnx_extended.tools</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../tech/index.html">Technical Details</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><div class="visually-hidden">Toggle navigation of Technical Details</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../tech/install_cuda_wsl.html">Install CUDA on WSL (2)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tech/usefulcmd.html">Useful commands on Linux</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tech/gemm.html">Gemm and storage order</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tech/2023-09-05-glibc.html">2023-09-05 - version GLIBCXX_3.4.30 not found</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../benchmarks.html">ONNX Benchmarks</a></li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="index.html">Examples Gallery</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><div class="visually-hidden">Toggle navigation of Examples Gallery</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2 current current-page"><a class="current reference internal" href="#">Measures loading, saving time for an onnx model in python</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_bench_cpu.html">Measuring CPU performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_op_conv_py_vs_c.html">Using C implementation of operator Conv</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_bench_cypy_ort.html">Measuring onnxruntime performance against a cython binding</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_bench_sparse_access.html">Evaluating random access for sparse</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_op_tfidfvectorizer_sparse.html">Measuring performance of TfIdfVectorizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_bench_gemm_f8.html">Measuring Gemm performance with different input and output tests</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_op_gemm2_cuda.html">Gemm Exploration with CUDA</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_op_transpose_2d_cast_cuda.html">Fuse Tranpose and Cast on CUDA</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_op_einsum.html">Compares implementations of Einsum</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_op_mul_cuda.html">Fusing multiplication operators on CUDA</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_op_conv_denorm.html">How float format has an impact on speed computation</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_op_tree_ensemble_optim.html">TreeEnsemble optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_op_scatternd_cuda.html">Optimizing ScatterND operator on CUDA</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_op_scatternd_mask_cuda.html">Optimizing Masked ScatterND operator on CUDA</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_op_tree_ensemble_sparse.html">TreeEnsemble, dense, and sparse</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_profile_gemm_ort.html">Profiles a simple onnx graph including a singleGemm</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_bench_gemm_ort.html">Measuring performance about Gemm with onnxruntime</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_op_tree_ensemble_implementations.html">Evaluate different implementation of TreeEnsemble</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">More</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../license.html">LICENSE</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="../_sources/auto_examples/plot_onnx2_time.rst" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-auto-examples-plot-onnx2-time-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="measures-loading-saving-time-for-an-onnx-model-in-python">
<span id="l-example-plot-onnx2-time"></span><span id="sphx-glr-auto-examples-plot-onnx2-time-py"></span><h1>Measures loading, saving time for an onnx model in python<a class="headerlink" href="#measures-loading-saving-time-for-an-onnx-model-in-python" title="Link to this heading">Â¶</a></h1>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">onnx</span>
<span class="kn">import</span> <span class="nn">onnx_extended.onnx2</span> <span class="k">as</span> <span class="nn">onnx2</span>


<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onnx_file</span></a></a> <span class="o">=</span> <span class="p">(</span>
    <span class="s2">&quot;dump_test/microsoft_Phi-4-mini-reasoning-onnx-dynamo-ir/&quot;</span>
    <span class="s2">&quot;microsoft_Phi-4-mini-reasoning-onnx-dynamo-ir.onnx&quot;</span>
<span class="p">)</span>
<span class="k">if</span> <span class="ow">not</span> <a href="https://docs.python.org/3/library/os.path.html#os.path.exists" title="os.path.exists" class="sphx-glr-backref-module-os-path sphx-glr-backref-type-py-function"><a href="https://docs.python.org/3/library/os.path.html#os.path.exists" title="os.path.exists" class="sphx-glr-backref-module-os-path sphx-glr-backref-type-py-function"><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span></a></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onnx_file</span></a></a><span class="p">):</span>
    <span class="kn">from</span> <span class="nn">onnx_diagnostic.torch_models.validate</span> <span class="kn">import</span> <span class="n">validate_model</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Creates the model...&quot;</span><span class="p">)</span>

    <span class="n">validate_model</span><span class="p">(</span>
        <span class="s2">&quot;microsoft/Phi-4-mini-reasoning&quot;</span><span class="p">,</span>
        <span class="n">do_run</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">exporter</span><span class="o">=</span><span class="s2">&quot;onnx-dynamo&quot;</span><span class="p">,</span>
        <span class="n">do_same</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">patch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">rewrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">optimization</span><span class="o">=</span><span class="s2">&quot;ir&quot;</span><span class="p">,</span>
        <span class="n">dump_folder</span><span class="o">=</span><span class="s2">&quot;dump_test&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;done.&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Creates the model...
[validate_model] dump into &#39;microsoft_Phi-4-mini-reasoning-onnx-dynamo-ir&#39;
[validate_model] validate model id &#39;microsoft/Phi-4-mini-reasoning&#39;
[validate_model] get dummy inputs with input_options=None...
[validate_model] rewrite=True, patch_kwargs={&#39;patch_transformers&#39;: True, &#39;patch_diffusers&#39;: True, &#39;patch&#39;: True}, stop_if_static=1
[validate_model] exporter=&#39;onnx-dynamo&#39;, optimization=&#39;ir&#39;
[validate_model] dump_folder=&#39;dump_test/microsoft_Phi-4-mini-reasoning-onnx-dynamo-ir&#39;
[validate_model] output_names=None
[get_untrained_model_with_inputs] model_id=&#39;microsoft/Phi-4-mini-reasoning&#39;
[get_untrained_model_with_inputs] use preinstalled &#39;microsoft/Phi-4-mini-reasoning&#39;
[get_untrained_model_with_inputs] architectures=[&#39;Phi3ForCausalLM&#39;]
[get_untrained_model_with_inputs] cls=&#39;Phi3Config&#39;
[get_untrained_model_with_inputs] task=&#39;text-generation&#39;
[get_untrained_model_with_inputs] default config._attn_implementation=None
[get_untrained_model_with_inputs] use fct=&lt;function get_inputs at 0x737cbd9eb880&gt;
[validate_model] --
[validate_model] task=text-generation
[validate_model] size=989.51953125 Mb
[validate_model] n_weights=259.396608 millions parameters
[validate_model] +INPUT input_ids=T7s2x3
[validate_model] +INPUT attention_mask=T7s2x33
[validate_model] +INPUT position_ids=T7s2x3
[validate_model] +INPUT past_key_values=DynamicCache(key_cache=#2[T1s2x8x30x128,T1s2x8x30x128], value_cache=#2[T1s2x8x30x128,T1s2x8x30x128])
[validate_model] +SHAPE input_ids={0:Dim(batch),1:DYN(seq_length)}
[validate_model] +SHAPE attention_mask={0:Dim(batch),1:DYN(cache+seq)}
[validate_model] +SHAPE position_ids={0:Dim(batch),1:DYN(cache+seq)}
[validate_model] +SHAPE past_key_values=#2[#2[{0:Dim(batch),2:DYN(cache_length)},{0:Dim(batch),2:DYN(cache_length)}],#2[{0:Dim(batch),2:DYN(cache_length)},{0:Dim(batch),2:DYN(cache_length)}]]
[validate_model] --
[validate_model] -- run the model inputs=&#39;inputs&#39;...
[validate_model] inputs=dict(input_ids:T7s2x3,attention_mask:T7s2x33,position_ids:T7s2x3,past_key_values:DynamicCache(key_cache=#2[T1s2x8x30x128,T1s2x8x30x128], value_cache=#2[T1s2x8x30x128,T1s2x8x30x128]))
[validate_model] done ([run])
[validate_model] -- run the model inputs=&#39;inputs2&#39;...
[validate_model] inputs2=dict(input_ids:T7s3x4,attention_mask:T7s3x35,position_ids:T7s3x4,past_key_values:DynamicCache(key_cache=#2[T1s3x8x31x128,T1s3x8x31x128], value_cache=#2[T1s3x8x31x128,T1s3x8x31x128]))
[validate_model] done ([run2])
[validate_model] -- export the model with &#39;onnx-dynamo&#39;, optimization=&#39;ir&#39;
[validate_model] applies patches before exporting stop_if_static=1
[torch_export_patches] replace torch.jit.isinstance, torch._dynamo.mark_static_address
[_fix_registration] DynamicCache is unregistered and registered first
[unregister_cache_serialization] unregistered DynamicCache
[register_class_serialization] ---------- register DynamicCache
[_fix_registration] DynamicCache done.
[_fix_registration] BaseModelOutput is unregistered and registered first
[unregister_cache_serialization] unregistered BaseModelOutput
[register_class_serialization] ---------- register BaseModelOutput
[_fix_registration] BaseModelOutput done.
[_fix_registration] UNet2DConditionOutput is unregistered and registered first
[unregister_cache_serialization] unregistered UNet2DConditionOutput
[register_class_serialization] ---------- register UNet2DConditionOutput
[_fix_registration] UNet2DConditionOutput done.
[register_class_serialization] already registered DynamicCache
[register_class_serialization] ---------- register HybridCache
[register_class_serialization] ---------- register MambaCache
[register_class_serialization] ---------- register EncoderDecoderCache
[register_class_serialization] ---------- register SlidingWindowCache
[register_class_serialization] ---------- register StaticCache
[register_class_serialization] already registered UNet2DConditionOutput
[register_class_serialization] already registered BaseModelOutput
[torch_export_patches] sympy.__version__=&#39;1.13.3&#39;
[torch_export_patches] patch sympy
[torch_export_patches] torch.__version__=&#39;2.9.0.dev20250727+cu126&#39;
[torch_export_patches] stop_if_static=1
[torch_export_patches] patch pytorch
[torch_export_patches] modifies shape constraints
[torch_export_patches] assert when a dynamic dimension turns static
[torch_export_patches] replaces ShapeEnv._set_replacement
[torch_export_patches] replaces ShapeEnv._log_guard
[torch_export_patches] transformers.__version__=&#39;4.55.0.dev0&#39;
[patch_module_or_classes] onnx_diagnostic.torch_export_patches.patches.patch_transformers.patched_AttentionMaskConverter:
[patch_module_or_classes] onnx_diagnostic.torch_export_patches.patches.patch_transformers.patched_Gemma2RotaryEmbedding: forward
[patch_module_or_classes] onnx_diagnostic.torch_export_patches.patches.patch_transformers.patched_Gemma3RotaryEmbedding: forward
[patch_module_or_classes] onnx_diagnostic.torch_export_patches.patches.patch_transformers.patched_GemmaRotaryEmbedding: forward
[patch_module_or_classes] onnx_diagnostic.torch_export_patches.patches.patch_transformers.patched_GenerationMixin: _cache_dependant_input_preparation, _cache_dependant_input_preparation_exporting, prepare_inputs_for_generation
[patch_module_or_classes] onnx_diagnostic.torch_export_patches.patches.patch_transformers.patched_IdeficsAttention: forward
[patch_module_or_classes] onnx_diagnostic.torch_export_patches.patches.patch_transformers.patched_IdeficsEmbedding: forward
[patch_module_or_classes] onnx_diagnostic.torch_export_patches.patches.patch_transformers.patched_LlamaRotaryEmbedding: forward
[patch_module_or_classes] onnx_diagnostic.torch_export_patches.patches.patch_transformers.patched_MistralRotaryEmbedding: forward
[patch_module_or_classes] onnx_diagnostic.torch_export_patches.patches.patch_transformers.patched_MixtralRotaryEmbedding: forward
[patch_module_or_classes] onnx_diagnostic.torch_export_patches.patches.patch_transformers.patched_Phi3RotaryEmbedding: forward
[patch_module_or_classes] onnx_diagnostic.torch_export_patches.patches.patch_transformers.patched_Phi4MultimodalRotaryEmbedding: forward
[patch_module_or_classes] onnx_diagnostic.torch_export_patches.patches.patch_transformers.patched_PhiRotaryEmbedding: forward
[patch_module_or_classes] onnx_diagnostic.torch_export_patches.patches.patch_transformers.patched_SamMaskDecoder: forward
[patch_module_or_classes] onnx_diagnostic.torch_export_patches.patches.patch_transformers.patched_SmolLM3RotaryEmbedding: forward
[patch_module_or_classes] function: transformers.models.bart.modeling_bart.eager_attention_forward
[patch_module_or_classes] function: transformers.models.marian.modeling_marian.eager_attention_forward
[patch_module_or_classes] function: transformers.cache_utils.parse_processor_args
[torch_export_patches] patches transformers.masking_utils._vmap_for_bhqkv
[torch_export_patches] patches transformers.masking_utils.eager_mask
[torch_export_patches] done patching
[validate_model] run patched model...
[validate_model] patched inputs=dict(input_ids:T7s2x3,attention_mask:T7s2x33,position_ids:T7s2x3,past_key_values:DynamicCache(key_cache=#2[T1s2x8x30x128,T1s2x8x30x128], value_cache=#2[T1s2x8x30x128,T1s2x8x30x128]))
[validate_model] done (patched run)
[validate_model] patched discrepancies=abs=0, rel=0
[call_torch_export_onnx] exporter=&#39;onnx-dynamo&#39;, optimization=&#39;ir&#39;
[call_torch_export_onnx] args=()
[call_torch_export_onnx] kwargs=dict(input_ids:T7s2x3,attention_mask:T7s2x33,position_ids:T7s2x3,past_key_values:DynamicCache(key_cache=#2[T1s2x8x30x128,T1s2x8x30x128], value_cache=#2[T1s2x8x30x128,T1s2x8x30x128]))
[call_torch_export_onnx] dynamic_shapes=dict(input_ids:{0:Dim(batch),1:DYN(seq_length)},attention_mask:{0:Dim(batch),1:DYN(cache+seq)},position_ids:{0:Dim(batch),1:DYN(cache+seq)},past_key_values:#2[#2[{0:Dim(batch),2:DYN(cache_length)},{0:Dim(batch),2:DYN(cache_length)}],#2[{0:Dim(batch),2:DYN(cache_length)},{0:Dim(batch),2:DYN(cache_length)}]])
[call_torch_export_onnx] export...
[call_torch_export_onnx] export_export_kwargs=dict(dynamo:bool,dynamic_shapes:dict(input_ids:{0:Dim(batch),1:DYN(seq_length)},attention_mask:{0:Dim(batch),1:DYN(cache+seq)},position_ids:{0:Dim(batch),1:DYN(cache+seq)},past_key_values:#2[#2[{0:Dim(batch),2:DYN(cache_length)},{0:Dim(batch),2:DYN(cache_length)}],#2[{0:Dim(batch),2:DYN(cache_length)},{0:Dim(batch),2:DYN(cache_length)}]]))
[torch.onnx] Obtain model graph for `Phi3ForCausalLM([...]` with `torch.export.export(..., strict=False)`...
[_catch_produce_guards_and_solve_constraints] ERROR: produce_guards_and_solve_constraints failed, use SKIP_SOLVE_CONSTRAINTS=0 to avoid skipping
fake_mode=&lt;torch._subclasses.fake_tensor.FakeTensorMode object at 0x737c6caaed20&gt;
dynamic_shapes={&#39;input_ids&#39;: {0: Dim(&#39;batch&#39;, min=1, max=1024), 1: _DimHint(type=&lt;_DimHintType.DYNAMIC: 3&gt;, min=None, max=None, _factory=True)}, &#39;attention_mask&#39;: {0: Dim(&#39;batch&#39;, min=1, max=1024), 1: _DimHint(type=&lt;_DimHintType.DYNAMIC: 3&gt;, min=None, max=None, _factory=True)}, &#39;position_ids&#39;: {0: Dim(&#39;batch&#39;, min=1, max=1024), 1: _DimHint(type=&lt;_DimHintType.DYNAMIC: 3&gt;, min=None, max=None, _factory=True)}, &#39;past_key_values&#39;: [[{0: Dim(&#39;batch&#39;, min=1, max=1024), 2: _DimHint(type=&lt;_DimHintType.DYNAMIC: 3&gt;, min=None, max=None, _factory=True)}, {0: Dim(&#39;batch&#39;, min=1, max=1024), 2: _DimHint(type=&lt;_DimHintType.DYNAMIC: 3&gt;, min=None, max=None, _factory=True)}], [{0: Dim(&#39;batch&#39;, min=1, max=1024), 2: _DimHint(type=&lt;_DimHintType.DYNAMIC: 3&gt;, min=None, max=None, _factory=True)}, {0: Dim(&#39;batch&#39;, min=1, max=1024), 2: _DimHint(type=&lt;_DimHintType.DYNAMIC: 3&gt;, min=None, max=None, _factory=True)}]]}
equalities_inputs=EqualityConstraint(warn_only=False, source_pairs=[(TensorPropertySource(base=LocalSource(local_name=&#39;attention_mask&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0), TensorPropertySource(base=LocalSource(local_name=&#39;input_ids&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0)), (TensorPropertySource(base=LocalSource(local_name=&#39;position_ids&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0), TensorPropertySource(base=LocalSource(local_name=&#39;input_ids&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0)), (TensorPropertySource(base=GetItemSource(base=GetItemSource(base=LocalSource(local_name=&#39;past_key_values&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), index=&#39;key_cache&#39;, index_is_slice=False), index=0, index_is_slice=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0), TensorPropertySource(base=LocalSource(local_name=&#39;input_ids&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0)), (TensorPropertySource(base=GetItemSource(base=GetItemSource(base=LocalSource(local_name=&#39;past_key_values&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), index=&#39;key_cache&#39;, index_is_slice=False), index=1, index_is_slice=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0), TensorPropertySource(base=LocalSource(local_name=&#39;input_ids&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0)), (TensorPropertySource(base=GetItemSource(base=GetItemSource(base=LocalSource(local_name=&#39;past_key_values&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), index=&#39;value_cache&#39;, index_is_slice=False), index=0, index_is_slice=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0), TensorPropertySource(base=LocalSource(local_name=&#39;input_ids&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0)), (TensorPropertySource(base=GetItemSource(base=GetItemSource(base=LocalSource(local_name=&#39;past_key_values&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), index=&#39;value_cache&#39;, index_is_slice=False), index=1, index_is_slice=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0), TensorPropertySource(base=LocalSource(local_name=&#39;input_ids&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0))], derived_equalities=[], phantom_symbols=[], relaxed_sources={TensorPropertySource(base=GetItemSource(base=GetItemSource(base=LocalSource(local_name=&#39;past_key_values&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), index=&#39;value_cache&#39;, index_is_slice=False), index=1, index_is_slice=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=2), TensorPropertySource(base=GetItemSource(base=GetItemSource(base=LocalSource(local_name=&#39;past_key_values&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), index=&#39;key_cache&#39;, index_is_slice=False), index=1, index_is_slice=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=2), TensorPropertySource(base=LocalSource(local_name=&#39;attention_mask&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=1), TensorPropertySource(base=LocalSource(local_name=&#39;input_ids&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=1), TensorPropertySource(base=LocalSource(local_name=&#39;position_ids&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=1), TensorPropertySource(base=GetItemSource(base=GetItemSource(base=LocalSource(local_name=&#39;past_key_values&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), index=&#39;value_cache&#39;, index_is_slice=False), index=0, index_is_slice=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=2), TensorPropertySource(base=GetItemSource(base=GetItemSource(base=LocalSource(local_name=&#39;past_key_values&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), index=&#39;key_cache&#39;, index_is_slice=False), index=0, index_is_slice=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=2)}, _parents={TensorPropertySource(base=LocalSource(local_name=&#39;attention_mask&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0): TensorPropertySource(base=LocalSource(local_name=&#39;input_ids&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0), TensorPropertySource(base=LocalSource(local_name=&#39;position_ids&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0): TensorPropertySource(base=LocalSource(local_name=&#39;input_ids&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0), TensorPropertySource(base=GetItemSource(base=GetItemSource(base=LocalSource(local_name=&#39;past_key_values&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), index=&#39;key_cache&#39;, index_is_slice=False), index=0, index_is_slice=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0): TensorPropertySource(base=LocalSource(local_name=&#39;input_ids&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0), TensorPropertySource(base=GetItemSource(base=GetItemSource(base=LocalSource(local_name=&#39;past_key_values&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), index=&#39;key_cache&#39;, index_is_slice=False), index=1, index_is_slice=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0): TensorPropertySource(base=LocalSource(local_name=&#39;input_ids&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0), TensorPropertySource(base=GetItemSource(base=GetItemSource(base=LocalSource(local_name=&#39;past_key_values&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), index=&#39;value_cache&#39;, index_is_slice=False), index=0, index_is_slice=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0): TensorPropertySource(base=LocalSource(local_name=&#39;input_ids&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0), TensorPropertySource(base=GetItemSource(base=GetItemSource(base=LocalSource(local_name=&#39;past_key_values&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), index=&#39;value_cache&#39;, index_is_slice=False), index=1, index_is_slice=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0): TensorPropertySource(base=LocalSource(local_name=&#39;input_ids&#39;, is_input=False, dynamism=None, is_derefed_cell_contents=False), prop=&lt;TensorProperty.SIZE: 0&gt;, idx=0)}, _defs={})
original_signature=(input_ids: Optional[torch.LongTensor] = None, attention_mask: Optional[torch.Tensor] = None, position_ids: Optional[torch.LongTensor] = None, past_key_values: Optional[transformers.cache_utils.Cache] = None, inputs_embeds: Optional[torch.FloatTensor] = None, labels: Optional[torch.LongTensor] = None, use_cache: Optional[bool] = None, cache_position: Optional[torch.LongTensor] = None, logits_to_keep: Union[int, torch.Tensor] = 0, **kwargs: Unpack[transformers.utils.generic.TransformersKwargs]) -&gt; transformers.modeling_outputs.CausalLMOutputWithPast
_is_torch_jit_trace=False
exc=produce_guards_and_solve_constraints() got an unexpected keyword argument &#39;_is_torch_jit_trace&#39;
gm=&lt;lambda&gt;(
  (true_graph_0): &lt;lambda&gt;()
  (false_graph_0): &lt;lambda&gt;()
)



def forward(self, arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1, arg6_1, arg7_1, arg8_1, arg9_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1, arg20_1, arg21_1, arg22_1):
    embedding = torch.ops.aten.embedding.default(arg14_1, arg16_1, 199999)
    sym_size_int = torch.ops.aten.sym_size.int(arg19_1, 2)
    sym_size_int_1 = torch.ops.aten.sym_size.int(arg16_1, 1)
    add = sym_size_int + sym_size_int_1
    arange = torch.ops.aten.arange.start(sym_size_int, add, device = device(type=&#39;cpu&#39;), pin_memory = False);  add = None
    to = torch.ops.aten.to.device(arg17_1, device(type=&#39;cpu&#39;), torch.bool);  arg17_1 = None
    sym_size_int_2 = torch.ops.aten.sym_size.int(arange, 0)
    add_1 = sym_size_int_2 + sym_size_int;  sym_size_int = None
    arange_1 = torch.ops.aten.arange.default(add_1, device = device(type=&#39;cpu&#39;), pin_memory = False);  add_1 = None
    add_ = torch.ops.aten.add_.Tensor(arange_1, 0)
    sym_size_int_4 = torch.ops.aten.sym_size.int(arg16_1, 0);  arg16_1 = None
    arange_2 = torch.ops.aten.arange.default(sym_size_int_4, device = device(type=&#39;cpu&#39;), pin_memory = False)
    arange_3 = torch.ops.aten.arange.default(1, device = device(type=&#39;cpu&#39;), pin_memory = False)
    sym_size_int_5 = torch.ops.aten.sym_size.int(arange_2, 0)
    sym_size_int_6 = torch.ops.aten.sym_size.int(arange_1, 0);  arange_1 = None
    reshape = torch.ops.aten.reshape.default(arange_2, [-1, 1, 1, 1]);  arange_2 = None
    reshape_1 = torch.ops.aten.reshape.default(arange_3, [1, -1, 1, 1]);  arange_3 = None
    reshape_2 = torch.ops.aten.reshape.default(arange, [1, 1, -1, 1]);  arange = None
    reshape_3 = torch.ops.aten.reshape.default(add_, [1, 1, 1, -1]);  add_ = None
    expand = torch.ops.aten.expand.default(reshape, [sym_size_int_5, 1, sym_size_int_2, sym_size_int_6]);  reshape = None
    expand_1 = torch.ops.aten.expand.default(reshape_1, [sym_size_int_5, 1, sym_size_int_2, sym_size_int_6]);  reshape_1 = expand_1 = None
    expand_2 = torch.ops.aten.expand.default(reshape_2, [sym_size_int_5, 1, sym_size_int_2, sym_size_int_6]);  reshape_2 = None
    expand_3 = torch.ops.aten.expand.default(reshape_3, [sym_size_int_5, 1, sym_size_int_2, sym_size_int_6]);  reshape_3 = sym_size_int_5 = sym_size_int_2 = sym_size_int_6 = None
    new_ones = torch.ops.aten.new_ones.default(expand_2, [], dtype = torch.bool, pin_memory = False)
    new_ones_1 = torch.ops.aten.new_ones.default(expand_2, [], dtype = torch.bool, pin_memory = False)
    sub_1 = torch.ops.aten.sub.Tensor(expand_2, 262144)
    gt_5 = torch.ops.aten.gt.Tensor(expand_3, sub_1);  sub_1 = None
    and_1 = torch.ops.aten.__and__.Tensor(new_ones_1, gt_5);  new_ones_1 = gt_5 = None
    le = torch.ops.aten.le.Tensor(expand_3, expand_2);  expand_2 = None
    and_2 = torch.ops.aten.__and__.Tensor(and_1, le);  and_1 = le = None
    and_3 = torch.ops.aten.__and__.Tensor(new_ones, and_2);  new_ones = and_2 = None
    index = torch.ops.aten.index.Tensor(to, [expand, expand_3]);  to = expand = expand_3 = None
    and_4 = torch.ops.aten.__and__.Tensor(and_3, index);  and_3 = index = None
    _set_grad_enabled = torch._C._set_grad_enabled(False);  _set_grad_enabled = None
    max_1 = torch.ops.aten.max.default(arg18_1)
    add_3 = torch.ops.aten.add.Tensor(max_1, 1);  max_1 = None
    _tensor_constant0 = self._tensor_constant0
    lift_fresh_copy = torch.ops.aten.lift_fresh_copy.default(_tensor_constant0);  _tensor_constant0 = None
    detach_ = torch.ops.aten.detach_.default(lift_fresh_copy);  lift_fresh_copy = None
    arange_4 = torch.ops.aten.arange.start_step(0, 96, 2, dtype = torch.int64, device = device(type=&#39;cpu&#39;), pin_memory = False)
    to_1 = torch.ops.aten.to.dtype(arange_4, torch.float32);  arange_4 = None
    div = torch.ops.aten.div.Tensor(to_1, 96);  to_1 = None
    pow_1 = torch.ops.aten.pow.Scalar(10000.0, div);  div = None
    mul = torch.ops.aten.mul.Tensor(detach_, pow_1);  detach_ = pow_1 = None
    reciprocal = torch.ops.aten.reciprocal.default(mul);  mul = None
    mul_1 = torch.ops.aten.mul.Tensor(reciprocal, 1.0);  reciprocal = None
    _tensor_constant1 = self._tensor_constant1
    to_2 = torch.ops.aten.to.dtype_layout(_tensor_constant1, dtype = torch.float32, layout = torch.strided, device = device(type=&#39;cpu&#39;));  _tensor_constant1 = None
    gt_6 = torch.ops.aten.gt.Scalar(add_3, 4096);  add_3 = None
    item = torch.ops.aten.item.default(gt_6);  gt_6 = None
    true_graph_0 = self.true_graph_0
    false_graph_0 = self.false_graph_0
    cond = torch.ops.higher_order.cond(item, true_graph_0, false_graph_0, (mul_1, to_2));  item = true_graph_0 = false_graph_0 = mul_1 = to_2 = None
    getitem = cond[0];  cond = None
    unsqueeze = torch.ops.aten.unsqueeze.default(getitem, 0);  getitem = None
    unsqueeze_1 = torch.ops.aten.unsqueeze.default(unsqueeze, 2);  unsqueeze = None
    to_3 = torch.ops.aten.to.dtype(unsqueeze_1, torch.float32);  unsqueeze_1 = None
    sym_size_int_7 = torch.ops.aten.sym_size.int(arg18_1, 0)
    expand_4 = torch.ops.aten.expand.default(to_3, [sym_size_int_7, -1, 1]);  to_3 = sym_size_int_7 = None
    to_4 = torch.ops.aten.to.dtype_layout(expand_4, dtype = torch.float32, layout = torch.strided, device = device(type=&#39;cpu&#39;));  expand_4 = None
    unsqueeze_2 = torch.ops.aten.unsqueeze.default(arg18_1, 1);  arg18_1 = None
    slice_1 = torch.ops.aten.slice.Tensor(unsqueeze_2, 2, 0, 9223372036854775807);  unsqueeze_2 = None
    to_5 = torch.ops.aten.to.dtype(slice_1, torch.float32);  slice_1 = None
    _enter_autocast = torch.amp.autocast_mode._enter_autocast(&#39;cpu&#39;, torch.bfloat16, False, False)
    to_6 = torch.ops.aten.to.dtype(to_4, torch.float32);  to_4 = None
    to_7 = torch.ops.aten.to.dtype(to_5, torch.float32);  to_5 = None
    matmul = torch.ops.aten.matmul.default(to_6, to_7);  to_6 = to_7 = None
    transpose = torch.ops.aten.transpose.int(matmul, 1, 2);  matmul = None
    cat = torch.ops.aten.cat.default([transpose, transpose], -1);  transpose = None
    cos = torch.ops.aten.cos.default(cat)
    mul_2 = torch.ops.aten.mul.Tensor(cos, 1.1902380714238083);  cos = None
    sin = torch.ops.aten.sin.default(cat);  cat = None
    mul_3 = torch.ops.aten.mul.Tensor(sin, 1.1902380714238083);  sin = None
    _exit_autocast = torch.amp.autocast_mode._exit_autocast(_enter_autocast);  _enter_autocast = _exit_autocast = None
    to_8 = torch.ops.aten.to.dtype(mul_2, torch.float32);  mul_2 = None
    to_9 = torch.ops.aten.to.dtype(mul_3, torch.float32);  mul_3 = None
    _set_grad_enabled_1 = torch._C._set_grad_enabled(True);  _set_grad_enabled_1 = None
    to_10 = torch.ops.aten.to.dtype(embedding, torch.float32);  embedding = None
    pow_2 = torch.ops.aten.pow.Tensor_Scalar(to_10, 2)
    mean = torch.ops.aten.mean.dim(pow_2, [-1], True);  pow_2 = None
    add_4 = torch.ops.aten.add.Tensor(mean, 1e-05);  mean = None
    rsqrt = torch.ops.aten.rsqrt.default(add_4);  add_4 = None
    mul_4 = torch.ops.aten.mul.Tensor(to_10, rsqrt);  rsqrt = None
    to_11 = torch.ops.aten.to.dtype(mul_4, torch.float32);  mul_4 = None
    mul_5 = torch.ops.aten.mul.Tensor(arg5_1, to_11);  arg5_1 = to_11 = None
    linear = torch.ops.aten.linear.default(mul_5, arg2_1);  mul_5 = arg2_1 = None
    slice_2 = torch.ops.aten.slice.Tensor(linear, 2, 0, 3072)
    slice_3 = torch.ops.aten.slice.Tensor(linear, 2, 3072, 4096)
    slice_4 = torch.ops.aten.slice.Tensor(linear, 2, 4096, 9223372036854775807);  linear = None
    view = torch.ops.aten.view.default(slice_2, [sym_size_int_4, sym_size_int_1, -1, 128]);  slice_2 = None
    transpose_1 = torch.ops.aten.transpose.int(view, 1, 2);  view = None
    view_1 = torch.ops.aten.view.default(slice_3, [sym_size_int_4, sym_size_int_1, -1, 128]);  slice_3 = None
    transpose_2 = torch.ops.aten.transpose.int(view_1, 1, 2);  view_1 = None
    view_2 = torch.ops.aten.view.default(slice_4, [sym_size_int_4, sym_size_int_1, -1, 128]);  slice_4 = None
    transpose_3 = torch.ops.aten.transpose.int(view_2, 1, 2);  view_2 = None
    unsqueeze_3 = torch.ops.aten.unsqueeze.default(to_8, 1)
    unsqueeze_4 = torch.ops.aten.unsqueeze.default(to_9, 1)
    slice_5 = torch.ops.aten.slice.Tensor(transpose_1, 3, 0, 96)
    slice_6 = torch.ops.aten.slice.Tensor(transpose_1, 3, 96, 9223372036854775807);  transpose_1 = None
    slice_7 = torch.ops.aten.slice.Tensor(transpose_2, 3, 0, 96)
    slice_8 = torch.ops.aten.slice.Tensor(transpose_2, 3, 96, 9223372036854775807);  transpose_2 = None
    mul_6 = torch.ops.aten.mul.Tensor(slice_5, unsqueeze_3)
    slice_9 = torch.ops.aten.slice.Tensor(slice_5, 3, 0, 48)
    slice_10 = torch.ops.aten.slice.Tensor(slice_5, 3, 48, 9223372036854775807);  slice_5 = None
    neg = torch.ops.aten.neg.default(slice_10);  slice_10 = None
    cat_1 = torch.ops.aten.cat.default([neg, slice_9], -1);  neg = slice_9 = None
    mul_7 = torch.ops.aten.mul.Tensor(cat_1, unsqueeze_4);  cat_1 = None
    add_5 = torch.ops.aten.add.Tensor(mul_6, mul_7);  mul_6 = mul_7 = None
    cat_2 = torch.ops.aten.cat.default([add_5, slice_6], -1);  add_5 = slice_6 = None
    mul_8 = torch.ops.aten.mul.Tensor(slice_7, unsqueeze_3);  unsqueeze_3 = None
    slice_11 = torch.ops.aten.slice.Tensor(slice_7, 3, 0, 48)
    slice_12 = torch.ops.aten.slice.Tensor(slice_7, 3, 48, 9223372036854775807);  slice_7 = None
    neg_1 = torch.ops.aten.neg.default(slice_12);  slice_12 = None
    cat_3 = torch.ops.aten.cat.default([neg_1, slice_11], -1);  neg_1 = slice_11 = None
    mul_9 = torch.ops.aten.mul.Tensor(cat_3, unsqueeze_4);  cat_3 = unsqueeze_4 = None
    add_6 = torch.ops.aten.add.Tensor(mul_8, mul_9);  mul_8 = mul_9 = None
    cat_4 = torch.ops.aten.cat.default([add_6, slice_8], -1);  add_6 = slice_8 = None
    cat_5 = torch.ops.aten.cat.default([arg19_1, cat_4], -2);  cat_4 = None
    cat_6 = torch.ops.aten.cat.default([arg21_1, transpose_3], -2);  transpose_3 = None
    sym_size_int_9 = torch.ops.aten.sym_size.int(arg19_1, 0);  arg19_1 = None
    unsqueeze_5 = torch.ops.aten.unsqueeze.default(cat_5, 2)
    sym_size_int_10 = torch.ops.aten.sym_size.int(cat_5, 2)
    slice_13 = torch.ops.aten.slice.Tensor(unsqueeze_5, 3, 0, 9223372036854775807);  unsqueeze_5 = None
    expand_5 = torch.ops.aten.expand.default(slice_13, [sym_size_int_9, 8, 3, sym_size_int_10, 128]);  slice_13 = None
    reshape_4 = torch.ops.aten.reshape.default(expand_5, [sym_size_int_9, 24, sym_size_int_10, 128]);  expand_5 = sym_size_int_9 = None
    sym_size_int_11 = torch.ops.aten.sym_size.int(arg21_1, 0);  arg21_1 = None
    unsqueeze_6 = torch.ops.aten.unsqueeze.default(cat_6, 2)
    sym_size_int_12 = torch.ops.aten.sym_size.int(cat_6, 2)
    slice_14 = torch.ops.aten.slice.Tensor(unsqueeze_6, 3, 0, 9223372036854775807);  unsqueeze_6 = None
    expand_6 = torch.ops.aten.expand.default(slice_14, [sym_size_int_11, 8, 3, sym_size_int_12, 128]);  slice_14 = None
    reshape_5 = torch.ops.aten.reshape.default(expand_6, [sym_size_int_11, 24, sym_size_int_12, 128]);  expand_6 = sym_size_int_11 = sym_size_int_12 = None
    slice_15 = torch.ops.aten.slice.Tensor(and_4, 3, None, sym_size_int_10);  sym_size_int_10 = None
    scaled_dot_product_attention = torch.ops.aten.scaled_dot_product_attention.default(cat_2, reshape_4, reshape_5, slice_15, scale = 0.08838834764831845);  cat_2 = reshape_4 = reshape_5 = slice_15 = None
    transpose_4 = torch.ops.aten.transpose.int(scaled_dot_product_attention, 1, 2);  scaled_dot_product_attention = None
    contiguous = torch.ops.aten.contiguous.default(transpose_4);  transpose_4 = None
    reshape_6 = torch.ops.aten.reshape.default(contiguous, [sym_size_int_4, sym_size_int_1, -1]);  contiguous = None
    linear_1 = torch.ops.aten.linear.default(reshape_6, arg1_1);  reshape_6 = arg1_1 = None
    dropout = torch.ops.aten.dropout.default(linear_1, 0.0, False);  linear_1 = None
    add_7 = torch.ops.aten.add.Tensor(to_10, dropout);  to_10 = dropout = None
    to_12 = torch.ops.aten.to.dtype(add_7, torch.float32);  add_7 = None
    pow_3 = torch.ops.aten.pow.Tensor_Scalar(to_12, 2)
    mean_1 = torch.ops.aten.mean.dim(pow_3, [-1], True);  pow_3 = None
    add_8 = torch.ops.aten.add.Tensor(mean_1, 1e-05);  mean_1 = None
    rsqrt_1 = torch.ops.aten.rsqrt.default(add_8);  add_8 = None
    mul_28 = torch.ops.aten.mul.Tensor(to_12, rsqrt_1);  rsqrt_1 = None
    to_13 = torch.ops.aten.to.dtype(mul_28, torch.float32);  mul_28 = None
    mul_29 = torch.ops.aten.mul.Tensor(arg6_1, to_13);  arg6_1 = to_13 = None
    linear_2 = torch.ops.aten.linear.default(mul_29, arg3_1);  mul_29 = arg3_1 = None
    chunk = torch.ops.aten.chunk.default(linear_2, 2, -1);  linear_2 = None
    getitem_1 = chunk[0]
    getitem_2 = chunk[1];  chunk = None
    silu = torch.ops.aten.silu.default(getitem_1);  getitem_1 = None
    mul_30 = torch.ops.aten.mul.Tensor(getitem_2, silu);  getitem_2 = silu = None
    linear_3 = torch.ops.aten.linear.default(mul_30, arg4_1);  mul_30 = arg4_1 = None
    dropout_1 = torch.ops.aten.dropout.default(linear_3, 0.0, False);  linear_3 = None
    add_9 = torch.ops.aten.add.Tensor(to_12, dropout_1);  to_12 = dropout_1 = None
    to_14 = torch.ops.aten.to.dtype(add_9, torch.float32);  add_9 = None
    pow_4 = torch.ops.aten.pow.Tensor_Scalar(to_14, 2)
    mean_2 = torch.ops.aten.mean.dim(pow_4, [-1], True);  pow_4 = None
    add_10 = torch.ops.aten.add.Tensor(mean_2, 1e-05);  mean_2 = None
    rsqrt_2 = torch.ops.aten.rsqrt.default(add_10);  add_10 = None
    mul_31 = torch.ops.aten.mul.Tensor(to_14, rsqrt_2);  rsqrt_2 = None
    to_15 = torch.ops.aten.to.dtype(mul_31, torch.float32);  mul_31 = None
    mul_32 = torch.ops.aten.mul.Tensor(arg11_1, to_15);  arg11_1 = to_15 = None
    linear_4 = torch.ops.aten.linear.default(mul_32, arg8_1);  mul_32 = arg8_1 = None
    slice_16 = torch.ops.aten.slice.Tensor(linear_4, 2, 0, 3072)
    slice_17 = torch.ops.aten.slice.Tensor(linear_4, 2, 3072, 4096)
    slice_18 = torch.ops.aten.slice.Tensor(linear_4, 2, 4096, 9223372036854775807);  linear_4 = None
    view_3 = torch.ops.aten.view.default(slice_16, [sym_size_int_4, sym_size_int_1, -1, 128]);  slice_16 = None
    transpose_5 = torch.ops.aten.transpose.int(view_3, 1, 2);  view_3 = None
    view_4 = torch.ops.aten.view.default(slice_17, [sym_size_int_4, sym_size_int_1, -1, 128]);  slice_17 = None
    transpose_6 = torch.ops.aten.transpose.int(view_4, 1, 2);  view_4 = None
    view_5 = torch.ops.aten.view.default(slice_18, [sym_size_int_4, sym_size_int_1, -1, 128]);  slice_18 = None
    transpose_7 = torch.ops.aten.transpose.int(view_5, 1, 2);  view_5 = None
    unsqueeze_7 = torch.ops.aten.unsqueeze.default(to_8, 1);  to_8 = None
    unsqueeze_8 = torch.ops.aten.unsqueeze.default(to_9, 1);  to_9 = None
    slice_19 = torch.ops.aten.slice.Tensor(transpose_5, 3, 0, 96)
    slice_20 = torch.ops.aten.slice.Tensor(transpose_5, 3, 96, 9223372036854775807);  transpose_5 = None
    slice_21 = torch.ops.aten.slice.Tensor(transpose_6, 3, 0, 96)
    slice_22 = torch.ops.aten.slice.Tensor(transpose_6, 3, 96, 9223372036854775807);  transpose_6 = None
    mul_33 = torch.ops.aten.mul.Tensor(slice_19, unsqueeze_7)
    slice_23 = torch.ops.aten.slice.Tensor(slice_19, 3, 0, 48)
    slice_24 = torch.ops.aten.slice.Tensor(slice_19, 3, 48, 9223372036854775807);  slice_19 = None
    neg_2 = torch.ops.aten.neg.default(slice_24);  slice_24 = None
    cat_7 = torch.ops.aten.cat.default([neg_2, slice_23], -1);  neg_2 = slice_23 = None
    mul_34 = torch.ops.aten.mul.Tensor(cat_7, unsqueeze_8);  cat_7 = None
    add_11 = torch.ops.aten.add.Tensor(mul_33, mul_34);  mul_33 = mul_34 = None
    cat_8 = torch.ops.aten.cat.default([add_11, slice_20], -1);  add_11 = slice_20 = None
    mul_35 = torch.ops.aten.mul.Tensor(slice_21, unsqueeze_7);  unsqueeze_7 = None
    slice_25 = torch.ops.aten.slice.Tensor(slice_21, 3, 0, 48)
    slice_26 = torch.ops.aten.slice.Tensor(slice_21, 3, 48, 9223372036854775807);  slice_21 = None
    neg_3 = torch.ops.aten.neg.default(slice_26);  slice_26 = None
    cat_9 = torch.ops.aten.cat.default([neg_3, slice_25], -1);  neg_3 = slice_25 = None
    mul_36 = torch.ops.aten.mul.Tensor(cat_9, unsqueeze_8);  cat_9 = unsqueeze_8 = None
    add_12 = torch.ops.aten.add.Tensor(mul_35, mul_36);  mul_35 = mul_36 = None
    cat_10 = torch.ops.aten.cat.default([add_12, slice_22], -1);  add_12 = slice_22 = None
    cat_11 = torch.ops.aten.cat.default([arg20_1, cat_10], -2);  cat_10 = None
    cat_12 = torch.ops.aten.cat.default([arg22_1, transpose_7], -2);  transpose_7 = None
    sym_size_int_13 = torch.ops.aten.sym_size.int(arg20_1, 0);  arg20_1 = None
    unsqueeze_9 = torch.ops.aten.unsqueeze.default(cat_11, 2)
    sym_size_int_14 = torch.ops.aten.sym_size.int(cat_11, 2)
    slice_27 = torch.ops.aten.slice.Tensor(unsqueeze_9, 3, 0, 9223372036854775807);  unsqueeze_9 = None
    expand_7 = torch.ops.aten.expand.default(slice_27, [sym_size_int_13, 8, 3, sym_size_int_14, 128]);  slice_27 = None
    reshape_7 = torch.ops.aten.reshape.default(expand_7, [sym_size_int_13, 24, sym_size_int_14, 128]);  expand_7 = sym_size_int_13 = None
    sym_size_int_15 = torch.ops.aten.sym_size.int(arg22_1, 0);  arg22_1 = None
    unsqueeze_10 = torch.ops.aten.unsqueeze.default(cat_12, 2)
    sym_size_int_16 = torch.ops.aten.sym_size.int(cat_12, 2)
    slice_28 = torch.ops.aten.slice.Tensor(unsqueeze_10, 3, 0, 9223372036854775807);  unsqueeze_10 = None
    expand_8 = torch.ops.aten.expand.default(slice_28, [sym_size_int_15, 8, 3, sym_size_int_16, 128]);  slice_28 = None
    reshape_8 = torch.ops.aten.reshape.default(expand_8, [sym_size_int_15, 24, sym_size_int_16, 128]);  expand_8 = sym_size_int_15 = sym_size_int_16 = None
    slice_29 = torch.ops.aten.slice.Tensor(and_4, 3, None, sym_size_int_14);  and_4 = sym_size_int_14 = None
    scaled_dot_product_attention_1 = torch.ops.aten.scaled_dot_product_attention.default(cat_8, reshape_7, reshape_8, slice_29, scale = 0.08838834764831845);  cat_8 = reshape_7 = reshape_8 = slice_29 = None
    transpose_8 = torch.ops.aten.transpose.int(scaled_dot_product_attention_1, 1, 2);  scaled_dot_product_attention_1 = None
    contiguous_1 = torch.ops.aten.contiguous.default(transpose_8);  transpose_8 = None
    reshape_9 = torch.ops.aten.reshape.default(contiguous_1, [sym_size_int_4, sym_size_int_1, -1]);  contiguous_1 = sym_size_int_4 = sym_size_int_1 = None
    linear_5 = torch.ops.aten.linear.default(reshape_9, arg7_1);  reshape_9 = arg7_1 = None
    dropout_2 = torch.ops.aten.dropout.default(linear_5, 0.0, False);  linear_5 = None
    add_13 = torch.ops.aten.add.Tensor(to_14, dropout_2);  to_14 = dropout_2 = None
    to_16 = torch.ops.aten.to.dtype(add_13, torch.float32);  add_13 = None
    pow_5 = torch.ops.aten.pow.Tensor_Scalar(to_16, 2)
    mean_3 = torch.ops.aten.mean.dim(pow_5, [-1], True);  pow_5 = None
    add_14 = torch.ops.aten.add.Tensor(mean_3, 1e-05);  mean_3 = None
    rsqrt_3 = torch.ops.aten.rsqrt.default(add_14);  add_14 = None
    mul_59 = torch.ops.aten.mul.Tensor(to_16, rsqrt_3);  rsqrt_3 = None
    to_17 = torch.ops.aten.to.dtype(mul_59, torch.float32);  mul_59 = None
    mul_60 = torch.ops.aten.mul.Tensor(arg12_1, to_17);  arg12_1 = to_17 = None
    linear_6 = torch.ops.aten.linear.default(mul_60, arg9_1);  mul_60 = arg9_1 = None
    chunk_1 = torch.ops.aten.chunk.default(linear_6, 2, -1);  linear_6 = None
    getitem_3 = chunk_1[0]
    getitem_4 = chunk_1[1];  chunk_1 = None
    silu_1 = torch.ops.aten.silu.default(getitem_3);  getitem_3 = None
    mul_61 = torch.ops.aten.mul.Tensor(getitem_4, silu_1);  getitem_4 = silu_1 = None
    linear_7 = torch.ops.aten.linear.default(mul_61, arg10_1);  mul_61 = arg10_1 = None
    dropout_3 = torch.ops.aten.dropout.default(linear_7, 0.0, False);  linear_7 = None
    add_15 = torch.ops.aten.add.Tensor(to_16, dropout_3);  to_16 = dropout_3 = None
    to_18 = torch.ops.aten.to.dtype(add_15, torch.float32);  add_15 = None
    pow_6 = torch.ops.aten.pow.Tensor_Scalar(to_18, 2)
    mean_4 = torch.ops.aten.mean.dim(pow_6, [-1], True);  pow_6 = None
    add_16 = torch.ops.aten.add.Tensor(mean_4, 1e-05);  mean_4 = None
    rsqrt_4 = torch.ops.aten.rsqrt.default(add_16);  add_16 = None
    mul_62 = torch.ops.aten.mul.Tensor(to_18, rsqrt_4);  to_18 = rsqrt_4 = None
    to_19 = torch.ops.aten.to.dtype(mul_62, torch.float32);  mul_62 = None
    mul_63 = torch.ops.aten.mul.Tensor(arg13_1, to_19);  arg13_1 = to_19 = None
    slice_30 = torch.ops.aten.slice.Tensor(mul_63, 1, 0, 9223372036854775807);  mul_63 = None
    linear_8 = torch.ops.aten.linear.default(slice_30, arg14_1);  slice_30 = arg14_1 = None
    return (linear_8, cat_5, cat_11, cat_6, cat_12)

# To see more debug info, please use `graph_module.print_readable()`
[torch.onnx] Obtain model graph for `Phi3ForCausalLM([...]` with `torch.export.export(..., strict=False)`... â
[torch.onnx] Run decomposition...
[torch.onnx] Run decomposition... â
[torch.onnx] Translate the graph into ONNX...
[torch.onnx] Translate the graph into ONNX... â
~/vv/this312/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_dynamic_shapes.py:264: UserWarning: # The axis name: batch will not be used, since it shares the same shape constraints with another axis: batch.
  warnings.warn(
~/vv/this312/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_dynamic_shapes.py:264: UserWarning: # The axis name: cache+seq will not be used, since it shares the same shape constraints with another axis: seq_length.
  warnings.warn(
~/vv/this312/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_dynamic_shapes.py:264: UserWarning: # The axis name: cache_length will not be used, since it shares the same shape constraints with another axis: cache_length.
  warnings.warn(
Applied 43 of general pattern rewrite rules.
[call_torch_export_onnx] done (export)
[call_torch_export_onnx] starts optimization=&#39;ir&#39;...
[call_torch_export_onnx] done (optimization)
[torch_export_patches] remove patches
[torch_export_patches] restored sympy functions
[torch_export_patches] restored pytorch functions
[torch_export_patches] restored ShapeEnv._set_replacement
[torch_export_patches] restored ShapeEnv._log_guard
[torch_export_patches] restored shape constraints
[torch_export_patches] unpatches transformers
[unpatch_module_or_classes] onnx_diagnostic.torch_export_patches.patches.patch_transformers.patched_AttentionMaskConverter:
[unpatch_module_or_classes] onnx_diagnostic.torch_export_patches.patches.patch_transformers.patched_Gemma2RotaryEmbedding: forward
[unpatch_module_or_classes] onnx_diagnostic.torch_export_patches.patches.patch_transformers.patched_Gemma3RotaryEmbedding: forward
[unpatch_module_or_classes] onnx_diagnostic.torch_export_patches.patches.patch_transformers.patched_GemmaRotaryEmbedding: forward
[unpatch_module_or_classes] onnx_diagnostic.torch_export_patches.patches.patch_transformers.patched_GenerationMixin: _cache_dependant_input_preparation, _cache_dependant_input_preparation_exporting, prepare_inputs_for_generation
[unpatch_module_or_classes] onnx_diagnostic.torch_export_patches.patches.patch_transformers.patched_IdeficsAttention: forward
[unpatch_module_or_classes] onnx_diagnostic.torch_export_patches.patches.patch_transformers.patched_IdeficsEmbedding: forward
[unpatch_module_or_classes] onnx_diagnostic.torch_export_patches.patches.patch_transformers.patched_LlamaRotaryEmbedding: forward
[unpatch_module_or_classes] onnx_diagnostic.torch_export_patches.patches.patch_transformers.patched_MistralRotaryEmbedding: forward
[unpatch_module_or_classes] onnx_diagnostic.torch_export_patches.patches.patch_transformers.patched_MixtralRotaryEmbedding: forward
[unpatch_module_or_classes] onnx_diagnostic.torch_export_patches.patches.patch_transformers.patched_Phi3RotaryEmbedding: forward
[unpatch_module_or_classes] onnx_diagnostic.torch_export_patches.patches.patch_transformers.patched_Phi4MultimodalRotaryEmbedding: forward
[unpatch_module_or_classes] onnx_diagnostic.torch_export_patches.patches.patch_transformers.patched_PhiRotaryEmbedding: forward
[unpatch_module_or_classes] onnx_diagnostic.torch_export_patches.patches.patch_transformers.patched_SamMaskDecoder: forward
[unpatch_module_or_classes] onnx_diagnostic.torch_export_patches.patches.patch_transformers.patched_SmolLM3RotaryEmbedding: forward
[unpatch_module_or_classes] function transformers.models.bart.modeling_bart.eager_attention_forward
[unpatch_module_or_classes] function transformers.models.marian.modeling_marian.eager_attention_forward
[unpatch_module_or_classes] function transformers.cache_utils.parse_processor_args
[torch_export_patches] restored transformers.masking_utils._vmap_for_bhqkv
[torch_export_patches] restored transformers.masking_utils.eager_mask
[validate_model] dumps onnx program in &#39;dump_test/microsoft_Phi-4-mini-reasoning-onnx-dynamo-ir&#39;...
[validate_model] done (dump onnx) in 2.781305350996263
[validate_model] dumps statistics in &#39;dump_test/microsoft_Phi-4-mini-reasoning-onnx-dynamo-ir&#39;...
[validate_model] done (dump)
[validate_onnx_model] verify onnx model with providers [&#39;CPUExecutionProvider&#39;]..., flavour=None
[validate_onnx_model] done (ort_session) flavour=None
[validate_onnx_model] -- make_feeds for &#39;inputs&#39;...
[validate_onnx_model] inputs=dict(input_ids:T7s2x3,attention_mask:T7s2x33,position_ids:T7s2x3,past_key_values:DynamicCache(key_cache=#2[T1s2x8x30x128,T1s2x8x30x128], value_cache=#2[T1s2x8x30x128,T1s2x8x30x128]))
[validate_onnx_model] ort inputs=dict(input_ids:A7s2x3,attention_mask:A7s2x33,position_ids:A7s2x3,past_key_values_key_cache_0:A1s2x8x30x128,past_key_values_key_cache_1:A1s2x8x30x128,past_key_values_value_cache_0:A1s2x8x30x128,past_key_values_value_cache_1:A1s2x8x30x128)
[validate_onnx_model] done (make_feeds)
[validate_onnx_model] run session...
[validate_onnx_model] done (run)
[validate_onnx_model] got=#5[A1s2x3x200064,A1s2x8x33x128,A1s2x8x33x128,A1s2x8x33x128,A1s2x8x33x128]
[validate_onnx_model] discrepancies=abs=3.606081008911133e-06, rel=0.0017793676259306645, n=1470720.0
[validate_onnx_model] -- make_feeds for &#39;inputs2&#39;...
[validate_onnx_model] inputs=dict(input_ids:T7s3x4,attention_mask:T7s3x35,position_ids:T7s3x4,past_key_values:DynamicCache(key_cache=#2[T1s3x8x31x128,T1s3x8x31x128], value_cache=#2[T1s3x8x31x128,T1s3x8x31x128]))
[validate_onnx_model] ort inputs=dict(input_ids:A7s3x4,attention_mask:A7s3x35,position_ids:A7s3x4,past_key_values_key_cache_0:A1s3x8x31x128,past_key_values_key_cache_1:A1s3x8x31x128,past_key_values_value_cache_0:A1s3x8x31x128,past_key_values_value_cache_1:A1s3x8x31x128)
[validate_onnx_model] done (make_feeds)
[validate_onnx_model] run session...
[validate_onnx_model] done (run)
[validate_onnx_model] got=#5[A1s3x4x200064,A1s3x8x35x128,A1s3x8x35x128,A1s3x8x35x128,A1s3x8x35x128]
[validate_onnx_model] discrepancies=abs=3.2782554626464844e-06, rel=0.00204118731285426, n=2830848.0
[validate_model] -- done (final)
done.
</pre></div>
</div>
<p>Letâs load and save the model to get one unique file.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">full_name</span></a></a> <span class="o">=</span> <span class="s2">&quot;dump_test/microsoft_Phi-4-mini-reasoning.onnx&quot;</span>
<span class="k">if</span> <span class="ow">not</span> <a href="https://docs.python.org/3/library/os.path.html#os.path.exists" title="os.path.exists" class="sphx-glr-backref-module-os-path sphx-glr-backref-type-py-function"><a href="https://docs.python.org/3/library/os.path.html#os.path.exists" title="os.path.exists" class="sphx-glr-backref-module-os-path sphx-glr-backref-type-py-function"><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span></a></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">full_name</span></a></a><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Loads the model and saves it as one unique file.&quot;</span><span class="p">)</span>
    <a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx</span></a></a> <span class="o">=</span> <a href="https://onnx.ai/onnx/api/serialization.html#onnx.load" title="onnx.load" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-function"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.load" title="onnx.load" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-function"><span class="n">onnx</span><span class="o">.</span><span class="n">load</span></a></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onnx_file</span></a></a><span class="p">)</span>
    <span class="n">onnx</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx</span></a></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">full_name</span></a></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Loads the model and saves it as one unique file.
</pre></div>
</div>
<p>Letâs get the size.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">size</span></a></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/os.html#os.stat" title="os.stat" class="sphx-glr-backref-module-os sphx-glr-backref-type-py-function"><a href="https://docs.python.org/3/library/os.html#os.stat" title="os.stat" class="sphx-glr-backref-module-os sphx-glr-backref-type-py-function"><span class="n">os</span><span class="o">.</span><span class="n">stat</span></a></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">full_name</span></a></a><span class="p">)</span><span class="o">.</span><span class="n">st_size</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;model size </span><span class="si">{</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">size</span></a></a><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">2</span><span class="o">**</span><span class="mi">20</span><span class="si">:</span><span class="s2">1.3f</span><span class="si">}</span><span class="s2"> Mb&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>model size 989.852 Mb
</pre></div>
</div>
<section id="measures-the-loading-time">
<h2>Measures the loading time<a class="headerlink" href="#measures-the-loading-time" title="Link to this heading">Â¶</a></h2>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">measure</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">N</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
    <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">times</span></a></a> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">begin</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/time.html#time.perf_counter" title="time.perf_counter" class="sphx-glr-backref-module-time sphx-glr-backref-type-py-function"><a href="https://docs.python.org/3/library/time.html#time.perf_counter" title="time.perf_counter" class="sphx-glr-backref-module-time sphx-glr-backref-type-py-function"><span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span></a></a><span class="p">()</span>
        <a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx</span></a></a> <span class="o">=</span> <span class="n">f</span><span class="p">()</span>
        <span class="n">end</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/time.html#time.perf_counter" title="time.perf_counter" class="sphx-glr-backref-module-time sphx-glr-backref-type-py-function"><a href="https://docs.python.org/3/library/time.html#time.perf_counter" title="time.perf_counter" class="sphx-glr-backref-module-time sphx-glr-backref-type-py-function"><span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span></a></a><span class="p">()</span>
        <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">times</span><span class="o">.</span><span class="n">append</span></a></a><span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">begin</span><span class="p">)</span>
    <span class="k">return</span> <a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx</span></a></a><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;avg&quot;</span><span class="p">:</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.mean.html#numpy.mean" title="numpy.mean" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><a href="https://numpy.org/doc/stable/reference/generated/numpy.mean.html#numpy.mean" title="numpy.mean" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">mean</span></a></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">times</span></a></a><span class="p">),</span> <span class="s2">&quot;times&quot;</span><span class="p">:</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">times</span></a></a><span class="p">}</span>
</pre></div>
</div>
<p>Letâs do it with onnx2.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Load time with onnx2.&quot;</span><span class="p">)</span>
<span class="n">onx2</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">times</span></a></a> <span class="o">=</span> <span class="n">measure</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">onnx2</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">full_name</span></a></a><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">times</span></a></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Load time with onnx2.
{&#39;avg&#39;: np.float64(1.9109536773321452), &#39;times&#39;: [1.866385472996626, 2.2022045769990655, 1.664270982000744]}
</pre></div>
</div>
<p>Then with onnx.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Load time with onnx.&quot;</span><span class="p">)</span>
<a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx</span></a></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">times</span></a></a> <span class="o">=</span> <span class="n">measure</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <a href="https://onnx.ai/onnx/api/serialization.html#onnx.load" title="onnx.load" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-function"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.load" title="onnx.load" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-function"><span class="n">onnx</span><span class="o">.</span><span class="n">load</span></a></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">full_name</span></a></a><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">times</span></a></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Load time with onnx.
{&#39;avg&#39;: np.float64(1.9776364249992184), &#39;times&#39;: [2.3620774800001527, 2.3361349849947146, 1.234696810002788]}
</pre></div>
</div>
</section>
<section id="measure-the-saving-time">
<h2>Measure the saving time<a class="headerlink" href="#measure-the-saving-time" title="Link to this heading">Â¶</a></h2>
<p>Letâs do it with onnx2.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Save time with onnx2.&quot;</span><span class="p">)</span>
<span class="n">_</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">times</span></a></a> <span class="o">=</span> <span class="n">measure</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">onnx2</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">onx2</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">full_name</span></a></a><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">times</span></a></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Save time with onnx2.
{&#39;avg&#39;: np.float64(4.362325190665918), &#39;times&#39;: [3.1312978290006868, 4.771354374999646, 5.184323367997422]}
</pre></div>
</div>
<p>Then with onnx.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Save time with onnx.&quot;</span><span class="p">)</span>
<span class="n">_</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">times</span></a></a> <span class="o">=</span> <span class="n">measure</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">onnx</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx</span></a></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">full_name</span></a></a><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">times</span></a></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Save time with onnx.
{&#39;avg&#39;: np.float64(3.8619260056633116), &#39;times&#39;: [4.143729067996901, 3.8224597579974215, 3.6195891909956117]}
</pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (1 minutes 40.482 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-plot-onnx2-time-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/f32ac4651c70ddb7e4a1094e7eb68b25/plot_onnx2_time.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_onnx2_time.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/e55c7808f73c4c254b50441745ce191c/plot_onnx2_time.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_onnx2_time.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../_downloads/443de4701acb8e43bbe3be4f902891e0/plot_onnx2_time.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">plot_onnx2_time.zip</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="plot_bench_cypy_ort.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Measuring onnxruntime performance against a cython binding</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="index.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Examples Gallery</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2023-2024, Xavier DuprÃ©
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Measures loading, saving time for an onnx model in python</a><ul>
<li><a class="reference internal" href="#measures-the-loading-time">Measures the loading time</a></li>
<li><a class="reference internal" href="#measure-the-saving-time">Measure the saving time</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../_static/documentation_options.js?v=e4e9a439"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/furo.js?v=46bd48cc"></script>
    </body>
</html>