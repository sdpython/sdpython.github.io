
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_conv.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_plot_conv.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_conv.py:


.. _l-example-conv:

Using C implementation of operator Conv
=======================================

*onnx-extended* includes an implementation of operator Conv
in language C++ must faster than the python implementation
available in package :epkg:`onnx`. These implementations
are automatically available through class
:class:`onnx.reference.CReferenceEvaluator`.
The following example compares the processing time for three runtimes.

Creation of a simple model
++++++++++++++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 17-50

.. code-block:: default

    import numpy as np
    import matplotlib.pyplot as plt
    from pandas import DataFrame
    from tqdm import tqdm
    from onnx import TensorProto
    from onnx.helper import (
        make_graph,
        make_model,
        make_node,
        make_opsetid,
        make_tensor_value_info,
    )
    from onnx.reference import ReferenceEvaluator
    from onnxruntime import InferenceSession
    from onnx_extended.ext_test_case import measure_time, unit_test_going
    from onnx_extended.reference import CReferenceEvaluator


    X = make_tensor_value_info("X", TensorProto.FLOAT, [None, None, None, None])
    Y = make_tensor_value_info("Y", TensorProto.FLOAT, [None, None, None, None])
    B = make_tensor_value_info("B", TensorProto.FLOAT, [None, None, None, None])
    W = make_tensor_value_info("W", TensorProto.FLOAT, [None, None, None, None])
    node = make_node(
        "Conv",
        ["X", "W", "B"],
        ["Y"],
        pads=[1, 1, 1, 1],
        dilations=[1, 1],
        strides=[2, 2],
    )
    graph = make_graph([node], "g", [X, W, B], [Y])
    onnx_model = make_model(graph, opset_imports=[make_opsetid("", 18)], ir_version=8)








.. GENERATED FROM PYTHON SOURCE LINES 51-54

ReferenceEvaluator and CReferenceEvaluator
++++++++++++++++++++++++++++++++++++++++++
Let's first compare the outputs are the same.

.. GENERATED FROM PYTHON SOURCE LINES 54-68

.. code-block:: default


    sH, sW = 64, 64
    X = np.arange(sW * sH).reshape((1, 1, sH, sW)).astype(np.float32)
    W = np.ones((1, 1, 3, 3), dtype=np.float32)
    B = np.array([[[[0]]]], dtype=np.float32)

    sess1 = ReferenceEvaluator(onnx_model)
    sess2 = CReferenceEvaluator(onnx_model)

    expected = sess1.run(None, {"X": X, "W": W, "B": B})[0]
    got = sess2.run(None, {"X": X, "W": W, "B": B})[0]
    diff = np.abs(expected - got).max()
    print(f"difference: {diff}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    difference: 0.0




.. GENERATED FROM PYTHON SOURCE LINES 69-73

Everything works fine.

Time measurement
++++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 73-83

.. code-block:: default


    feeds = {"X": X, "W": W, "B": B}

    t1 = measure_time(lambda: sess1.run(None, feeds))
    print(f"ReferenceEvaluator: {t1['average']}s")

    t2 = measure_time(lambda: sess2.run(None, feeds))
    print(f"CReferenceEvaluator: {t2['average']}s")
    print(f"speedup is {t1['average'] / t2['average']}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    ReferenceEvaluator: 0.0012023031539974906s
    CReferenceEvaluator: 8.0376197998703e-05s
    speedup is 14.958447698868412




.. GENERATED FROM PYTHON SOURCE LINES 84-85

Let's add :epkg:`onnxruntime` as well.

.. GENERATED FROM PYTHON SOURCE LINES 85-95

.. code-block:: default


    sess3 = InferenceSession(
        onnx_model.SerializeToString(), provider=["CPUExecutionProvider"]
    )

    t3 = measure_time(lambda: sess3.run(None, feeds))
    print(f"InferenceSession: {t3['average']}s")
    print(f"speedup is {t1['average'] / t3['average']}")






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    InferenceSession: 2.1825000003445895e-05s
    speedup is 55.088346108025746




.. GENERATED FROM PYTHON SOURCE LINES 96-98

Plotting
++++++++

.. GENERATED FROM PYTHON SOURCE LINES 98-118

.. code-block:: default


    data = []

    for i in tqdm([16, 32, 48, 64]):
        sH, sW = i, i
        X = np.arange(sW * sH).reshape((1, 1, sH, sW)).astype(np.float32)
        W = np.ones((1, 1, 3, 3), dtype=np.float32)
        B = np.array([[[[0]]]], dtype=np.float32)
        feeds = {"X": X, "W": W, "B": B}
        t1 = measure_time(lambda: sess1.run(None, feeds))
        t2 = measure_time(lambda: sess2.run(None, feeds))
        obs = dict(size=i, onnx=t1["average"], onnx_extended=t2["average"])
        data.append(obs)
        if unit_test_going() and len(data) >= 2:
            break

    df = DataFrame(data)
    df






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

      0%|          | 0/4 [00:00<?, ?it/s]     25%|##5       | 1/4 [00:00<00:00,  9.62it/s]     50%|#####     | 2/4 [00:00<00:00,  7.43it/s]     75%|#######5  | 3/4 [00:00<00:00,  7.76it/s]    100%|##########| 4/4 [00:00<00:00,  4.05it/s]    100%|##########| 4/4 [00:00<00:00,  4.94it/s]


.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>size</th>
          <th>onnx</th>
          <th>onnx_extended</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>16</td>
          <td>0.000192</td>
          <td>0.000015</td>
        </tr>
        <tr>
          <th>1</th>
          <td>32</td>
          <td>0.000292</td>
          <td>0.000018</td>
        </tr>
        <tr>
          <th>2</th>
          <td>48</td>
          <td>0.000225</td>
          <td>0.000017</td>
        </tr>
        <tr>
          <th>3</th>
          <td>64</td>
          <td>0.000776</td>
          <td>0.000076</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 119-120

Finally.

.. GENERATED FROM PYTHON SOURCE LINES 120-132

.. code-block:: default


    df = df.set_index("size")
    fig, ax = plt.subplots(1, 1, figsize=(10, 4))
    df.plot(
        ax=ax, logx=True, logy=True, title="Comparison python / C implementation for Conv"
    )
    df["speedup"] = df["onnx"] / df["onnx_extended"]
    ax2 = ax.twinx()
    df[["speedup"]].plot(ax=ax2, color="green")

    fig.savefig("plot_conv.png")
    # plt.show()



.. image-sg:: /auto_examples/images/sphx_glr_plot_conv_001.png
   :alt: Comparison python / C implementation for Conv
   :srcset: /auto_examples/images/sphx_glr_plot_conv_001.png
   :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  9.729 seconds)


.. _sphx_glr_download_auto_examples_plot_conv.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example




    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_conv.py <plot_conv.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_conv.ipynb <plot_conv.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
