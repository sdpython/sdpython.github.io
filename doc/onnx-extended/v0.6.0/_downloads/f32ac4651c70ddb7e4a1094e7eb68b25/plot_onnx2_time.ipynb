{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Measures loading, saving time for an onnx model in python\n\nThe script creates an ONNX model and measures the time to load and save it\nwith onnx and onnx2. This only compares the python bindings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport time\nimport numpy as np\nimport pandas\nimport onnx\nimport onnx_extended.onnx2 as onnx2\n\nmodel_id = (\n    \"microsoft/Phi-3.5-mini-instruct\"  # \"microsoft/Phi-4-mini-reasoning\", (too big)\n)\nmodel_idf = model_id.replace(\"/\", \"_\")\nexporter = \"custom\"  # or onnx-dynamo to use torch.onnx.export\noptimization = \"default\"  # or ir for onnx-dynamo\ndata = []\nonnx_files_ = [\n    f\"dump_test/{model_idf}/\"\n    f\"onnx-dynamo/ir/{model_idf}-{exporter}-{optimization}.onnx\",\n    f\"dump_test/{model_idf}/{exporter}/{optimization}/\"\n    f\"{model_idf}-{exporter}-{optimization}.onnx\",\n]\nonnx_files = [f for f in onnx_files_ if os.path.exists(f)]\nif not onnx_files:\n    print(\"Creates the model, starts with importing transformers...\")\n    import torch  # noqa: F401\n    import transformers  # noqa: F401\n\n    print(\"Imports onnx-diagnostic...\")\n    from onnx_diagnostic.torch_models.validate import validate_model\n\n    print(\"Starts creating the model...\")\n\n    validate_model(\n        model_id,\n        do_run=True,\n        verbose=2,\n        exporter=exporter,\n        do_same=True,\n        patch=True,\n        rewrite=True,\n        optimization=optimization,\n        dump_folder=\"dump_test\",\n        model_options=dict(num_hidden_layers=2),\n    )\n\n    print(\"done.\")\n\nonnx_files = [f for f in onnx_files_ if os.path.exists(f)]\nassert onnx_files, f\"Unable to find a file in {onnx_files}\"\nonnx_file = onnx_files[0]\nonnx_data = onnx_file + \".data\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's load and save the model to get one unique file.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "full_name = onnx_file.replace(\".onnx\", \".single.onnx\")\nif not os.path.exists(full_name):\n    print(\"Loads the model and saves it as one unique file.\")\n    onx = onnx.load(onnx_file)\n    onnx.save(onx, full_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's get the size.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "size = os.stat(full_name).st_size\nprint(f\"model size {size / 2**20:1.3f} Mb\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Measures the loading time\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def measure(step_name, f, N=3):\n    times = []\n    for _ in range(N):\n        begin = time.perf_counter()\n        onx = f()\n        end = time.perf_counter()\n        times.append(end - begin)\n    res = {\"avg\": np.mean(times), \"times\": times}\n    data.append(\n        dict(name=step_name, avg=res[\"avg\"], min=np.min(times), max=np.max(times))\n    )\n    return onx, res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's do it with onnx2.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Loading time with onnx2.\")\nonx2, times = measure(\"load/onnx2\", lambda: onnx2.load(full_name))\nprint(times)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then with onnx.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Loading time with onnx.\")\nonx, times = measure(\"load/onnx\", lambda: onnx.load(full_name))\nprint(times)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's do it with onnx2 but the loading of the tensors is parallelized.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\n    f\"Loading time with onnx2 and 4 threads, \"\n    f\"it has {len(onx2.graph.initializer)} initializers\"\n)\nonx2, times = measure(\n    \"load/onnx2/x4\", lambda: onnx2.load(full_name, parallel=True, num_threads=4)\n)\nprint(times)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It looks much faster.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's load it with :epkg:`onnxruntime`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import onnxruntime  # noqa: E402\n\nso = onnxruntime.SessionOptions()\nso.graph_optimization_level = onnxruntime.GraphOptimizationLevel.ORT_DISABLE_ALL\nprint(\"Loading time with onnxruntime\")\n_, times = measure(\n    \"load/ort\",\n    lambda: onnxruntime.InferenceSession(\n        full_name, so, providers=[\"CPUExecutionProvider\"]\n    ),\n)\nprint(times)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Measure the saving time\n\nLet's do it with onnx2.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Saving time with onnx2.\")\n_, times = measure(\"save/onnx2\", lambda: onnx2.save(onx2, full_name))\nprint(times)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then with onnx.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Saving time with onnx.\")\n_, times = measure(\"save/onnx\", lambda: onnx.save(onx, full_name))\nprint(times)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Measure the saving time with external weights\n\nLet's do it with onnx2.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "full_name = onnx_file.replace(\".onnx\", \".ext.onnx\")\nfull_weight = full_name.replace(\".onnx\", \".data\")\n\nprint(\"Saving time with onnx2 and external weights.\")\n_, times = measure(\n    \"save/onnx2/ext\", lambda: onnx2.save(onx2, full_name, location=full_weight)\n)\nprint(times)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then with onnx. We can only do that once,\nthe function modifies the model inplace to add information\nabout external data. The second run does not follow the same steps.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Saving time with onnx and external weights.\")\nfull_name_onnx = full_name.replace(\".onnx\", \".0.onnx\")\nfull_weight_onnx = full_name.replace(\".data\", \".0.data\")\n_, times = measure(\n    \"save/onnx/ext\",\n    lambda: onnx.save(\n        onx,\n        full_name_onnx,\n        location=os.path.split(full_weight_onnx)[-1],\n        save_as_external_data=True,\n        all_tensors_to_one_file=True,\n    ),\n    N=1,\n)\nprint(times)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Measure the load time with external weights\n\nLet's do it with onnx2.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Loading time with onnx2 and external weights.\")\n_, times = measure(\"load/onnx2/ext\", lambda: onnx2.load(onnx_file, location=onnx_data))\nprint(times)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Same measure but parallelized.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Loading time with onnx2 parallelized and external weights.\")\n_, times = measure(\n    \"load/onnx2/ext/x4\",\n    lambda: onnx2.load(onnx_file, location=onnx_data, parallel=True, num_threads=4),\n)\nprint(times)\n\n# Let's do it with onnx2.\n\nprint(\"Saving time with onnx and external weights.\")\n_, times = measure(\"load/onnx/ext\", lambda: onnx.load(onnx_file))\nprint(times)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plots\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df = pandas.DataFrame(data).sort_values(\"name\").set_index(\"name\")\nprint(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visually.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ax = df[[\"avg\"]].plot.barh(\n    title=f\"size={size / 2**20:1.3f} Mb\\n\"\n    \"onnx VS onnx2 for load/save (s)\\nthe lower, \"\n    \"the better\\next = external data\\nx4 = 4 threads\"\n)\nax.figure.tight_layout()\nax.figure.savefig(\"plot_onnx2_time.png\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}