
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_op_conv_py_vs_c.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_plot_op_conv_py_vs_c.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_op_conv_py_vs_c.py:


.. _l-example-conv:

Using C implementation of operator Conv
=======================================

*onnx-extended* includes an implementation of operator Conv
in language C++ must faster than the python implementation
available in package :epkg:`onnx`. These implementations
are automatically available through class
:class:`onnx_extended.reference.CReferenceEvaluator`.
The following example compares the processing time for three runtimes.

Creation of a simple model
++++++++++++++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 17-51

.. code-block:: Python


    import numpy as np
    import matplotlib.pyplot as plt
    from pandas import DataFrame
    from tqdm import tqdm
    from onnx import TensorProto
    from onnx.helper import (
        make_graph,
        make_model,
        make_node,
        make_opsetid,
        make_tensor_value_info,
    )
    from onnx.reference import ReferenceEvaluator
    from onnxruntime import InferenceSession
    from onnx_extended.ext_test_case import measure_time, unit_test_going
    from onnx_extended.reference import CReferenceEvaluator


    X = make_tensor_value_info("X", TensorProto.FLOAT, [None, None, None, None])
    Y = make_tensor_value_info("Y", TensorProto.FLOAT, [None, None, None, None])
    B = make_tensor_value_info("B", TensorProto.FLOAT, [None, None, None, None])
    W = make_tensor_value_info("W", TensorProto.FLOAT, [None, None, None, None])
    node = make_node(
        "Conv",
        ["X", "W", "B"],
        ["Y"],
        pads=[1, 1, 1, 1],
        dilations=[1, 1],
        strides=[2, 2],
    )
    graph = make_graph([node], "g", [X, W, B], [Y])
    onnx_model = make_model(graph, opset_imports=[make_opsetid("", 18)], ir_version=8)








.. GENERATED FROM PYTHON SOURCE LINES 52-55

ReferenceEvaluator and CReferenceEvaluator
++++++++++++++++++++++++++++++++++++++++++
Let's first compare the outputs are the same.

.. GENERATED FROM PYTHON SOURCE LINES 55-69

.. code-block:: Python


    sH, sW = 64, 64
    X = np.arange(sW * sH).reshape((1, 1, sH, sW)).astype(np.float32)
    W = np.ones((1, 1, 3, 3), dtype=np.float32)
    B = np.array([[[[0]]]], dtype=np.float32)

    sess1 = ReferenceEvaluator(onnx_model)
    sess2 = CReferenceEvaluator(onnx_model)

    expected = sess1.run(None, {"X": X, "W": W, "B": B})[0]
    got = sess2.run(None, {"X": X, "W": W, "B": B})[0]
    diff = np.abs(expected - got).max()
    print(f"difference: {diff}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    difference: 0.0




.. GENERATED FROM PYTHON SOURCE LINES 70-74

Everything works fine.

Time measurement
++++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 74-84

.. code-block:: Python


    feeds = {"X": X, "W": W, "B": B}

    t1 = measure_time(lambda: sess1.run(None, feeds))
    print(f"ReferenceEvaluator: {t1['average']}s")

    t2 = measure_time(lambda: sess2.run(None, feeds))
    print(f"CReferenceEvaluator: {t2['average']}s")
    print(f"speedup is {t1['average'] / t2['average']}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    ReferenceEvaluator: 0.00018555449999621486s
    CReferenceEvaluator: 1.9222871997044423e-05s
    speedup is 9.652797980694272




.. GENERATED FROM PYTHON SOURCE LINES 85-86

Let's add :epkg:`onnxruntime` as well.

.. GENERATED FROM PYTHON SOURCE LINES 86-96

.. code-block:: Python


    sess3 = InferenceSession(
        onnx_model.SerializeToString(), providers=["CPUExecutionProvider"]
    )

    t3 = measure_time(lambda: sess3.run(None, feeds))
    print(f"InferenceSession: {t3['average']}s")
    print(f"speedup is {t1['average'] / t3['average']}")






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    InferenceSession: 2.281684399713413e-05s
    speedup is 8.132347314094845




.. GENERATED FROM PYTHON SOURCE LINES 97-99

Plotting
++++++++

.. GENERATED FROM PYTHON SOURCE LINES 99-119

.. code-block:: Python


    data = []

    for i in tqdm([16, 32, 48, 64]):
        sH, sW = i, i
        X = np.arange(sW * sH).reshape((1, 1, sH, sW)).astype(np.float32)
        W = np.ones((1, 1, 3, 3), dtype=np.float32)
        B = np.array([[[[0]]]], dtype=np.float32)
        feeds = {"X": X, "W": W, "B": B}
        t1 = measure_time(lambda feeds=feeds: sess1.run(None, feeds))
        t2 = measure_time(lambda feeds=feeds: sess2.run(None, feeds))
        obs = dict(size=i, onnx=t1["average"], onnx_extended=t2["average"])
        data.append(obs)
        if unit_test_going() and len(data) >= 2:
            break

    df = DataFrame(data)
    df






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

      0%|          | 0/4 [00:00<?, ?it/s]     50%|█████     | 2/4 [00:00<00:00, 12.18it/s]    100%|██████████| 4/4 [00:00<00:00, 11.35it/s]    100%|██████████| 4/4 [00:00<00:00, 11.46it/s]


.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>size</th>
          <th>onnx</th>
          <th>onnx_extended</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>16</td>
          <td>0.000177</td>
          <td>0.000014</td>
        </tr>
        <tr>
          <th>1</th>
          <td>32</td>
          <td>0.000118</td>
          <td>0.000014</td>
        </tr>
        <tr>
          <th>2</th>
          <td>48</td>
          <td>0.000157</td>
          <td>0.000015</td>
        </tr>
        <tr>
          <th>3</th>
          <td>64</td>
          <td>0.000177</td>
          <td>0.000016</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 120-121

Finally.

.. GENERATED FROM PYTHON SOURCE LINES 121-134

.. code-block:: Python


    df = df.set_index("size")
    fig, ax = plt.subplots(1, 1, figsize=(10, 4))
    df.plot(
        ax=ax, logx=True, logy=True, title="Comparison python / C implementation for Conv"
    )
    df["speedup"] = df["onnx"] / df["onnx_extended"]
    ax2 = ax.twinx()
    df[["speedup"]].plot(ax=ax2, color="green")

    fig.tight_layout()
    fig.savefig("plot_op_conv.png")
    # plt.show()



.. image-sg:: /auto_examples/images/sphx_glr_plot_op_conv_py_vs_c_001.png
   :alt: Comparison python / C implementation for Conv
   :srcset: /auto_examples/images/sphx_glr_plot_op_conv_py_vs_c_001.png
   :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 5.421 seconds)


.. _sphx_glr_download_auto_examples_plot_op_conv_py_vs_c.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_op_conv_py_vs_c.ipynb <plot_op_conv_py_vs_c.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_op_conv_py_vs_c.py <plot_op_conv_py_vs_c.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_op_conv_py_vs_c.zip <plot_op_conv_py_vs_c.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
