{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Measuring Gemm performance with different input and output tests\n\nThis benchmark looks into various combinations allowed by functions\n:epkg:`cublasLtMatmul`. The tested configurations are available at\n:epkg:`cuda_gemm.cu`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pprint\nimport warnings\nfrom itertools import product\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom pandas import DataFrame\nfrom onnx_extended.ext_test_case import unit_test_going, get_parsed_args\n\ntry:\n    from onnx_extended.validation.cuda.cuda_example_py import (\n        gemm_benchmark_test,\n        get_device_prop,\n    )\n\n    has_cuda = True\nexcept ImportError:\n    # CUDA not available.\n    has_cuda = False\n    gemm_benchmark_test = None\n\nif has_cuda:\n    prop = get_device_prop()\n    if prop[\"major\"] <= 0:\n        # No CUDA.\n        dtests, ddims = \"\", \"\"\n    elif prop[\"major\"] < 7:\n        # No float 8.\n        dtests, ddims = \"0,1,2,3,4,15\", \"16,32,64,64x128x92\"\n    elif prop[\"major\"] < 9:  # T100, A100\n        # No float 8.\n        dtests, ddims = (\n            \"0,1,2,3,4,15\",\n            \"16,32,64,128,256,512,1024,2048,4096,8192,\"\n            \"128x768x768,128x3072x768,128x768x3072\",\n        )\n    else:\n        dtests, ddims = (\n            \"0,1,2,3,4,5,6,7,11,14,15\",\n            \"16,32,64,128,256,512,1024,2048,4096,8192,16384,\"\n            \"128x768x768,128x3072x768,128x768x3072\",\n        )\nelse:\n    dtests, ddims = \"\", \"\"\n\n\nscript_args = get_parsed_args(\n    \"plot_bench_gemm_f8\",\n    description=__doc__,\n    dims=(\n        \"16,32\" if unit_test_going() else ddims,\n        \"square matrix dimensions to try, comma separated values\",\n    ),\n    tests=(\n        \"0,1,2\" if unit_test_going() else dtests,\n        \"configuration to check, see cuda_gemm.cu\",\n    ),\n    warmup=2 if unit_test_going() else 5,\n    repeat=2 if unit_test_going() else 10,\n    expose=\"repeat,warmup\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Device\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if has_cuda:\n    prop = get_device_prop()\n    pprint.pprint(prop)\nelse:\n    print(\"CUDA is not available\")\n    prop = dict(major=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Benchmark\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def type2string(dt):\n    dtests = {\n        0: \"F32\",\n        2: \"F16\",\n        14: \"BF16\",\n        28: \"E4M3\",\n        29: \"E5M2\",\n        3: \"I8\",\n        10: \"I32\",\n    }\n    return dtests[int(dt)]\n\n\ndims = []\ntests = []\nif gemm_benchmark_test is not None:\n    for d in script_args.dims.split(\",\"):\n        if \"x\" in d:\n            spl = d.split(\"x\")\n            m, n, k = tuple(int(i) for i in spl)\n            dims.append((m, n, k))\n        else:\n            dims.append(int(d))\n    tests = list(int(i) for i in script_args.tests.split(\",\"))\n\npbar = tqdm(list(product(tests, dims)))\nobs = []\nfor test, dim in pbar:\n    pbar.set_description(f\"type={test} dim={dim}\")\n    if test in {8, 9, 10, 12, 13}:\n        warnings.warn(f\"unsupported configuration {test}.\")\n        continue\n    mdim = dim if isinstance(dim, int) else max(dim)\n    if mdim < 128:\n        n, N = script_args.warmup * 8, script_args.repeat * 8\n    elif mdim < 512:\n        n, N = script_args.warmup * 4, script_args.repeat * 4\n    elif mdim < 8192:\n        n, N = script_args.warmup * 2, script_args.repeat * 2\n    else:\n        n, N = script_args.warmup, script_args.repeat\n\n    if isinstance(dim, int):\n        gemm_args = [dim] * 6\n    else:\n        m, n, k = dim\n        lda, ldb, ldd = k, k, k\n        gemm_args = [m, n, k, lda, ldb, ldd]\n\n    # warmup\n    gemm_benchmark_test(test, N, *gemm_args)\n\n    # benchmark\n    res = gemm_benchmark_test(test, N, *gemm_args)\n\n    # better rendering\n    res[\"test\"] = test\n    update = {}\n    for k, v in res.items():\n        if \"type_\" in k:\n            update[k] = type2string(v)\n        if k.startswith(\"t-\"):\n            update[k] = res[k] / res[\"N\"]\n    update[\"compute_type\"] = f\"C{int(res['compute_type'])}\"\n    for c in [\"N\", \"m\", \"n\", \"k\", \"lda\", \"ldb\", \"ldd\"]:\n        update[c] = int(res[c])\n    update[\"~dim\"] = (update[\"k\"] * max(update[\"m\"], update[\"n\"])) ** 0.5\n    update[\"mnk\"] = f\"{update['m']}x{update['n']}x{update['k']}\"\n    update[\"name\"] = (\n        f\"{update['type_a']}x{update['type_b']}->\"\n        f\"{update['type_d']}{update['compute_type']}\"\n    )\n    res.update(update)\n    obs.append(res)\n    if unit_test_going() and len(obs) > 2:\n        break\n\ndf = DataFrame(obs)\ndf.to_csv(\"plot_bench_gemm_f8.csv\", index=False)\ndf.to_excel(\"plot_bench_gemm_f8.xlsx\", index=False)\nprint(df.head().T)\n\ndf.head().T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test definition\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "col_def = [\"name\", \"test\", \"type_a\", \"type_b\", \"type_d\", \"compute_type\"]\nif df.shape[0] > 0:\n    deft = df.copy()\n    gr = deft[col_def].groupby(col_def, as_index=False).count()\n    print(gr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Total time and only gemm\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if df.shape[0] > 0:\n    dfi = df[col_def + [\"~dim\", \"mnk\", \"t-total\", \"t-gemm_sync\"]]\n    print(dfi)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Smaller sets\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if df.shape[0] > 0:\n    subset = {1, 3, 4, 5, 7}\n    dfis = dfi[dfi.test.isin(subset)]\n    print()\n    print(\"t-gemm_sync\")\n    pivi = dfis.pivot_table(index=[\"~dim\", \"mnk\"], columns=\"name\", values=\"t-gemm_sync\")\n    print(pivi)\n    print()\n    print(\"t-total\")\n    pivi = dfis.pivot_table(index=[\"~dim\", \"mnk\"], columns=\"name\", values=\"t-total\")\n    print(pivi)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plots\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if df.shape[0] > 0:\n    piv = df.pivot_table(index=[\"~dim\", \"mnk\"], columns=\"name\", values=\"t-gemm_sync\")\n    piv.plot(title=\"MatMul performances\")\n\n    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n    piv.plot(ax=ax[0], title=\"Gemm performance\\nlower is better\", logx=True, logy=True)\n\n    piv = df[df.test.isin(subset)].pivot_table(\n        index=[\"~dim\", \"mnk\"], columns=\"name\", values=\"t-gemm_sync\"\n    )\n    if piv.shape[0] > 0:\n        piv.plot(\n            ax=ax[1], title=\"Gemm performance\\nlower is better\", logx=True, logy=True\n        )\n\n    fig.tight_layout()\n    fig.savefig(\"plot_bench_gemm_f8.png\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}