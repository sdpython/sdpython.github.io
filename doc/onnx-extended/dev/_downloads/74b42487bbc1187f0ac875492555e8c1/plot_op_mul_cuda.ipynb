{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Fusing multiplication operators on CUDA\n\nThe examples compare the performaance of two fused operators Mul\nwith the unfused sequence.\n\n## Cache Performance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from onnx_extended.args import get_parsed_args\n\nscript_args = get_parsed_args(\n    \"plot_op_mul_cuda\",\n    description=__doc__,\n    config=(\n        \"small\",\n        \"small, short optimization (default), \"\n        \"medium for medium sizes, \"\n        \"large for big sizes\",\n    ),\n    warmup=3,\n    repeat=5,\n    itype=(1, \"1 or 10 for float or float16\"),\n    expose=\"config,itype,warmup,repeat\",\n)\n\nitype = script_args.itype\nconfig = script_args.config\nprint(f\"config={config}\")\nprint(f\"itype={itype}\")\n\nif config == \"small\":\n    sizes = (256, 512, 1024)\nelif config == \"medium\":\n    sizes = (512, 1024, 2048)\nelif config == \"large\":\n    sizes = (1024, 2048, 4096, 8192)\nelse:\n    try:\n        sizes = list(map(int, config.split(\",\")))\n    except (ValueError, TypeError) as e:\n        raise AssertionError(f\"Unexpected config value {config!r}.\") from e\n\nimport time\nimport numpy as np\nimport onnx.helper as oh\nfrom tqdm import tqdm\nfrom pandas import DataFrame\nfrom onnxruntime import InferenceSession, SessionOptions, get_available_providers\nfrom onnx_array_api.plotting.text_plot import onnx_simple_text_plot\nfrom onnx_extended.ortops.optim.cuda import get_ort_ext_libs\n\n\ndef get_model1(itype):\n    return oh.make_model(\n        oh.make_graph(\n            [\n                oh.make_node(\"Mul\", [\"X\", \"Y\"], [\"xy\"]),\n                oh.make_node(\"Mul\", [\"xy\", \"Z\"], [\"xyz\"]),\n                oh.make_node(\"Mul\", [\"Y\", \"X\"], [\"yx\"]),\n                oh.make_node(\"Mul\", [\"xyz\", \"yx\"], [\"final\"]),\n            ],\n            \"nd\",\n            [\n                oh.make_tensor_value_info(\"X\", itype, [None, None]),\n                oh.make_tensor_value_info(\"Y\", itype, [None, None]),\n                oh.make_tensor_value_info(\"Z\", itype, [None, None]),\n            ],\n            [oh.make_tensor_value_info(\"final\", itype, [None, None])],\n        ),\n        opset_imports=[oh.make_opsetid(\"\", 18)],\n        ir_version=9,\n    )\n\n\nprint(onnx_simple_text_plot(get_model1(itype)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And the other model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def get_model2(itype):\n    return oh.make_model(\n        oh.make_graph(\n            [\n                oh.make_node(\n                    \"MulMul\",\n                    [\"X\", \"Y\", \"Z\"],\n                    [\"xyz\"],\n                    domain=\"onnx_extended.ortops.optim.cuda\",\n                ),\n                oh.make_node(\n                    \"MulMul\",\n                    [\"Y\", \"X\", \"xyz\"],\n                    [\"final\"],\n                    domain=\"onnx_extended.ortops.optim.cuda\",\n                ),\n            ],\n            \"nd\",\n            [\n                oh.make_tensor_value_info(\"X\", itype, [None, None]),\n                oh.make_tensor_value_info(\"Y\", itype, [None, None]),\n                oh.make_tensor_value_info(\"Z\", itype, [None, None]),\n            ],\n            [oh.make_tensor_value_info(\"final\", itype, [None, None])],\n        ),\n        opset_imports=[\n            oh.make_opsetid(\"\", 18),\n            oh.make_opsetid(\"onnx_extended.ortops.optim.cuda\", 1),\n        ],\n        ir_version=9,\n    )\n\n\nprint(onnx_simple_text_plot(get_model2(itype)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## InferenceSession\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "has_cuda = \"CUDAExecutionProvider\" in get_available_providers()\n\nif has_cuda:\n\n    dtype = np.float32 if itype == 1 else np.float16\n\n    x = np.random.randn(16, 16).astype(dtype)\n    y = np.random.randn(16, 16).astype(dtype)\n    z = np.random.randn(16, 16).astype(dtype)\n    feeds = dict(X=x, Y=y, Z=z)\n\n    sess1 = InferenceSession(\n        get_model1(itype).SerializeToString(), providers=[\"CUDAExecutionProvider\"]\n    )\n    expected = sess1.run(None, feeds)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The other model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if has_cuda:\n\n    opts = SessionOptions()\n    opts.register_custom_ops_library(get_ort_ext_libs()[0])\n\n    sess2 = InferenceSession(\n        get_model2(itype).SerializeToString(), opts, providers=[\"CUDAExecutionProvider\"]\n    )\n    got = sess2.run(None, feeds)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Discrepancies\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if has_cuda:\n\n    diff = np.abs(got - expected).max()\n    print(f\"diff={diff}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Benchmark\n\nsome code to avoid measuring copying the data from host to device\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def move_inputs(sess, feeds):\n    from onnxruntime.capi._pybind_state import (\n        SessionIOBinding,\n        OrtDevice as C_OrtDevice,\n        OrtValue as C_OrtValue,\n    )\n\n    input_names = [i.name for i in sess.get_inputs()]\n\n    ort_device = C_OrtDevice(C_OrtDevice.cuda(), C_OrtDevice.default_memory(), 0)\n\n    feed_ort_value = [\n        (name, C_OrtValue.ortvalue_from_numpy(feeds[name], ort_device))\n        for name in input_names\n    ]\n\n    bind = SessionIOBinding(sess._sess)\n    for name, value in feed_ort_value:\n        bind.bind_input(\n            name, ort_device, feeds[name].dtype, value.shape(), value.data_ptr()\n        )\n    for o in sess.get_outputs():\n        bind.bind_output(o.name, ort_device)\n    return bind, feed_ort_value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Benchmark function\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def benchmark(sess, sizes, label):\n\n    data = []\n    for size in tqdm(sizes):\n\n        x = np.random.randn(size, size).astype(dtype)\n        y = np.random.randn(size, size).astype(dtype)\n        z = np.random.randn(size, size).astype(dtype)\n        feeds = dict(X=x, Y=y, Z=z)\n        bind, cuda_feeds = move_inputs(sess, feeds)\n\n        begin = time.perf_counter()\n        for i in range(script_args.warmup):\n            # sess.run(None, feeds)\n            sess._sess.run_with_iobinding(bind, None)\n        warmup = time.perf_counter() - begin\n\n        times = []\n        for i in range(script_args.repeat):\n            begin = time.perf_counter()\n            # sess.run(None, feeds)\n            sess._sess.run_with_iobinding(bind, None)\n            times.append(time.perf_counter() - begin)\n\n        npt = np.array(times)\n        obs = dict(\n            warmup=warmup,\n            time=npt.mean(),\n            std=npt.std(),\n            min=npt.min(),\n            max=npt.max(),\n            repeat=script_args.repeat,\n            size=size,\n            label=label,\n        )\n        data.append(obs)\n    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Not Fused.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if has_cuda:\n\n    print(f\"sizes={sizes}\")\n\n    data_mul = benchmark(sess1, sizes, \"Not Fused\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fused.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if has_cuda:\n\n    data_mulmul = benchmark(sess2, sizes, \"Fused\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if has_cuda:\n\n    df = DataFrame(data_mul + data_mulmul)\n    df.to_csv(\"plot_op_mul_cuda.csv\", index=False)\n    df.to_csv(\"plot_op_mul_cuda.xlsx\", index=False)\n    print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pivot.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if has_cuda:\n\n    pivot = df.pivot(index=\"size\", columns=\"label\", values=\"time\")\n    pivot[\"ratio\"] = pivot[\"Fused\"] / pivot[\"Not Fused\"]\n    print(pivot)\n\n    ax = pivot[[\"Not Fused\", \"Fused\"]].plot(\n        logx=True,\n        logy=True,\n        title=f\"Fused/Unfused element wise multiplication on CUDA\\nitype={itype}\",\n    )\n    ax.get_figure().savefig(\"plot_op_mul_cuda.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It seems the fused operator is 33% faster.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}