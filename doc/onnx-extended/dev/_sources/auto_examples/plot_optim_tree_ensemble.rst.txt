
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_optim_tree_ensemble.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_plot_optim_tree_ensemble.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_optim_tree_ensemble.py:


.. _l-plot-optim-tree-ensemble:

TreeEnsemble optimization
=========================

The execution of a TreeEnsembleRegressor can lead to very different results
depending on how the computation is parallelized. By trees,
by rows, by both, for only one row, for a short batch of rows, a longer one.
The implementation in :epkg:`onnxruntime` does not let the user changed
the predetermined settings but a custom kernel might. That's what this example
is measuring.

The default set of optimized parameters is very short and is meant to be executed
fast. Many more parameters can be tried.

::

    python plot_optim_tree_ensemble --scenario=LONG

To change the training parameters:

::

    python plot_optim_tree_ensemble.py
        --n_trees=100
        --max_depth=10
        --n_features=50
        --batch_size=100000 

# Training a model
# ++++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 34-88

.. code-block:: default

    import os
    import timeit
    import numpy
    import onnx
    from onnx.reference import ReferenceEvaluator
    import matplotlib.pyplot as plt
    from pandas import DataFrame, concat
    from sklearn.datasets import make_regression
    from sklearn.ensemble import RandomForestRegressor
    from skl2onnx import to_onnx
    from onnxruntime import InferenceSession, SessionOptions
    from onnx_array_api.plotting.text_plot import onnx_simple_text_plot
    from onnx_extended.reference import CReferenceEvaluator
    from onnx_extended.ortops.optim.cpu import get_ort_ext_libs
    from onnx_extended.ortops.optim.optimize import (
        change_onnx_operator_domain,
        get_node_attribute,
        optimize_model,
    )
    from onnx_extended.ext_test_case import get_parsed_args

    script_args = get_parsed_args(
        "plot_optim_tree_ensemble",
        description=__doc__,
        scenarios={"SHORT": "short optimization", "LONG": "test more options"},
        n_features=(5, "number of features to generate"),
        n_trees=(10, "number of trees to train"),
        max_depth=(5, "max_depth"),
        batch_size=(10000, "batch size"),
    )

    batch_size = script_args.batch_size
    n_features = script_args.n_features
    n_trees = script_args.n_trees
    max_depth = script_args.max_depth

    filename = (
        f"plot_optim_tree_ensemble_b{batch_size}-f{n_features}-"
        f"t{n_trees}-d{max_depth}.onnx"
    )
    if not os.path.exists(filename):
        print(f"Training to get {filename!r}")
        X, y = make_regression(batch_size * 2, n_features=n_features, n_targets=1)
        X, y = X.astype(numpy.float32), y.astype(numpy.float32)
        model = RandomForestRegressor(n_trees, max_depth=max_depth, verbose=2)
        model.fit(X[:batch_size], y[:batch_size])
        onx = to_onnx(model, X[:1])
        with open(filename, "wb") as f:
            f.write(onx.SerializeToString())
    else:
        X, y = make_regression(batch_size, n_features=n_features, n_targets=1)
        X, y = X.astype(numpy.float32), y.astype(numpy.float32)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Training to get 'plot_optim_tree_ensemble_b10000-f5-t10-d5.onnx'
    [Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
    building tree 1 of 10
    [Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s
    building tree 2 of 10
    building tree 3 of 10
    building tree 4 of 10
    building tree 5 of 10
    building tree 6 of 10
    building tree 7 of 10
    building tree 8 of 10
    building tree 9 of 10
    building tree 10 of 10
    [Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.6s finished




.. GENERATED FROM PYTHON SOURCE LINES 89-96

Rewrite the onnx file to use a different kernel
+++++++++++++++++++++++++++++++++++++++++++++++

The custom kernel is mapped to a custom operator with the same name
the attributes and domain = `"onnx_extented.ortops.optim.cpu"`.
We call a function to do that replacement.
First the current model.

.. GENERATED FROM PYTHON SOURCE LINES 96-101

.. code-block:: default


    with open(filename, "rb") as f:
        onx = onnx.load(f)
    print(onnx_simple_text_plot(onx))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    opset: domain='ai.onnx.ml' version=1
    opset: domain='' version=18
    input: name='X' type=dtype('float32') shape=['', 5]
    TreeEnsembleRegressor(X, n_targets=1, nodes_falsenodeids=630:[32,17,10...62,0,0], nodes_featureids=630:[4,4,4...4,0,0], nodes_hitrates=630:[1.0,1.0...1.0,1.0], nodes_missing_value_tracks_true=630:[0,0,0...0,0,0], nodes_modes=630:[b'BRANCH_LEQ',b'BRANCH_LEQ'...b'LEAF',b'LEAF'], nodes_nodeids=630:[0,1,2...60,61,62], nodes_treeids=630:[0,0,0...9,9,9], nodes_truenodeids=630:[1,2,3...61,0,0], nodes_values=630:[-0.025208843871951103,-1.0372203588485718...0.0,0.0], post_transform=b'NONE', target_ids=320:[0,0,0...0,0,0], target_nodeids=320:[5,6,8...59,61,62], target_treeids=320:[0,0,0...9,9,9], target_weights=320:[-25.07267189025879,-18.60403060913086...34.62826156616211,41.99155044555664]) -> variable
    output: name='variable' type=dtype('float32') shape=['', 1]




.. GENERATED FROM PYTHON SOURCE LINES 102-103

And then the modified model.

.. GENERATED FROM PYTHON SOURCE LINES 103-126

.. code-block:: default



    def transform_model(onx, **kwargs):
        att = get_node_attribute(onx.graph.node[0], "nodes_modes")
        modes = ",".join(map(lambda s: s.decode("ascii"), att.strings))
        return change_onnx_operator_domain(
            onx,
            op_type="TreeEnsembleRegressor",
            op_domain="ai.onnx.ml",
            new_op_domain="onnx_extented.ortops.optim.cpu",
            nodes_modes=modes,
            **kwargs,
        )


    print("Tranform model to add a custom node.")
    onx_modified = transform_model(onx)
    print(f"Save into {filename + 'modified.onnx'!r}.")
    with open(filename + "modified.onnx", "wb") as f:
        f.write(onx_modified.SerializeToString())
    print("done.")
    print(onnx_simple_text_plot(onx_modified))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Tranform model to add a custom node.
    Save into 'plot_optim_tree_ensemble_b10000-f5-t10-d5.onnxmodified.onnx'.
    done.
    opset: domain='ai.onnx.ml' version=1
    opset: domain='' version=18
    opset: domain='onnx_extented.ortops.optim.cpu' version=1
    input: name='X' type=dtype('float32') shape=['', 5]
    TreeEnsembleRegressor[onnx_extented.ortops.optim.cpu](X, nodes_modes=b'BRANCH_LEQ,BRANCH_LEQ,BRANCH_LEQ,BRANC...LEAF,LEAF', n_targets=1, nodes_falsenodeids=630:[32,17,10...62,0,0], nodes_featureids=630:[4,4,4...4,0,0], nodes_hitrates=630:[1.0,1.0...1.0,1.0], nodes_missing_value_tracks_true=630:[0,0,0...0,0,0], nodes_nodeids=630:[0,1,2...60,61,62], nodes_treeids=630:[0,0,0...9,9,9], nodes_truenodeids=630:[1,2,3...61,0,0], nodes_values=630:[-0.025208843871951103,-1.0372203588485718...0.0,0.0], post_transform=b'NONE', target_ids=320:[0,0,0...0,0,0], target_nodeids=320:[5,6,8...59,61,62], target_treeids=320:[0,0,0...9,9,9], target_weights=320:[-25.07267189025879,-18.60403060913086...34.62826156616211,41.99155044555664]) -> variable
    output: name='variable' type=dtype('float32') shape=['', 1]




.. GENERATED FROM PYTHON SOURCE LINES 127-129

Comparing onnxruntime and the custom kernel
+++++++++++++++++++++++++++++++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 129-150

.. code-block:: default


    print(f"Loading {filename!r}")
    sess_ort = InferenceSession(filename, providers=["CPUExecutionProvider"])

    r = get_ort_ext_libs()
    print(f"Creating SessionOptions with {r!r}")
    opts = SessionOptions()
    if r is not None:
        opts.register_custom_ops_library(r[0])

    print("Loading modified {filename!r}")
    sess_cus = InferenceSession(
        onx_modified.SerializeToString(), opts, providers=["CPUExecutionProvider"]
    )

    print(f"Running once with shape {X[-batch_size:].shape}.")
    base = sess_ort.run(None, {"X": X[-batch_size:]})[0]
    print(f"Running modified with shape {X[-batch_size:].shape}.")
    got = sess_cus.run(None, {"X": X[-batch_size:]})[0]
    print("done.")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Loading 'plot_optim_tree_ensemble_b10000-f5-t10-d5.onnx'
    Creating SessionOptions with ['/home/xadupre/github/onnx-extended/onnx_extended/ortops/optim/cpu/libortops_optim_cpu.so']
    Loading modified {filename!r}
    Running once with shape (10000, 5).
    Running modified with shape (10000, 5).
    done.




.. GENERATED FROM PYTHON SOURCE LINES 151-152

Discrepancies?

.. GENERATED FROM PYTHON SOURCE LINES 152-156

.. code-block:: default


    diff = numpy.abs(base - got).max()
    print(f"Discrepancies: {diff}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Discrepancies: 3.0517578125e-05




.. GENERATED FROM PYTHON SOURCE LINES 157-161

Simple verification
+++++++++++++++++++

Baseline with onnxruntime.

.. GENERATED FROM PYTHON SOURCE LINES 161-164

.. code-block:: default

    t1 = timeit.timeit(lambda: sess_ort.run(None, {"X": X[-batch_size:]}), number=50)
    print(f"baseline: {t1}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    baseline: 0.10130870000284631




.. GENERATED FROM PYTHON SOURCE LINES 165-166

The custom implementation.

.. GENERATED FROM PYTHON SOURCE LINES 166-169

.. code-block:: default

    t2 = timeit.timeit(lambda: sess_cus.run(None, {"X": X[-batch_size:]}), number=50)
    print(f"new time: {t2}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    new time: 0.060323400000925176




.. GENERATED FROM PYTHON SOURCE LINES 170-171

The same implementation but ran from the onnx python backend.

.. GENERATED FROM PYTHON SOURCE LINES 171-176

.. code-block:: default

    ref = CReferenceEvaluator(filename)
    ref.run(None, {"X": X[-batch_size:]})
    t3 = timeit.timeit(lambda: ref.run(None, {"X": X[-batch_size:]}), number=50)
    print(f"CReferenceEvaluator: {t3}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    CReferenceEvaluator: 0.4059376000004704




.. GENERATED FROM PYTHON SOURCE LINES 177-178

The python implementation but from the onnx python backend.

.. GENERATED FROM PYTHON SOURCE LINES 178-184

.. code-block:: default

    ref = ReferenceEvaluator(filename)
    ref.run(None, {"X": X[-batch_size:]})
    t4 = timeit.timeit(lambda: ref.run(None, {"X": X[-batch_size:]}), number=5)
    print(f"ReferenceEvaluator: {t4} (only 5 times instead of 50)")






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    ReferenceEvaluator: 6.762963100001798 (only 5 times instead of 50)




.. GENERATED FROM PYTHON SOURCE LINES 185-194

Time for comparison
+++++++++++++++++++

The custom kernel supports the same attributes as *TreeEnsembleRegressor*
plus new ones to tune the parallelization. They can be seen in
`tree_ensemble.cc <https://github.com/sdpython/onnx-extended/
blob/main/onnx_extended/ortops/optim/cpu/tree_ensemble.cc#L102>`_.
Let's try out many possibilities.
The default values are the first ones.

.. GENERATED FROM PYTHON SOURCE LINES 194-218

.. code-block:: default


    if script_args.scenario in (None, "SHORT"):
        optim_params = dict(
            parallel_tree=[80, 40],  # default is 80
            parallel_tree_N=[128, 64],  # default is 128
            parallel_N=[50, 25],  # default is 50
            batch_size_tree=[2],  # default is 2
            batch_size_rows=[2],  # default is 2
            use_node3=[0],  # default is 0
        )
    elif script_args.scenario in (None, "LONG"):
        optim_params = dict(
            parallel_tree=[80, 160, 40],
            parallel_tree_N=[256, 128, 64],
            parallel_N=[100, 50, 25],
            batch_size_tree=[2, 4, 8],
            batch_size_rows=[2, 4, 8],
            use_node3=[0, 1],
        )
    else:
        raise ValueError(
            f"Unknown scenario {script_args.scenario!r}, use --help to get them."
        )








.. GENERATED FROM PYTHON SOURCE LINES 219-220

Then the optimization.

.. GENERATED FROM PYTHON SOURCE LINES 220-250

.. code-block:: default



    def create_session(onx):
        opts = SessionOptions()
        r = get_ort_ext_libs()
        if r is None:
            raise RuntimeError("No custom implementation available.")
        opts.register_custom_ops_library(r[0])
        return InferenceSession(
            onx.SerializeToString(), opts, providers=["CPUExecutionProvider"]
        )


    res = optimize_model(
        onx,
        feeds={"X": X[-batch_size:]},
        transform=transform_model,
        session=create_session,
        baseline=lambda onx: InferenceSession(
            onx.SerializeToString(), providers=["CPUExecutionProvider"]
        ),
        params=optim_params,
        verbose=True,
        number=script_args.number,
        repeat=script_args.repeat,
        warmup=script_args.warmup,
        sleep=script_args.sleep,
        n_tries=script_args.tries,
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

      0%|          | 0/16 [00:00<?, ?it/s]    i=1/16 TRY=0 parallel_tree=80 parallel_tree_N=128 parallel_N=50 batch_size_tree=2 batch_size_rows=2 use_node3=0:   0%|          | 0/16 [00:00<?, ?it/s]    i=1/16 TRY=0 parallel_tree=80 parallel_tree_N=128 parallel_N=50 batch_size_tree=2 batch_size_rows=2 use_node3=0:   6%|6         | 1/16 [00:00<00:13,  1.13it/s]    i=2/16 TRY=0 parallel_tree=80 parallel_tree_N=128 parallel_N=25 batch_size_tree=2 batch_size_rows=2 use_node3=0:   6%|6         | 1/16 [00:00<00:13,  1.13it/s]    i=2/16 TRY=0 parallel_tree=80 parallel_tree_N=128 parallel_N=25 batch_size_tree=2 batch_size_rows=2 use_node3=0:  12%|#2        | 2/16 [00:01<00:09,  1.50it/s]    i=3/16 TRY=0 parallel_tree=80 parallel_tree_N=64 parallel_N=50 batch_size_tree=2 batch_size_rows=2 use_node3=0:  12%|#2        | 2/16 [00:01<00:09,  1.50it/s]     i=3/16 TRY=0 parallel_tree=80 parallel_tree_N=64 parallel_N=50 batch_size_tree=2 batch_size_rows=2 use_node3=0:  19%|#8        | 3/16 [00:01<00:06,  2.00it/s]    i=4/16 TRY=0 parallel_tree=80 parallel_tree_N=64 parallel_N=25 batch_size_tree=2 batch_size_rows=2 use_node3=0:  19%|#8        | 3/16 [00:01<00:06,  2.00it/s]    i=4/16 TRY=0 parallel_tree=80 parallel_tree_N=64 parallel_N=25 batch_size_tree=2 batch_size_rows=2 use_node3=0:  25%|##5       | 4/16 [00:02<00:05,  2.31it/s]    i=5/16 TRY=0 parallel_tree=40 parallel_tree_N=128 parallel_N=50 batch_size_tree=2 batch_size_rows=2 use_node3=0:  25%|##5       | 4/16 [00:02<00:05,  2.31it/s]    i=5/16 TRY=0 parallel_tree=40 parallel_tree_N=128 parallel_N=50 batch_size_tree=2 batch_size_rows=2 use_node3=0:  31%|###1      | 5/16 [00:02<00:04,  2.41it/s]    i=6/16 TRY=0 parallel_tree=40 parallel_tree_N=128 parallel_N=25 batch_size_tree=2 batch_size_rows=2 use_node3=0:  31%|###1      | 5/16 [00:02<00:04,  2.41it/s]    i=6/16 TRY=0 parallel_tree=40 parallel_tree_N=128 parallel_N=25 batch_size_tree=2 batch_size_rows=2 use_node3=0:  38%|###7      | 6/16 [00:02<00:03,  2.52it/s]    i=7/16 TRY=0 parallel_tree=40 parallel_tree_N=64 parallel_N=50 batch_size_tree=2 batch_size_rows=2 use_node3=0:  38%|###7      | 6/16 [00:02<00:03,  2.52it/s]     i=7/16 TRY=0 parallel_tree=40 parallel_tree_N=64 parallel_N=50 batch_size_tree=2 batch_size_rows=2 use_node3=0:  44%|####3     | 7/16 [00:03<00:03,  2.83it/s]    i=8/16 TRY=0 parallel_tree=40 parallel_tree_N=64 parallel_N=25 batch_size_tree=2 batch_size_rows=2 use_node3=0:  44%|####3     | 7/16 [00:03<00:03,  2.83it/s]    i=8/16 TRY=0 parallel_tree=40 parallel_tree_N=64 parallel_N=25 batch_size_tree=2 batch_size_rows=2 use_node3=0:  50%|#####     | 8/16 [00:03<00:02,  3.14it/s]    i=9/16 TRY=1 parallel_tree=80 parallel_tree_N=128 parallel_N=50 batch_size_tree=2 batch_size_rows=2 use_node3=0:  50%|#####     | 8/16 [00:03<00:02,  3.14it/s]    i=9/16 TRY=1 parallel_tree=80 parallel_tree_N=128 parallel_N=50 batch_size_tree=2 batch_size_rows=2 use_node3=0:  56%|#####6    | 9/16 [00:03<00:02,  3.23it/s]    i=10/16 TRY=1 parallel_tree=80 parallel_tree_N=128 parallel_N=25 batch_size_tree=2 batch_size_rows=2 use_node3=0:  56%|#####6    | 9/16 [00:03<00:02,  3.23it/s]    i=10/16 TRY=1 parallel_tree=80 parallel_tree_N=128 parallel_N=25 batch_size_tree=2 batch_size_rows=2 use_node3=0:  62%|######2   | 10/16 [00:03<00:01,  3.08it/s]    i=11/16 TRY=1 parallel_tree=80 parallel_tree_N=64 parallel_N=50 batch_size_tree=2 batch_size_rows=2 use_node3=0:  62%|######2   | 10/16 [00:03<00:01,  3.08it/s]     i=11/16 TRY=1 parallel_tree=80 parallel_tree_N=64 parallel_N=50 batch_size_tree=2 batch_size_rows=2 use_node3=0:  69%|######8   | 11/16 [00:04<00:01,  2.95it/s]    i=12/16 TRY=1 parallel_tree=80 parallel_tree_N=64 parallel_N=25 batch_size_tree=2 batch_size_rows=2 use_node3=0:  69%|######8   | 11/16 [00:04<00:01,  2.95it/s]    i=12/16 TRY=1 parallel_tree=80 parallel_tree_N=64 parallel_N=25 batch_size_tree=2 batch_size_rows=2 use_node3=0:  75%|#######5  | 12/16 [00:04<00:01,  2.75it/s]    i=13/16 TRY=1 parallel_tree=40 parallel_tree_N=128 parallel_N=50 batch_size_tree=2 batch_size_rows=2 use_node3=0:  75%|#######5  | 12/16 [00:04<00:01,  2.75it/s]    i=13/16 TRY=1 parallel_tree=40 parallel_tree_N=128 parallel_N=50 batch_size_tree=2 batch_size_rows=2 use_node3=0:  81%|########1 | 13/16 [00:05<00:01,  2.79it/s]    i=14/16 TRY=1 parallel_tree=40 parallel_tree_N=128 parallel_N=25 batch_size_tree=2 batch_size_rows=2 use_node3=0:  81%|########1 | 13/16 [00:05<00:01,  2.79it/s]    i=14/16 TRY=1 parallel_tree=40 parallel_tree_N=128 parallel_N=25 batch_size_tree=2 batch_size_rows=2 use_node3=0:  88%|########7 | 14/16 [00:05<00:00,  2.76it/s]    i=15/16 TRY=1 parallel_tree=40 parallel_tree_N=64 parallel_N=50 batch_size_tree=2 batch_size_rows=2 use_node3=0:  88%|########7 | 14/16 [00:05<00:00,  2.76it/s]     i=15/16 TRY=1 parallel_tree=40 parallel_tree_N=64 parallel_N=50 batch_size_tree=2 batch_size_rows=2 use_node3=0:  94%|#########3| 15/16 [00:05<00:00,  2.67it/s]    i=16/16 TRY=1 parallel_tree=40 parallel_tree_N=64 parallel_N=25 batch_size_tree=2 batch_size_rows=2 use_node3=0:  94%|#########3| 15/16 [00:05<00:00,  2.67it/s]    i=16/16 TRY=1 parallel_tree=40 parallel_tree_N=64 parallel_N=25 batch_size_tree=2 batch_size_rows=2 use_node3=0: 100%|##########| 16/16 [00:06<00:00,  2.81it/s]    i=16/16 TRY=1 parallel_tree=40 parallel_tree_N=64 parallel_N=25 batch_size_tree=2 batch_size_rows=2 use_node3=0: 100%|##########| 16/16 [00:06<00:00,  2.60it/s]




.. GENERATED FROM PYTHON SOURCE LINES 251-252

And the results.

.. GENERATED FROM PYTHON SOURCE LINES 252-259

.. code-block:: default


    df = DataFrame(res)
    df.to_csv("plot_optim_tree_ensemble.csv", index=False)
    df.to_excel("plot_optim_tree_ensemble.xlsx", index=False)
    print(df.columns)
    print(df.head(5))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Index(['average', 'deviation', 'min_exec', 'max_exec', 'repeat', 'number',
           'ttime', 'context_size', 'warmup_time', 'n_exp', 'n_exp_name',
           'short_name', 'TRY', 'parallel_tree', 'parallel_tree_N', 'parallel_N',
           'batch_size_tree', 'batch_size_rows', 'use_node3'],
          dtype='object')
        average  deviation  min_exec  max_exec  repeat  number  ...  parallel_tree  parallel_tree_N  parallel_N  batch_size_tree batch_size_rows use_node3
    0  0.002982   0.001608  0.001797  0.005846      10      10  ...            NaN              NaN         NaN              NaN             NaN       NaN
    1  0.003363   0.001652  0.001652  0.007909      10      10  ...           80.0            128.0        50.0              2.0             2.0       0.0
    2  0.003817   0.000949  0.002614  0.006150      10      10  ...           80.0            128.0        25.0              2.0             2.0       0.0
    3  0.001819   0.000572  0.001271  0.003001      10      10  ...           80.0             64.0        50.0              2.0             2.0       0.0
    4  0.001828   0.000810  0.001217  0.004154      10      10  ...           80.0             64.0        25.0              2.0             2.0       0.0

    [5 rows x 19 columns]




.. GENERATED FROM PYTHON SOURCE LINES 260-262

Sorting
+++++++

.. GENERATED FROM PYTHON SOURCE LINES 262-277

.. code-block:: default


    small_df = df.drop(
        [
            "min_exec",
            "max_exec",
            "repeat",
            "number",
            "context_size",
            "n_exp_name",
        ],
        axis=1,
    ).sort_values("average")
    print(small_df.head(n=10))






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

         average  deviation     ttime  warmup_time  n_exp  ... parallel_tree_N  parallel_N  batch_size_tree  batch_size_rows  use_node3
    8   0.001273   0.000113  0.012734     0.010122      7  ...            64.0        25.0              2.0              2.0        0.0
    7   0.001421   0.000187  0.014210     0.008814      6  ...            64.0        50.0              2.0              2.0        0.0
    9   0.001753   0.000437  0.017533     0.010902      8  ...           128.0        50.0              2.0              2.0        0.0
    3   0.001819   0.000572  0.018194     0.011289      2  ...            64.0        50.0              2.0              2.0        0.0
    4   0.001828   0.000810  0.018276     0.045096      3  ...            64.0        25.0              2.0              2.0        0.0
    16  0.001882   0.001026  0.018820     0.015814     15  ...            64.0        25.0              2.0              2.0        0.0
    13  0.002172   0.001456  0.021716     0.016895     12  ...           128.0        50.0              2.0              2.0        0.0
    10  0.002362   0.000507  0.023618     0.014038      9  ...           128.0        25.0              2.0              2.0        0.0
    6   0.002498   0.000964  0.024976     0.006433      5  ...           128.0        25.0              2.0              2.0        0.0
    14  0.002506   0.000943  0.025060     0.014789     13  ...           128.0        25.0              2.0              2.0        0.0

    [10 rows x 13 columns]




.. GENERATED FROM PYTHON SOURCE LINES 278-280

Worst
+++++

.. GENERATED FROM PYTHON SOURCE LINES 280-284

.. code-block:: default


    print(small_df.tail(n=10))






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

         average  deviation     ttime  warmup_time  n_exp  ... parallel_tree_N  parallel_N  batch_size_tree  batch_size_rows  use_node3
    6   0.002498   0.000964  0.024976     0.006433      5  ...           128.0        25.0              2.0              2.0        0.0
    14  0.002506   0.000943  0.025060     0.014789     13  ...           128.0        25.0              2.0              2.0        0.0
    11  0.002534   0.000724  0.025345     0.012559     10  ...            64.0        50.0              2.0              2.0        0.0
    17  0.002572   0.001049  0.025719     0.018590      0  ...             NaN         NaN              NaN              NaN        NaN
    5   0.002612   0.000817  0.026117     0.013276      4  ...           128.0        50.0              2.0              2.0        0.0
    15  0.002835   0.001099  0.028353     0.015033     14  ...            64.0        50.0              2.0              2.0        0.0
    0   0.002982   0.001608  0.029825     0.025820      0  ...             NaN         NaN              NaN              NaN        NaN
    12  0.002991   0.000590  0.029914     0.007007     11  ...            64.0        25.0              2.0              2.0        0.0
    1   0.003363   0.001652  0.033629     0.015023      0  ...           128.0        50.0              2.0              2.0        0.0
    2   0.003817   0.000949  0.038174     0.023120      1  ...           128.0        25.0              2.0              2.0        0.0

    [10 rows x 13 columns]




.. GENERATED FROM PYTHON SOURCE LINES 285-287

Plot
++++

.. GENERATED FROM PYTHON SOURCE LINES 287-313

.. code-block:: default


    dfi = df[["short_name", "average"]].sort_values("average").reset_index(drop=True)
    baseline = dfi[dfi.short_name.str.contains("baseline")]
    not_baseline = dfi[~dfi.short_name.str.contains("baseline")].reset_index(drop=True)
    if not_baseline.shape[0] > 50:
        not_baseline = not_baseline[:50]
    merged = concat([baseline, not_baseline], axis=0)
    merged = merged.sort_values("average").reset_index(drop=True).set_index("short_name")
    skeys = ",".join(optim_params.keys())

    fig, ax = plt.subplots(1, 1, figsize=(10, merged.shape[0] / 4))
    merged.plot.barh(
        ax=ax, title=f"TreeEnsemble tuning, n_tries={script_args.tries}\n{skeys}"
    )
    b = df.loc[0, "average"]
    ax.plot([b, b], [0, df.shape[0]], "r--")
    ax.set_xlim(
        [
            (df["min_exec"].min() + df["average"].min()) / 2,
            (df["max_exec"].max() + df["average"].max()) / 2,
        ]
    )
    ax.set_xscale("log")

    fig.tight_layout()
    fig.savefig("plot_optim_tree_ensemble.png")



.. image-sg:: /auto_examples/images/sphx_glr_plot_optim_tree_ensemble_001.png
   :alt: TreeEnsemble tuning, n_tries=2 parallel_tree,parallel_tree_N,parallel_N,batch_size_tree,batch_size_rows,use_node3
   :srcset: /auto_examples/images/sphx_glr_plot_optim_tree_ensemble_001.png
   :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  18.844 seconds)


.. _sphx_glr_download_auto_examples_plot_optim_tree_ensemble.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example




    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_optim_tree_ensemble.py <plot_optim_tree_ensemble.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_optim_tree_ensemble.ipynb <plot_optim_tree_ensemble.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
