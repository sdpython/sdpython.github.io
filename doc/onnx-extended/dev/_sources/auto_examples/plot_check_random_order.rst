
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_check_random_order.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_plot_check_random_order.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_check_random_order.py:


Random order for a sum
======================

Parallelization usually means a summation is done with a random order.
That may lead to different values if the computation is made many times
even though the result should be the same. This example compares
summation of random permutation of the same array of values.

Setup
+++++

.. GENERATED FROM PYTHON SOURCE LINES 13-31

.. code-block:: Python

    from tqdm import tqdm
    import numpy as np

    unique_values = np.array(
        [2.1102535724639893, 0.5986238718032837, -0.49545818567276], dtype=np.float32
    )
    random_index = np.random.randint(0, 3, 2000)
    assert set(random_index) == {0, 1, 2}
    values = unique_values[random_index]

    s0 = values.sum()
    s1 = np.array(0, dtype=np.float32)
    for n in values:
        s1 += n

    delta = s1 - s0
    print(f"reduced sum={s0}, iterative sum={s1}, delta={delta}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    reduced sum=1399.2508544921875, iterative sum=1399.236328125, delta=-0.0145263671875




.. GENERATED FROM PYTHON SOURCE LINES 32-39

There are discrepancies.

Random order
++++++++++++

Let's go further and check the sum of random permutation of the same set.
Let's compare the result with the same sum done with a higher precision (double).

.. GENERATED FROM PYTHON SOURCE LINES 39-66

.. code-block:: Python



    def check_orders(values, n=200, bias=0):
        double_sums = []
        sums = []
        reduced_sums = []
        for i in tqdm(range(n)):
            permuted_values = np.random.permutation(values)
            s = np.array(bias, dtype=np.float32)
            sd = np.array(bias, dtype=np.float64)
            for n in permuted_values:
                s += n
                sd += n
            sums.append(s)
            double_sums.append(sd)
            reduced_sums.append(permuted_values.sum() + bias)

        mi, ma = min(sums), max(sums)
        print(f"min={mi} max={ma} delta={ma-mi}")
        mi, ma = min(double_sums), max(double_sums)
        print(f"min={mi} max={ma} delta={ma-mi} (double)")
        mi, ma = min(reduced_sums), max(reduced_sums)
        print(f"min={mi} max={ma} delta={ma-mi} (reduced)")


    check_orders(values)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

      0%|          | 0/200 [00:00<?, ?it/s]      4%|▎         | 7/200 [00:00<00:02, 68.78it/s]      7%|▋         | 14/200 [00:00<00:02, 62.44it/s]     10%|█         | 21/200 [00:00<00:02, 59.75it/s]     14%|█▍        | 28/200 [00:00<00:02, 63.00it/s]     18%|█▊        | 36/200 [00:00<00:02, 67.39it/s]     22%|██▏       | 43/200 [00:00<00:02, 66.33it/s]     26%|██▌       | 51/200 [00:00<00:02, 68.31it/s]     29%|██▉       | 58/200 [00:00<00:02, 55.97it/s]     32%|███▏      | 64/200 [00:01<00:02, 55.11it/s]     37%|███▋      | 74/200 [00:01<00:01, 65.82it/s]     42%|████▏     | 84/200 [00:01<00:01, 73.98it/s]     46%|████▌     | 92/200 [00:01<00:01, 71.99it/s]     51%|█████     | 102/200 [00:01<00:01, 77.66it/s]     56%|█████▌    | 112/200 [00:01<00:01, 83.52it/s]     62%|██████▏   | 123/200 [00:01<00:00, 89.34it/s]     66%|██████▋   | 133/200 [00:02<00:01, 43.20it/s]     70%|███████   | 140/200 [00:02<00:01, 33.89it/s]     73%|███████▎  | 146/200 [00:02<00:01, 29.57it/s]     76%|███████▌  | 151/200 [00:02<00:01, 30.85it/s]     78%|███████▊  | 156/200 [00:03<00:01, 33.75it/s]     80%|████████  | 161/200 [00:03<00:01, 34.78it/s]     84%|████████▎ | 167/200 [00:03<00:00, 37.38it/s]     86%|████████▌ | 172/200 [00:03<00:00, 36.23it/s]     88%|████████▊ | 177/200 [00:03<00:00, 39.07it/s]     91%|█████████ | 182/200 [00:03<00:00, 36.76it/s]     94%|█████████▎| 187/200 [00:03<00:00, 39.63it/s]     96%|█████████▌| 192/200 [00:04<00:00, 35.50it/s]     98%|█████████▊| 196/200 [00:04<00:00, 30.10it/s]    100%|██████████| 200/200 [00:04<00:00, 27.39it/s]    100%|██████████| 200/200 [00:04<00:00, 45.25it/s]
    min=1399.2342529296875 max=1399.239013671875 delta=0.0047607421875
    min=1399.250859439373 max=1399.250859439373 delta=0.0 (double)
    min=1399.250732421875 max=1399.2508544921875 delta=0.0001220703125 (reduced)




.. GENERATED FROM PYTHON SOURCE LINES 67-79

This example clearly shows the order has an impact.
It is usually unavoidable but it could reduced if the sum
it close to zero. In that case, the sum would be of the same
order of magnitude of the add values.

Removing the average
++++++++++++++++++++

Computing the average of the values requires to compute the sum.
However if we have an estimator of this average, not necessarily
the exact value, we would help the summation to keep the same order
of magnitude than the values it adds.

.. GENERATED FROM PYTHON SOURCE LINES 79-84

.. code-block:: Python


    mean = unique_values.mean()
    values -= mean
    check_orders(values, bias=len(values) * mean)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

      0%|          | 0/200 [00:00<?, ?it/s]      2%|▏         | 3/200 [00:00<00:08, 22.62it/s]      3%|▎         | 6/200 [00:00<00:07, 25.05it/s]      4%|▍         | 9/200 [00:00<00:09, 20.85it/s]      6%|▌         | 12/200 [00:00<00:10, 18.16it/s]      8%|▊         | 15/200 [00:00<00:09, 19.72it/s]     10%|█         | 20/200 [00:00<00:06, 26.51it/s]     12%|█▏        | 24/200 [00:00<00:06, 27.29it/s]     14%|█▎        | 27/200 [00:01<00:06, 26.94it/s]     15%|█▌        | 30/200 [00:01<00:07, 24.12it/s]     16%|█▋        | 33/200 [00:01<00:07, 22.24it/s]     18%|█▊        | 36/200 [00:01<00:07, 21.78it/s]     20%|█▉        | 39/200 [00:01<00:07, 22.55it/s]     21%|██        | 42/200 [00:01<00:07, 21.38it/s]     22%|██▎       | 45/200 [00:02<00:07, 19.79it/s]     24%|██▍       | 48/200 [00:02<00:08, 18.40it/s]     25%|██▌       | 50/200 [00:02<00:08, 17.81it/s]     26%|██▋       | 53/200 [00:02<00:07, 18.46it/s]     28%|██▊       | 55/200 [00:02<00:08, 17.04it/s]     28%|██▊       | 57/200 [00:02<00:08, 17.19it/s]     30%|██▉       | 59/200 [00:02<00:08, 16.15it/s]     32%|███▏      | 63/200 [00:03<00:06, 19.70it/s]     33%|███▎      | 66/200 [00:03<00:06, 21.09it/s]     34%|███▍      | 69/200 [00:03<00:06, 21.25it/s]     38%|███▊      | 75/200 [00:03<00:04, 29.71it/s]     40%|███▉      | 79/200 [00:03<00:03, 31.26it/s]     42%|████▏     | 83/200 [00:03<00:04, 28.10it/s]     44%|████▍     | 88/200 [00:03<00:03, 33.12it/s]     48%|████▊     | 97/200 [00:03<00:02, 46.32it/s]     53%|█████▎    | 106/200 [00:04<00:01, 57.23it/s]     58%|█████▊    | 117/200 [00:04<00:01, 71.42it/s]     62%|██████▎   | 125/200 [00:04<00:01, 72.77it/s]     68%|██████▊   | 135/200 [00:04<00:00, 78.79it/s]     72%|███████▏  | 144/200 [00:04<00:00, 75.34it/s]     76%|███████▌  | 152/200 [00:04<00:00, 63.21it/s]     80%|████████  | 160/200 [00:04<00:00, 66.47it/s]     85%|████████▌ | 170/200 [00:04<00:00, 74.65it/s]     90%|█████████ | 180/200 [00:04<00:00, 80.35it/s]     94%|█████████▍| 189/200 [00:05<00:00, 82.79it/s]    100%|██████████| 200/200 [00:05<00:00, 89.45it/s]    100%|██████████| 200/200 [00:05<00:00, 38.79it/s]
    min=1399.250732421875 max=1399.250732421875 delta=0.0
    min=1399.2508212327957 max=1399.2508212327957 delta=0.0 (double)
    min=1399.250823020935 max=1399.2508535385132 delta=3.0517578125e-05 (reduced)




.. GENERATED FROM PYTHON SOURCE LINES 85-86

The differences are clearly lower.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 9.647 seconds)


.. _sphx_glr_download_auto_examples_plot_check_random_order.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_check_random_order.ipynb <plot_check_random_order.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_check_random_order.py <plot_check_random_order.py>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
