{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Registering a custom class as a pytree node\n\n:func:`torch.export.export` requires every object that appears as a model\ninput or output to be decomposable into a flat list of\n:class:`torch.Tensor` objects.  ``torch.utils._pytree`` handles this\ndecomposition, but it only knows about built-in Python containers.\nCustom classes \u2014 including all the cache types from :epkg:`transformers` \u2014\nmust be explicitly **registered** before exporting.\n\nThis example walks through the three steps:\n\n1. Writing *flatten* / *unflatten* / *flatten-with-keys* callables for a\n   custom dict-like class.\n2. Registering the class with\n   :func:`register_class_flattening\n   <yobx.torch.flatten_helper.register_class_flattening>`.\n3. Verifying the round-trip and then cleaning up with\n   :func:`unregister_class_flattening\n   <yobx.torch.flatten_helper.unregister_class_flattening>`.\n\nSee `l-design-flatten` for a full description of the flattening design\nincluding the :epkg:`transformers` cache registrations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\nimport torch\nimport torch.utils._pytree\nfrom yobx.torch.flatten_helper import (\n    make_flattening_function_for_dataclass,\n    register_class_flattening,\n    unregister_class_flattening,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Define a custom dict-like container\n\nWe create a minimal dict subclass that stores named tensors.  This pattern\nmirrors how :class:`transformers.modeling_outputs.ModelOutput` works.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class EncoderOutput(dict):\n    \"\"\"Holds the output tensors produced by a (mock) encoder.\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Write the three required callables\n\n* **flatten** \u2014 extract a flat list of tensors plus a *context* (the key\n  order) that is needed to reconstruct the original object.\n* **flatten_with_keys** \u2014 same, but pair each tensor with a\n  :class:`torch.utils._pytree.MappingKey` so that :func:`torch.export.export`\n  can refer to each leaf by name.\n* **unflatten** \u2014 given the flat tensors and the context, recreate the\n  original :class:`EncoderOutput`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def flatten_encoder_output(obj):\n    keys = list(obj.keys())\n    return [obj[k] for k in keys], keys\n\n\ndef flatten_with_keys_encoder_output(obj):\n    keys = list(obj.keys())\n    values = [obj[k] for k in keys]\n    return [(torch.utils._pytree.MappingKey(k), v) for k, v in zip(keys, values)], keys\n\n\ndef unflatten_encoder_output(values, context, output_type=None):\n    return EncoderOutput(zip(context, values))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Register the class\n\n:func:`register_class_flattening\n<yobx.torch.flatten_helper.register_class_flattening>` wraps\n``torch.utils._pytree.register_pytree_node`` and returns ``True`` when the\nregistration succeeds (``False`` when the class is already registered).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "registered = register_class_flattening(\n    EncoderOutput,\n    flatten_encoder_output,\n    unflatten_encoder_output,\n    flatten_with_keys_encoder_output,\n)\nassert EncoderOutput in torch.utils._pytree.SUPPORTED_NODES\nprint(\"registered:\", registered)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Flatten a nested structure\n\nOnce registered, ``torch.utils._pytree.tree_flatten`` can decompose any\nnested Python structure that contains :class:`EncoderOutput` objects.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "output = EncoderOutput(t1=torch.zeros(2, 5, 8), t2=torch.ones(2, 8))\n\nflat, spec = torch.utils._pytree.tree_flatten(output)\nprint(\"number of leaf tensors:\", len(flat))\nfor i, t in enumerate(flat):\n    print(f\"  leaf[{i}]: shape={tuple(t.shape)}, dtype={t.dtype}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Unflatten and verify the round-trip\n\n:func:`torch.utils._pytree.tree_unflatten` reconstructs the original\n:class:`EncoderOutput` from the flat list using the spec returned by\n``tree_flatten``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "restored = torch.utils._pytree.tree_unflatten(flat, spec)\nprint(\"restored type :\", type(restored).__name__)\nprint(\"restored keys :\", list(restored.keys()))\nassert torch.equal(restored[\"t1\"], output[\"t1\"])\nassert torch.equal(restored[\"t2\"], output[\"t2\"])\nprint(\"round-trip OK\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Auto-generate callables with make_flattening_function_for_dataclass\n\nFor classes that already expose ``.keys()`` / ``.values()`` (all\n:class:`transformers.modeling_outputs.ModelOutput` subclasses do),\n:func:`make_flattening_function_for_dataclass\n<yobx.torch.flatten_helper.make_flattening_function_for_dataclass>`\ngenerates the three required callables automatically.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "@dataclass\nclass EncoderOutput2:\n    \"\"\"Holds the output tensors produced by a (mock) encoder.\"\"\"\n\n    t1: torch.Tensor\n    t2: torch.Tensor\n\n\nsupported = set()\nflatten_fn, flatten_with_keys_fn, unflatten_fn = make_flattening_function_for_dataclass(\n    EncoderOutput2, supported\n)\n\nprint(\"auto-generated names:\")\nprint(\" \", flatten_fn.__name__)\nprint(\" \", flatten_with_keys_fn.__name__)\nprint(\" \", unflatten_fn.__name__)\nprint(\"supported set:\", {c.__name__ for c in supported})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's register.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "registered = register_class_flattening(\n    EncoderOutput2, flatten_fn, unflatten_fn, flatten_with_keys_fn\n)\nassert EncoderOutput2 in torch.utils._pytree.SUPPORTED_NODES\nprint(\"registered:\", registered)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "New test.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "output2 = EncoderOutput2(t1=torch.zeros(2, 5, 8), t2=torch.ones(2, 8))\n\nflat, spec = torch.utils._pytree.tree_flatten(output)\nrestored = torch.utils._pytree.tree_unflatten(flat, spec)\nprint(\"restored type :\", type(restored).__name__)\nprint(\"restored keys :\", list(restored.keys()))\nassert torch.equal(restored[\"t1\"], output[\"t1\"])\nassert torch.equal(restored[\"t2\"], output[\"t2\"])\nprint(\"round-trip OK again\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Unregister to restore the original state\n\nAfter exporting (or when running inside a test) call\n:func:`unregister_class_flattening\n<yobx.torch.flatten_helper.unregister_class_flattening>` to undo the\nregistration and leave ``torch.utils._pytree.SUPPORTED_NODES`` exactly as\nit was before.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "assert EncoderOutput in torch.utils._pytree.SUPPORTED_NODES\nassert EncoderOutput2 in torch.utils._pytree.SUPPORTED_NODES\nunregister_class_flattening(EncoderOutput)\nunregister_class_flattening(EncoderOutput2)\nprint(\"EncoderOutput and EncoderOutput2 unregistered\")\nassert EncoderOutput not in torch.utils._pytree.SUPPORTED_NODES\nassert EncoderOutput2 not in torch.utils._pytree.SUPPORTED_NODES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot: pytree flatten / unflatten diagram\n\nThe diagram below illustrates the flatten\u2192leaf-list\u2192unflatten round-trip\nfor an :class:`EncoderOutput` container with two tensor fields.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt  # noqa: E402\nimport matplotlib.patches as mpatches  # noqa: E402\n\nfig, ax = plt.subplots(figsize=(7, 3.5))\nax.set_xlim(0, 10)\nax.set_ylim(0, 5)\nax.axis(\"off\")\nax.set_title(\"pytree flatten / unflatten round-trip\", fontsize=11)\n\n# Container box\ncontainer = mpatches.FancyBboxPatch(\n    (0.3, 1.5),\n    2.6,\n    2.0,\n    boxstyle=\"round,pad=0.15\",\n    linewidth=1.5,\n    edgecolor=\"#4c72b0\",\n    facecolor=\"#dce9f5\",\n)\nax.add_patch(container)\nax.text(1.6, 3.7, \"EncoderOutput\", ha=\"center\", va=\"center\", fontsize=9, fontweight=\"bold\")\nax.text(1.6, 2.85, \"t1: Tensor(2,5,8)\", ha=\"center\", va=\"center\", fontsize=8)\nax.text(1.6, 2.35, \"t2: Tensor(2,8)\", ha=\"center\", va=\"center\", fontsize=8)\n\n# Flat list box\nflat_box = mpatches.FancyBboxPatch(\n    (3.8, 1.5),\n    2.6,\n    2.0,\n    boxstyle=\"round,pad=0.15\",\n    linewidth=1.5,\n    edgecolor=\"#dd8452\",\n    facecolor=\"#fde8d8\",\n)\nax.add_patch(flat_box)\nax.text(5.1, 3.7, \"flat list + spec\", ha=\"center\", va=\"center\", fontsize=9, fontweight=\"bold\")\nax.text(5.1, 2.85, \"[Tensor(2,5,8),\", ha=\"center\", va=\"center\", fontsize=8)\nax.text(5.1, 2.35, \" Tensor(2,8)]\", ha=\"center\", va=\"center\", fontsize=8)\n\n# Restored box\nrestored_box = mpatches.FancyBboxPatch(\n    (7.3, 1.5),\n    2.4,\n    2.0,\n    boxstyle=\"round,pad=0.15\",\n    linewidth=1.5,\n    edgecolor=\"#4c72b0\",\n    facecolor=\"#dce9f5\",\n)\nax.add_patch(restored_box)\nax.text(8.5, 3.7, \"Restored\", ha=\"center\", va=\"center\", fontsize=9, fontweight=\"bold\")\nax.text(8.5, 2.85, \"t1: Tensor(2,5,8)\", ha=\"center\", va=\"center\", fontsize=8)\nax.text(8.5, 2.35, \"t2: Tensor(2,8)\", ha=\"center\", va=\"center\", fontsize=8)\n\n# Arrows\nax.annotate(\n    \"\",\n    xy=(3.8, 2.5),\n    xytext=(2.9, 2.5),\n    arrowprops=dict(arrowstyle=\"->\", color=\"#dd8452\", lw=1.5),\n)\nax.text(3.35, 2.75, \"flatten\", ha=\"center\", va=\"bottom\", fontsize=8, color=\"#dd8452\")\n\nax.annotate(\n    \"\",\n    xy=(7.3, 2.5),\n    xytext=(6.4, 2.5),\n    arrowprops=dict(arrowstyle=\"->\", color=\"#4c72b0\", lw=1.5),\n)\nax.text(6.85, 2.75, \"unflatten\", ha=\"center\", va=\"bottom\", fontsize=8, color=\"#4c72b0\")\n\nplt.tight_layout()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}