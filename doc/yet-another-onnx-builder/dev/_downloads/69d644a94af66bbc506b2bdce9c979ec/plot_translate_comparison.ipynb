{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Comparing the four ONNX translation APIs\n\n:func:`translate <yobx.translate.translate>` converts an\n:class:`onnx.ModelProto` into Python source code that, when executed,\nrecreates the same model.  Four output APIs are available:\n\n* ``\"onnx\"`` \u2014 uses :mod:`onnx.helper` (``oh.make_node``, ``oh.make_graph``, \u2026)\n  via :class:`~yobx.translate.inner_emitter.InnerEmitter`.\n* ``\"onnx-short\"`` \u2014 same as ``\"onnx\"`` but replaces large initializers with\n  random values to keep the snippet compact, via\n  :class:`~yobx.translate.inner_emitter.InnerEmitterShortInitializer`.\n* ``\"light\"`` \u2014 fluent ``start(\u2026).vin(\u2026).\u2026`` chain,\n  via :class:`~yobx.translate.light_emitter.LightEmitter`.\n* ``\"builder\"`` \u2014 ``GraphBuilder``-based function wrapper,\n  via :class:`~yobx.translate.builder_emitter.BuilderEmitter`.\n\nThis example builds a small model, translates it with every API, shows the\ngenerated code, and verifies that the ``\"onnx\"`` snippet can be re-executed to\nreproduce the original model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport onnx\nimport onnx.helper as oh\nimport onnx.numpy_helper as onh\nfrom yobx.translate import translate, translate_header"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build the model\n\nWe use ``Z = Relu(X @ W + b)`` as a running example:\na single ``Gemm`` followed by ``Relu``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "TFLOAT = onnx.TensorProto.FLOAT\nINT64 = onnx.TensorProto.INT64\n\nW = onh.from_array(np.random.randn(8, 5).astype(np.float32), name=\"W\")\nb = onh.from_array(np.random.randn(5).astype(np.float32), name=\"b\")\n\nmodel = oh.make_model(\n    oh.make_graph(\n        [\n            oh.make_node(\"Gemm\", [\"X\", \"W\", \"b\"], [\"T\"]),\n            oh.make_node(\"Relu\", [\"T\"], [\"Z\"]),\n        ],\n        \"gemm_relu\",\n        [oh.make_tensor_value_info(\"X\", TFLOAT, [None, 8])],\n        [oh.make_tensor_value_info(\"Z\", TFLOAT, [None, 5])],\n        [W, b],\n    ),\n    opset_imports=[oh.make_opsetid(\"\", 17)],\n    ir_version=9,\n)\n\nprint(f\"Model: {len(model.graph.node)} node(s), {len(model.graph.initializer)} initializer(s)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. ``\"onnx\"`` API \u2014 full initializer values\n\nThe generated code uses :func:`onnx.helper.make_node`,\n:func:`onnx.helper.make_graph`, and :func:`onnx.helper.make_model`.\nEvery initializer is serialised as an exact ``np.array(\u2026)`` literal.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "code_onnx = translate(model, api=\"onnx\")\nprint(\"=== api='onnx' ===\")\nprint(code_onnx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. ``\"onnx-short\"`` API \u2014 large initializers replaced by random values\n\nIdentical to ``\"onnx\"`` except that initializers with more than 16 elements\nare replaced by ``np.random.randn(\u2026)`` / ``np.random.randint(\u2026)`` calls.\nThis keeps the snippet readable when dealing with large weight tensors.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "code_short = translate(model, api=\"onnx-short\")\nprint(\"=== api='onnx-short' ===\")\nprint(code_short)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Size comparison between the two onnx variants:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(f\"\\nFull code length  : {len(code_onnx):>6} characters\")\nprint(f\"Short code length : {len(code_short):>6} characters\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. ``\"light\"`` API \u2014 fluent chain\n\nThe output is a single method-chain expression (``start(\u2026).vin(\u2026).\u2026``).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "code_light = translate(model, api=\"light\")\nprint(\"=== api='light' ===\")\nprint(code_light)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. ``\"builder\"`` API \u2014 GraphBuilder\n\nThe output uses ``GraphBuilder`` to wrap the graph nodes in a Python function.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "code_builder = translate(model, api=\"builder\")\nprint(\"=== api='builder' ===\")\nprint(code_builder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Round-trip verification\n\nThe ``\"onnx\"`` snippet is fully self-contained and executable.\nRunning it should recreate a model with the same graph structure.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "header = translate_header(\"onnx\")\nfull_code = header + \"\\n\" + code_onnx\nns: dict = {}\nexec(compile(full_code, \"<translate>\", \"exec\"), ns)  # noqa: S102\nrecreated = ns[\"model\"]\n\nassert isinstance(recreated, onnx.ModelProto)\nassert len(recreated.graph.node) == len(\n    model.graph.node\n), f\"Expected {len(model.graph.node)} nodes, got {len(recreated.graph.node)}\"\nassert len(recreated.graph.initializer) == len(model.graph.initializer), (\n    f\"Expected {len(model.graph.initializer)} initializers, \"\n    f\"got {len(recreated.graph.initializer)}\"\n)\nprint(\"\\nRound-trip succeeded \u2713\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot: code size by API\n\nThe bar chart compares the number of characters produced by each API for the\nsame model.  ``\"onnx-short\"`` is always \u2264 ``\"onnx\"`` because it compresses\nlarge initializers.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt  # noqa: E402\n\napi_labels = [\"onnx\", \"onnx-short\", \"light\", \"builder\"]\ncode_sizes = [len(code_onnx), len(code_short), len(code_light), len(code_builder)]\n\nfig, ax = plt.subplots(figsize=(7, 4))\nbars = ax.bar(api_labels, code_sizes, color=[\"#4c72b0\", \"#dd8452\", \"#55a868\", \"#c44e52\"])\nax.set_ylabel(\"Generated code size (characters)\")\nax.set_title(\"ONNX translation: code size by API\")\nfor bar, size in zip(bars, code_sizes):\n    ax.text(\n        bar.get_x() + bar.get_width() / 2,\n        bar.get_height() * 1.01,\n        str(size),\n        ha=\"center\",\n        va=\"bottom\",\n        fontsize=9,\n    )\nplt.tight_layout()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}