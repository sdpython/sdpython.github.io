{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Comparing the three evaluators\n\n``yobx`` ships three evaluators that share the same\n``run(outputs, feeds)`` interface but differ in their backend:\n\n* :class:`ExtendedReferenceEvaluator\n  <yobx.reference.evaluator.ExtendedReferenceEvaluator>` \u2014 pure Python /\n  NumPy, extends :class:`onnx.reference.ReferenceEvaluator` with contrib-op\n  kernels.  No ONNX Runtime dependency.\n* :class:`OnnxruntimeEvaluator\n  <yobx.reference.onnxruntime_evaluator.OnnxruntimeEvaluator>` \u2014 runs each\n  node individually through :class:`onnxruntime.InferenceSession`.  Allows\n  full intermediate-result inspection.\n* :class:`TorchReferenceEvaluator\n  <yobx.reference.torch_evaluator.TorchReferenceEvaluator>` \u2014 hand-written\n  PyTorch kernels; inputs and outputs are :class:`torch.Tensor`; supports\n  CUDA.\n\nThis example runs the same model through all three and verifies the outputs\nagree.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport onnx\nimport onnx.helper as oh\nimport torch\nfrom yobx.reference import ExtendedReferenceEvaluator\nfrom yobx.reference.onnxruntime_evaluator import OnnxruntimeEvaluator\nfrom yobx.reference.torch_evaluator import TorchReferenceEvaluator\n\nTFLOAT = onnx.TensorProto.FLOAT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build a small model\n\nThe model computes ``Z = Tanh(X + Y)``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = oh.make_model(\n    oh.make_graph(\n        [\n            oh.make_node(\"Add\", [\"X\", \"Y\"], [\"T\"]),\n            oh.make_node(\"Tanh\", [\"T\"], [\"Z\"]),\n        ],\n        \"add_tanh\",\n        [\n            oh.make_tensor_value_info(\"X\", TFLOAT, [None, None]),\n            oh.make_tensor_value_info(\"Y\", TFLOAT, [None, None]),\n        ],\n        [oh.make_tensor_value_info(\"Z\", TFLOAT, [None, None])],\n    ),\n    opset_imports=[oh.make_opsetid(\"\", 18)],\n    ir_version=10,\n)\n\nx = np.array([[1.0, -2.0], [3.0, -4.0]], dtype=np.float32)\ny = np.array([[0.5, 0.5], [-0.5, -0.5]], dtype=np.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. ExtendedReferenceEvaluator\n\nPure Python / NumPy.  A drop-in replacement for\n:class:`onnx.reference.ReferenceEvaluator` that also handles contrib ops.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ref = ExtendedReferenceEvaluator(model)\n(result_ref,) = ref.run(None, {\"X\": x, \"Y\": y})\nprint(\"ExtendedReferenceEvaluator:\", result_ref)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. OnnxruntimeEvaluator\n\nExecutes each node via ONNX Runtime.  Setting ``intermediate=True``\nreturns a dictionary with *all* intermediate results, which is very\nhandy when debugging a model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ort_eval = OnnxruntimeEvaluator(model)\n(result_ort,) = ort_eval.run(None, {\"X\": x, \"Y\": y})\nprint(\"OnnxruntimeEvaluator:\", result_ort)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Retrieve intermediate results:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "all_intermediates = ort_eval.run(None, {\"X\": x, \"Y\": y}, intermediate=True)\nfor name, value in sorted(all_intermediates.items()):\n    print(f\"  {name}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. TorchReferenceEvaluator\n\nAll computation uses PyTorch tensors.  The same model can run on CUDA\nby passing ``providers=[\"CUDAExecutionProvider\"]``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "torch_eval = TorchReferenceEvaluator(model)\nx_t = torch.from_numpy(x)\ny_t = torch.from_numpy(y)\n(result_torch,) = torch_eval.run(None, {\"X\": x_t, \"Y\": y_t})\nprint(\"TorchReferenceEvaluator:\", result_torch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Verify all three evaluators agree\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "assert np.allclose(result_ref, result_ort), \"ExtendedRef vs ORT mismatch\"\nassert np.allclose(result_ref, result_torch.numpy()), \"ExtendedRef vs Torch mismatch\"\nprint(\"All three evaluators produce the same result \u2713\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n\n+---------------------------------+--------------------+-----------------------------+\n| Evaluator                       | Input/output type  | Highlights                  |\n+=================================+====================+=============================+\n| ExtendedReferenceEvaluator      | NumPy ndarray      | No ORT required; contrib ops|\n+---------------------------------+--------------------+-----------------------------+\n| OnnxruntimeEvaluator            | NumPy or PyTorch   | intermediate=True; ORT backend |\n+---------------------------------+--------------------+-----------------------------+\n| TorchReferenceEvaluator         | torch.Tensor       | CUDA support; no round-trip |\n+---------------------------------+--------------------+-----------------------------+\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}