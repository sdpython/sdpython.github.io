{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# InputObserver: recording inputs for ONNX export\n\n:class:`InputObserver <yobx.torch.input_observer.InputObserver>` is a context manager\nthat **steals** a model's forward method during inference to record every set of inputs\nand outputs.  After the context exits, the collected data can be used to:\n\n* infer which tensor dimensions are **dynamic** across the observed calls, and\n* build a representative set of **export arguments** (with empty tensors for optional\n  inputs that were missing in some calls).\n\nThese two pieces of information are exactly what :func:`torch.export.export` and\n:func:`torch.onnx.export` need.\n\nThe example below shows three progressively richer scenarios:\n\n1. **Positional args** \u2014 two plain tensors whose batch and sequence lengths vary across\n   calls.\n2. **Keyword args** \u2014 same model, but inputs are passed as named arguments.\n3. **Optional argument** \u2014 a model where one input (``mask``) is absent in some calls.\n   The ``value_if_missing`` parameter tells the observer what substitute to use when the\n   argument is missing, so that dynamic shape analysis can still be performed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nfrom yobx.helpers import string_type\nfrom yobx.torch.input_observer import InputObserver"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Positional args \u2014 varying batch and sequence lengths\n\nWe start with the most basic case: a model that takes two float tensors and\nreturns their element-wise sum.  We run it with three different shapes so\nthat the observer can detect that both dimensions are dynamic.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class AddModel(torch.nn.Module):\n    \"\"\"Adds two tensors element-wise.\"\"\"\n\n    def forward(self, x, y):\n        return x + y\n\n\nmodel_add = AddModel()\n\n# Three calls with different shapes \u2014 batch size and sequence length both vary.\ninputs_add = [\n    (torch.randn(2, 6), torch.randn(2, 6)),\n    (torch.randn(3, 7), torch.randn(3, 7)),\n    (torch.randn(4, 8), torch.randn(4, 8)),\n]\n\nobserver_add = InputObserver()\nwith observer_add(model_add, store_n_calls=3):  # 3 is the default maximum\n    for x, y in inputs_add:\n        model_add(x, y)\n\nprint(\"Observations stored:\", observer_add.num_obs())\nassert observer_add.num_obs() == 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``infer_dynamic_shapes`` returns a tuple of per-argument shape specs, using\n``torch.export.Dim.DYNAMIC`` as a placeholder wherever a dimension varies\nacross calls.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dyn_add = observer_add.infer_dynamic_shapes()\nprint(\"Dynamic shapes:\", dyn_add)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``infer_arguments`` returns one representative set of inputs \u2014 usually the\nfirst observed set \u2014 suitable for passing to :func:`torch.export.export`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "args_add = observer_add.infer_arguments()\nprint(\"Inferred args:\", string_type(args_add, with_shape=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Both dimension 0 (batch) and dimension 1 (sequence) are marked dynamic for\nboth tensors because they changed across the three observed calls.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Keyword args \u2014 same model, named inputs\n\n:class:`InputObserver` works identically when the model is called with\nkeyword arguments.  The inferred dynamic shapes are returned as a\n*dict* (one entry per named argument) instead of a tuple.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class LinearModel(torch.nn.Module):\n    \"\"\"Applies a linear transformation: out = x @ W + b.\"\"\"\n\n    def __init__(self, in_features: int, out_features: int):\n        super().__init__()\n        self.weight = torch.nn.Parameter(torch.randn(out_features, in_features))\n        self.bias = torch.nn.Parameter(torch.zeros(out_features))\n\n    def forward(self, x, labels=None):\n        logits = x @ self.weight.T + self.bias\n        if labels is not None:\n            loss = torch.nn.functional.cross_entropy(logits, labels)\n            return logits, loss\n        return logits\n\n\nmodel_lin = LinearModel(8, 4)\n\n# Three calls with varying batch size; sequence dim is absent here.\nkwargs_lin = [\n    dict(x=torch.randn(2, 8), labels=torch.randint(0, 4, (2,))),\n    dict(x=torch.randn(5, 8), labels=torch.randint(0, 4, (5,))),\n    dict(x=torch.randn(7, 8), labels=torch.randint(0, 4, (7,))),\n]\n\nobserver_lin = InputObserver()\nwith observer_lin(model_lin):\n    for kwargs in kwargs_lin:\n        model_lin(**kwargs)\n\nprint(\"\\nObservations stored (linear):\", observer_lin.num_obs())\n\ndyn_lin = observer_lin.infer_dynamic_shapes()\nprint(\"Dynamic shapes (linear):\", dyn_lin)\n\nkwargs_inferred = observer_lin.infer_arguments()\nprint(\"Inferred kwargs:\", string_type(kwargs_inferred, with_shape=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dimension 0 is dynamic for both ``x`` and ``labels`` (batch size varies).\nDimension 1 of ``x`` is static (always 8, the fixed feature count).\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Optional argument \u2014 ``mask`` present only in some calls\n\nSometimes a model argument is optional: it is passed during some steps\n(e.g. when an attention mask is available) but absent in others.\nWithout extra information the observer cannot infer an empty tensor for\n``mask`` (it was never seen as an empty tensor). The ``value_if_missing``\nargument provides this information explicitly.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class MaskedModel(torch.nn.Module):\n    \"\"\"Applies an optional multiplicative mask to the input.\"\"\"\n\n    def forward(self, x, mask=None):\n        if mask is not None:\n            return x * mask\n        return x\n\n\nmodel_masked = MaskedModel()\n\n# Three calls \u2014 the first omits the mask, the other two include it.\nseq_len = 10\ninputs_masked = [\n    dict(x=torch.randn(2, seq_len)),  # no mask\n    dict(x=torch.randn(3, seq_len), mask=torch.ones(3, seq_len)),\n    dict(x=torch.randn(4, seq_len), mask=torch.ones(4, seq_len)),\n]\n\n# We tell the observer that when ``mask`` is absent it should be treated as an\n# all-ones tensor with batch=0 (the zero batch dimension signals \"optional\").\nobserver_masked = InputObserver(value_if_missing=dict(mask=torch.ones(0, seq_len)))\n\nwith observer_masked(model_masked):\n    for kwargs in inputs_masked:\n        model_masked(**kwargs)\n\nprint(\"\\nObservations stored (masked):\", observer_masked.num_obs())\n\ndyn_masked = observer_masked.infer_dynamic_shapes()\nprint(\"Dynamic shapes (masked):\", dyn_masked)\n\nkwargs_masked = observer_masked.infer_arguments()\nprint(\"Inferred kwargs:\", string_type(kwargs_masked, with_shape=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``mask`` appears in the inferred arguments with batch=0 (an empty tensor),\nsignalling that it is optional.  Dimension 0 is dynamic for both ``x`` and\n``mask`` because the batch size varied across calls.  Dimension 1 (sequence\nlength) is static because it was always ``seq_len``.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Using the results with torch.export.export\n\nThe inferred arguments and dynamic shapes can be passed directly to\n:func:`torch.export.export` or :func:`torch.onnx.export`:\n\n```python\nep = torch.export.export(\n    model_add,\n    args_add,           # representative inputs (tuple for positional args)\n    dynamic_shapes=dyn_add,\n)\n```\nFor models called with keyword arguments:\n\n```python\nep = torch.export.export(\n    model_lin,\n    (),\n    kwargs=kwargs_inferred,\n    dynamic_shapes=dyn_lin,\n)\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Diagram: how InputObserver works\n\nThe diagram below summarises the three-phase workflow.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(9, 3.5))\nax.set_xlim(0, 12)\nax.set_ylim(0, 5)\nax.axis(\"off\")\nax.set_title(\"InputObserver workflow\", fontsize=12)\n\n# Phase boxes\nphase_data = [\n    (\n        0.2,\n        \"#dce9f5\",\n        \"#4c72b0\",\n        \"1. Observe\",\n        [\"model(x1, y1)\", \"model(x2, y2)\", \"model(x3, y3)\"],\n    ),\n    (4.2, \"#fde8d8\", \"#dd8452\", \"2. Analyse\", [\"infer_dynamic_shapes()\", \"infer_arguments()\"]),\n    (\n        8.2,\n        \"#d5ecd4\",\n        \"#3a8a3a\",\n        \"3. Export\",\n        [\"torch.export.export(\", \"  model, args,\", \"  dynamic_shapes=dyn)\"],\n    ),\n]\n\nfor x0, fc, ec, title, lines in phase_data:\n    box = mpatches.FancyBboxPatch(\n        (x0, 0.8),\n        3.6,\n        3.2,\n        boxstyle=\"round,pad=0.15\",\n        linewidth=1.5,\n        edgecolor=ec,\n        facecolor=fc,\n    )\n    ax.add_patch(box)\n    ax.text(x0 + 1.8, 3.7, title, ha=\"center\", va=\"center\", fontsize=9, fontweight=\"bold\")\n    for i, line in enumerate(lines):\n        ax.text(\n            x0 + 1.8,\n            3.0 - i * 0.55,\n            line,\n            ha=\"center\",\n            va=\"center\",\n            fontsize=7.5,\n            family=\"monospace\",\n        )\n\n# Arrows between phases\nfor x in (3.8, 7.8):\n    ax.annotate(\n        \"\",\n        xy=(x + 0.4, 2.4),\n        xytext=(x, 2.4),\n        arrowprops=dict(arrowstyle=\"->\", color=\"#555555\", lw=1.5),\n    )\n\nplt.tight_layout()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}