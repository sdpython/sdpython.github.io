<!doctype html>
<html class="no-js" lang="fr" data-content_root="../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Recherche" href="../search.html" /><link rel="next" title="Réseaux de neurones" href="../notebooks/ml/reseau_neurones.html" /><link rel="prev" title="Voronoï et régression logistique" href="../notebooks/ml/logreg_voronoi.html" />

    <!-- Generated with Sphinx 8.1.3 and Furo 2024.08.06 -->
        <title>Régression logistique par morceaux, arbres de décision - Documentation mlstatpy 0.5.0</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=354aac6f" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css?v=4ae1632d" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css?v=7f9a90b1" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=302659d7" />
    
    


<style>
  body {
    --color-code-background: #eeffcc;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">Documentation mlstatpy 0.5.0</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="../_static/project_ico.png" alt="Logo"/>
  </div>
  
  <span class="sidebar-brand-text">Documentation mlstatpy 0.5.0</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Recherche" name="q" aria-label="Recherche">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Mathematics</span></p>
<ul class="current">
<li class="toctree-l1 has-children"><a class="reference internal" href="../c_clus/index.html">Clustering</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of Clustering</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../c_clus/kmeans.html">k-means</a></li>
<li class="toctree-l2"><a class="reference internal" href="../c_clus/gauss_mixture.html">Mélange de lois normales</a></li>
<li class="toctree-l2"><a class="reference internal" href="../c_clus/kohonen.html">Carte de Kohonen</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="index.html">Non linéaire</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of Non linéaire</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="rn/rn.html">Réseaux de neurones</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of Réseaux de neurones</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="rn/rn_1_def.html">Définition des réseaux de neurones multi-couches</a></li>
<li class="toctree-l3"><a class="reference internal" href="rn/rn_2_reg.html">La régression</a></li>
<li class="toctree-l3"><a class="reference internal" href="rn/rn_3_clas.html">La classification</a></li>
<li class="toctree-l3"><a class="reference internal" href="rn/rn_4_densite.html">Démonstration du théorème de la densité des réseaux de neurones</a></li>
<li class="toctree-l3"><a class="reference internal" href="rn/rn_5_newton.html">Descente de gradient</a></li>
<li class="toctree-l3"><a class="reference internal" href="rn/rn_6_apprentissage.html">Apprentissage d’un réseau de neurones</a></li>
<li class="toctree-l3"><a class="reference internal" href="rn/rn_7_clas2.html">Classification</a></li>
<li class="toctree-l3"><a class="reference internal" href="rn/rn_8_prol.html">Prolongements</a></li>
<li class="toctree-l3"><a class="reference internal" href="rn/rn_9_auto.html">Analyse en composantes principales (ACP) et Auto Encoders</a></li>
<li class="toctree-l3"><a class="reference internal" href="rn/rn_biblio.html">Bibliographie</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="kppv.html">Classification à l’aide des plus proches voisins</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="missing_values_mf.html">Liens entre factorisation de matrices, ACP, k-means</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of Liens entre factorisation de matrices, ACP, k-means</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/mf_acp.html">Factorisation et matrice et ACP</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/valeurs_manquantes_mf.html">Valeurs manquantes et factorisation de matrices</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/ml/neural_tree.html">Un arbre de décision en réseaux de neurones</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/ml/neural_tree_onnx.html">NeuralTreeNet et ONNX</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/ml/neural_tree_cost.html">NeuralTreeNet et coût</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="index_reg_lin.html">Régression linéaire</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of Régression linéaire</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/dsgarden/regression_lineaire.html">Régression linéaire</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="regression_quantile.html">Régression quantile ou régression L1</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle navigation of Régression quantile ou régression L1</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/dsgarden/quantile_regression_example.html">Régression quantile illustrée</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="piecewise.html">Régression linéaire par morceaux</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle navigation of Régression linéaire par morceaux</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/piecewise_linear_regression.html">Régression linéaire par morceaux</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/regression_no_inversion.html">Régression sans inversion</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="l1l2.html">Normalisation des coefficients</a></li>
</ul>
</li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="index_reg_log.html">Régression logistique</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle navigation of Régression logistique</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2 has-children"><a class="reference internal" href="lr_voronoi.html">Régression logistique, diagramme de Voronoï, k-Means</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle navigation of Régression logistique, diagramme de Voronoï, k-Means</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/logreg_voronoi.html">Voronoï et régression logistique</a></li>
</ul>
</li>
<li class="toctree-l2 current current-page"><a class="current reference internal" href="#">Régression logistique par morceaux, arbres de décision</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/ml/reseau_neurones.html">Réseaux de neurones</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="survival_analysis.html">Analyse de survie</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle navigation of Analyse de survie</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/survival.html">Analyse de survie en pratique</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../c_nlp/index.html">NLP</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><div class="visually-hidden">Toggle navigation of NLP</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../c_nlp/completion.html">Complétion</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><div class="visually-hidden">Toggle navigation of Complétion</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../c_nlp/completion_formalisation.html">Formalisation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../c_nlp/completion_fausse.html">Fausses idées reçues</a></li>
<li class="toctree-l3"><a class="reference internal" href="../c_nlp/completion_metrique.html">Nouvelle métrique</a></li>
<li class="toctree-l3"><a class="reference internal" href="../c_nlp/completion_propriete.html">Propriétés mathématiques</a></li>
<li class="toctree-l3"><a class="reference internal" href="../c_nlp/completion_optimisation.html">Problème d’optimisation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../c_nlp/completion_implementation.html">Implémentation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../c_nlp/completion_digression.html">Digressions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/nlp/completion_trie.html">Complétion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/nlp/completion_profiling.html">Completion profiling</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/nlp/completion_trie_long.html">Completion Trie and metrics</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/nlp/completion_simple.html">Complétion Simple</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../c_metric/index.html">Métriques</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" role="switch" type="checkbox"/><label for="toctree-checkbox-13"><div class="visually-hidden">Toggle navigation of Métriques</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../c_metric/roc.html">Courbe ROC</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" role="switch" type="checkbox"/><label for="toctree-checkbox-14"><div class="visually-hidden">Toggle navigation of Courbe ROC</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/metric/roc_example.html">ROC</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../c_metric/pvalues.html">Confidence Interval and p-Value</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" role="switch" type="checkbox"/><label for="toctree-checkbox-15"><div class="visually-hidden">Toggle navigation of Confidence Interval and p-Value</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/metric/pvalues_examples.html">p-values</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../c_algo/index.html">Algorithmes</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" role="switch" type="checkbox"/><label for="toctree-checkbox-16"><div class="visually-hidden">Toggle navigation of Algorithmes</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../c_algo/edit_distance.html">Distance d’édition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../c_algo/graph_distance.html">Distance between two graphs</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../c_algo/gest.html">Détection de segments</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" role="switch" type="checkbox"/><label for="toctree-checkbox-17"><div class="visually-hidden">Toggle navigation of Détection de segments</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/image/segment_detection.html">Détection de segments dans une image</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../c_garden/index.html">Pérégrinations</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" role="switch" type="checkbox"/><label for="toctree-checkbox-18"><div class="visually-hidden">Toggle navigation of Pérégrinations</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/dsgarden/split_train_test.html">Répartir en base d’apprentissage et de test</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/dsgarden/correlation_non_lineaire.html">Corrélations non linéaires</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../c_garden/file_dattente.html">File d’attente, un petit exemple</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" role="switch" type="checkbox"/><label for="toctree-checkbox-19"><div class="visually-hidden">Toggle navigation of File d’attente, un petit exemple</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/dsgarden/file_dattente_ex.html">File d’attente, un exemple simple</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../c_garden/strategie_avec_alea.html">Optimisation avec données aléatoires</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/dsgarden/discret_gradient.html">Le gradient et le discret</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../c_garden/quantization.html">Quantization</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" role="switch" type="checkbox"/><label for="toctree-checkbox-20"><div class="visually-hidden">Toggle navigation of Quantization</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/dsgarden/quantization_f8.html">Quantization</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/dsgarden/classification_multiple.html">Classification multiple</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api/index.html">API</a><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" role="switch" type="checkbox"/><label for="toctree-checkbox-21"><div class="visually-hidden">Toggle navigation of API</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../api/ml.html">Machine Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/optim.html">Optimisation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/text.html">Traitement du langage naturel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/data.html">Source de données</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/graph.html">Graphes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/image.html">Image</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/modules/index.html">Modules</a><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" role="switch" type="checkbox"/><label for="toctree-checkbox-22"><div class="visually-hidden">Toggle navigation of Modules</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/modules/poulet.html">mlstatpy.garden.poulet</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/modules/graph_distance.html">mlstatpy.graph.graph_distance</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/modules/kppv.html">mlstatpy.ml.kppv</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/modules/kppv_laesa.html">mlstatpy.ml.kppv_laesa</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/modules/logreg.html">mlstatpy.ml.logreg</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/modules/neural_tree.html">mlstatpy.ml.neural_tree</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/modules/roc.html">mlstatpy.ml.roc</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/modules/completion.html">mlstatpy.nlp.completion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/modules/completion_simple.html">mlstatpy.nlp.completion_simple</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/modules/sgd.html">mlstatpy.optim.sgd</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../i_ex.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../defthe_index.html">Listes des définitions et théorèmes</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../auto_examples/index.html">Gallery of examples</a><input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" role="switch" type="checkbox"/><label for="toctree-checkbox-23"><div class="visually-hidden">Toggle navigation of Gallery of examples</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_logistic_decision.html">Arbre d’indécision</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../notebooks/index.html">Galleries de notebooks</a><input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" role="switch" type="checkbox"/><label for="toctree-checkbox-24"><div class="visually-hidden">Toggle navigation of Galleries de notebooks</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../notebooks/dsgarden/index.html">Le petit coin des data scientists</a><input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" role="switch" type="checkbox"/><label for="toctree-checkbox-25"><div class="visually-hidden">Toggle navigation of Le petit coin des data scientists</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/dsgarden/classification_multiple.html">Classification multiple</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/dsgarden/correlation_non_lineaire.html">Corrélations non linéaires</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/dsgarden/discret_gradient.html">Le gradient et le discret</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/dsgarden/file_dattente_ex.html">File d’attente, un exemple simple</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/dsgarden/quantile_regression_example.html">Régression quantile illustrée</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/dsgarden/quantization_f8.html">Quantization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/dsgarden/regression_lineaire.html">Régression linéaire</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/dsgarden/split_train_test.html">Répartir en base d’apprentissage et de test</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../notebooks/image/index.html">Images</a><input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" role="switch" type="checkbox"/><label for="toctree-checkbox-26"><div class="visually-hidden">Toggle navigation of Images</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/image/segment_detection.html">Détection de segments dans une image</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../notebooks/metric/index.html">Métriques</a><input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" role="switch" type="checkbox"/><label for="toctree-checkbox-27"><div class="visually-hidden">Toggle navigation of Métriques</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/metric/pvalues_examples.html">p-values</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/metric/roc_example.html">ROC</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../notebooks/ml/index.html">Machine Learning</a><input class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" role="switch" type="checkbox"/><label for="toctree-checkbox-28"><div class="visually-hidden">Toggle navigation of Machine Learning</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/logreg_voronoi.html">Voronoï et régression logistique</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/mf_acp.html">Factorisation et matrice et ACP</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/neural_tree.html">Un arbre de décision en réseaux de neurones</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/neural_tree_cost.html">NeuralTreeNet et coût</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/neural_tree_onnx.html">NeuralTreeNet et ONNX</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/piecewise_linear_regression.html">Régression linéaire par morceaux</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/regression_no_inversion.html">Régression sans inversion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/reseau_neurones.html">Réseaux de neurones</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/survival.html">Analyse de survie en pratique</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/valeurs_manquantes_mf.html">Valeurs manquantes et factorisation de matrices</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../notebooks/nlp/index.html">NLP - Natural Language Processing</a><input class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" role="switch" type="checkbox"/><label for="toctree-checkbox-29"><div class="visually-hidden">Toggle navigation of NLP - Natural Language Processing</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/nlp/completion_profiling.html">Completion profiling</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/nlp/completion_simple.html">Complétion Simple</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/nlp/completion_trie.html">Complétion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/nlp/completion_trie_long.html">Completion Trie and metrics</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">More</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../glossary.html">Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../CHANGELOGS.html">Change Logs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../CHANGELOGS.html#id2">0.4.0</a></li>
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
<li class="toctree-l1"><a class="reference internal" href="../genindex.html">Index</a></li>
<li class="toctree-l1"><a class="reference internal" href="../py-modindex.html">Index du module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../search.html">Page de recherche</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="../_sources/c_ml/lr_trees.rst" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="regression-logistique-par-morceaux-arbres-de-decision">
<span id="l-lr-trees-nn"></span><h1>Régression logistique par morceaux, arbres de décision<a class="headerlink" href="#regression-logistique-par-morceaux-arbres-de-decision" title="Lien vers cette rubrique">¶</a></h1>
<p id="index-0">Ce qui suit explore une façon fantaisiste de construire des régressions
logistiques à mi-chemin entre les arbres de décisions
et les réseaux de neurones. Dans un premier temps, on s’intéresse
uniquement à une classification binaire.</p>
<section id="parallele-entre-un-neurone-et-une-regression-logistique">
<h2>Parallèle entre un neurone et une régression logistique<a class="headerlink" href="#parallele-entre-un-neurone-et-une-regression-logistique" title="Lien vers cette rubrique">¶</a></h2>
<p>Les paragraphes <a class="reference internal" href="rn/rn_7_clas2.html#rn-classification"><span class="std std-ref">Classification</span></a> et
<a class="reference internal" href="rn/rn_3_clas.html#nn-classification"><span class="std std-ref">La classification</span></a> présente le problème de la classification
qui consiste à trouver une fonction <em>f</em> qui maximise la vraisemblance
du nuage de points <img class="math" src="../_images/math/b9fcbdf90099e952b01c231bdafa14b368bd8c2d.svg" alt="(X_i, y_i)_i"/> où <img class="math" src="../_images/math/ffe8cf50d7747c488a36fbc58242a460fb6fe345.svg" alt="X_i \in \mathbb{R}^d"/>
et <img class="math" src="../_images/math/3e94f1f2fcb78ea4aea0bc5768428865c3e92b34.svg" alt="y_i \in \acc{0, 1}"/>.</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/ad4e65ea47878df03a30525ab4b51f4cf8ab92a4.svg" alt="\ln L(\Theta, X, y) = \sum_{i=1}^n y_i \ln f(\Theta, X_i) + (1-y_i) \ln (1-f(\Theta, X_i))"/></p>
</div></div>
<p>Dans le cas de la régression logistique, la fonction <em>f</em> est définie comme suit :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/288d0a79ad2cb5d6649a1d20a395fb4c2c4b0478.svg" alt="f(\Theta, X_i) = \frac{1}{1 + e^{-\sum_{k=1}^d \theta_k x_{ik}}}"/></p>
</div></div>
<p>Cela ressemble beaucoup à la définition d’un <a class="reference internal" href="rn/rn_1_def.html#l-rn-neurone"><span class="std std-ref">neurone</span></a>
où la fonction d’activation <img class="math" src="../_images/math/901c318c883eb3d7f98117bca8a8aa39aa976640.svg" alt="f(x) = \frac{1}{1 + e^{-x}}"/> est une
fonction sigmoïde.</p>
</section>
<section id="principe-d-un-arbre-de-decision">
<span id="l-lr-log-likelihood"></span><h2>Principe d’un arbre de décision<a class="headerlink" href="#principe-d-un-arbre-de-decision" title="Lien vers cette rubrique">¶</a></h2>
<p>Un arbre de décision se construit peu à peu en répétant toujours
la même optimisation sur des sous-ensemble de plus en plus petit.
Il faut d’abord un critère qui permette d’évaluer la pertinence
de la division effectuée par un noeud de l’arbre.
Pour un ensemble <img class="math" src="../_images/math/fc5e032afff6533919187521dbc4fe06f7e05cfc.svg" alt="(X_i, y_i)_{1 \leqslant i \leqslant n}"/>, on
peut estimer la probabilité
<img class="math" src="../_images/math/5a0a34953eda219d1de293e247077c260bba8c52.svg" alt="p(y_1, ..., y_n) = p(Y) = \frac{1}{n}\sum{i=1}^n y_i"/>.
Le critère de Gini <em>G</em> qui évalue la pertinence d’une classification est
défini par <img class="math" src="../_images/math/e804294146fa87e476bb17dd3470a5e1704a490f.svg" alt="G(Y) = p(Y) (1 - p(Y))"/>.
Un autre critère est le gain d’information ou entropie <em>H</em> :
<img class="math" src="../_images/math/ad93996a4e215efad6477fee9935d0b0dcf7fd42.svg" alt="H(Y) = - p(Y) \ln p(Y) - (1-p(Y)) \ln (1 - p(Y))"/>.</p>
<p>On note <img class="math" src="../_images/math/05a71410aaa870b65b552aab8416211bda12649d.svg" alt="Y_S"/> l’ensemble des <img class="math" src="../_images/math/824f8c1cf4d933e5a0952972e52248f815bf5b46.svg" alt="\acc{y_i | i \in S}"/>
où <em>S</em> est un sous-ensemble. <img class="math" src="../_images/math/c6d2fe4ce4543952ec313467aad41d6822c3eda4.svg" alt="S^C"/> est noté le complémentaire.</p>
<p>Pour le premier noeud de l’arbre de décision, on calcule pour
toutes les variables et toutes les observations la diminution
du critère choisi :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/06ba11f79195abba450d7cff37116e22575ef5a1.svg" alt="\begin{array}{rcl}
S_{ik} &amp;=&amp; \acc{ m | x_{mk} \leqslant x_{ik}} \\
\Delta_{ik} &amp;=&amp; H(Y) - ( H(Y_{S_{ik}}) + H(Y_{S_{ik}^C} )
\end{array}"/></p>
</div></div>
<p>On choisit alors la variable <em>k</em> et le seuil <img class="math" src="../_images/math/b510bf05496cee5a8dded0e87278911b3341ed9c.svg" alt="x_{ik}"/> qui
maximise le gain. Dans le cas d’une régression logistique,
la vraisemblance correspond à :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/ad4e65ea47878df03a30525ab4b51f4cf8ab92a4.svg" alt="\ln L(\Theta, X, y) = \sum_{i=1}^n y_i \ln f(\Theta, X_i) + (1-y_i) \ln (1-f(\Theta, X_i))"/></p>
</div></div>
<p>Si on suppose que la fonction <em>f</em> retourne une constante <em>c</em>,
cette expression devient :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/32403573678a2aed9a40034e09bd533edeed0a97.svg" alt="\ln L(\Theta, X, y) = \sum_{i=1}^n y_i \ln c + (1-y_i) \ln (1-c) = p(Y) \ln c + (1-p(Y)) \ln (1-c)"/></p>
</div></div>
<p>Or cette expression admet un maximum pour <img class="math" src="../_images/math/59ee1df05f7b961a0dadebb8190b275e26b9277c.svg" alt="c=p(Y)"/> puisque la dérivée
s’annule de façon évidente pour cette valeur :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/97f377cbc21d6572cf554d82f8f99e9e5041f4b0.svg" alt="\frac{\partial \ln L(\Theta, X, y)}{\partial c} = \frac{p(Y)}{c} - \frac{1-p(Y)}{1-c}"/></p>
</div></div>
<p>On remarque que l’optimisation d’un noeud d’un arbre de décision
correspond à l’optimisation de la vraisemblance par une
fonction constante. Une régression logistique calculée sur une
seule variable est en quelque sorte une généralisation de ce modèle.
On apprend un arbre de décision qu’on exporte au format <a class="reference external" href="https://fr.wikipedia.org/wiki/DOT_(langage)">dot</a>.</p>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span><span class="p">,</span> <span class="n">export_graphviz</span>

<span class="n">ds</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">ds</span><span class="o">.</span><span class="n">target</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y</span> <span class="o">%</span> <span class="mi">2</span>
<span class="n">dt</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="s2">&quot;entropy&quot;</span><span class="p">)</span>
<span class="n">dt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dt</span><span class="p">)</span>
<span class="c1"># export_graphviz(dt)</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">criterion</span><span class="o">=</span><span class="s1">&#39;entropy&#39;</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
<p>Ce qui donne :</p>
<div class="graphviz"><img src="../_images/graphviz-77252c69fe458f4b693e321577d953cb2aa0422f.png" alt="digraph Tree {
    node [shape=box] ;
    0 [label=&quot;X[3] &lt;= 0.8\nentropy = 0.918\nsamples = 150\nvalue = [100, 50]&quot;] ;
    1 [label=&quot;entropy = 0.0\nsamples = 50\nvalue = [50, 0]&quot;] ;
    0 -&gt; 1 [labeldistance=2.5, labelangle=45, headlabel=&quot;True&quot;] ;
    2 [label=&quot;X[3] &lt;= 1.75\nentropy = 1.0\nsamples = 100\nvalue = [50, 50]&quot;] ;
    0 -&gt; 2 [labeldistance=2.5, labelangle=-45, headlabel=&quot;False&quot;] ;
    3 [label=&quot;X[2] &lt;= 4.95\nentropy = 0.445\nsamples = 54\nvalue = [5, 49]&quot;] ;
    2 -&gt; 3 ;
    4 [label=&quot;entropy = 0.146\nsamples = 48\nvalue = [1, 47]&quot;] ;
    3 -&gt; 4 ;
    5 [label=&quot;entropy = 0.918\nsamples = 6\nvalue = [4, 2]&quot;] ;
    3 -&gt; 5 ;
    6 [label=&quot;X[2] &lt;= 4.85\nentropy = 0.151\nsamples = 46\nvalue = [45, 1]&quot;] ;
    2 -&gt; 6 ;
    7 [label=&quot;entropy = 0.918\nsamples = 3\nvalue = [2, 1]&quot;] ;
    6 -&gt; 7 ;
    8 [label=&quot;entropy = 0.0\nsamples = 43\nvalue = [43, 0]&quot;] ;
    6 -&gt; 8 ;
}" class="graphviz" /></div>
</section>
<section id="construction-d-un-pseudo-arbre">
<span id="l-criteria-reg-log"></span><h2>Construction d’un pseudo arbre<a class="headerlink" href="#construction-d-un-pseudo-arbre" title="Lien vers cette rubrique">¶</a></h2>
<p>Et si on remplaçait chaque noeud par une régression logistique
appris sur les exemples passant par ce noeud… Plutôt que de prendre
une décision basée sur une variable donnée et de retourner une probabilité
constante, on estime une régression logistique et on retourne
la probabilité retournée par la régression.</p>
<p>S’il n’y a théoriquement aucun obstacle, en pratique, certains cas
posent quelques problèmes comme le montre l’exemple
<a class="reference internal" href="../auto_examples/plot_logistic_decision.html#l-example-logistic-decision"><span class="std std-ref">Arbre d’indécision</span></a> et repris ci-dessous.
La fonction <a class="reference internal" href="../api/modules/logreg.html#mlstatpy.ml.logreg.criteria" title="mlstatpy.ml.logreg.criteria"><code class="xref py py-func docutils literal notranslate"><span class="pre">criteria</span></code></a>
calcule les différents gains selon les points de coupure.</p>
<p>(<a class="reference download internal" download="" href="../_downloads/531af7b80f366303f390485c8cd1ee16/lr_trees-1.py"><code class="xref download docutils literal notranslate"><span class="pre">Source</span> <span class="pre">code</span></code></a>, <a class="reference download internal" download="" href="../_downloads/a2c0745acab7d3c94fac2245153cdb03/lr_trees-1.png"><code class="xref download docutils literal notranslate"><span class="pre">png</span></code></a>, <a class="reference download internal" download="" href="../_downloads/62374232df2a743ea34be18c892cae77/lr_trees-1.hires.png"><code class="xref download docutils literal notranslate"><span class="pre">hires.png</span></code></a>, <a class="reference download internal" download="" href="../_downloads/868238c99784e257ca069fbf1a8025e8/lr_trees-1.pdf"><code class="xref download docutils literal notranslate"><span class="pre">pdf</span></code></a>)</p>
<figure class="align-default">
<img alt="../_images/lr_trees-1.png" class="plot-directive" src="../_images/lr_trees-1.png" />
</figure>
<p>Le seuil de coupure est évident dans le premier cas et
quasiment impossible à trouver de façon numérique dans le second
avec les algorithmes tels qu’ils sont implémentés.
Les arbres de décision contournent
ce problème en imposant que le seuil de coupure laisse au moins
quelques exemples de chaque côté ce que la régression logistique
ne fait pas. On peut réflechir à d’autres critères.
Le suivant explore la log-vraisemblance.</p>
<p>(<a class="reference download internal" download="" href="../_downloads/4e0344eee99db31604908633cd37a711/lr_trees-2.py"><code class="xref download docutils literal notranslate"><span class="pre">Source</span> <span class="pre">code</span></code></a>, <a class="reference download internal" download="" href="../_downloads/31f57bf26430f0072efb381f4353b705/lr_trees-2.png"><code class="xref download docutils literal notranslate"><span class="pre">png</span></code></a>, <a class="reference download internal" download="" href="../_downloads/70994af43ed566f2a3001c3e99d0fa94/lr_trees-2.hires.png"><code class="xref download docutils literal notranslate"><span class="pre">hires.png</span></code></a>, <a class="reference download internal" download="" href="../_downloads/447af61da46bb961bfdb5f44996ab02f/lr_trees-2.pdf"><code class="xref download docutils literal notranslate"><span class="pre">pdf</span></code></a>)</p>
<figure class="align-default">
<img alt="../_images/lr_trees-2.png" class="plot-directive" src="../_images/lr_trees-2.png" />
</figure>
<p>La log-vraisemblance dans ce problème à une dimension
est assez simple à écrire. Pour avoir une expression qui
ne change pas en invertissant les classes, on considère
le maxiimum des vraisemblance en considérant deux classifieurs
opposés. Le graphe précédent fait varier <img class="math" src="../_images/math/97c4568f4c81437317fcedb2bfafe4ef3dcc5c33.svg" alt="x_0"/> avec
différents <img class="math" src="../_images/math/38b8dfb3d1a10a5197333bf027a6a9c326563ed9.svg" alt="\theta"/>.</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/c682ccf995442aff91b8d04782d1cf774a09b52b.svg" alt="LL(x_0, \theta) = \max \left\{ \begin{array}{ll}
\frac{1}{1 + \exp{\left(\frac{x-x_0}{\theta}\right)}} \\
\frac{1}{1 + \exp{\left(-\frac{x-x_0}{\theta}\right)}}
\end{array}\right."/></p>
</div></div>
</section>
<section id="aparte-mathematique">
<h2>Aparté mathématique<a class="headerlink" href="#aparte-mathematique" title="Lien vers cette rubrique">¶</a></h2>
<p>La log-vraisemblance d’une régression logistique pour
un jeu de données <img class="math" src="../_images/math/3190ad9816294c28609eb295103dfe16eb2f1af9.svg" alt="(X_i, y_i)"/> s’exprime comme
suit pour une régression logistique de paramètre
<img class="math" src="../_images/math/bd898b02c226d1ce791865c51d30012165adf53d.svg" alt="\beta"/>.</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/9c53b6cc877178acfdc5c914708536fe3620afc1.svg" alt="\begin{array}{rcl}
L(\beta, X, y) &amp;=&amp; \sum_{i=1}^n y_i \ln f(\beta, X_i) + (1-y_i) \ln (1-f(\beta, X_i)) \\
\text{avec } f(\beta, X_i) &amp;=&amp; \frac{1}{1 + \exp(- (\beta_0 + \sum_{k=1}^d x_{ik} \beta_k))}
\end{array}"/></p>
</div></div>
<p>On remarque que :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/2568bcef85c14d9d76a7f126e6fcd2ea0f9c44b1.svg" alt="\begin{array}{rcl}
f(x) &amp;=&amp; \frac{1}{1 + e^{-x}} \\
\mathbb{R}ightarrow f(-x) &amp;=&amp; \frac{1}{1 + e^{x}} = \frac{e^{-x}}{1 + e^{-x}} \\
\mathbb{R}ightarrow f(x) + f(-x) &amp;=&amp; \frac{1}{1 + e^{-x}} + \frac{e^{-x}}{1 + e^{-x}} = 1
\end{array}"/></p>
</div></div>
<p>Cela explique pour on utilise souvent cette fonction pour transformer
une distance en probabilité pour un classifieur binaire.
L’apprentissage d’un arbre de décision
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier" title="(disponible dans scikit-learn v1.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.tree.DecisionTreeClassifier</span></code></a> propose le
paramètre <code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code>. On se propose dans le cadre
de la régression logistique de chercher le paramètre
<img class="math" src="../_images/math/187f6a9980782a0dca16d03f610fda1f27f6ef66.svg" alt="\beta_0"/> qui permet de vérifier la contrainte
fixée par <code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code>. Cela revient à trounver
un classifieur linéaire parallèle au premier qui vérifie
les contraintes.</p>
</section>
<section id="approche-em-et-regression-logistique">
<h2>Approche EM et régression logistique<a class="headerlink" href="#approche-em-et-regression-logistique" title="Lien vers cette rubrique">¶</a></h2>
<p>L’article <a class="reference internal" href="#scott2013" id="id1"><span>[Scott2013]</span></a> explicite un algorithme d’apprentissage EM
pour une régression logistique.</p>
<img alt="../_images/bayes.png" src="../_images/bayes.png" />
<p>Il faudrait adapter cet agorithme pour apprendre deux régressions
logistiques dont la combinaison sur deux parties disjointes
serait meilleure qu’une seule régression logistique sur
la réunion des deux parties. Cet algorithme devrait trouver à
la fois les modèles et la séparation entre les deux parties.</p>
</section>
<section id="lien-vers-les-reseaux-de-neurones">
<span id="l-decnntrees"></span><h2>Lien vers les réseaux de neurones<a class="headerlink" href="#lien-vers-les-reseaux-de-neurones" title="Lien vers cette rubrique">¶</a></h2>
<p>En remplaçant chaque noeud par une régression logistique,
l’arbre de décision deviendrait un réseau de neurones,
avec une structure particulière certes mais un réseau de
neurones tout de même.
Chaque noeud du graphe serait transformé en un neurone
avec une régression logistique impliquant toutes les variables.
Il ne resterait plus qu’à continuer l’apprentissage avec des
algorithmes à base de gradient stochastique. Cela reviendrait
à changer l’initialisation du réseau de neurones.
On considère le petit arbre décision suivant,
trois features, trois noeuds, deux classes.</p>
<div class="graphviz"><img src="../_images/graphviz-7edaaeb8b7bea2c7c1a58b600614e5271da95ffc.png" alt="digraph tree {
    A [label=&quot;X1 &amp;lt; 5&quot;,shape=record];
    B [label=&quot;X2 &amp;lt; 3&quot;,shape=record];
    C [label=&quot;X3 &amp;lt; 2&quot;,shape=record];
    A -&gt; B;
    A -&gt; C;
    D [label=&quot;&lt;c0&gt; 0|&lt;c1&gt; 1&quot;,shape=record];
    E [label=&quot;&lt;c0&gt; 0|&lt;c1&gt; 1&quot;,shape=record];
    B -&gt; D:c0;
    B -&gt; D:c1;
    C -&gt; E:c0;
    C -&gt; E:c1;
}" class="graphviz" /></div>
<p>On souhaite le transformer en réseau de neurones avec une
structure qui serait celle qui suit. On note tout d’abord
la fonction sigmoïde <img class="math" src="../_images/math/f1dcbd117beeb2ca73e7c169cd263599663a1abb.svg" alt="f(x, s, h)=\frac{1}{1 + e^{-h(x - s)}}"/>.
Elle vaut <em>1/2</em> lorsque <em>x</em> vaut <em>s</em>, vaut 1 lorsque <em>x</em>
est très grand, et 0 lorsque <em>x</em> est très petit.
C’est équivalent à la fonction
<img class="math" src="../_images/math/c1711779e3ce0601bc4ddefdb0501c3cb6f43192.svg" alt="f(x, s, h)=g(X, S, v_0, h)\frac{1}{1 + e^{h(&lt;X,V&gt; + v_0)}}"/>
où <img class="math" src="../_images/math/b27eff5d2e3f215726775131fd8e71b5e0d7ec15.svg" alt="X=(x_1, x_2, x_3)"/>, <img class="math" src="../_images/math/2ee382df89009496bd7b32148d8d7274ac09d1eb.svg" alt="V=(-1, 0, 0)"/> et <img class="math" src="../_images/math/e4a6748bb8cc947a84af5a7f1f3077cad094c0ac.svg" alt="v_0=s"/>.</p>
<div class="graphviz"><img src="../_images/graphviz-ea73b40fb594b0ad7c6f920ced380bdde5c53a62.png" alt="digraph tree {
    A [label=&quot;y1=g(X, (-1, 0, 0), 5, h)&quot;,shape=record];
    B [label=&quot;y2=g(X, (0, -1, 0), 3, h)&quot;,shape=record];
    C [label=&quot;y3=g(X, (0, 0, -1), 2, h)&quot;,shape=record];
    D [label=&quot;y4=g((y1, y2), (-1, -1), 1, h)&quot;,shape=record];
    E [label=&quot;y5=g((y1, y3), (-1, -1), 1, h)&quot;,shape=record];
    A -&gt; D;
    A -&gt; E;
    B -&gt; D;
    C -&gt; E;

    F [label=&quot;y6=g((y4, y5), (-1, -1), 1, h)&quot;,shape=record];
    CL3 [label=&quot;&lt;c0&gt; 0|&lt;c1&gt; 1&quot;];
    D -&gt; F;
    E -&gt; F;
    F -&gt; CL3:c0;
    F -&gt; CL3:c1;
}" class="graphviz" /></div>
<p>Le problème avec la structure proposée est que chaque noeud
final retourne toujours une classe alors que dans un arbre de
décision, seule une feuille répond. Un noeud final fait la somme
de toutes les feuilles, deux dans cet exemple. L’implémentation
de <a class="reference external" href="https://scikit-learn.org/stable/index.html">scikit-learn</a> n’est pas la plus facile à manipuler
dans le sens où chaque couche ne peut prendre comme entrée
que les sorties de la précédente et la fonction d’activation
est la même pour tous les neurones. On ne peut pas non plus
geler certains coefficients lors de l’apprentissage.
C’est à ce moment-là qu’on se demande si ça vaut le coup
de se lancer dans une implémentation à la rigueur jolie mais
sans doute pas porteuse d’une innovation majeure. Et ce n’est
pas la première fois que quelqu’un se lance dans la conversion
d’un arbre en réseaux de neurones.</p>
<p>J’ai quand même essayé avec le notebook <a class="reference internal" href="../notebooks/ml/neural_tree.html"><span class="std std-ref">Un arbre de décision en réseaux de neurones</span></a>
et les classes <a class="reference internal" href="../api/modules/neural_tree.html#mlstatpy.ml._neural_tree_node.NeuralTreeNode" title="mlstatpy.ml._neural_tree_node.NeuralTreeNode"><code class="xref py py-class docutils literal notranslate"><span class="pre">NeuralTreeNode</span></code></a>,
<a class="reference internal" href="../api/modules/neural_tree.html#mlstatpy.ml.neural_tree.NeuralTreeNet" title="mlstatpy.ml.neural_tree.NeuralTreeNet"><code class="xref py py-class docutils literal notranslate"><span class="pre">NeuralTreeNet</span></code></a>.
Si l’idée de départ est séduisante, elle requiert une contrainte
supplémentaire qui est de créer un réseau de neurones qui ne soit
pas un minimum local de la fonction d’erreur auquel cas
un apprentissage avec un algorithme à base de gradient ne pourra
pas améliorer les performances du réseau de neurones.</p>
<a class="reference internal image-reference" href="../_images/mloc.png"><img alt="../_images/mloc.png" src="../_images/mloc.png" style="width: 200px;" />
</a>
<p>La structure proposée n’est cependant pas la meilleure et elle
pourrait être simplifiée. D’autres projets s’appuie des librairies
existantes :</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/kimhc6028/soft-decision-tree">Soft-Decision-Tree</a></p></li>
<li><p><a class="reference external" href="https://github.com/jingxil/Neural-Decision-Forests">Neural-Decision-Forests</a></p></li>
<li><p><a class="reference external" href="https://github.com/microsoft/hummingbird">hummingbird</a></p></li>
</ul>
<p>Ce dernier package convertit un réseau de neurones en autant de couches
que la profondeur de l’arbre. L’image qui suit est tiré de l’article
<a class="reference internal" href="#nakandalam2020" id="id2"><span>[Nakandalam2020]</span></a> et qui résume leur idée.</p>
<img alt="../_images/hb.png" src="../_images/hb.png" />
</section>
<section id="plan-orthogonal">
<h2>Plan orthogonal<a class="headerlink" href="#plan-orthogonal" title="Lien vers cette rubrique">¶</a></h2>
<p>Dans un espace à plusieurs dimensions, la régression logistique
divise l’espace à l’aide d’un hyperplan. La fonction de décision
reste similaire puisque la probabilité de classification dépend de la
distance à cet hyperplan. On suppose qu’il existe une
régression logistique binaire apprise sur un nuage de points
<img class="math" src="../_images/math/3190ad9816294c28609eb295103dfe16eb2f1af9.svg" alt="(X_i, y_i)"/>. La probabilité de bonne classification est
définie par :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/060fc5a6ee1327ff34efe1cf787b1b8eecba4f1c.svg" alt="f(\Theta, X_i) = \frac{1}{1 + e^{-\theta_0 + \sum_{k=1}^d \theta_k x_{ik}}}"/></p>
</div></div>
<p>Le vecteur <img class="math" src="../_images/math/cedeedd03cef3c883a44d87e1b30d11b4096832b.svg" alt="\Theta"/> définit un hyperplan. On choisit un vecteur
<img class="math" src="../_images/math/c3489f3eb27b77220c9fac4658290e92e2c5e21c.svg" alt="\Theta'"/> de telle sorte que <img class="math" src="../_images/math/69122eb9ebc5c57f39ac6a78ec836460a16a2957.svg" alt="&lt;\Theta,\Theta'&gt; = 0"/>. Les deux
vecteurs sont orthogonaux. On définit maintenant deux
autres vecteurs <img class="math" src="../_images/math/1077f7e30552bd2046af1f5c68844e8d8c2e624c.svg" alt="\Theta_1, \Theta_2"/> pour deux autres régressions
logistiques. Pour classer un point <img class="math" src="../_images/math/b66c7d6c52c7b12bee7fb24d76c38fc70cfc0a2f.svg" alt="X"/>, on procède comme suit :</p>
<ul class="simple">
<li><p>si <img class="math" src="../_images/math/424dd88e1ca83843c41a5cedab10f5067539684a.svg" alt="&lt;\Theta',X&gt; &lt; 0"/>, on classe le point en appliquant
la régression logistique définie par <img class="math" src="../_images/math/a42f69ae1f1c27fa56d58c8973cb47ff483f5286.svg" alt="Theta_1"/>,</p></li>
<li><p>si <img class="math" src="../_images/math/48b69add5053cec3fa8d97de200ae16d62f08cf4.svg" alt="&lt;\Theta',X&gt; \leqslant 0"/>, on classe le point en appliquant
la régression logistique définie par <img class="math" src="../_images/math/3d3a5758c2ee818a6841358ed871715b3f32e4f0.svg" alt="Theta_2"/>.</p></li>
</ul>
<p>De manière évidente, les performances en classification sont les mêmes
que la première régression logistique. On peut ensuite réestimer les
vecteurs <img class="math" src="../_images/math/1077f7e30552bd2046af1f5c68844e8d8c2e624c.svg" alt="\Theta_1, \Theta_2"/> pour maximiser la vraisemblance
sur chacune des parties. Il ne reste plus qu’à montrer que la vraisemblance
globale sera supérieur à celle obtenue par la première régression logistique.</p>
<p>On pourrait implémenter l’algorithme suivant
(Arbre de régressions logistiques en cascade orthogonale) :</p>
<ul class="simple">
<li><p>Apprendre une régression logistique</p></li>
<li><dl class="simple">
<dt>Choisir un hyperplan perpendiculaire en optimisation</dt><dd><p>un critère <a class="reference internal" href="#l-criteria-reg-log"><span class="std std-ref">Construction d’un pseudo arbre</span></a></p>
</dd>
</dl>
</li>
<li><p>Apprendre une régression logistique sur chacune des parties.</p></li>
<li><p>Continuer jusqu’à ce l’amélioration soit négligeable</p></li>
</ul>
</section>
<section id="interpretabilite">
<h2>Interprétabilité<a class="headerlink" href="#interpretabilite" title="Lien vers cette rubrique">¶</a></h2>
</section>
<section id="bibliographie">
<h2>Bibliographie<a class="headerlink" href="#bibliographie" title="Lien vers cette rubrique">¶</a></h2>
<div role="list" class="citation-list">
<div class="citation" id="scott2013" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">Scott2013</a><span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://arxiv.org/pdf/1306.0040.pdf">Expectation-maximization for logistic regression</a>,
James G. Scott, Liang Sun</p>
</div>
<div class="citation" id="nakandalam2020" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">Nakandalam2020</a><span class="fn-bracket">]</span></span>
<p>A Tensor-based Approach for One-size-fits-all ML Prediction Serving.
Supun Nakandalam, Karla Saur, Gyeong-In Yu, Konstantinos Karanasos, Carlo Curino,
Markus Weimer, Matteo Interlandi. To appear at <a class="reference external" href="https://www.usenix.org/conference/osdi20">OSDI 2020</a>.</p>
</div>
</div>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="../notebooks/ml/reseau_neurones.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Réseaux de neurones</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="../notebooks/ml/logreg_voronoi.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Voronoï et régression logistique</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2016-2025, Xavier Dupré
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Régression logistique par morceaux, arbres de décision</a><ul>
<li><a class="reference internal" href="#parallele-entre-un-neurone-et-une-regression-logistique">Parallèle entre un neurone et une régression logistique</a></li>
<li><a class="reference internal" href="#principe-d-un-arbre-de-decision">Principe d’un arbre de décision</a></li>
<li><a class="reference internal" href="#construction-d-un-pseudo-arbre">Construction d’un pseudo arbre</a></li>
<li><a class="reference internal" href="#aparte-mathematique">Aparté mathématique</a></li>
<li><a class="reference internal" href="#approche-em-et-regression-logistique">Approche EM et régression logistique</a></li>
<li><a class="reference internal" href="#lien-vers-les-reseaux-de-neurones">Lien vers les réseaux de neurones</a></li>
<li><a class="reference internal" href="#plan-orthogonal">Plan orthogonal</a></li>
<li><a class="reference internal" href="#interpretabilite">Interprétabilité</a></li>
<li><a class="reference internal" href="#bibliographie">Bibliographie</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../_static/documentation_options.js?v=0886690b"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/furo.js?v=5fa4622c"></script>
    <script src="../_static/translations.js?v=e6b791cb"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    </body>
</html>