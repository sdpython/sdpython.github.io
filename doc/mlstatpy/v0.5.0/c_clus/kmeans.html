<!doctype html>
<html class="no-js" lang="fr" data-content_root="../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Recherche" href="../search.html" /><link rel="next" title="Mélange de lois normales" href="gauss_mixture.html" /><link rel="prev" title="Clustering" href="index.html" />

    <!-- Generated with Sphinx 8.1.3 and Furo 2024.08.06 -->
        <title>k-means - Documentation mlstatpy 0.5.0</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=354aac6f" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css?v=4ae1632d" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css?v=7f9a90b1" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=302659d7" />
    
    


<style>
  body {
    --color-code-background: #eeffcc;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">Documentation mlstatpy 0.5.0</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="../_static/project_ico.png" alt="Logo"/>
  </div>
  
  <span class="sidebar-brand-text">Documentation mlstatpy 0.5.0</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Recherche" name="q" aria-label="Recherche">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Mathematics</span></p>
<ul class="current">
<li class="toctree-l1 current has-children"><a class="reference internal" href="index.html">Clustering</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of Clustering</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2 current current-page"><a class="current reference internal" href="#">k-means</a></li>
<li class="toctree-l2"><a class="reference internal" href="gauss_mixture.html">Mélange de lois normales</a></li>
<li class="toctree-l2"><a class="reference internal" href="kohonen.html">Carte de Kohonen</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../c_ml/index.html">Non linéaire</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of Non linéaire</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../c_ml/rn/rn.html">Réseaux de neurones</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of Réseaux de neurones</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../c_ml/rn/rn_1_def.html">Définition des réseaux de neurones multi-couches</a></li>
<li class="toctree-l3"><a class="reference internal" href="../c_ml/rn/rn_2_reg.html">La régression</a></li>
<li class="toctree-l3"><a class="reference internal" href="../c_ml/rn/rn_3_clas.html">La classification</a></li>
<li class="toctree-l3"><a class="reference internal" href="../c_ml/rn/rn_4_densite.html">Démonstration du théorème de la densité des réseaux de neurones</a></li>
<li class="toctree-l3"><a class="reference internal" href="../c_ml/rn/rn_5_newton.html">Descente de gradient</a></li>
<li class="toctree-l3"><a class="reference internal" href="../c_ml/rn/rn_6_apprentissage.html">Apprentissage d’un réseau de neurones</a></li>
<li class="toctree-l3"><a class="reference internal" href="../c_ml/rn/rn_7_clas2.html">Classification</a></li>
<li class="toctree-l3"><a class="reference internal" href="../c_ml/rn/rn_8_prol.html">Prolongements</a></li>
<li class="toctree-l3"><a class="reference internal" href="../c_ml/rn/rn_9_auto.html">Analyse en composantes principales (ACP) et Auto Encoders</a></li>
<li class="toctree-l3"><a class="reference internal" href="../c_ml/rn/rn_biblio.html">Bibliographie</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../c_ml/kppv.html">Classification à l’aide des plus proches voisins</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../c_ml/missing_values_mf.html">Liens entre factorisation de matrices, ACP, k-means</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of Liens entre factorisation de matrices, ACP, k-means</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/mf_acp.html">Factorisation et matrice et ACP</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/valeurs_manquantes_mf.html">Valeurs manquantes et factorisation de matrices</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/ml/neural_tree.html">Un arbre de décision en réseaux de neurones</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/ml/neural_tree_onnx.html">NeuralTreeNet et ONNX</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/ml/neural_tree_cost.html">NeuralTreeNet et coût</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../c_ml/index_reg_lin.html">Régression linéaire</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of Régression linéaire</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/dsgarden/regression_lineaire.html">Régression linéaire</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../c_ml/regression_quantile.html">Régression quantile ou régression L1</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle navigation of Régression quantile ou régression L1</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/dsgarden/quantile_regression_example.html">Régression quantile illustrée</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../c_ml/piecewise.html">Régression linéaire par morceaux</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle navigation of Régression linéaire par morceaux</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/piecewise_linear_regression.html">Régression linéaire par morceaux</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/regression_no_inversion.html">Régression sans inversion</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../c_ml/l1l2.html">Normalisation des coefficients</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../c_ml/index_reg_log.html">Régression logistique</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle navigation of Régression logistique</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../c_ml/lr_voronoi.html">Régression logistique, diagramme de Voronoï, k-Means</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle navigation of Régression logistique, diagramme de Voronoï, k-Means</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/logreg_voronoi.html">Voronoï et régression logistique</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../c_ml/lr_trees.html">Régression logistique par morceaux, arbres de décision</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/ml/reseau_neurones.html">Réseaux de neurones</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../c_ml/survival_analysis.html">Analyse de survie</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle navigation of Analyse de survie</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/survival.html">Analyse de survie en pratique</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../c_nlp/index.html">NLP</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><div class="visually-hidden">Toggle navigation of NLP</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../c_nlp/completion.html">Complétion</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><div class="visually-hidden">Toggle navigation of Complétion</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../c_nlp/completion_formalisation.html">Formalisation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../c_nlp/completion_fausse.html">Fausses idées reçues</a></li>
<li class="toctree-l3"><a class="reference internal" href="../c_nlp/completion_metrique.html">Nouvelle métrique</a></li>
<li class="toctree-l3"><a class="reference internal" href="../c_nlp/completion_propriete.html">Propriétés mathématiques</a></li>
<li class="toctree-l3"><a class="reference internal" href="../c_nlp/completion_optimisation.html">Problème d’optimisation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../c_nlp/completion_implementation.html">Implémentation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../c_nlp/completion_digression.html">Digressions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/nlp/completion_trie.html">Complétion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/nlp/completion_profiling.html">Completion profiling</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/nlp/completion_trie_long.html">Completion Trie and metrics</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/nlp/completion_simple.html">Complétion Simple</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../c_metric/index.html">Métriques</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" role="switch" type="checkbox"/><label for="toctree-checkbox-13"><div class="visually-hidden">Toggle navigation of Métriques</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../c_metric/roc.html">Courbe ROC</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" role="switch" type="checkbox"/><label for="toctree-checkbox-14"><div class="visually-hidden">Toggle navigation of Courbe ROC</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/metric/roc_example.html">ROC</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../c_metric/pvalues.html">Confidence Interval and p-Value</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" role="switch" type="checkbox"/><label for="toctree-checkbox-15"><div class="visually-hidden">Toggle navigation of Confidence Interval and p-Value</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/metric/pvalues_examples.html">p-values</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../c_algo/index.html">Algorithmes</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" role="switch" type="checkbox"/><label for="toctree-checkbox-16"><div class="visually-hidden">Toggle navigation of Algorithmes</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../c_algo/edit_distance.html">Distance d’édition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../c_algo/graph_distance.html">Distance between two graphs</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../c_algo/gest.html">Détection de segments</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" role="switch" type="checkbox"/><label for="toctree-checkbox-17"><div class="visually-hidden">Toggle navigation of Détection de segments</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/image/segment_detection.html">Détection de segments dans une image</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../c_garden/index.html">Pérégrinations</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" role="switch" type="checkbox"/><label for="toctree-checkbox-18"><div class="visually-hidden">Toggle navigation of Pérégrinations</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/dsgarden/split_train_test.html">Répartir en base d’apprentissage et de test</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/dsgarden/correlation_non_lineaire.html">Corrélations non linéaires</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../c_garden/file_dattente.html">File d’attente, un petit exemple</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" role="switch" type="checkbox"/><label for="toctree-checkbox-19"><div class="visually-hidden">Toggle navigation of File d’attente, un petit exemple</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/dsgarden/file_dattente_ex.html">File d’attente, un exemple simple</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../c_garden/strategie_avec_alea.html">Optimisation avec données aléatoires</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/dsgarden/discret_gradient.html">Le gradient et le discret</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../c_garden/quantization.html">Quantization</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" role="switch" type="checkbox"/><label for="toctree-checkbox-20"><div class="visually-hidden">Toggle navigation of Quantization</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/dsgarden/quantization_f8.html">Quantization</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/dsgarden/classification_multiple.html">Classification multiple</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api/index.html">API</a><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" role="switch" type="checkbox"/><label for="toctree-checkbox-21"><div class="visually-hidden">Toggle navigation of API</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../api/ml.html">Machine Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/optim.html">Optimisation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/text.html">Traitement du langage naturel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/data.html">Source de données</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/graph.html">Graphes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/image.html">Image</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/modules/index.html">Modules</a><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" role="switch" type="checkbox"/><label for="toctree-checkbox-22"><div class="visually-hidden">Toggle navigation of Modules</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/modules/poulet.html">mlstatpy.garden.poulet</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/modules/graph_distance.html">mlstatpy.graph.graph_distance</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/modules/kppv.html">mlstatpy.ml.kppv</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/modules/kppv_laesa.html">mlstatpy.ml.kppv_laesa</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/modules/logreg.html">mlstatpy.ml.logreg</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/modules/neural_tree.html">mlstatpy.ml.neural_tree</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/modules/roc.html">mlstatpy.ml.roc</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/modules/completion.html">mlstatpy.nlp.completion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/modules/completion_simple.html">mlstatpy.nlp.completion_simple</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/modules/sgd.html">mlstatpy.optim.sgd</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../i_ex.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../defthe_index.html">Listes des définitions et théorèmes</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../auto_examples/index.html">Gallery of examples</a><input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" role="switch" type="checkbox"/><label for="toctree-checkbox-23"><div class="visually-hidden">Toggle navigation of Gallery of examples</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_logistic_decision.html">Arbre d’indécision</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../notebooks/index.html">Galleries de notebooks</a><input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" role="switch" type="checkbox"/><label for="toctree-checkbox-24"><div class="visually-hidden">Toggle navigation of Galleries de notebooks</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../notebooks/dsgarden/index.html">Le petit coin des data scientists</a><input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" role="switch" type="checkbox"/><label for="toctree-checkbox-25"><div class="visually-hidden">Toggle navigation of Le petit coin des data scientists</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/dsgarden/classification_multiple.html">Classification multiple</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/dsgarden/correlation_non_lineaire.html">Corrélations non linéaires</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/dsgarden/discret_gradient.html">Le gradient et le discret</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/dsgarden/file_dattente_ex.html">File d’attente, un exemple simple</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/dsgarden/quantile_regression_example.html">Régression quantile illustrée</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/dsgarden/quantization_f8.html">Quantization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/dsgarden/regression_lineaire.html">Régression linéaire</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/dsgarden/split_train_test.html">Répartir en base d’apprentissage et de test</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../notebooks/image/index.html">Images</a><input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" role="switch" type="checkbox"/><label for="toctree-checkbox-26"><div class="visually-hidden">Toggle navigation of Images</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/image/segment_detection.html">Détection de segments dans une image</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../notebooks/metric/index.html">Métriques</a><input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" role="switch" type="checkbox"/><label for="toctree-checkbox-27"><div class="visually-hidden">Toggle navigation of Métriques</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/metric/pvalues_examples.html">p-values</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/metric/roc_example.html">ROC</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../notebooks/ml/index.html">Machine Learning</a><input class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" role="switch" type="checkbox"/><label for="toctree-checkbox-28"><div class="visually-hidden">Toggle navigation of Machine Learning</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/logreg_voronoi.html">Voronoï et régression logistique</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/mf_acp.html">Factorisation et matrice et ACP</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/neural_tree.html">Un arbre de décision en réseaux de neurones</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/neural_tree_cost.html">NeuralTreeNet et coût</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/neural_tree_onnx.html">NeuralTreeNet et ONNX</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/piecewise_linear_regression.html">Régression linéaire par morceaux</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/regression_no_inversion.html">Régression sans inversion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/reseau_neurones.html">Réseaux de neurones</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/survival.html">Analyse de survie en pratique</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/valeurs_manquantes_mf.html">Valeurs manquantes et factorisation de matrices</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../notebooks/nlp/index.html">NLP - Natural Language Processing</a><input class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" role="switch" type="checkbox"/><label for="toctree-checkbox-29"><div class="visually-hidden">Toggle navigation of NLP - Natural Language Processing</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/nlp/completion_profiling.html">Completion profiling</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/nlp/completion_simple.html">Complétion Simple</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/nlp/completion_trie.html">Complétion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/nlp/completion_trie_long.html">Completion Trie and metrics</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">More</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../glossary.html">Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../CHANGELOGS.html">Change Logs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../CHANGELOGS.html#id2">0.4.0</a></li>
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
<li class="toctree-l1"><a class="reference internal" href="../genindex.html">Index</a></li>
<li class="toctree-l1"><a class="reference internal" href="../py-modindex.html">Index du module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../search.html">Page de recherche</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="../_sources/c_clus/kmeans.rst" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="k-means">
<span id="l-k-means"></span><h1>k-means<a class="headerlink" href="#k-means" title="Lien vers cette rubrique">¶</a></h1>
<p><em>Dénomination française : algorithme des centres mobiles.</em></p>
<section id="principe">
<span id="index-0"></span><h2>Principe<a class="headerlink" href="#principe" title="Lien vers cette rubrique">¶</a></h2>
<p>Les centres mobiles ou nuées dynamiques sont un algorithme de classification
<em>non supervisée</em>. A partir d’un ensemble de points, il détermine pour un
nombre de classes fixé, une répartition des points qui minimise un
critère appelé <em>inertie</em> ou variance <em>intra-classe</em>.</p>
<div class="admonition-mathdef admonition" id="indexmathe-Algorithme0">
<div class="docutils container">
</div>
<p class="admonition-title" id="kmeans-def-algo">Algorithme A1 : centre mobile, k-means</p>
<p>On considère un ensemble de points :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/3aecfb408214f41fe14dff6fc080cb52c6f2d7a0.svg" alt="\left(X_i\right)_{1\leqslant i\leqslant P}\in\left(\mathbb{R}^N\right)^P"/></p>
</div></div>
<p>A chaque point est associée une classe :
<img class="math" src="../_images/math/8fbb04a7fd604cf3d5ab4f74d7a34f443fee16b0.svg" alt="\left(c_i\right)_{1\leqslant i\leqslant P}\in\left\{1,...,C\right\}^P"/>.
On définit les barycentres des classes :
<img class="math" src="../_images/math/e45775312199459dbdab618b1e133f66f02ee6a3.svg" alt="\left( G_i\right)_{1\leqslant i\leqslant C}\in\left(\mathbb{R}^N\right)^C"/>.</p>
<p><em>Initialisation</em></p>
<p>L’initialisation consiste à choisir pour chaque point une classe aléatoirement dans
<img class="math" src="../_images/math/2ab98387c03ab0e650306cbd442f1f9a60ff4218.svg" alt="\left\{1,...,C\right\}"/>. On pose <img class="math" src="../_images/math/e75ee36648418afabd4cbd3434fb5e3f14b2dd35.svg" alt="t = 0"/>.</p>
<p id="hmm-cm-step-bary"><em>Calcul des barycentres</em></p>
<div class="line-block">
<div class="line">for k in <img class="math" src="../_images/math/f963c7631cb87c320d1687686f34c5e48b508b2d.svg" alt="1..C"/></div>
<div class="line-block">
<div class="line"><img class="math" src="../_images/math/8a3db512bbb25da3c950ee29e091b8bbd5386d18.svg" alt="G_k^t \longleftarrow \sum_{i=1}^P X_i \, \mathbf{1}_{\left\{c_i^t=k\right\}} \sum_{i=1}^P \mathbf{1}_{\left\{c_i^t=k\right\}}"/></div>
</div>
</div>
<p><em>Calcul de l’inertie</em></p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/28fa5741d138e33445bca8bd990c592a523aa6b9.svg" alt="\begin{array}{lll}
I^t &amp;\longleftarrow&amp; \sum_{i=1}^P \; d^2\left(X_i, G_{c_i^t}^t\right) \\
t   &amp;\longleftarrow&amp; t+1
\end{array}"/></p>
</div></div>
<div class="line-block">
<div class="line">if <img class="math" src="../_images/math/00d07f71cd210dbc4d6982774175b3b746d6330e.svg" alt="t &gt; 0"/> et <img class="math" src="../_images/math/620d5f81891c433e5f48def7a7191a56b1d5dfe6.svg" alt="I_t \sim I_{t-1}"/></div>
<div class="line-block">
<div class="line">arrêt de l’algorithme</div>
</div>
</div>
<p id="hmm-cm-step-attr"><em>Attribution des classes</em></p>
<div class="line-block">
<div class="line">for in <img class="math" src="../_images/math/df2683ce64cbd8aa455227bc05a9dff56f80cd46.svg" alt="1..P"/></div>
<div class="line-block">
<div class="line"><img class="math" src="../_images/math/cf85f2c54f14763d61530fad52f5f476aeb71ed1.svg" alt="c_i^{t+1} \longleftarrow \underset{k}{\arg\min} \; d\left(  X_{i},G_{k}^{t}\right)"/></div>
<div class="line">où <img class="math" src="../_images/math/c2cc82176a4ab3caca55fe95f563d4e0657fbf8f.svg" alt="d\left(X_i,G_k^t\right)"/> est la distance entre <img class="math" src="../_images/math/c15b262677ad7177c2e37298a2eb382d712b3a52.svg" alt="X_i"/> et <img class="math" src="../_images/math/75014aeefe371ad56993a725fb07f0591c0c8820.svg" alt="G_k^t"/></div>
</div>
</div>
<p>Retour à l’étape du calcul des barycentres jusqu’à convergence de l’inertie <img class="math" src="../_images/math/8384668a714bfd2a900009fc5988cdcae0e5679a.svg" alt="I^t"/>.</p>
</div>
<div class="admonition-mathdef admonition" id="indexmathe-Théorème0">
<div class="docutils container">
</div>
<p class="admonition-title" id="theoreme-inertie-1">Théorème T1 : convergence des k-means</p>
<p>Quelque soit l’initialisation choisie, la suite <img class="math" src="../_images/math/dc6e79a6b925c6370d9f1098066ee6268c69fb4d.svg" alt="\pa{I_t}_{t\supegal 0}"/>
construite par l’algorithme des <a class="reference internal" href="#kmeans-def-algo"><span class="std std-ref">k-means</span></a>
converge.</p>
</div>
<p>La démonstration du théorème nécessite le lemme suivant.</p>
<div class="admonition-mathdef admonition" id="indexmathe-Lemme0">
<div class="docutils container">
</div>
<p class="admonition-title" id="lemme-inertie-minimum">Lemme L1 : inertie minimum</p>
<p>Soit <img class="math" src="../_images/math/ab327c4830bd67061a70965838dd5f0e4304b4ae.svg" alt="\vecteur{X_1}{X_P} \in \pa{\mathbb{R}^N}^P"/>,
<img class="math" src="../_images/math/2f2a105c289b01c226ad6e0f506d96386c48d440.svg" alt="P"/> points de <img class="math" src="../_images/math/e0d2c3c43a5ca8a93521f5070fcc03a4109482da.svg" alt="\mathbb{R}^N"/>, le minimum de la quantité
<img class="math" src="../_images/math/1a51aede74e61c53ebf9251dda9798d53db0c8a7.svg" alt="Q\pa{Y \in \mathbb{R}^N}"/> :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/24c842009c8496b5cfa1ba182a599e7f574954f6.svg" alt="\begin{eqnarray}
Q\pa{Y} &amp;=&amp; \sum_{i=1}^P \; d^2\pa{X_i,Y}
\end{eqnarray}"/></p>
</div></div>
<p>est atteint pour <img class="math" src="../_images/math/9640141c96e289d1cc695d1777f52505fcf46649.svg" alt="Y=G=\dfrac{1}{P} \sum_{i=1}^{P} X_i"/>
le barycentre des points <img class="math" src="../_images/math/cf168a3f3647fa1f5fa81a83378c60fc279eecf3.svg" alt="\vecteur{X_1}{X_P}"/>.</p>
</div>
<p>Soit <img class="math" src="../_images/math/ab327c4830bd67061a70965838dd5f0e4304b4ae.svg" alt="\vecteur{X_1}{X_P} \in \pa{\mathbb{R}^N}^P"/>,
<img class="math" src="../_images/math/2f2a105c289b01c226ad6e0f506d96386c48d440.svg" alt="P"/> points de <img class="math" src="../_images/math/e0d2c3c43a5ca8a93521f5070fcc03a4109482da.svg" alt="\mathbb{R}^N"/>.</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/6a29e9ab68372844dac0a4127ffee0352f17639f.svg" alt="\begin{eqnarray*}
                    \sum_{i=1}^{P} \overrightarrow{GX_{i}} = \overrightarrow{0}
&amp;\Longrightarrow&amp;      \sum_{i=1}^{P} d^2\pa{X_i,Y} = \sum_{i=1}^{P} d^2\pa{X_i,G}+ P \, d^2\pa{G,Y} \\
&amp;\Longrightarrow&amp;     \underset{Y\in\mathbb{R}^N}{\arg\min} \; \sum_{i=1}^{P} d^2\pa{X_i,Y} = \acc{G}
\end{eqnarray*}"/></p>
</div></div>
<p>On peut maintenant démontrer le théorème.
L’étape d’attribution des classes consiste à attribuer à chaque
point le barycentre le plus proche. On définit <img class="math" src="../_images/math/3b1d41c0394f1d0df53dcd8a361ce1a3c2fc5160.svg" alt="J_t"/> par :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/543a741e1011b1ec47fda7a2979b2b21b386ae0d.svg" alt="\begin{eqnarray}
J^{t+1} &amp;=&amp; \sum_{i=1}^{P} \; d^2\pa{ X_i, G_{c_i^{t+1}}^t}
\end{eqnarray}"/></p>
</div></div>
<p>On en déduit que :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/8b124540807ab83949a654170bc67bb44d2272b9.svg" alt="\begin{eqnarray}
J^{t+1}    &amp;=&amp; \sum_{i, c_i^t \neq c_i^{t+1}} \; d^2\pa{ X_i, G_{c_i^{t+1}}^t} + J^{t+1} \sum_{i, c_i^t = c_i^{t+1}} \; d^2\pa{ X_i, G_{c_i^{t+1}}^t}  \\
J^{t+1}    &amp;\leqslant&amp;  \sum_{i, c_i^t \neq c_i^{t+1}} \; d^2\pa{ X_i, G_{c_i^{t}}^t} + \sum_{i, c_i^t = c_i^{t+1}} \; d^2\pa{ X_i, G_{c_i^{t}}^t} \\
J^{t+1}    &amp;\leqslant&amp;  I^t
\end{eqnarray}"/></p>
</div></div>
<p>Le lemme précédent appliqué à chacune des classes <img class="math" src="../_images/math/79c96636ca69f9cb49bd9df5dab7ef30f8d5ba3e.svg" alt="\ensemble{1}{C}"/>,
permet d’affirmer que <img class="math" src="../_images/math/1c81190f60b3604688ed32ba3a2467860ad1a838.svg" alt="I^{t+1} \leqslant J^{t+1}"/>.
Par conséquent, la suite <img class="math" src="../_images/math/dc6e79a6b925c6370d9f1098066ee6268c69fb4d.svg" alt="\pa{I_t}_{t\supegal 0}"/> est décroissante et minorée par
0, elle est donc convergente.</p>
<p id="index-1">L’algorithme des centres mobiles cherche à attribuer à chaque
point de l’ensemble une classe parmi les <img class="math" src="../_images/math/2c0e77bc741b692ecdf6e85966263a89422af4c8.svg" alt="C"/> disponibles.
La solution trouvée dépend de l’initialisation et n’est pas forcément
celle qui minimise l’inertie intra-classe : l’inertie finale est
un minimum local. Néanmoins, elle assure que la partition est formée
de classes convexes : soit <img class="math" src="../_images/math/3950d3def11e9f0784eacec55d2b79c3a0bf19df.svg" alt="c_1"/> et <img class="math" src="../_images/math/c50924711ece3aac359df4fd02db9d6f74bb0fb1.svg" alt="c_2"/> deux classes différentes,
on note <img class="math" src="../_images/math/0247a196052dd9baf0366fbf8f6a1d87e64c7c5f.svg" alt="C_1"/> et <img class="math" src="../_images/math/5838b45439d93f4669eab86d0796eeb6e7195cba.svg" alt="C_2"/> les enveloppes convexes des points qui
constituent ces deux classes, alors
<img class="math" src="../_images/math/d985fae5e74d3e4571004f70e62cd235c3007e27.svg" alt="\overset{o}{C_1} \cap \overset{o}{C_2} = \emptyset"/>.
La figure suivante présente un exemple d’utilisation de l’algorithme
des centres mobiles. Des points sont générés aléatoirement
dans le plan et répartis en quatre groupes.</p>
<img alt="../_images/cm.png" src="../_images/cm.png" />
<p>C’est une application des centres mobiles avec une classification en quatre classes
d’un ensemble aléatoire de points plus dense sur la partie droite du graphe. Les quatre classes
ainsi formées sont convexes.</p>
<section id="homogeneite-des-dimensions">
<span id="hmm-classification-obs-deux"></span><h3>Homogénéité des dimensions<a class="headerlink" href="#homogeneite-des-dimensions" title="Lien vers cette rubrique">¶</a></h3>
<p>Les coordonnées des points
<img class="math" src="../_images/math/290945200c23b05845ac6cad5878df00c915d756.svg" alt="\left(X_i\right) \in \mathbb{R}^N"/> sont généralement non homogènes :
les ordres de grandeurs de chaque dimension sont différents.
C’est pourquoi il est conseillé de centrer et normaliser chaque dimension.
On note : <img class="math" src="../_images/math/0ebe5f3361de03c441c9b2cbf93bb1339755661c.svg" alt="\forall i \in \intervalle{1}{P}, \; X_i = \vecteur{X_{i,1}}{X_{i,N}}"/> :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/2d27398f90cd778fc8219befb5f4969fccdc1f11.svg" alt="\begin{eqnarray*}
g_k &amp;=&amp; \pa{EX}_k = \frac{1}{P} \sum_{i=1}^P X_{i,k} \\
v_{kk} &amp;=&amp; \pa{E\left(X-EX\right)^2}_{kk}=\pa{EX^2}_{kk} - g_k^2
\end{eqnarray*}"/></p>
</div></div>
<p>Les points centrés et normalisés sont :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/2e5a10fc46f97a6baa43b43deddb13bf0349f460.svg" alt="\forall i \in \intervalle{1}{P}, \;
X_i^{\prime}=\left(\dfrac{x_{i,1}-g_{1}}{\sqrt{v_{11}}},...,\dfrac{x_{i,N}-g_{N}}{\sqrt{v_{NN}}}\right)"/></p>
</div></div>
<p id="index-2">L’algorithme des centres mobiles est appliqué sur l’ensemble
<img class="math" src="../_images/math/b2057ecde740acd964bd1160b7789a09dfb3c71c.svg" alt="\left( X_{i}^{\prime}\right)_{1\leqslant i\leqslant P}"/>.
Il est possible ensuite de décorréler les variables ou d’utiliser
une distance dite de <a class="reference external" href="https://fr.wikipedia.org/wiki/Distance_de_Mahalanobis">Malahanobis</a> définie par
<img class="math" src="../_images/math/cac45acdfd9138ea17baa41d675fcda9e107bc4d.svg" alt="d_M\pa{X, Y} = X \, M \, Y'"/> où <img class="math" src="../_images/math/2f38be5157e7f5029042c49957a29cf7c2f29ee0.svg" alt="Y'"/>
désigne la transposée de <img class="math" src="../_images/math/b59453388a752e340d555df9064bfb27e7112e68.svg" alt="Y"/> et <img class="math" src="../_images/math/e5c619f0600e251cabb3318b03870bc6f2c4870f.svg" alt="M"/>
est une matrice symétrique définie positive.
Dans le cas de variables corrélées, la matrice
<img class="math" src="../_images/math/8f2e404988e46f58a6e37c86071bc82d8322d3de.svg" alt="M = \Sigma^{-1}"/> où <img class="math" src="../_images/math/101365d041befcd5108977fd092dbd8bc9785dbc.svg" alt="\Sigma^{-1}"/> est la matrice
de variance-covariance des variables aléatoires <img class="math" src="../_images/math/72643a45ac37dbe64e26a084f8d7bf0c765e522b.svg" alt="\pa{X_i}_i"/>.</p>
</section>
</section>
<section id="ameliorations-de-l-initialisation">
<h2>Améliorations de l’initialisation<a class="headerlink" href="#ameliorations-de-l-initialisation" title="Lien vers cette rubrique">¶</a></h2>
<section id="l-kmeanspp">
<span id="id1"></span><h3>K-means++<a class="headerlink" href="#l-kmeanspp" title="Lien vers cette rubrique">¶</a></h3>
<p id="index-3">L’article <a class="reference internal" href="#arthur2007" id="id2"><span>[Arthur2007]</span></a> montre que l’initialisation aléatoire n’est pas efficace et
est sensible aux outliers ou points aberrants. L’étape d’initialisation est remplacée
par la suivante :</p>
<div class="admonition-mathdef admonition" id="indexmathe-Algorithme1">
<div class="docutils container">
</div>
<p class="admonition-title" id="init-kmeanspp">Algorithme A2 : initialisation k-means++</p>
<p>Cette étape d’initialisation viendra remplacer celle
définie dans l’algorithme
<a class="reference internal" href="#kmeans-def-algo"><span class="std std-ref">k-means</span></a>.
On considère un ensemble de points :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/8641428d8eda2dcf8698b45287eb4579b53979ad.svg" alt="X=\left(X_i\right)_{1\leqslant i\leqslant P}\in\left(\mathbb{R}^N\right)^P"/></p>
</div></div>
<p>A chaque point est associée une classe :
<img class="math" src="../_images/math/8fbb04a7fd604cf3d5ab4f74d7a34f443fee16b0.svg" alt="\left(c_i\right)_{1\leqslant i\leqslant P}\in\left\{1,...,C\right\}^P"/>.</p>
<p>Pour <img class="math" src="../_images/math/312028c07e271534bd0dbde5434e49e76880744f.svg" alt="k"/> centres, on choisit <img class="math" src="../_images/math/0247a196052dd9baf0366fbf8f6a1d87e64c7c5f.svg" alt="C_1"/>
au hasard dans l’ensemble <img class="math" src="../_images/math/b66c7d6c52c7b12bee7fb24d76c38fc70cfc0a2f.svg" alt="X"/>.
Pour les suivants :</p>
<ol class="arabic simple">
<li><p><img class="math" src="../_images/math/f3426cfc16493940b22f7321730b3e3c6e4aa4bb.svg" alt="k \leftarrow 2"/></p></li>
<li><p>On choisit aléatoirement <img class="math" src="../_images/math/e005910ee0a428539915444c2ea62c0b8c6bba74.svg" alt="G_k \in X"/> avec la probabilité
<img class="math" src="../_images/math/b217ea0d59e42a46339694765455b3f276d18b0d.svg" alt="P(x) = \frac{D_{k-1}(x)^2}{\sum_{x\in X}D_{k-1}(x)^2}"/></p></li>
<li><p><img class="math" src="../_images/math/26f65fceab6599facc16133f496cd1c24b9073f8.svg" alt="k \leftarrow k+1"/></p></li>
<li><p>On revient à l’étape 2 jusqu’à ce que <img class="math" src="../_images/math/2142171ad258df7aa0ffd1bc4abe7f785f080ecb.svg" alt="k=C"/>.</p></li>
</ol>
<p>La fonction <img class="math" src="../_images/math/96d648b9ba49faf544f18bffe162bff2e293634f.svg" alt="D_k"/> est définie par la distance du point <img class="math" src="../_images/math/cdd160a57af92571d6838c69c7bde600843a23bf.svg" alt="x"/>
au centre <img class="math" src="../_images/math/36b42e357e2e138a2e83f331c2467495293aac6d.svg" alt="G_l"/> choisi parmi les <img class="math" src="../_images/math/312028c07e271534bd0dbde5434e49e76880744f.svg" alt="k"/> premiers centres.
<img class="math" src="../_images/math/15a4e895a74f9813c8ce9ee38c5c3e1eaddffa4a.svg" alt="D_k(x) = \min_{1 \leqslant l \leqslant k} d(x - G_l)"/>.</p>
<p>La suite de l’algorithme <em>k-means++</em> reprend les mêmes étapes que
<a class="reference internal" href="#kmeans-def-algo"><span class="std std-ref">k-means</span></a>.</p>
</div>
<p>Cette initilisation éloigne le prochain centre le plus possibles des
centres déjà choisis. L’article montre que :</p>
<div class="admonition-mathdef admonition" id="indexmathe-Théorème1">
<p class="admonition-title">Théorème T2 : Borne supérieure de l’erreur produite par k-means++</p>
<p>On définit l’inertie par
<img class="math" src="../_images/math/1326dc7c9643c65fdf963b33d46e022fc14bbac9.svg" alt="J_(X) = \sum_{i=1}^{P} \; \min_G d^2(X_i, G)"/>.
Si <img class="math" src="../_images/math/83176a4f55c394ebf2e1fdf290bd87eb5a99a345.svg" alt="J_{OPT}"/> définit l’inertie optimale alors
<img class="math" src="../_images/math/607c80d070f5233c1c31ac01ccffef6b2947200d.svg" alt="\esp{J(X)} \leqslant 8 (\ln C + 2) J_{OPT}(X)"/>.</p>
</div>
<p>La démonstration est disponible dans l’article <a class="reference internal" href="#arthur2007" id="id3"><span>[Arthur2007]</span></a>.</p>
</section>
<section id="id4">
<h3>K-means||<a class="headerlink" href="#id4" title="Lien vers cette rubrique">¶</a></h3>
<p>L’article <a class="reference internal" href="#bahmani2012" id="id5"><span>[Bahmani2012]</span></a> propose une autre initialisation
que <a class="reference internal" href="#l-kmeanspp"><span class="std std-ref">K-means++</span></a> mais plus rapide et parallélisable.</p>
<div class="admonition-mathdef admonition" id="indexmathe-Algorithme2">
<div class="docutils container">
</div>
<p class="admonition-title" id="init-kmeansppll">Algorithme A3 : initialisation k-means||</p>
<p>Cette étape d’initialisation viendra remplacer celle
définie dans l’algorithme
<a class="reference internal" href="#kmeans-def-algo"><span class="std std-ref">k-means</span></a>.
On considère un ensemble de points :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/8641428d8eda2dcf8698b45287eb4579b53979ad.svg" alt="X=\left(X_i\right)_{1\leqslant i\leqslant P}\in\left(\mathbb{R}^N\right)^P"/></p>
</div></div>
<p>A chaque point est associée une classe :
<img class="math" src="../_images/math/8fbb04a7fd604cf3d5ab4f74d7a34f443fee16b0.svg" alt="\left(c_i\right)_{1\leqslant i\leqslant P}\in\left\{1,...,C\right\}^P"/>.</p>
<p>Pour <img class="math" src="../_images/math/312028c07e271534bd0dbde5434e49e76880744f.svg" alt="k"/> centres, on choisit <img class="math" src="../_images/math/67ff5828e87602fb558f801a96396559e04e0dd9.svg" alt="G = \{G_1\}"/>
au hasard dans l’ensemble <img class="math" src="../_images/math/b66c7d6c52c7b12bee7fb24d76c38fc70cfc0a2f.svg" alt="X"/>.</p>
<div class="line-block">
<div class="line">on répète <img class="math" src="../_images/math/0a185a031e88ca1155325a6e0ba9c06642d3fab1.svg" alt="O(\ln D(G, X))"/> fois :</div>
<div class="line-block">
<div class="line"><img class="math" src="../_images/math/e193c978ec2415600c7ea2810f794ff2959db4c2.svg" alt="G' \leftarrow"/> échantillon aléatoire issue de <img class="math" src="../_images/math/b66c7d6c52c7b12bee7fb24d76c38fc70cfc0a2f.svg" alt="X"/> de probabilité <img class="math" src="../_images/math/4eea0ad742152d6108fde2a6a484470903d03702.svg" alt="p(x) = l \frac{D(G,x)^2}{\sum_x D(G,x)^2}"/></div>
<div class="line"><img class="math" src="../_images/math/6261544c59180ee36cd1108bd4e15069bd94c12f.svg" alt="G \leftarrow G \cup G'"/></div>
</div>
</div>
<p>La fonction <img class="math" src="../_images/math/6f299d138def92cb9b8de6e24011d19bbbfb2e76.svg" alt="D(G,x)"/> est définie par la distance du point <img class="math" src="../_images/math/cdd160a57af92571d6838c69c7bde600843a23bf.svg" alt="x"/>
au plus proche centre <img class="math" src="../_images/math/d3a5ece8d7ec78151cf34c4ac504aa41edd1f660.svg" alt="g \in G"/> :
<img class="math" src="../_images/math/3a7b447089b20dc22e9407de72af078c6c025584.svg" alt="D(g,x) = \min_{g \in G} d(x - g)"/>.
Cette étape ajoute à l’ensemble des centres <img class="math" src="../_images/math/86a30eae2899d36dcee14ab62c5e4c8a68feed4d.svg" alt="G"/>
un nombre aléatoire de centres à chaque étape.
L’ensemble <img class="math" src="../_images/math/86a30eae2899d36dcee14ab62c5e4c8a68feed4d.svg" alt="G"/> contiendra plus de <img class="math" src="../_images/math/2c0e77bc741b692ecdf6e85966263a89422af4c8.svg" alt="C"/> centres.</p>
<ol class="arabic simple">
<li><p>Pour tout <img class="math" src="../_images/math/d3a5ece8d7ec78151cf34c4ac504aa41edd1f660.svg" alt="g \in G"/>, on assigne le poids <img class="math" src="../_images/math/7a384ce2009fcbc54c587a963141c4ba88347609.svg" alt="w_g = card \acc{ y | d(x, y) &lt; \min_{h \in G} d(x, h)}"/></p></li>
<li><p>On clusterise l’ensemble des points <img class="math" src="../_images/math/86a30eae2899d36dcee14ab62c5e4c8a68feed4d.svg" alt="G"/> en <img class="math" src="../_images/math/2c0e77bc741b692ecdf6e85966263a89422af4c8.svg" alt="C"/> clusters
(avec un k-means classique par exemple)</p></li>
</ol>
</div>
<p>Au lieu d’ajouter les centres un par un comme dans l’algorithme
<a class="reference internal" href="#init-kmeanspp"><span class="std std-ref">k-means++</span></a>, plusieurs sont ajoutés à chaque fois,
plus <img class="math" src="../_images/math/b40d7de3530507b378090edb54198bdc06e33be9.svg" alt="l"/> est grand, plus ce nombre est grand. Le tirage d’un échantillon
aléatoire consiste à inclure chaque point <img class="math" src="../_images/math/cdd160a57af92571d6838c69c7bde600843a23bf.svg" alt="x"/> avec la probabilité
<img class="math" src="../_images/math/4eea0ad742152d6108fde2a6a484470903d03702.svg" alt="p(x) = l \frac{D(G,x)^2}{\sum_x D(G,x)^2}"/>.</p>
</section>
</section>
<section id="estimation-de-probabilites">
<span id="hmm-classification-obs-trois"></span><h2>Estimation de probabilités<a class="headerlink" href="#estimation-de-probabilites" title="Lien vers cette rubrique">¶</a></h2>
<p>A partir de cette classification en <img class="math" src="../_images/math/2c0e77bc741b692ecdf6e85966263a89422af4c8.svg" alt="C"/> classes, on construit un
vecteur de probabilités pour chaque point <img class="math" src="../_images/math/cc127b27a3989c9a0645437c30a848e90837afc7.svg" alt="\pa{X_{i}}_{1 \leqslant i \leqslant P}"/>
en supposant que la loi de <img class="math" src="../_images/math/b66c7d6c52c7b12bee7fb24d76c38fc70cfc0a2f.svg" alt="X"/> sachant sa classe <img class="math" src="../_images/math/f69ba531fba42e37e610be4c5e36f06fa00e78f4.svg" alt="c_X"/> est une loi
normale multidimensionnelle. La classe de <img class="math" src="../_images/math/c15b262677ad7177c2e37298a2eb382d712b3a52.svg" alt="X_i"/> est
notée <img class="math" src="../_images/math/fa4ae29716395f8ebb2444ec26b1c6da2f3b53db.svg" alt="c_i"/>. On peut alors écrire :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/9a5fb39737956619460c225d56792438543f79bb.svg" alt="\begin{eqnarray*}
\forall i \in \intervalle{1}{C}, \; &amp; &amp; \\
G_i &amp;=&amp; E\pa{X \indicatrice{c_X = i}} = \dfrac{\sum_{k=1}^{P} X_k \indicatrice {c_k = i}} {\sum_{k=1}^{P} \indicatrice {c_k = i}} \\
V_i &amp;=&amp; E\pa{XX' \indicatrice{c_X = i}} = \dfrac{\sum_{k=1}^{P} X_k X_k' \indicatrice {c_k = i}} {\sum_{k=1}^{P} \indicatrice {c_k = i}} \\
\pr{c_X = i} &amp;=&amp; \sum_{k=1}^{P} \indicatrice {c_k = i} \\
f\pa{X | c_X = i} &amp;=&amp; \dfrac{1}{\pa{2\pi}^{\frac{N}{2}} \sqrt{\det \pa{V_i}}} \; e^{ - \frac{1}{2} \pa{X - G_i}' \; V_i^{-1} \; \pa{X - G_i} } \\
f\pa{X} &amp;=&amp; \sum_{k=1}^{P}  f\pa{X | c_X = i} \pr{c_X = i}
\end{eqnarray*}"/></p>
</div></div>
<p>On en déduit que :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/8f1131ba92f299ab42d7e3925c303eab93f02633.svg" alt="\pr{c_X = i |X } = \dfrac{f\pa{X | c_X = i}\pr{c_X = i}} {f\pa{X} }"/></p>
</div></div>
<p>La densité des obervations est alors modélisée par une mélange de
lois normales, chacune centrée au barycentre de chaque classe.
Ces probabilités peuvent également être apprises par un réseau de neurones
classifieur où servir d’initialisation à un
<a class="reference external" href="https://fr.wikipedia.org/wiki/Algorithme_esp%C3%A9rance-maximisation">algorithme EM</a>.</p>
</section>
<section id="selection-du-nombre-de-classes">
<h2>Sélection du nombre de classes<a class="headerlink" href="#selection-du-nombre-de-classes" title="Lien vers cette rubrique">¶</a></h2>
<section id="critere-de-qualite">
<span id="classification-selection-nb-classe-bouldin"></span><h3>Critère de qualité<a class="headerlink" href="#critere-de-qualite" title="Lien vers cette rubrique">¶</a></h3>
<p>L’algorithme des centres mobiles effectue une classification non supervisée
à condition de connaître au préalable le nombre de classes et
cette information est rarement disponible. Une alternative consiste à
estimer la pertinence des classifications obtenues pour différents
nombres de classes, le nombre de classes optimal est celui
qui correspond à la classification la plus pertinente.
Cette pertinence ne peut être estimée de manière unique, elle dépend des
hypothèses faites sur les éléments à classer, notamment sur la forme
des classes qui peuvent être convexes ou pas, être modélisées par des
lois normales multidimensionnelles, à matrice de covariances diagonales, …
Les deux critères qui suivent sont adaptés à l’algorithme des centres mobiles.
Le critère de <a class="reference external" href="https://en.wikipedia.org/wiki/Davies%E2%80%93Bouldin_index">Davies-Bouldin</a>
(voir <a class="reference internal" href="#davies1979" id="id6"><span>[Davies1979]</span></a>)
est minimum lorsque le nombre de classes est optimal.</p>
<div class="math-wrapper docutils container" id="index-4">
<div class="math" id="index-4">
<p><img src="../_images/math/1fc5f1924491aa845b7d3b4aca6781b95d97cf7f.svg" alt="\begin{eqnarray}
DB &amp;=&amp; \dfrac{1}{C} \;     \sum_{i=1}^{C} \; \max_{i \neq j} \; \dfrac{\sigma_i + \sigma_j}{ d\pa{C_i,C_j}}
\end{eqnarray}"/></p>
</div></div>
<p>Avec :</p>
<div class="table-wrapper colwidths-given docutils container">
<table class="docutils align-default">
<colgroup>
<col style="width: 33.3%" />
<col style="width: 66.7%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p><img class="math" src="../_images/math/2c0e77bc741b692ecdf6e85966263a89422af4c8.svg" alt="C"/></p></th>
<th class="head"><p>nombre de classes</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><img class="math" src="../_images/math/918edf1163affce55968c2b270f7ebe1865389aa.svg" alt="\sigma_i"/></p></td>
<td><p>écart-type des distances des observations de la classe <img class="math" src="../_images/math/6c9c36eeb0679ad71efe34ded19d79168983fb38.svg" alt="i"/></p></td>
</tr>
<tr class="row-odd"><td><p><img class="math" src="../_images/math/028f0a9b50db11bb7b06a1941fbc0c441259482c.svg" alt="C_i"/></p></td>
<td><p>centre de la classe <img class="math" src="../_images/math/6c9c36eeb0679ad71efe34ded19d79168983fb38.svg" alt="i"/></p></td>
</tr>
</tbody>
</table>
</div>
<p>Le critère de <a class="reference external" href="https://en.wikipedia.org/wiki/Goodman_and_Kruskal%27s_gamma">Goodman-Kruskal</a>
(voir <a class="reference internal" href="#goodman1954" id="id7"><span>[Goodman1954]</span></a>) est quant à lui maximum lorsque le nombre de classes est optimal.
Il est toutefois plus coûteux à calculer.</p>
<div class="math-wrapper docutils container" id="index-5">
<div class="math" id="index-5">
<p><img src="../_images/math/0768685dee2700f421deb6400b093439d6cbd03e.svg" alt="\begin{eqnarray}
GK &amp;=&amp; \dfrac{S^+ - S^-} { S^+ + S^-}
\end{eqnarray}"/></p>
</div></div>
<p>Avec :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/3970264331ba20df051df7bb3fd64d7e416e1b4c.svg" alt="\begin{eqnarray*}
S^+ &amp;=&amp; \acc{ \pa{q,r,s,t} \sac d\pa{q,r} &lt; d\pa{s,t} } \\
S^- &amp;=&amp; \acc{ \pa{q,r,s,t} \sac d\pa{q,r} &lt; d\pa{s,t} }
\end{eqnarray*}"/></p>
</div></div>
<p>Où <img class="math" src="../_images/math/347189a1a98974758d795362c319c74abba1aca3.svg" alt="\pa{q,r}"/> sont dans la même classe et <img class="math" src="../_images/math/c00163f11b47dc018c3149112d68ee2c77359f1a.svg" alt="\pa{s,t}"/> sont dans des classes différentes.</p>
<div class="table-wrapper colwidths-given docutils container">
<table class="docutils align-default">
<colgroup>
<col style="width: 50.0%" />
<col style="width: 50.0%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><img alt="../_images/class_4.png" src="../_images/class_4.png" />
</td>
<td><img alt="../_images/class_4_db.png" src="../_images/class_4_db.png" />
</td>
</tr>
</tbody>
</table>
</div>
<p>Classification en quatre classes : nombre de classes sélectionnées par le critère
de Davies-Bouldin dont les valeurs sont illustrées par le graphe apposé à droite.</p>
</section>
<section id="maxima-de-la-fonction-densite">
<h3>Maxima de la fonction densité<a class="headerlink" href="#maxima-de-la-fonction-densite" title="Lien vers cette rubrique">¶</a></h3>
<p>L’article <a class="reference internal" href="#herbin2001" id="id8"><span>[Herbin2001]</span></a> propose une méthode différente pour estimer
le nombre de classes, il s’agit tout d’abord d’estimer la fonction
densité du nuage de points qui est une fonction de
<img class="math" src="../_images/math/c9ace9fa2a853820e391fef3b70bd8706fa1e270.svg" alt="\mathbb{R}^n \longrightarrow \mathbb{R}"/>. Cette estimation est effectuée au moyen
d’une méthode non paramètrique telle que les estimateurs à noyau
(voir <a class="reference internal" href="#silverman1986" id="id9"><span>[Silverman1986]</span></a>)
Soit <img class="math" src="../_images/math/26f924af3662c85fdae93b78379cf709640d2119.svg" alt="\vecteur{X_1}{X_N}"/> un nuage de points inclus dans une image,
on cherche à estimer la densité <img class="math" src="../_images/math/6f28fd7539a56974612f2213cb591ec0a3a84dfa.svg" alt="f_H\pa{x}"/> au pixel <img class="math" src="../_images/math/cdd160a57af92571d6838c69c7bde600843a23bf.svg" alt="x"/> :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/89da891f3b8e707b7d971bcae862881797a35bf1.svg" alt="\hat{f}_H\pa{x} = \dfrac{1}{N} \; \sum_{i=1}^{N} \; \dfrac{1}{\det H} \; K\pa{ H^{-1} \pa{x - X_i}}"/></p>
</div></div>
<p>Où :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/6bbe174691ee6154a0430ed381cf37c64c380bf4.svg" alt="K\pa{x} = \dfrac{1}{ \pa{2 \pi}^{ \frac{d}{2}} } \; e^{ - \frac{ \norme{x}^2 } {2} }"/></p>
</div></div>
<p><img class="math" src="../_images/math/dd8a8ece0b1684a9537eb7947dc6b8fdc1652abc.svg" alt="H"/> est un paramètre estimée avec la règle de Silverman.
L’exemple utilisé dans cet article est un problème de segmentation
d’image qui ne peut pas être résolu par la méthode des nuées
dynamiques puisque la forme des classes n’est pas convexe,
ainsi que le montre la figure suivante. La fonction de densité
<img class="math" src="../_images/math/bd1e0600a66dbe0f8deddbd57953774419ba4e4f.svg" alt="f"/> est seuillée de manière à obtenir une fonction
<img class="math" src="../_images/math/2e01f937d0a2d8c83cc01e29112f51ce06b0a9a8.svg" alt="g : \mathbb{R}^n \longrightarrow \acc{0,1}"/> définie par :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/93c93cd7cae65ced8e18c991415b215492d994bc.svg" alt="g \pa{x} = \indicatrice{f\pa{x} \supegal s}"/></p>
</div></div>
<p id="index-6">L’ensemble <img class="math" src="../_images/math/0ff3fd49f1428ac4a60756aa62ed347b7aa583ae.svg" alt="g^{-1}\pa{\acc{1}} \subset \mathbb{R}^n"/>
est composée de <img class="math" src="../_images/math/bceb9186b5004313ecccd0d22d07ea9617b62f98.svg" alt="N"/> composantes connexes notées
<img class="math" src="../_images/math/a20f10afa060e7ffe17e890961a8c5c514e607aa.svg" alt="\vecteur{C_1}{C_N}"/>, la classe d’un point <img class="math" src="../_images/math/cdd160a57af92571d6838c69c7bde600843a23bf.svg" alt="x"/>
est alors l’indice de la composante connexe à la
laquelle il appartient ou la plus proche le cas échéant.</p>
<div class="table-wrapper colwidths-given docutils container">
<table class="docutils align-default">
<colgroup>
<col style="width: 50.0%" />
<col style="width: 50.0%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><img alt="../_images/herbin1.png" src="../_images/herbin1.png" />
</td>
<td><img alt="../_images/herbin2.png" src="../_images/herbin2.png" />
</td>
</tr>
</tbody>
</table>
</div>
<p>Exemple de classification non supervisée appliquée à un problème
de segmentation d’image, la première figure montre la densité obtenue,
la seconde figure illustre la classification obtenue, figure extraite de <a class="reference internal" href="#herbin2001" id="id10"><span>[Herbin2001]</span></a>.
Cette méthode paraît néanmoins difficilement applicable lorsque la
dimension de l’espace vectoriel atteint de grande valeur. L’exemple de l’image
est pratique, elle est déjà découpée en région représentées par les pixels,
l’ensemble <img class="math" src="../_images/math/e86e25f9bcdebece2cacba7f08ce89fff5255162.svg" alt="g^{-1}\pa{\acc{1}}"/> correspond à
l’ensemble des pixels <img class="math" src="../_images/math/cdd160a57af92571d6838c69c7bde600843a23bf.svg" alt="x"/> pour lesquels <img class="math" src="../_images/math/f4fe0782fbd5a03d4b57fb70f83e9517bca8ed6b.svg" alt="f\pa{x} \supegal s"/>.</p>
</section>
<section id="decroissance-du-nombre-de-classes">
<h3>Décroissance du nombre de classes<a class="headerlink" href="#decroissance-du-nombre-de-classes" title="Lien vers cette rubrique">¶</a></h3>
<p>L’article <a class="reference internal" href="#kothari1999" id="id11"><span>[Kothari1999]</span></a> propose une méthode permettant de
faire décroître le nombre de classes afin de choisir le nombre
approprié. L’algorithme des centres mobiles
proposent de faire décroître l’inertie notée <img class="math" src="../_images/math/49d95c6215d3875f7504526ed066025568d9ebd7.svg" alt="I"/>
définie pour un ensemble de points noté <img class="math" src="../_images/math/c892e2c9602fd4163676454715101e9a50ce09f3.svg" alt="X = \vecteur{x_1}{x_N}"/>
et <img class="math" src="../_images/math/2c1a946cef5763c39269198f722873a239852f50.svg" alt="K"/> classes. La classe d’un élément <img class="math" src="../_images/math/cdd160a57af92571d6838c69c7bde600843a23bf.svg" alt="x"/>
est notée <img class="math" src="../_images/math/95bf46381c090f66d5e98e0d3be6e029f6548726.svg" alt="C\pa{x}"/>. Les centres des classes sont notés
<img class="math" src="../_images/math/074ee5adf2cbdff1b8d7b0ead440d12636e4aabe.svg" alt="Y = \vecteur{y_1}{y_K}"/>.
L’inertie de ce nuage de points est définie par :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/31be75e9671bc62b1758455dbe298cb2252619fe.svg" alt="I  =  \sum_{x \in X} \; \norme{ x - y_{C\pa{x} }}^2"/></p>
</div></div>
<p>On définit tout d’abord une distance
<img class="math" src="../_images/math/13c3eb42cca2ce046974c4ed3428301a4cd40db6.svg" alt="\alpha \in \mathbb{R}^+"/>, puis l’ensemble
<img class="math" src="../_images/math/dc892b550e974eb952cdc4d80e45144376f5a924.svg" alt="V\pa{y,\alpha} = \acc{ z \in Y \sac d\pa{y,z} \leqslant \alpha }"/>,
<img class="math" src="../_images/math/28a053cbc22f90a9759293ff092729de4c8f1ba3.svg" alt="V\pa{y,\alpha}"/> est donc l’ensemble des voisins des
centres dont la distance avec <img class="math" src="../_images/math/bd7dd5ee003cda2294a46fd47aa8a1ecf28b0418.svg" alt="y"/> est inférieur à <img class="math" src="../_images/math/a1e7b66a55fc77cebd91d9a1ebfa93a29c1736fb.svg" alt="\alpha"/>.
L’article <a class="reference internal" href="#kothari1999" id="id12"><span>[Kothari1999]</span></a> propose de minimiser le coût <img class="math" src="../_images/math/f3e6140f911171400bdaceb5d083d9209c5edcd3.svg" alt="J\pa{\alpha}"/>
suivant :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/90f2a125b6b5f85477afd3470a19e16b3101e243.svg" alt="J\pa{\alpha} = \sum_{x \in X} \; \norme{ x - y_{C\pa{x} }}^2 + \sum_{x \in X} \;
\sum_{y \in V\pa{y_{C\pa{x}}, \alpha} } \; \lambda\pa{y} \, \norme{ y -  y_{C\pa{x}}}^2"/></p>
</div></div>
<p>Lorsque <img class="math" src="../_images/math/a1e7b66a55fc77cebd91d9a1ebfa93a29c1736fb.svg" alt="\alpha"/> est nul, ce facteur est égal à l’inertie :
<img class="math" src="../_images/math/4610cbefa0b0e891dffd33740d3ed6da052b0960.svg" alt="I = J\pa{0}"/> et ce terme est minimal lorsqu’il y a autant de
classes que d’éléments dans <img class="math" src="../_images/math/b66c7d6c52c7b12bee7fb24d76c38fc70cfc0a2f.svg" alt="X"/>. Lorsque <img class="math" src="../_images/math/a1e7b66a55fc77cebd91d9a1ebfa93a29c1736fb.svg" alt="\alpha"/>
tend vers l’infini, <img class="math" src="../_images/math/addb662507d13d8b52795a48d310f8ac82d303aa.svg" alt="J\pa{\alpha} \rightarrow J\pa{\infty}"/> où :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/d2ac8602353aef93ea590fe08b5d7744eedd8850.svg" alt="J\pa{\infty} = \sum_{x \in X} \; \norme{ x - y_{C\pa{x} }}^2 + \sum_{x \in X} \; \sum_{y \in Y} \;
\lambda\pa{y} \, \norme{ y -  y_{C\pa{x}}} ^2"/></p>
</div></div>
<p>Ici encore, il est possible de montrer que ce terme
<img class="math" src="../_images/math/7ac7481f42895412479c377e02d6ca83a3bb6eef.svg" alt="J\pa{\infty}"/> est minimal lorsqu’il n’existe plus qu’une
seule classe. Le principe de cette méthode consiste à faire varier
le paramètre <img class="math" src="../_images/math/a1e7b66a55fc77cebd91d9a1ebfa93a29c1736fb.svg" alt="\alpha"/>, plus le paramètre <img class="math" src="../_images/math/a1e7b66a55fc77cebd91d9a1ebfa93a29c1736fb.svg" alt="\alpha"/> augmente,
plus le nombre de classes devra être réduit. Néanmoins, il existe
des intervalles pour lequel ce nombre de classes est stable,
le véritable nombre de classes de l’ensemble <img class="math" src="../_images/math/b66c7d6c52c7b12bee7fb24d76c38fc70cfc0a2f.svg" alt="X"/>
sera considéré comme celui correspondant au plus grand intervalle
stable.</p>
<div class="table-wrapper colwidths-given docutils container">
<table class="docutils align-default">
<colgroup>
<col style="width: 50.0%" />
<col style="width: 50.0%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><img alt="../_images/koth1.png" src="../_images/koth1.png" />
</td>
<td><img alt="../_images/koth2.png" src="../_images/koth2.png" />
</td>
</tr>
<tr class="row-even"><td><p><em>(a)</em></p></td>
<td><p><em>(b)</em></p></td>
</tr>
</tbody>
</table>
</div>
<p>Evolutation du nombre de classes en fonction du paramètre <img class="math" src="../_images/math/a1e7b66a55fc77cebd91d9a1ebfa93a29c1736fb.svg" alt="\alpha"/> lors de la
minimisation du critère <img class="math" src="../_images/math/f3e6140f911171400bdaceb5d083d9209c5edcd3.svg" alt="J\pa{\alpha}"/>, figure extraite de <a class="reference internal" href="#kothari1999" id="id13"><span>[Kothari1999]</span></a>.
La première image représente le nuage de points illustrant quatre classes sans recouvrement.
La seconde image montre que quatre classes est l’état le plus longtemps stable
lorsque <img class="math" src="../_images/math/a1e7b66a55fc77cebd91d9a1ebfa93a29c1736fb.svg" alt="\alpha"/> croît.</p>
<p id="index-7">Le coût <img class="math" src="../_images/math/f3e6140f911171400bdaceb5d083d9209c5edcd3.svg" alt="J\pa{\alpha}"/> est une somme de coût dont
l’importance de l’un par rapport à l’autre est contrôle
par les paramètres <img class="math" src="../_images/math/80afa851b8fd175808926b7332be30d5049ac387.svg" alt="\lambda\pa{y}"/>. Le problème de
minimisation de <img class="math" src="../_images/math/f3e6140f911171400bdaceb5d083d9209c5edcd3.svg" alt="J\pa{\alpha}"/> est résolu par l’algorithme qui suit.
Il s’appuie sur la méthode des multiplicateurs de Lagrange.</p>
<div class="admonition-mathdef admonition" id="indexmathe-Algorithme3">
<div class="docutils container">
</div>
<p class="admonition-title" id="classification-kothari-1999">Algorithme A4 : sélection du nombre de classes</p>
<p>(voir  <a class="reference internal" href="#kothari1999" id="id14"><span>[Kothari1999]</span></a>)
Les notations sont celles utilisés dans les paragraphes précédents. On suppose que le
paramètre <img class="math" src="../_images/math/a1e7b66a55fc77cebd91d9a1ebfa93a29c1736fb.svg" alt="\alpha"/> évolue dans l’intervalle <img class="math" src="../_images/math/07a162d4ebb87d9aff1af094d5e7a401193212fb.svg" alt="\cro{\alpha_1, \alpha_2}"/>
à intervalle régulier <img class="math" src="../_images/math/b16448ae42ff1802844bc83136c27e139a1b4be6.svg" alt="\alpha_t"/>.
Le nombre initial de classes est noté <img class="math" src="../_images/math/2c1a946cef5763c39269198f722873a239852f50.svg" alt="K"/> et il est supposé surestimer le véritable
nombre de classes. Soit <img class="math" src="../_images/math/0af93cb0b8d164e9534df19c3e33895aca887fe8.svg" alt="\eta \in \left]0,1\right["/>,
ce paramètre doit être choisi de telle sorte que dans
l’algorithme qui suit, l’évolution des centres <img class="math" src="../_images/math/785ba36534ec0d91ce856196476629c1d1f2715d.svg" alt="y_k"/>
soit autant assurée par le premier de la fonction de coût que par le second.</p>
<p><em>initialisation</em></p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/f73d5167f2b49ca17745dfed32ea3daa88001439.svg" alt="\alpha \longleftarrow \alpha_1"/></p>
</div></div>
<p>On tire aléatoirement les centres des <img class="math" src="../_images/math/2c1a946cef5763c39269198f722873a239852f50.svg" alt="K"/> classes <img class="math" src="../_images/math/7a56d6c75a92645253c6ef84dd286840abdbf0fd.svg" alt="\vecteur{y_1}{y_K}"/>.</p>
<p><em>préparation</em></p>
<p>On définit les deux suites entières <img class="math" src="../_images/math/bf703c0d5c7e771b938eb3394d199ff195365c09.svg" alt="\vecteur{c^1_1}{c^1_K}"/>, <img class="math" src="../_images/math/b0512fd7cd213cc45a3ff646ddf9b126de778c6e.svg" alt="\vecteur{c^2_1}{c^2_K}"/>,
et les deux suites de vecteur <img class="math" src="../_images/math/ab6bdf44db868b8f626a24676119e1fad6c8d884.svg" alt="\vecteur{z^1_1}{z^1_K}"/>,
<img class="math" src="../_images/math/433c8f9af7a82dd5c6bf2e59101ef85ff36c60c9.svg" alt="\vecteur{z^2_1}{z^2_K}"/>.</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/7162f87c88eebed2bf2ae5ed53d0248e9ac17a32.svg" alt="\begin{array}{rlll}
\forall k, &amp;  c^1_k &amp;=&amp; 0 \\
\forall k, &amp;  c^2_k &amp;=&amp; 0 \\
\forall k, &amp;  z^1_k &amp;=&amp; 0 \\
\forall k, &amp;  z^2_k &amp;=&amp; 0
\end{array}"/></p>
</div></div>
<p><em>calcul des mises à jour</em></p>
<div class="line-block">
<div class="line">for i in <img class="math" src="../_images/math/e4d60e95747872a941338b80fe2b8a00b4b8429e.svg" alt="1..N"/></div>
<div class="line-block">
<div class="line">Mise à jour d’après le premier terme de la fonction de coût <img class="math" src="../_images/math/f3e6140f911171400bdaceb5d083d9209c5edcd3.svg" alt="J\pa{\alpha}"/>.</div>
<div class="line"><img class="math" src="../_images/math/3b1c4c170f7b983fa7961fa744400ca2572a8896.svg" alt="w \longleftarrow \underset{1 \leqslant l \leqslant K}{\arg \min} \; \norme{x_i - y_l}^2"/></div>
<div class="line"><img class="math" src="../_images/math/c62cc04a2a9e8462d3730bebf0d7a71c5fcffc4d.svg" alt="z^1_w \longleftarrow z^1_w + \eta \pa{ x_i - y_w}"/></div>
<div class="line"><img class="math" src="../_images/math/e0a900b1f252eca04a439fc8ba280471b0fe287f.svg" alt="c^1_w \longleftarrow c^1_w + 1"/></div>
<div class="line"><br /></div>
<div class="line">Mise à jour d’après le second terme de la fonction de coût <img class="math" src="../_images/math/f3e6140f911171400bdaceb5d083d9209c5edcd3.svg" alt="J\pa{\alpha}"/></div>
<div class="line"><br /></div>
<div class="line">for v in <img class="math" src="../_images/math/addc0166f989e29d1c798c0c5f3e67c87458d71e.svg" alt="1..k"/></div>
<div class="line-block">
<div class="line">if <img class="math" src="../_images/math/2ede1329c159e73f44a8ae9d888d916f15715dd1.svg" alt="\norme{y_v - y_w} &lt; \alpha"/></div>
<div class="line-block">
<div class="line"><img class="math" src="../_images/math/067f9f7794c24f4895d70674b56365d2f24bc3bf.svg" alt="z^2_v \longleftarrow z^2_v - \pa{ y_v - y_w}"/></div>
<div class="line"><img class="math" src="../_images/math/1dcc26f65780391461c4266fb214fc5bd5be7558.svg" alt="c^2_v \longleftarrow c^2_v + 1"/></div>
<div class="line"><br /></div>
</div>
</div>
<div class="line">for v in <img class="math" src="../_images/math/addc0166f989e29d1c798c0c5f3e67c87458d71e.svg" alt="1..k"/></div>
<div class="line-block">
<div class="line"><img class="math" src="../_images/math/7ec218064d0ff287b9e40bbecdc922096e4bdb2b.svg" alt="\lambda_v \longleftarrow \frac{ c^2_v \norme{z^1_v} } { c^1_v \norme{z^2_v} }"/></div>
<div class="line"><img class="math" src="../_images/math/b5a6888df5ed8b61a742f85268ce721f7e49e923.svg" alt="y_v \longleftarrow y_v + z^1_v + \lambda_v z^2_v"/></div>
</div>
</div>
</div>
<p><em>convergence</em></p>
<p>Tant que l’étape précédente n’a pas convergé vers une version stable des centres,
<img class="math" src="../_images/math/785ba36534ec0d91ce856196476629c1d1f2715d.svg" alt="y_k"/>, retour à l’étape précédente. Sinon, tous les couples de classes <img class="math" src="../_images/math/2fb092f228ae912a8b75d8fc2ad7929b84aa9483.svg" alt="\pa{i,j}"/>
vérifiant <img class="math" src="../_images/math/b98226fd74e5a8f077f4051c2c6afca781680b6d.svg" alt="\norme{y_i - y_j} &gt; \alpha"/> sont fusionnés :
<img class="math" src="../_images/math/49fd77d5a18fbf5909d5b71ab19a89b7fe6cceaa.svg" alt="\alpha \longleftarrow \alpha + \alpha_t"/>.
Si <img class="math" src="../_images/math/abf21c5bb300ba86be0818847d7349bc853a2085.svg" alt="\alpha \leqslant \alpha2"/>, retour à l’étape de préparation.</p>
<p><em>terminaison</em></p>
<p>Le nombre de classes est celui ayant prévalu pour le plus grand nombre de valeur de <img class="math" src="../_images/math/a1e7b66a55fc77cebd91d9a1ebfa93a29c1736fb.svg" alt="\alpha"/>.</p>
</div>
</section>
</section>
<section id="extension-des-nuees-dynamiques">
<h2>Extension des nuées dynamiques<a class="headerlink" href="#extension-des-nuees-dynamiques" title="Lien vers cette rubrique">¶</a></h2>
<section id="classes-elliptiques">
<span id="classification-nuees-dynamique-extension"></span><h3>Classes elliptiques<a class="headerlink" href="#classes-elliptiques" title="Lien vers cette rubrique">¶</a></h3>
<p id="index-8">La version de l’algorithme des nuées dynamique proposée dans l’article
<a class="reference internal" href="#cheung2003" id="id15"><span>[Cheung2003]</span></a> suppose que les classes ne sont plus de forme circulaire
mais suivent une loi normale quelconque. La loi de l’échantillon
constituant le nuage de points est de la forme :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/37adf413e36e8b14c77a742988f64916af67c86c.svg" alt="f\pa{x} =  \sum_{i=1}^{N} \; p_i \; \dfrac{1}{\pa{2 \pi}^{\frac{d}{2}}\sqrt{\det \Sigma_i}} \; exp \pa{-\frac{1}{2}  \pa{x-\mu_i}' \Sigma_i^{-1} \pa{x-\mu_i} }"/></p>
</div></div>
<p>Avec <img class="math" src="../_images/math/f3e0f7f4cefff66c9c97898243d62b1862457ed8.svg" alt="sum_{i=1}^{N} \; p_i = 1"/>. On définit :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/46b7df49a10e3ed7d44f05ed384524a85f13806f.svg" alt="G\pa{x, \mu, \Sigma} = \dfrac{1}{\pa{2 \pi}^{\frac{d}{2}}\sqrt{\det \Sigma}} \; exp \pa{-\frac{1}{2}  \pa{x-\mu}' \Sigma^{-1} \pa{x-\mu} }"/></p>
</div></div>
<p>L’algorithme qui suit a pour objectif de minimiser la quantité pour un échantillon <img class="math" src="../_images/math/7ccf5fe9b0a4a7c90908c020c8f6660232583105.svg" alt="\vecteur{X_1}{X_K}"/> :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/e2326fe991e74a547e28a1e9ede8696d83c28748.svg" alt="I = \sum_{i=1}^{N}\sum_{k=1}^{K} \indicatrice{ i = \underset{1 \leqslant j \leqslant N}{\arg \max}
G\pa{X_k, \mu_j,\Sigma_j} } \; \ln \cro{ p_i G\pa{ X_k, \mu_i, \Sigma_i } }"/></p>
</div></div>
<div class="admonition-mathdef admonition" id="indexmathe-Algorithme4">
<p class="admonition-title">Algorithme A5 : nuées dynamiques généralisées</p>
<p>Les notations sont celles utilisées dans ce paragraphe. Soient <img class="math" src="../_images/math/b3b84fabe7c42a7e9b77253ea0d56f2812634ba8.svg" alt="\eta"/>,
<img class="math" src="../_images/math/17d10a5a2c9e2139752a8ebb8c733ccc29293c20.svg" alt="\eta_s"/> deux réels tels que <img class="math" src="../_images/math/b864139223cc8bcb51ff3c36ddcaadc00d1949af.svg" alt="\eta &gt; \eta_s"/>.
La règle préconisée par l’article <a class="reference internal" href="#cheung2003" id="id16"><span>[Cheung2003]</span></a> est <img class="math" src="../_images/math/277952fbe124fd0ff6a3174af75c663c6d97301b.svg" alt="\eta_s \sim \frac{\eta}{10}"/>.</p>
<p><em>initialisation</em></p>
<p><img class="math" src="../_images/math/b00a80936656de39ddcaf3e556b63da3145c2258.svg" alt="t \longleftarrow 0"/>.
Les paramètres <img class="math" src="../_images/math/6f74fcc5b52fb38700a749f3b8c7d14a9ff1e0e8.svg" alt="\acc{p_i^0, \mu_i^0, \Sigma_i^0 \sac 1 \leqslant i \leqslant N}"/> sont initialisés
grâce à un algorithme des <a class="reference internal" href="#kmeans-def-algo"><span class="std std-ref">k-means</span></a> ou <a class="reference internal" href="#label-kmeans-fscl"><span class="std std-ref">FSCL</span></a>.
<img class="math" src="../_images/math/5efb9b8bac01ce9912371bc225e335d9061c92bd.svg" alt="\forall i, \; p_i^0 = \frac{1}{N}"/> et <img class="math" src="../_images/math/c57eeb0a88c2d9caceb75b59901b834fae2d15c5.svg" alt="\beta_i^0 = 0"/>.</p>
<p><em>récurrence</em></p>
<p>Soit <img class="math" src="../_images/math/a64fc33c15255329b8e9309a9a44e1e0f012f72f.svg" alt="X_k"/> choisi aléatoirement dans <img class="math" src="../_images/math/7ccf5fe9b0a4a7c90908c020c8f6660232583105.svg" alt="\vecteur{X_1}{X_K}"/>.</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/359a2863f521bcd2920d7821b53f4794b53af19e.svg" alt="i = \underset{1 \leqslant i \leqslant N}{\arg \min} \; G\pa{X_k, \mu_i^t, \Sigma_i^t}"/></p>
</div></div>
<div class="line-block">
<div class="line">for i in <img class="math" src="../_images/math/e4d60e95747872a941338b80fe2b8a00b4b8429e.svg" alt="1..N"/></div>
<div class="line-block">
<div class="line"><img class="math" src="../_images/math/adb57abc9603e0235b766603a17c83819d695994.svg" alt="\mu_i^{t+1} = \mu_i^t + \eta \, \pa{\Sigma_i^t}^{-1} \, \pa{ X_k - \mu_i^t}"/></div>
<div class="line"><img class="math" src="../_images/math/8f35e78c82f2656e410a45a49e6d57c2dd541fc7.svg" alt="\beta_i^{t+1} = \beta_i^t + \eta \, \pa{1 - \alpha_i^t}"/></div>
<div class="line"><img class="math" src="../_images/math/fa5968afec024ee9b3edd0a37ca365633ea6ee75.svg" alt="\Sigma^{t+1}_i = \pa{1 - \eta_s} \, \Sigma_i^t + \eta_s \, \pa{ X_k - \mu_i^t} \pa{ X_k - \mu_i^t}'"/></div>
<div class="line"><br /></div>
</div>
<div class="line">for i in <img class="math" src="../_images/math/e4d60e95747872a941338b80fe2b8a00b4b8429e.svg" alt="1..N"/></div>
<div class="line-block">
<div class="line"><img class="math" src="../_images/math/d7f1de0bc9afbff6a3bcf3d3bb37151cd1affc46.svg" alt="p^{t+1}_i = \frac{ e^{ \beta_i^{t+1} } } { \sum_{j=1}^{N} e^{ \beta_j^{t+1} } }"/></div>
<div class="line"><br /></div>
</div>
<div class="line"><img class="math" src="../_images/math/c38192a0bf7fc25d58110b59ec881f89dae27bb7.svg" alt="t \longleftarrow t + 1"/></div>
</div>
<p><em>terminaison</em></p>
<p>Tant que <img class="math" src="../_images/math/92b1a4195bd55fb0d3d3aee34e54522e81b9374d.svg" alt="\underset{1 \leqslant i \leqslant N}{\arg \min} \; G\pa{X_k, \mu_i^t, \Sigma_i^t}"/>
change pour au moins un des points <img class="math" src="../_images/math/a64fc33c15255329b8e9309a9a44e1e0f012f72f.svg" alt="X_k"/>.</p>
</div>
<p>Lors de la mise à jour de <img class="math" src="../_images/math/101365d041befcd5108977fd092dbd8bc9785dbc.svg" alt="\Sigma^{-1}"/>,
l’algorithme précédent propose la mise à jour de <img class="math" src="../_images/math/7db6957ff4e3716bec2334044990cfc332851bb9.svg" alt="\Sigma_i"/>
alors que le calcul de <img class="math" src="../_images/math/74fe222dfce78c1d224c9499b08b7c11c849db18.svg" alt="G\pa{., \mu_i, \Sigma_i}"/>
implique <img class="math" src="../_images/math/83b454fbaf2d869cc101169851dfa6d12333aad5.svg" alt="\Sigma_i^{-1}"/>,
par conséquent, il est préférable de mettre à jour directement la matrice
<img class="math" src="../_images/math/101365d041befcd5108977fd092dbd8bc9785dbc.svg" alt="\Sigma^{-1}"/> :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/e7c86991000483459e58075e1e136f6ed27ba59f.svg" alt="\pa{\Sigma^{t+1}_i}^{-1} = \frac{ \pa{\Sigma_i^t}^{-1} } {1 - \eta_s}
\cro{I - \frac{ \eta_s  \pa{ X_k - \mu_i^t} \pa{ X_k - \mu_i^t}' \pa{\Sigma_i^t}^{-1} }
{1 - \eta_s + \eta_s \pa{ X_k - \mu_i^t}' \, \pa{\Sigma_i^t}^{-1}\pa{ X_k - \mu_i^t} } }"/></p>
</div></div>
</section>
<section id="rival-penalized-competitive-learning-rpcl">
<span id="class-rpcl"></span><h3>Rival Penalized Competitive Learning (RPCL)<a class="headerlink" href="#rival-penalized-competitive-learning-rpcl" title="Lien vers cette rubrique">¶</a></h3>
<p id="index-9">L’algorithme suivant développé dans <a class="reference internal" href="#xu1993" id="id17"><span>[Xu1993]</span></a>, est une variante de celui des centres mobiles.
Il entreprend à la fois la classification et la sélection du nombre optimal de classes à condition
qu’il soit inférieur à une valeur maximale à déterminer au départ de l’algorithme.
Un mécanisme permet d’éloigner les centres des classes peu pertinentes
de sorte qu’aucun point ne leur sera affecté.</p>
<div class="admonition-mathdef admonition" id="indexmathe-Algorithme5">
<div class="docutils container">
</div>
<p class="admonition-title" id="classif-algo-rpcl">Algorithme A6 : RPCL</p>
<p>Soient <img class="math" src="../_images/math/26f924af3662c85fdae93b78379cf709640d2119.svg" alt="\vecteur{X_1}{X_N}"/>, <img class="math" src="../_images/math/bceb9186b5004313ecccd0d22d07ea9617b62f98.svg" alt="N"/> vecteurs à classer en au
plus <img class="math" src="../_images/math/6cf1fdb1c46f5cefb926a2b20ec9dd4a481dd11d.svg" alt="T"/> classes de centres <img class="math" src="../_images/math/fb3d517c4eeb65cce6c34dfc9b7dc7089292995d.svg" alt="\vecteur{C_1}{C_T}"/>.
Soient deux réels <img class="math" src="../_images/math/03b31e7dea339fc978bc9c23c1cae7daa6bd2615.svg" alt="\alpha_r"/> et <img class="math" src="../_images/math/5f6da0c05eb3c25ba2397c23d2086b3f9dc39501.svg" alt="\alpha_c"/>
tels que <img class="math" src="../_images/math/fd93c6698c67f35e2a22cb1c7a6803db2576461a.svg" alt="0 &lt; \alpha_r \ll \alpha_c &lt; 1"/>.</p>
<p><em>initialisation</em></p>
<p>Tirer aléatoirement les centres <img class="math" src="../_images/math/fb3d517c4eeb65cce6c34dfc9b7dc7089292995d.svg" alt="\vecteur{C_1}{C_T}"/>.</p>
<div class="line-block">
<div class="line">for j in <img class="math" src="../_images/math/f963c7631cb87c320d1687686f34c5e48b508b2d.svg" alt="1..C"/></div>
<div class="line-block">
<div class="line"><img class="math" src="../_images/math/625febfb4c1fa41b81a2a7ca2f2786fd0752f4ee.svg" alt="n_j^0 \longleftarrow 1"/></div>
</div>
</div>
<p><em>calcul de poids</em></p>
<p>Choisir aléatoirement un point <img class="math" src="../_images/math/c15b262677ad7177c2e37298a2eb382d712b3a52.svg" alt="X_i"/>.</p>
<div class="line-block">
<div class="line">for j in <img class="math" src="../_images/math/f963c7631cb87c320d1687686f34c5e48b508b2d.svg" alt="1..C"/></div>
<div class="line-block">
<div class="line"><img class="math" src="../_images/math/819208f885e89ffcd0fd93ab5fd1ef848907e5c7.svg" alt="\gamma_j = \dfrac{n_j}{ \sum_{k=1}^{C} n_k}"/></div>
<div class="line"><br /></div>
</div>
<div class="line">for j in <img class="math" src="../_images/math/f963c7631cb87c320d1687686f34c5e48b508b2d.svg" alt="1..C"/></div>
<div class="line-block">
<div class="line"><img class="math" src="../_images/math/1b39f5dac1c02fc3e0eae94c98dfb253f39bf2d7.svg" alt="u_j ="/></div>
<div class="line-block">
<div class="line">1 si <img class="math" src="../_images/math/fbf3eb686a733e9b53bcd0d32bc83cef97f55e13.svg" alt="j \in \underset{k}{\arg \min} \; \cro {\gamma_k \; d\pa{X_i,C_k} }"/></div>
<div class="line">-1 si <img class="math" src="../_images/math/d01fb1b2ebcf432016cb3bd7de5fb0fe0a7a6107.svg" alt="j \in \underset{j \neq k}{\arg \min} \; \cro {\gamma_k \; d\pa{X_i,C_k} }"/></div>
<div class="line">0 sinon</div>
</div>
</div>
</div>
<p><em>mise à jour</em></p>
<div class="line-block">
<div class="line">for j in <img class="math" src="../_images/math/f963c7631cb87c320d1687686f34c5e48b508b2d.svg" alt="1..C"/></div>
<div class="line-block">
<div class="line"><img class="math" src="../_images/math/09dd9c63a737d007f778fad69a9eefc45afbf503.svg" alt="C_j^{t+1} \longleftarrow  C_j^t +  \left \{ \begin{array}{ll} \alpha_c \pa{X_i - C_j} &amp; \text{si } u_j = 1 \\ - \alpha_r \pa{X_i - C_j} &amp; \text{si } u_j = -1 \\ 0 &amp; \text{sinon} \end{array} \right."/></div>
<div class="line"><img class="math" src="../_images/math/71536267e1787bbc8916f6f2124324fce9b3b850.svg" alt="n_j^t +  \left \{ \begin{array}{ll} 1 &amp; \text{si } u_j = 1 \\ 0 &amp; \text{sinon} \end{array} \right."/></div>
<div class="line"><br /></div>
</div>
<div class="line"><img class="math" src="../_images/math/02dd178e61d85f10a2824b1cd98c269269370b59.svg" alt="t \longleftarrow t+1"/></div>
</div>
<p><em>terminaison</em></p>
<p>S’il existe un indice <img class="math" src="../_images/math/c2ca7da683b1e0aa549bb4675efbd6008c4ffa6e.svg" alt="j"/> pour lequel <img class="math" src="../_images/math/c4d5551f26826df6ec17ca781fc2a10021174733.svg" alt="C^{t+1}_j \neq C^t_j"/>
alors retourner à  l’étape de calcul de poids ou que les centres des classes jugées inutiles
ont été repoussés vers l’infini.</p>
</div>
<p>Pour chaque point, le centre de la classe la plus proche en est rapproché
tandis que le centre de la seconde classe la plus proche en est éloigné
mais d’une façon moins importante (condition <img class="math" src="../_images/math/eeaffc9e6b3b9543f3086f2664cb223ac3fba57a.svg" alt="\alpha_r \ll \alpha_c"/>).
Après convergence, les centres des classes inutiles ou non pertinentes
seront repoussés vers l’infini. Par conséquent, aucun point n’y sera rattaché.</p>
<p>L’algorithme doit être lancé plusieurs fois. L’algorithme RPCL peut terminer
sur un résultat comme celui de la figure suivante où un centre reste coincé
entre plusieurs autres. Ce problème est moins important
lorsque la dimension de l’espace est plus grande.</p>
<img alt="../_images/class6.png" src="../_images/class6.png" />
<p>Application de l’algorithme <a class="reference internal" href="#classif-algo-rpcl"><span class="std std-ref">RPCL</span></a> : la classe 0 est incrusté entre les quatre autres
et son centre ne peut se « faufiler » vers l’infini.</p>
</section>
<section id="rpcl-based-local-pca">
<span id="classification-rpcl-local-pca"></span><h3>RPCL-based local PCA<a class="headerlink" href="#rpcl-based-local-pca" title="Lien vers cette rubrique">¶</a></h3>
<p id="index-10">L’article <a class="reference internal" href="#liu2003" id="id18"><span>[Liu2003]</span></a> propose une extension de l’algorithme <a class="reference internal" href="#classif-algo-rpcl"><span class="std std-ref">RPCL</span></a>
et suppose que les classes ne sont plus de forme circulaire mais
suivent une loi normale quelconque. Cette méthode est utilisée pour
la détection de ligne considérées ici comme des lois normales dégénérées
en deux dimensions, la matrice de covariance définit une ellipse dont le
grand axe est très supérieur au petit axe, ce que montre la figure suivante.
Cette méthode est aussi présentée comme un possible algorithme de squelettisation.</p>
<img alt="../_images/liu3.png" src="../_images/liu3.png" />
<p>Figure extraite de <a class="reference internal" href="#liu2003" id="id19"><span>[Liu2003]</span></a>, l’algorithme est utilisé pour la détection de lignes
considérées ici comme des lois normales dont la matrice de covariance définit une ellipse
dégénérée dont le petit axe est très inférieur au grand axe. Les traits fin grisés correspondent aux
classes isolées par l’algorithme RPCL-based local PCA.</p>
<p>On modélise le nuage de points par une mélange de lois normales :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/09d3deb3f6ba3f5d925b5e79e6ff9e9b53c81ff6.svg" alt="f\pa{x} =  \sum_{i=1}^{N} \; p_i \; \dfrac{1}{\pa{2 \pi}^{\frac{d}{2}}\sqrt{\det \Sigma_i}} \;
exp \pa{-\frac{1}{2}  \pa{x-\mu_i}' \Sigma_i^{-1} \pa{x-\mu_i} }"/></p>
</div></div>
<p>Avec <img class="math" src="../_images/math/4818fb2d6e00bee968d65982434c0e7c0bfbe18d.svg" alt="\sum_{i=1}^{N} \; p_i = 1"/>.</p>
<p>On suppose que le nombre de classes initiales <img class="math" src="../_images/math/bceb9186b5004313ecccd0d22d07ea9617b62f98.svg" alt="N"/> surestime le
véritable nombre de classes. L’article <a class="reference internal" href="#liu2003" id="id20"><span>[Liu2003]</span></a> s’intéresse
au cas particulier où les matrices de covariances vérifient
<img class="math" src="../_images/math/09871a20d40f17cc98971443d3a19c487934fddc.svg" alt="\Sigma_i = \zeta_i \, I + \sigma_i \, \phi_i \phi_i'"/>
avec <img class="math" src="../_images/math/198b07e64fd2fa4750aa3695b2ea2b3fb5dae3a1.svg" alt="\zeta_i &gt; 0, \; \sigma_i &gt; 0, \; \phi_i' \phi_i = 1"/>.</p>
<p>On définit également :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/6eb7b1bb68207926c1af7e42158c8d6a1ebc03f6.svg" alt="G\pa{x, \mu, \Sigma} = \dfrac{1}{\pa{2 \pi}^{\frac{d}{2}}\sqrt{\det \Sigma}} \;
exp \pa{-\frac{1}{2}  \pa{x-\mu}' \Sigma^{-1} \pa{x-\mu} }"/></p>
</div></div>
<p>L’algorithme utilisé est similaire à l’algortihme <a class="reference internal" href="#classif-algo-rpcl"><span class="std std-ref">RPCL</span></a>.
La distance <img class="math" src="../_images/math/2160a217243173398700954f681412f83f781a6e.svg" alt="d"/> utilisée lors de l’étape de calcul des poids
afin de trouver la classe la plus probable pour un point
donné <img class="math" src="../_images/math/a64fc33c15255329b8e9309a9a44e1e0f012f72f.svg" alt="X_k"/> est remplacée par l’expression :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/c0d6806ed4c76aea403828810c79d39ef322687a.svg" alt="d\pa{X_k, classe \, i} = - \ln { p_i^t \, G\pa{X_k, \, \mu_i^t, \, \Sigma^t_i } }"/></p>
</div></div>
<p>L’étape de mise à jour des coefficients est remplacée par :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/f952370525f7703ca7254c74428d36b69e5dd027.svg" alt="x^{t+1} \longleftarrow  x^t +  \left \{ \begin{array}{ll}
\alpha_c \nabla x^t &amp; \text{si } u_j = 1 \\
- \alpha_r \nabla x^t &amp; \text{si } u_j = -1 \\
0 &amp; \text{sinon}
\end{array} \right."/></p>
</div></div>
<p>Où <img class="math" src="../_images/math/4171408fcfbe97daea34f08aef4aac37520717b1.svg" alt="x^t"/> joue le rôle d’un paramètre et est remplacé
successivement par <img class="math" src="../_images/math/77d7f28937206f8e34b8b96b0d0d264c9facca66.svg" alt="p_i^t"/>, <img class="math" src="../_images/math/6ed63b7beea15877e6ba7cec114276350657dae1.svg" alt="\mu_i^t"/>, <img class="math" src="../_images/math/e9a905eb88b274112b4100f00439e1cc973868d8.svg" alt="\zeta_i^t"/>, <img class="math" src="../_images/math/4863314ea214002f4ff7fd2f783a5e672ebe6239.svg" alt="\sigma^t_i"/>, <img class="math" src="../_images/math/99f29dadea043e5b60520a183519551ba589eb98.svg" alt="\phi^t_i"/> :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/bb1785385e15b2920550c06d3826dba61d478d70.svg" alt="\begin{array}{lll}
\nabla p_i^t &amp;=&amp; - \frac{1}{p_i^t} \\
\nabla \mu_i^t &amp;=&amp; - \pa{ X_k - \mu_i^t} \\
\nabla \zeta_i^t  &amp;=&amp; \frac{1}{2} \; tr\cro{ \pa{\Sigma_i^t}^{-1} \,
\pa{ I - \pa{ X_k - \mu_i^t} \pa{ X_k - \mu_i^t}' \pa{\Sigma_i^t}^{-1} } } \\
\nabla \sigma_i^t &amp;=&amp;    \frac{1}{2} \; \pa{\phi_i^t}' \pa{\Sigma_i^t}^{-1}
\pa{ I - \pa{ X_k - \mu_i^t} \pa{ X_k - \mu_i^t}' \pa{\Sigma_i^t}^{-1} } \phi_i^t \\
\nabla \phi_i^t     &amp;=&amp;    \sigma_i^t \pa{\Sigma_i^t}^{-1}
\pa{ I - \pa{ X_k - \mu_i^t} \pa{ X_k - \mu_i^t}' \pa{\Sigma_i^t}^{-1} } \phi_i^t \\
\end{array}"/></p>
</div></div>
</section>
<section id="frequency-sensitive-competitive-learning-fscl">
<span id="label-kmeans-fscl"></span><h3>Frequency Sensitive Competitive Learning (FSCL)<a class="headerlink" href="#frequency-sensitive-competitive-learning-fscl" title="Lien vers cette rubrique">¶</a></h3>
<p id="index-11">L’algorithme Frequency Sensitive Competitive Learning est présenté dans
<a class="reference internal" href="#balakrishnan1996" id="id21"><span>[Balakrishnan1996]</span></a>. Par rapport à l’algorithme des centres mobiles classique,
lors de l’estimation des centres des classes, l’algorithme évite la formation de classes sous-représentées.</p>
<div class="admonition-mathdef admonition" id="indexmathe-Algorithme6">
<div class="docutils container">
</div>
<p class="admonition-title" id="classification-fscl">Algorithme A7 : FSCL</p>
<p>Soit un nuage de points <img class="math" src="../_images/math/26f924af3662c85fdae93b78379cf709640d2119.svg" alt="\vecteur{X_1}{X_N}"/>,
soit <img class="math" src="../_images/math/2c0e77bc741b692ecdf6e85966263a89422af4c8.svg" alt="C"/> vecteurs <img class="math" src="../_images/math/006dd3f24de01449dca0eca6514bdde697fc8cb3.svg" alt="\vecteur{\omega_1}{\omega_C}"/>
initialisés de manière aléatoires.
Soit <img class="math" src="../_images/math/3302dd9d46486c64dd86a47b65df645d5258bcce.svg" alt="F : \pa{u,t} \in \mathbb{R}^2 \longrightarrow \mathbb{R}^+"/>
croissante par rapport à <img class="math" src="../_images/math/3ded7c5accc3db646e5a061facda1aef616d548f.svg" alt="u"/>.
Soit une suite de réels <img class="math" src="../_images/math/aff557df7578eefb5dca5b59e3147960acf07f7c.svg" alt="\vecteur{u_1}{u_C}"/>,
soit une suite <img class="math" src="../_images/math/712de58615936cdf87cfd5b1c5f017bccc7ea9f8.svg" alt="\epsilon\pa{t} \in \cro{0,1}"/> décroissante où <img class="math" src="../_images/math/09c7628f51842c683db31bd6826cff8cc447ece3.svg" alt="t"/>
représente le nombre d’itérations.
Au début <img class="math" src="../_images/math/06589e14407f2f6b63d16767dd96125304b98dd7.svg" alt="t \leftarrow 0"/>.</p>
<p><em>meilleur candidat</em></p>
<p>Pour un vecteur <img class="math" src="../_images/math/a64fc33c15255329b8e9309a9a44e1e0f012f72f.svg" alt="X_k"/> choisi aléatoirement dans
l’ensemble <img class="math" src="../_images/math/26f924af3662c85fdae93b78379cf709640d2119.svg" alt="\vecteur{X_1}{X_N}"/>, on détermine :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/be7749778fe4c36c60c7283bc5a0089c4938a94c.svg" alt="i^* \in \arg \min \acc{ D_i = F\pa{u_i,t} \, d\pa{X_k, \omega_i} }"/></p>
</div></div>
<p><em>mise à jour</em></p>
<div class="line-block">
<div class="line"><img class="math" src="../_images/math/71df14eb8e9a48aa4aaa710d7ca820442aa71819.svg" alt="\omega_{i^*} \pa{t+1}  \longleftarrow \omega_{i^*} \pa{t} + \epsilon\pa{t} \pa { X_k - \omega_{i^*} \pa{t} }"/></div>
<div class="line"><img class="math" src="../_images/math/02dd178e61d85f10a2824b1cd98c269269370b59.svg" alt="t \longleftarrow t+1"/></div>
<div class="line"><img class="math" src="../_images/math/eb010d3f7364d6bab102b761d4b112de022f29e6.svg" alt="u_{i^*} \longleftarrow u_{i^*} + 1"/></div>
</div>
<p>Retour à l’étape précédente jusqu’à ce que les nombres
<img class="math" src="../_images/math/dda6a76e26fd07cf6c368a3365438c65050f34a5.svg" alt="\frac{u_i}{\sum_{i}u_i}"/> convergent.</p>
</div>
<p>Exemple de fonctions pour <img class="math" src="../_images/math/d3df781b97caf23fd84697ec8aac41efdf4f6793.svg" alt="F"/>, <img class="math" src="../_images/math/5d07e66e6e9d55b1dd504ca14a3d870dfe30fb29.svg" alt="\epsilon"/> (voir <a class="reference internal" href="#balakrishnan1996" id="id22"><span>[Balakrishnan1996]</span></a>) :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/c97dd7bb1f54357b2f271b937b03dfe3bd886d4e.svg" alt="\begin{eqnarray*}
F\pa{u,t} &amp;=&amp; u \, \beta e^{-t/T} \text{ avec } \beta = 0,06 \text{ et } 1/T = 0,00005 \\
\epsilon\pa{t} &amp;=&amp; \beta \, e^{ - \gamma t } \text{ avec } \gamma = 0,05
\end{eqnarray*}"/></p>
</div></div>
<p>Cet algorithme ressemble à celui des cartes topographiques de Kohonen
sans toutefois utiliser un maillage entre les neurones
(ici les vecteurs <img class="math" src="../_images/math/ce439c3bf6e8d427634dd59f969b64429819b464.svg" alt="\omega_i"/>). Contrairement à l’algorithme RPCL,
les neurones ne sont pas repoussés s’ils ne sont pas choisis mais la fonction
croissante <img class="math" src="../_images/math/d6ee29fc5b0000217692b3fe96efde422a6c371a.svg" alt="F\pa{u,t}"/> par rapport à <img class="math" src="../_images/math/3ded7c5accc3db646e5a061facda1aef616d548f.svg" alt="u"/> assure que plus un neurone
est sélectionné, moins il a de chance de l’être,
bien que cet avantage disparaisse au fur et à mesure des itérations.</p>
</section>
</section>
<section id="k-means-norme-l1">
<h2>k-means norme L1<a class="headerlink" href="#k-means-norme-l1" title="Lien vers cette rubrique">¶</a></h2>
<p>L’algorithme dans sa version la plus courante optimise l’inertie définie
par <img class="math" src="../_images/math/40bbc182fe555c7e5da694e0535ddc2b0adb23ee.svg" alt="\sum_{i=1}^P \; d^2\left(X_i, G_{c_i^t}^t\right)"/>, qui est
en quelque sorte une inertie <em>L2</em>. Que devriendrait l’algorithme
si la norme choisie était une norme <em>L1</em>, il faudrait alors choisir
à chaque itération <em>t</em> des <em>points</em> qui minimise la quantité :
<img class="math" src="../_images/math/ba04609461dc2d5ca073ac714d021b17b621180b.svg" alt="\sum_{i=1}^P \; d_1\left(X_i, G_{c_i^t}^t\right)"/> où
<img class="math" src="../_images/math/dba54403216e84bb9f17c788e3602a282932af16.svg" alt="d_1"/> est la norme <em>L1</em> entre deux points <em>X,Y</em> :
<img class="math" src="../_images/math/e2762704c8e87d7119880487281a3baf9559b381.svg" alt="d_1(X, Y) = \sum_i |X_i - Y_i|"/>. Avant de continuer,
on rappelle un théorème :</p>
<div class="admonition-mathdef admonition" id="indexmathe-propriété0">
<div class="docutils container">
</div>
<p class="admonition-title" id="mediane-l1">propriété P1 : Médiane et valeur absolue</p>
<p>Soit <img class="math" src="../_images/math/b403da094d28e0106b06efe11a8771d61757252e.svg" alt="A=(x_1, ..., x_n)"/> un ensembl de <em>n</em> réels quelconque.
On note <img class="math" src="../_images/math/414fe48e1d982fcdb0d024ae5192bfa6a5553663.svg" alt="m=med(x_1, ..., x_n)"/> la médiane
de l’ensemble de points <em>A</em>. Alors la médiane <em>m</em>
minimise la quantité <img class="math" src="../_images/math/ed2739077602d2045deb89d56b9de19f197c0e14.svg" alt="\sum_{i=1}^n |m-x_i|"/>.</p>
</div>
<p>C’est cette propriété qui est utilisée pour définir ce qu’est
la <a class="reference internal" href="../c_ml/regression_quantile.html#l-reg-quantile"><span class="std std-ref">régression quantile</span></a> et sa démonstration
est présentée à la page <a class="reference internal" href="../c_ml/regression_quantile.html#l-reg-quantile-demo"><span class="std std-ref">Médiane et valeur absolue</span></a>. Il ne reste
plus qu’à se servir de ce résultat pour mettre à jour l’algorithme
<a class="reference internal" href="#kmeans-def-algo"><span class="std std-ref">centre mobile, k-means</span></a>. L’étape qui
consiste à affecter un point à un cluster représenté par un point
ne pose pas de problème si on utilise cette nouvelle norme. Il ne reste
plus qu’à déterminer le point qui représente un cluster sachant
les points qui le constituent. Autrement dit, il faut déterminer
le point qui minimiser la pseudo-inertie définie comme suit
pour un ensemble de points <img class="math" src="../_images/math/bfe5330a47312509984b1f7abf71fd221d3d8dc1.svg" alt="(X_1, ..., X_n)"/> appartenant à un
espace vectoriel de dimension <em>k</em>.</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/33584f87f2dfdf574e2906c428e43546e5672afc.svg" alt="I(G,X_1,...,X_n) = \norm{G - X_i}_1 = \sum_{i=1}^n \sum_{k=1}^d \abs{G_k - X_{ik}}"/></p>
</div></div>
<p>On cherche le point <em>G</em> qui minimise la quantité <img class="math" src="../_images/math/c484af6489df0496107d8da599f9d84c3931aebf.svg" alt="I(G,X_1,...,X_n)"/>.
Comme <img class="math" src="../_images/math/60d3d7234cef59ab3e1d4c4caa7c88c629e43cab.svg" alt="\sum_{i=1}^n \sum_{k=1}^d \abs{G_k - X_{ik}} = \sum_{k=1}^d \sum_{i=1}^n  \abs{G_k - X_{ik}}"/>,
on en déduit qu’on peut chercher la coordonnée <img class="math" src="../_images/math/5b586d8ac2fcc343ef09f4c37723e90b948ae179.svg" alt="G_k"/> indépendemment
les unes des autres. On en déduit
que le barycentre de norme L1 d’un ensemble de points dans un
espace vectoriel de dimension <em>d</em> a pour coordonnées les <em>d</em>
médianes extraites sur chacune des dimensions.
L’algorithme est implémenté dans le module <a class="reference external" href="https://sdpython.github.io/doc/mlinsights/dev/index.html">mlinsights</a>
en s’inspirant du code <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html">KMeans</a>.</p>
</section>
<section id="bibliographie">
<h2>Bibliographie<a class="headerlink" href="#bibliographie" title="Lien vers cette rubrique">¶</a></h2>
<div role="list" class="citation-list">
<div class="citation" id="arthur2007" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Arthur2007<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id2">1</a>,<a role="doc-backlink" href="#id3">2</a>)</span>
<p>k-means++: the advantages of careful seeding (2007),
<em>Arthur, D.; Vassilvitskii, S.</em>,
Proceedings of the eighteenth annual ACM-SIAM symposium on Discrete algorithms.
Society for Industrial and Applied Mathematics Philadelphia, PA, USA. pp. 1027–1035.
<a class="reference external" href="http://ilpubs.stanford.edu:8090/778/1/2006-13.pdf">2006-13.pdf</a>.</p>
</div>
<div class="citation" id="balakrishnan1996" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Balakrishnan1996<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id21">1</a>,<a role="doc-backlink" href="#id22">2</a>)</span>
<p>Comparative performance of the FSCL neural net and K-means algorithm for market segmentation (1996),
P. V. Sundar Balakrishnan, Martha Cooper, Varghese S. Jacob, Phillip A. Lewis,
<em>European Journal of Operation Research</em>, volume 93, pages 346-357</p>
</div>
<div class="citation" id="bahmani2012" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id5">Bahmani2012</a><span class="fn-bracket">]</span></span>
<p>Scalable K-Means++ (2012),
<em>Bahman Bahmani, Benjamin Moseley, Andrea Vattani, Ravi Kumar, Sergei Vassilvitskii</em>,
Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 7, pp. 622-633 (2012)
<a class="reference external" href="http://theory.stanford.edu/~sergei/papers/vldb12-kmpar.pdf">vldb12-kmpar.pdf</a>,
<a class="reference external" href="https://arxiv.org/abs/1203.6402">arXiv.1203.6402</a></p>
</div>
<div class="citation" id="cheung2003" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Cheung2003<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id15">1</a>,<a role="doc-backlink" href="#id16">2</a>)</span>
<p><img class="math" src="../_images/math/fc90b3f44afc581dfadde98aeb786a78889e3a4c.svg" alt="k^*"/>-Means: A new generalized k-means clustering algorithm (2003),
Yiu-Ming Cheung,
<em>Pattern Recognition Letters</em>, volume 24, 2883-2893</p>
</div>
<div class="citation" id="davies1979" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id6">Davies1979</a><span class="fn-bracket">]</span></span>
<p>A cluster Separation Measure (1979),
D. L. Davies, D. W. Bouldin,
<em>IEEE Trans. Pattern Analysis and Machine Intelligence (PAMI)</em>, volume 1(2)</p>
</div>
<div class="citation" id="goodman1954" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id7">Goodman1954</a><span class="fn-bracket">]</span></span>
<p>Measures of associations for cross-validations (1954),
L. Goodman, W. Kruskal,
<em>J. Am. Stat. Assoc.</em>, volume 49, pages 732-764</p>
</div>
<div class="citation" id="herbin2001" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Herbin2001<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id8">1</a>,<a role="doc-backlink" href="#id10">2</a>)</span>
<p>Estimation of the number of clusters and influence zones (2001),
M. Herbin, N. Bonnet, P. Vautrot,
<em>Pattern Recognition Letters</em>, volume 22, pages 1557-1568</p>
</div>
<div class="citation" id="kothari1999" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Kothari1999<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id11">1</a>,<a role="doc-backlink" href="#id12">2</a>,<a role="doc-backlink" href="#id13">3</a>,<a role="doc-backlink" href="#id14">4</a>)</span>
<p>On finding the number of clusters (1999),
Ravi Kothari, Dax Pitts,
<em>Pattern Recognition Letters</em>, volume 20, pages 405-416</p>
</div>
<div class="citation" id="liu2003" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Liu2003<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id18">1</a>,<a role="doc-backlink" href="#id19">2</a>,<a role="doc-backlink" href="#id20">3</a>)</span>
<p>Strip line detection and thinning by RPCL-based local PCA (2003),
Zhi-Yong Liu, Kai-Chun Chiu, Lei Xu,
<em>Pattern Recognition Letters</em> volume 24, pages 2335-2344</p>
</div>
<div class="citation" id="silverman1986" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id9">Silverman1986</a><span class="fn-bracket">]</span></span>
<p>Density Estimation for Statistics and Data Analysis (1986),
B. W. Silverman,
<em>Monographs on Statistics and Applied Probability, Chapman and Hall, London</em>, volume 26</p>
</div>
<div class="citation" id="xu1993" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id17">Xu1993</a><span class="fn-bracket">]</span></span>
<p>Rival penalized competitive learning for clustering analysis, rbf net and curve detection (1993),
L. Xu, A. Krzyzak, E. Oja,
<em>IEEE Trans. Neural Networks</em>, volume (4), pages 636-649</p>
</div>
</div>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="gauss_mixture.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Mélange de lois normales</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="index.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Clustering</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2016-2025, Xavier Dupré
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">k-means</a><ul>
<li><a class="reference internal" href="#principe">Principe</a><ul>
<li><a class="reference internal" href="#homogeneite-des-dimensions">Homogénéité des dimensions</a></li>
</ul>
</li>
<li><a class="reference internal" href="#ameliorations-de-l-initialisation">Améliorations de l’initialisation</a><ul>
<li><a class="reference internal" href="#l-kmeanspp">K-means++</a></li>
<li><a class="reference internal" href="#id4">K-means||</a></li>
</ul>
</li>
<li><a class="reference internal" href="#estimation-de-probabilites">Estimation de probabilités</a></li>
<li><a class="reference internal" href="#selection-du-nombre-de-classes">Sélection du nombre de classes</a><ul>
<li><a class="reference internal" href="#critere-de-qualite">Critère de qualité</a></li>
<li><a class="reference internal" href="#maxima-de-la-fonction-densite">Maxima de la fonction densité</a></li>
<li><a class="reference internal" href="#decroissance-du-nombre-de-classes">Décroissance du nombre de classes</a></li>
</ul>
</li>
<li><a class="reference internal" href="#extension-des-nuees-dynamiques">Extension des nuées dynamiques</a><ul>
<li><a class="reference internal" href="#classes-elliptiques">Classes elliptiques</a></li>
<li><a class="reference internal" href="#rival-penalized-competitive-learning-rpcl">Rival Penalized Competitive Learning (RPCL)</a></li>
<li><a class="reference internal" href="#rpcl-based-local-pca">RPCL-based local PCA</a></li>
<li><a class="reference internal" href="#frequency-sensitive-competitive-learning-fscl">Frequency Sensitive Competitive Learning (FSCL)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#k-means-norme-l1">k-means norme L1</a></li>
<li><a class="reference internal" href="#bibliographie">Bibliographie</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../_static/documentation_options.js?v=0886690b"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/furo.js?v=5fa4622c"></script>
    <script src="../_static/translations.js?v=e6b791cb"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    </body>
</html>