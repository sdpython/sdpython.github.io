<!doctype html>
<html class="no-js" lang="fr" data-content_root="../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Recherche" href="../search.html" /><link rel="next" title="MÃ©lange de lois normales" href="gauss_mixture.html" /><link rel="prev" title="Clustering" href="index.html" />

    <!-- Generated with Sphinx 8.1.3 and Furo 2024.08.06 -->
        <title>k-means - Documentation mlstatpy 0.5.0</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=354aac6f" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css?v=4ae1632d" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css?v=7f9a90b1" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=302659d7" />
    
    


<style>
  body {
    --color-code-background: #eeffcc;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">Documentation mlstatpy 0.5.0</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="../_static/project_ico.png" alt="Logo"/>
  </div>
  
  <span class="sidebar-brand-text">Documentation mlstatpy 0.5.0</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Recherche" name="q" aria-label="Recherche">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Mathematics</span></p>
<ul class="current">
<li class="toctree-l1 current has-children"><a class="reference internal" href="index.html">Clustering</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of Clustering</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2 current current-page"><a class="current reference internal" href="#">k-means</a></li>
<li class="toctree-l2"><a class="reference internal" href="gauss_mixture.html">MÃ©lange de lois normales</a></li>
<li class="toctree-l2"><a class="reference internal" href="kohonen.html">Carte de Kohonen</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../c_ml/index.html">Non linÃ©aire</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of Non linÃ©aire</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../c_ml/rn/rn.html">RÃ©seaux de neurones</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of RÃ©seaux de neurones</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../c_ml/rn/rn_1_def.html">DÃ©finition des rÃ©seaux de neurones multi-couches</a></li>
<li class="toctree-l3"><a class="reference internal" href="../c_ml/rn/rn_2_reg.html">La rÃ©gression</a></li>
<li class="toctree-l3"><a class="reference internal" href="../c_ml/rn/rn_3_clas.html">La classification</a></li>
<li class="toctree-l3"><a class="reference internal" href="../c_ml/rn/rn_4_densite.html">DÃ©monstration du thÃ©orÃ¨me de la densitÃ© des rÃ©seaux de neurones</a></li>
<li class="toctree-l3"><a class="reference internal" href="../c_ml/rn/rn_5_newton.html">Descente de gradient</a></li>
<li class="toctree-l3"><a class="reference internal" href="../c_ml/rn/rn_6_apprentissage.html">Apprentissage dâun rÃ©seau de neurones</a></li>
<li class="toctree-l3"><a class="reference internal" href="../c_ml/rn/rn_7_clas2.html">Classification</a></li>
<li class="toctree-l3"><a class="reference internal" href="../c_ml/rn/rn_8_prol.html">Prolongements</a></li>
<li class="toctree-l3"><a class="reference internal" href="../c_ml/rn/rn_9_auto.html">Analyse en composantes principales (ACP) et Auto Encoders</a></li>
<li class="toctree-l3"><a class="reference internal" href="../c_ml/rn/rn_biblio.html">Bibliographie</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../c_ml/kppv.html">Classification Ã  lâaide des plus proches voisins</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../c_ml/missing_values_mf.html">Liens entre factorisation de matrices, ACP, k-means</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of Liens entre factorisation de matrices, ACP, k-means</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/mf_acp.html">Factorisation et matrice et ACP</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/valeurs_manquantes_mf.html">Valeurs manquantes et factorisation de matrices</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/ml/neural_tree.html">Un arbre de dÃ©cision en rÃ©seaux de neurones</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/ml/neural_tree_onnx.html">NeuralTreeNet et ONNX</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/ml/neural_tree_cost.html">NeuralTreeNet et coÃ»t</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../c_ml/index_reg_lin.html">RÃ©gression linÃ©aire</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of RÃ©gression linÃ©aire</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/dsgarden/regression_lineaire.html">RÃ©gression linÃ©aire</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../c_ml/regression_quantile.html">RÃ©gression quantile ou rÃ©gression L1</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle navigation of RÃ©gression quantile ou rÃ©gression L1</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/dsgarden/quantile_regression_example.html">RÃ©gression quantile illustrÃ©e</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../c_ml/piecewise.html">RÃ©gression linÃ©aire par morceaux</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle navigation of RÃ©gression linÃ©aire par morceaux</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/piecewise_linear_regression.html">RÃ©gression linÃ©aire par morceaux</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/regression_no_inversion.html">RÃ©gression sans inversion</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../c_ml/l1l2.html">Normalisation des coefficients</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../c_ml/index_reg_log.html">RÃ©gression logistique</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle navigation of RÃ©gression logistique</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../c_ml/lr_voronoi.html">RÃ©gression logistique, diagramme de VoronoÃ¯, k-Means</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle navigation of RÃ©gression logistique, diagramme de VoronoÃ¯, k-Means</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/logreg_voronoi.html">VoronoÃ¯ et rÃ©gression logistique</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../c_ml/lr_trees.html">RÃ©gression logistique par morceaux, arbres de dÃ©cision</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/ml/reseau_neurones.html">RÃ©seaux de neurones</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../c_ml/survival_analysis.html">Analyse de survie</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle navigation of Analyse de survie</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/survival.html">Analyse de survie en pratique</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../c_nlp/index.html">NLP</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><div class="visually-hidden">Toggle navigation of NLP</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../c_nlp/completion.html">ComplÃ©tion</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><div class="visually-hidden">Toggle navigation of ComplÃ©tion</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../c_nlp/completion_formalisation.html">Formalisation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../c_nlp/completion_fausse.html">Fausses idÃ©es reÃ§ues</a></li>
<li class="toctree-l3"><a class="reference internal" href="../c_nlp/completion_metrique.html">Nouvelle mÃ©trique</a></li>
<li class="toctree-l3"><a class="reference internal" href="../c_nlp/completion_propriete.html">PropriÃ©tÃ©s mathÃ©matiques</a></li>
<li class="toctree-l3"><a class="reference internal" href="../c_nlp/completion_optimisation.html">ProblÃ¨me dâoptimisation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../c_nlp/completion_implementation.html">ImplÃ©mentation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../c_nlp/completion_digression.html">Digressions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/nlp/completion_trie.html">ComplÃ©tion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/nlp/completion_profiling.html">Completion profiling</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/nlp/completion_trie_long.html">Completion Trie and metrics</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/nlp/completion_simple.html">ComplÃ©tion Simple</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../c_metric/index.html">MÃ©triques</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" role="switch" type="checkbox"/><label for="toctree-checkbox-13"><div class="visually-hidden">Toggle navigation of MÃ©triques</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../c_metric/roc.html">Courbe ROC</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" role="switch" type="checkbox"/><label for="toctree-checkbox-14"><div class="visually-hidden">Toggle navigation of Courbe ROC</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/metric/roc_example.html">ROC</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../c_metric/pvalues.html">Confidence Interval and p-Value</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" role="switch" type="checkbox"/><label for="toctree-checkbox-15"><div class="visually-hidden">Toggle navigation of Confidence Interval and p-Value</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/metric/pvalues_examples.html">p-values</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../c_algo/index.html">Algorithmes</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" role="switch" type="checkbox"/><label for="toctree-checkbox-16"><div class="visually-hidden">Toggle navigation of Algorithmes</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../c_algo/edit_distance.html">Distance dâÃ©dition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../c_algo/graph_distance.html">Distance between two graphs</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../c_algo/gest.html">DÃ©tection de segments</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" role="switch" type="checkbox"/><label for="toctree-checkbox-17"><div class="visually-hidden">Toggle navigation of DÃ©tection de segments</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/image/segment_detection.html">DÃ©tection de segments dans une image</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../c_garden/index.html">PÃ©rÃ©grinations</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" role="switch" type="checkbox"/><label for="toctree-checkbox-18"><div class="visually-hidden">Toggle navigation of PÃ©rÃ©grinations</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/dsgarden/split_train_test.html">RÃ©partir en base dâapprentissage et de test</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/dsgarden/correlation_non_lineaire.html">CorrÃ©lations non linÃ©aires</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../c_garden/file_dattente.html">File dâattente, un petit exemple</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" role="switch" type="checkbox"/><label for="toctree-checkbox-19"><div class="visually-hidden">Toggle navigation of File dâattente, un petit exemple</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/dsgarden/file_dattente_ex.html">File dâattente, un exemple simple</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../c_garden/strategie_avec_alea.html">Optimisation avec donnÃ©es alÃ©atoires</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/dsgarden/discret_gradient.html">Le gradient et le discret</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../c_garden/quantization.html">Quantization</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" role="switch" type="checkbox"/><label for="toctree-checkbox-20"><div class="visually-hidden">Toggle navigation of Quantization</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/dsgarden/quantization_f8.html">Quantization</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/dsgarden/classification_multiple.html">Classification multiple</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api/index.html">API</a><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" role="switch" type="checkbox"/><label for="toctree-checkbox-21"><div class="visually-hidden">Toggle navigation of API</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../api/ml.html">Machine Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/optim.html">Optimisation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/text.html">Traitement du langage naturel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/data.html">Source de donnÃ©es</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/graph.html">Graphes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/image.html">Image</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/modules/index.html">Modules</a><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" role="switch" type="checkbox"/><label for="toctree-checkbox-22"><div class="visually-hidden">Toggle navigation of Modules</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/modules/poulet.html">mlstatpy.garden.poulet</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/modules/graph_distance.html">mlstatpy.graph.graph_distance</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/modules/kppv.html">mlstatpy.ml.kppv</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/modules/kppv_laesa.html">mlstatpy.ml.kppv_laesa</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/modules/logreg.html">mlstatpy.ml.logreg</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/modules/neural_tree.html">mlstatpy.ml.neural_tree</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/modules/roc.html">mlstatpy.ml.roc</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/modules/completion.html">mlstatpy.nlp.completion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/modules/completion_simple.html">mlstatpy.nlp.completion_simple</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/modules/sgd.html">mlstatpy.optim.sgd</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../i_ex.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../defthe_index.html">Listes des dÃ©finitions et thÃ©orÃ¨mes</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../auto_examples/index.html">Gallery of examples</a><input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" role="switch" type="checkbox"/><label for="toctree-checkbox-23"><div class="visually-hidden">Toggle navigation of Gallery of examples</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_logistic_decision.html">Arbre dâindÃ©cision</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../notebooks/index.html">Galleries de notebooks</a><input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" role="switch" type="checkbox"/><label for="toctree-checkbox-24"><div class="visually-hidden">Toggle navigation of Galleries de notebooks</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../notebooks/dsgarden/index.html">Le petit coin des data scientists</a><input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" role="switch" type="checkbox"/><label for="toctree-checkbox-25"><div class="visually-hidden">Toggle navigation of Le petit coin des data scientists</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/dsgarden/classification_multiple.html">Classification multiple</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/dsgarden/correlation_non_lineaire.html">CorrÃ©lations non linÃ©aires</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/dsgarden/discret_gradient.html">Le gradient et le discret</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/dsgarden/file_dattente_ex.html">File dâattente, un exemple simple</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/dsgarden/quantile_regression_example.html">RÃ©gression quantile illustrÃ©e</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/dsgarden/quantization_f8.html">Quantization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/dsgarden/regression_lineaire.html">RÃ©gression linÃ©aire</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/dsgarden/split_train_test.html">RÃ©partir en base dâapprentissage et de test</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../notebooks/image/index.html">Images</a><input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" role="switch" type="checkbox"/><label for="toctree-checkbox-26"><div class="visually-hidden">Toggle navigation of Images</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/image/segment_detection.html">DÃ©tection de segments dans une image</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../notebooks/metric/index.html">MÃ©triques</a><input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" role="switch" type="checkbox"/><label for="toctree-checkbox-27"><div class="visually-hidden">Toggle navigation of MÃ©triques</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/metric/pvalues_examples.html">p-values</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/metric/roc_example.html">ROC</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../notebooks/ml/index.html">Machine Learning</a><input class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" role="switch" type="checkbox"/><label for="toctree-checkbox-28"><div class="visually-hidden">Toggle navigation of Machine Learning</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/logreg_voronoi.html">VoronoÃ¯ et rÃ©gression logistique</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/mf_acp.html">Factorisation et matrice et ACP</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/neural_tree.html">Un arbre de dÃ©cision en rÃ©seaux de neurones</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/neural_tree_cost.html">NeuralTreeNet et coÃ»t</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/neural_tree_onnx.html">NeuralTreeNet et ONNX</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/piecewise_linear_regression.html">RÃ©gression linÃ©aire par morceaux</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/regression_no_inversion.html">RÃ©gression sans inversion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/reseau_neurones.html">RÃ©seaux de neurones</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/survival.html">Analyse de survie en pratique</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/ml/valeurs_manquantes_mf.html">Valeurs manquantes et factorisation de matrices</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../notebooks/nlp/index.html">NLP - Natural Language Processing</a><input class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" role="switch" type="checkbox"/><label for="toctree-checkbox-29"><div class="visually-hidden">Toggle navigation of NLP - Natural Language Processing</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/nlp/completion_profiling.html">Completion profiling</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/nlp/completion_simple.html">ComplÃ©tion Simple</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/nlp/completion_trie.html">ComplÃ©tion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/nlp/completion_trie_long.html">Completion Trie and metrics</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">More</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../glossary.html">Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../CHANGELOGS.html">Change Logs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../CHANGELOGS.html#id2">0.4.0</a></li>
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
<li class="toctree-l1"><a class="reference internal" href="../genindex.html">Index</a></li>
<li class="toctree-l1"><a class="reference internal" href="../py-modindex.html">Index du module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../search.html">Page de recherche</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="../_sources/c_clus/kmeans.rst" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="k-means">
<span id="l-k-means"></span><h1>k-means<a class="headerlink" href="#k-means" title="Lien vers cette rubrique">Â¶</a></h1>
<p><em>DÃ©nomination franÃ§aise : algorithme des centres mobiles.</em></p>
<section id="principe">
<span id="index-0"></span><h2>Principe<a class="headerlink" href="#principe" title="Lien vers cette rubrique">Â¶</a></h2>
<p>Les centres mobiles ou nuÃ©es dynamiques sont un algorithme de classification
<em>non supervisÃ©e</em>. A partir dâun ensemble de points, il dÃ©termine pour un
nombre de classes fixÃ©, une rÃ©partition des points qui minimise un
critÃ¨re appelÃ© <em>inertie</em> ou variance <em>intra-classe</em>.</p>
<div class="admonition-mathdef admonition" id="indexmathe-Algorithme0">
<div class="docutils container">
</div>
<p class="admonition-title" id="kmeans-def-algo">Algorithme A1 : centre mobile, k-means</p>
<p>On considÃ¨re un ensemble de points :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/3aecfb408214f41fe14dff6fc080cb52c6f2d7a0.svg" alt="\left(X_i\right)_{1\leqslant i\leqslant P}\in\left(\mathbb{R}^N\right)^P"/></p>
</div></div>
<p>A chaque point est associÃ©e une classe :
<img class="math" src="../_images/math/8fbb04a7fd604cf3d5ab4f74d7a34f443fee16b0.svg" alt="\left(c_i\right)_{1\leqslant i\leqslant P}\in\left\{1,...,C\right\}^P"/>.
On dÃ©finit les barycentres des classes :
<img class="math" src="../_images/math/e45775312199459dbdab618b1e133f66f02ee6a3.svg" alt="\left( G_i\right)_{1\leqslant i\leqslant C}\in\left(\mathbb{R}^N\right)^C"/>.</p>
<p><em>Initialisation</em></p>
<p>Lâinitialisation consiste Ã  choisir pour chaque point une classe alÃ©atoirement dans
<img class="math" src="../_images/math/2ab98387c03ab0e650306cbd442f1f9a60ff4218.svg" alt="\left\{1,...,C\right\}"/>. On pose <img class="math" src="../_images/math/e75ee36648418afabd4cbd3434fb5e3f14b2dd35.svg" alt="t = 0"/>.</p>
<p id="hmm-cm-step-bary"><em>Calcul des barycentres</em></p>
<div class="line-block">
<div class="line">for k in <img class="math" src="../_images/math/f963c7631cb87c320d1687686f34c5e48b508b2d.svg" alt="1..C"/></div>
<div class="line-block">
<div class="line"><img class="math" src="../_images/math/8a3db512bbb25da3c950ee29e091b8bbd5386d18.svg" alt="G_k^t \longleftarrow \sum_{i=1}^P X_i \, \mathbf{1}_{\left\{c_i^t=k\right\}} \sum_{i=1}^P \mathbf{1}_{\left\{c_i^t=k\right\}}"/></div>
</div>
</div>
<p><em>Calcul de lâinertie</em></p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/28fa5741d138e33445bca8bd990c592a523aa6b9.svg" alt="\begin{array}{lll}
I^t &amp;\longleftarrow&amp; \sum_{i=1}^P \; d^2\left(X_i, G_{c_i^t}^t\right) \\
t   &amp;\longleftarrow&amp; t+1
\end{array}"/></p>
</div></div>
<div class="line-block">
<div class="line">if <img class="math" src="../_images/math/00d07f71cd210dbc4d6982774175b3b746d6330e.svg" alt="t &gt; 0"/> et <img class="math" src="../_images/math/620d5f81891c433e5f48def7a7191a56b1d5dfe6.svg" alt="I_t \sim I_{t-1}"/></div>
<div class="line-block">
<div class="line">arrÃªt de lâalgorithme</div>
</div>
</div>
<p id="hmm-cm-step-attr"><em>Attribution des classes</em></p>
<div class="line-block">
<div class="line">for in <img class="math" src="../_images/math/df2683ce64cbd8aa455227bc05a9dff56f80cd46.svg" alt="1..P"/></div>
<div class="line-block">
<div class="line"><img class="math" src="../_images/math/cf85f2c54f14763d61530fad52f5f476aeb71ed1.svg" alt="c_i^{t+1} \longleftarrow \underset{k}{\arg\min} \; d\left(  X_{i},G_{k}^{t}\right)"/></div>
<div class="line">oÃ¹ <img class="math" src="../_images/math/c2cc82176a4ab3caca55fe95f563d4e0657fbf8f.svg" alt="d\left(X_i,G_k^t\right)"/> est la distance entre <img class="math" src="../_images/math/c15b262677ad7177c2e37298a2eb382d712b3a52.svg" alt="X_i"/> et <img class="math" src="../_images/math/75014aeefe371ad56993a725fb07f0591c0c8820.svg" alt="G_k^t"/></div>
</div>
</div>
<p>Retour Ã  lâÃ©tape du calcul des barycentres jusquâÃ  convergence de lâinertie <img class="math" src="../_images/math/8384668a714bfd2a900009fc5988cdcae0e5679a.svg" alt="I^t"/>.</p>
</div>
<div class="admonition-mathdef admonition" id="indexmathe-ThÃ©orÃ¨me0">
<div class="docutils container">
</div>
<p class="admonition-title" id="theoreme-inertie-1">ThÃ©orÃ¨me T1 : convergence des k-means</p>
<p>Quelque soit lâinitialisation choisie, la suite <img class="math" src="../_images/math/dc6e79a6b925c6370d9f1098066ee6268c69fb4d.svg" alt="\pa{I_t}_{t\supegal 0}"/>
construite par lâalgorithme des <a class="reference internal" href="#kmeans-def-algo"><span class="std std-ref">k-means</span></a>
converge.</p>
</div>
<p>La dÃ©monstration du thÃ©orÃ¨me nÃ©cessite le lemme suivant.</p>
<div class="admonition-mathdef admonition" id="indexmathe-Lemme0">
<div class="docutils container">
</div>
<p class="admonition-title" id="lemme-inertie-minimum">Lemme L1 : inertie minimum</p>
<p>Soit <img class="math" src="../_images/math/ab327c4830bd67061a70965838dd5f0e4304b4ae.svg" alt="\vecteur{X_1}{X_P} \in \pa{\mathbb{R}^N}^P"/>,
<img class="math" src="../_images/math/2f2a105c289b01c226ad6e0f506d96386c48d440.svg" alt="P"/> points de <img class="math" src="../_images/math/e0d2c3c43a5ca8a93521f5070fcc03a4109482da.svg" alt="\mathbb{R}^N"/>, le minimum de la quantitÃ©
<img class="math" src="../_images/math/1a51aede74e61c53ebf9251dda9798d53db0c8a7.svg" alt="Q\pa{Y \in \mathbb{R}^N}"/> :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/24c842009c8496b5cfa1ba182a599e7f574954f6.svg" alt="\begin{eqnarray}
Q\pa{Y} &amp;=&amp; \sum_{i=1}^P \; d^2\pa{X_i,Y}
\end{eqnarray}"/></p>
</div></div>
<p>est atteint pour <img class="math" src="../_images/math/9640141c96e289d1cc695d1777f52505fcf46649.svg" alt="Y=G=\dfrac{1}{P} \sum_{i=1}^{P} X_i"/>
le barycentre des points <img class="math" src="../_images/math/cf168a3f3647fa1f5fa81a83378c60fc279eecf3.svg" alt="\vecteur{X_1}{X_P}"/>.</p>
</div>
<p>Soit <img class="math" src="../_images/math/ab327c4830bd67061a70965838dd5f0e4304b4ae.svg" alt="\vecteur{X_1}{X_P} \in \pa{\mathbb{R}^N}^P"/>,
<img class="math" src="../_images/math/2f2a105c289b01c226ad6e0f506d96386c48d440.svg" alt="P"/> points de <img class="math" src="../_images/math/e0d2c3c43a5ca8a93521f5070fcc03a4109482da.svg" alt="\mathbb{R}^N"/>.</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/6a29e9ab68372844dac0a4127ffee0352f17639f.svg" alt="\begin{eqnarray*}
                    \sum_{i=1}^{P} \overrightarrow{GX_{i}} = \overrightarrow{0}
&amp;\Longrightarrow&amp;      \sum_{i=1}^{P} d^2\pa{X_i,Y} = \sum_{i=1}^{P} d^2\pa{X_i,G}+ P \, d^2\pa{G,Y} \\
&amp;\Longrightarrow&amp;     \underset{Y\in\mathbb{R}^N}{\arg\min} \; \sum_{i=1}^{P} d^2\pa{X_i,Y} = \acc{G}
\end{eqnarray*}"/></p>
</div></div>
<p>On peut maintenant dÃ©montrer le thÃ©orÃ¨me.
LâÃ©tape dâattribution des classes consiste Ã  attribuer Ã  chaque
point le barycentre le plus proche. On dÃ©finit <img class="math" src="../_images/math/3b1d41c0394f1d0df53dcd8a361ce1a3c2fc5160.svg" alt="J_t"/> par :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/543a741e1011b1ec47fda7a2979b2b21b386ae0d.svg" alt="\begin{eqnarray}
J^{t+1} &amp;=&amp; \sum_{i=1}^{P} \; d^2\pa{ X_i, G_{c_i^{t+1}}^t}
\end{eqnarray}"/></p>
</div></div>
<p>On en dÃ©duit que :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/8b124540807ab83949a654170bc67bb44d2272b9.svg" alt="\begin{eqnarray}
J^{t+1}    &amp;=&amp; \sum_{i, c_i^t \neq c_i^{t+1}} \; d^2\pa{ X_i, G_{c_i^{t+1}}^t} + J^{t+1} \sum_{i, c_i^t = c_i^{t+1}} \; d^2\pa{ X_i, G_{c_i^{t+1}}^t}  \\
J^{t+1}    &amp;\leqslant&amp;  \sum_{i, c_i^t \neq c_i^{t+1}} \; d^2\pa{ X_i, G_{c_i^{t}}^t} + \sum_{i, c_i^t = c_i^{t+1}} \; d^2\pa{ X_i, G_{c_i^{t}}^t} \\
J^{t+1}    &amp;\leqslant&amp;  I^t
\end{eqnarray}"/></p>
</div></div>
<p>Le lemme prÃ©cÃ©dent appliquÃ© Ã  chacune des classes <img class="math" src="../_images/math/79c96636ca69f9cb49bd9df5dab7ef30f8d5ba3e.svg" alt="\ensemble{1}{C}"/>,
permet dâaffirmer que <img class="math" src="../_images/math/1c81190f60b3604688ed32ba3a2467860ad1a838.svg" alt="I^{t+1} \leqslant J^{t+1}"/>.
Par consÃ©quent, la suite <img class="math" src="../_images/math/dc6e79a6b925c6370d9f1098066ee6268c69fb4d.svg" alt="\pa{I_t}_{t\supegal 0}"/> est dÃ©croissante et minorÃ©e par
0, elle est donc convergente.</p>
<p id="index-1">Lâalgorithme des centres mobiles cherche Ã  attribuer Ã  chaque
point de lâensemble une classe parmi les <img class="math" src="../_images/math/2c0e77bc741b692ecdf6e85966263a89422af4c8.svg" alt="C"/> disponibles.
La solution trouvÃ©e dÃ©pend de lâinitialisation et nâest pas forcÃ©ment
celle qui minimise lâinertie intra-classe : lâinertie finale est
un minimum local. NÃ©anmoins, elle assure que la partition est formÃ©e
de classes convexes : soit <img class="math" src="../_images/math/3950d3def11e9f0784eacec55d2b79c3a0bf19df.svg" alt="c_1"/> et <img class="math" src="../_images/math/c50924711ece3aac359df4fd02db9d6f74bb0fb1.svg" alt="c_2"/> deux classes diffÃ©rentes,
on note <img class="math" src="../_images/math/0247a196052dd9baf0366fbf8f6a1d87e64c7c5f.svg" alt="C_1"/> et <img class="math" src="../_images/math/5838b45439d93f4669eab86d0796eeb6e7195cba.svg" alt="C_2"/> les enveloppes convexes des points qui
constituent ces deux classes, alors
<img class="math" src="../_images/math/d985fae5e74d3e4571004f70e62cd235c3007e27.svg" alt="\overset{o}{C_1} \cap \overset{o}{C_2} = \emptyset"/>.
La figure suivante prÃ©sente un exemple dâutilisation de lâalgorithme
des centres mobiles. Des points sont gÃ©nÃ©rÃ©s alÃ©atoirement
dans le plan et rÃ©partis en quatre groupes.</p>
<img alt="../_images/cm.png" src="../_images/cm.png" />
<p>Câest une application des centres mobiles avec une classification en quatre classes
dâun ensemble alÃ©atoire de points plus dense sur la partie droite du graphe. Les quatre classes
ainsi formÃ©es sont convexes.</p>
<section id="homogeneite-des-dimensions">
<span id="hmm-classification-obs-deux"></span><h3>HomogÃ©nÃ©itÃ© des dimensions<a class="headerlink" href="#homogeneite-des-dimensions" title="Lien vers cette rubrique">Â¶</a></h3>
<p>Les coordonnÃ©es des points
<img class="math" src="../_images/math/290945200c23b05845ac6cad5878df00c915d756.svg" alt="\left(X_i\right) \in \mathbb{R}^N"/> sont gÃ©nÃ©ralement non homogÃ¨nes :
les ordres de grandeurs de chaque dimension sont diffÃ©rents.
Câest pourquoi il est conseillÃ© de centrer et normaliser chaque dimension.
On note : <img class="math" src="../_images/math/0ebe5f3361de03c441c9b2cbf93bb1339755661c.svg" alt="\forall i \in \intervalle{1}{P}, \; X_i = \vecteur{X_{i,1}}{X_{i,N}}"/> :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/2d27398f90cd778fc8219befb5f4969fccdc1f11.svg" alt="\begin{eqnarray*}
g_k &amp;=&amp; \pa{EX}_k = \frac{1}{P} \sum_{i=1}^P X_{i,k} \\
v_{kk} &amp;=&amp; \pa{E\left(X-EX\right)^2}_{kk}=\pa{EX^2}_{kk} - g_k^2
\end{eqnarray*}"/></p>
</div></div>
<p>Les points centrÃ©s et normalisÃ©s sont :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/2e5a10fc46f97a6baa43b43deddb13bf0349f460.svg" alt="\forall i \in \intervalle{1}{P}, \;
X_i^{\prime}=\left(\dfrac{x_{i,1}-g_{1}}{\sqrt{v_{11}}},...,\dfrac{x_{i,N}-g_{N}}{\sqrt{v_{NN}}}\right)"/></p>
</div></div>
<p id="index-2">Lâalgorithme des centres mobiles est appliquÃ© sur lâensemble
<img class="math" src="../_images/math/b2057ecde740acd964bd1160b7789a09dfb3c71c.svg" alt="\left( X_{i}^{\prime}\right)_{1\leqslant i\leqslant P}"/>.
Il est possible ensuite de dÃ©corrÃ©ler les variables ou dâutiliser
une distance dite de <a class="reference external" href="https://fr.wikipedia.org/wiki/Distance_de_Mahalanobis">Malahanobis</a> dÃ©finie par
<img class="math" src="../_images/math/cac45acdfd9138ea17baa41d675fcda9e107bc4d.svg" alt="d_M\pa{X, Y} = X \, M \, Y'"/> oÃ¹ <img class="math" src="../_images/math/2f38be5157e7f5029042c49957a29cf7c2f29ee0.svg" alt="Y'"/>
dÃ©signe la transposÃ©e de <img class="math" src="../_images/math/b59453388a752e340d555df9064bfb27e7112e68.svg" alt="Y"/> et <img class="math" src="../_images/math/e5c619f0600e251cabb3318b03870bc6f2c4870f.svg" alt="M"/>
est une matrice symÃ©trique dÃ©finie positive.
Dans le cas de variables corrÃ©lÃ©es, la matrice
<img class="math" src="../_images/math/8f2e404988e46f58a6e37c86071bc82d8322d3de.svg" alt="M = \Sigma^{-1}"/> oÃ¹ <img class="math" src="../_images/math/101365d041befcd5108977fd092dbd8bc9785dbc.svg" alt="\Sigma^{-1}"/> est la matrice
de variance-covariance des variables alÃ©atoires <img class="math" src="../_images/math/72643a45ac37dbe64e26a084f8d7bf0c765e522b.svg" alt="\pa{X_i}_i"/>.</p>
</section>
</section>
<section id="ameliorations-de-l-initialisation">
<h2>AmÃ©liorations de lâinitialisation<a class="headerlink" href="#ameliorations-de-l-initialisation" title="Lien vers cette rubrique">Â¶</a></h2>
<section id="l-kmeanspp">
<span id="id1"></span><h3>K-means++<a class="headerlink" href="#l-kmeanspp" title="Lien vers cette rubrique">Â¶</a></h3>
<p id="index-3">Lâarticle <a class="reference internal" href="#arthur2007" id="id2"><span>[Arthur2007]</span></a> montre que lâinitialisation alÃ©atoire nâest pas efficace et
est sensible aux outliers ou points aberrants. LâÃ©tape dâinitialisation est remplacÃ©e
par la suivante :</p>
<div class="admonition-mathdef admonition" id="indexmathe-Algorithme1">
<div class="docutils container">
</div>
<p class="admonition-title" id="init-kmeanspp">Algorithme A2 : initialisation k-means++</p>
<p>Cette Ã©tape dâinitialisation viendra remplacer celle
dÃ©finie dans lâalgorithme
<a class="reference internal" href="#kmeans-def-algo"><span class="std std-ref">k-means</span></a>.
On considÃ¨re un ensemble de points :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/8641428d8eda2dcf8698b45287eb4579b53979ad.svg" alt="X=\left(X_i\right)_{1\leqslant i\leqslant P}\in\left(\mathbb{R}^N\right)^P"/></p>
</div></div>
<p>A chaque point est associÃ©e une classe :
<img class="math" src="../_images/math/8fbb04a7fd604cf3d5ab4f74d7a34f443fee16b0.svg" alt="\left(c_i\right)_{1\leqslant i\leqslant P}\in\left\{1,...,C\right\}^P"/>.</p>
<p>Pour <img class="math" src="../_images/math/312028c07e271534bd0dbde5434e49e76880744f.svg" alt="k"/> centres, on choisit <img class="math" src="../_images/math/0247a196052dd9baf0366fbf8f6a1d87e64c7c5f.svg" alt="C_1"/>
au hasard dans lâensemble <img class="math" src="../_images/math/b66c7d6c52c7b12bee7fb24d76c38fc70cfc0a2f.svg" alt="X"/>.
Pour les suivants :</p>
<ol class="arabic simple">
<li><p><img class="math" src="../_images/math/f3426cfc16493940b22f7321730b3e3c6e4aa4bb.svg" alt="k \leftarrow 2"/></p></li>
<li><p>On choisit alÃ©atoirement <img class="math" src="../_images/math/e005910ee0a428539915444c2ea62c0b8c6bba74.svg" alt="G_k \in X"/> avec la probabilitÃ©
<img class="math" src="../_images/math/b217ea0d59e42a46339694765455b3f276d18b0d.svg" alt="P(x) = \frac{D_{k-1}(x)^2}{\sum_{x\in X}D_{k-1}(x)^2}"/></p></li>
<li><p><img class="math" src="../_images/math/26f65fceab6599facc16133f496cd1c24b9073f8.svg" alt="k \leftarrow k+1"/></p></li>
<li><p>On revient Ã  lâÃ©tape 2 jusquâÃ  ce que <img class="math" src="../_images/math/2142171ad258df7aa0ffd1bc4abe7f785f080ecb.svg" alt="k=C"/>.</p></li>
</ol>
<p>La fonction <img class="math" src="../_images/math/96d648b9ba49faf544f18bffe162bff2e293634f.svg" alt="D_k"/> est dÃ©finie par la distance du point <img class="math" src="../_images/math/cdd160a57af92571d6838c69c7bde600843a23bf.svg" alt="x"/>
au centre <img class="math" src="../_images/math/36b42e357e2e138a2e83f331c2467495293aac6d.svg" alt="G_l"/> choisi parmi les <img class="math" src="../_images/math/312028c07e271534bd0dbde5434e49e76880744f.svg" alt="k"/> premiers centres.
<img class="math" src="../_images/math/15a4e895a74f9813c8ce9ee38c5c3e1eaddffa4a.svg" alt="D_k(x) = \min_{1 \leqslant l \leqslant k} d(x - G_l)"/>.</p>
<p>La suite de lâalgorithme <em>k-means++</em> reprend les mÃªmes Ã©tapes que
<a class="reference internal" href="#kmeans-def-algo"><span class="std std-ref">k-means</span></a>.</p>
</div>
<p>Cette initilisation Ã©loigne le prochain centre le plus possibles des
centres dÃ©jÃ  choisis. Lâarticle montre que :</p>
<div class="admonition-mathdef admonition" id="indexmathe-ThÃ©orÃ¨me1">
<p class="admonition-title">ThÃ©orÃ¨me T2 : Borne supÃ©rieure de lâerreur produite par k-means++</p>
<p>On dÃ©finit lâinertie par
<img class="math" src="../_images/math/1326dc7c9643c65fdf963b33d46e022fc14bbac9.svg" alt="J_(X) = \sum_{i=1}^{P} \; \min_G d^2(X_i, G)"/>.
Si <img class="math" src="../_images/math/83176a4f55c394ebf2e1fdf290bd87eb5a99a345.svg" alt="J_{OPT}"/> dÃ©finit lâinertie optimale alors
<img class="math" src="../_images/math/607c80d070f5233c1c31ac01ccffef6b2947200d.svg" alt="\esp{J(X)} \leqslant 8 (\ln C + 2) J_{OPT}(X)"/>.</p>
</div>
<p>La dÃ©monstration est disponible dans lâarticle <a class="reference internal" href="#arthur2007" id="id3"><span>[Arthur2007]</span></a>.</p>
</section>
<section id="id4">
<h3>K-means||<a class="headerlink" href="#id4" title="Lien vers cette rubrique">Â¶</a></h3>
<p>Lâarticle <a class="reference internal" href="#bahmani2012" id="id5"><span>[Bahmani2012]</span></a> propose une autre initialisation
que <a class="reference internal" href="#l-kmeanspp"><span class="std std-ref">K-means++</span></a> mais plus rapide et parallÃ©lisable.</p>
<div class="admonition-mathdef admonition" id="indexmathe-Algorithme2">
<div class="docutils container">
</div>
<p class="admonition-title" id="init-kmeansppll">Algorithme A3 : initialisation k-means||</p>
<p>Cette Ã©tape dâinitialisation viendra remplacer celle
dÃ©finie dans lâalgorithme
<a class="reference internal" href="#kmeans-def-algo"><span class="std std-ref">k-means</span></a>.
On considÃ¨re un ensemble de points :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/8641428d8eda2dcf8698b45287eb4579b53979ad.svg" alt="X=\left(X_i\right)_{1\leqslant i\leqslant P}\in\left(\mathbb{R}^N\right)^P"/></p>
</div></div>
<p>A chaque point est associÃ©e une classe :
<img class="math" src="../_images/math/8fbb04a7fd604cf3d5ab4f74d7a34f443fee16b0.svg" alt="\left(c_i\right)_{1\leqslant i\leqslant P}\in\left\{1,...,C\right\}^P"/>.</p>
<p>Pour <img class="math" src="../_images/math/312028c07e271534bd0dbde5434e49e76880744f.svg" alt="k"/> centres, on choisit <img class="math" src="../_images/math/67ff5828e87602fb558f801a96396559e04e0dd9.svg" alt="G = \{G_1\}"/>
au hasard dans lâensemble <img class="math" src="../_images/math/b66c7d6c52c7b12bee7fb24d76c38fc70cfc0a2f.svg" alt="X"/>.</p>
<div class="line-block">
<div class="line">on rÃ©pÃ¨te <img class="math" src="../_images/math/0a185a031e88ca1155325a6e0ba9c06642d3fab1.svg" alt="O(\ln D(G, X))"/> fois :</div>
<div class="line-block">
<div class="line"><img class="math" src="../_images/math/e193c978ec2415600c7ea2810f794ff2959db4c2.svg" alt="G' \leftarrow"/> Ã©chantillon alÃ©atoire issue de <img class="math" src="../_images/math/b66c7d6c52c7b12bee7fb24d76c38fc70cfc0a2f.svg" alt="X"/> de probabilitÃ© <img class="math" src="../_images/math/4eea0ad742152d6108fde2a6a484470903d03702.svg" alt="p(x) = l \frac{D(G,x)^2}{\sum_x D(G,x)^2}"/></div>
<div class="line"><img class="math" src="../_images/math/6261544c59180ee36cd1108bd4e15069bd94c12f.svg" alt="G \leftarrow G \cup G'"/></div>
</div>
</div>
<p>La fonction <img class="math" src="../_images/math/6f299d138def92cb9b8de6e24011d19bbbfb2e76.svg" alt="D(G,x)"/> est dÃ©finie par la distance du point <img class="math" src="../_images/math/cdd160a57af92571d6838c69c7bde600843a23bf.svg" alt="x"/>
au plus proche centre <img class="math" src="../_images/math/d3a5ece8d7ec78151cf34c4ac504aa41edd1f660.svg" alt="g \in G"/> :
<img class="math" src="../_images/math/3a7b447089b20dc22e9407de72af078c6c025584.svg" alt="D(g,x) = \min_{g \in G} d(x - g)"/>.
Cette Ã©tape ajoute Ã  lâensemble des centres <img class="math" src="../_images/math/86a30eae2899d36dcee14ab62c5e4c8a68feed4d.svg" alt="G"/>
un nombre alÃ©atoire de centres Ã  chaque Ã©tape.
Lâensemble <img class="math" src="../_images/math/86a30eae2899d36dcee14ab62c5e4c8a68feed4d.svg" alt="G"/> contiendra plus de <img class="math" src="../_images/math/2c0e77bc741b692ecdf6e85966263a89422af4c8.svg" alt="C"/> centres.</p>
<ol class="arabic simple">
<li><p>Pour tout <img class="math" src="../_images/math/d3a5ece8d7ec78151cf34c4ac504aa41edd1f660.svg" alt="g \in G"/>, on assigne le poids <img class="math" src="../_images/math/7a384ce2009fcbc54c587a963141c4ba88347609.svg" alt="w_g = card \acc{ y | d(x, y) &lt; \min_{h \in G} d(x, h)}"/></p></li>
<li><p>On clusterise lâensemble des points <img class="math" src="../_images/math/86a30eae2899d36dcee14ab62c5e4c8a68feed4d.svg" alt="G"/> en <img class="math" src="../_images/math/2c0e77bc741b692ecdf6e85966263a89422af4c8.svg" alt="C"/> clusters
(avec un k-means classique par exemple)</p></li>
</ol>
</div>
<p>Au lieu dâajouter les centres un par un comme dans lâalgorithme
<a class="reference internal" href="#init-kmeanspp"><span class="std std-ref">k-means++</span></a>, plusieurs sont ajoutÃ©s Ã  chaque fois,
plus <img class="math" src="../_images/math/b40d7de3530507b378090edb54198bdc06e33be9.svg" alt="l"/> est grand, plus ce nombre est grand. Le tirage dâun Ã©chantillon
alÃ©atoire consiste Ã  inclure chaque point <img class="math" src="../_images/math/cdd160a57af92571d6838c69c7bde600843a23bf.svg" alt="x"/> avec la probabilitÃ©
<img class="math" src="../_images/math/4eea0ad742152d6108fde2a6a484470903d03702.svg" alt="p(x) = l \frac{D(G,x)^2}{\sum_x D(G,x)^2}"/>.</p>
</section>
</section>
<section id="estimation-de-probabilites">
<span id="hmm-classification-obs-trois"></span><h2>Estimation de probabilitÃ©s<a class="headerlink" href="#estimation-de-probabilites" title="Lien vers cette rubrique">Â¶</a></h2>
<p>A partir de cette classification en <img class="math" src="../_images/math/2c0e77bc741b692ecdf6e85966263a89422af4c8.svg" alt="C"/> classes, on construit un
vecteur de probabilitÃ©s pour chaque point <img class="math" src="../_images/math/cc127b27a3989c9a0645437c30a848e90837afc7.svg" alt="\pa{X_{i}}_{1 \leqslant i \leqslant P}"/>
en supposant que la loi de <img class="math" src="../_images/math/b66c7d6c52c7b12bee7fb24d76c38fc70cfc0a2f.svg" alt="X"/> sachant sa classe <img class="math" src="../_images/math/f69ba531fba42e37e610be4c5e36f06fa00e78f4.svg" alt="c_X"/> est une loi
normale multidimensionnelle. La classe de <img class="math" src="../_images/math/c15b262677ad7177c2e37298a2eb382d712b3a52.svg" alt="X_i"/> est
notÃ©e <img class="math" src="../_images/math/fa4ae29716395f8ebb2444ec26b1c6da2f3b53db.svg" alt="c_i"/>. On peut alors Ã©crire :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/9a5fb39737956619460c225d56792438543f79bb.svg" alt="\begin{eqnarray*}
\forall i \in \intervalle{1}{C}, \; &amp; &amp; \\
G_i &amp;=&amp; E\pa{X \indicatrice{c_X = i}} = \dfrac{\sum_{k=1}^{P} X_k \indicatrice {c_k = i}} {\sum_{k=1}^{P} \indicatrice {c_k = i}} \\
V_i &amp;=&amp; E\pa{XX' \indicatrice{c_X = i}} = \dfrac{\sum_{k=1}^{P} X_k X_k' \indicatrice {c_k = i}} {\sum_{k=1}^{P} \indicatrice {c_k = i}} \\
\pr{c_X = i} &amp;=&amp; \sum_{k=1}^{P} \indicatrice {c_k = i} \\
f\pa{X | c_X = i} &amp;=&amp; \dfrac{1}{\pa{2\pi}^{\frac{N}{2}} \sqrt{\det \pa{V_i}}} \; e^{ - \frac{1}{2} \pa{X - G_i}' \; V_i^{-1} \; \pa{X - G_i} } \\
f\pa{X} &amp;=&amp; \sum_{k=1}^{P}  f\pa{X | c_X = i} \pr{c_X = i}
\end{eqnarray*}"/></p>
</div></div>
<p>On en dÃ©duit que :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/8f1131ba92f299ab42d7e3925c303eab93f02633.svg" alt="\pr{c_X = i |X } = \dfrac{f\pa{X | c_X = i}\pr{c_X = i}} {f\pa{X} }"/></p>
</div></div>
<p>La densitÃ© des obervations est alors modÃ©lisÃ©e par une mÃ©lange de
lois normales, chacune centrÃ©e au barycentre de chaque classe.
Ces probabilitÃ©s peuvent Ã©galement Ãªtre apprises par un rÃ©seau de neurones
classifieur oÃ¹ servir dâinitialisation Ã  un
<a class="reference external" href="https://fr.wikipedia.org/wiki/Algorithme_esp%C3%A9rance-maximisation">algorithme EM</a>.</p>
</section>
<section id="selection-du-nombre-de-classes">
<h2>SÃ©lection du nombre de classes<a class="headerlink" href="#selection-du-nombre-de-classes" title="Lien vers cette rubrique">Â¶</a></h2>
<section id="critere-de-qualite">
<span id="classification-selection-nb-classe-bouldin"></span><h3>CritÃ¨re de qualitÃ©<a class="headerlink" href="#critere-de-qualite" title="Lien vers cette rubrique">Â¶</a></h3>
<p>Lâalgorithme des centres mobiles effectue une classification non supervisÃ©e
Ã  condition de connaÃ®tre au prÃ©alable le nombre de classes et
cette information est rarement disponible. Une alternative consiste Ã 
estimer la pertinence des classifications obtenues pour diffÃ©rents
nombres de classes, le nombre de classes optimal est celui
qui correspond Ã  la classification la plus pertinente.
Cette pertinence ne peut Ãªtre estimÃ©e de maniÃ¨re unique, elle dÃ©pend des
hypothÃ¨ses faites sur les Ã©lÃ©ments Ã  classer, notamment sur la forme
des classes qui peuvent Ãªtre convexes ou pas, Ãªtre modÃ©lisÃ©es par des
lois normales multidimensionnelles, Ã  matrice de covariances diagonales, â¦
Les deux critÃ¨res qui suivent sont adaptÃ©s Ã  lâalgorithme des centres mobiles.
Le critÃ¨re de <a class="reference external" href="https://en.wikipedia.org/wiki/Davies%E2%80%93Bouldin_index">Davies-Bouldin</a>
(voir <a class="reference internal" href="#davies1979" id="id6"><span>[Davies1979]</span></a>)
est minimum lorsque le nombre de classes est optimal.</p>
<div class="math-wrapper docutils container" id="index-4">
<div class="math" id="index-4">
<p><img src="../_images/math/1fc5f1924491aa845b7d3b4aca6781b95d97cf7f.svg" alt="\begin{eqnarray}
DB &amp;=&amp; \dfrac{1}{C} \;     \sum_{i=1}^{C} \; \max_{i \neq j} \; \dfrac{\sigma_i + \sigma_j}{ d\pa{C_i,C_j}}
\end{eqnarray}"/></p>
</div></div>
<p>Avec :</p>
<div class="table-wrapper colwidths-given docutils container">
<table class="docutils align-default">
<colgroup>
<col style="width: 33.3%" />
<col style="width: 66.7%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p><img class="math" src="../_images/math/2c0e77bc741b692ecdf6e85966263a89422af4c8.svg" alt="C"/></p></th>
<th class="head"><p>nombre de classes</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><img class="math" src="../_images/math/918edf1163affce55968c2b270f7ebe1865389aa.svg" alt="\sigma_i"/></p></td>
<td><p>Ã©cart-type des distances des observations de la classe <img class="math" src="../_images/math/6c9c36eeb0679ad71efe34ded19d79168983fb38.svg" alt="i"/></p></td>
</tr>
<tr class="row-odd"><td><p><img class="math" src="../_images/math/028f0a9b50db11bb7b06a1941fbc0c441259482c.svg" alt="C_i"/></p></td>
<td><p>centre de la classe <img class="math" src="../_images/math/6c9c36eeb0679ad71efe34ded19d79168983fb38.svg" alt="i"/></p></td>
</tr>
</tbody>
</table>
</div>
<p>Le critÃ¨re de <a class="reference external" href="https://en.wikipedia.org/wiki/Goodman_and_Kruskal%27s_gamma">Goodman-Kruskal</a>
(voir <a class="reference internal" href="#goodman1954" id="id7"><span>[Goodman1954]</span></a>) est quant Ã  lui maximum lorsque le nombre de classes est optimal.
Il est toutefois plus coÃ»teux Ã  calculer.</p>
<div class="math-wrapper docutils container" id="index-5">
<div class="math" id="index-5">
<p><img src="../_images/math/0768685dee2700f421deb6400b093439d6cbd03e.svg" alt="\begin{eqnarray}
GK &amp;=&amp; \dfrac{S^+ - S^-} { S^+ + S^-}
\end{eqnarray}"/></p>
</div></div>
<p>Avec :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/3970264331ba20df051df7bb3fd64d7e416e1b4c.svg" alt="\begin{eqnarray*}
S^+ &amp;=&amp; \acc{ \pa{q,r,s,t} \sac d\pa{q,r} &lt; d\pa{s,t} } \\
S^- &amp;=&amp; \acc{ \pa{q,r,s,t} \sac d\pa{q,r} &lt; d\pa{s,t} }
\end{eqnarray*}"/></p>
</div></div>
<p>OÃ¹ <img class="math" src="../_images/math/347189a1a98974758d795362c319c74abba1aca3.svg" alt="\pa{q,r}"/> sont dans la mÃªme classe et <img class="math" src="../_images/math/c00163f11b47dc018c3149112d68ee2c77359f1a.svg" alt="\pa{s,t}"/> sont dans des classes diffÃ©rentes.</p>
<div class="table-wrapper colwidths-given docutils container">
<table class="docutils align-default">
<colgroup>
<col style="width: 50.0%" />
<col style="width: 50.0%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><img alt="../_images/class_4.png" src="../_images/class_4.png" />
</td>
<td><img alt="../_images/class_4_db.png" src="../_images/class_4_db.png" />
</td>
</tr>
</tbody>
</table>
</div>
<p>Classification en quatre classes : nombre de classes sÃ©lectionnÃ©es par le critÃ¨re
de Davies-Bouldin dont les valeurs sont illustrÃ©es par le graphe apposÃ© Ã  droite.</p>
</section>
<section id="maxima-de-la-fonction-densite">
<h3>Maxima de la fonction densitÃ©<a class="headerlink" href="#maxima-de-la-fonction-densite" title="Lien vers cette rubrique">Â¶</a></h3>
<p>Lâarticle <a class="reference internal" href="#herbin2001" id="id8"><span>[Herbin2001]</span></a> propose une mÃ©thode diffÃ©rente pour estimer
le nombre de classes, il sâagit tout dâabord dâestimer la fonction
densitÃ© du nuage de points qui est une fonction de
<img class="math" src="../_images/math/c9ace9fa2a853820e391fef3b70bd8706fa1e270.svg" alt="\mathbb{R}^n \longrightarrow \mathbb{R}"/>. Cette estimation est effectuÃ©e au moyen
dâune mÃ©thode non paramÃ¨trique telle que les estimateurs Ã  noyau
(voir <a class="reference internal" href="#silverman1986" id="id9"><span>[Silverman1986]</span></a>)
Soit <img class="math" src="../_images/math/26f924af3662c85fdae93b78379cf709640d2119.svg" alt="\vecteur{X_1}{X_N}"/> un nuage de points inclus dans une image,
on cherche Ã  estimer la densitÃ© <img class="math" src="../_images/math/6f28fd7539a56974612f2213cb591ec0a3a84dfa.svg" alt="f_H\pa{x}"/> au pixel <img class="math" src="../_images/math/cdd160a57af92571d6838c69c7bde600843a23bf.svg" alt="x"/> :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/89da891f3b8e707b7d971bcae862881797a35bf1.svg" alt="\hat{f}_H\pa{x} = \dfrac{1}{N} \; \sum_{i=1}^{N} \; \dfrac{1}{\det H} \; K\pa{ H^{-1} \pa{x - X_i}}"/></p>
</div></div>
<p>OÃ¹ :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/6bbe174691ee6154a0430ed381cf37c64c380bf4.svg" alt="K\pa{x} = \dfrac{1}{ \pa{2 \pi}^{ \frac{d}{2}} } \; e^{ - \frac{ \norme{x}^2 } {2} }"/></p>
</div></div>
<p><img class="math" src="../_images/math/dd8a8ece0b1684a9537eb7947dc6b8fdc1652abc.svg" alt="H"/> est un paramÃ¨tre estimÃ©e avec la rÃ¨gle de Silverman.
Lâexemple utilisÃ© dans cet article est un problÃ¨me de segmentation
dâimage qui ne peut pas Ãªtre rÃ©solu par la mÃ©thode des nuÃ©es
dynamiques puisque la forme des classes nâest pas convexe,
ainsi que le montre la figure suivante. La fonction de densitÃ©
<img class="math" src="../_images/math/bd1e0600a66dbe0f8deddbd57953774419ba4e4f.svg" alt="f"/> est seuillÃ©e de maniÃ¨re Ã  obtenir une fonction
<img class="math" src="../_images/math/2e01f937d0a2d8c83cc01e29112f51ce06b0a9a8.svg" alt="g : \mathbb{R}^n \longrightarrow \acc{0,1}"/> dÃ©finie par :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/93c93cd7cae65ced8e18c991415b215492d994bc.svg" alt="g \pa{x} = \indicatrice{f\pa{x} \supegal s}"/></p>
</div></div>
<p id="index-6">Lâensemble <img class="math" src="../_images/math/0ff3fd49f1428ac4a60756aa62ed347b7aa583ae.svg" alt="g^{-1}\pa{\acc{1}} \subset \mathbb{R}^n"/>
est composÃ©e de <img class="math" src="../_images/math/bceb9186b5004313ecccd0d22d07ea9617b62f98.svg" alt="N"/> composantes connexes notÃ©es
<img class="math" src="../_images/math/a20f10afa060e7ffe17e890961a8c5c514e607aa.svg" alt="\vecteur{C_1}{C_N}"/>, la classe dâun point <img class="math" src="../_images/math/cdd160a57af92571d6838c69c7bde600843a23bf.svg" alt="x"/>
est alors lâindice de la composante connexe Ã  la
laquelle il appartient ou la plus proche le cas Ã©chÃ©ant.</p>
<div class="table-wrapper colwidths-given docutils container">
<table class="docutils align-default">
<colgroup>
<col style="width: 50.0%" />
<col style="width: 50.0%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><img alt="../_images/herbin1.png" src="../_images/herbin1.png" />
</td>
<td><img alt="../_images/herbin2.png" src="../_images/herbin2.png" />
</td>
</tr>
</tbody>
</table>
</div>
<p>Exemple de classification non supervisÃ©e appliquÃ©e Ã  un problÃ¨me
de segmentation dâimage, la premiÃ¨re figure montre la densitÃ© obtenue,
la seconde figure illustre la classification obtenue, figure extraite de <a class="reference internal" href="#herbin2001" id="id10"><span>[Herbin2001]</span></a>.
Cette mÃ©thode paraÃ®t nÃ©anmoins difficilement applicable lorsque la
dimension de lâespace vectoriel atteint de grande valeur. Lâexemple de lâimage
est pratique, elle est dÃ©jÃ  dÃ©coupÃ©e en rÃ©gion reprÃ©sentÃ©es par les pixels,
lâensemble <img class="math" src="../_images/math/e86e25f9bcdebece2cacba7f08ce89fff5255162.svg" alt="g^{-1}\pa{\acc{1}}"/> correspond Ã 
lâensemble des pixels <img class="math" src="../_images/math/cdd160a57af92571d6838c69c7bde600843a23bf.svg" alt="x"/> pour lesquels <img class="math" src="../_images/math/f4fe0782fbd5a03d4b57fb70f83e9517bca8ed6b.svg" alt="f\pa{x} \supegal s"/>.</p>
</section>
<section id="decroissance-du-nombre-de-classes">
<h3>DÃ©croissance du nombre de classes<a class="headerlink" href="#decroissance-du-nombre-de-classes" title="Lien vers cette rubrique">Â¶</a></h3>
<p>Lâarticle <a class="reference internal" href="#kothari1999" id="id11"><span>[Kothari1999]</span></a> propose une mÃ©thode permettant de
faire dÃ©croÃ®tre le nombre de classes afin de choisir le nombre
appropriÃ©. Lâalgorithme des centres mobiles
proposent de faire dÃ©croÃ®tre lâinertie notÃ©e <img class="math" src="../_images/math/49d95c6215d3875f7504526ed066025568d9ebd7.svg" alt="I"/>
dÃ©finie pour un ensemble de points notÃ© <img class="math" src="../_images/math/c892e2c9602fd4163676454715101e9a50ce09f3.svg" alt="X = \vecteur{x_1}{x_N}"/>
et <img class="math" src="../_images/math/2c1a946cef5763c39269198f722873a239852f50.svg" alt="K"/> classes. La classe dâun Ã©lÃ©ment <img class="math" src="../_images/math/cdd160a57af92571d6838c69c7bde600843a23bf.svg" alt="x"/>
est notÃ©e <img class="math" src="../_images/math/95bf46381c090f66d5e98e0d3be6e029f6548726.svg" alt="C\pa{x}"/>. Les centres des classes sont notÃ©s
<img class="math" src="../_images/math/074ee5adf2cbdff1b8d7b0ead440d12636e4aabe.svg" alt="Y = \vecteur{y_1}{y_K}"/>.
Lâinertie de ce nuage de points est dÃ©finie par :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/31be75e9671bc62b1758455dbe298cb2252619fe.svg" alt="I  =  \sum_{x \in X} \; \norme{ x - y_{C\pa{x} }}^2"/></p>
</div></div>
<p>On dÃ©finit tout dâabord une distance
<img class="math" src="../_images/math/13c3eb42cca2ce046974c4ed3428301a4cd40db6.svg" alt="\alpha \in \mathbb{R}^+"/>, puis lâensemble
<img class="math" src="../_images/math/dc892b550e974eb952cdc4d80e45144376f5a924.svg" alt="V\pa{y,\alpha} = \acc{ z \in Y \sac d\pa{y,z} \leqslant \alpha }"/>,
<img class="math" src="../_images/math/28a053cbc22f90a9759293ff092729de4c8f1ba3.svg" alt="V\pa{y,\alpha}"/> est donc lâensemble des voisins des
centres dont la distance avec <img class="math" src="../_images/math/bd7dd5ee003cda2294a46fd47aa8a1ecf28b0418.svg" alt="y"/> est infÃ©rieur Ã  <img class="math" src="../_images/math/a1e7b66a55fc77cebd91d9a1ebfa93a29c1736fb.svg" alt="\alpha"/>.
Lâarticle <a class="reference internal" href="#kothari1999" id="id12"><span>[Kothari1999]</span></a> propose de minimiser le coÃ»t <img class="math" src="../_images/math/f3e6140f911171400bdaceb5d083d9209c5edcd3.svg" alt="J\pa{\alpha}"/>
suivant :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/90f2a125b6b5f85477afd3470a19e16b3101e243.svg" alt="J\pa{\alpha} = \sum_{x \in X} \; \norme{ x - y_{C\pa{x} }}^2 + \sum_{x \in X} \;
\sum_{y \in V\pa{y_{C\pa{x}}, \alpha} } \; \lambda\pa{y} \, \norme{ y -  y_{C\pa{x}}}^2"/></p>
</div></div>
<p>Lorsque <img class="math" src="../_images/math/a1e7b66a55fc77cebd91d9a1ebfa93a29c1736fb.svg" alt="\alpha"/> est nul, ce facteur est Ã©gal Ã  lâinertie :
<img class="math" src="../_images/math/4610cbefa0b0e891dffd33740d3ed6da052b0960.svg" alt="I = J\pa{0}"/> et ce terme est minimal lorsquâil y a autant de
classes que dâÃ©lÃ©ments dans <img class="math" src="../_images/math/b66c7d6c52c7b12bee7fb24d76c38fc70cfc0a2f.svg" alt="X"/>. Lorsque <img class="math" src="../_images/math/a1e7b66a55fc77cebd91d9a1ebfa93a29c1736fb.svg" alt="\alpha"/>
tend vers lâinfini, <img class="math" src="../_images/math/addb662507d13d8b52795a48d310f8ac82d303aa.svg" alt="J\pa{\alpha} \rightarrow J\pa{\infty}"/> oÃ¹ :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/d2ac8602353aef93ea590fe08b5d7744eedd8850.svg" alt="J\pa{\infty} = \sum_{x \in X} \; \norme{ x - y_{C\pa{x} }}^2 + \sum_{x \in X} \; \sum_{y \in Y} \;
\lambda\pa{y} \, \norme{ y -  y_{C\pa{x}}} ^2"/></p>
</div></div>
<p>Ici encore, il est possible de montrer que ce terme
<img class="math" src="../_images/math/7ac7481f42895412479c377e02d6ca83a3bb6eef.svg" alt="J\pa{\infty}"/> est minimal lorsquâil nâexiste plus quâune
seule classe. Le principe de cette mÃ©thode consiste Ã  faire varier
le paramÃ¨tre <img class="math" src="../_images/math/a1e7b66a55fc77cebd91d9a1ebfa93a29c1736fb.svg" alt="\alpha"/>, plus le paramÃ¨tre <img class="math" src="../_images/math/a1e7b66a55fc77cebd91d9a1ebfa93a29c1736fb.svg" alt="\alpha"/> augmente,
plus le nombre de classes devra Ãªtre rÃ©duit. NÃ©anmoins, il existe
des intervalles pour lequel ce nombre de classes est stable,
le vÃ©ritable nombre de classes de lâensemble <img class="math" src="../_images/math/b66c7d6c52c7b12bee7fb24d76c38fc70cfc0a2f.svg" alt="X"/>
sera considÃ©rÃ© comme celui correspondant au plus grand intervalle
stable.</p>
<div class="table-wrapper colwidths-given docutils container">
<table class="docutils align-default">
<colgroup>
<col style="width: 50.0%" />
<col style="width: 50.0%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><img alt="../_images/koth1.png" src="../_images/koth1.png" />
</td>
<td><img alt="../_images/koth2.png" src="../_images/koth2.png" />
</td>
</tr>
<tr class="row-even"><td><p><em>(a)</em></p></td>
<td><p><em>(b)</em></p></td>
</tr>
</tbody>
</table>
</div>
<p>Evolutation du nombre de classes en fonction du paramÃ¨tre <img class="math" src="../_images/math/a1e7b66a55fc77cebd91d9a1ebfa93a29c1736fb.svg" alt="\alpha"/> lors de la
minimisation du critÃ¨re <img class="math" src="../_images/math/f3e6140f911171400bdaceb5d083d9209c5edcd3.svg" alt="J\pa{\alpha}"/>, figure extraite de <a class="reference internal" href="#kothari1999" id="id13"><span>[Kothari1999]</span></a>.
La premiÃ¨re image reprÃ©sente le nuage de points illustrant quatre classes sans recouvrement.
La seconde image montre que quatre classes est lâÃ©tat le plus longtemps stable
lorsque <img class="math" src="../_images/math/a1e7b66a55fc77cebd91d9a1ebfa93a29c1736fb.svg" alt="\alpha"/> croÃ®t.</p>
<p id="index-7">Le coÃ»t <img class="math" src="../_images/math/f3e6140f911171400bdaceb5d083d9209c5edcd3.svg" alt="J\pa{\alpha}"/> est une somme de coÃ»t dont
lâimportance de lâun par rapport Ã  lâautre est contrÃ´le
par les paramÃ¨tres <img class="math" src="../_images/math/80afa851b8fd175808926b7332be30d5049ac387.svg" alt="\lambda\pa{y}"/>. Le problÃ¨me de
minimisation de <img class="math" src="../_images/math/f3e6140f911171400bdaceb5d083d9209c5edcd3.svg" alt="J\pa{\alpha}"/> est rÃ©solu par lâalgorithme qui suit.
Il sâappuie sur la mÃ©thode des multiplicateurs de Lagrange.</p>
<div class="admonition-mathdef admonition" id="indexmathe-Algorithme3">
<div class="docutils container">
</div>
<p class="admonition-title" id="classification-kothari-1999">Algorithme A4 : sÃ©lection du nombre de classes</p>
<p>(voir  <a class="reference internal" href="#kothari1999" id="id14"><span>[Kothari1999]</span></a>)
Les notations sont celles utilisÃ©s dans les paragraphes prÃ©cÃ©dents. On suppose que le
paramÃ¨tre <img class="math" src="../_images/math/a1e7b66a55fc77cebd91d9a1ebfa93a29c1736fb.svg" alt="\alpha"/> Ã©volue dans lâintervalle <img class="math" src="../_images/math/07a162d4ebb87d9aff1af094d5e7a401193212fb.svg" alt="\cro{\alpha_1, \alpha_2}"/>
Ã  intervalle rÃ©gulier <img class="math" src="../_images/math/b16448ae42ff1802844bc83136c27e139a1b4be6.svg" alt="\alpha_t"/>.
Le nombre initial de classes est notÃ© <img class="math" src="../_images/math/2c1a946cef5763c39269198f722873a239852f50.svg" alt="K"/> et il est supposÃ© surestimer le vÃ©ritable
nombre de classes. Soit <img class="math" src="../_images/math/0af93cb0b8d164e9534df19c3e33895aca887fe8.svg" alt="\eta \in \left]0,1\right["/>,
ce paramÃ¨tre doit Ãªtre choisi de telle sorte que dans
lâalgorithme qui suit, lâÃ©volution des centres <img class="math" src="../_images/math/785ba36534ec0d91ce856196476629c1d1f2715d.svg" alt="y_k"/>
soit autant assurÃ©e par le premier de la fonction de coÃ»t que par le second.</p>
<p><em>initialisation</em></p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/f73d5167f2b49ca17745dfed32ea3daa88001439.svg" alt="\alpha \longleftarrow \alpha_1"/></p>
</div></div>
<p>On tire alÃ©atoirement les centres des <img class="math" src="../_images/math/2c1a946cef5763c39269198f722873a239852f50.svg" alt="K"/> classes <img class="math" src="../_images/math/7a56d6c75a92645253c6ef84dd286840abdbf0fd.svg" alt="\vecteur{y_1}{y_K}"/>.</p>
<p><em>prÃ©paration</em></p>
<p>On dÃ©finit les deux suites entiÃ¨res <img class="math" src="../_images/math/bf703c0d5c7e771b938eb3394d199ff195365c09.svg" alt="\vecteur{c^1_1}{c^1_K}"/>, <img class="math" src="../_images/math/b0512fd7cd213cc45a3ff646ddf9b126de778c6e.svg" alt="\vecteur{c^2_1}{c^2_K}"/>,
et les deux suites de vecteur <img class="math" src="../_images/math/ab6bdf44db868b8f626a24676119e1fad6c8d884.svg" alt="\vecteur{z^1_1}{z^1_K}"/>,
<img class="math" src="../_images/math/433c8f9af7a82dd5c6bf2e59101ef85ff36c60c9.svg" alt="\vecteur{z^2_1}{z^2_K}"/>.</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/7162f87c88eebed2bf2ae5ed53d0248e9ac17a32.svg" alt="\begin{array}{rlll}
\forall k, &amp;  c^1_k &amp;=&amp; 0 \\
\forall k, &amp;  c^2_k &amp;=&amp; 0 \\
\forall k, &amp;  z^1_k &amp;=&amp; 0 \\
\forall k, &amp;  z^2_k &amp;=&amp; 0
\end{array}"/></p>
</div></div>
<p><em>calcul des mises Ã  jour</em></p>
<div class="line-block">
<div class="line">for i in <img class="math" src="../_images/math/e4d60e95747872a941338b80fe2b8a00b4b8429e.svg" alt="1..N"/></div>
<div class="line-block">
<div class="line">Mise Ã  jour dâaprÃ¨s le premier terme de la fonction de coÃ»t <img class="math" src="../_images/math/f3e6140f911171400bdaceb5d083d9209c5edcd3.svg" alt="J\pa{\alpha}"/>.</div>
<div class="line"><img class="math" src="../_images/math/3b1c4c170f7b983fa7961fa744400ca2572a8896.svg" alt="w \longleftarrow \underset{1 \leqslant l \leqslant K}{\arg \min} \; \norme{x_i - y_l}^2"/></div>
<div class="line"><img class="math" src="../_images/math/c62cc04a2a9e8462d3730bebf0d7a71c5fcffc4d.svg" alt="z^1_w \longleftarrow z^1_w + \eta \pa{ x_i - y_w}"/></div>
<div class="line"><img class="math" src="../_images/math/e0a900b1f252eca04a439fc8ba280471b0fe287f.svg" alt="c^1_w \longleftarrow c^1_w + 1"/></div>
<div class="line"><br /></div>
<div class="line">Mise Ã  jour dâaprÃ¨s le second terme de la fonction de coÃ»t <img class="math" src="../_images/math/f3e6140f911171400bdaceb5d083d9209c5edcd3.svg" alt="J\pa{\alpha}"/></div>
<div class="line"><br /></div>
<div class="line">for v in <img class="math" src="../_images/math/addc0166f989e29d1c798c0c5f3e67c87458d71e.svg" alt="1..k"/></div>
<div class="line-block">
<div class="line">if <img class="math" src="../_images/math/2ede1329c159e73f44a8ae9d888d916f15715dd1.svg" alt="\norme{y_v - y_w} &lt; \alpha"/></div>
<div class="line-block">
<div class="line"><img class="math" src="../_images/math/067f9f7794c24f4895d70674b56365d2f24bc3bf.svg" alt="z^2_v \longleftarrow z^2_v - \pa{ y_v - y_w}"/></div>
<div class="line"><img class="math" src="../_images/math/1dcc26f65780391461c4266fb214fc5bd5be7558.svg" alt="c^2_v \longleftarrow c^2_v + 1"/></div>
<div class="line"><br /></div>
</div>
</div>
<div class="line">for v in <img class="math" src="../_images/math/addc0166f989e29d1c798c0c5f3e67c87458d71e.svg" alt="1..k"/></div>
<div class="line-block">
<div class="line"><img class="math" src="../_images/math/7ec218064d0ff287b9e40bbecdc922096e4bdb2b.svg" alt="\lambda_v \longleftarrow \frac{ c^2_v \norme{z^1_v} } { c^1_v \norme{z^2_v} }"/></div>
<div class="line"><img class="math" src="../_images/math/b5a6888df5ed8b61a742f85268ce721f7e49e923.svg" alt="y_v \longleftarrow y_v + z^1_v + \lambda_v z^2_v"/></div>
</div>
</div>
</div>
<p><em>convergence</em></p>
<p>Tant que lâÃ©tape prÃ©cÃ©dente nâa pas convergÃ© vers une version stable des centres,
<img class="math" src="../_images/math/785ba36534ec0d91ce856196476629c1d1f2715d.svg" alt="y_k"/>, retour Ã  lâÃ©tape prÃ©cÃ©dente. Sinon, tous les couples de classes <img class="math" src="../_images/math/2fb092f228ae912a8b75d8fc2ad7929b84aa9483.svg" alt="\pa{i,j}"/>
vÃ©rifiant <img class="math" src="../_images/math/b98226fd74e5a8f077f4051c2c6afca781680b6d.svg" alt="\norme{y_i - y_j} &gt; \alpha"/> sont fusionnÃ©s :
<img class="math" src="../_images/math/49fd77d5a18fbf5909d5b71ab19a89b7fe6cceaa.svg" alt="\alpha \longleftarrow \alpha + \alpha_t"/>.
Si <img class="math" src="../_images/math/abf21c5bb300ba86be0818847d7349bc853a2085.svg" alt="\alpha \leqslant \alpha2"/>, retour Ã  lâÃ©tape de prÃ©paration.</p>
<p><em>terminaison</em></p>
<p>Le nombre de classes est celui ayant prÃ©valu pour le plus grand nombre de valeur de <img class="math" src="../_images/math/a1e7b66a55fc77cebd91d9a1ebfa93a29c1736fb.svg" alt="\alpha"/>.</p>
</div>
</section>
</section>
<section id="extension-des-nuees-dynamiques">
<h2>Extension des nuÃ©es dynamiques<a class="headerlink" href="#extension-des-nuees-dynamiques" title="Lien vers cette rubrique">Â¶</a></h2>
<section id="classes-elliptiques">
<span id="classification-nuees-dynamique-extension"></span><h3>Classes elliptiques<a class="headerlink" href="#classes-elliptiques" title="Lien vers cette rubrique">Â¶</a></h3>
<p id="index-8">La version de lâalgorithme des nuÃ©es dynamique proposÃ©e dans lâarticle
<a class="reference internal" href="#cheung2003" id="id15"><span>[Cheung2003]</span></a> suppose que les classes ne sont plus de forme circulaire
mais suivent une loi normale quelconque. La loi de lâÃ©chantillon
constituant le nuage de points est de la forme :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/37adf413e36e8b14c77a742988f64916af67c86c.svg" alt="f\pa{x} =  \sum_{i=1}^{N} \; p_i \; \dfrac{1}{\pa{2 \pi}^{\frac{d}{2}}\sqrt{\det \Sigma_i}} \; exp \pa{-\frac{1}{2}  \pa{x-\mu_i}' \Sigma_i^{-1} \pa{x-\mu_i} }"/></p>
</div></div>
<p>Avec <img class="math" src="../_images/math/f3e0f7f4cefff66c9c97898243d62b1862457ed8.svg" alt="sum_{i=1}^{N} \; p_i = 1"/>. On dÃ©finit :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/46b7df49a10e3ed7d44f05ed384524a85f13806f.svg" alt="G\pa{x, \mu, \Sigma} = \dfrac{1}{\pa{2 \pi}^{\frac{d}{2}}\sqrt{\det \Sigma}} \; exp \pa{-\frac{1}{2}  \pa{x-\mu}' \Sigma^{-1} \pa{x-\mu} }"/></p>
</div></div>
<p>Lâalgorithme qui suit a pour objectif de minimiser la quantitÃ© pour un Ã©chantillon <img class="math" src="../_images/math/7ccf5fe9b0a4a7c90908c020c8f6660232583105.svg" alt="\vecteur{X_1}{X_K}"/> :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/e2326fe991e74a547e28a1e9ede8696d83c28748.svg" alt="I = \sum_{i=1}^{N}\sum_{k=1}^{K} \indicatrice{ i = \underset{1 \leqslant j \leqslant N}{\arg \max}
G\pa{X_k, \mu_j,\Sigma_j} } \; \ln \cro{ p_i G\pa{ X_k, \mu_i, \Sigma_i } }"/></p>
</div></div>
<div class="admonition-mathdef admonition" id="indexmathe-Algorithme4">
<p class="admonition-title">Algorithme A5 : nuÃ©es dynamiques gÃ©nÃ©ralisÃ©es</p>
<p>Les notations sont celles utilisÃ©es dans ce paragraphe. Soient <img class="math" src="../_images/math/b3b84fabe7c42a7e9b77253ea0d56f2812634ba8.svg" alt="\eta"/>,
<img class="math" src="../_images/math/17d10a5a2c9e2139752a8ebb8c733ccc29293c20.svg" alt="\eta_s"/> deux rÃ©els tels que <img class="math" src="../_images/math/b864139223cc8bcb51ff3c36ddcaadc00d1949af.svg" alt="\eta &gt; \eta_s"/>.
La rÃ¨gle prÃ©conisÃ©e par lâarticle <a class="reference internal" href="#cheung2003" id="id16"><span>[Cheung2003]</span></a> est <img class="math" src="../_images/math/277952fbe124fd0ff6a3174af75c663c6d97301b.svg" alt="\eta_s \sim \frac{\eta}{10}"/>.</p>
<p><em>initialisation</em></p>
<p><img class="math" src="../_images/math/b00a80936656de39ddcaf3e556b63da3145c2258.svg" alt="t \longleftarrow 0"/>.
Les paramÃ¨tres <img class="math" src="../_images/math/6f74fcc5b52fb38700a749f3b8c7d14a9ff1e0e8.svg" alt="\acc{p_i^0, \mu_i^0, \Sigma_i^0 \sac 1 \leqslant i \leqslant N}"/> sont initialisÃ©s
grÃ¢ce Ã  un algorithme des <a class="reference internal" href="#kmeans-def-algo"><span class="std std-ref">k-means</span></a> ou <a class="reference internal" href="#label-kmeans-fscl"><span class="std std-ref">FSCL</span></a>.
<img class="math" src="../_images/math/5efb9b8bac01ce9912371bc225e335d9061c92bd.svg" alt="\forall i, \; p_i^0 = \frac{1}{N}"/> et <img class="math" src="../_images/math/c57eeb0a88c2d9caceb75b59901b834fae2d15c5.svg" alt="\beta_i^0 = 0"/>.</p>
<p><em>rÃ©currence</em></p>
<p>Soit <img class="math" src="../_images/math/a64fc33c15255329b8e9309a9a44e1e0f012f72f.svg" alt="X_k"/> choisi alÃ©atoirement dans <img class="math" src="../_images/math/7ccf5fe9b0a4a7c90908c020c8f6660232583105.svg" alt="\vecteur{X_1}{X_K}"/>.</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/359a2863f521bcd2920d7821b53f4794b53af19e.svg" alt="i = \underset{1 \leqslant i \leqslant N}{\arg \min} \; G\pa{X_k, \mu_i^t, \Sigma_i^t}"/></p>
</div></div>
<div class="line-block">
<div class="line">for i in <img class="math" src="../_images/math/e4d60e95747872a941338b80fe2b8a00b4b8429e.svg" alt="1..N"/></div>
<div class="line-block">
<div class="line"><img class="math" src="../_images/math/adb57abc9603e0235b766603a17c83819d695994.svg" alt="\mu_i^{t+1} = \mu_i^t + \eta \, \pa{\Sigma_i^t}^{-1} \, \pa{ X_k - \mu_i^t}"/></div>
<div class="line"><img class="math" src="../_images/math/8f35e78c82f2656e410a45a49e6d57c2dd541fc7.svg" alt="\beta_i^{t+1} = \beta_i^t + \eta \, \pa{1 - \alpha_i^t}"/></div>
<div class="line"><img class="math" src="../_images/math/fa5968afec024ee9b3edd0a37ca365633ea6ee75.svg" alt="\Sigma^{t+1}_i = \pa{1 - \eta_s} \, \Sigma_i^t + \eta_s \, \pa{ X_k - \mu_i^t} \pa{ X_k - \mu_i^t}'"/></div>
<div class="line"><br /></div>
</div>
<div class="line">for i in <img class="math" src="../_images/math/e4d60e95747872a941338b80fe2b8a00b4b8429e.svg" alt="1..N"/></div>
<div class="line-block">
<div class="line"><img class="math" src="../_images/math/d7f1de0bc9afbff6a3bcf3d3bb37151cd1affc46.svg" alt="p^{t+1}_i = \frac{ e^{ \beta_i^{t+1} } } { \sum_{j=1}^{N} e^{ \beta_j^{t+1} } }"/></div>
<div class="line"><br /></div>
</div>
<div class="line"><img class="math" src="../_images/math/c38192a0bf7fc25d58110b59ec881f89dae27bb7.svg" alt="t \longleftarrow t + 1"/></div>
</div>
<p><em>terminaison</em></p>
<p>Tant que <img class="math" src="../_images/math/92b1a4195bd55fb0d3d3aee34e54522e81b9374d.svg" alt="\underset{1 \leqslant i \leqslant N}{\arg \min} \; G\pa{X_k, \mu_i^t, \Sigma_i^t}"/>
change pour au moins un des points <img class="math" src="../_images/math/a64fc33c15255329b8e9309a9a44e1e0f012f72f.svg" alt="X_k"/>.</p>
</div>
<p>Lors de la mise Ã  jour de <img class="math" src="../_images/math/101365d041befcd5108977fd092dbd8bc9785dbc.svg" alt="\Sigma^{-1}"/>,
lâalgorithme prÃ©cÃ©dent propose la mise Ã  jour de <img class="math" src="../_images/math/7db6957ff4e3716bec2334044990cfc332851bb9.svg" alt="\Sigma_i"/>
alors que le calcul de <img class="math" src="../_images/math/74fe222dfce78c1d224c9499b08b7c11c849db18.svg" alt="G\pa{., \mu_i, \Sigma_i}"/>
implique <img class="math" src="../_images/math/83b454fbaf2d869cc101169851dfa6d12333aad5.svg" alt="\Sigma_i^{-1}"/>,
par consÃ©quent, il est prÃ©fÃ©rable de mettre Ã  jour directement la matrice
<img class="math" src="../_images/math/101365d041befcd5108977fd092dbd8bc9785dbc.svg" alt="\Sigma^{-1}"/> :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/e7c86991000483459e58075e1e136f6ed27ba59f.svg" alt="\pa{\Sigma^{t+1}_i}^{-1} = \frac{ \pa{\Sigma_i^t}^{-1} } {1 - \eta_s}
\cro{I - \frac{ \eta_s  \pa{ X_k - \mu_i^t} \pa{ X_k - \mu_i^t}' \pa{\Sigma_i^t}^{-1} }
{1 - \eta_s + \eta_s \pa{ X_k - \mu_i^t}' \, \pa{\Sigma_i^t}^{-1}\pa{ X_k - \mu_i^t} } }"/></p>
</div></div>
</section>
<section id="rival-penalized-competitive-learning-rpcl">
<span id="class-rpcl"></span><h3>Rival Penalized Competitive Learning (RPCL)<a class="headerlink" href="#rival-penalized-competitive-learning-rpcl" title="Lien vers cette rubrique">Â¶</a></h3>
<p id="index-9">Lâalgorithme suivant dÃ©veloppÃ© dans <a class="reference internal" href="#xu1993" id="id17"><span>[Xu1993]</span></a>, est une variante de celui des centres mobiles.
Il entreprend Ã  la fois la classification et la sÃ©lection du nombre optimal de classes Ã  condition
quâil soit infÃ©rieur Ã  une valeur maximale Ã  dÃ©terminer au dÃ©part de lâalgorithme.
Un mÃ©canisme permet dâÃ©loigner les centres des classes peu pertinentes
de sorte quâaucun point ne leur sera affectÃ©.</p>
<div class="admonition-mathdef admonition" id="indexmathe-Algorithme5">
<div class="docutils container">
</div>
<p class="admonition-title" id="classif-algo-rpcl">Algorithme A6 : RPCL</p>
<p>Soient <img class="math" src="../_images/math/26f924af3662c85fdae93b78379cf709640d2119.svg" alt="\vecteur{X_1}{X_N}"/>, <img class="math" src="../_images/math/bceb9186b5004313ecccd0d22d07ea9617b62f98.svg" alt="N"/> vecteurs Ã  classer en au
plus <img class="math" src="../_images/math/6cf1fdb1c46f5cefb926a2b20ec9dd4a481dd11d.svg" alt="T"/> classes de centres <img class="math" src="../_images/math/fb3d517c4eeb65cce6c34dfc9b7dc7089292995d.svg" alt="\vecteur{C_1}{C_T}"/>.
Soient deux rÃ©els <img class="math" src="../_images/math/03b31e7dea339fc978bc9c23c1cae7daa6bd2615.svg" alt="\alpha_r"/> et <img class="math" src="../_images/math/5f6da0c05eb3c25ba2397c23d2086b3f9dc39501.svg" alt="\alpha_c"/>
tels que <img class="math" src="../_images/math/fd93c6698c67f35e2a22cb1c7a6803db2576461a.svg" alt="0 &lt; \alpha_r \ll \alpha_c &lt; 1"/>.</p>
<p><em>initialisation</em></p>
<p>Tirer alÃ©atoirement les centres <img class="math" src="../_images/math/fb3d517c4eeb65cce6c34dfc9b7dc7089292995d.svg" alt="\vecteur{C_1}{C_T}"/>.</p>
<div class="line-block">
<div class="line">for j in <img class="math" src="../_images/math/f963c7631cb87c320d1687686f34c5e48b508b2d.svg" alt="1..C"/></div>
<div class="line-block">
<div class="line"><img class="math" src="../_images/math/625febfb4c1fa41b81a2a7ca2f2786fd0752f4ee.svg" alt="n_j^0 \longleftarrow 1"/></div>
</div>
</div>
<p><em>calcul de poids</em></p>
<p>Choisir alÃ©atoirement un point <img class="math" src="../_images/math/c15b262677ad7177c2e37298a2eb382d712b3a52.svg" alt="X_i"/>.</p>
<div class="line-block">
<div class="line">for j in <img class="math" src="../_images/math/f963c7631cb87c320d1687686f34c5e48b508b2d.svg" alt="1..C"/></div>
<div class="line-block">
<div class="line"><img class="math" src="../_images/math/819208f885e89ffcd0fd93ab5fd1ef848907e5c7.svg" alt="\gamma_j = \dfrac{n_j}{ \sum_{k=1}^{C} n_k}"/></div>
<div class="line"><br /></div>
</div>
<div class="line">for j in <img class="math" src="../_images/math/f963c7631cb87c320d1687686f34c5e48b508b2d.svg" alt="1..C"/></div>
<div class="line-block">
<div class="line"><img class="math" src="../_images/math/1b39f5dac1c02fc3e0eae94c98dfb253f39bf2d7.svg" alt="u_j ="/></div>
<div class="line-block">
<div class="line">1 si <img class="math" src="../_images/math/fbf3eb686a733e9b53bcd0d32bc83cef97f55e13.svg" alt="j \in \underset{k}{\arg \min} \; \cro {\gamma_k \; d\pa{X_i,C_k} }"/></div>
<div class="line">-1 si <img class="math" src="../_images/math/d01fb1b2ebcf432016cb3bd7de5fb0fe0a7a6107.svg" alt="j \in \underset{j \neq k}{\arg \min} \; \cro {\gamma_k \; d\pa{X_i,C_k} }"/></div>
<div class="line">0 sinon</div>
</div>
</div>
</div>
<p><em>mise Ã  jour</em></p>
<div class="line-block">
<div class="line">for j in <img class="math" src="../_images/math/f963c7631cb87c320d1687686f34c5e48b508b2d.svg" alt="1..C"/></div>
<div class="line-block">
<div class="line"><img class="math" src="../_images/math/09dd9c63a737d007f778fad69a9eefc45afbf503.svg" alt="C_j^{t+1} \longleftarrow  C_j^t +  \left \{ \begin{array}{ll} \alpha_c \pa{X_i - C_j} &amp; \text{si } u_j = 1 \\ - \alpha_r \pa{X_i - C_j} &amp; \text{si } u_j = -1 \\ 0 &amp; \text{sinon} \end{array} \right."/></div>
<div class="line"><img class="math" src="../_images/math/71536267e1787bbc8916f6f2124324fce9b3b850.svg" alt="n_j^t +  \left \{ \begin{array}{ll} 1 &amp; \text{si } u_j = 1 \\ 0 &amp; \text{sinon} \end{array} \right."/></div>
<div class="line"><br /></div>
</div>
<div class="line"><img class="math" src="../_images/math/02dd178e61d85f10a2824b1cd98c269269370b59.svg" alt="t \longleftarrow t+1"/></div>
</div>
<p><em>terminaison</em></p>
<p>Sâil existe un indice <img class="math" src="../_images/math/c2ca7da683b1e0aa549bb4675efbd6008c4ffa6e.svg" alt="j"/> pour lequel <img class="math" src="../_images/math/c4d5551f26826df6ec17ca781fc2a10021174733.svg" alt="C^{t+1}_j \neq C^t_j"/>
alors retourner Ã   lâÃ©tape de calcul de poids ou que les centres des classes jugÃ©es inutiles
ont Ã©tÃ© repoussÃ©s vers lâinfini.</p>
</div>
<p>Pour chaque point, le centre de la classe la plus proche en est rapprochÃ©
tandis que le centre de la seconde classe la plus proche en est Ã©loignÃ©
mais dâune faÃ§on moins importante (condition <img class="math" src="../_images/math/eeaffc9e6b3b9543f3086f2664cb223ac3fba57a.svg" alt="\alpha_r \ll \alpha_c"/>).
AprÃ¨s convergence, les centres des classes inutiles ou non pertinentes
seront repoussÃ©s vers lâinfini. Par consÃ©quent, aucun point nây sera rattachÃ©.</p>
<p>Lâalgorithme doit Ãªtre lancÃ© plusieurs fois. Lâalgorithme RPCL peut terminer
sur un rÃ©sultat comme celui de la figure suivante oÃ¹ un centre reste coincÃ©
entre plusieurs autres. Ce problÃ¨me est moins important
lorsque la dimension de lâespace est plus grande.</p>
<img alt="../_images/class6.png" src="../_images/class6.png" />
<p>Application de lâalgorithme <a class="reference internal" href="#classif-algo-rpcl"><span class="std std-ref">RPCL</span></a> : la classe 0 est incrustÃ© entre les quatre autres
et son centre ne peut se Â«Â faufilerÂ Â» vers lâinfini.</p>
</section>
<section id="rpcl-based-local-pca">
<span id="classification-rpcl-local-pca"></span><h3>RPCL-based local PCA<a class="headerlink" href="#rpcl-based-local-pca" title="Lien vers cette rubrique">Â¶</a></h3>
<p id="index-10">Lâarticle <a class="reference internal" href="#liu2003" id="id18"><span>[Liu2003]</span></a> propose une extension de lâalgorithme <a class="reference internal" href="#classif-algo-rpcl"><span class="std std-ref">RPCL</span></a>
et suppose que les classes ne sont plus de forme circulaire mais
suivent une loi normale quelconque. Cette mÃ©thode est utilisÃ©e pour
la dÃ©tection de ligne considÃ©rÃ©es ici comme des lois normales dÃ©gÃ©nÃ©rÃ©es
en deux dimensions, la matrice de covariance dÃ©finit une ellipse dont le
grand axe est trÃ¨s supÃ©rieur au petit axe, ce que montre la figure suivante.
Cette mÃ©thode est aussi prÃ©sentÃ©e comme un possible algorithme de squelettisation.</p>
<img alt="../_images/liu3.png" src="../_images/liu3.png" />
<p>Figure extraite de <a class="reference internal" href="#liu2003" id="id19"><span>[Liu2003]</span></a>, lâalgorithme est utilisÃ© pour la dÃ©tection de lignes
considÃ©rÃ©es ici comme des lois normales dont la matrice de covariance dÃ©finit une ellipse
dÃ©gÃ©nÃ©rÃ©e dont le petit axe est trÃ¨s infÃ©rieur au grand axe. Les traits fin grisÃ©s correspondent aux
classes isolÃ©es par lâalgorithme RPCL-based local PCA.</p>
<p>On modÃ©lise le nuage de points par une mÃ©lange de lois normales :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/09d3deb3f6ba3f5d925b5e79e6ff9e9b53c81ff6.svg" alt="f\pa{x} =  \sum_{i=1}^{N} \; p_i \; \dfrac{1}{\pa{2 \pi}^{\frac{d}{2}}\sqrt{\det \Sigma_i}} \;
exp \pa{-\frac{1}{2}  \pa{x-\mu_i}' \Sigma_i^{-1} \pa{x-\mu_i} }"/></p>
</div></div>
<p>Avec <img class="math" src="../_images/math/4818fb2d6e00bee968d65982434c0e7c0bfbe18d.svg" alt="\sum_{i=1}^{N} \; p_i = 1"/>.</p>
<p>On suppose que le nombre de classes initiales <img class="math" src="../_images/math/bceb9186b5004313ecccd0d22d07ea9617b62f98.svg" alt="N"/> surestime le
vÃ©ritable nombre de classes. Lâarticle <a class="reference internal" href="#liu2003" id="id20"><span>[Liu2003]</span></a> sâintÃ©resse
au cas particulier oÃ¹ les matrices de covariances vÃ©rifient
<img class="math" src="../_images/math/09871a20d40f17cc98971443d3a19c487934fddc.svg" alt="\Sigma_i = \zeta_i \, I + \sigma_i \, \phi_i \phi_i'"/>
avec <img class="math" src="../_images/math/198b07e64fd2fa4750aa3695b2ea2b3fb5dae3a1.svg" alt="\zeta_i &gt; 0, \; \sigma_i &gt; 0, \; \phi_i' \phi_i = 1"/>.</p>
<p>On dÃ©finit Ã©galement :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/6eb7b1bb68207926c1af7e42158c8d6a1ebc03f6.svg" alt="G\pa{x, \mu, \Sigma} = \dfrac{1}{\pa{2 \pi}^{\frac{d}{2}}\sqrt{\det \Sigma}} \;
exp \pa{-\frac{1}{2}  \pa{x-\mu}' \Sigma^{-1} \pa{x-\mu} }"/></p>
</div></div>
<p>Lâalgorithme utilisÃ© est similaire Ã  lâalgortihme <a class="reference internal" href="#classif-algo-rpcl"><span class="std std-ref">RPCL</span></a>.
La distance <img class="math" src="../_images/math/2160a217243173398700954f681412f83f781a6e.svg" alt="d"/> utilisÃ©e lors de lâÃ©tape de calcul des poids
afin de trouver la classe la plus probable pour un point
donnÃ© <img class="math" src="../_images/math/a64fc33c15255329b8e9309a9a44e1e0f012f72f.svg" alt="X_k"/> est remplacÃ©e par lâexpression :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/c0d6806ed4c76aea403828810c79d39ef322687a.svg" alt="d\pa{X_k, classe \, i} = - \ln { p_i^t \, G\pa{X_k, \, \mu_i^t, \, \Sigma^t_i } }"/></p>
</div></div>
<p>LâÃ©tape de mise Ã  jour des coefficients est remplacÃ©e par :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/f952370525f7703ca7254c74428d36b69e5dd027.svg" alt="x^{t+1} \longleftarrow  x^t +  \left \{ \begin{array}{ll}
\alpha_c \nabla x^t &amp; \text{si } u_j = 1 \\
- \alpha_r \nabla x^t &amp; \text{si } u_j = -1 \\
0 &amp; \text{sinon}
\end{array} \right."/></p>
</div></div>
<p>OÃ¹ <img class="math" src="../_images/math/4171408fcfbe97daea34f08aef4aac37520717b1.svg" alt="x^t"/> joue le rÃ´le dâun paramÃ¨tre et est remplacÃ©
successivement par <img class="math" src="../_images/math/77d7f28937206f8e34b8b96b0d0d264c9facca66.svg" alt="p_i^t"/>, <img class="math" src="../_images/math/6ed63b7beea15877e6ba7cec114276350657dae1.svg" alt="\mu_i^t"/>, <img class="math" src="../_images/math/e9a905eb88b274112b4100f00439e1cc973868d8.svg" alt="\zeta_i^t"/>, <img class="math" src="../_images/math/4863314ea214002f4ff7fd2f783a5e672ebe6239.svg" alt="\sigma^t_i"/>, <img class="math" src="../_images/math/99f29dadea043e5b60520a183519551ba589eb98.svg" alt="\phi^t_i"/> :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/bb1785385e15b2920550c06d3826dba61d478d70.svg" alt="\begin{array}{lll}
\nabla p_i^t &amp;=&amp; - \frac{1}{p_i^t} \\
\nabla \mu_i^t &amp;=&amp; - \pa{ X_k - \mu_i^t} \\
\nabla \zeta_i^t  &amp;=&amp; \frac{1}{2} \; tr\cro{ \pa{\Sigma_i^t}^{-1} \,
\pa{ I - \pa{ X_k - \mu_i^t} \pa{ X_k - \mu_i^t}' \pa{\Sigma_i^t}^{-1} } } \\
\nabla \sigma_i^t &amp;=&amp;    \frac{1}{2} \; \pa{\phi_i^t}' \pa{\Sigma_i^t}^{-1}
\pa{ I - \pa{ X_k - \mu_i^t} \pa{ X_k - \mu_i^t}' \pa{\Sigma_i^t}^{-1} } \phi_i^t \\
\nabla \phi_i^t     &amp;=&amp;    \sigma_i^t \pa{\Sigma_i^t}^{-1}
\pa{ I - \pa{ X_k - \mu_i^t} \pa{ X_k - \mu_i^t}' \pa{\Sigma_i^t}^{-1} } \phi_i^t \\
\end{array}"/></p>
</div></div>
</section>
<section id="frequency-sensitive-competitive-learning-fscl">
<span id="label-kmeans-fscl"></span><h3>Frequency Sensitive Competitive Learning (FSCL)<a class="headerlink" href="#frequency-sensitive-competitive-learning-fscl" title="Lien vers cette rubrique">Â¶</a></h3>
<p id="index-11">Lâalgorithme Frequency Sensitive Competitive Learning est prÃ©sentÃ© dans
<a class="reference internal" href="#balakrishnan1996" id="id21"><span>[Balakrishnan1996]</span></a>. Par rapport Ã  lâalgorithme des centres mobiles classique,
lors de lâestimation des centres des classes, lâalgorithme Ã©vite la formation de classes sous-reprÃ©sentÃ©es.</p>
<div class="admonition-mathdef admonition" id="indexmathe-Algorithme6">
<div class="docutils container">
</div>
<p class="admonition-title" id="classification-fscl">Algorithme A7 : FSCL</p>
<p>Soit un nuage de points <img class="math" src="../_images/math/26f924af3662c85fdae93b78379cf709640d2119.svg" alt="\vecteur{X_1}{X_N}"/>,
soit <img class="math" src="../_images/math/2c0e77bc741b692ecdf6e85966263a89422af4c8.svg" alt="C"/> vecteurs <img class="math" src="../_images/math/006dd3f24de01449dca0eca6514bdde697fc8cb3.svg" alt="\vecteur{\omega_1}{\omega_C}"/>
initialisÃ©s de maniÃ¨re alÃ©atoires.
Soit <img class="math" src="../_images/math/3302dd9d46486c64dd86a47b65df645d5258bcce.svg" alt="F : \pa{u,t} \in \mathbb{R}^2 \longrightarrow \mathbb{R}^+"/>
croissante par rapport Ã  <img class="math" src="../_images/math/3ded7c5accc3db646e5a061facda1aef616d548f.svg" alt="u"/>.
Soit une suite de rÃ©els <img class="math" src="../_images/math/aff557df7578eefb5dca5b59e3147960acf07f7c.svg" alt="\vecteur{u_1}{u_C}"/>,
soit une suite <img class="math" src="../_images/math/712de58615936cdf87cfd5b1c5f017bccc7ea9f8.svg" alt="\epsilon\pa{t} \in \cro{0,1}"/> dÃ©croissante oÃ¹ <img class="math" src="../_images/math/09c7628f51842c683db31bd6826cff8cc447ece3.svg" alt="t"/>
reprÃ©sente le nombre dâitÃ©rations.
Au dÃ©but <img class="math" src="../_images/math/06589e14407f2f6b63d16767dd96125304b98dd7.svg" alt="t \leftarrow 0"/>.</p>
<p><em>meilleur candidat</em></p>
<p>Pour un vecteur <img class="math" src="../_images/math/a64fc33c15255329b8e9309a9a44e1e0f012f72f.svg" alt="X_k"/> choisi alÃ©atoirement dans
lâensemble <img class="math" src="../_images/math/26f924af3662c85fdae93b78379cf709640d2119.svg" alt="\vecteur{X_1}{X_N}"/>, on dÃ©termine :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/be7749778fe4c36c60c7283bc5a0089c4938a94c.svg" alt="i^* \in \arg \min \acc{ D_i = F\pa{u_i,t} \, d\pa{X_k, \omega_i} }"/></p>
</div></div>
<p><em>mise Ã  jour</em></p>
<div class="line-block">
<div class="line"><img class="math" src="../_images/math/71df14eb8e9a48aa4aaa710d7ca820442aa71819.svg" alt="\omega_{i^*} \pa{t+1}  \longleftarrow \omega_{i^*} \pa{t} + \epsilon\pa{t} \pa { X_k - \omega_{i^*} \pa{t} }"/></div>
<div class="line"><img class="math" src="../_images/math/02dd178e61d85f10a2824b1cd98c269269370b59.svg" alt="t \longleftarrow t+1"/></div>
<div class="line"><img class="math" src="../_images/math/eb010d3f7364d6bab102b761d4b112de022f29e6.svg" alt="u_{i^*} \longleftarrow u_{i^*} + 1"/></div>
</div>
<p>Retour Ã  lâÃ©tape prÃ©cÃ©dente jusquâÃ  ce que les nombres
<img class="math" src="../_images/math/dda6a76e26fd07cf6c368a3365438c65050f34a5.svg" alt="\frac{u_i}{\sum_{i}u_i}"/> convergent.</p>
</div>
<p>Exemple de fonctions pour <img class="math" src="../_images/math/d3df781b97caf23fd84697ec8aac41efdf4f6793.svg" alt="F"/>, <img class="math" src="../_images/math/5d07e66e6e9d55b1dd504ca14a3d870dfe30fb29.svg" alt="\epsilon"/> (voir <a class="reference internal" href="#balakrishnan1996" id="id22"><span>[Balakrishnan1996]</span></a>) :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/c97dd7bb1f54357b2f271b937b03dfe3bd886d4e.svg" alt="\begin{eqnarray*}
F\pa{u,t} &amp;=&amp; u \, \beta e^{-t/T} \text{ avec } \beta = 0,06 \text{ et } 1/T = 0,00005 \\
\epsilon\pa{t} &amp;=&amp; \beta \, e^{ - \gamma t } \text{ avec } \gamma = 0,05
\end{eqnarray*}"/></p>
</div></div>
<p>Cet algorithme ressemble Ã  celui des cartes topographiques de Kohonen
sans toutefois utiliser un maillage entre les neurones
(ici les vecteurs <img class="math" src="../_images/math/ce439c3bf6e8d427634dd59f969b64429819b464.svg" alt="\omega_i"/>). Contrairement Ã  lâalgorithme RPCL,
les neurones ne sont pas repoussÃ©s sâils ne sont pas choisis mais la fonction
croissante <img class="math" src="../_images/math/d6ee29fc5b0000217692b3fe96efde422a6c371a.svg" alt="F\pa{u,t}"/> par rapport Ã  <img class="math" src="../_images/math/3ded7c5accc3db646e5a061facda1aef616d548f.svg" alt="u"/> assure que plus un neurone
est sÃ©lectionnÃ©, moins il a de chance de lâÃªtre,
bien que cet avantage disparaisse au fur et Ã  mesure des itÃ©rations.</p>
</section>
</section>
<section id="k-means-norme-l1">
<h2>k-means norme L1<a class="headerlink" href="#k-means-norme-l1" title="Lien vers cette rubrique">Â¶</a></h2>
<p>Lâalgorithme dans sa version la plus courante optimise lâinertie dÃ©finie
par <img class="math" src="../_images/math/40bbc182fe555c7e5da694e0535ddc2b0adb23ee.svg" alt="\sum_{i=1}^P \; d^2\left(X_i, G_{c_i^t}^t\right)"/>, qui est
en quelque sorte une inertie <em>L2</em>. Que devriendrait lâalgorithme
si la norme choisie Ã©tait une norme <em>L1</em>, il faudrait alors choisir
Ã  chaque itÃ©ration <em>t</em> des <em>points</em> qui minimise la quantitÃ© :
<img class="math" src="../_images/math/ba04609461dc2d5ca073ac714d021b17b621180b.svg" alt="\sum_{i=1}^P \; d_1\left(X_i, G_{c_i^t}^t\right)"/> oÃ¹
<img class="math" src="../_images/math/dba54403216e84bb9f17c788e3602a282932af16.svg" alt="d_1"/> est la norme <em>L1</em> entre deux points <em>X,Y</em> :
<img class="math" src="../_images/math/e2762704c8e87d7119880487281a3baf9559b381.svg" alt="d_1(X, Y) = \sum_i |X_i - Y_i|"/>. Avant de continuer,
on rappelle un thÃ©orÃ¨me :</p>
<div class="admonition-mathdef admonition" id="indexmathe-propriÃ©tÃ©0">
<div class="docutils container">
</div>
<p class="admonition-title" id="mediane-l1">propriÃ©tÃ© P1 : MÃ©diane et valeur absolue</p>
<p>Soit <img class="math" src="../_images/math/b403da094d28e0106b06efe11a8771d61757252e.svg" alt="A=(x_1, ..., x_n)"/> un ensembl de <em>n</em> rÃ©els quelconque.
On note <img class="math" src="../_images/math/414fe48e1d982fcdb0d024ae5192bfa6a5553663.svg" alt="m=med(x_1, ..., x_n)"/> la mÃ©diane
de lâensemble de points <em>A</em>. Alors la mÃ©diane <em>m</em>
minimise la quantitÃ© <img class="math" src="../_images/math/ed2739077602d2045deb89d56b9de19f197c0e14.svg" alt="\sum_{i=1}^n |m-x_i|"/>.</p>
</div>
<p>Câest cette propriÃ©tÃ© qui est utilisÃ©e pour dÃ©finir ce quâest
la <a class="reference internal" href="../c_ml/regression_quantile.html#l-reg-quantile"><span class="std std-ref">rÃ©gression quantile</span></a> et sa dÃ©monstration
est prÃ©sentÃ©e Ã  la page <a class="reference internal" href="../c_ml/regression_quantile.html#l-reg-quantile-demo"><span class="std std-ref">MÃ©diane et valeur absolue</span></a>. Il ne reste
plus quâÃ  se servir de ce rÃ©sultat pour mettre Ã  jour lâalgorithme
<a class="reference internal" href="#kmeans-def-algo"><span class="std std-ref">centre mobile, k-means</span></a>. LâÃ©tape qui
consiste Ã  affecter un point Ã  un cluster reprÃ©sentÃ© par un point
ne pose pas de problÃ¨me si on utilise cette nouvelle norme. Il ne reste
plus quâÃ  dÃ©terminer le point qui reprÃ©sente un cluster sachant
les points qui le constituent. Autrement dit, il faut dÃ©terminer
le point qui minimiser la pseudo-inertie dÃ©finie comme suit
pour un ensemble de points <img class="math" src="../_images/math/bfe5330a47312509984b1f7abf71fd221d3d8dc1.svg" alt="(X_1, ..., X_n)"/> appartenant Ã  un
espace vectoriel de dimension <em>k</em>.</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../_images/math/33584f87f2dfdf574e2906c428e43546e5672afc.svg" alt="I(G,X_1,...,X_n) = \norm{G - X_i}_1 = \sum_{i=1}^n \sum_{k=1}^d \abs{G_k - X_{ik}}"/></p>
</div></div>
<p>On cherche le point <em>G</em> qui minimise la quantitÃ© <img class="math" src="../_images/math/c484af6489df0496107d8da599f9d84c3931aebf.svg" alt="I(G,X_1,...,X_n)"/>.
Comme <img class="math" src="../_images/math/60d3d7234cef59ab3e1d4c4caa7c88c629e43cab.svg" alt="\sum_{i=1}^n \sum_{k=1}^d \abs{G_k - X_{ik}} = \sum_{k=1}^d \sum_{i=1}^n  \abs{G_k - X_{ik}}"/>,
on en dÃ©duit quâon peut chercher la coordonnÃ©e <img class="math" src="../_images/math/5b586d8ac2fcc343ef09f4c37723e90b948ae179.svg" alt="G_k"/> indÃ©pendemment
les unes des autres. On en dÃ©duit
que le barycentre de norme L1 dâun ensemble de points dans un
espace vectoriel de dimension <em>d</em> a pour coordonnÃ©es les <em>d</em>
mÃ©dianes extraites sur chacune des dimensions.
Lâalgorithme est implÃ©mentÃ© dans le module <a class="reference external" href="https://sdpython.github.io/doc/mlinsights/dev/index.html">mlinsights</a>
en sâinspirant du code <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html">KMeans</a>.</p>
</section>
<section id="bibliographie">
<h2>Bibliographie<a class="headerlink" href="#bibliographie" title="Lien vers cette rubrique">Â¶</a></h2>
<div role="list" class="citation-list">
<div class="citation" id="arthur2007" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Arthur2007<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id2">1</a>,<a role="doc-backlink" href="#id3">2</a>)</span>
<p>k-means++: the advantages of careful seeding (2007),
<em>Arthur, D.; Vassilvitskii, S.</em>,
Proceedings of the eighteenth annual ACM-SIAM symposium on Discrete algorithms.
Society for Industrial and Applied Mathematics Philadelphia, PA, USA. pp. 1027â1035.
<a class="reference external" href="http://ilpubs.stanford.edu:8090/778/1/2006-13.pdf">2006-13.pdf</a>.</p>
</div>
<div class="citation" id="balakrishnan1996" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Balakrishnan1996<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id21">1</a>,<a role="doc-backlink" href="#id22">2</a>)</span>
<p>Comparative performance of the FSCL neural net and K-means algorithm for market segmentation (1996),
P. V. Sundar Balakrishnan, Martha Cooper, Varghese S. Jacob, Phillip A. Lewis,
<em>European Journal of Operation Research</em>, volume 93, pages 346-357</p>
</div>
<div class="citation" id="bahmani2012" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id5">Bahmani2012</a><span class="fn-bracket">]</span></span>
<p>Scalable K-Means++ (2012),
<em>Bahman Bahmani, Benjamin Moseley, Andrea Vattani, Ravi Kumar, Sergei Vassilvitskii</em>,
Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 7, pp. 622-633 (2012)
<a class="reference external" href="http://theory.stanford.edu/~sergei/papers/vldb12-kmpar.pdf">vldb12-kmpar.pdf</a>,
<a class="reference external" href="https://arxiv.org/abs/1203.6402">arXiv.1203.6402</a></p>
</div>
<div class="citation" id="cheung2003" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Cheung2003<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id15">1</a>,<a role="doc-backlink" href="#id16">2</a>)</span>
<p><img class="math" src="../_images/math/fc90b3f44afc581dfadde98aeb786a78889e3a4c.svg" alt="k^*"/>-Means: A new generalized k-means clustering algorithm (2003),
Yiu-Ming Cheung,
<em>Pattern Recognition Letters</em>, volume 24, 2883-2893</p>
</div>
<div class="citation" id="davies1979" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id6">Davies1979</a><span class="fn-bracket">]</span></span>
<p>A cluster Separation Measure (1979),
D. L. Davies, D. W. Bouldin,
<em>IEEE Trans. Pattern Analysis and Machine Intelligence (PAMI)</em>, volume 1(2)</p>
</div>
<div class="citation" id="goodman1954" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id7">Goodman1954</a><span class="fn-bracket">]</span></span>
<p>Measures of associations for cross-validations (1954),
L. Goodman, W. Kruskal,
<em>J. Am. Stat. Assoc.</em>, volume 49, pages 732-764</p>
</div>
<div class="citation" id="herbin2001" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Herbin2001<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id8">1</a>,<a role="doc-backlink" href="#id10">2</a>)</span>
<p>Estimation of the number of clusters and influence zones (2001),
M. Herbin, N. Bonnet, P. Vautrot,
<em>Pattern Recognition Letters</em>, volume 22, pages 1557-1568</p>
</div>
<div class="citation" id="kothari1999" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Kothari1999<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id11">1</a>,<a role="doc-backlink" href="#id12">2</a>,<a role="doc-backlink" href="#id13">3</a>,<a role="doc-backlink" href="#id14">4</a>)</span>
<p>On finding the number of clusters (1999),
Ravi Kothari, Dax Pitts,
<em>Pattern Recognition Letters</em>, volume 20, pages 405-416</p>
</div>
<div class="citation" id="liu2003" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Liu2003<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id18">1</a>,<a role="doc-backlink" href="#id19">2</a>,<a role="doc-backlink" href="#id20">3</a>)</span>
<p>Strip line detection and thinning by RPCL-based local PCA (2003),
Zhi-Yong Liu, Kai-Chun Chiu, Lei Xu,
<em>Pattern Recognition Letters</em> volume 24, pages 2335-2344</p>
</div>
<div class="citation" id="silverman1986" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id9">Silverman1986</a><span class="fn-bracket">]</span></span>
<p>Density Estimation for Statistics and Data Analysis (1986),
B. W. Silverman,
<em>Monographs on Statistics and Applied Probability, Chapman and Hall, London</em>, volume 26</p>
</div>
<div class="citation" id="xu1993" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id17">Xu1993</a><span class="fn-bracket">]</span></span>
<p>Rival penalized competitive learning for clustering analysis, rbf net and curve detection (1993),
L. Xu, A. Krzyzak, E. Oja,
<em>IEEE Trans. Neural Networks</em>, volume (4), pages 636-649</p>
</div>
</div>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="gauss_mixture.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">MÃ©lange de lois normales</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="index.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Clustering</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2016-2025, Xavier DuprÃ©
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">k-means</a><ul>
<li><a class="reference internal" href="#principe">Principe</a><ul>
<li><a class="reference internal" href="#homogeneite-des-dimensions">HomogÃ©nÃ©itÃ© des dimensions</a></li>
</ul>
</li>
<li><a class="reference internal" href="#ameliorations-de-l-initialisation">AmÃ©liorations de lâinitialisation</a><ul>
<li><a class="reference internal" href="#l-kmeanspp">K-means++</a></li>
<li><a class="reference internal" href="#id4">K-means||</a></li>
</ul>
</li>
<li><a class="reference internal" href="#estimation-de-probabilites">Estimation de probabilitÃ©s</a></li>
<li><a class="reference internal" href="#selection-du-nombre-de-classes">SÃ©lection du nombre de classes</a><ul>
<li><a class="reference internal" href="#critere-de-qualite">CritÃ¨re de qualitÃ©</a></li>
<li><a class="reference internal" href="#maxima-de-la-fonction-densite">Maxima de la fonction densitÃ©</a></li>
<li><a class="reference internal" href="#decroissance-du-nombre-de-classes">DÃ©croissance du nombre de classes</a></li>
</ul>
</li>
<li><a class="reference internal" href="#extension-des-nuees-dynamiques">Extension des nuÃ©es dynamiques</a><ul>
<li><a class="reference internal" href="#classes-elliptiques">Classes elliptiques</a></li>
<li><a class="reference internal" href="#rival-penalized-competitive-learning-rpcl">Rival Penalized Competitive Learning (RPCL)</a></li>
<li><a class="reference internal" href="#rpcl-based-local-pca">RPCL-based local PCA</a></li>
<li><a class="reference internal" href="#frequency-sensitive-competitive-learning-fscl">Frequency Sensitive Competitive Learning (FSCL)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#k-means-norme-l1">k-means norme L1</a></li>
<li><a class="reference internal" href="#bibliographie">Bibliographie</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../_static/documentation_options.js?v=0886690b"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/furo.js?v=5fa4622c"></script>
    <script src="../_static/translations.js?v=e6b791cb"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    </body>
</html>