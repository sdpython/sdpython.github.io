<!doctype html>
<html class="no-js" lang="fr" data-content_root="../../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../../genindex.html" /><link rel="search" title="Recherche" href="../../search.html" /><link rel="next" title="Classification" href="rn_7_clas2.html" /><link rel="prev" title="Descente de gradient" href="rn_5_newton.html" />

    <!-- Generated with Sphinx 8.1.3 and Furo 2024.08.06 -->
        <title>Apprentissage d’un réseau de neurones - Documentation mlstatpy 0.5.0</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo.css?v=354aac6f" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css?v=4ae1632d" />
    <link rel="stylesheet" type="text/css" href="../../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo-extensions.css?v=302659d7" />
    
    


<style>
  body {
    --color-code-background: #eeffcc;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../../index.html"><div class="brand">Documentation mlstatpy 0.5.0</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../../index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="../../_static/project_ico.png" alt="Logo"/>
  </div>
  
  <span class="sidebar-brand-text">Documentation mlstatpy 0.5.0</span>
  
</a><form class="sidebar-search-container" method="get" action="../../search.html" role="search">
  <input class="sidebar-search" placeholder="Recherche" name="q" aria-label="Recherche">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Mathematics</span></p>
<ul class="current">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../c_clus/index.html">Clustering</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of Clustering</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../c_clus/kmeans.html">k-means</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../c_clus/gauss_mixture.html">Mélange de lois normales</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../c_clus/kohonen.html">Carte de Kohonen</a></li>
</ul>
</li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="../index.html">Non linéaire</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of Non linéaire</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2 current has-children"><a class="reference internal" href="rn.html">Réseaux de neurones</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of Réseaux de neurones</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="rn_1_def.html">Définition des réseaux de neurones multi-couches</a></li>
<li class="toctree-l3"><a class="reference internal" href="rn_2_reg.html">La régression</a></li>
<li class="toctree-l3"><a class="reference internal" href="rn_3_clas.html">La classification</a></li>
<li class="toctree-l3"><a class="reference internal" href="rn_4_densite.html">Démonstration du théorème de la densité des réseaux de neurones</a></li>
<li class="toctree-l3"><a class="reference internal" href="rn_5_newton.html">Descente de gradient</a></li>
<li class="toctree-l3 current current-page"><a class="current reference internal" href="#">Apprentissage d’un réseau de neurones</a></li>
<li class="toctree-l3"><a class="reference internal" href="rn_7_clas2.html">Classification</a></li>
<li class="toctree-l3"><a class="reference internal" href="rn_8_prol.html">Prolongements</a></li>
<li class="toctree-l3"><a class="reference internal" href="rn_9_auto.html">Analyse en composantes principales (ACP) et Auto Encoders</a></li>
<li class="toctree-l3"><a class="reference internal" href="rn_biblio.html">Bibliographie</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../kppv.html">Classification à l’aide des plus proches voisins</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../missing_values_mf.html">Liens entre factorisation de matrices, ACP, k-means</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of Liens entre factorisation de matrices, ACP, k-means</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/mf_acp.html">Factorisation et matrice et ACP</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/valeurs_manquantes_mf.html">Valeurs manquantes et factorisation de matrices</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/ml/neural_tree.html">Un arbre de décision en réseaux de neurones</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/ml/neural_tree_onnx.html">NeuralTreeNet et ONNX</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/ml/neural_tree_cost.html">NeuralTreeNet et coût</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../index_reg_lin.html">Régression linéaire</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of Régression linéaire</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/dsgarden/regression_lineaire.html">Régression linéaire</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../regression_quantile.html">Régression quantile ou régression L1</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle navigation of Régression quantile ou régression L1</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/dsgarden/quantile_regression_example.html">Régression quantile illustrée</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../piecewise.html">Régression linéaire par morceaux</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle navigation of Régression linéaire par morceaux</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/piecewise_linear_regression.html">Régression linéaire par morceaux</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/regression_no_inversion.html">Régression sans inversion</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../l1l2.html">Normalisation des coefficients</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../index_reg_log.html">Régression logistique</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle navigation of Régression logistique</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lr_voronoi.html">Régression logistique, diagramme de Voronoï, k-Means</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle navigation of Régression logistique, diagramme de Voronoï, k-Means</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/logreg_voronoi.html">Voronoï et régression logistique</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../lr_trees.html">Régression logistique par morceaux, arbres de décision</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/ml/reseau_neurones.html">Réseaux de neurones</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../survival_analysis.html">Analyse de survie</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle navigation of Analyse de survie</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/survival.html">Analyse de survie en pratique</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../c_nlp/index.html">NLP</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><div class="visually-hidden">Toggle navigation of NLP</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../c_nlp/completion.html">Complétion</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><div class="visually-hidden">Toggle navigation of Complétion</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../c_nlp/completion_formalisation.html">Formalisation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../c_nlp/completion_fausse.html">Fausses idées reçues</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../c_nlp/completion_metrique.html">Nouvelle métrique</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../c_nlp/completion_propriete.html">Propriétés mathématiques</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../c_nlp/completion_optimisation.html">Problème d’optimisation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../c_nlp/completion_implementation.html">Implémentation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../c_nlp/completion_digression.html">Digressions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/nlp/completion_trie.html">Complétion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/nlp/completion_profiling.html">Completion profiling</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/nlp/completion_trie_long.html">Completion Trie and metrics</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/nlp/completion_simple.html">Complétion Simple</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../c_metric/index.html">Métriques</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" role="switch" type="checkbox"/><label for="toctree-checkbox-13"><div class="visually-hidden">Toggle navigation of Métriques</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../c_metric/roc.html">Courbe ROC</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" role="switch" type="checkbox"/><label for="toctree-checkbox-14"><div class="visually-hidden">Toggle navigation of Courbe ROC</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/metric/roc_example.html">ROC</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../c_metric/pvalues.html">Confidence Interval and p-Value</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" role="switch" type="checkbox"/><label for="toctree-checkbox-15"><div class="visually-hidden">Toggle navigation of Confidence Interval and p-Value</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/metric/pvalues_examples.html">p-values</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../c_algo/index.html">Algorithmes</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" role="switch" type="checkbox"/><label for="toctree-checkbox-16"><div class="visually-hidden">Toggle navigation of Algorithmes</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../c_algo/edit_distance.html">Distance d’édition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../c_algo/graph_distance.html">Distance between two graphs</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../c_algo/gest.html">Détection de segments</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" role="switch" type="checkbox"/><label for="toctree-checkbox-17"><div class="visually-hidden">Toggle navigation of Détection de segments</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/image/segment_detection.html">Détection de segments dans une image</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../c_garden/index.html">Pérégrinations</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" role="switch" type="checkbox"/><label for="toctree-checkbox-18"><div class="visually-hidden">Toggle navigation of Pérégrinations</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/dsgarden/split_train_test.html">Répartir en base d’apprentissage et de test</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/dsgarden/correlation_non_lineaire.html">Corrélations non linéaires</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../c_garden/file_dattente.html">File d’attente, un petit exemple</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" role="switch" type="checkbox"/><label for="toctree-checkbox-19"><div class="visually-hidden">Toggle navigation of File d’attente, un petit exemple</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/dsgarden/file_dattente_ex.html">File d’attente, un exemple simple</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../c_garden/strategie_avec_alea.html">Optimisation avec données aléatoires</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/dsgarden/discret_gradient.html">Le gradient et le discret</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../c_garden/quantization.html">Quantization</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" role="switch" type="checkbox"/><label for="toctree-checkbox-20"><div class="visually-hidden">Toggle navigation of Quantization</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/dsgarden/quantization_f8.html">Quantization</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/dsgarden/classification_multiple.html">Classification multiple</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../api/index.html">API</a><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" role="switch" type="checkbox"/><label for="toctree-checkbox-21"><div class="visually-hidden">Toggle navigation of API</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../api/ml.html">Machine Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/optim.html">Optimisation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/text.html">Traitement du langage naturel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/data.html">Source de données</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/graph.html">Graphes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/image.html">Image</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../api/modules/index.html">Modules</a><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" role="switch" type="checkbox"/><label for="toctree-checkbox-22"><div class="visually-hidden">Toggle navigation of Modules</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../api/modules/poulet.html">mlstatpy.garden.poulet</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/modules/graph_distance.html">mlstatpy.graph.graph_distance</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/modules/kppv.html">mlstatpy.ml.kppv</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/modules/kppv_laesa.html">mlstatpy.ml.kppv_laesa</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/modules/logreg.html">mlstatpy.ml.logreg</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/modules/neural_tree.html">mlstatpy.ml.neural_tree</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/modules/roc.html">mlstatpy.ml.roc</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/modules/completion.html">mlstatpy.nlp.completion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/modules/completion_simple.html">mlstatpy.nlp.completion_simple</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/modules/sgd.html">mlstatpy.optim.sgd</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../i_ex.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../defthe_index.html">Listes des définitions et théorèmes</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../auto_examples/index.html">Gallery of examples</a><input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" role="switch" type="checkbox"/><label for="toctree-checkbox-23"><div class="visually-hidden">Toggle navigation of Gallery of examples</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../auto_examples/plot_logistic_decision.html">Arbre d’indécision</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../notebooks/index.html">Galleries de notebooks</a><input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" role="switch" type="checkbox"/><label for="toctree-checkbox-24"><div class="visually-hidden">Toggle navigation of Galleries de notebooks</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../notebooks/dsgarden/index.html">Le petit coin des data scientists</a><input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" role="switch" type="checkbox"/><label for="toctree-checkbox-25"><div class="visually-hidden">Toggle navigation of Le petit coin des data scientists</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/dsgarden/classification_multiple.html">Classification multiple</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/dsgarden/correlation_non_lineaire.html">Corrélations non linéaires</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/dsgarden/discret_gradient.html">Le gradient et le discret</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/dsgarden/file_dattente_ex.html">File d’attente, un exemple simple</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/dsgarden/quantile_regression_example.html">Régression quantile illustrée</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/dsgarden/quantization_f8.html">Quantization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/dsgarden/regression_lineaire.html">Régression linéaire</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/dsgarden/split_train_test.html">Répartir en base d’apprentissage et de test</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../notebooks/image/index.html">Images</a><input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" role="switch" type="checkbox"/><label for="toctree-checkbox-26"><div class="visually-hidden">Toggle navigation of Images</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/image/segment_detection.html">Détection de segments dans une image</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../notebooks/metric/index.html">Métriques</a><input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" role="switch" type="checkbox"/><label for="toctree-checkbox-27"><div class="visually-hidden">Toggle navigation of Métriques</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/metric/pvalues_examples.html">p-values</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/metric/roc_example.html">ROC</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../notebooks/ml/index.html">Machine Learning</a><input class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" role="switch" type="checkbox"/><label for="toctree-checkbox-28"><div class="visually-hidden">Toggle navigation of Machine Learning</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/logreg_voronoi.html">Voronoï et régression logistique</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/mf_acp.html">Factorisation et matrice et ACP</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/neural_tree.html">Un arbre de décision en réseaux de neurones</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/neural_tree_cost.html">NeuralTreeNet et coût</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/neural_tree_onnx.html">NeuralTreeNet et ONNX</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/piecewise_linear_regression.html">Régression linéaire par morceaux</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/regression_no_inversion.html">Régression sans inversion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/reseau_neurones.html">Réseaux de neurones</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/survival.html">Analyse de survie en pratique</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/valeurs_manquantes_mf.html">Valeurs manquantes et factorisation de matrices</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../notebooks/nlp/index.html">NLP - Natural Language Processing</a><input class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" role="switch" type="checkbox"/><label for="toctree-checkbox-29"><div class="visually-hidden">Toggle navigation of NLP - Natural Language Processing</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/nlp/completion_profiling.html">Completion profiling</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/nlp/completion_simple.html">Complétion Simple</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/nlp/completion_trie.html">Complétion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/nlp/completion_trie_long.html">Completion Trie and metrics</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">More</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../glossary.html">Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../CHANGELOGS.html">Change Logs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../CHANGELOGS.html#id2">0.4.0</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../license.html">License</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="../../_sources/c_ml/rn/rn_6_apprentissage.rst" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="apprentissage-d-un-reseau-de-neurones">
<h1>Apprentissage d’un réseau de neurones<a class="headerlink" href="#apprentissage-d-un-reseau-de-neurones" title="Lien vers cette rubrique">¶</a></h1>
<nav class="contents local" id="sommaire">
<ul class="simple">
<li><p><a class="reference internal" href="#apprentissage-avec-gradient-global" id="id8">Apprentissage avec gradient global</a></p>
<ul>
<li><p><a class="reference internal" href="#methodes-du-premier-ordre" id="id9">Méthodes du premier ordre</a></p></li>
<li><p><a class="reference internal" href="#methodes-du-second-ordre" id="id10">Méthodes du second ordre</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#apprentissage-avec-gradient-stochastique" id="id11">Apprentissage avec gradient stochastique</a></p></li>
</ul>
</nav>
<p>Le terme apprentissage est encore inspiré de la biologie et se traduit
par la minimisation de la fonction <a class="reference internal" href="rn_5_newton.html#equation-equation-fonction-erreur-g">(2)</a> où
<img class="math" src="../../_images/math/bd1e0600a66dbe0f8deddbd57953774419ba4e4f.svg" alt="f"/> est un réseau de neurone défini par un <a class="reference internal" href="rn_1_def.html#rn-definition-perpception-1"><span class="std std-ref">perceptron</span></a>.
Il existe plusieurs méthodes pour effectuer celle-ci.
Chacune d’elles vise à minimiser la fonction d’erreur :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/ab0f3aab1b6c085dce399157adfa87c341cd01ad.svg" alt="E\pa{W}   = G \pa{W}  =   \sum_{i=1}^{N} e\pa {Y_{i} - \widehat{Y_{i}^W}}
                                    =   \sum_{i=1}^{N} e\pa {Y_{i} - f \pa{W,X_{i}}}"/></p>
</div></div>
<p>Dans tous les cas, les différents apprentissages utilisent la suite
suivante <img class="math" src="../../_images/math/88c60f67e721d340b6249b8e809044ced8ec128a.svg" alt="\pa{ \epsilon_{t}}"/> vérifiant <a class="reference internal" href="#equation-rn-suite-epsilon-train">(1)</a>
et proposent une convergence vers un minimum local.</p>
<div class="math-wrapper docutils container" id="equation-rn-suite-epsilon-train">
<div class="math" id="equation-rn-suite-epsilon-train">
<p><span class="eqno">(1)<a class="headerlink" href="#equation-rn-suite-epsilon-train" title="Lien vers cette équation">¶</a></span><img src="../../_images/math/e7170d20a676d3babc18439fa91fc00dcb2965d7.svg" alt="\forall t&gt;0,\quad\varepsilon_{t}\in \mathbb{R}_{+}^{\ast} \text{ et }
\sum_{t\geqslant0}\varepsilon_{t}=+\infty,\quad
\sum_{t\geqslant0}\varepsilon_{t}^{2}&lt;+\infty"/></p>
</div></div>
<p>Il est souhaitable d’apprendre plusieurs fois la même fonction en modifiant
les conditions initiales de ces méthodes de manière à améliorer la robustesse de la solution.</p>
<section id="apprentissage-avec-gradient-global">
<span id="rn-apprentissage-global"></span><h2><a class="toc-backref" href="#id8" role="doc-backlink">Apprentissage avec gradient global</a><a class="headerlink" href="#apprentissage-avec-gradient-global" title="Lien vers cette rubrique">¶</a></h2>
<p>L’algorithme de <a class="reference internal" href="rn_5_newton.html#algo-retropropagation"><span class="std std-ref">rétropropagation</span></a> permet d’obtenir
la dérivée de l’erreur <img class="math" src="../../_images/math/a52a5cbf4e378c1f5b4401b55b3ed7cd1a281e1d.svg" alt="e"/> pour un vecteur d’entrée <img class="math" src="../../_images/math/b66c7d6c52c7b12bee7fb24d76c38fc70cfc0a2f.svg" alt="X"/>. Or l’erreur
<img class="math" src="../../_images/math/dd1ae49ba41cce059d20a1b88a25aac2f5f49ddc.svg" alt="E\pa{W}"/> à minimiser est la somme des erreurs pour chaque exemple
<img class="math" src="../../_images/math/c15b262677ad7177c2e37298a2eb382d712b3a52.svg" alt="X_i"/>, le gradient global <img class="math" src="../../_images/math/016fd3067731d48565711ad8c1a265ee4ddbb750.svg" alt="\partialfrac{E\pa{W}}{W}"/> de cette erreur
globale est la somme des gradients pour chaque exemple
(voir équation <a class="reference internal" href="rn_5_newton.html#equation-algo-retro-1">(3)</a>).
Parmi les méthodes d’optimisation basées sur le gradient global, on distingue deux catégories :</p>
<ul class="simple">
<li><p>Les méthodes du premier ordre, elles sont calquées sur la
<a class="reference external" href="https://fr.wikipedia.org/wiki/M%C3%A9thode_de_Newton">méthode de Newton</a>
et n’utilisent que le gradient.</p></li>
<li><p>Les méthodes du second ordre ou méthodes utilisant un
<a class="reference external" href="https://fr.wikipedia.org/wiki/M%C3%A9thode_du_gradient_conjugu%C3%A9">gradient conjugué</a>
elles sont plus coûteuses en calcul mais plus performantes
puisque elles utilisent la dérivée seconde ou une valeur approchée.</p></li>
</ul>
<section id="methodes-du-premier-ordre">
<span id="rn-optim-premier-ordre"></span><h3><a class="toc-backref" href="#id9" role="doc-backlink">Méthodes du premier ordre</a><a class="headerlink" href="#methodes-du-premier-ordre" title="Lien vers cette rubrique">¶</a></h3>
<p>Les méthodes du premier ordre sont rarement utilisées.
Elles sont toutes basées sur le principe
de la descente de gradient de Newton présentée dans
la section <a class="reference internal" href="rn_5_newton.html#optimisation-newton"><span class="std std-ref">Algorithme et convergence</span></a> :</p>
<div class="admonition-mathdef admonition" id="indexmathe-Algorithme0">
<div class="docutils container">
</div>
<p class="admonition-title" id="rn-algorithme-apprentissage-1">Algorithme A1 : optimisation du premier ordre</p>
<p><em>Initialiation</em></p>
<p>Le premier jeu de coefficients <img class="math" src="../../_images/math/bc75580554dcbb669594f87f31230f72104e48c7.svg" alt="W_0"/> du réseau
de neurones est choisi aléatoirement.</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/5388ef68de96930b793a48328dff1504867571e5.svg" alt="\begin{array}{rcl}
t   &amp;\longleftarrow&amp;    0 \\
E_0 &amp;\longleftarrow&amp;    \sum_{i=1}^{N} e\pa {Y_{i} - f \pa{W_0,X_{i}}}
\end{array}"/></p>
</div></div>
<p><em>Calcul du gradient</em></p>
<p><img class="math" src="../../_images/math/aeed0fb547a698da1ca6d0363ab80b896841cd08.svg" alt="g_t \longleftarrow \partialfrac{E_t}{W} \pa {W_t} = \sum_{i=1}^{N}
e'\pa {Y_{i} - f \pa{W_t,X_{i}}}"/></p>
<p><em>Mise à jour</em></p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/a312431bf0192fab0852451b6e48f1159ba5f63b.svg" alt="\begin{array}{rcl}
W_{t+1} &amp;\longleftarrow&amp; W_t - \epsilon_t g_t \\
E_{t+1} &amp;\longleftarrow&amp; \sum_{i=1}^{N} e\pa {Y_i - f \pa{W_{t+1},X_i}} \\
t       &amp;\longleftarrow&amp; t+1
\end{array}"/></p>
</div></div>
<p><em>Terminaison</em></p>
<p>Si <img class="math" src="../../_images/math/3b6716971f87450506016adebd159bd9d428fb33.svg" alt="\frac{E_t}{E_{t-1}} \approx 1"/> (ou <img class="math" src="../../_images/math/01f3e82099e7da9fc961e88b4160ff0bcb2bd37a.svg" alt="\norm{g_t} \approx 0"/>)
alors l’apprentissage a convergé sinon retour au calcul du gradient.</p>
</div>
<p>La condition d’arrêt peut-être plus ou moins stricte selon les besoins du problème.
Cet algorithme converge vers un minimum local de la fonction d’erreur
(d’après le théorème de <a class="reference internal" href="rn_5_newton.html#theoreme-convergence"><span class="std std-ref">convergence</span></a>
mais la vitesse de convergence est inconnue.</p>
</section>
<section id="methodes-du-second-ordre">
<span id="rn-optim-second-ordre"></span><h3><a class="toc-backref" href="#id10" role="doc-backlink">Méthodes du second ordre</a><a class="headerlink" href="#methodes-du-second-ordre" title="Lien vers cette rubrique">¶</a></h3>
<p>L’algorithme <a class="reference internal" href="#rn-apprentissage-global"><span class="std std-ref">apprentissage global</span></a> fournit le canevas des
méthodes d’optimisation du second ordre. La mise à jour des coefficients est différente car
elle prend en compte les dernières valeurs des coefficients ainsi que les
derniers gradients calculés. Ce passé va être utilisé pour estimer une
direction de recherche pour le minimum différente de celle du gradient,
cette direction est appelée gradient conjugué (voir <a class="reference internal" href="rn_biblio.html#more1977" id="id1"><span>[Moré1977]</span></a>).</p>
<p>Ces techniques sont basées sur une approximation du second degré de la fonction à minimiser.
On note <img class="math" src="../../_images/math/e5c619f0600e251cabb3318b03870bc6f2c4870f.svg" alt="M"/> le nombre de coefficients du réseau de neurones (biais compris).
Soit <img class="math" src="../../_images/math/7957dc2c460013e29b92889472c06fcb74fa1a54.svg" alt="h: \mathbb{R}^{M} \dans \mathbb{R}"/> la fonction d’erreur associée au réseau de neurones :
<img class="math" src="../../_images/math/b5dca968eb586406aa09b85d022fc4a41382fe28.svg" alt="h \pa {W} = \sum_{i} e \pa{Y_i,f \pa{ W,X_i} }"/>.
Au voisinage de <img class="math" src="../../_images/math/8b51d45c8d4a3a12e6d7fdfbaedc54c592cb6b03.svg" alt="W_{0}"/>, un développement limité donne :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/27cd274752f6c17d97a3c357fc3a92cc49b6070f.svg" alt="h \pa {W}     =   h\pa {W_0}  + \frac{\partial h\left( W_{0}\right)  }{\partial W}\left( W-W_{0}\right) +\left(
W-W_{0}\right) ^{\prime}\frac{\partial^{2}h\left(  W_{0}\right)  }{\partial W^{2}}\left( W-W_{0}\right) +o\left\|
W-W_{0}\right\|  ^{2}"/></p>
</div></div>
<p>Par conséquent, sur un voisinage de <img class="math" src="../../_images/math/8b51d45c8d4a3a12e6d7fdfbaedc54c592cb6b03.svg" alt="W_{0}"/>, la fonction <img class="math" src="../../_images/math/f2a2cbec18360093e12a24d5658016c0669c3216.svg" alt="h\left( W\right)"/>
admet un minimum local si <img class="math" src="../../_images/math/4d8c8b6f93eaa2f51c19b94bffd23bd4af00868d.svg" alt="\frac{\partial^{2}h\left( W_{0}\right) }{\partial W^{2}}"/>
est définie positive strictement.</p>
<p><em>Rappel :</em> <img class="math" src="../../_images/math/c23baac04e89eda1a09673a2d72750acc500ac49.svg" alt="\dfrac{\partial^{2}h\left(  W_{0}\right)  }{\partial W^{2}}"/>
est définie positive strictement <img class="math" src="../../_images/math/8c3b289c531774a893de7f136bb0c400707de00f.svg" alt="\Longleftrightarrow\forall Z\in\mathbb{R}^{N},\; Z\neq0\Longrightarrow
Z^{\prime}\dfrac{\partial ^{2}h\left( W_{0}\right)  }{\partial W^{2}}Z&gt;0"/>.</p>
<p>Une matrice symétrique définie strictement positive est inversible,
et le minimum est atteint pour la valeur :</p>
<div class="math-wrapper docutils container" id="equation-rn-hessien">
<div class="math" id="equation-rn-hessien">
<p><span class="eqno">(2)<a class="headerlink" href="#equation-rn-hessien" title="Lien vers cette équation">¶</a></span><img src="../../_images/math/06cec53733bd1fac736fa67e71a42d1a5a7b43e7.svg" alt="\begin{eqnarray}
W_{\min}= W_0 + \frac{1}{2}\left[  \dfrac{\partial^{2}h\left(  W_{0}\right) }
        {\partial W^{2}}\right]  ^{-1}\left[  \frac{\partial h\left(  W_{0}\right)
}{\partial W}\right] \nonumber
\end{eqnarray}"/></p>
</div></div>
<p>Néanmoins, pour un réseau de neurones, le calcul de la dérivée seconde est coûteux,
son inversion également. C’est pourquoi les dernières valeurs des coefficients
et du gradient sont utilisées afin d’approcher cette dérivée seconde ou directement
son inverse. Deux méthodes d’approximation sont présentées :</p>
<ul class="simple">
<li><p>L’algorithme <a class="reference external" href="https://en.wikipedia.org/wiki/Broyden%E2%80%93Fletcher%E2%80%93Goldfarb%E2%80%93Shanno_algorithm">BFGS (Broyden-Fletcher-Goldfarb-Shano)</a>
(<a class="reference internal" href="rn_biblio.html#broyden1967" id="id2"><span>[Broyden1967]</span></a>, <a class="reference internal" href="rn_biblio.html#fletcher1993" id="id3"><span>[Fletcher1993]</span></a>), voir aussi les versions <a class="reference external" href="https://en.wikipedia.org/wiki/Limited-memory_BFGS">L-BFGS</a>.</p></li>
<li><p>L’algoritmhe <a class="reference external" href="https://en.wikipedia.org/wiki/Davidon%E2%80%93Fletcher%E2%80%93Powell_formula">DFP  (Davidon-Fletcher-Powell)</a>
(<a class="reference internal" href="rn_biblio.html#davidon1959" id="id4"><span>[Davidon1959]</span></a>, <a class="reference internal" href="rn_biblio.html#fletcher1963" id="id5"><span>[Fletcher1963]</span></a>).</p></li>
</ul>
<p>La figure du <a class="reference internal" href="#figure-gradient-conjugue"><span class="std std-ref">gradient conjugué</span></a> est couramment employée
pour illustrer l’intérêt des méthodes de gradient conjugué.
Le problème consiste à trouver le minimum d’une fonction quadratique,
par exemple, <img class="math" src="../../_images/math/df55abf7d78ed004fee5c47137dcbf9f96665ad8.svg" alt="G\pa{x,y} = 3x^2 + y^2"/>. Tandis que le gradient est orthogonal
aux lignes de niveaux de la fonction <img class="math" src="../../_images/math/86a30eae2899d36dcee14ab62c5e4c8a68feed4d.svg" alt="G"/>, le gradient conjugué se dirige plus
sûrement vers le minimum global.</p>
<div class="admonition-mathdef admonition" id="indexmathe-Figure0">
<div class="docutils container">
</div>
<p class="admonition-title" id="figure-gradient-conjugue">Figure F1 : Gradient conjugué</p>
<img alt="Wikipedia" src="../../_images/Conjugate_gradient_illustration.png" />
<p>Gradient et gradient conjugué sur une ligne de niveau de la fonction <img class="math" src="../../_images/math/df55abf7d78ed004fee5c47137dcbf9f96665ad8.svg" alt="G\pa{x,y} = 3x^2 + y^2"/>,
le gradient est orthogonal aux lignes de niveaux de la fonction <img class="math" src="../../_images/math/86a30eae2899d36dcee14ab62c5e4c8a68feed4d.svg" alt="G"/>,
mais cette direction est rarement la bonne à moins que le point
<img class="math" src="../../_images/math/6b06a232d5ddbeef16cc8e18544872a82ea7ce8b.svg" alt="\pa{x,y}"/> se situe sur un des axes des ellipses,
le gradient conjugué agrège les derniers déplacements et propose une direction
de recherche plus plausible pour le minimum de la fonction.
Voir <a class="reference external" href="https://en.wikipedia.org/wiki/Conjugate_gradient_method">Conjugate Gradient Method</a>.</p>
</div>
<p>Ces méthodes proposent une estimation de la dérivée seconde
(ou de son inverse) utilisée en <a class="reference internal" href="#equation-rn-hessien">(2)</a>.
Dans les méthodes du premier ordre, une itération permet de calculer les
poids <img class="math" src="../../_images/math/c22f92a3a7715cbda63093d0b91e1f5901d695a9.svg" alt="W_{t+1}"/> à partir des poids <img class="math" src="../../_images/math/bddf7a6848121731125f5226c8406dc99bab1b4b.svg" alt="W_t"/> et du
gradient <img class="math" src="../../_images/math/960be04fe11ab2149364585d376337ecc81ce7d0.svg" alt="G_t"/>. Si ce gradient est petit, on peut supposer
que <img class="math" src="../../_images/math/c3cca538a050f4f0f173f692d5185f3695bd2394.svg" alt="G_{t+1}"/> est presque égal au produit de la dérivée seconde par
<img class="math" src="../../_images/math/960be04fe11ab2149364585d376337ecc81ce7d0.svg" alt="G_t"/>. Cette relation est mise à profit pour construire une estimation
de la dérivée seconde. Cette matrice notée <img class="math" src="../../_images/math/739004e0316eecb56f6f6a20192d7308ead48c54.svg" alt="B_t"/> dans
l’algorithme <a class="reference internal" href="#rn-algo-bfgs"><span class="std std-ref">BFGS</span></a>
est d’abord supposée égale à l’identité puis actualisée à chaque
itération en tenant de l’information apportée par chaque déplacement.</p>
<div class="admonition-mathdef admonition" id="indexmathe-Algorithme1">
<div class="docutils container">
</div>
<p class="admonition-title" id="rn-algo-bfgs">Algorithme A2 : BFGS</p>
<p>Le nombre de paramètres de la fonction <img class="math" src="../../_images/math/bd1e0600a66dbe0f8deddbd57953774419ba4e4f.svg" alt="f"/> est <img class="math" src="../../_images/math/e5c619f0600e251cabb3318b03870bc6f2c4870f.svg" alt="M"/>.</p>
<p><em>Initialisation</em></p>
<p>Le premier jeu de coefficients <img class="math" src="../../_images/math/bc75580554dcbb669594f87f31230f72104e48c7.svg" alt="W_0"/> du réseau de neurones est
choisi aléatoirement.</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/804c33ea5bcf5b8bacc5e8fa7a961ce9653d9a7b.svg" alt="\begin{array}{lcl}
t   &amp;\longleftarrow&amp;    0 \\
E_0 &amp;\longleftarrow&amp;    \sum_{i=1}^{N} e\pa {Y_{i} - f \pa{W_0,X_{i}}} \\
B_0 &amp;\longleftarrow&amp;    I_M \\
i   &amp;\longleftarrow&amp;    0
\end{array}"/></p>
</div></div>
<p><em>Calcul du gradient</em></p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/a7ecc026d9ab8a9a72c088ef011ae6405de4a317.svg" alt="\begin{array}{lcl}
g_t &amp;\longleftarrow&amp; \partialfrac{E_t}{W} \pa {W_t}= \sum_{i=1}^{N} e'\pa {Y_{i} - f \pa{W_t,X_{i}}} \\
c_t &amp;\longleftarrow&amp; B_t g_t
\end{array}"/></p>
</div></div>
<p><em>Mise à jour des coefficients</em></p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/76d9807a61c38275b95502c8d60559473cb32d88.svg" alt="\begin{array}{lcl}
\epsilon^*  &amp;\longleftarrow&amp;    \underset{\epsilon}{\arg \inf} \; \sum_{i=1}^{N}
         e\pa {Y_i - f \pa{W_t - \epsilon c_t,X_i}}  \\
W_{t+1}     &amp;\longleftarrow&amp;    W_t - \epsilon^* c_t \\
E_{t+1}     &amp;\longleftarrow&amp;    \sum_{i=1}^{N} e\pa {Y_i - f \pa{W_{t+1},X_i}} \\
t           &amp;\longleftarrow&amp;    t+1
\end{array}"/></p>
</div></div>
<p><em>Mise à jour de la marice :math:`B_t`</em></p>
<div class="line-block">
<div class="line">si <img class="math" src="../../_images/math/f3e52d8e225c30d827b35e29dd145dec90aba17e.svg" alt="t - i \supegal M"/> ou <img class="math" src="../../_images/math/168442a635b1869902c9dfc14541e92d3dee47be.svg" alt="g'_{t-1} B_{t-1} g_{t-1} \leqslant 0"/> ou <img class="math" src="../../_images/math/5cce46936d2ed7ded9486f3c92ffca40cbdbacaf.svg" alt="g'_{t-1} B_{t-1} \pa {g_t - g_{t-1}} \leqslant 0"/></div>
<div class="line-block">
<div class="line"><img class="math" src="../../_images/math/1ba32dc8d96e50cbc4af248f7e833f1f573dcab9.svg" alt="B_{t} \longleftarrow I_M"/></div>
<div class="line"><img class="math" src="../../_images/math/b83d14d4cbb48b16e40aea2cbeef640eef199e61.svg" alt="i \longleftarrow  t"/></div>
</div>
<div class="line">sinon</div>
<div class="line-block">
<div class="line"><img class="math" src="../../_images/math/c3f33b1ac6c3a0812d73921e1c22938636591089.svg" alt="s_t \longleftarrow    W_t - W_{t-1}"/></div>
<div class="line"><img class="math" src="../../_images/math/ad6fdd3eae29399f3641eea97fb925caf5237ba6.svg" alt="d_t    \longleftarrow    g_t - g_{t-1}"/></div>
<div class="line"><img class="math" src="../../_images/math/789736e77349e0a5712132a79f9eb70e1edc2c8d.svg" alt="B_{t}  \longleftarrow    B_{t-1} +   \pa{1 + \dfrac{ d'_t B_{t-1} d_t}{d'_t s_t}}\dfrac{s_t s'_t} {s'_t d_t}- \dfrac{s_t d'_t B_{t-1} +  B_{t-1} d_t s'_t } { d'_t s_t }"/></div>
</div>
</div>
<p><em>Terminaison</em></p>
<p>Si <img class="math" src="../../_images/math/3b6716971f87450506016adebd159bd9d428fb33.svg" alt="\frac{E_t}{E_{t-1}} \approx 1"/> alors l’apprentissage a convergé sinon retour au calcul
du gradient.</p>
</div>
<p>Lorsque la matrice <img class="math" src="../../_images/math/739004e0316eecb56f6f6a20192d7308ead48c54.svg" alt="B_t"/> est égale à l’identité,
le gradient conjugué est égal au gradient. Au fur et
à mesure des itérations, cette matrice toujours
symétrique évolue en améliorant la convergence de l’optimisation.
Néanmoins, la matrice <img class="math" src="../../_images/math/739004e0316eecb56f6f6a20192d7308ead48c54.svg" alt="B_t"/> doit être « nettoyée »
(égale à l’identité) fréquemment afin d’éviter qu’elle
n’agrège un passé trop lointain. Elle est aussi nettoyée lorsque
le gradient conjugué semble trop s’éloigner du véritable gradient
et devient plus proche d’une direction perpendiculaire.</p>
<p>La convergence de cet algorithme dans le cas des réseaux de
neurones est plus rapide qu’un algorithme du premier ordre,
une preuve en est donnée dans <a class="reference internal" href="rn_biblio.html#driancourt1996" id="id6"><span>[Driancourt1996]</span></a>.</p>
<p>En pratique, la recherche de <img class="math" src="../../_images/math/86639fcd9d046a06aedfa8d313c7db83bb87ea6a.svg" alt="\epsilon^*"/> est réduite car
le calcul de l’erreur est souvent coûteux, il peut être effectué
sur un grand nombre d’exemples. C’est pourquoi on remplace
l’étape de mise à jour de l’algorithme <a class="reference internal" href="#rn-algo-bfgs"><span class="std std-ref">BFGS</span></a>
par celle-ci :</p>
<div class="admonition-mathdef admonition" id="indexmathe-Algorithme2">
<div class="docutils container">
</div>
<p class="admonition-title" id="rn-algo-bfgs-prime">Algorithme A3 : BFGS”</p>
<p>Le nombre de paramètre de la fonction <img class="math" src="../../_images/math/bd1e0600a66dbe0f8deddbd57953774419ba4e4f.svg" alt="f"/> est <img class="math" src="../../_images/math/e5c619f0600e251cabb3318b03870bc6f2c4870f.svg" alt="M"/>.</p>
<p><em>Initialisation, calcul du gradient</em></p>
<p>Voir <a class="reference internal" href="#rn-algo-bfgs"><span class="std std-ref">BFGS</span></a>.</p>
<p><em>Recherche de :math:`epsilon^*`</em></p>
<div class="line-block">
<div class="line"><img class="math" src="../../_images/math/c2f4787ef82d766dea8c28c3e4cbac971fc1dc62.svg" alt="\epsilon^*  \longleftarrow    \epsilon_0"/></div>
<div class="line">while <img class="math" src="../../_images/math/11597c815a54a4ddb3661b9b20f3c1ebb1e359a9.svg" alt="E_{t+1} \supegal E_t"/> et <img class="math" src="../../_images/math/d53e61f7f95e1f232f3c89173cb1faa81c976ee1.svg" alt="\epsilon^* \gg 0"/></div>
<div class="line-block">
<div class="line"><img class="math" src="../../_images/math/f4a4f67b7bdcdeb007c58b06750772e00b6e5b34.svg" alt="\epsilon^*  \longleftarrow   \frac{\epsilon^*}{2}"/></div>
<div class="line"><img class="math" src="../../_images/math/4bf26dbaa478f61a2210c669b127a0165e8097d1.svg" alt="W_{t+1}     \longleftarrow    W_t - \epsilon^* c_t"/></div>
<div class="line"><img class="math" src="../../_images/math/acbc9d1e717a03726b906d62eab8743bdd0fa457.svg" alt="E_{t+1}     \longleftarrow    \sum_{i=1}^{N} e\pa {Y_i - f \pa{W_{t+1},X_i}}"/></div>
<div class="line"><br /></div>
</div>
<div class="line">if <img class="math" src="../../_images/math/e17cb35f4573720c3e638f5daf5a38c21f3a0ff7.svg" alt="\epsilon_* \approx 0"/> et <img class="math" src="../../_images/math/5e51e64fddb431273f3f79871c42877e4757e8a9.svg" alt="B_t \neq I_M"/></div>
<div class="line-block">
<div class="line"><img class="math" src="../../_images/math/cf9e9f0f427389eccf91cbf5ef61cb29697bbf0f.svg" alt="B_{t}       \longleftarrow   I_M"/></div>
<div class="line"><img class="math" src="../../_images/math/39a5c4292337b8d76d9482579c3e647be3c90710.svg" alt="i           \longleftarrow    t"/></div>
<div class="line">Retour au calcul du gradient.</div>
</div>
</div>
<p><em>Mise à jour des coefficients</em></p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/88eab5209c4e6d7bbc92a2efc2f52e2cd41e7d5c.svg" alt="\begin{array}{lcl}
W_{t+1}     &amp;\longleftarrow&amp;    W_t - \epsilon^* c_t \\
E_{t+1}     &amp;\longleftarrow&amp;    \sum_{i=1}^{N} e\pa {Y_i - f \pa{W_{t+1},X_i}} \\
t           &amp;\longleftarrow&amp;    t+1
\end{array}"/></p>
</div></div>
<p><em>Mise à jour de la matrice :math:`B_t`, temrinaison</em></p>
<p>Voir <a class="reference internal" href="#rn-algo-bfgs"><span class="std std-ref">BFGS</span></a>.</p>
</div>
<p>L’algorithme DFP est aussi un algorithme de gradient conjugué
qui propose une approximation différente de l’inverse de la dérivée seconde.</p>
<div class="admonition-mathdef admonition" id="indexmathe-Algorithme3">
<div class="docutils container">
</div>
<p class="admonition-title" id="rn-algo-dfp">Algorithme A4 : DFP</p>
<p>Le nombre de paramètre de la fonction <img class="math" src="../../_images/math/bd1e0600a66dbe0f8deddbd57953774419ba4e4f.svg" alt="f"/> est <img class="math" src="../../_images/math/e5c619f0600e251cabb3318b03870bc6f2c4870f.svg" alt="M"/>.</p>
<p><em>Initialisation</em></p>
<p>Le premier jeu de coefficients <img class="math" src="../../_images/math/bc75580554dcbb669594f87f31230f72104e48c7.svg" alt="W_0"/>
du réseau de neurones est choisi aléatoirement.</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/804c33ea5bcf5b8bacc5e8fa7a961ce9653d9a7b.svg" alt="\begin{array}{lcl}
t   &amp;\longleftarrow&amp;    0 \\
E_0 &amp;\longleftarrow&amp;    \sum_{i=1}^{N} e\pa {Y_{i} - f \pa{W_0,X_{i}}} \\
B_0 &amp;\longleftarrow&amp;    I_M \\
i   &amp;\longleftarrow&amp;    0
\end{array}"/></p>
</div></div>
<p><em>Calcul du gradient</em></p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/a7ecc026d9ab8a9a72c088ef011ae6405de4a317.svg" alt="\begin{array}{lcl}
g_t &amp;\longleftarrow&amp; \partialfrac{E_t}{W} \pa {W_t}= \sum_{i=1}^{N} e'\pa {Y_{i} - f \pa{W_t,X_{i}}} \\
c_t &amp;\longleftarrow&amp; B_t g_t
\end{array}"/></p>
</div></div>
<p><em>Mise à jour des coefficients</em></p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/0015ebaa71bdf20549057303b634591859387414.svg" alt="\begin{array}{lcl}
\epsilon^*  &amp;\longleftarrow&amp;    \underset{\epsilon}{\arg \inf} \;
                             \sum_{i=1}^{N} e\pa {Y_i - f \pa{W_t - \epsilon c_t,X_i}}  \\
W_{t+1}     &amp;\longleftarrow&amp;    W_t - \epsilon^* c_t \\
E_{t+1}     &amp;\longleftarrow&amp;    \sum_{i=1}^{N} e\pa {Y_i - f \pa{W_{t+1},X_i}} \\
t           &amp;\longleftarrow&amp;    t+1
\end{array}"/></p>
</div></div>
<p><em>Mise à jour de la matrice :math:`B_t`</em></p>
<div class="line-block">
<div class="line">si <img class="math" src="../../_images/math/f3e52d8e225c30d827b35e29dd145dec90aba17e.svg" alt="t - i \supegal M"/> ou <img class="math" src="../../_images/math/168442a635b1869902c9dfc14541e92d3dee47be.svg" alt="g'_{t-1} B_{t-1} g_{t-1} \leqslant 0"/> ou <img class="math" src="../../_images/math/5cce46936d2ed7ded9486f3c92ffca40cbdbacaf.svg" alt="g'_{t-1} B_{t-1} \pa {g_t - g_{t-1}} \leqslant 0"/></div>
<div class="line-block">
<div class="line"><img class="math" src="../../_images/math/807869dc278eadfef93c21dde16f86514cbf9a0b.svg" alt="B_{t}       \longleftarrow    I_M"/></div>
<div class="line"><img class="math" src="../../_images/math/39a5c4292337b8d76d9482579c3e647be3c90710.svg" alt="i           \longleftarrow    t"/></div>
</div>
<div class="line">sinon</div>
<div class="line-block">
<div class="line"><img class="math" src="../../_images/math/83a63df4d67019872cef3e6df6179d431d594cba.svg" alt="d_t         \longleftarrow    W_t - W_{t-1}"/></div>
<div class="line"><img class="math" src="../../_images/math/6c98162b604899d81a0c52f3f4e6d2f1ed676e55.svg" alt="s_t         \longleftarrow    g_t - g_{t-1}"/></div>
<div class="line"><img class="math" src="../../_images/math/3aa698b1dd0f06d7f324112666625ff2bc0a1f5f.svg" alt="B_{t}       \longleftarrow"/>    B_{t-1} +     dfrac{d_t d’_t} {d’_t s_t} - dfrac{B_{t-1} s_t s’_t B_{t-1} } { s’_t B_{t-1} s_t }`</div>
</div>
</div>
<p><em>Terminaison</em></p>
<p>Si <img class="math" src="../../_images/math/3b6716971f87450506016adebd159bd9d428fb33.svg" alt="\frac{E_t}{E_{t-1}} \approx 1"/> alors l’apprentissage a convergé sinon retour à
du calcul du gradient.</p>
</div>
<p>Seule l’étape de mise à jour <img class="math" src="../../_images/math/739004e0316eecb56f6f6a20192d7308ead48c54.svg" alt="B_t"/> diffère dans les
algorithmes <a class="reference internal" href="#rn-algo-bfgs"><span class="std std-ref">BFGS</span></a> et <a class="reference internal" href="#rn-algo-dfp"><span class="std std-ref">DFP</span></a>.
Comme l’algorithme <a class="reference internal" href="#rn-algo-bfgs"><span class="std std-ref">BFGS</span></a>,
on peut construire une version <a class="reference internal" href="#rn-algo-dfp"><span class="std std-ref">DFP</span></a>”
inspirée de l’algorithme <a class="reference internal" href="#rn-algo-bfgs-prime"><span class="std std-ref">BFGS”</span></a>.</p>
</section>
</section>
<section id="apprentissage-avec-gradient-stochastique">
<h2><a class="toc-backref" href="#id11" role="doc-backlink">Apprentissage avec gradient stochastique</a><a class="headerlink" href="#apprentissage-avec-gradient-stochastique" title="Lien vers cette rubrique">¶</a></h2>
<p>Compte tenu des courbes d’erreurs très <a class="reference internal" href="#figure-courbe-accident"><span class="std std-ref">accidentées</span></a>
dessinées par les réseaux de neurones, il existe une multitude de minima
locaux. De ce fait, l’apprentissage global converge rarement vers le
minimum global de la fonction d’erreur lorsqu’on applique les algorithmes
basés sur le gradient global. L’apprentissage avec gradient stochastique
est une solution permettant de mieux explorer ces courbes d’erreurs.
De plus, les méthodes de gradient conjugué nécessite le stockage d’une
matrice trop grande parfois pour des fonctions ayant quelques milliers
de paramètres. C’est pourquoi l’apprentissage avec gradient stochastique
est souvent préféré à l’apprentissage global pour de grands réseaux de
neurones alors que les méthodes du second ordre trop coûteuses en
calcul sont cantonnées à de petits réseaux. En contrepartie, la
convergence est plus lente. La démonstration de cette convergence nécessite
l’utilisation de quasi-martingales et est une convergence presque sûre <a class="reference internal" href="rn_biblio.html#bottou1991" id="id7"><span>[Bottou1991]</span></a>.</p>
<div class="admonition-mathdef admonition" id="indexmathe-Figure1">
<div class="docutils container">
</div>
<p class="admonition-title" id="figure-courbe-accident">Figure F2 : Exemple de minimal locaux</p>
<img alt="../../_images/errminloc.png" src="../../_images/errminloc.png" />
</div>
<div class="admonition-mathdef admonition" id="indexmathe-Algprithme0">
<div class="docutils container">
</div>
<p class="admonition-title" id="rn-algorithme-apprentissage-2">Algprithme A1 : apprentissage stochastique</p>
<p><em>Initialisation</em></p>
<p>Le premier jeu de coefficients <img class="math" src="../../_images/math/bc75580554dcbb669594f87f31230f72104e48c7.svg" alt="W_0"/>
du réseau de neurones est choisi aléatoirement.</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/991a0fbe8fd698858c4f61e05f1bfc6e10cefacb.svg" alt="\begin{array}{lcl}
t       &amp;\longleftarrow&amp;    0 \\
E_0 &amp;\longleftarrow&amp;    \sum_{i=1}^{N} e\pa {Y_{i} - f \pa{W_0,X_{i}}}
\end{array}"/></p>
</div></div>
<p><em>Récurrence</em></p>
<div class="line-block">
<div class="line"><img class="math" src="../../_images/math/fda32587146b31ad06e47a16a6ae551a5417c920.svg" alt="W_{t,0} \longleftarrow    W_0"/></div>
<div class="line">for <img class="math" src="../../_images/math/3f43cb1046b6339c2199c6ab241d6fb272ca7a82.svg" alt="t'"/> in <img class="math" src="../../_images/math/b8884bfe4e80e0c9234f8806465397209a2d4395.svg" alt="0..N-1"/></div>
<div class="line-block">
<div class="line"><img class="math" src="../../_images/math/375d56054bff1fbb9621c9c64afe7a514bc4d35f.svg" alt="i \longleftarrow"/> nombre aléatoire dans <img class="math" src="../../_images/math/aa9ee889bdbcfbaa910718c537b7ed7dd93f5123.svg" alt="\ensemble{1}{N}"/></div>
<div class="line"><img class="math" src="../../_images/math/a25ed9f8afe8bb6d796cfc93081217a717b88328.svg" alt="g \longleftarrow \partialfrac{E}{W} \pa {W_{t,t'}}=  e'\pa {Y_{i} - f\pa{W_{t,t'},X_{i}}}"/></div>
<div class="line"><img class="math" src="../../_images/math/9953cf1952d3da30c599da7fee5afab03d274696.svg" alt="W_{t,t'+1} \longleftarrow    W_{t,t'} - \epsilon_t g"/></div>
</div>
<div class="line"><img class="math" src="../../_images/math/0935c9d88dedb7635588ccd0f1ec14453f3c6468.svg" alt="W_{t+1} \longleftarrow W_{t,N}"/></div>
<div class="line"><img class="math" src="../../_images/math/45148d8b094084ca0e9ae5ac503192904467e958.svg" alt="E_{t+1} \longleftarrow \sum_{i=1}^{N} e\pa {Y_{i} - f \pa{W_{t+1},X_{i}}}"/></div>
<div class="line"><img class="math" src="../../_images/math/02dd178e61d85f10a2824b1cd98c269269370b59.svg" alt="t \longleftarrow t+1"/></div>
</div>
<p><em>Terminaison</em></p>
<p>Si <img class="math" src="../../_images/math/3b6716971f87450506016adebd159bd9d428fb33.svg" alt="\frac{E_t}{E_{t-1}} \approx 1"/>
alors l’apprentissage a convergé sinon retour au
calcul du gradient.</p>
</div>
<p>En pratique, il est utile de converser le meilleur jeu de
coefficients : <img class="math" src="../../_images/math/dca43c0fbab92989b5f823e604dd34ee28bd2c93.svg" alt="W^* = \underset{u \supegal 0}{\arg \min} \; E_{u}"/>
car la suite <img class="math" src="../../_images/math/a3ad3c031439712b7229bcab40dbcd8b8ec547ff.svg" alt="\pa {E_u}_{u \supegal 0}"/> n’est pas une suite décroissante.</p>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="rn_7_clas2.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Classification</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="rn_5_newton.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Descente de gradient</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2016-2025, Xavier Dupré
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Apprentissage d’un réseau de neurones</a><ul>
<li><a class="reference internal" href="#apprentissage-avec-gradient-global">Apprentissage avec gradient global</a><ul>
<li><a class="reference internal" href="#methodes-du-premier-ordre">Méthodes du premier ordre</a></li>
<li><a class="reference internal" href="#methodes-du-second-ordre">Méthodes du second ordre</a></li>
</ul>
</li>
<li><a class="reference internal" href="#apprentissage-avec-gradient-stochastique">Apprentissage avec gradient stochastique</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../../_static/documentation_options.js?v=0886690b"></script>
    <script src="../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/scripts/furo.js?v=5fa4622c"></script>
    <script src="../../_static/translations.js?v=e6b791cb"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    </body>
</html>