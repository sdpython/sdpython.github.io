<!doctype html>
<html class="no-js" lang="fr" data-content_root="../../">
  <head><meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../../genindex.html"><link rel="search" title="Recherche" href="../../search.html"><link rel="next" title="Analyse en composantes principales (ACP) et Auto Encoders" href="rn_9_auto.html"><link rel="prev" title="Classification" href="rn_7_clas2.html">
        <link rel="prefetch" href="../../_static/project_ico.png" as="image">

    <!-- Generated with Sphinx 8.2.3 and Furo 2025.09.25 -->
        <title>Prolongements - Documentation mlstatpy 0.5.0</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo.css?v=580074bf" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css?v=4ae1632d" />
    <link rel="stylesheet" type="text/css" href="../../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo-extensions.css?v=8dab3a3b" />
    
    


<style>
  body {
    --color-code-background: #eeffcc;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle site navigation sidebar">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc" aria-label="Toggle table of contents sidebar">
<label class="overlay sidebar-overlay" for="__navigation"></label>
<label class="overlay toc-overlay" for="__toc"></label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <span class="icon"><svg><use href="#svg-menu"></use></svg></span>
      </label>
    </div>
    <div class="header-center">
      <a href="../../index.html"><div class="brand">Documentation mlstatpy 0.5.0</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle" aria-label="Toggle Light / Dark / Auto color theme">
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <span class="icon"><svg><use href="#svg-toc"></use></svg></span>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../../index.html">
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="../../_static/project_ico.png" alt="Logo"/>
  </div>
  
  <span class="sidebar-brand-text">Documentation mlstatpy 0.5.0</span>
  
</a><form class="sidebar-search-container" method="get" action="../../search.html" role="search">
  <input class="sidebar-search" placeholder="Recherche" name="q" aria-label="Recherche">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Mathematics</span></p>
<ul class="current">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../c_clus/index.html">Clustering</a><input aria-label="Toggle navigation of Clustering" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../c_clus/kmeans.html">k-means</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../c_clus/gauss_mixture.html">Mélange de lois normales</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../c_clus/kohonen.html">Carte de Kohonen</a></li>
</ul>
</li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="../index.html">Non linéaire</a><input aria-label="Toggle navigation of Non linéaire" checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul class="current">
<li class="toctree-l2 current has-children"><a class="reference internal" href="rn.html">Réseaux de neurones</a><input aria-label="Toggle navigation of Réseaux de neurones" checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="rn_1_def.html">Définition des réseaux de neurones multi-couches</a></li>
<li class="toctree-l3"><a class="reference internal" href="rn_2_reg.html">La régression</a></li>
<li class="toctree-l3"><a class="reference internal" href="rn_3_clas.html">La classification</a></li>
<li class="toctree-l3"><a class="reference internal" href="rn_4_densite.html">Démonstration du théorème de la densité des réseaux de neurones</a></li>
<li class="toctree-l3"><a class="reference internal" href="rn_5_newton.html">Descente de gradient</a></li>
<li class="toctree-l3"><a class="reference internal" href="rn_6_apprentissage.html">Apprentissage d’un réseau de neurones</a></li>
<li class="toctree-l3"><a class="reference internal" href="rn_7_clas2.html">Classification</a></li>
<li class="toctree-l3 current current-page"><a class="current reference internal" href="#">Prolongements</a></li>
<li class="toctree-l3"><a class="reference internal" href="rn_9_auto.html">Analyse en composantes principales (ACP) et Auto Encoders</a></li>
<li class="toctree-l3"><a class="reference internal" href="rn_biblio.html">Bibliographie</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../kppv.html">Classification à l’aide des plus proches voisins</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../missing_values_mf.html">Liens entre factorisation de matrices, ACP, k-means</a><input aria-label="Toggle navigation of Liens entre factorisation de matrices, ACP, k-means" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/mf_acp.html">Factorisation et matrice et ACP</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/valeurs_manquantes_mf.html">Valeurs manquantes et factorisation de matrices</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/ml/neural_tree.html">Un arbre de décision en réseaux de neurones</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/ml/neural_tree_onnx.html">NeuralTreeNet et ONNX</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/ml/neural_tree_cost.html">NeuralTreeNet et coût</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../index_reg_lin.html">Régression linéaire</a><input aria-label="Toggle navigation of Régression linéaire" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/dsgarden/regression_lineaire.html">Régression linéaire</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../regression_quantile.html">Régression quantile ou régression L1</a><input aria-label="Toggle navigation of Régression quantile ou régression L1" class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/dsgarden/quantile_regression_example.html">Régression quantile illustrée</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../piecewise.html">Régression linéaire par morceaux</a><input aria-label="Toggle navigation of Régression linéaire par morceaux" class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/piecewise_linear_regression.html">Régression linéaire par morceaux</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/regression_no_inversion.html">Régression sans inversion</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../l1l2.html">Normalisation des coefficients</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../index_reg_log.html">Régression logistique</a><input aria-label="Toggle navigation of Régression logistique" class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lr_voronoi.html">Régression logistique, diagramme de Voronoï, k-Means</a><input aria-label="Toggle navigation of Régression logistique, diagramme de Voronoï, k-Means" class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/logreg_voronoi.html">Voronoï et régression logistique</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../lr_trees.html">Régression logistique par morceaux, arbres de décision</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/ml/reseau_neurones.html">Réseaux de neurones</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../survival_analysis.html">Analyse de survie</a><input aria-label="Toggle navigation of Analyse de survie" class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/survival.html">Analyse de survie en pratique</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../c_nlp/index.html">NLP</a><input aria-label="Toggle navigation of NLP" class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../c_nlp/completion.html">Complétion</a><input aria-label="Toggle navigation of Complétion" class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../c_nlp/completion_formalisation.html">Formalisation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../c_nlp/completion_fausse.html">Fausses idées reçues</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../c_nlp/completion_metrique.html">Nouvelle métrique</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../c_nlp/completion_propriete.html">Propriétés mathématiques</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../c_nlp/completion_optimisation.html">Problème d’optimisation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../c_nlp/completion_implementation.html">Implémentation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../c_nlp/completion_digression.html">Digressions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/nlp/completion_trie.html">Complétion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/nlp/completion_profiling.html">Completion profiling</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/nlp/completion_trie_long.html">Completion Trie and metrics</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/nlp/completion_simple.html">Complétion Simple</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../c_metric/index.html">Métriques</a><input aria-label="Toggle navigation of Métriques" class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" role="switch" type="checkbox"/><label for="toctree-checkbox-13"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../c_metric/roc.html">Courbe ROC</a><input aria-label="Toggle navigation of Courbe ROC" class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" role="switch" type="checkbox"/><label for="toctree-checkbox-14"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/metric/roc_example.html">ROC</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../c_metric/pvalues.html">Confidence Interval and p-Value</a><input aria-label="Toggle navigation of Confidence Interval and p-Value" class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" role="switch" type="checkbox"/><label for="toctree-checkbox-15"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/metric/pvalues_examples.html">p-values</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../c_algo/index.html">Algorithmes</a><input aria-label="Toggle navigation of Algorithmes" class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" role="switch" type="checkbox"/><label for="toctree-checkbox-16"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../c_algo/edit_distance.html">Distance d’édition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../c_algo/graph_distance.html">Distance between two graphs</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../c_algo/gest.html">Détection de segments</a><input aria-label="Toggle navigation of Détection de segments" class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" role="switch" type="checkbox"/><label for="toctree-checkbox-17"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/image/segment_detection.html">Détection de segments dans une image</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../c_garden/index.html">Pérégrinations</a><input aria-label="Toggle navigation of Pérégrinations" class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" role="switch" type="checkbox"/><label for="toctree-checkbox-18"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/dsgarden/split_train_test.html">Répartir en base d’apprentissage et de test</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/dsgarden/correlation_non_lineaire.html">Corrélations non linéaires</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../c_garden/file_dattente.html">File d’attente, un petit exemple</a><input aria-label="Toggle navigation of File d’attente, un petit exemple" class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" role="switch" type="checkbox"/><label for="toctree-checkbox-19"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/dsgarden/file_dattente_ex.html">File d’attente, un exemple simple</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../c_garden/strategie_avec_alea.html">Optimisation avec données aléatoires</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/dsgarden/discret_gradient.html">Le gradient et le discret</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../c_garden/quantization.html">Quantization</a><input aria-label="Toggle navigation of Quantization" class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" role="switch" type="checkbox"/><label for="toctree-checkbox-20"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/dsgarden/quantization_f8.html">Quantization</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/dsgarden/classification_multiple.html">Classification multiple</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../api/index.html">API</a><input aria-label="Toggle navigation of API" class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" role="switch" type="checkbox"/><label for="toctree-checkbox-21"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../api/ml.html">Machine Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/optim.html">Optimisation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/text.html">Traitement du langage naturel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/data.html">Source de données</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/graph.html">Graphes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/image.html">Image</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../api/modules/index.html">Modules</a><input aria-label="Toggle navigation of Modules" class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" role="switch" type="checkbox"/><label for="toctree-checkbox-22"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../api/modules/poulet.html">mlstatpy.garden.poulet</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/modules/graph_distance.html">mlstatpy.graph.graph_distance</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/modules/kppv.html">mlstatpy.ml.kppv</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/modules/kppv_laesa.html">mlstatpy.ml.kppv_laesa</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/modules/logreg.html">mlstatpy.ml.logreg</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/modules/neural_tree.html">mlstatpy.ml.neural_tree</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/modules/roc.html">mlstatpy.ml.roc</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/modules/completion.html">mlstatpy.nlp.completion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/modules/completion_simple.html">mlstatpy.nlp.completion_simple</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/modules/sgd.html">mlstatpy.optim.sgd</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../i_ex.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../defthe_index.html">Listes des définitions et théorèmes</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../auto_examples/index.html">Gallery of examples</a><input aria-label="Toggle navigation of Gallery of examples" class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" role="switch" type="checkbox"/><label for="toctree-checkbox-23"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../auto_examples/plot_logistic_decision.html">Arbre d’indécision</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../notebooks/index.html">Galleries de notebooks</a><input aria-label="Toggle navigation of Galleries de notebooks" class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" role="switch" type="checkbox"/><label for="toctree-checkbox-24"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../notebooks/dsgarden/index.html">Le petit coin des data scientists</a><input aria-label="Toggle navigation of Le petit coin des data scientists" class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" role="switch" type="checkbox"/><label for="toctree-checkbox-25"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/dsgarden/classification_multiple.html">Classification multiple</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/dsgarden/correlation_non_lineaire.html">Corrélations non linéaires</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/dsgarden/discret_gradient.html">Le gradient et le discret</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/dsgarden/file_dattente_ex.html">File d’attente, un exemple simple</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/dsgarden/quantile_regression_example.html">Régression quantile illustrée</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/dsgarden/quantization_f8.html">Quantization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/dsgarden/regression_lineaire.html">Régression linéaire</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/dsgarden/split_train_test.html">Répartir en base d’apprentissage et de test</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../notebooks/image/index.html">Images</a><input aria-label="Toggle navigation of Images" class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" role="switch" type="checkbox"/><label for="toctree-checkbox-26"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/image/segment_detection.html">Détection de segments dans une image</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../notebooks/metric/index.html">Métriques</a><input aria-label="Toggle navigation of Métriques" class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" role="switch" type="checkbox"/><label for="toctree-checkbox-27"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/metric/pvalues_examples.html">p-values</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/metric/roc_example.html">ROC</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../notebooks/ml/index.html">Machine Learning</a><input aria-label="Toggle navigation of Machine Learning" class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" role="switch" type="checkbox"/><label for="toctree-checkbox-28"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/logreg_voronoi.html">Voronoï et régression logistique</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/mf_acp.html">Factorisation et matrice et ACP</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/neural_tree.html">Un arbre de décision en réseaux de neurones</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/neural_tree_cost.html">NeuralTreeNet et coût</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/neural_tree_onnx.html">NeuralTreeNet et ONNX</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/piecewise_linear_regression.html">Régression linéaire par morceaux</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/regression_no_inversion.html">Régression sans inversion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/reseau_neurones.html">Réseaux de neurones</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/survival.html">Analyse de survie en pratique</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/valeurs_manquantes_mf.html">Valeurs manquantes et factorisation de matrices</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../notebooks/nlp/index.html">NLP - Natural Language Processing</a><input aria-label="Toggle navigation of NLP - Natural Language Processing" class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" role="switch" type="checkbox"/><label for="toctree-checkbox-29"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/nlp/completion_profiling.html">Completion profiling</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/nlp/completion_simple.html">Complétion Simple</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/nlp/completion_trie.html">Complétion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/nlp/completion_trie_long.html">Completion Trie and metrics</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">More</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../glossary.html">Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../CHANGELOGS.html">Change Logs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../license.html">License</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../genindex.html">Index</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../py-modindex.html">Index du module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../search.html">Page de recherche</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="../../_sources/c_ml/rn/rn_8_prol.rst" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle" aria-label="Toggle Light / Dark / Auto color theme">
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <span class="icon"><svg><use href="#svg-toc"></use></svg></span>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="prolongements">
<h1>Prolongements<a class="headerlink" href="#prolongements" title="Lien vers cette rubrique">¶</a></h1>
<section id="base-d-apprentissage-et-base-de-test">
<h2>Base d’apprentissage et base de test<a class="headerlink" href="#base-d-apprentissage-et-base-de-test" title="Lien vers cette rubrique">¶</a></h2>
<p>Les deux exemples de régression et de classification
<a class="reference internal" href="rn_2_reg.html#rn-section-regression"><span class="std std-ref">La régression</span></a> et <a class="reference internal" href="rn_7_clas2.html#subsection-classifieur"><span class="std std-ref">Problème de classification pour les réseaux de neurones</span></a> ont montré
que la structure du réseau de neurones la mieux adaptée a
une grande importance. Dans ces deux cas, une rapide vérification visuelle
permet de juger de la qualité du modèle obtenu après apprentissage,
mais bien souvent, cette « vision » est inaccessible pour
des dimensions supérieures à deux. Le meilleur moyen de jauger
le modèle appris est de vérifier si l’erreur obtenue sur une base
ayant servi à l’apprentissage (ou <em>base d’apprentissage</em>) est conservée
sur une autre base (ou <em>base de test</em>) que le modèle découvre pour la première fois.</p>
<p>Soit <img class="math" src="../../_images/math/fc2a85c849ed06ab55c20b172687a6f400a313f1.svg" alt="B=\acc{\pa{X_i,Y_i} | 1 \leqslant i \leqslant N}"/>
l’ensemble des observations disponibles. Cet ensemble est
aléatoirement scindé en deux sous-ensembles <img class="math" src="../../_images/math/0eeb12bcfd68682b81a08bd0a0891d66fb489efb.svg" alt="B_a"/> et <img class="math" src="../../_images/math/739004e0316eecb56f6f6a20192d7308ead48c54.svg" alt="B_t"/>
de telle sorte que :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/c27888ed784c4f9cf26a5cd430e81ab050531e09.svg" alt="\begin{array}{l}
B_a \neq \emptyset \text{ et } B_t \neq \emptyset \\
B_a \cup B_t = B \text{ et } B_a \cap B_t = \emptyset \\
\frac{\#{B_a}}{\#{B_a \cup B_t}} = p \in ]0,1[
            \text{, en règle générale, } p \in \cro{\frac{1}{2},\frac{3}{4}}
\end{array}"/></p>
</div></div>
<p>Ce découpage est valide si tous les exemples de la base <img class="math" src="../../_images/math/3fba415f1647be3b47dae3f8a76087fd88af90a9.svg" alt="B"/>
obéissent à la même loi, les deux bases <img class="math" src="../../_images/math/0eeb12bcfd68682b81a08bd0a0891d66fb489efb.svg" alt="B_a"/> et <img class="math" src="../../_images/math/739004e0316eecb56f6f6a20192d7308ead48c54.svg" alt="B_t"/>
sont dites <em>homogènes</em>. Le réseau de neurones sera donc appris sur la
base d’apprentissage <img class="math" src="../../_images/math/0eeb12bcfd68682b81a08bd0a0891d66fb489efb.svg" alt="B_a"/> et « testé » sur la base de test
<img class="math" src="../../_images/math/739004e0316eecb56f6f6a20192d7308ead48c54.svg" alt="B_t"/>. Le test consiste à vérifier que l’erreur sur <img class="math" src="../../_images/math/739004e0316eecb56f6f6a20192d7308ead48c54.svg" alt="B_t"/>
est sensiblement égale à celle sur <img class="math" src="../../_images/math/0eeb12bcfd68682b81a08bd0a0891d66fb489efb.svg" alt="B_a"/>, auquel cas on dit que le
modèle (ou réseau de neurones) généralise bien. Le modèle trouvé
n’est pas pour autant le bon modèle mais il est robuste.
La courbe figure suivante illustre une définition du modèle optimal
comme étant celui qui minimise l’erreur sur la base de test.
Lorsque le modèle choisi n’est pas celui-là, deux cas sont possibles :</p>
<ul class="simple">
<li><p>Le nombre de coefficients est trop petit :
le modèle généralise bien mais il existe d’autres modèles
meilleurs pour lesquels l’erreur d’apprentissage et de test est moindre.</p></li>
<li><p>Le nombre de coefficients est trop grand : le modèle généralise mal,
l’erreur d’apprentissage est faible et l’erreur de test élevée,
le réseau a appris la base d’apprentissage par coeur.</p></li>
</ul>
<div class="admonition-mathdef admonition" id="indexmathe-Figure0">
<p class="admonition-title">Figure F1 : Modèle optimal pour la base de test</p>
<img alt="../../_images/errapptest.png" src="../../_images/errapptest.png" />
</div>
<p>Ce découpage des données en deux bases d’apprentissage et de
test est fréquemment utilisé pour toute estimation de modèles
résultant d’une optimisation réalisée au moyen d’un algorithme itératif.
C’est le cas par exemple des modèles de Markov cachés.
Elle permet de s’assurer qu’un modèle s’adapte bien à de nouvelles données.</p>
</section>
<section id="fonction-de-transfert-a-base-radiale">
<span id="rnn-fonction-base-radiale-rbf"></span><h2>Fonction de transfert à base radiale<a class="headerlink" href="#fonction-de-transfert-a-base-radiale" title="Lien vers cette rubrique">¶</a></h2>
<p>La fonction de transfert est dans ce cas à base radiale
(souvent abrégée par RBF pour <a class="reference external" href="https://en.wikipedia.org/wiki/Radial_basis_function">radial basis function</a>.
Elle ne s’applique pas au produit scalaire entre le
vecteur des poids et celui des entrées mais
à la distance euclidienne entre ces vecteurs.</p>
<div class="admonition-mathdef admonition" id="indexmathe-Définition0">
<div class="docutils container">
</div>
<p class="admonition-title" id="rn-definition-neurone-dist">Définition D1 : neurone distance</p>
<p>Un neurone distance à <img class="math" src="../../_images/math/6fe7973e241cac84eec5598231dc7f6e68e88282.svg" alt="p"/> entrées est une fonction
<img class="math" src="../../_images/math/52cf97d8f0b8f4036d1de45c2d29e2d656391b7f.svg" alt="f : \mathbb{R}^{p+1} \times \mathbb{R}^p \longrightarrow \mathbb{R}"/> définie par :</p>
<ul class="simple">
<li><p><img class="math" src="../../_images/math/cde37f212e7219edf5062c413522f4e66e75e526.svg" alt="g : \mathbb{R} \dans \mathbb{R}"/></p></li>
<li><p><img class="math" src="../../_images/math/2463400b6f0242dd9cebce8502ade396e7201580.svg" alt="W \in \mathbb{R}^{p+1}"/>, <img class="math" src="../../_images/math/7e6959ce99b2f5ef6937138101ddde49982677f4.svg" alt="W=\pa{w_1,\dots,w_{p+1}} = \pa{W',w_{p+1}}"/></p></li>
<li><p><img class="math" src="../../_images/math/40ea54a38f6f5e1c90c718c4e5e12f8647ce3b93.svg" alt="\forall x \in \mathbb{R}^p, \; f\pa{W,x} = e^{-\norm{W'-x}^2 + w_{p+1}}"/>
avec <img class="math" src="../../_images/math/e96b76f3cc6d0e71bfa4bd54d8b4bb4776fe4eba.svg" alt="x = \pa{x_1,\dots,x_p}"/></p></li>
</ul>
</div>
<p>Ce neurone est un cas particulier du suivant qui pondère chaque
dimension par un coefficient. Toutefois, ce neurone possède <img class="math" src="../../_images/math/97c134dacbc7ac99e2aa798e720033e5964e71b3.svg" alt="2p+1"/>
coefficients où <img class="math" src="../../_images/math/6fe7973e241cac84eec5598231dc7f6e68e88282.svg" alt="p"/> est le nombre d’entrée.</p>
<div class="admonition-mathdef admonition" id="indexmathe-Définition1">
<div class="docutils container">
</div>
<p class="admonition-title" id="rn-definition-neurone-dist-pond">Définition D2 : neurone distance pondérée</p>
<p>Pour un vecteur donné <img class="math" src="../../_images/math/a5d9e17533626c1153c0783d32562e59a632bce8.svg" alt="W \in \mathbb{R}^p = \pa{w_1,\dots,w_p}"/>,
on note <img class="math" src="../../_images/math/68c2725662f4994bd3d6b23d68bdf1a7efb47635.svg" alt="W_i^j = \pa{w_i,\dots,w_j}"/>.
Un neurone distance pondérée à <img class="math" src="../../_images/math/6fe7973e241cac84eec5598231dc7f6e68e88282.svg" alt="p"/> entrées est une fonction
<img class="math" src="../../_images/math/d582801d7d559907d4942ae8f1938ccab68bec37.svg" alt="f : \mathbb{R}^{2p+1} \times \mathbb{R}^p \longrightarrow \mathbb{R}"/> définie par :</p>
<ul class="simple">
<li><p><img class="math" src="../../_images/math/cde37f212e7219edf5062c413522f4e66e75e526.svg" alt="g : \mathbb{R} \dans \mathbb{R}"/></p></li>
<li><p><img class="math" src="../../_images/math/d7ccb255e8369e580ee87658685320571e2682a5.svg" alt="W \in \mathbb{R}^{2p+1}"/>, <img class="math" src="../../_images/math/fd92eab23ccf050cd11111d69ef6c8b6928ce6fa.svg" alt="W=\pa{w_1,\dots,w_{2p+1}} = \pa{w_1,w_{2p+1}}"/></p></li>
<li><p><img class="math" src="../../_images/math/763dccfba3f0c7e3c3cb9659c28b43311fa60c0b.svg" alt="\forall x \in \mathbb{R}^p, \; f\pa{W,x} =
\exp \cro {-\cro{\sum_{i=1}^{p} w_{p+i}\pa{w_i - x_i}^2 } + w_{p+1}}"/>
avec <img class="math" src="../../_images/math/e96b76f3cc6d0e71bfa4bd54d8b4bb4776fe4eba.svg" alt="x = \pa{x_1,\dots,x_p}"/></p></li>
</ul>
</div>
<p>La fonction de transfert est <img class="math" src="../../_images/math/53fc7242bc9d4dcbd819c12e80288717a653a670.svg" alt="x \longrightarrow e^x"/>
est le potentiel de ce neurone donc :
<img class="math" src="../../_images/math/1b8e393e264c5084d87180b6f20d4a76e40f82aa.svg" alt="y = -\cro{\sum_{i=1}^{p} w_{p+i}\pa{w_i - x_i}^2 } + w_{p+1}"/>.</p>
<p>L’algorithme de <a class="reference internal" href="rn_5_newton.html#algo-retropropagation"><span class="std std-ref">rétropropagation</span></a>
est modifié par l’insertion d’un tel neurone dans un réseau ainsi que la rétropropagation.
Le plus simple tout d’abord :</p>
<div class="math-wrapper docutils container" id="equation-eq-no-distance-nn">
<div class="math" id="equation-eq-no-distance-nn">
<p><span class="eqno">(1)<a class="headerlink" href="#equation-eq-no-distance-nn" title="Lien vers cette équation">¶</a></span><img src="../../_images/math/609fb9a40211db06520e0718c709964155c08f80.svg" alt="\begin{eqnarray*}
1 \leqslant i \leqslant p, &amp; \dfrac{\partial y}{\partial w_{i}} = &amp; - 2 w_{p+i}\pa{w_i - x_i} \\
p+1 \leqslant i \leqslant 2p, &amp; \dfrac{\partial y}{\partial w_{i}} = &amp; - \pa{w_i - x_i}^2 \\
i = 2p+1, &amp; \dfrac{\partial y}{\partial w_{i}} = &amp; -1
\end{eqnarray*}"/></p>
</div></div>
<p>Pour le neurone distance simple, la ligne <a class="reference internal" href="#equation-eq-no-distance-nn">(1)</a>
est superflue, tous les coefficients <img class="math" src="../../_images/math/9ab39f4686c6d36c7543068677e2cda37290c8e5.svg" alt="(w_i)_{p+1 \leqslant i \leqslant 2p}"/>
sont égaux à 1. La relation <a class="reference internal" href="rn_5_newton.html#equation-retro-eq-nn-3">(6)</a> reste vraie mais n’aboutit plus à:eq:<cite>algo_retro_5</cite>,
celle-ci devient en supposant que la couche d’indice <img class="math" src="../../_images/math/022815260d4c6668817165e3f0dccd3607173715.svg" alt="c+1"/>
ne contient que des neurones définie par la définition précédente.</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/5db3471a58b471833cd7165065b2f30a9d42be7f.svg" alt="\begin{eqnarray*}
\partialfrac{e}{y_{c,i}}
                            &amp;=&amp; \sum_{l=1}^{C_{c+1}}              \partialfrac{e}{y_{c+1,l}}
                                                                \partialfrac{y_{c+1,l}}{z_{c,i}}
                                                                \partialfrac{z_{c,i}}{y_{c,i}}  \\
     &amp;=&amp; \cro{ \sum_{l=1}^{C_{c+1}}
                             \partialfrac{e}{y_{c+1,l}}
                \pa{ 2 w_{c+1,l,p+i} \pa{ w_{c+1,l,i} - z_{c,i} } } }
                \partialfrac{z_{c,i}}{y_{c,i}}
\end{eqnarray*}"/></p>
</div></div>
</section>
<section id="poids-partages">
<h2>Poids partagés<a class="headerlink" href="#poids-partages" title="Lien vers cette rubrique">¶</a></h2>
<p>Les poids partagés sont simplement un ensemble de poids qui sont
contraints à conserver la même valeur. Soit <img class="math" src="../../_images/math/86a30eae2899d36dcee14ab62c5e4c8a68feed4d.svg" alt="G"/> un groupe de poids
partagés dont la valeur est <img class="math" src="../../_images/math/605e55ee78028b38b4c009d5846f85b3b1f7bf62.svg" alt="w_{G}"/>. Soit <img class="math" src="../../_images/math/a64fc33c15255329b8e9309a9a44e1e0f012f72f.svg" alt="X_k"/> et <img class="math" src="../../_images/math/3ea04d0a63c72ed9fe99343c10c80d1c65850271.svg" alt="Y_k"/>
un exemple de la base d’apprentissage (entrées et sorties désirées),
l’erreur commise par le réseau de neurones est <img class="math" src="../../_images/math/5b7b74551bcbca5ac2facd2fb44076688b1255a7.svg" alt="e\left(  W,X_k,Y_k\right)"/>.</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/2dc01c864c3d4a0fc4cd23913d3c0ef7f6519e3e.svg" alt="\dfrac{\partial e\left(  W,X_{k},Y_{k}\right)  }
{\partial w_{G}}=\sum_{w\in G}\dfrac{\partial e\left(  W,X_{k},Y_{k}\right) }{\partial
w_G}\dfrac{\partial w_{G}}{\partial w}=\sum_{w\in G}
{\sum} \dfrac{\partial e\left(  W,X_{k},Y_{k}\right)  }{\partial w_G}"/></p>
</div></div>
<p>Par conséquent, si un poids <img class="math" src="../../_images/math/c43b263f4cf0cb143b4ab0c37fb828bcde629b5b.svg" alt="w"/> appartient à un groupe <img class="math" src="../../_images/math/86a30eae2899d36dcee14ab62c5e4c8a68feed4d.svg" alt="G"/> de poids partagés,
sa valeur à l’itération suivante sera :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/13b490b8bc82b1076298f1f092c7ab9c6d4a0406.svg" alt="w_{t+1}=w_{t}-\varepsilon_{t}\left(  \underset{w\in G}
{\sum}\dfrac{\partial e\left(  W,X_{k},Y_{k}\right)  }{\partial w}\right)"/></p>
</div></div>
<p>Cette idée est utilisée dans les
<a class="reference external" href="https://fr.wikipedia.org/wiki/R%C3%A9seau_neuronal_convolutif">réseaux neuronaux convolutifs</a>
(<a class="reference external" href="https://fr.wikipedia.org/wiki/Apprentissage_profond">deep learning</a>,
<a class="reference external" href="http://cs231n.github.io/neural-networks-1/#layers">CS231n Convolutional Neural Networks for Visual Recognition</a>).</p>
</section>
<section id="derivee-par-rapport-aux-entrees">
<h2>Dérivée par rapport aux entrées<a class="headerlink" href="#derivee-par-rapport-aux-entrees" title="Lien vers cette rubrique">¶</a></h2>
<p>On note <img class="math" src="../../_images/math/0627a90adefbbb8c362ddfc681454ed4a38a901e.svg" alt="\left(  X_k,Y_k\right)"/> un exemple de la base d’apprentissage.
Le réseau de neurones est composé de <img class="math" src="../../_images/math/2c0e77bc741b692ecdf6e85966263a89422af4c8.svg" alt="C"/> couches, <img class="math" src="../../_images/math/028f0a9b50db11bb7b06a1941fbc0c441259482c.svg" alt="C_i"/> est le
nombre de neurones sur la ième couche, <img class="math" src="../../_images/math/9416b3762998776263c210d40042d2775b70deeb.svg" alt="C_0"/> est le nombre d’entrées.
Les entrées sont appelées <img class="math" src="../../_images/math/26e1797c0a4758dde7c5e0b991bec29f2be88541.svg" alt="\left( z_{0,i}\right) _{1\leqslant i\leqslant C_{0}}"/>,
<img class="math" src="../../_images/math/a314398299b02b6b3139d63e7be38b62f9e96be9.svg" alt="\left(  y_{1,i}\right)  _{1\leqslant i\leqslant C_{1}}"/>
sont les potentiels des neurones de la première couche, on en déduit que, dans le cas d’un neurone classique (non distance) :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/c41e22786c61e938ee94808bad1b390e699b9616.svg" alt="\dfrac{\partial e\left(  W,X_{k},Y_{k}\right)  }{\partial z_{0,i}} =
    \underset{j=1}{\overset{C_{1}}{\sum}}\dfrac{\partial e\left(  W,X_{k}
,Y_{k}\right)  }{\partial y_{1,j}}\dfrac{\partial y_{1,j}}{\partial z_{0,i}
 }=\underset{j=1}{\overset{C_{1}}{\sum}}\dfrac{\partial e\left( W,X_{k}
,Y_{k}\right)  }{\partial y_{1,j}}w_{1,j,i}"/></p>
</div></div>
<p>Comme le potentiel d’un neurone distance n’est pas linéaire par
rapport aux entrées <img class="math" src="../../_images/math/4c0545b1fe2134de5024b1d37b4d807ba86dc59b.svg" alt="\left( y=\overset{N} {\underset{i=1}{\sum}}\left( w_{i}-z_{0,i}\right)  ^{2}+b\right)"/>,
la formule devient dans ce cas :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/0ae2c2ccbb1a753bd84d33f29157330b27697fe3.svg" alt="\dfrac{\partial e\left(  W,X_{k},Y_{k}\right)  }{\partial z_{0,i}} =
        \underset{j=1}{\overset{C_{1}}{\sum}}\dfrac{\partial e\left(  W,X_{k}
,Y_{k}\right)  }{\partial y_{1,j}}\dfrac{\partial y_{1,j}}{\partial z_{0,i}
     }=-2\underset{j=1}{\overset{C_{1}}{\sum}}\dfrac{\partial e\left(
W,X_{k},Y_{k}\right)  }{\partial y_{1,j}}\left(  w_{1,j,i}-z_{0,i}\right)"/></p>
</div></div>
</section>
<section id="regularisation-ou-decay">
<span id="rn-decay"></span><h2>Régularisation ou Decay<a class="headerlink" href="#regularisation-ou-decay" title="Lien vers cette rubrique">¶</a></h2>
<p>Lors de l’apprentissage, comme les fonctions de seuil du réseau de
neurones sont bornées, pour une grande variation des coefficients,
la sortie varie peu. De plus, pour ces grandes valeurs, la dérivée
est quasi nulle et l’apprentissage s’en trouve ralenti. Par conséquent,
il est préférable d’éviter ce cas et c’est pourquoi un terme de
régularisation est ajouté lors de la mise à jour des
coefficients (voir <a class="reference internal" href="rn_biblio.html#bishop1995" id="id1"><span>[Bishop1995]</span></a>). L’idée consiste à ajouter
à l’erreur une pénalité fonction des coefficients du réseau de neurones :
<img class="math" src="../../_images/math/32a2787c89949469760c6dd1a803b8ddece0f75f.svg" alt="E_{reg} = E + \lambda \; \sum_{i} \; w_i^2"/>.</p>
<p>Et lors de la mise à jour du poids <img class="math" src="../../_images/math/1f0b3b7ecfa3fe112f400063c7a21c12ebdce12d.svg" alt="w_i^t"/> à l’itération <img class="math" src="../../_images/math/20a0ef7ca257843f3a625036da7c31d4a697742d.svg" alt="t+1"/> :
<img class="math" src="../../_images/math/d8c835f4f3da47a6faaffc7c199abe0797141df2.svg" alt="w_i^{t+1} = w_i^t - \epsilon_t \cro{ \partialfrac{E}{w_i} - 2\lambda w_i^t }"/>.</p>
<p>Le coefficient <img class="math" src="../../_images/math/15a3ea48c9262583d78f2931985b4fe6ef0b912e.svg" alt="\lambda"/> peut décroître avec le nombre
d’itérations et est en général de l’ordre de <img class="math" src="../../_images/math/846c221bf011b22e2ea917c1c9328467c287b965.svg" alt="0,01"/> pour un
apprentissage avec gradient global, plus faible pour un
apprentissage avec gradient stochastique.</p>
</section>
<section id="problemes-de-gradients">
<h2>Problèmes de gradients<a class="headerlink" href="#problemes-de-gradients" title="Lien vers cette rubrique">¶</a></h2>
<p>La descente du gradient repose sur l’algorithme de <a class="reference internal" href="rn_5_newton.html#algo-retropropagation"><span class="std std-ref">rétropropagation</span></a>
qui propoge l’erreur depuis la dernière couche jusqu’à la première.
Pour peu qu’une fonction de seuil soit saturée. Hors la zone rouge,
le gradient est très atténué.</p>
<p>(<a class="reference download internal" download="" href="../../_downloads/1873cb36a7e959870caf4430c6509499/rn_8_prol-1.py"><code class="xref download docutils literal notranslate"><span class="pre">Source</span> <span class="pre">code</span></code></a>, <a class="reference download internal" download="" href="../../_downloads/60d8ca63d272598ae22ebc089308998e/rn_8_prol-1.png"><code class="xref download docutils literal notranslate"><span class="pre">png</span></code></a>, <a class="reference download internal" download="" href="../../_downloads/3a96f40fa319711a242ceb1f49d50555/rn_8_prol-1.hires.png"><code class="xref download docutils literal notranslate"><span class="pre">hires.png</span></code></a>, <a class="reference download internal" download="" href="../../_downloads/e8362d6036c915138e3f81a41a679cdc/rn_8_prol-1.pdf"><code class="xref download docutils literal notranslate"><span class="pre">pdf</span></code></a>)</p>
<figure class="align-default">
<img alt="../../_images/rn_8_prol-1.png" class="plot-directive" src="../../_images/rn_8_prol-1.png" />
</figure>
<p id="index-0">Après deux couches de fonctions de transferts, le
gradient est souvent diminué. On appelle ce phénomène
le <a class="reference external" href="https://en.wikipedia.org/wiki/Vanishing_gradient_problem">Vanishing gradient problem</a>.
C’est d’autant plus probable que le réseau est gros. Quelques pistes pour y remédier :
<a class="reference external" href="http://www.wildml.com/2015/10/recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/">Recurrent Neural Networks Tutorial, Part 3 – Backpropagation Through Time and Vanishing Gradients</a>,
<a class="reference external" href="http://neuralnetworksanddeeplearning.com/chap5.html">Why are deep neural networks hard to train?</a>.
L’article <a class="reference external" href="http://arxiv.org/pdf/1512.03385v1.pdf">Deep Residual Learning for Image Recognition</a>
présente une structure de réseau qui va dnas le même sens.
De la même manière, la norme du gradient peut exploser plus particulièrement dans le cas des
<a class="reference external" href="https://en.wikipedia.org/wiki/Recurrent_neural_network">réseaux de neurones récurrents</a> :
<a class="reference external" href="http://arxiv.org/pdf/1211.5063v1.pdf">Understanding the exploding gradient problem</a>.</p>
</section>
<section id="selection-de-connexions">
<span id="selection-connexion"></span><h2>Sélection de connexions<a class="headerlink" href="#selection-de-connexions" title="Lien vers cette rubrique">¶</a></h2>
<p>Ce paragraphe présente un algorithme de sélection de l’architecture
d’un réseau de neurones proposé par Cottrel et Al. dans <a class="reference internal" href="rn_biblio.html#cottrel1995" id="id2"><span>[Cottrel1995]</span></a>.
La méthode est applicable à tout réseau de neurones mais n’a été démontrée
que pour la classe de réseau de neurones utilisée pour la
<a class="reference internal" href="rn_2_reg.html#rn-section-regression"><span class="std std-ref">régression</span></a>. Les propriétés qui suivent ne sont
vraies que des réseaux à une couche cachée et dont les sorties
sont linéaires. Soit <img class="math" src="../../_images/math/5deecdaa457deb4cc37c10590bee9a26ac07cddf.svg" alt="\pa{X_k,Y_k}"/> un exemple de la base
d’apprentissage, les résidus de la régression sont supposés normaux
et i.i.d. L’erreur est donc (voir <a class="reference internal" href="rn_4_densite.html#rn-enonce-probleme-regression"><span class="std std-ref">Formulation du problème de la régression</span></a>) :
<img class="math" src="../../_images/math/8950420dbb0ce1cd8668395d2030bd6a05d90ae8.svg" alt="e\left( W,X_k,Y_k\right) =\left(f\left( W,X_k\right)  -Y_k\right)^2"/>.</p>
<p>On peut estimer la loi asymptotique des coefficients du réseau de neurones.
Des connexions ayant un rôle peu important peuvent alors être supprimées
sans nuire à l’apprentissage en testant la nullité du coefficient associé.
On note <img class="math" src="../../_images/math/57a5bdd0c93fcbf6887f74a4798ec923aa656dec.svg" alt="\widehat{W}"/> les poids trouvés par apprentissage et
<img class="math" src="../../_images/math/1b179b5819480b7b8dec14aa124853c1a7219c58.svg" alt="\overset{\ast}{W}"/> les poids optimaux. On définit :</p>
<div class="math-wrapper docutils container" id="equation-rn-selection-suite">
<div class="math" id="equation-rn-selection-suite">
<p><span class="eqno">(2)<a class="headerlink" href="#equation-rn-selection-suite" title="Lien vers cette équation">¶</a></span><img src="../../_images/math/b9251f12bf18caba5ce5e2729539d993877e7af0.svg" alt="\begin{eqnarray*}
\text{la suite } \widehat{\varepsilon_{k}} &amp;=&amp;   f\left(  \widehat{W} ,X_{k}\right)  -Y_{k}, \;
                             \widehat{\sigma}_{N}^{2}=\dfrac{1}{N}\underset
                                {k=1}{\overset{N}{\sum}}\widehat{\varepsilon_{k}}^{2} \\
\text{la matrice }
\widehat{\Sigma_{N}}      &amp;=&amp;   \dfrac{1}{N}\left[  \nabla_{\widehat{W}%
                                }e\left(  W,X_{k},Y_{k}\right)  \right]
                                \left[  \nabla_{\widehat{W}}
                                e\left(  W,X_{k},Y_{k}\right)  \right]  ^{\prime}
\end{eqnarray*}"/></p>
</div></div>
<div class="admonition-mathdef admonition" id="indexmathe-Théorème0">
<div class="docutils container">
</div>
<p class="admonition-title" id="theoreme-loi-asym">Théorème T1 : loi asymptotique des coefficients</p>
<p>Soit <img class="math" src="../../_images/math/bd1e0600a66dbe0f8deddbd57953774419ba4e4f.svg" alt="f"/> un réseau de neurone défini par <a class="reference internal" href="rn_1_def.html#rn-definition-perpception-1"><span class="std std-ref">perceptron</span></a>
composé de :</p>
<ul class="simple">
<li><p>une couche d’entrées</p></li>
<li><p>une couche cachée dont les fonctions de transfert sont sigmoïdes</p></li>
<li><p>une couche de sortie dont les fonctions de transfert sont linéaires</p></li>
</ul>
<p>Ce réseau sert de modèle pour la fonction <img class="math" src="../../_images/math/bd1e0600a66dbe0f8deddbd57953774419ba4e4f.svg" alt="f"/>
dans le problème de <a class="reference internal" href="rn_2_reg.html#problem-regression"><span class="std std-ref">régression</span></a>
avec un échantillon <img class="math" src="../../_images/math/c163f50d6d186bd7c7d4756763a5d3f4224633e7.svg" alt="\vecteur{\pa{X_1,Y_1}}{\pa{X_N,Y_N}}"/>,
les résidus sont supposés normaux.
La suite <img class="math" src="../../_images/math/3319517f5d321d500a6d68814a33d89a79db2358.svg" alt="\pa{\widehat{\epsilon_k}}"/> définie par <a class="reference internal" href="#equation-rn-selection-suite">(2)</a> vérifie :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/ee90a064010c907ffc7f53301f41fed319db38ce.svg" alt="\dfrac{1}{N} \sum_{i=1}^{N} \widehat{\epsilon_k} = 0 = \esp\cro{f\pa{\widehat{W},X} - Y}"/></p>
</div></div>
<p>Et le vecteur aléatoire <img class="math" src="../../_images/math/0fbcfb607f20adbde032e5407bfdc00131184cc6.svg" alt="\widehat{W} - W^*"/> vérifie :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/41d2e2dd5099d129025c3cec7fce599c993a45cf.svg" alt="\sqrt{N} \cro { \widehat{W} - W^* } \; \overset{T \rightarrow + \infty}{\longrightarrow} \;
        \loinormale{0}{\widehat{\sigma_N}^2  \widehat{\Sigma_N}}"/></p>
</div></div>
<p>Où la matrice <img class="math" src="../../_images/math/9418335eb3c551e154e1b21d3dfd75ff40f8d2b7.svg" alt="\widehat{\Sigma_N}"/> est définie par <a class="reference internal" href="#equation-rn-selection-suite">(2)</a>.</p>
<p>end{xtheorem}</p>
</div>
<div class="admonition-mathdef admonition" id="indexmathe-Figure1">
<div class="docutils container">
</div>
<p class="admonition-title" id="figure-selection-connexion-reseau-fig">Figure F2 : Réseau de neurones pour lequel la sélection de connexions s’applique</p>
<img alt="../../_images/selection_connexion.png" src="../../_images/selection_connexion.png" />
</div>
<p>La démonstration de ce théorème est donnée par l’article <a class="reference internal" href="rn_biblio.html#cottrel1995" id="id3"><span>[Cottrel1995]</span></a>.
Ce théorème mène au corollaire suivant :</p>
<div class="admonition-mathdef admonition" id="indexmathe-Corollaire0">
<p class="admonition-title">Corollaire C1 : nullité d’un coefficient</p>
<p>Les notations utilisées sont celles du théorème sur <a class="reference internal" href="#theoreme-loi-asym"><span class="std std-ref">loi asymptotique des coefficients</span></a>.
Soit <img class="math" src="../../_images/math/7ce138f79658aa7905cfd9a26a656ed8feb7b343.svg" alt="w_k"/> un poids du réseau de neurones
d’indice quelconque <img class="math" src="../../_images/math/312028c07e271534bd0dbde5434e49e76880744f.svg" alt="k"/>. Sa valeur estimée est <img class="math" src="../../_images/math/979882112343af87c6768ac9de482e7f92ebd677.svg" alt="\widehat{w_k}"/>,
sa valeur optimale <img class="math" src="../../_images/math/8a6d2a2b69b8d0a53bb736e6ca7eef7c12aec198.svg" alt="w^*_k"/>. D’après le théorème :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/58f8107283925144fb2f49c063885082398750ef.svg" alt="N \dfrac{ \pa{\widehat{w_k} - w^*_k}^2  } { \widehat{\sigma_N}^2 \pa{\widehat{\Sigma_N}^{-1}}_{kk} }
\; \overset{T \rightarrow + \infty}{\longrightarrow} \; \chi^2_1"/></p>
</div></div>
</div>
<p>Ce résultat permet, à partir d’un réseau de neurones, de supprimer les
connexions pour lesquelles l’hypothèse de nullité n’est pas réfutée.
Afin d’aboutir à l’architecture minimale adaptée au problème,
Cottrel et Al. proposent dans <a class="reference internal" href="rn_biblio.html#cottrel1995" id="id4"><span>[Cottrel1995]</span></a> l’algorithme suivant :</p>
<div class="admonition-mathdef admonition" id="indexmathe-Théorème1">
<div class="docutils container">
</div>
<p class="admonition-title" id="rn-algorithme-selection-connexion-1">Théorème T2 : sélection d’architecture</p>
<p>Les notations utilisées sont celles du théorème
<a class="reference internal" href="#theoreme-loi-asym"><span class="std std-ref">loi asymptotique des coefficients</span></a>.
<img class="math" src="../../_images/math/bd1e0600a66dbe0f8deddbd57953774419ba4e4f.svg" alt="f"/> est un réseau de neurones
de paramètres <img class="math" src="../../_images/math/6ed861ef9c1c0829f1587232c699cfac35dacce7.svg" alt="W"/>. On définit la constante <img class="math" src="../../_images/math/47d551fe327b69e25084e035c2cf3e9e6d73c033.svg" alt="\tau"/>,
en général <img class="math" src="../../_images/math/3e1d45b9ff08525a3e4ce124ae97f01e5af6b84d.svg" alt="\tau = 3,84"/> puisque
<img class="math" src="../../_images/math/602be74aca7c948e60e6617cc78f9ccad79fc552.svg" alt="\pr {X &lt; \tau} = 0,95"/> si <img class="math" src="../../_images/math/9458a0a7d4012518f5cd3476676da7f16f400d00.svg" alt="X \sim \chi_1^2"/>.</p>
<p><em>Initialisation</em></p>
<p>Une architecture est choisie pour le réseau de neurones <img class="math" src="../../_images/math/bd1e0600a66dbe0f8deddbd57953774419ba4e4f.svg" alt="f"/> incluant un nombre <cite>M</cite> de paramètres.</p>
<p><em>Apprentissage</em></p>
<p>Le réseau de neurones <img class="math" src="../../_images/math/bd1e0600a66dbe0f8deddbd57953774419ba4e4f.svg" alt="f"/> est appris. On calcule les nombre et matrice
<img class="math" src="../../_images/math/70f7c40ae4ee12c8a7a79c900dcd3636f76da807.svg" alt="\widehat{\sigma_N}^2"/> et <img class="math" src="../../_images/math/9418335eb3c551e154e1b21d3dfd75ff40f8d2b7.svg" alt="\widehat{\Sigma_N}"/>.
La base d’apprentissage contient <img class="math" src="../../_images/math/bceb9186b5004313ecccd0d22d07ea9617b62f98.svg" alt="N"/> exemples.</p>
<p><em>Test</em></p>
<div class="line-block">
<div class="line">for <img class="math" src="../../_images/math/312028c07e271534bd0dbde5434e49e76880744f.svg" alt="k"/> in <img class="math" src="../../_images/math/fcdd037da4fc0ce013fc612a738c5eaa250fa8a5.svg" alt="1..M"/></div>
<div class="line-block">
<div class="line"><img class="math" src="../../_images/math/02ba6c70075149bb9e1bf4cb51656746c4bf9d23.svg" alt="t_k \longleftarrow N \dfrac{ \widehat{w_k} ^2  } { \widehat{\sigma_N}^2 \pa{\widehat{\Sigma_N}^{-1}}_{kk} }"/></div>
</div>
</div>
<p><em>Sélection</em></p>
<div class="line-block">
<div class="line"><img class="math" src="../../_images/math/621116b378ce5a1253f21a8b73aadb90f6720639.svg" alt="k' \longleftarrow \underset{k}{\arg \min} \; t_k"/></div>
<div class="line">si <img class="math" src="../../_images/math/0ceb92f2dbe62b3b566ce97c8efe6bdd636d82ae.svg" alt="t_{k'} &lt; \tau"/></div>
<div class="line-block">
<div class="line">Le modèle obtenu est supposé être le modèle optimal. L’algorithme s’arrête.</div>
</div>
<div class="line">sinon</div>
<div class="line-block">
<div class="line">La connexion <img class="math" src="../../_images/math/3878fbf6dff1d22ddae62bf36097813d359ccc25.svg" alt="k'"/> est supprimée ou le poids <img class="math" src="../../_images/math/0d75aff769bb2e861e0341dad25d32005fa56be2.svg" alt="w_{k'}"/> est maintenue à zéro.</div>
<div class="line"><img class="math" src="../../_images/math/0c4fa2836d4d011f6704f4ad3c9e677f24fe0c10.svg" alt="M \longleftarrow M-1"/></div>
<div class="line">Retour à l’apprentissage.</div>
</div>
</div>
</div>
<p>Cet algorithme est sensible au minimum local trouvé lors de l’apprentissage, il est préférable d’utiliser des méthodes
du second ordre afin d’assurer une meilleure convergence du réseau de neurones.</p>
<p>L’étape de sélection ne supprime qu’une seule connexion. Comme l’apprentissage
est coûteux en calcul, il peut être intéressant de supprimer toutes les connexions
<img class="math" src="../../_images/math/312028c07e271534bd0dbde5434e49e76880744f.svg" alt="k"/> qui vérifient <img class="math" src="../../_images/math/34ae902eb2b1df4db1b087a5cadbc85f581fb02d.svg" alt="t_k &lt; \tau"/>. Il est toutefois conseillé de ne
pas enlever trop de connexions simultanément puisque la suppression d’une connexion nulle peut
réhausser le test d’une autre connexion, nulle à cette même itération, mais non nulle à l’itération suivante.
Dans l’article <a class="reference internal" href="rn_biblio.html#cottrel1995" id="id5"><span>[Cottrel1995]</span></a>, les auteurs valident leur algorithme dans le cas d’une
régression grâce à l’algorithme suivant.</p>
<div class="admonition-mathdef admonition" id="indexmathe-Algorithme0">
<div class="docutils container">
</div>
<p class="admonition-title" id="nn-algorithme-valid-selection">Algorithme A1 : validation de l’algorithme de sélection des coefficients</p>
<p><em>Choix aléatoire d’un modèle</em></p>
<p>Un réseau de neurones est choisi aléatoirement,
soit <img class="math" src="../../_images/math/35126ddde248236e526d6f7bc5cc201734832be2.svg" alt="f : \mathbb{R}^p \dans \mathbb{R}"/> la fonction qu’il représente.
Une base d’apprentissage <img class="math" src="../../_images/math/5fdb7ef407cf673109e4443028c7e8898ee8c89e.svg" alt="A"/> (ou échantillon)
de <img class="math" src="../../_images/math/bceb9186b5004313ecccd0d22d07ea9617b62f98.svg" alt="N"/> observations est générée aléatoirement à partir de ce modèle :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/5a4076d35e02dae275174ee4ae5878560523d56e.svg" alt="\begin{array}{l}
\text{soit } \pa{\epsilon_i}_{1 \leqslant i \leqslant N} \text{ un bruit blanc} \\
A = \acc{ \left. \pa{X_i,Y_i}_{1 \leqslant i \leqslant N} \right|
            \forall i \in \intervalle{1}{N}, \; Y_i = f\pa{X_i} + \epsilon_i }
\end{array}"/></p>
</div></div>
<p><em>Choix aléatoire d’un modèle</em></p>
<p>L’algorithme de <a class="reference internal" href="#rn-algorithme-selection-connexion-1"><span class="std std-ref">sélection</span></a>
à un réseau de neurones plus riche que le modèle choisi
dans l’étape d’initilisation. Le modèle sélectionné est noté <img class="math" src="../../_images/math/3a8d8bad8d0f9dcf76fdcc134f09a2a698f2d77f.svg" alt="g"/>.</p>
<p><em>Validation</em></p>
<p>Si <img class="math" src="../../_images/math/7a297e087475ab6bbe0dee373c7906e21786ea72.svg" alt="\norm{f-g} \approx 0"/>,
l’algorithme de
<a class="reference internal" href="#rn-algorithme-selection-connexion-1"><span class="std std-ref">sélection</span></a>
est validé.</p>
</div>
<p>La réduction des réseaux de neurones ne se posent plus en ce sens.
Les réseaux de neurones sont aujourd’hui des réseaux de neurones
de neurones profonds qui ne suivent plus cette architecture à une
couche.</p>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="rn_9_auto.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Analyse en composantes principales (ACP) et Auto Encoders</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="rn_7_clas2.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Classification</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2016-2025, Xavier Dupré
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Prolongements</a><ul>
<li><a class="reference internal" href="#base-d-apprentissage-et-base-de-test">Base d’apprentissage et base de test</a></li>
<li><a class="reference internal" href="#fonction-de-transfert-a-base-radiale">Fonction de transfert à base radiale</a></li>
<li><a class="reference internal" href="#poids-partages">Poids partagés</a></li>
<li><a class="reference internal" href="#derivee-par-rapport-aux-entrees">Dérivée par rapport aux entrées</a></li>
<li><a class="reference internal" href="#regularisation-ou-decay">Régularisation ou Decay</a></li>
<li><a class="reference internal" href="#problemes-de-gradients">Problèmes de gradients</a></li>
<li><a class="reference internal" href="#selection-de-connexions">Sélection de connexions</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../../_static/documentation_options.js?v=0886690b"></script>
    <script src="../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/scripts/furo.js?v=46bd48cc"></script>
    <script src="../../_static/translations.js?v=e6b791cb"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    </body>
</html>