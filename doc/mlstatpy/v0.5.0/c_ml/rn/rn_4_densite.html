<!doctype html>
<html class="no-js" lang="fr" data-content_root="../../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../../genindex.html" /><link rel="search" title="Recherche" href="../../search.html" /><link rel="next" title="Descente de gradient" href="rn_5_newton.html" /><link rel="prev" title="La classification" href="rn_3_clas.html" />

    <!-- Generated with Sphinx 8.1.3 and Furo 2024.08.06 -->
        <title>Démonstration du théorème de la densité des réseaux de neurones - Documentation mlstatpy 0.5.0</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo.css?v=354aac6f" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css?v=4ae1632d" />
    <link rel="stylesheet" type="text/css" href="../../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo-extensions.css?v=302659d7" />
    
    


<style>
  body {
    --color-code-background: #eeffcc;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../../index.html"><div class="brand">Documentation mlstatpy 0.5.0</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../../index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="../../_static/project_ico.png" alt="Logo"/>
  </div>
  
  <span class="sidebar-brand-text">Documentation mlstatpy 0.5.0</span>
  
</a><form class="sidebar-search-container" method="get" action="../../search.html" role="search">
  <input class="sidebar-search" placeholder="Recherche" name="q" aria-label="Recherche">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Mathematics</span></p>
<ul class="current">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../c_clus/index.html">Clustering</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of Clustering</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../c_clus/kmeans.html">k-means</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../c_clus/gauss_mixture.html">Mélange de lois normales</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../c_clus/kohonen.html">Carte de Kohonen</a></li>
</ul>
</li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="../index.html">Non linéaire</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of Non linéaire</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2 current has-children"><a class="reference internal" href="rn.html">Réseaux de neurones</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of Réseaux de neurones</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="rn_1_def.html">Définition des réseaux de neurones multi-couches</a></li>
<li class="toctree-l3"><a class="reference internal" href="rn_2_reg.html">La régression</a></li>
<li class="toctree-l3"><a class="reference internal" href="rn_3_clas.html">La classification</a></li>
<li class="toctree-l3 current current-page"><a class="current reference internal" href="#">Démonstration du théorème de la densité des réseaux de neurones</a></li>
<li class="toctree-l3"><a class="reference internal" href="rn_5_newton.html">Descente de gradient</a></li>
<li class="toctree-l3"><a class="reference internal" href="rn_6_apprentissage.html">Apprentissage d’un réseau de neurones</a></li>
<li class="toctree-l3"><a class="reference internal" href="rn_7_clas2.html">Classification</a></li>
<li class="toctree-l3"><a class="reference internal" href="rn_8_prol.html">Prolongements</a></li>
<li class="toctree-l3"><a class="reference internal" href="rn_9_auto.html">Analyse en composantes principales (ACP) et Auto Encoders</a></li>
<li class="toctree-l3"><a class="reference internal" href="rn_biblio.html">Bibliographie</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../kppv.html">Classification à l’aide des plus proches voisins</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../missing_values_mf.html">Liens entre factorisation de matrices, ACP, k-means</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of Liens entre factorisation de matrices, ACP, k-means</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/mf_acp.html">Factorisation et matrice et ACP</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/valeurs_manquantes_mf.html">Valeurs manquantes et factorisation de matrices</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/ml/neural_tree.html">Un arbre de décision en réseaux de neurones</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/ml/neural_tree_onnx.html">NeuralTreeNet et ONNX</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/ml/neural_tree_cost.html">NeuralTreeNet et coût</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../index_reg_lin.html">Régression linéaire</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of Régression linéaire</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/dsgarden/regression_lineaire.html">Régression linéaire</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../regression_quantile.html">Régression quantile ou régression L1</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle navigation of Régression quantile ou régression L1</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/dsgarden/quantile_regression_example.html">Régression quantile illustrée</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../piecewise.html">Régression linéaire par morceaux</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle navigation of Régression linéaire par morceaux</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/piecewise_linear_regression.html">Régression linéaire par morceaux</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/regression_no_inversion.html">Régression sans inversion</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../l1l2.html">Normalisation des coefficients</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../index_reg_log.html">Régression logistique</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle navigation of Régression logistique</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lr_voronoi.html">Régression logistique, diagramme de Voronoï, k-Means</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle navigation of Régression logistique, diagramme de Voronoï, k-Means</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/logreg_voronoi.html">Voronoï et régression logistique</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../lr_trees.html">Régression logistique par morceaux, arbres de décision</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/ml/reseau_neurones.html">Réseaux de neurones</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../survival_analysis.html">Analyse de survie</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle navigation of Analyse de survie</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/survival.html">Analyse de survie en pratique</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../c_nlp/index.html">NLP</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><div class="visually-hidden">Toggle navigation of NLP</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../c_nlp/completion.html">Complétion</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><div class="visually-hidden">Toggle navigation of Complétion</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../c_nlp/completion_formalisation.html">Formalisation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../c_nlp/completion_fausse.html">Fausses idées reçues</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../c_nlp/completion_metrique.html">Nouvelle métrique</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../c_nlp/completion_propriete.html">Propriétés mathématiques</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../c_nlp/completion_optimisation.html">Problème d’optimisation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../c_nlp/completion_implementation.html">Implémentation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../c_nlp/completion_digression.html">Digressions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/nlp/completion_trie.html">Complétion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/nlp/completion_profiling.html">Completion profiling</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/nlp/completion_trie_long.html">Completion Trie and metrics</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/nlp/completion_simple.html">Complétion Simple</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../c_metric/index.html">Métriques</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" role="switch" type="checkbox"/><label for="toctree-checkbox-13"><div class="visually-hidden">Toggle navigation of Métriques</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../c_metric/roc.html">Courbe ROC</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" role="switch" type="checkbox"/><label for="toctree-checkbox-14"><div class="visually-hidden">Toggle navigation of Courbe ROC</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/metric/roc_example.html">ROC</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../c_metric/pvalues.html">Confidence Interval and p-Value</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" role="switch" type="checkbox"/><label for="toctree-checkbox-15"><div class="visually-hidden">Toggle navigation of Confidence Interval and p-Value</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/metric/pvalues_examples.html">p-values</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../c_algo/index.html">Algorithmes</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" role="switch" type="checkbox"/><label for="toctree-checkbox-16"><div class="visually-hidden">Toggle navigation of Algorithmes</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../c_algo/edit_distance.html">Distance d’édition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../c_algo/graph_distance.html">Distance between two graphs</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../c_algo/gest.html">Détection de segments</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" role="switch" type="checkbox"/><label for="toctree-checkbox-17"><div class="visually-hidden">Toggle navigation of Détection de segments</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/image/segment_detection.html">Détection de segments dans une image</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../c_garden/index.html">Pérégrinations</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" role="switch" type="checkbox"/><label for="toctree-checkbox-18"><div class="visually-hidden">Toggle navigation of Pérégrinations</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/dsgarden/split_train_test.html">Répartir en base d’apprentissage et de test</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/dsgarden/correlation_non_lineaire.html">Corrélations non linéaires</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../c_garden/file_dattente.html">File d’attente, un petit exemple</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" role="switch" type="checkbox"/><label for="toctree-checkbox-19"><div class="visually-hidden">Toggle navigation of File d’attente, un petit exemple</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/dsgarden/file_dattente_ex.html">File d’attente, un exemple simple</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../c_garden/strategie_avec_alea.html">Optimisation avec données aléatoires</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/dsgarden/discret_gradient.html">Le gradient et le discret</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../c_garden/quantization.html">Quantization</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" role="switch" type="checkbox"/><label for="toctree-checkbox-20"><div class="visually-hidden">Toggle navigation of Quantization</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/dsgarden/quantization_f8.html">Quantization</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/dsgarden/classification_multiple.html">Classification multiple</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../api/index.html">API</a><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" role="switch" type="checkbox"/><label for="toctree-checkbox-21"><div class="visually-hidden">Toggle navigation of API</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../api/ml.html">Machine Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/optim.html">Optimisation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/text.html">Traitement du langage naturel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/data.html">Source de données</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/graph.html">Graphes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/image.html">Image</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../api/modules/index.html">Modules</a><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" role="switch" type="checkbox"/><label for="toctree-checkbox-22"><div class="visually-hidden">Toggle navigation of Modules</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../api/modules/poulet.html">mlstatpy.garden.poulet</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/modules/graph_distance.html">mlstatpy.graph.graph_distance</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/modules/kppv.html">mlstatpy.ml.kppv</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/modules/kppv_laesa.html">mlstatpy.ml.kppv_laesa</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/modules/logreg.html">mlstatpy.ml.logreg</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/modules/neural_tree.html">mlstatpy.ml.neural_tree</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/modules/roc.html">mlstatpy.ml.roc</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/modules/completion.html">mlstatpy.nlp.completion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/modules/completion_simple.html">mlstatpy.nlp.completion_simple</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/modules/sgd.html">mlstatpy.optim.sgd</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../i_ex.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../defthe_index.html">Listes des définitions et théorèmes</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../auto_examples/index.html">Gallery of examples</a><input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" role="switch" type="checkbox"/><label for="toctree-checkbox-23"><div class="visually-hidden">Toggle navigation of Gallery of examples</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../auto_examples/plot_logistic_decision.html">Arbre d’indécision</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../notebooks/index.html">Galleries de notebooks</a><input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" role="switch" type="checkbox"/><label for="toctree-checkbox-24"><div class="visually-hidden">Toggle navigation of Galleries de notebooks</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../notebooks/dsgarden/index.html">Le petit coin des data scientists</a><input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" role="switch" type="checkbox"/><label for="toctree-checkbox-25"><div class="visually-hidden">Toggle navigation of Le petit coin des data scientists</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/dsgarden/classification_multiple.html">Classification multiple</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/dsgarden/correlation_non_lineaire.html">Corrélations non linéaires</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/dsgarden/discret_gradient.html">Le gradient et le discret</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/dsgarden/file_dattente_ex.html">File d’attente, un exemple simple</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/dsgarden/quantile_regression_example.html">Régression quantile illustrée</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/dsgarden/quantization_f8.html">Quantization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/dsgarden/regression_lineaire.html">Régression linéaire</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/dsgarden/split_train_test.html">Répartir en base d’apprentissage et de test</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../notebooks/image/index.html">Images</a><input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" role="switch" type="checkbox"/><label for="toctree-checkbox-26"><div class="visually-hidden">Toggle navigation of Images</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/image/segment_detection.html">Détection de segments dans une image</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../notebooks/metric/index.html">Métriques</a><input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" role="switch" type="checkbox"/><label for="toctree-checkbox-27"><div class="visually-hidden">Toggle navigation of Métriques</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/metric/pvalues_examples.html">p-values</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/metric/roc_example.html">ROC</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../notebooks/ml/index.html">Machine Learning</a><input class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" role="switch" type="checkbox"/><label for="toctree-checkbox-28"><div class="visually-hidden">Toggle navigation of Machine Learning</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/logreg_voronoi.html">Voronoï et régression logistique</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/mf_acp.html">Factorisation et matrice et ACP</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/neural_tree.html">Un arbre de décision en réseaux de neurones</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/neural_tree_cost.html">NeuralTreeNet et coût</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/neural_tree_onnx.html">NeuralTreeNet et ONNX</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/piecewise_linear_regression.html">Régression linéaire par morceaux</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/regression_no_inversion.html">Régression sans inversion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/reseau_neurones.html">Réseaux de neurones</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/survival.html">Analyse de survie en pratique</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/ml/valeurs_manquantes_mf.html">Valeurs manquantes et factorisation de matrices</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../notebooks/nlp/index.html">NLP - Natural Language Processing</a><input class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" role="switch" type="checkbox"/><label for="toctree-checkbox-29"><div class="visually-hidden">Toggle navigation of NLP - Natural Language Processing</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/nlp/completion_profiling.html">Completion profiling</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/nlp/completion_simple.html">Complétion Simple</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/nlp/completion_trie.html">Complétion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../notebooks/nlp/completion_trie_long.html">Completion Trie and metrics</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">More</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../glossary.html">Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../CHANGELOGS.html">Change Logs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../CHANGELOGS.html#id2">0.4.0</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../license.html">License</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="../../_sources/c_ml/rn/rn_4_densite.rst" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="demonstration-du-theoreme-de-la-densite-des-reseaux-de-neurones">
<h1>Démonstration du théorème de la densité des réseaux de neurones<a class="headerlink" href="#demonstration-du-theoreme-de-la-densite-des-reseaux-de-neurones" title="Lien vers cette rubrique">¶</a></h1>
<nav class="contents local" id="sommaire">
<ul class="simple">
<li><p><a class="reference internal" href="#formulation-du-probleme-de-la-regression" id="id6">Formulation du problème de la régression</a></p></li>
<li><p><a class="reference internal" href="#densite-des-reseaux-de-neurones" id="id7">Densité des réseaux de neurones</a></p></li>
</ul>
</nav>
<section id="formulation-du-probleme-de-la-regression">
<span id="rn-enonce-probleme-regression"></span><h2><a class="toc-backref" href="#id6" role="doc-backlink">Formulation du problème de la régression</a><a class="headerlink" href="#formulation-du-probleme-de-la-regression" title="Lien vers cette rubrique">¶</a></h2>
<p>Soient deux variables aléatoires continues
<img class="math" src="../../_images/math/a326530de7ff629e506d5b217ff1af2f2c9e0d62.svg" alt="\pa{X,Y} \in \mathbb{R}^p \times \mathbb{R}^q \sim \loi"/> quelconque,
la résolution du problème de <a class="reference internal" href="rn_2_reg.html#problem-regression"><span class="std std-ref">régression</span></a>
est l’estimation de la fonction <img class="math" src="../../_images/math/ecfd65eaf18107c11633ac1ffe793c6dbb4da3c9.svg" alt="\esp(Y|X) = F\pa{X}"/>.
Pour cela, on dispose d’un ensemble de points
<img class="math" src="../../_images/math/f544470c232c2c25d04b0a7b8124ffbb2d7bc6e8.svg" alt="A = \acc{ \pa{X_{i},Y_{i}} \sim \loi | 1 \leqslant i \leqslant N }"/>.</p>
<p>Soit <img class="math" src="../../_images/math/3df057643622c96965f07b1e6c349166c94b041e.svg" alt="f : \mathbb{R}^M \times \mathbb{R}^p \longrightarrow \mathbb{R}^q"/> une fonction, on définit
<img class="math" src="../../_images/math/5edd29e696bf705c4d2e0261c4670f53b7ff1b0e.svg" alt="\forall i \in \intervalle{1}{N}, \; \widehat{Y_{i}^{W}} = f \pa{W,X_{i}}"/>.
On appelle aussi <img class="math" src="../../_images/math/6c082bb0e47bb9812b6ec121f80351fad38422a7.svg" alt="\widehat{Y_{i}^{W}}"/> la valeur prédite pour <img class="math" src="../../_images/math/fb12421c4f381279c9b53208a2cb00559ed767f1.svg" alt="X_{i}"/>.
On pose alors
<img class="math" src="../../_images/math/472c3ba671aeb8b43a4daeac50a737255426ee18.svg" alt="\epsilon_{i}^{W} = Y_{i} -  \widehat{Y_{i}^{W}} = Y_{i} - f \pa{W,X_{i}}"/>.</p>
<p>Les résidus sont supposés
<a class="reference external" href="https://fr.wikipedia.org/wiki/Variables_ind%C3%A9pendantes_et_identiquement_distribu%C3%A9es">i.i.d. (identiquement et indépendemment distribués)</a>,
et suivant une loi normale
<img class="math" src="../../_images/math/f67f501ac5984ccecffb05b94b4c0552d47eb5e7.svg" alt="\forall i \in \intervalle{1}{N}, \; \epsilon_{i}^{W} \sim \loinormale{\mu_{W}}{\sigma_{W}}"/>
La vraisemblance d’un échantillon
<img class="math" src="../../_images/math/54372cbe0a6cbc457d9d48707a66b4d58b16b7e1.svg" alt="\pa{Z_i}_{1\leqslant i \leqslant N}"/>,
où les <img class="math" src="../../_images/math/f17e8c265d7e0200ae83cb0ab155527cc9338d22.svg" alt="Z_i"/> sont indépendantes entre elles et suivent la loi de densité
<img class="math" src="../../_images/math/1bbb007ad626c1f9adbd0dc838ab93f44e068f0b.svg" alt="f \pa{z | \theta}"/>
est la densité du vecteur <img class="math" src="../../_images/math/3994db625c8f8578da33308b3942386cc69cbae4.svg" alt="\vecteur{Z_1}{Z_N}"/> qu’on exprime
comme suit :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/c74d923fc3261f39b8b30e31706659abbc6cb2b4.svg" alt="\begin{array}{rrcl}
                &amp;L\pa{\theta, \vecteurno{Z_1}{Z_N}} &amp; =&amp; \prod_{n=1}^{N} f\pa{Z_i | \theta} \\
\Longrightarrow&amp;
\ln L\pa{\theta, \vecteurno{Z_1}{Z_N}} &amp;=&amp; \sum_{n=1}^{N} \ln f\pa{Z_i | \theta}
\end{array}"/></p>
</div></div>
<p>La log-vraisemblance de l’échantillon s’écrit
<img class="math" src="../../_images/math/65425345f2bcc61becef1c75a5907311d4621b5b.svg" alt="L_{W} = -\frac{1}{2\sigma_{W}^2} \sum_{i=1}^{N}
\pa{Y_{i} - \widehat{Y_{i}^W} - \mu_{W} }^2 + N\ln\pa{\sigma_{W}\sqrt{2\pi}}"/>.
Les estimateurs du maximum de vraisemblance
pour <img class="math" src="../../_images/math/6fbff0a1556930f1faabc4efd7d7d3b42b8c2a4e.svg" alt="\mu_W"/> et <img class="math" src="../../_images/math/10b2ddea6d861305d323b665a1394559a31aa639.svg" alt="\sigma_W"/> sont (voir <a class="reference internal" href="../../c_metric/roc.html#saporta1990" id="id1"><span>[Saporta1990]</span></a>) :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/c177c52a8e93943c83a5d763a9c85f5fe1d4fde8.svg" alt="\begin{array}{rcl}
\widehat{\mu_{W}}     &amp;=&amp;     \frac{1}{N} \sum_{i=1}^{N} Y_{i} - \widehat{Y_{i}^W} \\
\widehat{\sigma_{W}}  &amp;=&amp;     \sqrt{ \frac{ \sum_{i=1}^{N} \pa{Y_{i} -
                              \widehat{Y_{i}^W} - \mu_{W}}^2}{N}}
\end{array}"/></p>
</div></div>
<p>L’estimateur de <img class="math" src="../../_images/math/3d0704f182700b605d780207c1b0d9048ead9048.svg" alt="\widehat{Y}=f\pa{W,X}"/> désirée est de préférence
sans biais (<img class="math" src="../../_images/math/235971c901af52fd5e54ba16177d01cc4ee7653f.svg" alt="\mu_W = 0"/>) et de variance minimum,
par conséquent, les paramètres <img class="math" src="../../_images/math/f643d150644d5f0e344555776f04cdf8c713f7df.svg" alt="\overset{*}{W}"/>
qui maximisent la vraisemblance <img class="math" src="../../_images/math/8d6fb494bfed2c24f97534c703d6389dbc9fff38.svg" alt="L_W"/> sont :</p>
<div class="math-wrapper docutils container" id="equation-rn-eqn-regression-1">
<div class="math" id="equation-rn-eqn-regression-1">
<p><span class="eqno">(1)<a class="headerlink" href="#equation-rn-eqn-regression-1" title="Lien vers cette équation">¶</a></span><img src="../../_images/math/09154a9547775ef55f90e0e8f5712e536b20aa93.svg" alt="\begin{array}{rcl}
\overset{*}{W}   &amp;=&amp; \underset{W \in \mathbb{R}^M}{\arg \min} \sum_{i=1}^{N}
                                        \pa {Y_{i} - \widehat{Y_{i}^W}}^2 \\
                 &amp;=&amp; \underset{W \in \mathbb{R}^M}{\arg \min} \sum_{i=1}^{N}
                        \pa {Y_{i} - f \pa{W,X_{i}}}^2
\end{array}"/></p>
</div></div>
<p>Réciproquement, on vérifie que si <img class="math" src="../../_images/math/4d4f4910fb33f542260bd4f5593ffb800c330e49.svg" alt="W^*"/> vérifie
l’équation <a class="reference internal" href="#equation-rn-eqn-regression-1">(1)</a> alors l’estimateur défini par
<img class="math" src="../../_images/math/bd1e0600a66dbe0f8deddbd57953774419ba4e4f.svg" alt="f"/> est sans biais
Il suffit pour s’en convaincre de poser
<img class="math" src="../../_images/math/7363edc6324fe342c166fdd2720834f0c7ac9340.svg" alt="g = f + \alpha"/> avec
<img class="math" src="../../_images/math/3eeda8b2dbf36460e7cbf264c749d947fe37a45a.svg" alt="\alpha \in \mathbb{R}"/> et de vérifier que la valeur optimale pour
<img class="math" src="../../_images/math/a1e7b66a55fc77cebd91d9a1ebfa93a29c1736fb.svg" alt="\alpha"/> est
<img class="math" src="../../_images/math/afe3aad371fc4500c02697587aa9162a2859a826.svg" alt="\alpha = - \frac{1}{N}\, \sum_{i=1}^{N} \, \left. Y_i - f\pa{W,X_i} \right."/>.
L’estimateur minimise la vraisemblance <img class="math" src="../../_images/math/8d6fb494bfed2c24f97534c703d6389dbc9fff38.svg" alt="L_W"/>.
Cette formule peut être généralisée en faisant une autre hypothèse
que celle de la normalité des résidus (l’indépendance étant conservée),
l’équation <a class="reference internal" href="#equation-rn-eqn-regression-1">(1)</a>
peut généralisée par <a class="reference internal" href="#equation-rn-eqn-regression-2">(2)</a>.</p>
<div class="math-wrapper docutils container" id="equation-rn-eqn-regression-2">
<div class="math" id="equation-rn-eqn-regression-2">
<p><span class="eqno">(2)<a class="headerlink" href="#equation-rn-eqn-regression-2" title="Lien vers cette équation">¶</a></span><img src="../../_images/math/922e0d45ad37c45fa0d3d4ac99d0835b1e513a95.svg" alt="\begin{array}{rcl}
\overset{*}{W}     &amp;=&amp; \underset{W \in \mathbb{R}^M}{\arg \min} \sum_{i=1}^{N}
                                                        e\pa {Y_{i} - \widehat{Y_{i}^W}} \\
                    &amp;=&amp; \underset{W \in \mathbb{R}^M}{\arg \min} \sum_{i=1}^{N}
                            e\pa{Y_{i} - f \pa{W,X_{i}}}
\end{array}"/></p>
</div></div>
<p>Où la fonction <img class="math" src="../../_images/math/bb957c035f5f1cefdef8c5c16db0bf8c0a93c01b.svg" alt="e : \mathbb{R}^q \in \mathbb{R}"/> est appelée fonction d’erreur.</p>
</section>
<section id="densite-des-reseaux-de-neurones">
<h2><a class="toc-backref" href="#id7" role="doc-backlink">Densité des réseaux de neurones</a><a class="headerlink" href="#densite-des-reseaux-de-neurones" title="Lien vers cette rubrique">¶</a></h2>
<p>L’utilisation de réseaux de neurones s’est considérablement
développée depuis que l’algorithme de rétropropagation a
été trouvé (<a class="reference internal" href="rn_biblio.html#lecun1985" id="id2"><span>[LeCun1985]</span></a>, <a class="reference internal" href="rn_biblio.html#rumelhart1986" id="id3"><span>[Rumelhart1986]</span></a>, <a class="reference internal" href="rn_biblio.html#bishop1995" id="id4"><span>[Bishop1995]</span></a>).
Ce dernier permet d’estimer la dérivée d’un réseau de neurones en
un point donné et a ouvert la voie à des méthodes classiques
de résolution pour des problèmes d’optimisation tels que la régression non linéaire.</p>
<p>Comme l’ensemble des fonctions polynômiales,
l’ensemble des fonctions engendrées par des réseaux de neurones
multi-couches possède des propriétés de <a class="reference internal" href="#theoreme-densite"><span class="std std-ref">densité</span></a>
et sont infiniment dérivables. Les réseaux de neurones comme
les polynômes sont utilisés pour modéliser la fonction
<img class="math" src="../../_images/math/bd1e0600a66dbe0f8deddbd57953774419ba4e4f.svg" alt="f"/> de l’équation <a class="reference internal" href="#equation-rn-eqn-regression-2">(2)</a>.
Ils diffèrent néanmoins sur certains points</p>
<p>Si une couche ne contient que des fonctions de transfert bornées
comme la fonction sigmoïde, tout réseau de neurones incluant cette couche
sera aussi borné. D’un point de vue informatique, il est
préférable d’effectuer des calculs avec des valeurs du même
ordre de grandeur. Pour un polynôme, les valeurs des termes de
degré élevé peuvent être largement supérieurs à leur somme.</p>
<p>Un autre attrait est la symétrie dans l’architecture d’un réseau
de neurones, les neurones qui le composent jouent des rôles
symétriques (corollaire <a class="reference internal" href="#corollaire-famille-libre"><span class="std std-ref">familles libres</span></a>.
Pour améliorer l’approximation d’une fonction, dans un cas,
il suffit d’ajouter un neurone au réseau, dans l’autre,
il faut inclure des polynômes de degré plus élevé que ceux déjà  employés.</p>
<div class="admonition-mathdef admonition" id="indexmathe-Théorème0">
<div class="docutils container">
</div>
<p class="admonition-title" id="theoreme-densite">Théorème T1 : densité des réseaux de neurones (Cybenko1989)</p>
<p><a class="reference internal" href="rn_biblio.html#cybenko1989" id="id5"><span>[Cybenko1989]</span></a>
Soit <img class="math" src="../../_images/math/166322259d8d974ece7902b461c1bf3d15a96cc6.svg" alt="E_{p}^{q}"/> l’espace des réseaux de neurones à
<img class="math" src="../../_images/math/6fe7973e241cac84eec5598231dc7f6e68e88282.svg" alt="p"/> entrées et <img class="math" src="../../_images/math/53e75bcd7eafea2c0896729a913b09b70e220d12.svg" alt="q"/> sorties, possédant une couche cachée dont la
fonction de seuil est une fonction sigmoïde
<img class="math" src="../../_images/math/cfc879a334e0bdb6c27e609b16da5e5bd99629c6.svg" alt="\left(  x\rightarrow 1-\frac{2}{1+e^{x}}\right)"/>,
une couche de sortie dont la fonction de seuil est linéaire
Soit <img class="math" src="../../_images/math/c1274df568c53289e39e0881babfedfde2591e9d.svg" alt="F_{p}^{q}"/> l’ensemble des fonctions continues de
<img class="math" src="../../_images/math/99da60b00ee9076f309d55e2c2654657a9bc1fea.svg" alt="C\subset\mathbb{R}^{p}\longrightarrow\mathbb{R}^{q}"/> avec <img class="math" src="../../_images/math/2c0e77bc741b692ecdf6e85966263a89422af4c8.svg" alt="C"/>
compact muni de la norme
<img class="math" src="../../_images/math/89d5ff3f5f71076c7fa1b65b745470e495c966b3.svg" alt="\left\| f\right\| =\underset{x\in C}{\sup}\left\|  f\left( x\right)  \right\|"/>
Alors <img class="math" src="../../_images/math/166322259d8d974ece7902b461c1bf3d15a96cc6.svg" alt="E_{p}^{q}"/> est dense dans <img class="math" src="../../_images/math/c1274df568c53289e39e0881babfedfde2591e9d.svg" alt="F_{p}^{q}"/>.</p>
</div>
<p>La démonstration de ce théorème nécessite deux lemmes.
Ceux-ci utilisent la définition usuelle du produit scalaire
sur <img class="math" src="../../_images/math/e49341cfc9f50d52ff78f13b382a34866c9524c1.svg" alt="\mathbb{R}^p"/> défini par
<img class="math" src="../../_images/math/e9ecdf629140bf9fdb6c104029c920f0aa4a27e8.svg" alt="\pa{x,y} = \pa{\vecteurno{x_1}{x_p},\vecteurno{y_1}{y_p}} \in \mathbb{R}^{2p} \longrightarrow
\left\langle x,y \right\rangle = \sum_{i=1}^{p} x_i y_i"/>.
et la norme infinie :
<img class="math" src="../../_images/math/4da501f52c99572787f59a3ce9f85faf3583f71a.svg" alt="x = \vecteur{x_1}{x_p} \in \mathbb{R}^p \longrightarrow \norm{x} =
\underset{i \in \intervalle{1}{p}}{\max} x_i"/>.
Toutes les normes sont
<a class="reference external" href="https://fr.wikipedia.org/wiki/Norme_%C3%A9quivalente">équivalentes</a>
sur <img class="math" src="../../_images/math/e49341cfc9f50d52ff78f13b382a34866c9524c1.svg" alt="\mathbb{R}^p"/>.</p>
<div class="admonition-mathdef admonition" id="indexmathe-Corollaire0">
<div class="docutils container">
</div>
<p class="admonition-title" id="theoreme-densite-lemme-a">Corollaire C1 : approximation d’une fonction créneau</p>
<p>Soit <img class="math" src="../../_images/math/517c8bf9a780106de93e1c9a3f70e78af0afd7de.svg" alt="C \subset \mathbb{R}^p, \; C= \acc { \vecteur{y_1}{y_p} \in \mathbb{R}^p \, | \forall i\in \intervalle{1}{p},\, 0 \leqslant y_{i}\leqslant 1   }"/>,
alors :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/a763c7a26bb57800c540139f586f0783c8ee7c8e.svg" alt="\begin{array}{l}
\forall \varepsilon &gt; 0, \; \forall \alpha&gt;0, \; \exists n \in \N^*, \;
            \exists \vecteur{x_1}{x_n}
            \in\left(  \mathbb{R}^p\right)  ^{n}, \; \exists
    \vecteur{\gamma_1}{\gamma_n} \in \mathbb{R}^n  \text{ tels que } \forall x\in \mathbb{R}^p, \\ \\
\begin{array}{ll}
&amp;   \left| \underset{i=1}{\overset{n}{\sum}}\dfrac{\gamma_i}
                {1+e^{\left\langle x_{i},x\right\rangle +b_{i}}}-\indicatrice{x\in C
    }\right| \leqslant1 \\ \\
\text{ et } &amp;   \underset{y\in Fr\left( C\right)  }{\inf }\left\| x-y\right\| &gt;
                \alpha\mathbb{R}ightarrow\left| \underset{i=1}{\overset
    {n}{\sum}}\dfrac{\gamma_i}{1+e^{\left\langle x_{i},x\right\rangle +b_{i}}}
            -\indicatrice{x\in C}\right| \leqslant\varepsilon
\end{array}
\end{array}"/></p>
</div></div>
</div>
<p><strong>Démonstration du corollaire</strong></p>
<p><em>Partie 1</em></p>
<p>Soit <img class="math" src="../../_images/math/777afd6041e6d265ef21483c121300e1c7aa565a.svg" alt="h"/> la fonction définie par :
<img class="math" src="../../_images/math/4e0fcbd48ddc90093f6c65d965d4fbb49e7fec48.svg" alt="h\pa{x} = \pa{\dfrac{1}{1+e^{-kx}}}^p"/>
avec <img class="math" src="../../_images/math/edd1af8ae1d4ee71bd631ab5bfb5c03ecea2412b.svg" alt="p&gt;0"/> et <img class="math" src="../../_images/math/93828e26e50bfc2c5777fccd4fe84d772a9c7a91.svg" alt="0 &lt; \epsilon &lt; 1"/>.
A <img class="math" src="../../_images/math/a1e7b66a55fc77cebd91d9a1ebfa93a29c1736fb.svg" alt="\alpha"/>, <img class="math" src="../../_images/math/5d07e66e6e9d55b1dd504ca14a3d870dfe30fb29.svg" alt="\epsilon"/> fixé, <img class="math" src="../../_images/math/93828e26e50bfc2c5777fccd4fe84d772a9c7a91.svg" alt="0 &lt; \epsilon &lt; 1"/>,
on cherche <img class="math" src="../../_images/math/312028c07e271534bd0dbde5434e49e76880744f.svg" alt="k"/> tel que :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/e681722819d3286eee928b5b5606139c64aa771c.svg" alt="\begin{array}{crcl}
                &amp;   \epsilon                    &amp;=&amp; h\pa{\alpha} = \pa{\dfrac{1}{1+e^{-k\alpha}}}^p \\
\Longrightarrow &amp;   \epsilon^{-\frac{1}{p}}               &amp;=&amp; 1+e^{-k\alpha} \\
\Longrightarrow &amp;   \epsilon^{-\frac{1}{p}} -1            &amp;=&amp; e^{-k\alpha} \\
\Longrightarrow &amp;   \ln \pa{\epsilon^{-\frac{1}{p}} -1}   &amp;=&amp; -k\alpha \\
\Longrightarrow &amp;   k                           &amp;=&amp; - \dfrac{ \ln\pa{\epsilon^{-\frac{1}{p}} -1}}{\alpha} =
                                                        k_0\pa{\epsilon,\alpha,p}
\end{array}"/></p>
</div></div>
<p><em>Partie 2</em></p>
<p>Soit <img class="math" src="../../_images/math/bd41a2e78e74e917477a39b1a385cc47fa1c94a2.svg" alt="\alpha&gt;0"/> et <img class="math" src="../../_images/math/030dd8dbbfdfdb1e6238484a36d5847538222529.svg" alt="1\geqslant\varepsilon&gt;0, \, k&gt;0"/>,</p>
<p>On pose <img class="math" src="../../_images/math/f37f95f78ccc5c54757fb6704385d9bc9033da5f.svg" alt="f\left(  y_{1},...,y_{p}\right)  =\underset{i=1}{\overset{p}{\prod}}
\dfrac{1}{1+e^{-ky_{i}}}\underset{i=1}{\overset{p}{\prod}}\dfrac {1}{1+e^{-k\left(  1-y_{i}\right)}}"/>
d’après sa définition, <img class="math" src="../../_images/math/4ecd364f288bf747d0d68a1205018cce20c7ad5f.svg" alt="0 \leqslant f\left(  y_{1},...,y_{p}\right)  \leqslant 1"/>.</p>
<p>Pour <img class="math" src="../../_images/math/800054f05eea2dd5fbf17c2eb5ecc5534f01d3b3.svg" alt="k \supegal k_0 \pa{\epsilon,\alpha,2p}"/>
obtenu dans la partie précédente :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/df3b01f2ac130c7278e2cd1260a5ccd961ceef26.svg" alt="\underset{_{i\in\left\{ 1,...,p\right\}}}{\inf}
\cro { \min\left\{  \left|  y_{i}\right|  ,\left|  1-y_{i}\right|  \right\} } &gt;\alpha
\Longrightarrow\left\|  f\left(  y_{1},...,y_{p}\right) - \indicatrice{x\in C}\right\|  \leqslant\varepsilon"/></p>
</div></div>
<p><em>Partie 3</em></p>
<p>Soit <img class="math" src="../../_images/math/3a8d8bad8d0f9dcf76fdcc134f09a2a698f2d77f.svg" alt="g"/> la fonction définie par :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/b005afca1829951c184fdfd9caebe1876dc437f0.svg" alt="\begin{array}{rcl}
g\pa{x}     &amp;=&amp;     \pa{\dfrac{1}{1+e^{-kx}}}\pa{\dfrac{1}{1+e^{-k\pa{1-x}}}}
            =     \dfrac{1}{1+e^{-kx}+e^{-k\pa{1-x}}+e^{-k}} \\
            &amp;=&amp;     \dfrac{1}{1+e^{-kx}+e^{-k}e^{kx}+e^{-k}}
            =     \dfrac{e^{kx}}{e^{kx}\pa{1+e^{-k}}+1+e^{-k}e^{2kx}}
\end{array}"/></p>
</div></div>
<p>La fonction <img class="math" src="../../_images/math/4e953a6b9c300bfe2fe5f17ee88313b9f9ce6f01.svg" alt="x \longrightarrow e^{kx}\pa{1+e^{-k}}+1+e^{-k}e^{2kx}"/>
est un polynôme en <img class="math" src="../../_images/math/2a2c7b506f4e79f3c998865096d0231db22e8bfb.svg" alt="e^{kx}"/> dont le
discriminant est positif. Par conséquent la fraction
rationnelle <img class="math" src="../../_images/math/0d6279f158c6944c5919be6e6c38f2051ba3a8c0.svg" alt="g\pa{x}"/> admet une décomposition en éléments
simples du premier ordre
et il existe quatre réels <img class="math" src="../../_images/math/40db27db442a32375344820b3e18003e4bc4c5b2.svg" alt="\eta_1"/>, <img class="math" src="../../_images/math/e20267a0dd2e1793ff457cf3d1c9e4a494a19c93.svg" alt="\eta_2"/>,
<img class="math" src="../../_images/math/6b6d56368a97339ef3b23677ed07f7d44a8f3b3b.svg" alt="\delta_1"/>, <img class="math" src="../../_images/math/dacd01bd7e14a82a9424a0c3fc8798f4ecbbb71f.svg" alt="\delta_2"/> tels que :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/2b433c7f2662486cfd9ef2a72d115e0e2083cc49.svg" alt="g\pa{x} = \dfrac{\eta_1}{1+ e^{kx+\delta_1}} + \dfrac{\eta_2}{1+ e^{kx+\delta_2}}"/></p>
</div></div>
<p>Par conséquent :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/1a798b4cb9519c05a874d8517ffce625a4d72e43.svg" alt="f\vecteur{y_1}{y_p} = \prod_{i=1}^{p} g\pa{y_i} =
                      \prod_{i=1}^{p} \cro { \dfrac{\eta_1^i}{1+ e^{ky_i+\delta_1^i}} + \dfrac{\eta_2^i}{1+
                      e^{ky_i+\delta_2^i}} }"/></p>
</div></div>
<p>Il existe <img class="math" src="../../_images/math/927ae9ea273d21dce23af63addd38a52af901d71.svg" alt="n \in \N"/> tel qu’il soit possible d’écrire <img class="math" src="../../_images/math/bd1e0600a66dbe0f8deddbd57953774419ba4e4f.svg" alt="f"/> sous la forme :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/5c130393f336f9225deab90eb99c106963ea1dfc.svg" alt="f\pa{y} = \sum_{i=1}^{n}  \dfrac{\gamma_i}{ 1 + e^{ &lt;x_i,y&gt; + b_i } }"/></p>
</div></div>
<div class="admonition-mathdef admonition" id="indexmathe-Corollaire1">
<div class="docutils container">
</div>
<p class="admonition-title" id="theoreme-densite-lemme-b">Corollaire C2 : approximation d’une fonction indicatrice</p>
<p>Soit <img class="math" src="../../_images/math/b48125bc036af067cd3054aefecf71e4ec2b010b.svg" alt="C\subset\mathbb{R}^p"/> compact, alors :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/543387b89f76f624b61d30d98627e306d64b8385.svg" alt="\begin{array}{c}
\forall\varepsilon&gt;0, \; \forall\alpha&gt;0, \; \exists\left(  x_{1},...,x_{n}\right)
        \in\left(  \mathbb{R}^{p}\right)^{n}, \; \exists\left(
b_{1},...,b_{n}\right)  \in\mathbb{R}^n \text{ tels que } \forall x\in\mathbb{R}^{p},\\ \\
\begin{array}{ll}
&amp;   \left|  \sum_{i=1}^n \dfrac{\gamma_i}
            {1+e^{\left\langle x_{i},x\right\rangle +b_{i}}}-\indicatrice{x\in C
    }\right|  \leqslant1+2\varepsilon^2\\ \\
\text{ et } &amp;   \underset{y\in Fr\left( C\right)  }{\inf}\left\|  x-y\right\|
    &gt;\alpha\mathbb{R}ightarrow\left| \sum_{i=1}^n
                \dfrac{\gamma_i}{1+e^{\left\langle x_{i} ,x\right\rangle +b_{i}}}-
    \indicatrice{x\in C}\right| \leqslant \varepsilon
\end{array}
\end{array}"/></p>
</div></div>
</div>
<p><strong>Démonstration du corollaire</strong></p>
<p><em>Partie 1</em></p>
<p>Soit <img class="math" src="../../_images/math/298c3442c5b9daa6a08f3aaf4679637abde7e548.svg" alt="C_1=\left\{  y=\left(  y_{1},...,y_{p}\right)  \in\mathbb{R}^p
\,\left| \, \forall i\in\left\{  1,...,n\right\}  ,\,0\leqslant y_{i}\leqslant1\right.  \right\}"/>
et <img class="math" src="../../_images/math/009643c2d5ef66c86689325ce09f8fffe32de57b.svg" alt="C_{2}^{j}=\left\{  y=\left(
y_{1},...,y_{p}\right)  \in\mathbb{R}^p\,\left| \,
\forall i\neq j,\,0\leqslant y_{i}\leqslant1 \text{ et }1\leqslant y_{j}\leqslant2\right.
\right\}"/></p>
<p>Le premier lemme suggère que la fonction cherchée pour ce lemme
dans le cas particulier <img class="math" src="../../_images/math/fa3e9bd8053c01a1542ba77ea54677e8d1e5a1b9.svg" alt="C_1\cup C_2^j"/> est :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/31b8a9555c4dba90d00ad1edbf46810e89388446.svg" alt="\begin{array}{rcl}
f\left(  y_{1},...,y_{p}\right) &amp;=&amp;   \prod_{i=1}^p \dfrac
                                    {1}{1+e^{-ky_{i}}} \prod_{i=1}^p\dfrac{1}{1+e^{-k\left( 1-y_{i}\right)
                                    }}+ \\
                            &amp;&amp;      \quad \left(  \prod_{i \neq j}
                                    \dfrac
                                    {1}{1+e^{-ky_{i}}}\right)  \left(  \prod_{i \neq j}
                                    \dfrac{1}{1+e^{-k\left(  1-y_{i}\right)  }}\right)
                                    \dfrac{1}{1+e^{k\left( 1-y_{j}\right)  }}\dfrac{1}{1+e^{-k\left(  2-y_{j}\right)
                                    }}\\
%
                            &amp;=&amp;  \left(  \prod_{i \neq j} \dfrac{1}{1+e^{-ky_{i}}}\right)
                                \left(  \prod_{i \neq j} \dfrac{1}{1+e^{-k\left(  1-y_{i}\right)
                                }}\right) \\
                            &amp;&amp;  \quad  \left( \dfrac{1}{1+e^{-ky_{j}}}\dfrac{1}{1+e^{-k\left(  1-y_{j}\right)  }}
                                 +\dfrac {1}{1+e^{k\left(  1-y_{j}\right)  }}
                                            \dfrac{1}{1+e^{-k\left(2-y_{j}\right) }}\right)
                                 \\
%
                            &amp;=&amp; \left(  \prod_{i \neq j} \dfrac{1}{1+e^{-ky_{i}}}\right)
                                 \left(  \prod_{i \neq j} \dfrac{1}{1+e^{-k\left(  1-y_{i}\right)  }}\right) \\
                            &amp;&amp;  \quad \left[\dfrac{1}{1+e^{-ky_{j}}}\left(  \dfrac{1}{1+e^{-k\left(  1-y_{j}\right)  }
                                }+1-1\right)  +\left(  1-\dfrac{1}{1+e^{-k\left(  1-y_{j}\right)  }}\right)
                                \dfrac{1}{1+e^{-k\left(  2-y_{j}\right)  }}\right]
\end{array}"/></p>
</div></div>
<p>Pour <img class="math" src="../../_images/math/430caa5125297680e23078baca4c1751d3acc356.svg" alt="k \supegal k_0\pa{\epsilon,\alpha,2p}"/>, on a :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/1e1d56b20466da1aca0a74a8938cb1a4800d2af7.svg" alt="\begin{array}{rcl}
f\left(  y_{1},...,y_{p}\right)  &amp;=&amp; \left(  \prod_{i\neq j}
\dfrac{1}{1+e^{-ky_{i}}}\right)  \left(  \prod_{i\neq j}
\dfrac{1}{1+e^{-k\left(  1-y_{i}\right)  }}\right)
\\
&amp;&amp; \quad \left(  \dfrac{1}%
{1+e^{-ky_{j}}}+\dfrac{1}{1+e^{-k\left(  2-y_{j}\right)  }}+
\underset {\leqslant\varepsilon^{2}}{\underbrace{\dfrac{1}{1+e^{k\left( 1-y_{j}\right)
}}\dfrac{1}{1+e^{-ky_{j}}}}}-\underset{\leqslant\varepsilon^{2}}%
{\underbrace{\dfrac{1}{1+e^{-k\left(  1-y_{j}\right)  }}\dfrac{1}%
{1+e^{-k\left(  2-y_{j}\right)  }}}}\right)
\end{array}"/></p>
</div></div>
<p>Par conséquent, il est facile de construire la fonction cherchée
pour tout compact connexe par arc.</p>
<p><em>Partie 2</em></p>
<p>Si un compact <img class="math" src="../../_images/math/2c0e77bc741b692ecdf6e85966263a89422af4c8.svg" alt="C"/> n’est pas connexe par arc,
on peut le recouvrir par une somme finie de
compacts connexes par arcs et disjoints
<img class="math" src="../../_images/math/deb72793fb071514155e1cda6ccd4f3b74937cd4.svg" alt="\left(C_{k}\right) _{1\leqslant k\leqslant K}"/> de telle sorte que :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/b1301d89c9021a83b093f273b4223a619e4fdb78.svg" alt="\forall y\in\underset{k=1}{\overset{K}{\cup}}C_{k},\,\inf\left\{  \left\|
x-y\right\|  ,\,x\in C\right\}  \leqslant\dfrac{\alpha}{2}"/></p>
</div></div>
<p><strong>Démontration du théorème de</strong> <a class="reference internal" href="#theoreme-densite"><span class="std std-ref">densité des réseaux de neurones</span></a></p>
<p><em>Partie 1</em></p>
<p>On démontre le théorème dans le cas où <img class="math" src="../../_images/math/2a73425479e21fc22276406e75ba619a8a061cee.svg" alt="q=1"/>.
Soit <img class="math" src="../../_images/math/bd1e0600a66dbe0f8deddbd57953774419ba4e4f.svg" alt="f"/> une fonction continue du compact
<img class="math" src="../../_images/math/4ecc47b3853a71821e433930b1eb353803c2ad52.svg" alt="C\subset\mathbb{R}^p\rightarrow \mathbb{R}"/> et soit <img class="math" src="../../_images/math/935f4b41c99c830ddcefccc6723bb5c102973b43.svg" alt="\varepsilon&gt;0"/>.</p>
<p>On suppose également que <img class="math" src="../../_images/math/bd1e0600a66dbe0f8deddbd57953774419ba4e4f.svg" alt="f"/> est positive, dans le cas contraire, on pose
<img class="math" src="../../_images/math/b817b36303e1dc91cda3e07db5ec7909d156224c.svg" alt="f=\underset{\text{fonction positive}}{\underbrace{f-\inf f}}+\inf f"/>.</p>
<p>Si <img class="math" src="../../_images/math/bd1e0600a66dbe0f8deddbd57953774419ba4e4f.svg" alt="f"/> est nulle, alors c’est fini, sinon, on pose <img class="math" src="../../_images/math/95ce55c937802dbddf12f7e365ecc07769a75c6d.svg" alt="M=\underset{x\in C}{\sup }f\left(  x\right)"/>.
<img class="math" src="../../_images/math/e5c619f0600e251cabb3318b03870bc6f2c4870f.svg" alt="M"/> existe car <img class="math" src="../../_images/math/bd1e0600a66dbe0f8deddbd57953774419ba4e4f.svg" alt="f"/> est continue et <img class="math" src="../../_images/math/2c0e77bc741b692ecdf6e85966263a89422af4c8.svg" alt="C"/>
est compact (de même, <img class="math" src="../../_images/math/5dbbf477b3e37aab1c338288dc72b26bd3939556.svg" alt="\inf f"/> existe également).</p>
<p>On pose <img class="math" src="../../_images/math/5d9cc29f710a7956b4d6aa7a290873407502d170.svg" alt="C_{k}=f^{-1}\left(  \left[  k\varepsilon,M\right]  \right)"/>.
<img class="math" src="../../_images/math/8d5ea7c11912b80ccba3fa191c7dcd0355bd3dcf.svg" alt="C_k"/> est compact car il est l’image
réciproque d’un compact par une fonction continue et <img class="math" src="../../_images/math/2510082f8cd53b1e5c0c8b3368a71afeeb242806.svg" alt="C_k\subset C"/> compact.</p>
<img alt="../../_images/rn_densite_idee.png" src="../../_images/rn_densite_idee.png" />
<p>Par construction, <img class="math" src="../../_images/math/f36e14ed548a1c4e777333e44e637902c521ce29.svg" alt="C_{k+1}\subset C_{k}"/> et <img class="math" src="../../_images/math/3e0440141a58a6cbb1631bac0b83b9f74711cbda.svg" alt="C=\underset{k=0}{\overset {\frac{M}{\varepsilon}}
{\bigcup}}C_{k}=C_{0}"/> on définit~:</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/be282cfddfbeb0fa74c6e1e894ce0e9abf5912b2.svg" alt="\forall x\in
C,\; g_{\varepsilon}\left(  x\right)  =
        \varepsilon\overset{\frac {M}{\varepsilon}}{ \sum_{k=0}}\indicatrice{x\in C_{k}}"/></p>
</div></div>
<p>D’où~:</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/6df132dfc8913a3bd240780d3717400d3f18247d.svg" alt="\begin{eqnarray}
f\left(  x\right)  -g_{\varepsilon}\left(  x\right)  &amp;=&amp;
                    f\left(  x\right)-\varepsilon\overset{\frac{M}{\varepsilon}}{\sum_{k=0}}
    \indicatrice{x\in C_{k}} \nonumber
= f\left(  x\right)  -\varepsilon \overset{\frac{M}{\varepsilon}}
            {\sum_{k=0}}\indicatrice
                { f\pa{x} \supegal k \varepsilon } \nonumber \\
&amp;=&amp; f\left( x\right)  -\varepsilon\left[  \dfrac{f\left(  x\right) }
                {\varepsilon}\right] \quad \text{ (partie entière)}\nonumber  \\
&amp; \text{d'où }&amp;  0\leqslant f\left(  x\right)  -g_{\varepsilon}\left(  x\right)  \leqslant \frac{\varepsilon}{4}
\end{eqnarray}"/></p>
</div></div>
<p>Comme <img class="math" src="../../_images/math/bd1e0600a66dbe0f8deddbd57953774419ba4e4f.svg" alt="f"/> est continue sur un compact, elle est uniformément continue sur ce compact :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/ba6fab2c8cd058f1e5b4c9f2c09a8fe32d9cd018.svg" alt="\begin{array}{l}
\exists\alpha&gt;0 \text{ tel que } \forall\left(  x,y\right)  \in C^{2},
            \; \left\| x-y\right\|  \leqslant\alpha\Longrightarrow\left|  f\left(
    x\right) -f\left(  y\right)  \right|  \leqslant \frac{ \varepsilon}{2} \\ \\
\text{ d'où } \left|  f\left(  x\right)  -f\left(  y\right)  \right| \supegal \varepsilon
                 \Longrightarrow\left\|  x-y\right\|  &gt;\alpha
\end{array}"/></p>
</div></div>
<p>Par conséquent :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/d0c0789f1be0bfc854d7e2c34a20bb15a3a71745.svg" alt="\inf\left\{  \left\|  x-y\right\|  \,\left|  \,x\in Fr\left(  C_{k}\right) ,\,y\in
                Fr\left(  C_{k+1}\right)  \right.  \right\}
&gt;\alpha"/></p>
</div></div>
<p>D’après le second lemme, on peut construire des fonctions <img class="math" src="../../_images/math/2f5128308527f42e434a3e7421dbbf8348e9b5b0.svg" alt="h_{k}\left( x\right)
=\sum_{i=1}^n\dfrac{1}{1+e^{\left\langle x_{i}^{k},x\right\rangle +b_{i}^{k}}}"/>
telles que :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/eacf460aad2d44ccca52e170bf0f0354f97a8e69.svg" alt="\left(  \left\|  h_{k}\left(  x\right)  -\indicatrice{x\in C_{k}}\right\|
    \leqslant1 \right)  \text{ et } \left( \underset{y\in
Fr\left(  C\right)  }{\inf}\left\|  x-y\right\|  &gt;\dfrac{\alpha}{2}%
\mathbb{R}ightarrow\left\|  h_{k}\left(  x\right)  -\indicatrice{x\in C_{k}}\right\|  \leqslant\varepsilon^{2}\right)"/></p>
</div></div>
<p>On en déduit que :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/9e3bca230dd2e6267a5bf8b0fb764b710ef20940.svg" alt="\begin{array}{rcl}
\left|  f\left(  x\right)  -\varepsilon\overset{\frac{M}{\varepsilon}}
        {\sum_{k=0}}h_{k}\left(  x\right)  \right|  &amp;\leqslant&amp;
    \left| f\left(  x\right)  -g_{\varepsilon}\left(  x\right)  \right|
         +\left|g_{\varepsilon}\left(  x\right)  -\varepsilon
    \overset{\frac{M}{\varepsilon}}{\sum_{k=0}}h_{k}\left(  x\right)  \right| \\
&amp;\leqslant&amp; \varepsilon+ \varepsilon^2 \left[  \dfrac{M}{\varepsilon}\right] + 2\varepsilon^2 \\
&amp;\leqslant&amp; \varepsilon\left(  M+3\right)
\end{array}"/></p>
</div></div>
<p>Comme <img class="math" src="../../_images/math/441890308ae8353d29b06870e8fe65ded70849e3.svg" alt="\varepsilon\overset{\frac{M}{\varepsilon}}{\sum_{k=1}}
h_{k}\left(  x\right)"/> est de la forme désirée, le théorème est démontré dans le cas <img class="math" src="../../_images/math/2a73425479e21fc22276406e75ba619a8a061cee.svg" alt="q=1"/>.</p>
<p><em>Partie 2</em></p>
<p>Dans le cas <img class="math" src="../../_images/math/39d4e44fcae2463826f3b846fa06c0f2260397c8.svg" alt="q&gt;1"/>, on utilise la méthode précédente pour chacune des projections de <img class="math" src="../../_images/math/bd1e0600a66dbe0f8deddbd57953774419ba4e4f.svg" alt="f"/>
dans un repère orthonormé de <img class="math" src="../../_images/math/03f376aa051516d4d497404ef2495ac7d9953625.svg" alt="\mathbb{R}^{q}"/>. Il suffit de
sommer sur chacune des dimensions.</p>
<p>Ce théorème montre qu’il est judicieux de modéliser la fonction
<img class="math" src="../../_images/math/bd1e0600a66dbe0f8deddbd57953774419ba4e4f.svg" alt="f"/> dans l’équation <a class="reference internal" href="#equation-rn-eqn-regression-2">(2)</a>
par un réseau de neurones puisqu’il possible de s’approcher d’aussi
près qu’on veut de la fonction <img class="math" src="../../_images/math/1bccd86e61977742f53b4fca6b4cbbb0a6fff0f8.svg" alt="\esp\pa{Y | X}"/>,
il suffit d’ajouter des neurones sur la couche cachée du réseau.
Ce théorème permet de déduire le corollaire suivant :</p>
<div class="admonition-mathdef admonition" id="indexmathe-Corollaire2">
<div class="docutils container">
</div>
<p class="admonition-title" id="corollaire-famille-libre">Corollaire C3 : famille libre de fonctions</p>
<p>Soit <img class="math" src="../../_images/math/8faa305a5ba70beaf67fd1ef7ecbf9ec0a9157aa.svg" alt="F_{p}"/> l’ensemble des fonctions continues de
<img class="math" src="../../_images/math/a3b97531d59545ab86149eed9e86222cc4dd7d4b.svg" alt="C\subset\mathbb{R}^{p}\longrightarrow\mathbb{R}"/> avec <img class="math" src="../../_images/math/2c0e77bc741b692ecdf6e85966263a89422af4c8.svg" alt="C"/>
compact muni de la norme :
<img class="math" src="../../_images/math/89d5ff3f5f71076c7fa1b65b745470e495c966b3.svg" alt="\left\| f\right\| =\underset{x\in C}{\sup}\left\|  f\left( x\right)  \right\|"/>
Alors l’ensemble <img class="math" src="../../_images/math/f79dd35c45921a843ee73ca6ceb9d8adf913ee22.svg" alt="E_{p}"/> des fonctions sigmoïdes :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/3893a56fa2899b7f40d5b57d50a372d2ad57943d.svg" alt="E_{p} =  \acc{ x \longrightarrow 1 - \dfrac{2}{1 + e^{&lt;y,x&gt;+b}} | y
\in \mathbb{R}^p \text{ et } b \in \mathbb{R}}"/></p>
</div></div>
<p>est une base de <img class="math" src="../../_images/math/8faa305a5ba70beaf67fd1ef7ecbf9ec0a9157aa.svg" alt="F_{p}"/>.</p>
</div>
<p><strong>Démonstration du corollaire</strong></p>
<p>Le théorème de <a class="reference internal" href="#theoreme-densite"><span class="std std-ref">densité</span></a> montre que la famille
<img class="math" src="../../_images/math/f79dd35c45921a843ee73ca6ceb9d8adf913ee22.svg" alt="E_{p}"/> est une famille génératrice. Il reste à montrer que c’est une
famille libre. Soient <img class="math" src="../../_images/math/42b0afbeac1e38e16da34b6893c564593752500a.svg" alt="\pa{y_i}_{1 \leqslant i \leqslant N} \in \pa{\mathbb{R}^p}^N"/> et
<img class="math" src="../../_images/math/8d61834887d62504b9e17e30fefd983436f606dd.svg" alt="\pa{b_i}_{1 \leqslant i \leqslant N} \in \mathbb{R}^N"/> vérifiant :
<img class="math" src="../../_images/math/75a818d87f51b3e660e3a49cad50e835c4ccc54c.svg" alt="i \neq j \Longrightarrow y_i \neq y_j \text{ ou } b_i \neq b_j"/>.
Soit <img class="math" src="../../_images/math/f349fa060d2baf84941ba159b4e2c1469140226c.svg" alt="\pa{\lambda_i}_{1 \leqslant i \leqslant N} \in \mathbb{R}^N"/>, il faut montrer que :</p>
<div class="math-wrapper docutils container" id="equation-corollaire-demo-recurrence-base">
<div class="math" id="equation-corollaire-demo-recurrence-base">
<p><span class="eqno">(3)<a class="headerlink" href="#equation-corollaire-demo-recurrence-base" title="Lien vers cette équation">¶</a></span><img src="../../_images/math/8e8d64981a8d9d1fc15238b572de87ff6ede3aaa.svg" alt="\begin{eqnarray}
\forall x \in \mathbb{R}^p, \; \sum_{i=1}^{N} \lambda_i \pa{ 1 - \dfrac{2}{1 + e^{&lt;y_i,x&gt;+b_i}  }} = 0
\Longrightarrow \forall i \, \lambda_i = 0
\end{eqnarray}"/></p>
</div></div>
<p>C’est évidemment vrai pour <img class="math" src="../../_images/math/5ef3c9cf976a9fcdbe57c1a7cc3d0ee8ad33081b.svg" alt="N=1"/>.
La démonstration est basée sur un raisonnement par récurrence,
on suppose qu’elle est vraie pour <img class="math" src="../../_images/math/5b7182a9e61cfdfecb16e3e366844540f84a51c9.svg" alt="N-1"/>,
démontrons qu’elle est vraie pour <img class="math" src="../../_images/math/bceb9186b5004313ecccd0d22d07ea9617b62f98.svg" alt="N"/>.
On suppose donc <img class="math" src="../../_images/math/011379fa8c2134b84632ff3165450936b8c55563.svg" alt="N \supegal 2"/>.
S’il existe <img class="math" src="../../_images/math/ade6825e6e139f44828f98e4f0b932639f33f538.svg" alt="i \in \ensemble{1}{N}"/> tel que <img class="math" src="../../_images/math/0e2d9d15f0cb6fbd75d4fa26a18f749d24676386.svg" alt="y_i = 0"/>,
la fonction <img class="math" src="../../_images/math/4b30c47dc01ecb21644b0b5f66de3b9e8138d2d6.svg" alt="x \longrightarrow 1 - \dfrac{2}{1 + e^{&lt;y_i,x&gt;+b_i}}"/>
est une constante, par conséquent, dans ce cas le corollaire est
est vrai pour <img class="math" src="../../_images/math/bceb9186b5004313ecccd0d22d07ea9617b62f98.svg" alt="N"/>. Dans le cas contraire,
<img class="math" src="../../_images/math/6e9eb67b080ccdf31786d4212accd218648e4410.svg" alt="\forall i \in \ensemble{1}{N}, \; y_i \neq 0"/>.
On définit les vecteurs <img class="math" src="../../_images/math/c1f0412bd01d3687dfb7903df73602baf42bc06a.svg" alt="X_i = \pa{x_i,1}"/> et
<img class="math" src="../../_images/math/3c374a7a79bb7542ce0fd1d9169142fbabe9f7e5.svg" alt="Y_i = \pa{y_j, b_j}"/>.
On cherche à résoude le système de <img class="math" src="../../_images/math/bceb9186b5004313ecccd0d22d07ea9617b62f98.svg" alt="N"/> équations à <img class="math" src="../../_images/math/bceb9186b5004313ecccd0d22d07ea9617b62f98.svg" alt="N"/> inconnues :</p>
<div class="math-wrapper docutils container" id="equation-rn-coro-eq-1">
<div class="math" id="equation-rn-coro-eq-1">
<p><span class="eqno">(4)<a class="headerlink" href="#equation-rn-coro-eq-1" title="Lien vers cette équation">¶</a></span><img src="../../_images/math/08b47841bae57dc65facc30385f9a8df6ab85f70.svg" alt="\begin{eqnarray}
\left\{
\begin{array}{ccc}
\sum_{j=1}^{N} \lambda_j \pa{ 1 - \dfrac{2}{1 + e^{&lt;Y_j,X_1&gt;}}} &amp;=&amp; 0 \\
\ldots \\
\sum_{j=1}^{N} \lambda_j \pa{ 1 - \dfrac{2}{1 + e^{&lt;Y_j,X_i&gt;}}} &amp;=&amp; 0 \\
\ldots \\
\sum_{j=1}^{N} \lambda_j \pa{ 1 - \dfrac{2}{1 + e^{&lt;Y_j,X_N&gt;}}} &amp;=&amp; 0
\end{array}
\right.
\end{eqnarray}"/></p>
</div></div>
<p>On note le vecteur
<img class="math" src="../../_images/math/de861323b954b3668d799bb8551edb260b051824.svg" alt="\Lambda = \pa{\lambda_i}_{ 1 \leqslant i \leqslant N}"/> et <img class="math" src="../../_images/math/e5c619f0600e251cabb3318b03870bc6f2c4870f.svg" alt="M"/> la matrice :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/d204130bb8e5e468bb10f99457d7524214657777.svg" alt="M= \pa{m_{ij}}_{ 1 \leqslant i,j \leqslant N} = \pa{ 1 - \dfrac{2}{1 + e^{&lt;Y_j,X_i&gt;}} }_{ 1 \leqslant i,j \leqslant N}"/></p>
</div></div>
<p>L’équation <a class="reference internal" href="#equation-rn-coro-eq-1">(4)</a> est équivalente à l’équation matricielle :
<img class="math" src="../../_images/math/e72aa076911edbc2afd14f3af3a95a2dbad95a41.svg" alt="M\Lambda = 0"/>. On effectue une itération du pivot de Gauss.
<a class="reference internal" href="#equation-rn-coro-eq-1">(4)</a> équivaut à :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/9ce2ce1f59bb1f34c4876e434677f83ed92937d7.svg" alt="\begin{array}{rcl}
&amp;\Longleftrightarrow&amp; \left\{ \begin{array}{ccllllllll}
                                \lambda_1  m_{11} &amp;+&amp; \lambda_2 &amp; m_{12} &amp;+&amp; \ldots &amp;+&amp; \lambda_N &amp; m_{1N} &amp; = 0 \\
                                0                 &amp;+&amp; \lambda_2 &amp; \pa{ m_{22} m_{11} - m_{12} m_{21} }
                                                                    &amp;+&amp; \ldots &amp;+&amp; \lambda_N &amp; \pa{ m_{2N} m_{11} - m_{1N} m_{21} }
                                                                     &amp; = 0 \\
                                \ldots \\
                                0                 &amp;+&amp; \lambda_2 &amp; \pa{ m_{N2} m_{11} - m_{12} m_{N1} } &amp;+&amp; \ldots
                                                                    &amp;+&amp; \lambda_N &amp; \pa{ m_{NN} m_{11} - m_{1N} m_{N1} } &amp; = 0
                                \end{array}
                                \right.
\end{array}"/></p>
</div></div>
<p>On note <img class="math" src="../../_images/math/35f4264ffaa2f0534083417a244b918bc437c9e6.svg" alt="\Lambda_* = \pa{\lambda_i}_{ 2 \leqslant i \leqslant N}"/> et
<img class="math" src="../../_images/math/b34f827f7dbe8f8ddc7f07c8d64ef573a7df0eb0.svg" alt="\Delta_*"/>, <img class="math" src="../../_images/math/9dbbcd2e21b352cb8958a49ba190d4b6e60b8b09.svg" alt="M_*"/> les matrices :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/6840846ade1040752dee837e64718b7bfaf5e46b.svg" alt="\begin{array}{rcl}
M_*         &amp;=&amp;     \pa{m_{ij}}_{ 2 \leqslant i,j \leqslant N} \\
\Delta_*    &amp;=&amp;     \pa{ m_{1j} \, m_{i1} }_{ 2 \leqslant i,j \leqslant N}
\end{array}"/></p>
</div></div>
<p>Donc <a class="reference internal" href="#equation-rn-coro-eq-1">(4)</a> est équivalent à :</p>
<div class="math-wrapper docutils container" id="equation-rn-coro-eq-3">
<div class="math" id="equation-rn-coro-eq-3">
<p><span class="eqno">(5)<a class="headerlink" href="#equation-rn-coro-eq-3" title="Lien vers cette équation">¶</a></span><img src="../../_images/math/3e9cf9f022fbddd4af273b1db8ddb5eb20d974ae.svg" alt="\begin{eqnarray}
\begin{array}{ccl}
                     &amp;\Longleftrightarrow&amp; \left\{ \begin{array}{cccc}
                                \lambda_1  m_{11}&amp;+&amp; \lambda_2  m_{12} + \ldots + \lambda_N  m_{1N}  &amp;= 0 \\
                                0                &amp;+&amp;   \pa{ m_{11} M_* -  \Delta_*} \Lambda_* &amp; = 0
                                \end{array}
                                \right.
\end{array}
\end{eqnarray}"/></p>
</div></div>
<p>Il est possible de choisir <img class="math" src="../../_images/math/7ac94b39321bbcfb20a4da4ae7a383a2e43d6e99.svg" alt="X_1\pa{\alpha} = \pa{\alpha x_1, 1}"/>
de telle sorte qu’il existe une suite <img class="math" src="../../_images/math/656882c08008a3b5337bcd33dff63e98b267fa21.svg" alt="\pa{s_l}_{ 1 \leqslant l \leqslant N } \in \acc{-1,1}^{N}"/>
avec <img class="math" src="../../_images/math/59742d21f1126253a54e806c0e6e7a5725243551.svg" alt="s_1=1"/> et vérifiant :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/970a1e660e2c04323db550409742209a554f6632.svg" alt="\forall j \in \vecteur{1}{N}, \;
\underset{\alpha \longrightarrow +\infty} {\lim }  \cro{ 1 - \dfrac{2}{1 + e^{&lt;Y_j, \, X_1\pa{\alpha}   &gt;}} } =
\underset{\alpha \longrightarrow +\infty} {\lim }  m_{1j}\pa{\alpha} = s_j"/></p>
</div></div>
<p>On définit :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/bc9337af612ab9e25269978265157e33bddb0ccd.svg" alt="\begin{array}{rll}
U_* &amp;=&amp; \vecteur{m_{21}}{m_{N1}}' \\
V_* &amp;=&amp; \vecteur{s_2 \, m_{21}}{s_N \, m_{N1}}' \\
\text{ et la matrice } L_* &amp;=&amp; \pa{V_*}_ { 2 \leqslant i \leqslant N } \text{ dont les $N-1$ colonnes sont identiques }
\end{array}"/></p>
</div></div>
<p>On vérifie que :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/bde002bbd60d290389fbbc3c36b93a89e0f372d1.svg" alt="\underset{\alpha \longrightarrow +\infty} {\lim } \Delta\pa{\alpha} = V_*"/></p>
</div></div>
<p>On obtient, toujours pour <a class="reference internal" href="#equation-rn-coro-eq-1">(4)</a> :</p>
<blockquote>
<div><div class="math-wrapper docutils container" id="equation-rn-coro-eq-2">
<div class="math" id="equation-rn-coro-eq-2">
<p><span class="eqno">(6)<a class="headerlink" href="#equation-rn-coro-eq-2" title="Lien vers cette équation">¶</a></span><img src="../../_images/math/530ce036945f5c1f97c96c2b88b4760e5078aaea.svg" alt="\begin{eqnarray}
                     &amp;\Longleftrightarrow&amp; \left\{ \begin{array}{cclc}
                                \lambda_1  m_{11}\pa{\alpha}    &amp;+&amp;
                                                            \lambda_2  m_{12}\pa{\alpha} + \ldots + \lambda_N  m_{1N}\pa{\alpha}  &amp;= 0 \\
                                0                &amp;+&amp;   \cro{m_{11}\pa{\alpha} M_* -
                                                                                    \pa{ L_* + \pa{ \Delta_*\pa{\alpha} - L_* } } }
                                                                                \Lambda_* &amp; = 0
                                \end{array}
                                \right. \\ \nonumber\\
                     &amp;\Longleftrightarrow&amp; \left\{ \begin{array}{cclc}
                                \lambda_1  m_{11}\pa{\alpha}    &amp;+&amp;
                                                            \lambda_2  m_{12}\pa{\alpha} + \ldots + \lambda_N  m_{1N}\pa{\alpha}  &amp;= 0 \\
                                0                &amp;+&amp;   \pa{m_{11}\pa{\alpha} M_* -    L_* }      \Lambda_*
                                                     +  \pa{ \Delta_*\pa{\alpha} - L_* }     \Lambda_* &amp;  = 0
                                \end{array}
                                \right. \nonumber
\end{eqnarray}"/></p>
</div></div>
</div></blockquote>
<p>On étudie la limite lorsque <img class="math" src="../../_images/math/4e8a38a3459f3dc0db32df208b0b6c26361afd9e.svg" alt="\alpha \longrightarrow +\infty"/> :</p>
<div class="math-wrapper docutils container">
<div class="math">
<p><img src="../../_images/math/70591f4d7130eb24a88af638567bd703cf07d97d.svg" alt="\begin{array}{crcl}
                    &amp; \pa{ \Delta_*\pa{\alpha} - L_* }   &amp;
                        \underset{ \alpha \rightarrow +\infty}{ \longrightarrow} &amp; 0                 \\
\Longrightarrow     &amp; \pa{m_{11}\pa{\alpha} M_* -   L_* }      \Lambda_* &amp;
                        \underset{ \alpha \rightarrow +\infty}{ \longrightarrow} &amp;  0\\
\Longrightarrow     &amp; \pa{M_* -  L_* }      \Lambda_* &amp;   = &amp;  0\\
\Longrightarrow     &amp; M_* \Lambda_* -    \pa{  \sum_{j=2}^{N} \lambda_j   }   V_*   &amp;   = &amp;  0\\
\end{array}"/></p>
</div></div>
<p>Donc :</p>
<div class="math-wrapper docutils container" id="equation-rn-coro-eq-5">
<div class="math" id="equation-rn-coro-eq-5">
<p><span class="eqno">(7)<a class="headerlink" href="#equation-rn-coro-eq-5" title="Lien vers cette équation">¶</a></span><img src="../../_images/math/9c36a6e4dfe72c3c4a6289aeec59c0d4cef04c0f.svg" alt="\begin{eqnarray*}
M_* \Lambda_* -    \pa{  \sum_{j=2}^{N} \lambda_j   }   V_*   &amp;=&amp;  0
\end{eqnarray*}"/></p>
</div></div>
<p>D’après l’hypothèse de récurrence, <a class="reference internal" href="#equation-rn-coro-eq-5">(7)</a> implique que :
<img class="math" src="../../_images/math/69cd38d29275ef67fd8b33b50629bbb4f87cfc42.svg" alt="\forall i \in \ensemble{2}{N}, \; \lambda_i = 0"/>.
Il reste à montrer que <img class="math" src="../../_images/math/73a087d25af7a13483c39ff28ca01c3d9986b07a.svg" alt="\lambda_1"/>
est nécessairement nul ce qui est le cas losque <img class="math" src="../../_images/math/4e8a38a3459f3dc0db32df208b0b6c26361afd9e.svg" alt="\alpha \longrightarrow +\infty"/>,
alors <img class="math" src="../../_images/math/dba06ac43905cbaef199007b6037b0412b34bcd3.svg" alt="\lambda_1  m_{11}\pa{\alpha} \longrightarrow \lambda_1 = 0"/>.
La récurrence est démontrée.</p>
<p>A chaque fonction sigmoïde du corollaire <a class="reference internal" href="#corollaire-famille-libre"><span class="std std-ref">famille libre</span></a>
correspond un neurone de la couche cachée. Tous ont des rôles
symétriques les uns par rapport aux autres ce qui ne serait
pas le cas si les fonctions de transfert étaient des polynômes.
C’est une des raisons pour lesquelles les réseaux de neurones
ont du succès. Le théorème <a class="reference internal" href="#theoreme-densite"><span class="std std-ref">densité</span></a>
et le corollaire <a class="reference internal" href="#corollaire-famille-libre"><span class="std std-ref">famille libre</span></a>
sont aussi vraies pour des fonctions du type exponentielle :
<img class="math" src="../../_images/math/cc0e9f1e4b1b79e937443ef4a3d1034563bc7156.svg" alt="\pa{y,b} \in \mathbb{R}^p \times \mathbb{R} \longrightarrow e^{-\pa{&lt;y,x&gt;+b}^2}"/>.
Maintenant qu’il est prouvé que les réseaux de neurones conviennent
pour modéliser <img class="math" src="../../_images/math/bd1e0600a66dbe0f8deddbd57953774419ba4e4f.svg" alt="f"/> dans l’équation <a class="reference internal" href="#equation-rn-eqn-regression-2">(2)</a>,
il reste à étudier les méthodes qui permettent de trouver
les paramètres <img class="math" src="../../_images/math/4d4f4910fb33f542260bd4f5593ffb800c330e49.svg" alt="W^*"/> optimaux de cette fonction.</p>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="rn_5_newton.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Descente de gradient</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="rn_3_clas.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">La classification</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2016-2025, Xavier Dupré
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Démonstration du théorème de la densité des réseaux de neurones</a><ul>
<li><a class="reference internal" href="#formulation-du-probleme-de-la-regression">Formulation du problème de la régression</a></li>
<li><a class="reference internal" href="#densite-des-reseaux-de-neurones">Densité des réseaux de neurones</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../../_static/documentation_options.js?v=0886690b"></script>
    <script src="../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/scripts/furo.js?v=5fa4622c"></script>
    <script src="../../_static/translations.js?v=e6b791cb"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    </body>
</html>