
<!DOCTYPE html>


<html lang="fr" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Régression linéaire &#8212; Documentation mlstatpy 0.4.0</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css?v=fd3f3429" />
    <link rel="stylesheet" type="text/css" href="../../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../../_static/nbsphinx-code-cells.css?v=2aa19091" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=f45c5ce7"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/translations.js?v=041d0952"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"chtml": {"displayAlign": "left"}, "tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/dsgarden/regression_lineaire';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Recherche" href="../../search.html" />
    <link rel="next" title="Régression quantile ou régression L1" href="../../c_ml/regression_quantile.html" />
    <link rel="prev" title="Régression linéaire" href="../../c_ml/index_reg_lin.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="fr"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Passer au contenu principal</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Haut de page</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Navigation dans le site">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/project_ico.png" class="logo__image only-light" alt="Documentation mlstatpy 0.4.0 - Home"/>
    <script>document.write(`<img src="../../_static/project_ico.png" class="logo__image only-dark" alt="Documentation mlstatpy 0.4.0 - Home"/>`);</script>
  
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../c_clus/index.html">
    Clustering
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../c_ml/index.html">
    Non linéaire
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../c_ml/index_reg_lin.html">
    Régression linéaire
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../c_ml/index_reg_log.html">
    Régression logistique
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../c_nlp/index.html">
    NLP
  </a>
</li>

            <li class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-controls="pst-nav-more-links">
                    More
                </button>
                <ul id="pst-nav-more-links" class="dropdown-menu">
                    
<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../c_metric/index.html">
    Métriques
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../c_algo/index.html">
    Algorithmes
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../c_garden/index.html">
    Pérégrinations
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../api/index.html">
    API
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../i_ex.html">
    Examples
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../defthe_index.html">
    Listes des définitions et théorèmes
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../auto_examples/index.html">
    Gallery of examples
  </a>
</li>


<li class=" current active">
  <a class="nav-link dropdown-item nav-internal" href="../index.html">
    Galleries de notebooks
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../glossary.html">
    Glossary
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../CHANGELOGS.html">
    Change Logs
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../license.html">
    License
  </a>
</li>

                </ul>
            </li>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Recherche" aria-label="Recherche" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Recherche</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script>
        </div>
      
      
        <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="clair/sombre" aria-label="clair/sombre" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Recherche" aria-label="Recherche" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Recherche</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="Sur cette page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../c_clus/index.html">
    Clustering
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../c_ml/index.html">
    Non linéaire
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../c_ml/index_reg_lin.html">
    Régression linéaire
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../c_ml/index_reg_log.html">
    Régression logistique
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../c_nlp/index.html">
    NLP
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../c_metric/index.html">
    Métriques
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../c_algo/index.html">
    Algorithmes
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../c_garden/index.html">
    Pérégrinations
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../api/index.html">
    API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../i_ex.html">
    Examples
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../defthe_index.html">
    Listes des définitions et théorèmes
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../auto_examples/index.html">
    Gallery of examples
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../index.html">
    Galleries de notebooks
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../glossary.html">
    Glossary
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../CHANGELOGS.html">
    Change Logs
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../license.html">
    License
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="clair/sombre" aria-label="clair/sombre" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Navigation de la section">
  <p class="bd-links__title" role="heading" aria-level="1">Navigation de la section</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="index.html">Le petit coin des data scientists</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="classification_multiple.html">Classification multiple</a></li>
<li class="toctree-l2"><a class="reference internal" href="correlation_non_lineaire.html">Corrélations non linéaires</a></li>
<li class="toctree-l2"><a class="reference internal" href="discret_gradient.html">Le gradient et le discret</a></li>
<li class="toctree-l2"><a class="reference internal" href="file_dattente_ex.html">File d’attente, un exemple simple</a></li>
<li class="toctree-l2"><a class="reference internal" href="quantile_regression_example.html">Régression quantile illustrée</a></li>
<li class="toctree-l2"><a class="reference internal" href="quantization_f8.html">Quantization</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Régression linéaire</a></li>
<li class="toctree-l2"><a class="reference internal" href="split_train_test.html">Répartir en base d’apprentissage et de test</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../image/index.html">Images</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../image/segment_detection.html">Détection de segments dans une image</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../metric/index.html">Métriques</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../metric/pvalues_examples.html">p-values</a></li>
<li class="toctree-l2"><a class="reference internal" href="../metric/roc_example.html">ROC</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../ml/index.html">Machine Learning</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../ml/logreg_voronoi.html">Voronoï et régression logistique</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ml/mf_acp.html">Factorisation et matrice et ACP</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ml/neural_tree.html">Un arbre de décision en réseaux de neurones</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ml/neural_tree_cost.html">NeuralTreeNet et coût</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ml/neural_tree_onnx.html">NeuralTreeNet et ONNX</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ml/piecewise_linear_regression.html">Régression linéaire par morceaux</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ml/regression_no_inversion.html">Régression sans inversion</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ml/reseau_neurones.html">Réseaux de neurones</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ml/survival.html">Analyse de survie en pratique</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ml/valeurs_manquantes_mf.html">Valeurs manquantes et factorisation de matrices</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../nlp/index.html">NLP - Natural Language Processing</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../nlp/completion_profiling.html">Completion profiling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp/completion_simple.html">Complétion Simple</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp/completion_trie.html">Complétion</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp/completion_trie_long.html">Completion Trie and metrics</a></li>
</ul>
</details></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Fil d'Ariane" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../index.html" class="nav-link" aria-label="Accueil">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../../c_ml/index_reg_lin.html" class="nav-link">Régression linéaire</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">Régression linéaire</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="Régression-linéaire">
<h1>Régression linéaire<a class="headerlink" href="#Régression-linéaire" title="Lien vers cette rubrique">#</a></h1>
<p>Ce notebook s’intéresse à la façon d’interpréter les résultats d’une régression linéaire lorsque les variables sont corrélées puis il explore une façon d’associer arbre de décision et régression linéaire pour construire une régression linéaire par morceaux.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>
</div>
</div>
<section id="Un-cas-simple">
<h2>Un cas simple<a class="headerlink" href="#Un-cas-simple" title="Lien vers cette rubrique">#</a></h2>
<p>Une façon d’interpréter des résultats statistiques est de les calculer dans un cas où la réponse cherchée est connue. On simule un modèle simple <span class="math notranslate nohighlight">\(Y=\alpha X_1 + 0.X_2 + \epsilon\)</span> et on cale une régression linéaire. On suppose que <span class="math notranslate nohighlight">\(X_1, X_2, \epsilon\)</span> sont des variables aléatoires gaussiennes de même variance et moyenne.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy.random</span> <span class="k">as</span> <span class="nn">npr</span>

<span class="n">eps</span> <span class="o">=</span> <span class="n">npr</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">npr</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span>
<span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
((1000, 3), (1000,))
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">corrcoef</span>

<span class="n">corrcoef</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
array([[ 1.        ,  0.02585011, -0.00808406],
       [ 0.02585011,  1.        ,  0.00338766],
       [-0.00808406,  0.00338766,  1.        ]])
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">statsmodels.regression.linear_model</span> <span class="kn">import</span> <span class="n">OLS</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">OLS</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">])</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">su</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
<span class="n">su</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.803</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.802</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   2029.</td>
</tr>
<tr>
  <th>Date:</th>             <td>Mon, 07 Oct 2024</td> <th>  Prob (F-statistic):</th>           <td>  0.00</td>
</tr>
<tr>
  <th>Time:</th>                 <td>11:29:03</td>     <th>  Log-Likelihood:    </th>          <td> -1417.8</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>  1000</td>      <th>  AIC:               </th>          <td>   2840.</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>   998</td>      <th>  BIC:               </th>          <td>   2849.</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>              <td> </td>
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>
</tr>
</table>
<table class="simpletable">
<tr>
   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>
</tr>
<tr>
  <th>x1</th> <td>    1.9922</td> <td>    0.031</td> <td>   63.680</td> <td> 0.000</td> <td>    1.931</td> <td>    2.054</td>
</tr>
<tr>
  <th>x2</th> <td>    0.0041</td> <td>    0.032</td> <td>    0.130</td> <td> 0.896</td> <td>   -0.058</td> <td>    0.067</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td> 4.685</td> <th>  Durbin-Watson:     </th> <td>   2.126</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.096</td> <th>  Jarque-Bera (JB):  </th> <td>   4.706</td>
</tr>
<tr>
  <th>Skew:</th>          <td>-0.167</td> <th>  Prob(JB):          </th> <td>  0.0951</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 2.972</td> <th>  Cond. No.          </th> <td>    1.03</td>
</tr>
</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span><span class="o">.</span><span class="n">rsquared</span><span class="p">,</span> <span class="n">results</span><span class="o">.</span><span class="n">rsquared_adj</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(np.float64(0.8026213180783517), np.float64(0.8022257696175868))
</pre></div></div>
</div>
<p>On vérifie que le coefficient devant <span class="math notranslate nohighlight">\(X_1\)</span> est non nul (P-value nulle, 0 n’est pas l’intervalle de confiance). Le coefficient devant <span class="math notranslate nohighlight">\(X_2\)</span> n’est pas nul mais presque, la P-value est élevée, le coefficient <span class="math notranslate nohighlight">\(R^2\)</span> est élevé. Dessinons.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">Y</span><span class="p">,</span> <span class="s2">&quot;.&quot;</span><span class="p">)</span>
<span class="n">seaborn</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">Y</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Reds&quot;</span><span class="p">,</span> <span class="n">shade</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">shade_lowest</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;nuage de points&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;estimation de la densité&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/tmp/ipykernel_21413/1827909711.py:6: UserWarning:

`shade_lowest` has been replaced by `thresh`; setting `thresh=0.05.
This will become an error in seaborn v0.14.0; please update your code.

  seaborn.kdeplot(x=X[:, 0], y=Y, cmap=&#34;Reds&#34;, shade=True, shade_lowest=False, ax=ax[1])
/tmp/ipykernel_21413/1827909711.py:6: FutureWarning:

`shade` is now deprecated in favor of `fill`; setting `fill=True`.
This will become an error in seaborn v0.14.0; please update your code.

  seaborn.kdeplot(x=X[:, 0], y=Y, cmap=&#34;Reds&#34;, shade=True, shade_lowest=False, ax=ax[1])
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_dsgarden_regression_lineaire_9_1.png" src="../../_images/notebooks_dsgarden_regression_lineaire_9_1.png" />
</div>
</div>
</section>
<section id="Evolution-de-R2">
<h2>Evolution de R2<a class="headerlink" href="#Evolution-de-R2" title="Lien vers cette rubrique">#</a></h2>
<p>Dans la régression précédente, le coefficient <span class="math notranslate nohighlight">\(R^2\)</span> transcrit en quelque sorte la part du bruit <span class="math notranslate nohighlight">\(\epsilon\)</span> par rapport au terme <span class="math notranslate nohighlight">\(\alpha X_1\)</span>. Faisons varier <span class="math notranslate nohighlight">\(\alpha\)</span>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">alphas</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">r2s</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="p">[</span><span class="mf">0.1</span> <span class="o">*</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">50</span><span class="p">)]:</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">OLS</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">])</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
    <span class="n">alphas</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="n">r2s</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">rsquared</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span> <span class="n">r2s</span><span class="p">,</span> <span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;observed&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span> <span class="p">[</span><span class="n">a</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">a</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">alphas</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;theoretical&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;alpha&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;r2&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_dsgarden_regression_lineaire_12_0.png" src="../../_images/notebooks_dsgarden_regression_lineaire_12_0.png" />
</div>
</div>
<p>Dans ce cas de régression simple, la valeur à prédire est <span class="math notranslate nohighlight">\(y_i\)</span>, la valeur prédite est <span class="math notranslate nohighlight">\(\hat{y_i}=\alpha X_{1i}\)</span> et la moyenne <span class="math notranslate nohighlight">\(\bar{y} = \alpha \bar{X_1} + \bar{\epsilon} = 0\)</span>.</p>
<div class="math notranslate nohighlight">
\[R^2 = 1 - \frac{\sum_{i=1}^n (\hat{y_i}-\bar{y})^2}{\sum_{i=1}^n (y_i - \bar{y})^2}=1-\frac{\mathbb{V}\epsilon}{\alpha^2\mathbb{V}X_1+\mathbb{V}\epsilon} = 1 - \frac{1}{1+\alpha^2}=\frac{\alpha^2}{1+\alpha^2}\]</div>
</section>
<section id="Deux-variables-corrélées">
<h2>Deux variables corrélées<a class="headerlink" href="#Deux-variables-corrélées" title="Lien vers cette rubrique">#</a></h2>
<p>On ne change pas le modèle mais on fait en sorte que <span class="math notranslate nohighlight">\(X_2=X_1\)</span>. Les deux variables sont corrélées.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">Y</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">OLS</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">])</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">results</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.803</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.802</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   4062.</td>
</tr>
<tr>
  <th>Date:</th>             <td>Mon, 07 Oct 2024</td> <th>  Prob (F-statistic):</th>           <td>  0.00</td>
</tr>
<tr>
  <th>Time:</th>                 <td>11:29:04</td>     <th>  Log-Likelihood:    </th>          <td> -1417.8</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>  1000</td>      <th>  AIC:               </th>          <td>   2838.</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>   999</td>      <th>  BIC:               </th>          <td>   2843.</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>              <td> </td>
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>
</tr>
</table>
<table class="simpletable">
<tr>
   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>
</tr>
<tr>
  <th>x1</th> <td>    0.9961</td> <td>    0.016</td> <td>   63.736</td> <td> 0.000</td> <td>    0.965</td> <td>    1.027</td>
</tr>
<tr>
  <th>x2</th> <td>    0.9961</td> <td>    0.016</td> <td>   63.736</td> <td> 0.000</td> <td>    0.965</td> <td>    1.027</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td> 4.681</td> <th>  Durbin-Watson:     </th> <td>   2.126</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.096</td> <th>  Jarque-Bera (JB):  </th> <td>   4.705</td>
</tr>
<tr>
  <th>Skew:</th>          <td>-0.167</td> <th>  Prob(JB):          </th> <td>  0.0951</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 2.971</td> <th>  Cond. No.          </th> <td>3.15e+16</td>
</tr>
</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[3] The smallest eigenvalue is 2.06e-30. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular.</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">rank</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
np.int64(1)
</pre></div></div>
</div>
<p>Les variables corrélées n’ont pas l’air de déranger l’algorithme de résolution car il utilise la méthode <a class="reference external" href="https://en.wikipedia.org/wiki/Singular-value_decomposition">SVD</a> pour résoudre le même problème dans un espace de moindre dimension. Le problème survient que les deux variables ne sont pas complétement corrélées. On étudie le modèle <span class="math notranslate nohighlight">\(Y \sim X_1 + X'_2\)</span> avec <span class="math notranslate nohighlight">\(X'_2 = \alpha X_1 + (1-\alpha) X_2\)</span> et on réduit la variance du bruit pour en diminuer les effets.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_</span> <span class="o">=</span> <span class="n">npr</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">alphas</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.9</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="mf">0.01</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">11</span><span class="p">)]</span>
<span class="n">res</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">alphas</span><span class="p">:</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">X_</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">a</span><span class="p">)</span> <span class="o">*</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">OLS</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">])</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
    <span class="n">res</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
        <span class="nb">dict</span><span class="p">(</span>
            <span class="n">alpha</span><span class="o">=</span><span class="n">a</span><span class="p">,</span>
            <span class="n">r2</span><span class="o">=</span><span class="n">results</span><span class="o">.</span><span class="n">rsquared</span><span class="p">,</span>
            <span class="n">rank</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">rank</span><span class="p">,</span>
            <span class="n">c1</span><span class="o">=</span><span class="n">results</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="n">c2</span><span class="o">=</span><span class="n">results</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
        <span class="p">)</span>
    <span class="p">)</span>

<span class="kn">import</span> <span class="nn">pandas</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s2">&quot;alpha&quot;</span><span class="p">)</span>
<span class="n">df</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>r2</th>
      <th>rank</th>
      <th>c1</th>
      <th>c2</th>
    </tr>
    <tr>
      <th>alpha</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0.90</th>
      <td>0.997328</td>
      <td>2</td>
      <td>1.013974</td>
      <td>0.986445</td>
    </tr>
    <tr>
      <th>0.91</th>
      <td>0.997353</td>
      <td>2</td>
      <td>1.015480</td>
      <td>0.984939</td>
    </tr>
    <tr>
      <th>0.92</th>
      <td>0.997379</td>
      <td>2</td>
      <td>1.017363</td>
      <td>0.983056</td>
    </tr>
    <tr>
      <th>0.93</th>
      <td>0.997403</td>
      <td>2</td>
      <td>1.019783</td>
      <td>0.980636</td>
    </tr>
    <tr>
      <th>0.94</th>
      <td>0.997428</td>
      <td>2</td>
      <td>1.023011</td>
      <td>0.977409</td>
    </tr>
    <tr>
      <th>0.95</th>
      <td>0.997453</td>
      <td>2</td>
      <td>1.027529</td>
      <td>0.972890</td>
    </tr>
    <tr>
      <th>0.96</th>
      <td>0.997477</td>
      <td>2</td>
      <td>1.034306</td>
      <td>0.966113</td>
    </tr>
    <tr>
      <th>0.97</th>
      <td>0.997501</td>
      <td>2</td>
      <td>1.045602</td>
      <td>0.954817</td>
    </tr>
    <tr>
      <th>0.98</th>
      <td>0.997525</td>
      <td>2</td>
      <td>1.068193</td>
      <td>0.932226</td>
    </tr>
    <tr>
      <th>0.99</th>
      <td>0.997548</td>
      <td>2</td>
      <td>1.135968</td>
      <td>0.864452</td>
    </tr>
    <tr>
      <th>1.00</th>
      <td>0.997571</td>
      <td>1</td>
      <td>1.000861</td>
      <td>1.000861</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">df</span><span class="p">[[</span><span class="s2">&quot;r2&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">df</span><span class="p">[[</span><span class="s2">&quot;c1&quot;</span><span class="p">,</span> <span class="s2">&quot;c2&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;R2&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;coefficients&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_dsgarden_regression_lineaire_20_0.png" src="../../_images/notebooks_dsgarden_regression_lineaire_20_0.png" />
</div>
</div>
<p>Le <span class="math notranslate nohighlight">\(r^2\)</span> augmente quand la corrélation augmente mais les coefficients sont moins fiables. Les résultats devraient être sensiblement identiques en théorie mais en pratique, plus le déterminant devient proche de zéro, plus l’ordinateur est limité par sa précision numérique. Pour en savoir plus, vous pouvez lire un examen écrit que j’ai rédigé, en python bien sûr : <a class="reference external" href="https://sdpython.github.io/doc/teachpyx/dev/_downloads/f9f86ad8c2bcfcba777d6ed8caafb5f6/td_note_2006.pdf">Examen Programmation ENSAE première année
2006</a>. Cette précision est aux alentours de <span class="math notranslate nohighlight">\(10^{-15}\)</span> ce qui correspond à la précision numérique des <a class="reference external" href="https://en.wikipedia.org/wiki/Double-precision_floating-point_format">double</a>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">alphas</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span> <span class="o">-</span> <span class="mi">10</span> <span class="o">**</span> <span class="p">(</span><span class="o">-</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">18</span><span class="p">)]</span>
<span class="n">res</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">alphas</span><span class="p">:</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">X_</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">a</span><span class="p">)</span> <span class="o">*</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">OLS</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">])</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
    <span class="n">res</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
        <span class="nb">dict</span><span class="p">(</span>
            <span class="n">alpha_1</span><span class="o">=</span><span class="n">a</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>
            <span class="n">r2</span><span class="o">=</span><span class="n">results</span><span class="o">.</span><span class="n">rsquared</span><span class="p">,</span>
            <span class="n">rank</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">rank</span><span class="p">,</span>
            <span class="n">c1</span><span class="o">=</span><span class="n">results</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="n">c2</span><span class="o">=</span><span class="n">results</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
        <span class="p">)</span>
    <span class="p">)</span>

<span class="kn">import</span> <span class="nn">pandas</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s2">&quot;alpha_1&quot;</span><span class="p">)</span>
<span class="n">df</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>r2</th>
      <th>rank</th>
      <th>c1</th>
      <th>c2</th>
    </tr>
    <tr>
      <th>alpha_1</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>-1.000000e-10</th>
      <td>0.806651</td>
      <td>2</td>
      <td>1.355493e+08</td>
      <td>-1.355493e+08</td>
    </tr>
    <tr>
      <th>-1.000000e-11</th>
      <td>0.806651</td>
      <td>2</td>
      <td>1.355632e+09</td>
      <td>-1.355632e+09</td>
    </tr>
    <tr>
      <th>-9.999779e-13</th>
      <td>0.806651</td>
      <td>2</td>
      <td>1.355997e+10</td>
      <td>-1.355997e+10</td>
    </tr>
    <tr>
      <th>-1.000311e-13</th>
      <td>0.806651</td>
      <td>2</td>
      <td>1.357117e+11</td>
      <td>-1.357117e+11</td>
    </tr>
    <tr>
      <th>-9.992007e-15</th>
      <td>0.806648</td>
      <td>2</td>
      <td>1.410632e+12</td>
      <td>-1.410632e+12</td>
    </tr>
    <tr>
      <th>-9.992007e-16</th>
      <td>0.806616</td>
      <td>2</td>
      <td>1.008605e+00</td>
      <td>1.008605e+00</td>
    </tr>
    <tr>
      <th>-1.110223e-16</th>
      <td>0.806616</td>
      <td>1</td>
      <td>1.008605e+00</td>
      <td>1.008605e+00</td>
    </tr>
    <tr>
      <th>0.000000e+00</th>
      <td>0.806616</td>
      <td>1</td>
      <td>1.008605e+00</td>
      <td>1.008605e+00</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>On fait un dernier test avec <a class="reference external" href="http://scikit-learn.org/stable/">scikit-learn</a> pour vérifier que l’algorithme de résolution donne des résultats similaires pour un cas où le déterminant est quasi-nul.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span>

<span class="n">alphas</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.9</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="mf">0.01</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">11</span><span class="p">)]</span>
<span class="n">res</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">alphas</span><span class="p">:</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">X_</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">a</span><span class="p">)</span> <span class="o">*</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">],</span> <span class="n">Y</span><span class="p">)</span>
    <span class="n">r2</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]))</span>
    <span class="n">res</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="n">a</span><span class="p">,</span> <span class="n">c1</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">c2</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">r2</span><span class="o">=</span><span class="n">r2</span><span class="p">))</span>

<span class="kn">import</span> <span class="nn">pandas</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s2">&quot;alpha&quot;</span><span class="p">)</span>
<span class="n">df</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>c1</th>
      <th>c2</th>
      <th>r2</th>
    </tr>
    <tr>
      <th>alpha</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0.90</th>
      <td>1.140599</td>
      <td>0.863675</td>
      <td>0.791250</td>
    </tr>
    <tr>
      <th>0.91</th>
      <td>1.155746</td>
      <td>0.848528</td>
      <td>0.792821</td>
    </tr>
    <tr>
      <th>0.92</th>
      <td>1.174680</td>
      <td>0.829593</td>
      <td>0.794384</td>
    </tr>
    <tr>
      <th>0.93</th>
      <td>1.199024</td>
      <td>0.805250</td>
      <td>0.795940</td>
    </tr>
    <tr>
      <th>0.94</th>
      <td>1.231482</td>
      <td>0.772791</td>
      <td>0.797489</td>
    </tr>
    <tr>
      <th>0.95</th>
      <td>1.276924</td>
      <td>0.727350</td>
      <td>0.799029</td>
    </tr>
    <tr>
      <th>0.96</th>
      <td>1.345087</td>
      <td>0.659187</td>
      <td>0.800562</td>
    </tr>
    <tr>
      <th>0.97</th>
      <td>1.458691</td>
      <td>0.545583</td>
      <td>0.802087</td>
    </tr>
    <tr>
      <th>0.98</th>
      <td>1.685900</td>
      <td>0.318374</td>
      <td>0.803603</td>
    </tr>
    <tr>
      <th>0.99</th>
      <td>2.367526</td>
      <td>-0.363252</td>
      <td>0.805111</td>
    </tr>
    <tr>
      <th>1.00</th>
      <td>1.008682</td>
      <td>1.008682</td>
      <td>0.806575</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">df</span><span class="p">[[</span><span class="s2">&quot;c1&quot;</span><span class="p">,</span> <span class="s2">&quot;c2&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">df</span><span class="p">[[</span><span class="s2">&quot;c1&quot;</span><span class="p">,</span> <span class="s2">&quot;c2&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="n">df</span><span class="p">[[</span><span class="s2">&quot;r2&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;R2&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;coefficients&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;coefficients, échelle tronquée&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_dsgarden_regression_lineaire_25_0.png" src="../../_images/notebooks_dsgarden_regression_lineaire_25_0.png" />
</div>
</div>
<p>Le second graphe est trompeur mais il ne faut pas oublier de regarder l’échelle de l’axe des ordonnées.</p>
</section>
<section id="Indicatrices">
<h2>Indicatrices<a class="headerlink" href="#Indicatrices" title="Lien vers cette rubrique">#</a></h2>
<p><span class="math notranslate nohighlight">\(X_1\)</span> est une variable aléatoire gaussienne. On teste maintenant un modèle <span class="math notranslate nohighlight">\(Y = X'_1 + X'_2 + \epsilon\)</span> avec <span class="math notranslate nohighlight">\(X'_1 = X_1 \mathbb{1}_{X_1 &lt; 0}\)</span> et <span class="math notranslate nohighlight">\(X'_2 = X_1 \mathbb{1}_{X_1 \geqslant 0}\)</span>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">npr</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">X</span><span class="p">[</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">X</span><span class="p">[</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span>
<span class="n">corrcoef</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
array([[ 1.        ,  0.48561838,  0.0042644 ],
       [ 0.48561838,  1.        , -0.01058737],
       [ 0.0042644 , -0.01058737,  1.        ]])
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[29]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pandas</span> <span class="kn">import</span> <span class="n">DataFrame</span>

<span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;X</span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)]</span>
<span class="n">ax</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">50</span><span class="p">,</span> <span class="p">:</span><span class="mi">2</span><span class="p">],</span> <span class="n">columns</span><span class="o">=</span><span class="n">names</span><span class="p">)</span>
    <span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">names</span><span class="p">)</span>
    <span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Représentation des features tronquées&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_dsgarden_regression_lineaire_29_0.png" src="../../_images/notebooks_dsgarden_regression_lineaire_29_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[30]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">OLS</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">3</span><span class="p">])</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">results</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[30]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>       <td>   1.000</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th>  <td>   1.000</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>           <td>1.581e+33</td>
</tr>
<tr>
  <th>Date:</th>             <td>Mon, 07 Oct 2024</td> <th>  Prob (F-statistic):</th>            <td>  0.00</td>
</tr>
<tr>
  <th>Time:</th>                 <td>11:29:06</td>     <th>  Log-Likelihood:    </th>           <td>  33532.</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>  1000</td>      <th>  AIC:               </th>          <td>-6.706e+04</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>   997</td>      <th>  BIC:               </th>          <td>-6.704e+04</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>               <td> </td>
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>               <td> </td>
</tr>
</table>
<table class="simpletable">
<tr>
   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>
</tr>
<tr>
  <th>x1</th> <td>    1.0000</td> <td> 2.98e-17</td> <td> 3.35e+16</td> <td> 0.000</td> <td>    1.000</td> <td>    1.000</td>
</tr>
<tr>
  <th>x2</th> <td>    1.0000</td> <td> 2.73e-17</td> <td> 3.66e+16</td> <td> 0.000</td> <td>    1.000</td> <td>    1.000</td>
</tr>
<tr>
  <th>x3</th> <td>    1.0000</td> <td> 2.09e-17</td> <td> 4.79e+16</td> <td> 0.000</td> <td>    1.000</td> <td>    1.000</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>20.214</td> <th>  Durbin-Watson:     </th> <td>   1.267</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  30.796</td>
</tr>
<tr>
  <th>Skew:</th>          <td> 0.179</td> <th>  Prob(JB):          </th> <td>2.05e-07</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 3.781</td> <th>  Cond. No.          </th> <td>    1.43</td>
</tr>
</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.</div>
</div>
<p>On découpe en trois.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[31]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">npr</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">X</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">X</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span>
<span class="n">X</span><span class="p">[</span><span class="n">X_</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">X</span><span class="p">[(</span><span class="n">X_</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">X_</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">),</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">X</span><span class="p">[</span><span class="n">X_</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">]</span>
<span class="n">corrcoef</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[31]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
array([[ 1.        , -0.0221138 ,  0.15312241, -0.01158589],
       [-0.0221138 ,  1.        ,  0.02182757,  0.03734989],
       [ 0.15312241,  0.02182757,  1.        ,  0.01263351],
       [-0.01158589,  0.03734989,  0.01263351,  1.        ]])
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[32]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pandas</span> <span class="kn">import</span> <span class="n">DataFrame</span>

<span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;X</span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)]</span>
<span class="n">ax</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">50</span><span class="p">,</span> <span class="p">:</span><span class="mi">3</span><span class="p">],</span> <span class="n">columns</span><span class="o">=</span><span class="n">names</span><span class="p">)</span>
    <span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">names</span><span class="p">)</span>
    <span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Représentation des features tronquées&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_dsgarden_regression_lineaire_33_0.png" src="../../_images/notebooks_dsgarden_regression_lineaire_33_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[33]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">OLS</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">4</span><span class="p">])</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">results</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[33]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>       <td>   1.000</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th>  <td>   1.000</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>           <td>3.030e+31</td>
</tr>
<tr>
  <th>Date:</th>             <td>Mon, 07 Oct 2024</td> <th>  Prob (F-statistic):</th>            <td>  0.00</td>
</tr>
<tr>
  <th>Time:</th>                 <td>11:29:06</td>     <th>  Log-Likelihood:    </th>           <td>  31722.</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>  1000</td>      <th>  AIC:               </th>          <td>-6.344e+04</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>   996</td>      <th>  BIC:               </th>          <td>-6.342e+04</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>               <td> </td>
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>               <td> </td>
</tr>
</table>
<table class="simpletable">
<tr>
   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>
</tr>
<tr>
  <th>x1</th> <td>    1.0000</td> <td> 2.07e-16</td> <td> 4.84e+15</td> <td> 0.000</td> <td>    1.000</td> <td>    1.000</td>
</tr>
<tr>
  <th>x2</th> <td>    1.0000</td> <td> 2.87e-16</td> <td> 3.49e+15</td> <td> 0.000</td> <td>    1.000</td> <td>    1.000</td>
</tr>
<tr>
  <th>x3</th> <td>    1.0000</td> <td> 2.01e-16</td> <td> 4.97e+15</td> <td> 0.000</td> <td>    1.000</td> <td>    1.000</td>
</tr>
<tr>
  <th>x4</th> <td>    1.0000</td> <td>  1.3e-16</td> <td> 7.66e+15</td> <td> 0.000</td> <td>    1.000</td> <td>    1.000</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>457.510</td> <th>  Durbin-Watson:     </th> <td>   1.879</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1715.476</td>
</tr>
<tr>
  <th>Skew:</th>          <td> 2.280</td>  <th>  Prob(JB):          </th> <td>    0.00</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 7.514</td>  <th>  Cond. No.          </th> <td>    2.20</td>
</tr>
</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.</div>
</div>
</section>
<section id="Régression-linéaire-par-morceaux">
<h2>Régression linéaire par morceaux<a class="headerlink" href="#Régression-linéaire-par-morceaux" title="Lien vers cette rubrique">#</a></h2>
<p>On se place dans un cas particulier où le problème est linéaire par morceaux :</p>
<div class="math notranslate nohighlight">
\[Y = -2 X_1 \mathbb{1}_{X_1 + \epsilon_1 &lt;0} + 4 X_1 \mathbb{1}_{X + \epsilon_1 &gt; 0} + \epsilon_2\]</div>
<p>La régression donne de très mauvais résultat sur ce type de problèmes mais on cherche une façon systématique de découper le problème en segments linéaires.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[34]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">npr</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">]</span>
<span class="n">t</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">]</span> <span class="o">*</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>
<span class="n">switch</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">switch</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">alpha</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">t</span> <span class="o">+</span> <span class="n">alpha</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">t</span><span class="p">)</span> <span class="o">+</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[35]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">Y</span><span class="p">,</span> <span class="s2">&quot;.&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Nuage de points linéaire par morceaux&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_dsgarden_regression_lineaire_37_0.png" src="../../_images/notebooks_dsgarden_regression_lineaire_37_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[36]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">OLS</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">1</span><span class="p">])</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">results</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[36]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.107</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.106</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   119.3</td>
</tr>
<tr>
  <th>Date:</th>             <td>Mon, 07 Oct 2024</td> <th>  Prob (F-statistic):</th>          <td>2.56e-26</td>
</tr>
<tr>
  <th>Time:</th>                 <td>11:29:06</td>     <th>  Log-Likelihood:    </th>          <td> -2555.7</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>  1000</td>      <th>  AIC:               </th>          <td>   5113.</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>   999</td>      <th>  BIC:               </th>          <td>   5118.</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>              <td> </td>
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>
</tr>
</table>
<table class="simpletable">
<tr>
   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>
</tr>
<tr>
  <th>x1</th> <td>    1.0940</td> <td>    0.100</td> <td>   10.924</td> <td> 0.000</td> <td>    0.897</td> <td>    1.290</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td> 3.084</td> <th>  Durbin-Watson:     </th> <td>   1.111</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.214</td> <th>  Jarque-Bera (JB):  </th> <td>   2.960</td>
</tr>
<tr>
  <th>Skew:</th>          <td> 0.088</td> <th>  Prob(JB):          </th> <td>   0.228</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 2.801</td> <th>  Cond. No.          </th> <td>    1.00</td>
</tr>
</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[37]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">yp</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[38]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">Y</span><span class="p">,</span> <span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;expected&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">yp</span><span class="p">,</span> <span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;predicted&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Régression linéaire sur un nuage linéaire par morceaux&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_dsgarden_regression_lineaire_40_0.png" src="../../_images/notebooks_dsgarden_regression_lineaire_40_0.png" />
</div>
</div>
<p>Passons à un arbre de décision qui n’est pas le meilleur modèle mais on va détourner ses résultats pour revenir à un problème de régression par morceaux.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[39]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">1</span><span class="p">],</span> <span class="n">Y</span><span class="p">)</span>
<span class="n">yp</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[40]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">Y</span><span class="p">,</span> <span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;expected&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">yp</span><span class="p">,</span> <span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;predicted&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">r2</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">1</span><span class="p">]))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Arbre de décision sur un nuage linéaire par morceaux</span><span class="se">\n</span><span class="s2">R2=</span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">r2</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_dsgarden_regression_lineaire_43_0.png" src="../../_images/notebooks_dsgarden_regression_lineaire_43_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[41]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">graphviz</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">export_graphviz</span>

<span class="n">dot</span> <span class="o">=</span> <span class="n">export_graphviz</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

<span class="n">src</span> <span class="o">=</span> <span class="n">graphviz</span><span class="o">.</span><span class="n">Source</span><span class="p">(</span><span class="n">dot</span><span class="p">)</span>
<span class="n">src</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="s2">&quot;tree_dot.gv&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[41]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&#39;tree_dot.gv.pdf&#39;
</pre></div></div>
</div>
<p>On extrait tous les seuils de l’arbre et on ajoute les milieux de segments.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[42]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">th</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">threshold</span><span class="p">)))</span>
<span class="n">th</span> <span class="o">+=</span> <span class="p">[(</span><span class="n">th</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">th</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="mi">2</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">th</span><span class="p">))]</span>
<span class="n">th</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">th</span><span class="p">))</span>
<span class="n">th</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[42]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[np.float64(-2.0),
 np.float64(-1.85539710521698),
 np.float64(-1.71079421043396),
 np.float64(-1.3022041469812393),
 np.float64(-0.8936140835285187),
 np.float64(-0.2086283266544342),
 np.float64(0.47635743021965027),
 np.float64(0.6395495533943176),
 np.float64(0.802741676568985),
 np.float64(0.942541167140007),
 np.float64(1.082340657711029),
 np.float64(1.310522198677063),
 np.float64(1.538703739643097),
 np.float64(1.6980005204677582),
 np.float64(1.8572973012924194)]
</pre></div></div>
</div>
<p>On fait une régression sur les variables <span class="math notranslate nohighlight">\(W_{i&gt;0} = X_1 \mathbb{1}_{X_1 &gt; t_i}\)</span>, <span class="math notranslate nohighlight">\(W_0 = X_1\)</span> où les <span class="math notranslate nohighlight">\((t_i)\)</span> sont les seuils.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[43]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">W</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">len</span><span class="p">(</span><span class="n">th</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">W</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">th</span><span class="p">)):</span>
    <span class="n">W</span><span class="p">[</span><span class="n">x</span> <span class="o">&gt;</span> <span class="n">th</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">x</span> <span class="o">&gt;</span> <span class="n">th</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[44]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">OLS</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">results</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[44]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.858</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.855</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   370.4</td>
</tr>
<tr>
  <th>Date:</th>             <td>Mon, 07 Oct 2024</td> <th>  Prob (F-statistic):</th>           <td>  0.00</td>
</tr>
<tr>
  <th>Time:</th>                 <td>11:29:07</td>     <th>  Log-Likelihood:    </th>          <td> -1637.5</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>  1000</td>      <th>  AIC:               </th>          <td>   3307.</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>   984</td>      <th>  BIC:               </th>          <td>   3385.</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>    16</td>      <th>                     </th>              <td> </td>
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>
</tr>
</table>
<table class="simpletable">
<tr>
   <td></td>      <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>
</tr>
<tr>
  <th>x1</th>  <td>   -1.8183</td> <td>    0.119</td> <td>  -15.303</td> <td> 0.000</td> <td>   -2.051</td> <td>   -1.585</td>
</tr>
<tr>
  <th>x2</th>  <td>   -0.4155</td> <td>    0.260</td> <td>   -1.600</td> <td> 0.110</td> <td>   -0.925</td> <td>    0.094</td>
</tr>
<tr>
  <th>x3</th>  <td>    0.2157</td> <td>    0.320</td> <td>    0.673</td> <td> 0.501</td> <td>   -0.413</td> <td>    0.845</td>
</tr>
<tr>
  <th>x4</th>  <td>    0.1368</td> <td>    0.247</td> <td>    0.553</td> <td> 0.581</td> <td>   -0.349</td> <td>    0.622</td>
</tr>
<tr>
  <th>x5</th>  <td>   -0.2634</td> <td>    0.166</td> <td>   -1.589</td> <td> 0.112</td> <td>   -0.589</td> <td>    0.062</td>
</tr>
<tr>
  <th>x6</th>  <td>    1.0105</td> <td>    0.196</td> <td>    5.164</td> <td> 0.000</td> <td>    0.627</td> <td>    1.395</td>
</tr>
<tr>
  <th>x7</th>  <td>    3.3282</td> <td>    0.356</td> <td>    9.357</td> <td> 0.000</td> <td>    2.630</td> <td>    4.026</td>
</tr>
<tr>
  <th>x8</th>  <td>    1.3866</td> <td>    0.454</td> <td>    3.051</td> <td> 0.002</td> <td>    0.495</td> <td>    2.278</td>
</tr>
<tr>
  <th>x9</th>  <td>    0.3655</td> <td>    0.403</td> <td>    0.907</td> <td> 0.365</td> <td>   -0.425</td> <td>    1.156</td>
</tr>
<tr>
  <th>x10</th> <td>    0.1177</td> <td>    0.334</td> <td>    0.353</td> <td> 0.724</td> <td>   -0.537</td> <td>    0.773</td>
</tr>
<tr>
  <th>x11</th> <td>   -0.3147</td> <td>    0.307</td> <td>   -1.023</td> <td> 0.306</td> <td>   -0.918</td> <td>    0.289</td>
</tr>
<tr>
  <th>x12</th> <td>    0.2972</td> <td>    0.255</td> <td>    1.166</td> <td> 0.244</td> <td>   -0.203</td> <td>    0.797</td>
</tr>
<tr>
  <th>x13</th> <td>   -0.0456</td> <td>    0.197</td> <td>   -0.231</td> <td> 0.817</td> <td>   -0.433</td> <td>    0.342</td>
</tr>
<tr>
  <th>x14</th> <td>    0.2807</td> <td>    0.252</td> <td>    1.112</td> <td> 0.266</td> <td>   -0.215</td> <td>    0.776</td>
</tr>
<tr>
  <th>x15</th> <td>   -0.3102</td> <td>    0.303</td> <td>   -1.024</td> <td> 0.306</td> <td>   -0.904</td> <td>    0.284</td>
</tr>
<tr>
  <th>x16</th> <td>   -0.0231</td> <td>    0.237</td> <td>   -0.097</td> <td> 0.923</td> <td>   -0.489</td> <td>    0.443</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>207.506</td> <th>  Durbin-Watson:     </th> <td>   1.993</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 673.510</td>
</tr>
<tr>
  <th>Skew:</th>          <td>-0.999</td>  <th>  Prob(JB):          </th> <td>5.61e-147</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 6.489</td>  <th>  Cond. No.          </th> <td>    37.1</td>
</tr>
</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.</div>
</div>
<p>Dessinons les résultats de la prédictions.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[45]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">yp</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">W</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">Y</span><span class="p">,</span> <span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;expected&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">yp</span><span class="p">,</span> <span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;predicted&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span>
    <span class="s2">&quot;Régression linéaire par morceaux</span><span class="se">\n</span><span class="s2">sur un nuage linéaire par morceaux</span><span class="se">\n</span><span class="s2">R2=</span><span class="si">%f</span><span class="s2">&quot;</span>
    <span class="o">%</span> <span class="n">results</span><span class="o">.</span><span class="n">rsquared</span>
<span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_dsgarden_regression_lineaire_51_0.png" src="../../_images/notebooks_dsgarden_regression_lineaire_51_0.png" />
</div>
</div>
<p>Le modèle nous suggère de ne garder que quelques seuils. En s’appuyant sur les p-values :</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[46]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">keep</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">pvalues</span><span class="p">))[</span><span class="n">results</span><span class="o">.</span><span class="n">pvalues</span> <span class="o">&lt;</span> <span class="mf">0.05</span><span class="p">]</span>
<span class="n">keep</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[46]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
array([0, 5, 6, 7])
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[47]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">W2</span> <span class="o">=</span> <span class="n">W</span><span class="p">[:,</span> <span class="n">keep</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[48]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">OLS</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">W2</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">results</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[48]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.856</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.855</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   1481.</td>
</tr>
<tr>
  <th>Date:</th>             <td>Mon, 07 Oct 2024</td> <th>  Prob (F-statistic):</th>           <td>  0.00</td>
</tr>
<tr>
  <th>Time:</th>                 <td>11:29:08</td>     <th>  Log-Likelihood:    </th>          <td> -1642.9</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>  1000</td>      <th>  AIC:               </th>          <td>   3294.</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>   996</td>      <th>  BIC:               </th>          <td>   3314.</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>              <td> </td>
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>
</tr>
</table>
<table class="simpletable">
<tr>
   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>
</tr>
<tr>
  <th>x1</th> <td>   -1.9657</td> <td>    0.062</td> <td>  -31.604</td> <td> 0.000</td> <td>   -2.088</td> <td>   -1.844</td>
</tr>
<tr>
  <th>x2</th> <td>    0.8316</td> <td>    0.163</td> <td>    5.106</td> <td> 0.000</td> <td>    0.512</td> <td>    1.151</td>
</tr>
<tr>
  <th>x3</th> <td>    3.3282</td> <td>    0.355</td> <td>    9.363</td> <td> 0.000</td> <td>    2.631</td> <td>    4.026</td>
</tr>
<tr>
  <th>x4</th> <td>    1.7842</td> <td>    0.327</td> <td>    5.455</td> <td> 0.000</td> <td>    1.142</td> <td>    2.426</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>225.520</td> <th>  Durbin-Watson:     </th> <td>   2.011</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 775.424</td>
</tr>
<tr>
  <th>Skew:</th>          <td>-1.066</td>  <th>  Prob(JB):          </th> <td>4.16e-169</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 6.750</td>  <th>  Cond. No.          </th> <td>    17.4</td>
</tr>
</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[49]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">yp</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">W2</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">Y</span><span class="p">,</span> <span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;expected&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">yp</span><span class="p">,</span> <span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;predicted&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span>
    <span class="s2">&quot;Régression linéaire par morceaux</span><span class="se">\n</span><span class="s2">sur un nuage linéaire par morceaux</span><span class="se">\n</span><span class="s2">&quot;</span>
    <span class="o">+</span> <span class="s2">&quot;réduction du nombre de segments</span><span class="se">\n</span><span class="s2">R2=</span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">results</span><span class="o">.</span><span class="n">rsquared</span>
<span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_dsgarden_regression_lineaire_56_0.png" src="../../_images/notebooks_dsgarden_regression_lineaire_56_0.png" />
</div>
</div>
<p>Le coefficient <span class="math notranslate nohighlight">\(R^2\)</span> est quasiment identique pour un nombre de segments moindre. Je me suis amusé à rendre ce code plus générique pour comparer la première étape, le découpage en morceaux, via deux modèles, un arbre de décision et le nouvel objet <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.KBinsDiscretizer.html">KBinsDiscretizer</a> qui segmente une variable sans tenir compte de la cible. La régression n’est plus nécessaire linéaire : <a class="reference external" href="https://sdpython.github.io/doc/mlinsights/dev/auto_examples/plot_piecewise_linear_regression.html">Piecewise linear
regression</a>. Je me suis également amusé à faire de même pour une classification par morceaux <a class="reference external" href="https://sdpython.github.io/doc/mlinsights/dev/api/mlmodel.html#piecewiseclassifier">PiecewiseClassifier</a>. Celle-ci pose quelques soucis pratiques car toutes les classes ne sont pas forcément représentées dans chaque compartiment…</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[41]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</section>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../../c_ml/index_reg_lin.html"
       title="page précédente">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">précédent</p>
        <p class="prev-next-title">Régression linéaire</p>
      </div>
    </a>
    <a class="right-next"
       href="../../c_ml/regression_quantile.html"
       title="page suivante">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">suivant</p>
        <p class="prev-next-title">Régression quantile ou régression L1</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Sur cette page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Un-cas-simple">Un cas simple</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Evolution-de-R2">Evolution de R2</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Deux-variables-corrélées">Deux variables corrélées</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Indicatrices">Indicatrices</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Régression-linéaire-par-morceaux">Régression linéaire par morceaux</a></li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">

  <div class="tocsection sourcelink">
    <a href="../../_sources/notebooks/dsgarden/regression_lineaire.ipynb">
      <i class="fa-solid fa-file-lines"></i> Montrer le code source
    </a>
  </div>
</div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2016-2024, Xavier Dupré.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Créé en utilisant <a href="https://www.sphinx-doc.org/">Sphinx</a> 8.0.2.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  Construit avec le <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">Thème PyData Sphinx</a> 0.15.4.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>