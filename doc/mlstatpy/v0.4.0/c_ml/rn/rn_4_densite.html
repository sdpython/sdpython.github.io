
<!DOCTYPE html>


<html lang="fr" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Démonstration du théorème de la densité des réseaux de neurones &#8212; Documentation mlstatpy 0.4.0</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css?v=eafc0fe6" />
    <link rel="stylesheet" type="text/css" href="../../_static/plot_directive.css?v=7f9a90b1" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css?v=61a4c737" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js?v=72ff47bc"></script>
    <script src="../../_static/doctools.js?v=888ff710"></script>
    <script src="../../_static/sphinx_highlight.js?v=4825356b"></script>
    <script src="../../_static/translations.js?v=d99ca74e"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'c_ml/rn/rn_4_densite';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Recherche" href="../../search.html" />
    <link rel="next" title="Descente de gradient" href="rn_5_newton.html" />
    <link rel="prev" title="La classification" href="rn_3_clas.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="fr"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Passer au contenu principal</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
<div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
    <span class="fa-solid fa-bars"></span>
  </label>
  
  <div class="navbar-header-items__start">
    
      <div class="navbar-item">
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
    
    
      
    
    
    <img src="../../_static/project_ico.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../../_static/project_ico.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
    
  </div>
  
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item"><nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Navigation du site">
    Navigation du site
  </p>
  <ul class="bd-navbar-elements navbar-nav">
    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../c_clus/index.html">
                        Clustering
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="../index.html">
                        Non linéaire
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../index_reg_lin.html">
                        Régression linéaire
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../index_reg_log.html">
                        Régression logistique
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../c_nlp/index.html">
                        NLP
                      </a>
                    </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../c_metric/index.html">
                        Métriques
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../c_algo/index.html">
                        Algorithmes
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../c_garden/index.html">
                        Pérégrinations
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../api/index.html">
                        API
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../i_ex.html">
                        Examples
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../defthe_index.html">
                        Listes des définitions et théorèmes
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../auto_examples/index.html">
                        Gallery of examples
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../notebooks/index.html">
                        Galleries de notebooks
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../glossary.html">
                        Glossary
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../CHANGELOGS.html">
                        Change Logs
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../license.html">
                        License
                      </a>
                    </li>
                
                </div>
            </div>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          
<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Recherche" aria-label="Recherche" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
        </div>
      
      
        <div class="navbar-item">
<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="clair/sombre" aria-label="clair/sombre" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">
<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Recherche" aria-label="Recherche" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
    </div>
  

  
    <label class="sidebar-toggle secondary-toggle" for="__secondary">
      <span class="fa-solid fa-outdent"></span>
    </label>
  
</div>

    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          <div class="navbar-item"><nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Navigation du site">
    Navigation du site
  </p>
  <ul class="bd-navbar-elements navbar-nav">
    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../c_clus/index.html">
                        Clustering
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="../index.html">
                        Non linéaire
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../index_reg_lin.html">
                        Régression linéaire
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../index_reg_log.html">
                        Régression logistique
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../c_nlp/index.html">
                        NLP
                      </a>
                    </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../c_metric/index.html">
                        Métriques
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../c_algo/index.html">
                        Algorithmes
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../c_garden/index.html">
                        Pérégrinations
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../api/index.html">
                        API
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../i_ex.html">
                        Examples
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../defthe_index.html">
                        Listes des définitions et théorèmes
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../auto_examples/index.html">
                        Gallery of examples
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../notebooks/index.html">
                        Galleries de notebooks
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../glossary.html">
                        Glossary
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../CHANGELOGS.html">
                        Change Logs
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../license.html">
                        License
                      </a>
                    </li>
                
                </div>
            </div>
            
  </ul>
</nav></div>
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="clair/sombre" aria-label="clair/sombre" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item"><nav class="bd-docs-nav bd-links"
     aria-label="Navigation de la section">
  <p class="bd-links__title" role="heading" aria-level="1">Navigation de la section</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="rn.html">Réseaux de neurones</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="rn_1_def.html">Définition des réseaux de neurones multi-couches</a></li>
<li class="toctree-l2"><a class="reference internal" href="rn_2_reg.html">La régression</a></li>
<li class="toctree-l2"><a class="reference internal" href="rn_3_clas.html">La classification</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Démonstration du théorème de la densité des réseaux de neurones</a></li>
<li class="toctree-l2"><a class="reference internal" href="rn_5_newton.html">Descente de gradient</a></li>
<li class="toctree-l2"><a class="reference internal" href="rn_6_apprentissage.html">Apprentissage d’un réseau de neurones</a></li>
<li class="toctree-l2"><a class="reference internal" href="rn_7_clas2.html">Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="rn_8_prol.html">Prolongements</a></li>
<li class="toctree-l2"><a class="reference internal" href="rn_9_auto.html">Analyse en composantes principales (ACP) et Auto Encoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="rn_biblio.html">Bibliographie</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../kppv.html">Classification à l’aide des plus proches voisins</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../missing_values_mf.html">Liens entre factorisation de matrices, ACP, k-means</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/ml/mf_acp.html">Factorisation et matrice et ACP</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/ml/valeurs_manquantes_mf.html">Valeurs manquantes et factorisation de matrices</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/ml/neural_tree.html">Un arbre de décision en réseaux de neurones</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/ml/neural_tree_onnx.html">NeuralTreeNet et ONNX</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/ml/neural_tree_cost.html">NeuralTreeNet et coût</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Fils d'Ariane">
  <ul class="bd-breadcrumbs" role="navigation" aria-label="Fil d'Ariane">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../index.html" class="nav-link" aria-label="Acceuil">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../index.html" class="nav-link">Non linéaire</a></li>
    
    
    <li class="breadcrumb-item"><a href="rn.html" class="nav-link">Réseaux de neurones</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">Démonstration du théorème de la densité des réseaux de neurones</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section id="demonstration-du-theoreme-de-la-densite-des-reseaux-de-neurones">
<h1>Démonstration du théorème de la densité des réseaux de neurones<a class="headerlink" href="#demonstration-du-theoreme-de-la-densite-des-reseaux-de-neurones" title="Lien permanent vers cette rubrique">#</a></h1>
<nav class="contents local" id="sommaire">
<ul class="simple">
<li><p><a class="reference internal" href="#formulation-du-probleme-de-la-regression" id="id6">Formulation du problème de la régression</a></p></li>
<li><p><a class="reference internal" href="#densite-des-reseaux-de-neurones" id="id7">Densité des réseaux de neurones</a></p></li>
</ul>
</nav>
<section id="formulation-du-probleme-de-la-regression">
<span id="rn-enonce-probleme-regression"></span><h2><a class="toc-backref" href="#id6" role="doc-backlink">Formulation du problème de la régression</a><a class="headerlink" href="#formulation-du-probleme-de-la-regression" title="Lien permanent vers cette rubrique">#</a></h2>
<p>Soient deux variables aléatoires continues
<img class="math" src="../../_images/math/adcf9a2d5847a0d969b582f72e01e080f95a81eb.svg" alt="\pa{X,Y} \in \R^p \times \R^q \sim \loi"/> quelconque,
la résolution du problème de <a class="reference internal" href="rn_2_reg.html#problem-regression"><span class="std std-ref">régression</span></a>
est l’estimation de la fonction <img class="math" src="../../_images/math/ecfd65eaf18107c11633ac1ffe793c6dbb4da3c9.svg" alt="\esp(Y|X) = F\pa{X}"/>.
Pour cela, on dispose d’un ensemble de points
<img class="math" src="../../_images/math/8415bc0f820e9cd2cebce34c47fc20f974dc7058.svg" alt="A = \acc{ \pa{X_{i},Y_{i}} \sim \loi | 1 \infegal i \infegal N }"/>.</p>
<p>Soit <img class="math" src="../../_images/math/8dc7d6327ec0947f3ca14e4208ded3481569e617.svg" alt="f : \R^M \times \R^p \longrightarrow \R^q"/> une fonction, on définit
<img class="math" src="../../_images/math/5edd29e696bf705c4d2e0261c4670f53b7ff1b0e.svg" alt="\forall i \in \intervalle{1}{N}, \; \widehat{Y_{i}^{W}} = f \pa{W,X_{i}}"/>.
On appelle aussi <img class="math" src="../../_images/math/6c082bb0e47bb9812b6ec121f80351fad38422a7.svg" alt="\widehat{Y_{i}^{W}}"/> la valeur prédite pour <img class="math" src="../../_images/math/fb12421c4f381279c9b53208a2cb00559ed767f1.svg" alt="X_{i}"/>.
On pose alors
<img class="math" src="../../_images/math/472c3ba671aeb8b43a4daeac50a737255426ee18.svg" alt="\epsilon_{i}^{W} = Y_{i} -  \widehat{Y_{i}^{W}} = Y_{i} - f \pa{W,X_{i}}"/>.</p>
<p>Les résidus sont supposés
<a class="reference external" href="https://fr.wikipedia.org/wiki/Variables_ind%C3%A9pendantes_et_identiquement_distribu%C3%A9es">i.i.d. (identiquement et indépendemment distribués)</a>,
et suivant une loi normale
<img class="math" src="../../_images/math/f67f501ac5984ccecffb05b94b4c0552d47eb5e7.svg" alt="\forall i \in \intervalle{1}{N}, \; \epsilon_{i}^{W} \sim \loinormale{\mu_{W}}{\sigma_{W}}"/>
La vraisemblance d’un échantillon
<img class="math" src="../../_images/math/1e08e3ab42a7c052a38942811b556fdc38307a4e.svg" alt="\pa{Z_i}_{1\infegal i \infegal N}"/>,
où les <img class="math" src="../../_images/math/f17e8c265d7e0200ae83cb0ab155527cc9338d22.svg" alt="Z_i"/> sont indépendantes entre elles et suivent la loi de densité
<img class="math" src="../../_images/math/1bbb007ad626c1f9adbd0dc838ab93f44e068f0b.svg" alt="f \pa{z | \theta}"/>
est la densité du vecteur <img class="math" src="../../_images/math/3994db625c8f8578da33308b3942386cc69cbae4.svg" alt="\vecteur{Z_1}{Z_N}"/> qu’on exprime
comme suit :</p>
<div class="math">
<p><img src="../../_images/math/c74d923fc3261f39b8b30e31706659abbc6cb2b4.svg" alt="\begin{array}{rrcl}
                &amp;L\pa{\theta, \vecteurno{Z_1}{Z_N}} &amp; =&amp; \prod_{n=1}^{N} f\pa{Z_i | \theta} \\
\Longrightarrow&amp;
\ln L\pa{\theta, \vecteurno{Z_1}{Z_N}} &amp;=&amp; \sum_{n=1}^{N} \ln f\pa{Z_i | \theta}
\end{array}"/></p>
</div><p>La log-vraisemblance de l’échantillon s’écrit
<img class="math" src="../../_images/math/65425345f2bcc61becef1c75a5907311d4621b5b.svg" alt="L_{W} = -\frac{1}{2\sigma_{W}^2} \sum_{i=1}^{N}
\pa{Y_{i} - \widehat{Y_{i}^W} - \mu_{W} }^2 + N\ln\pa{\sigma_{W}\sqrt{2\pi}}"/>.
Les estimateurs du maximum de vraisemblance
pour <img class="math" src="../../_images/math/6fbff0a1556930f1faabc4efd7d7d3b42b8c2a4e.svg" alt="\mu_W"/> et <img class="math" src="../../_images/math/10b2ddea6d861305d323b665a1394559a31aa639.svg" alt="\sigma_W"/> sont (voir <a class="reference internal" href="../../c_metric/roc.html#saporta1990" id="id1"><span>[Saporta1990]</span></a>) :</p>
<div class="math">
<p><img src="../../_images/math/c177c52a8e93943c83a5d763a9c85f5fe1d4fde8.svg" alt="\begin{array}{rcl}
\widehat{\mu_{W}}     &amp;=&amp;     \frac{1}{N} \sum_{i=1}^{N} Y_{i} - \widehat{Y_{i}^W} \\
\widehat{\sigma_{W}}  &amp;=&amp;     \sqrt{ \frac{ \sum_{i=1}^{N} \pa{Y_{i} -
                              \widehat{Y_{i}^W} - \mu_{W}}^2}{N}}
\end{array}"/></p>
</div><p>L’estimateur de <img class="math" src="../../_images/math/3d0704f182700b605d780207c1b0d9048ead9048.svg" alt="\widehat{Y}=f\pa{W,X}"/> désirée est de préférence
sans biais (<img class="math" src="../../_images/math/235971c901af52fd5e54ba16177d01cc4ee7653f.svg" alt="\mu_W = 0"/>) et de variance minimum,
par conséquent, les paramètres <img class="math" src="../../_images/math/f643d150644d5f0e344555776f04cdf8c713f7df.svg" alt="\overset{*}{W}"/>
qui maximisent la vraisemblance <img class="math" src="../../_images/math/8d6fb494bfed2c24f97534c703d6389dbc9fff38.svg" alt="L_W"/> sont :</p>
<div class="math" id="equation-rn-eqn-regression-1">
<p><span class="eqno">(1)<a class="headerlink" href="#equation-rn-eqn-regression-1" title="Lien permanent vers cette équation">#</a></span><img src="../../_images/math/4a6ad86bd529fa6941128814a952799852db7242.svg" alt="\begin{array}{rcl}
\overset{*}{W}   &amp;=&amp; \underset{W \in \R^M}{\arg \min} \sum_{i=1}^{N}
                                        \pa {Y_{i} - \widehat{Y_{i}^W}}^2 \\
                 &amp;=&amp; \underset{W \in \R^M}{\arg \min} \sum_{i=1}^{N}
                        \pa {Y_{i} - f \pa{W,X_{i}}}^2
\end{array}"/></p>
</div><p>Réciproquement, on vérifie que si <img class="math" src="../../_images/math/4d4f4910fb33f542260bd4f5593ffb800c330e49.svg" alt="W^*"/> vérifie
l’équation <a class="reference internal" href="#equation-rn-eqn-regression-1">(1)</a> alors l’estimateur défini par
<img class="math" src="../../_images/math/bd1e0600a66dbe0f8deddbd57953774419ba4e4f.svg" alt="f"/> est sans biais
Il suffit pour s’en convaincre de poser
<img class="math" src="../../_images/math/7363edc6324fe342c166fdd2720834f0c7ac9340.svg" alt="g = f + \alpha"/> avec
<img class="math" src="../../_images/math/7a051ee83c9f9cf646e55a4d9c4f0a649f2e480a.svg" alt="\alpha \in \R"/> et de vérifier que la valeur optimale pour
<img class="math" src="../../_images/math/a1e7b66a55fc77cebd91d9a1ebfa93a29c1736fb.svg" alt="\alpha"/> est
<img class="math" src="../../_images/math/afe3aad371fc4500c02697587aa9162a2859a826.svg" alt="\alpha = - \frac{1}{N}\, \sum_{i=1}^{N} \, \left. Y_i - f\pa{W,X_i} \right."/>.
L’estimateur minimise la vraisemblance <img class="math" src="../../_images/math/8d6fb494bfed2c24f97534c703d6389dbc9fff38.svg" alt="L_W"/>.
Cette formule peut être généralisée en faisant une autre hypothèse
que celle de la normalité des résidus (l’indépendance étant conservée),
l’équation <a class="reference internal" href="#equation-rn-eqn-regression-1">(1)</a>
peut généralisée par <a class="reference internal" href="#equation-rn-eqn-regression-2">(2)</a>.</p>
<div class="math" id="equation-rn-eqn-regression-2">
<p><span class="eqno">(2)<a class="headerlink" href="#equation-rn-eqn-regression-2" title="Lien permanent vers cette équation">#</a></span><img src="../../_images/math/16c71f5f78a04b7a0009f0cb3bbae1dcc9ea1952.svg" alt="\begin{array}{rcl}
\overset{*}{W}     &amp;=&amp; \underset{W \in \R^M}{\arg \min} \sum_{i=1}^{N}
                                                        e\pa {Y_{i} - \widehat{Y_{i}^W}} \\
                    &amp;=&amp; \underset{W \in \R^M}{\arg \min} \sum_{i=1}^{N}
                            e\pa{Y_{i} - f \pa{W,X_{i}}}
\end{array}"/></p>
</div><p>Où la fonction <img class="math" src="../../_images/math/bb641cfe134c9a50d5b127cb44726bee024a712f.svg" alt="e : \R^q \in \R"/> est appelée fonction d’erreur.</p>
</section>
<section id="densite-des-reseaux-de-neurones">
<h2><a class="toc-backref" href="#id7" role="doc-backlink">Densité des réseaux de neurones</a><a class="headerlink" href="#densite-des-reseaux-de-neurones" title="Lien permanent vers cette rubrique">#</a></h2>
<p>L’utilisation de réseaux de neurones s’est considérablement
développée depuis que l’algorithme de rétropropagation a
été trouvé (<a class="reference internal" href="rn_biblio.html#lecun1985" id="id2"><span>[LeCun1985]</span></a>, <a class="reference internal" href="rn_biblio.html#rumelhart1986" id="id3"><span>[Rumelhart1986]</span></a>, <a class="reference internal" href="rn_biblio.html#bishop1995" id="id4"><span>[Bishop1995]</span></a>).
Ce dernier permet d’estimer la dérivée d’un réseau de neurones en
un point donné et a ouvert la voie à des méthodes classiques
de résolution pour des problèmes d’optimisation tels que la régression non linéaire.</p>
<p>Comme l’ensemble des fonctions polynômiales,
l’ensemble des fonctions engendrées par des réseaux de neurones
multi-couches possède des propriétés de <a class="reference internal" href="#theoreme-densite"><span class="std std-ref">densité</span></a>
et sont infiniment dérivables. Les réseaux de neurones comme
les polynômes sont utilisés pour modéliser la fonction
<img class="math" src="../../_images/math/bd1e0600a66dbe0f8deddbd57953774419ba4e4f.svg" alt="f"/> de l’équation <a class="reference internal" href="#equation-rn-eqn-regression-2">(2)</a>.
Ils diffèrent néanmoins sur certains points</p>
<p>Si une couche ne contient que des fonctions de transfert bornées
comme la fonction sigmoïde, tout réseau de neurones incluant cette couche
sera aussi borné. D’un point de vue informatique, il est
préférable d’effectuer des calculs avec des valeurs du même
ordre de grandeur. Pour un polynôme, les valeurs des termes de
degré élevé peuvent être largement supérieurs à leur somme.</p>
<p>Un autre attrait est la symétrie dans l’architecture d’un réseau
de neurones, les neurones qui le composent jouent des rôles
symétriques (corollaire <a class="reference internal" href="#corollaire-famille-libre"><span class="std std-ref">familles libres</span></a>.
Pour améliorer l’approximation d’une fonction, dans un cas,
il suffit d’ajouter un neurone au réseau, dans l’autre,
il faut inclure des polynômes de degré plus élevé que ceux déjà  employés.</p>
<div class="admonition-mathdef admonition" id="indexmathe-Théorème0">
<div class="docutils container">
</div>
<p class="admonition-title" id="theoreme-densite">Théorème T1 : densité des réseaux de neurones (Cybenko1989)</p>
<p><a class="reference internal" href="rn_biblio.html#cybenko1989" id="id5"><span>[Cybenko1989]</span></a>
Soit <img class="math" src="../../_images/math/166322259d8d974ece7902b461c1bf3d15a96cc6.svg" alt="E_{p}^{q}"/> l’espace des réseaux de neurones à
<img class="math" src="../../_images/math/6fe7973e241cac84eec5598231dc7f6e68e88282.svg" alt="p"/> entrées et <img class="math" src="../../_images/math/53e75bcd7eafea2c0896729a913b09b70e220d12.svg" alt="q"/> sorties, possédant une couche cachée dont la
fonction de seuil est une fonction sigmoïde
<img class="math" src="../../_images/math/cfc879a334e0bdb6c27e609b16da5e5bd99629c6.svg" alt="\left(  x\rightarrow 1-\frac{2}{1+e^{x}}\right)"/>,
une couche de sortie dont la fonction de seuil est linéaire
Soit <img class="math" src="../../_images/math/c1274df568c53289e39e0881babfedfde2591e9d.svg" alt="F_{p}^{q}"/> l’ensemble des fonctions continues de
<img class="math" src="../../_images/math/af45f568cad8a4ce5cd14dc88174305ed958b23f.svg" alt="C\subset\R^{p}\longrightarrow\R^{q}"/> avec <img class="math" src="../../_images/math/2c0e77bc741b692ecdf6e85966263a89422af4c8.svg" alt="C"/>
compact muni de la norme
<img class="math" src="../../_images/math/89d5ff3f5f71076c7fa1b65b745470e495c966b3.svg" alt="\left\| f\right\| =\underset{x\in C}{\sup}\left\|  f\left( x\right)  \right\|"/>
Alors <img class="math" src="../../_images/math/166322259d8d974ece7902b461c1bf3d15a96cc6.svg" alt="E_{p}^{q}"/> est dense dans <img class="math" src="../../_images/math/c1274df568c53289e39e0881babfedfde2591e9d.svg" alt="F_{p}^{q}"/>.</p>
</div>
<p>La démonstration de ce théorème nécessite deux lemmes.
Ceux-ci utilisent la définition usuelle du produit scalaire
sur <img class="math" src="../../_images/math/22df7dfe54ba00a8469b0e962f822a541c85c3d8.svg" alt="\R^p"/> défini par
<img class="math" src="../../_images/math/dc3d9f79207eefdbf7551d1ba0ac3dcbb99a395c.svg" alt="\pa{x,y} = \pa{\vecteurno{x_1}{x_p},\vecteurno{y_1}{y_p}} \in \R^{2p} \longrightarrow
\left\langle x,y \right\rangle = \sum_{i=1}^{p} x_i y_i"/>.
et la norme infinie :
<img class="math" src="../../_images/math/cb934d1f33744c851ee41dfbe43caf507ea0e472.svg" alt="x = \vecteur{x_1}{x_p} \in \R^p \longrightarrow \norm{x} =
\underset{i \in \intervalle{1}{p}}{\max} x_i"/>.
Toutes les normes sont
<a class="reference external" href="https://fr.wikipedia.org/wiki/Norme_%C3%A9quivalente">équivalentes</a>
sur <img class="math" src="../../_images/math/22df7dfe54ba00a8469b0e962f822a541c85c3d8.svg" alt="\R^p"/>.</p>
<div class="admonition-mathdef admonition" id="indexmathe-Corollaire0">
<div class="docutils container">
</div>
<p class="admonition-title" id="theoreme-densite-lemme-a">Corollaire C1 : approximation d’une fonction créneau</p>
<p>Soit <img class="math" src="../../_images/math/67373ec132d1cb3812060c261e2d7fede7cd2bf4.svg" alt="C \subset \R^p, \; C= \acc { \vecteur{y_1}{y_p} \in \R^p \, | \forall i\in \intervalle{1}{p},\, 0 \leqslant y_{i}\leqslant 1   }"/>,
alors :</p>
<div class="math">
<p><img src="../../_images/math/81b046a7c16f8c6e2ee3affefaa37255894b6fdf.svg" alt="\begin{array}{l}
\forall \varepsilon &gt; 0, \; \forall \alpha&gt;0, \; \exists n \in \N^*, \;
            \exists \vecteur{x_1}{x_n}
            \in\left(  \R^p\right)  ^{n}, \; \exists
    \vecteur{\gamma_1}{\gamma_n} \in \R^n  \text{ tels que } \forall x\in \R^p, \\ \\
\begin{array}{ll}
&amp;   \left| \underset{i=1}{\overset{n}{\sum}}\dfrac{\gamma_i}
                {1+e^{\left\langle x_{i},x\right\rangle +b_{i}}}-\indicatrice{x\in C
    }\right| \leqslant1 \\ \\
\text{ et } &amp;   \underset{y\in Fr\left( C\right)  }{\inf }\left\| x-y\right\| &gt;
                \alpha\Rightarrow\left| \underset{i=1}{\overset
    {n}{\sum}}\dfrac{\gamma_i}{1+e^{\left\langle x_{i},x\right\rangle +b_{i}}}
            -\indicatrice{x\in C}\right| \leqslant\varepsilon
\end{array}
\end{array}"/></p>
</div></div>
<p><strong>Démonstration du corollaire</strong></p>
<p><em>Partie 1</em></p>
<p>Soit <img class="math" src="../../_images/math/777afd6041e6d265ef21483c121300e1c7aa565a.svg" alt="h"/> la fonction définie par :
<img class="math" src="../../_images/math/4e0fcbd48ddc90093f6c65d965d4fbb49e7fec48.svg" alt="h\pa{x} = \pa{\dfrac{1}{1+e^{-kx}}}^p"/>
avec <img class="math" src="../../_images/math/edd1af8ae1d4ee71bd631ab5bfb5c03ecea2412b.svg" alt="p&gt;0"/> et <img class="math" src="../../_images/math/93828e26e50bfc2c5777fccd4fe84d772a9c7a91.svg" alt="0 &lt; \epsilon &lt; 1"/>.
A <img class="math" src="../../_images/math/a1e7b66a55fc77cebd91d9a1ebfa93a29c1736fb.svg" alt="\alpha"/>, <img class="math" src="../../_images/math/5d07e66e6e9d55b1dd504ca14a3d870dfe30fb29.svg" alt="\epsilon"/> fixé, <img class="math" src="../../_images/math/93828e26e50bfc2c5777fccd4fe84d772a9c7a91.svg" alt="0 &lt; \epsilon &lt; 1"/>,
on cherche <img class="math" src="../../_images/math/312028c07e271534bd0dbde5434e49e76880744f.svg" alt="k"/> tel que :</p>
<div class="math">
<p><img src="../../_images/math/e681722819d3286eee928b5b5606139c64aa771c.svg" alt="\begin{array}{crcl}
                &amp;   \epsilon                    &amp;=&amp; h\pa{\alpha} = \pa{\dfrac{1}{1+e^{-k\alpha}}}^p \\
\Longrightarrow &amp;   \epsilon^{-\frac{1}{p}}               &amp;=&amp; 1+e^{-k\alpha} \\
\Longrightarrow &amp;   \epsilon^{-\frac{1}{p}} -1            &amp;=&amp; e^{-k\alpha} \\
\Longrightarrow &amp;   \ln \pa{\epsilon^{-\frac{1}{p}} -1}   &amp;=&amp; -k\alpha \\
\Longrightarrow &amp;   k                           &amp;=&amp; - \dfrac{ \ln\pa{\epsilon^{-\frac{1}{p}} -1}}{\alpha} =
                                                        k_0\pa{\epsilon,\alpha,p}
\end{array}"/></p>
</div><p><em>Partie 2</em></p>
<p>Soit <img class="math" src="../../_images/math/bd41a2e78e74e917477a39b1a385cc47fa1c94a2.svg" alt="\alpha&gt;0"/> et <img class="math" src="../../_images/math/030dd8dbbfdfdb1e6238484a36d5847538222529.svg" alt="1\geqslant\varepsilon&gt;0, \, k&gt;0"/>,</p>
<p>On pose <img class="math" src="../../_images/math/f37f95f78ccc5c54757fb6704385d9bc9033da5f.svg" alt="f\left(  y_{1},...,y_{p}\right)  =\underset{i=1}{\overset{p}{\prod}}
\dfrac{1}{1+e^{-ky_{i}}}\underset{i=1}{\overset{p}{\prod}}\dfrac {1}{1+e^{-k\left(  1-y_{i}\right)}}"/>
d’après sa définition, <img class="math" src="../../_images/math/edc4f813a298b509469fc552b5f837f6fcfa28dc.svg" alt="0 \infegal f\left(  y_{1},...,y_{p}\right)  \infegal 1"/>.</p>
<p>Pour <img class="math" src="../../_images/math/800054f05eea2dd5fbf17c2eb5ecc5534f01d3b3.svg" alt="k \supegal k_0 \pa{\epsilon,\alpha,2p}"/>
obtenu dans la partie précédente :</p>
<div class="math">
<p><img src="../../_images/math/8f7e0be3be492c7e15f50aa71c3bd390637a78c8.svg" alt="\underset{_{i\in\left\{ 1,...,p\right\}}}{\inf}
\cro { \min\left\{  \left|  y_{i}\right|  ,\left|  1-y_{i}\right|  \right\} } &gt;\alpha
\Longrightarrow\left\|  f\left(  y_{1},...,y_{p}\right) - \indicatrice{x\in C}\right\|  \infegal\varepsilon"/></p>
</div><p><em>Partie 3</em></p>
<p>Soit <img class="math" src="../../_images/math/3a8d8bad8d0f9dcf76fdcc134f09a2a698f2d77f.svg" alt="g"/> la fonction définie par :</p>
<div class="math">
<p><img src="../../_images/math/b005afca1829951c184fdfd9caebe1876dc437f0.svg" alt="\begin{array}{rcl}
g\pa{x}     &amp;=&amp;     \pa{\dfrac{1}{1+e^{-kx}}}\pa{\dfrac{1}{1+e^{-k\pa{1-x}}}}
            =     \dfrac{1}{1+e^{-kx}+e^{-k\pa{1-x}}+e^{-k}} \\
            &amp;=&amp;     \dfrac{1}{1+e^{-kx}+e^{-k}e^{kx}+e^{-k}}
            =     \dfrac{e^{kx}}{e^{kx}\pa{1+e^{-k}}+1+e^{-k}e^{2kx}}
\end{array}"/></p>
</div><p>La fonction <img class="math" src="../../_images/math/4e953a6b9c300bfe2fe5f17ee88313b9f9ce6f01.svg" alt="x \longrightarrow e^{kx}\pa{1+e^{-k}}+1+e^{-k}e^{2kx}"/>
est un polynôme en <img class="math" src="../../_images/math/2a2c7b506f4e79f3c998865096d0231db22e8bfb.svg" alt="e^{kx}"/> dont le
discriminant est positif. Par conséquent la fraction
rationnelle <img class="math" src="../../_images/math/0d6279f158c6944c5919be6e6c38f2051ba3a8c0.svg" alt="g\pa{x}"/> admet une décomposition en éléments
simples du premier ordre
et il existe quatre réels <img class="math" src="../../_images/math/40db27db442a32375344820b3e18003e4bc4c5b2.svg" alt="\eta_1"/>, <img class="math" src="../../_images/math/e20267a0dd2e1793ff457cf3d1c9e4a494a19c93.svg" alt="\eta_2"/>,
<img class="math" src="../../_images/math/6b6d56368a97339ef3b23677ed07f7d44a8f3b3b.svg" alt="\delta_1"/>, <img class="math" src="../../_images/math/dacd01bd7e14a82a9424a0c3fc8798f4ecbbb71f.svg" alt="\delta_2"/> tels que :</p>
<div class="math">
<p><img src="../../_images/math/2b433c7f2662486cfd9ef2a72d115e0e2083cc49.svg" alt="g\pa{x} = \dfrac{\eta_1}{1+ e^{kx+\delta_1}} + \dfrac{\eta_2}{1+ e^{kx+\delta_2}}"/></p>
</div><p>Par conséquent :</p>
<div class="math">
<p><img src="../../_images/math/1a798b4cb9519c05a874d8517ffce625a4d72e43.svg" alt="f\vecteur{y_1}{y_p} = \prod_{i=1}^{p} g\pa{y_i} =
                      \prod_{i=1}^{p} \cro { \dfrac{\eta_1^i}{1+ e^{ky_i+\delta_1^i}} + \dfrac{\eta_2^i}{1+
                      e^{ky_i+\delta_2^i}} }"/></p>
</div><p>Il existe <img class="math" src="../../_images/math/927ae9ea273d21dce23af63addd38a52af901d71.svg" alt="n \in \N"/> tel qu’il soit possible d’écrire <img class="math" src="../../_images/math/bd1e0600a66dbe0f8deddbd57953774419ba4e4f.svg" alt="f"/> sous la forme :</p>
<div class="math">
<p><img src="../../_images/math/5c130393f336f9225deab90eb99c106963ea1dfc.svg" alt="f\pa{y} = \sum_{i=1}^{n}  \dfrac{\gamma_i}{ 1 + e^{ &lt;x_i,y&gt; + b_i } }"/></p>
</div><div class="admonition-mathdef admonition" id="indexmathe-Corollaire1">
<div class="docutils container">
</div>
<p class="admonition-title" id="theoreme-densite-lemme-b">Corollaire C2 : approximation d’une fonction indicatrice</p>
<p>Soit <img class="math" src="../../_images/math/ea4bae8ad7fa54b1fb46923a1894ef20fd6a67b4.svg" alt="C\subset\R^p"/> compact, alors :</p>
<div class="math">
<p><img src="../../_images/math/2438971c64fbcb5fa05cab6a1210f152a5cf6ed3.svg" alt="\begin{array}{c}
\forall\varepsilon&gt;0, \; \forall\alpha&gt;0, \; \exists\left(  x_{1},...,x_{n}\right)
        \in\left(  \R^{p}\right)^{n}, \; \exists\left(
b_{1},...,b_{n}\right)  \in\R^n \text{ tels que } \forall x\in\R^{p},\\ \\
\begin{array}{ll}
&amp;   \left|  \sum_{i=1}^n \dfrac{\gamma_i}
            {1+e^{\left\langle x_{i},x\right\rangle +b_{i}}}-\indicatrice{x\in C
    }\right|  \leqslant1+2\varepsilon^2\\ \\
\text{ et } &amp;   \underset{y\in Fr\left( C\right)  }{\inf}\left\|  x-y\right\|
    &gt;\alpha\Rightarrow\left| \sum_{i=1}^n
                \dfrac{\gamma_i}{1+e^{\left\langle x_{i} ,x\right\rangle +b_{i}}}-
    \indicatrice{x\in C}\right| \leqslant \varepsilon
\end{array}
\end{array}"/></p>
</div></div>
<p><strong>Démonstration du corollaire</strong></p>
<p><em>Partie 1</em></p>
<p>Soit <img class="math" src="../../_images/math/947bbb2644c8e7ba526fa39c09697b1b2bc0be3d.svg" alt="C_1=\left\{  y=\left(  y_{1},...,y_{p}\right)  \in\R^p
\,\left| \, \forall i\in\left\{  1,...,n\right\}  ,\,0\leqslant y_{i}\leqslant1\right.  \right\}"/>
et <img class="math" src="../../_images/math/61df32afa0633ad665ab917acf227ad8202e5658.svg" alt="C_{2}^{j}=\left\{  y=\left(
y_{1},...,y_{p}\right)  \in\R^p\,\left| \,
\forall i\neq j,\,0\leqslant y_{i}\leqslant1 \text{ et }1\leqslant y_{j}\leqslant2\right.
\right\}"/></p>
<p>Le premier lemme suggère que la fonction cherchée pour ce lemme
dans le cas particulier <img class="math" src="../../_images/math/fa3e9bd8053c01a1542ba77ea54677e8d1e5a1b9.svg" alt="C_1\cup C_2^j"/> est :</p>
<div class="math">
<p><img src="../../_images/math/31b8a9555c4dba90d00ad1edbf46810e89388446.svg" alt="\begin{array}{rcl}
f\left(  y_{1},...,y_{p}\right) &amp;=&amp;   \prod_{i=1}^p \dfrac
                                    {1}{1+e^{-ky_{i}}} \prod_{i=1}^p\dfrac{1}{1+e^{-k\left( 1-y_{i}\right)
                                    }}+ \\
                            &amp;&amp;      \quad \left(  \prod_{i \neq j}
                                    \dfrac
                                    {1}{1+e^{-ky_{i}}}\right)  \left(  \prod_{i \neq j}
                                    \dfrac{1}{1+e^{-k\left(  1-y_{i}\right)  }}\right)
                                    \dfrac{1}{1+e^{k\left( 1-y_{j}\right)  }}\dfrac{1}{1+e^{-k\left(  2-y_{j}\right)
                                    }}\\
%
                            &amp;=&amp;  \left(  \prod_{i \neq j} \dfrac{1}{1+e^{-ky_{i}}}\right)
                                \left(  \prod_{i \neq j} \dfrac{1}{1+e^{-k\left(  1-y_{i}\right)
                                }}\right) \\
                            &amp;&amp;  \quad  \left( \dfrac{1}{1+e^{-ky_{j}}}\dfrac{1}{1+e^{-k\left(  1-y_{j}\right)  }}
                                 +\dfrac {1}{1+e^{k\left(  1-y_{j}\right)  }}
                                            \dfrac{1}{1+e^{-k\left(2-y_{j}\right) }}\right)
                                 \\
%
                            &amp;=&amp; \left(  \prod_{i \neq j} \dfrac{1}{1+e^{-ky_{i}}}\right)
                                 \left(  \prod_{i \neq j} \dfrac{1}{1+e^{-k\left(  1-y_{i}\right)  }}\right) \\
                            &amp;&amp;  \quad \left[\dfrac{1}{1+e^{-ky_{j}}}\left(  \dfrac{1}{1+e^{-k\left(  1-y_{j}\right)  }
                                }+1-1\right)  +\left(  1-\dfrac{1}{1+e^{-k\left(  1-y_{j}\right)  }}\right)
                                \dfrac{1}{1+e^{-k\left(  2-y_{j}\right)  }}\right]
\end{array}"/></p>
</div><p>Pour <img class="math" src="../../_images/math/430caa5125297680e23078baca4c1751d3acc356.svg" alt="k \supegal k_0\pa{\epsilon,\alpha,2p}"/>, on a :</p>
<div class="math">
<p><img src="../../_images/math/1e1d56b20466da1aca0a74a8938cb1a4800d2af7.svg" alt="\begin{array}{rcl}
f\left(  y_{1},...,y_{p}\right)  &amp;=&amp; \left(  \prod_{i\neq j}
\dfrac{1}{1+e^{-ky_{i}}}\right)  \left(  \prod_{i\neq j}
\dfrac{1}{1+e^{-k\left(  1-y_{i}\right)  }}\right)
\\
&amp;&amp; \quad \left(  \dfrac{1}%
{1+e^{-ky_{j}}}+\dfrac{1}{1+e^{-k\left(  2-y_{j}\right)  }}+
\underset {\leqslant\varepsilon^{2}}{\underbrace{\dfrac{1}{1+e^{k\left( 1-y_{j}\right)
}}\dfrac{1}{1+e^{-ky_{j}}}}}-\underset{\leqslant\varepsilon^{2}}%
{\underbrace{\dfrac{1}{1+e^{-k\left(  1-y_{j}\right)  }}\dfrac{1}%
{1+e^{-k\left(  2-y_{j}\right)  }}}}\right)
\end{array}"/></p>
</div><p>Par conséquent, il est facile de construire la fonction cherchée
pour tout compact connexe par arc.</p>
<p><em>Partie 2</em></p>
<p>Si un compact <img class="math" src="../../_images/math/2c0e77bc741b692ecdf6e85966263a89422af4c8.svg" alt="C"/> n’est pas connexe par arc,
on peut le recouvrir par une somme finie de
compacts connexes par arcs et disjoints
<img class="math" src="../../_images/math/deb72793fb071514155e1cda6ccd4f3b74937cd4.svg" alt="\left(C_{k}\right) _{1\leqslant k\leqslant K}"/> de telle sorte que :</p>
<div class="math">
<p><img src="../../_images/math/b1301d89c9021a83b093f273b4223a619e4fdb78.svg" alt="\forall y\in\underset{k=1}{\overset{K}{\cup}}C_{k},\,\inf\left\{  \left\|
x-y\right\|  ,\,x\in C\right\}  \leqslant\dfrac{\alpha}{2}"/></p>
</div><p><strong>Démontration du théorème de</strong> <a class="reference internal" href="#theoreme-densite"><span class="std std-ref">densité des réseaux de neurones</span></a></p>
<p><em>Partie 1</em></p>
<p>On démontre le théorème dans le cas où <img class="math" src="../../_images/math/2a73425479e21fc22276406e75ba619a8a061cee.svg" alt="q=1"/>.
Soit <img class="math" src="../../_images/math/bd1e0600a66dbe0f8deddbd57953774419ba4e4f.svg" alt="f"/> une fonction continue du compact
<img class="math" src="../../_images/math/501051e0200b03a45d70794119a384602b3229de.svg" alt="C\subset\R^p\rightarrow \R"/> et soit <img class="math" src="../../_images/math/935f4b41c99c830ddcefccc6723bb5c102973b43.svg" alt="\varepsilon&gt;0"/>.</p>
<p>On suppose également que <img class="math" src="../../_images/math/bd1e0600a66dbe0f8deddbd57953774419ba4e4f.svg" alt="f"/> est positive, dans le cas contraire, on pose
<img class="math" src="../../_images/math/b817b36303e1dc91cda3e07db5ec7909d156224c.svg" alt="f=\underset{\text{fonction positive}}{\underbrace{f-\inf f}}+\inf f"/>.</p>
<p>Si <img class="math" src="../../_images/math/bd1e0600a66dbe0f8deddbd57953774419ba4e4f.svg" alt="f"/> est nulle, alors c’est fini, sinon, on pose <img class="math" src="../../_images/math/95ce55c937802dbddf12f7e365ecc07769a75c6d.svg" alt="M=\underset{x\in C}{\sup }f\left(  x\right)"/>.
<img class="math" src="../../_images/math/e5c619f0600e251cabb3318b03870bc6f2c4870f.svg" alt="M"/> existe car <img class="math" src="../../_images/math/bd1e0600a66dbe0f8deddbd57953774419ba4e4f.svg" alt="f"/> est continue et <img class="math" src="../../_images/math/2c0e77bc741b692ecdf6e85966263a89422af4c8.svg" alt="C"/>
est compact (de même, <img class="math" src="../../_images/math/5dbbf477b3e37aab1c338288dc72b26bd3939556.svg" alt="\inf f"/> existe également).</p>
<p>On pose <img class="math" src="../../_images/math/5d9cc29f710a7956b4d6aa7a290873407502d170.svg" alt="C_{k}=f^{-1}\left(  \left[  k\varepsilon,M\right]  \right)"/>.
<img class="math" src="../../_images/math/8d5ea7c11912b80ccba3fa191c7dcd0355bd3dcf.svg" alt="C_k"/> est compact car il est l’image
réciproque d’un compact par une fonction continue et <img class="math" src="../../_images/math/2510082f8cd53b1e5c0c8b3368a71afeeb242806.svg" alt="C_k\subset C"/> compact.</p>
<img alt="../../_images/rn_densite_idee.png" src="../../_images/rn_densite_idee.png" />
<p>Par construction, <img class="math" src="../../_images/math/f36e14ed548a1c4e777333e44e637902c521ce29.svg" alt="C_{k+1}\subset C_{k}"/> et <img class="math" src="../../_images/math/3e0440141a58a6cbb1631bac0b83b9f74711cbda.svg" alt="C=\underset{k=0}{\overset {\frac{M}{\varepsilon}}
{\bigcup}}C_{k}=C_{0}"/> on définit~:</p>
<div class="math">
<p><img src="../../_images/math/be282cfddfbeb0fa74c6e1e894ce0e9abf5912b2.svg" alt="\forall x\in
C,\; g_{\varepsilon}\left(  x\right)  =
        \varepsilon\overset{\frac {M}{\varepsilon}}{ \sum_{k=0}}\indicatrice{x\in C_{k}}"/></p>
</div><p>D’où~:</p>
<div class="math">
<p><img src="../../_images/math/6df132dfc8913a3bd240780d3717400d3f18247d.svg" alt="\begin{eqnarray}
f\left(  x\right)  -g_{\varepsilon}\left(  x\right)  &amp;=&amp;
                    f\left(  x\right)-\varepsilon\overset{\frac{M}{\varepsilon}}{\sum_{k=0}}
    \indicatrice{x\in C_{k}} \nonumber
= f\left(  x\right)  -\varepsilon \overset{\frac{M}{\varepsilon}}
            {\sum_{k=0}}\indicatrice
                { f\pa{x} \supegal k \varepsilon } \nonumber \\
&amp;=&amp; f\left( x\right)  -\varepsilon\left[  \dfrac{f\left(  x\right) }
                {\varepsilon}\right] \quad \text{ (partie entière)}\nonumber  \\
&amp; \text{d'où }&amp;  0\leqslant f\left(  x\right)  -g_{\varepsilon}\left(  x\right)  \leqslant \frac{\varepsilon}{4}
\end{eqnarray}"/></p>
</div><p>Comme <img class="math" src="../../_images/math/bd1e0600a66dbe0f8deddbd57953774419ba4e4f.svg" alt="f"/> est continue sur un compact, elle est uniformément continue sur ce compact :</p>
<div class="math">
<p><img src="../../_images/math/ba6fab2c8cd058f1e5b4c9f2c09a8fe32d9cd018.svg" alt="\begin{array}{l}
\exists\alpha&gt;0 \text{ tel que } \forall\left(  x,y\right)  \in C^{2},
            \; \left\| x-y\right\|  \leqslant\alpha\Longrightarrow\left|  f\left(
    x\right) -f\left(  y\right)  \right|  \leqslant \frac{ \varepsilon}{2} \\ \\
\text{ d'où } \left|  f\left(  x\right)  -f\left(  y\right)  \right| \supegal \varepsilon
                 \Longrightarrow\left\|  x-y\right\|  &gt;\alpha
\end{array}"/></p>
</div><p>Par conséquent :</p>
<div class="math">
<p><img src="../../_images/math/d0c0789f1be0bfc854d7e2c34a20bb15a3a71745.svg" alt="\inf\left\{  \left\|  x-y\right\|  \,\left|  \,x\in Fr\left(  C_{k}\right) ,\,y\in
                Fr\left(  C_{k+1}\right)  \right.  \right\}
&gt;\alpha"/></p>
</div><p>D’après le second lemme, on peut construire des fonctions <img class="math" src="../../_images/math/2f5128308527f42e434a3e7421dbbf8348e9b5b0.svg" alt="h_{k}\left( x\right)
=\sum_{i=1}^n\dfrac{1}{1+e^{\left\langle x_{i}^{k},x\right\rangle +b_{i}^{k}}}"/>
telles que :</p>
<div class="math">
<p><img src="../../_images/math/0404afbe06ad71e493cd436b592ebe3916306945.svg" alt="\left(  \left\|  h_{k}\left(  x\right)  -\indicatrice{x\in C_{k}}\right\|
    \leqslant1 \right)  \text{ et } \left( \underset{y\in
Fr\left(  C\right)  }{\inf}\left\|  x-y\right\|  &gt;\dfrac{\alpha}{2}%
\Rightarrow\left\|  h_{k}\left(  x\right)  -\indicatrice{x\in C_{k}}\right\|  \leqslant\varepsilon^{2}\right)"/></p>
</div><p>On en déduit que :</p>
<div class="math">
<p><img src="../../_images/math/9e3bca230dd2e6267a5bf8b0fb764b710ef20940.svg" alt="\begin{array}{rcl}
\left|  f\left(  x\right)  -\varepsilon\overset{\frac{M}{\varepsilon}}
        {\sum_{k=0}}h_{k}\left(  x\right)  \right|  &amp;\leqslant&amp;
    \left| f\left(  x\right)  -g_{\varepsilon}\left(  x\right)  \right|
         +\left|g_{\varepsilon}\left(  x\right)  -\varepsilon
    \overset{\frac{M}{\varepsilon}}{\sum_{k=0}}h_{k}\left(  x\right)  \right| \\
&amp;\leqslant&amp; \varepsilon+ \varepsilon^2 \left[  \dfrac{M}{\varepsilon}\right] + 2\varepsilon^2 \\
&amp;\leqslant&amp; \varepsilon\left(  M+3\right)
\end{array}"/></p>
</div><p>Comme <img class="math" src="../../_images/math/441890308ae8353d29b06870e8fe65ded70849e3.svg" alt="\varepsilon\overset{\frac{M}{\varepsilon}}{\sum_{k=1}}
h_{k}\left(  x\right)"/> est de la forme désirée, le théorème est démontré dans le cas <img class="math" src="../../_images/math/2a73425479e21fc22276406e75ba619a8a061cee.svg" alt="q=1"/>.</p>
<p><em>Partie 2</em></p>
<p>Dans le cas <img class="math" src="../../_images/math/39d4e44fcae2463826f3b846fa06c0f2260397c8.svg" alt="q&gt;1"/>, on utilise la méthode précédente pour chacune des projections de <img class="math" src="../../_images/math/bd1e0600a66dbe0f8deddbd57953774419ba4e4f.svg" alt="f"/>
dans un repère orthonormé de <img class="math" src="../../_images/math/84344891b943192dbcca7bf2b3fae9ed243aa5e2.svg" alt="\R^{q}"/>. Il suffit de
sommer sur chacune des dimensions.</p>
<p>Ce théorème montre qu’il est judicieux de modéliser la fonction
<img class="math" src="../../_images/math/bd1e0600a66dbe0f8deddbd57953774419ba4e4f.svg" alt="f"/> dans l’équation <a class="reference internal" href="#equation-rn-eqn-regression-2">(2)</a>
par un réseau de neurones puisqu’il possible de s’approcher d’aussi
près qu’on veut de la fonction <img class="math" src="../../_images/math/1bccd86e61977742f53b4fca6b4cbbb0a6fff0f8.svg" alt="\esp\pa{Y | X}"/>,
il suffit d’ajouter des neurones sur la couche cachée du réseau.
Ce théorème permet de déduire le corollaire suivant :</p>
<div class="admonition-mathdef admonition" id="indexmathe-Corollaire2">
<div class="docutils container">
</div>
<p class="admonition-title" id="corollaire-famille-libre">Corollaire C3 : famille libre de fonctions</p>
<p>Soit <img class="math" src="../../_images/math/8faa305a5ba70beaf67fd1ef7ecbf9ec0a9157aa.svg" alt="F_{p}"/> l’ensemble des fonctions continues de
<img class="math" src="../../_images/math/ab08a76d24955be7c59b97821531c78a3c8079b3.svg" alt="C\subset\R^{p}\longrightarrow\R"/> avec <img class="math" src="../../_images/math/2c0e77bc741b692ecdf6e85966263a89422af4c8.svg" alt="C"/>
compact muni de la norme :
<img class="math" src="../../_images/math/89d5ff3f5f71076c7fa1b65b745470e495c966b3.svg" alt="\left\| f\right\| =\underset{x\in C}{\sup}\left\|  f\left( x\right)  \right\|"/>
Alors l’ensemble <img class="math" src="../../_images/math/f79dd35c45921a843ee73ca6ceb9d8adf913ee22.svg" alt="E_{p}"/> des fonctions sigmoïdes :</p>
<div class="math">
<p><img src="../../_images/math/7513f7c62ef74f06258bf0a825825d33fc746143.svg" alt="E_{p} =  \acc{ x \longrightarrow 1 - \dfrac{2}{1 + e^{&lt;y,x&gt;+b}} | y
\in \R^p \text{ et } b \in \R}"/></p>
</div><p>est une base de <img class="math" src="../../_images/math/8faa305a5ba70beaf67fd1ef7ecbf9ec0a9157aa.svg" alt="F_{p}"/>.</p>
</div>
<p><strong>Démonstration du corollaire</strong></p>
<p>Le théorème de <a class="reference internal" href="#theoreme-densite"><span class="std std-ref">densité</span></a> montre que la famille
<img class="math" src="../../_images/math/f79dd35c45921a843ee73ca6ceb9d8adf913ee22.svg" alt="E_{p}"/> est une famille génératrice. Il reste à montrer que c’est une
famille libre. Soient <img class="math" src="../../_images/math/6af94056626cd0fad7cc96e4d9310648643a9be5.svg" alt="\pa{y_i}_{1 \infegal i \infegal N} \in \pa{\R^p}^N"/> et
<img class="math" src="../../_images/math/96ae1e8f90da09c66312228c4ea6f11cfeee64d3.svg" alt="\pa{b_i}_{1 \infegal i \infegal N} \in \R^N"/> vérifiant :
<img class="math" src="../../_images/math/75a818d87f51b3e660e3a49cad50e835c4ccc54c.svg" alt="i \neq j \Longrightarrow y_i \neq y_j \text{ ou } b_i \neq b_j"/>.
Soit <img class="math" src="../../_images/math/b2fe778ba1f32ca71257c3e79f826d09aaefe6f1.svg" alt="\pa{\lambda_i}_{1 \infegal i \infegal N} \in \R^N"/>, il faut montrer que :</p>
<div class="math" id="equation-corollaire-demo-recurrence-base">
<p><span class="eqno">(3)<a class="headerlink" href="#equation-corollaire-demo-recurrence-base" title="Lien permanent vers cette équation">#</a></span><img src="../../_images/math/cf058dee46dc31cee81dad0b7c2e03c26ab9fbc0.svg" alt="\begin{eqnarray}
\forall x \in \R^p, \; \sum_{i=1}^{N} \lambda_i \pa{ 1 - \dfrac{2}{1 + e^{&lt;y_i,x&gt;+b_i}  }} = 0
\Longrightarrow \forall i \, \lambda_i = 0
\end{eqnarray}"/></p>
</div><p>C’est évidemment vrai pour <img class="math" src="../../_images/math/5ef3c9cf976a9fcdbe57c1a7cc3d0ee8ad33081b.svg" alt="N=1"/>.
La démonstration est basée sur un raisonnement par récurrence,
on suppose qu’elle est vraie pour <img class="math" src="../../_images/math/5b7182a9e61cfdfecb16e3e366844540f84a51c9.svg" alt="N-1"/>,
démontrons qu’elle est vraie pour <img class="math" src="../../_images/math/bceb9186b5004313ecccd0d22d07ea9617b62f98.svg" alt="N"/>.
On suppose donc <img class="math" src="../../_images/math/011379fa8c2134b84632ff3165450936b8c55563.svg" alt="N \supegal 2"/>.
S’il existe <img class="math" src="../../_images/math/ade6825e6e139f44828f98e4f0b932639f33f538.svg" alt="i \in \ensemble{1}{N}"/> tel que <img class="math" src="../../_images/math/0e2d9d15f0cb6fbd75d4fa26a18f749d24676386.svg" alt="y_i = 0"/>,
la fonction <img class="math" src="../../_images/math/4b30c47dc01ecb21644b0b5f66de3b9e8138d2d6.svg" alt="x \longrightarrow 1 - \dfrac{2}{1 + e^{&lt;y_i,x&gt;+b_i}}"/>
est une constante, par conséquent, dans ce cas le corollaire est
est vrai pour <img class="math" src="../../_images/math/bceb9186b5004313ecccd0d22d07ea9617b62f98.svg" alt="N"/>. Dans le cas contraire,
<img class="math" src="../../_images/math/6e9eb67b080ccdf31786d4212accd218648e4410.svg" alt="\forall i \in \ensemble{1}{N}, \; y_i \neq 0"/>.
On définit les vecteurs <img class="math" src="../../_images/math/c1f0412bd01d3687dfb7903df73602baf42bc06a.svg" alt="X_i = \pa{x_i,1}"/> et
<img class="math" src="../../_images/math/3c374a7a79bb7542ce0fd1d9169142fbabe9f7e5.svg" alt="Y_i = \pa{y_j, b_j}"/>.
On cherche à résoude le système de <img class="math" src="../../_images/math/bceb9186b5004313ecccd0d22d07ea9617b62f98.svg" alt="N"/> équations à <img class="math" src="../../_images/math/bceb9186b5004313ecccd0d22d07ea9617b62f98.svg" alt="N"/> inconnues :</p>
<div class="math" id="equation-rn-coro-eq-1">
<p><span class="eqno">(4)<a class="headerlink" href="#equation-rn-coro-eq-1" title="Lien permanent vers cette équation">#</a></span><img src="../../_images/math/08b47841bae57dc65facc30385f9a8df6ab85f70.svg" alt="\begin{eqnarray}
\left\{
\begin{array}{ccc}
\sum_{j=1}^{N} \lambda_j \pa{ 1 - \dfrac{2}{1 + e^{&lt;Y_j,X_1&gt;}}} &amp;=&amp; 0 \\
\ldots \\
\sum_{j=1}^{N} \lambda_j \pa{ 1 - \dfrac{2}{1 + e^{&lt;Y_j,X_i&gt;}}} &amp;=&amp; 0 \\
\ldots \\
\sum_{j=1}^{N} \lambda_j \pa{ 1 - \dfrac{2}{1 + e^{&lt;Y_j,X_N&gt;}}} &amp;=&amp; 0
\end{array}
\right.
\end{eqnarray}"/></p>
</div><p>On note le vecteur
<img class="math" src="../../_images/math/4e47f3d963ab57e39e33bb66aeb68a677168bdd5.svg" alt="\Lambda = \pa{\lambda_i}_{ 1 \infegal i \infegal N}"/> et <img class="math" src="../../_images/math/e5c619f0600e251cabb3318b03870bc6f2c4870f.svg" alt="M"/> la matrice :</p>
<div class="math">
<p><img src="../../_images/math/bbf38a370dbc724031805c562dc7eb6a87285e62.svg" alt="M= \pa{m_{ij}}_{ 1 \infegal i,j \infegal N} = \pa{ 1 - \dfrac{2}{1 + e^{&lt;Y_j,X_i&gt;}} }_{ 1 \infegal i,j \infegal N}"/></p>
</div><p>L’équation <a class="reference internal" href="#equation-rn-coro-eq-1">(4)</a> est équivalente à l’équation matricielle :
<img class="math" src="../../_images/math/e72aa076911edbc2afd14f3af3a95a2dbad95a41.svg" alt="M\Lambda = 0"/>. On effectue une itération du pivot de Gauss.
<a class="reference internal" href="#equation-rn-coro-eq-1">(4)</a> équivaut à :</p>
<div class="math">
<p><img src="../../_images/math/9ce2ce1f59bb1f34c4876e434677f83ed92937d7.svg" alt="\begin{array}{rcl}
&amp;\Longleftrightarrow&amp; \left\{ \begin{array}{ccllllllll}
                                \lambda_1  m_{11} &amp;+&amp; \lambda_2 &amp; m_{12} &amp;+&amp; \ldots &amp;+&amp; \lambda_N &amp; m_{1N} &amp; = 0 \\
                                0                 &amp;+&amp; \lambda_2 &amp; \pa{ m_{22} m_{11} - m_{12} m_{21} }
                                                                    &amp;+&amp; \ldots &amp;+&amp; \lambda_N &amp; \pa{ m_{2N} m_{11} - m_{1N} m_{21} }
                                                                     &amp; = 0 \\
                                \ldots \\
                                0                 &amp;+&amp; \lambda_2 &amp; \pa{ m_{N2} m_{11} - m_{12} m_{N1} } &amp;+&amp; \ldots
                                                                    &amp;+&amp; \lambda_N &amp; \pa{ m_{NN} m_{11} - m_{1N} m_{N1} } &amp; = 0
                                \end{array}
                                \right.
\end{array}"/></p>
</div><p>On note <img class="math" src="../../_images/math/e384442c0f9291f45c3806fd30a607356fe71f4b.svg" alt="\Lambda_* = \pa{\lambda_i}_{ 2 \infegal i \infegal N}"/> et
<img class="math" src="../../_images/math/b34f827f7dbe8f8ddc7f07c8d64ef573a7df0eb0.svg" alt="\Delta_*"/>, <img class="math" src="../../_images/math/9dbbcd2e21b352cb8958a49ba190d4b6e60b8b09.svg" alt="M_*"/> les matrices :</p>
<div class="math">
<p><img src="../../_images/math/390cffafdec7e29e95034f82538b8c5aeda5b33c.svg" alt="\begin{array}{rcl}
M_*         &amp;=&amp;     \pa{m_{ij}}_{ 2 \infegal i,j \infegal N} \\
\Delta_*    &amp;=&amp;     \pa{ m_{1j} \, m_{i1} }_{ 2 \infegal i,j \infegal N}
\end{array}"/></p>
</div><p>Donc <a class="reference internal" href="#equation-rn-coro-eq-1">(4)</a> est équivalent à :</p>
<div class="math" id="equation-rn-coro-eq-3">
<p><span class="eqno">(5)<a class="headerlink" href="#equation-rn-coro-eq-3" title="Lien permanent vers cette équation">#</a></span><img src="../../_images/math/3e9cf9f022fbddd4af273b1db8ddb5eb20d974ae.svg" alt="\begin{eqnarray}
\begin{array}{ccl}
                     &amp;\Longleftrightarrow&amp; \left\{ \begin{array}{cccc}
                                \lambda_1  m_{11}&amp;+&amp; \lambda_2  m_{12} + \ldots + \lambda_N  m_{1N}  &amp;= 0 \\
                                0                &amp;+&amp;   \pa{ m_{11} M_* -  \Delta_*} \Lambda_* &amp; = 0
                                \end{array}
                                \right.
\end{array}
\end{eqnarray}"/></p>
</div><p>Il est possible de choisir <img class="math" src="../../_images/math/7ac94b39321bbcfb20a4da4ae7a383a2e43d6e99.svg" alt="X_1\pa{\alpha} = \pa{\alpha x_1, 1}"/>
de telle sorte qu’il existe une suite <img class="math" src="../../_images/math/f6d17f24d82a9f6c9dd18ac878c74aee063f2693.svg" alt="\pa{s_l}_{ 1 \infegal l \infegal N } \in \acc{-1,1}^{N}"/>
avec <img class="math" src="../../_images/math/59742d21f1126253a54e806c0e6e7a5725243551.svg" alt="s_1=1"/> et vérifiant :</p>
<div class="math">
<p><img src="../../_images/math/970a1e660e2c04323db550409742209a554f6632.svg" alt="\forall j \in \vecteur{1}{N}, \;
\underset{\alpha \longrightarrow +\infty} {\lim }  \cro{ 1 - \dfrac{2}{1 + e^{&lt;Y_j, \, X_1\pa{\alpha}   &gt;}} } =
\underset{\alpha \longrightarrow +\infty} {\lim }  m_{1j}\pa{\alpha} = s_j"/></p>
</div><p>On définit :</p>
<div class="math">
<p><img src="../../_images/math/f46136f4eb3e97064b952e1c64674768431883a6.svg" alt="\begin{array}{rll}
U_* &amp;=&amp; \vecteur{m_{21}}{m_{N1}}' \\
V_* &amp;=&amp; \vecteur{s_2 \, m_{21}}{s_N \, m_{N1}}' \\
\text{ et la matrice } L_* &amp;=&amp; \pa{V_*}_ { 2 \infegal i \infegal N } \text{ dont les $N-1$ colonnes sont identiques }
\end{array}"/></p>
</div><p>On vérifie que :</p>
<div class="math">
<p><img src="../../_images/math/bde002bbd60d290389fbbc3c36b93a89e0f372d1.svg" alt="\underset{\alpha \longrightarrow +\infty} {\lim } \Delta\pa{\alpha} = V_*"/></p>
</div><p>On obtient, toujours pour <a class="reference internal" href="#equation-rn-coro-eq-1">(4)</a> :</p>
<blockquote>
<div><div class="math" id="equation-rn-coro-eq-2">
<p><span class="eqno">(6)<a class="headerlink" href="#equation-rn-coro-eq-2" title="Lien permanent vers cette équation">#</a></span><img src="../../_images/math/530ce036945f5c1f97c96c2b88b4760e5078aaea.svg" alt="\begin{eqnarray}
                     &amp;\Longleftrightarrow&amp; \left\{ \begin{array}{cclc}
                                \lambda_1  m_{11}\pa{\alpha}    &amp;+&amp;
                                                            \lambda_2  m_{12}\pa{\alpha} + \ldots + \lambda_N  m_{1N}\pa{\alpha}  &amp;= 0 \\
                                0                &amp;+&amp;   \cro{m_{11}\pa{\alpha} M_* -
                                                                                    \pa{ L_* + \pa{ \Delta_*\pa{\alpha} - L_* } } }
                                                                                \Lambda_* &amp; = 0
                                \end{array}
                                \right. \\ \nonumber\\
                     &amp;\Longleftrightarrow&amp; \left\{ \begin{array}{cclc}
                                \lambda_1  m_{11}\pa{\alpha}    &amp;+&amp;
                                                            \lambda_2  m_{12}\pa{\alpha} + \ldots + \lambda_N  m_{1N}\pa{\alpha}  &amp;= 0 \\
                                0                &amp;+&amp;   \pa{m_{11}\pa{\alpha} M_* -    L_* }      \Lambda_*
                                                     +  \pa{ \Delta_*\pa{\alpha} - L_* }     \Lambda_* &amp;  = 0
                                \end{array}
                                \right. \nonumber
\end{eqnarray}"/></p>
</div></div></blockquote>
<p>On étudie la limite lorsque <img class="math" src="../../_images/math/4e8a38a3459f3dc0db32df208b0b6c26361afd9e.svg" alt="\alpha \longrightarrow +\infty"/> :</p>
<div class="math">
<p><img src="../../_images/math/70591f4d7130eb24a88af638567bd703cf07d97d.svg" alt="\begin{array}{crcl}
                    &amp; \pa{ \Delta_*\pa{\alpha} - L_* }   &amp;
                        \underset{ \alpha \rightarrow +\infty}{ \longrightarrow} &amp; 0                 \\
\Longrightarrow     &amp; \pa{m_{11}\pa{\alpha} M_* -   L_* }      \Lambda_* &amp;
                        \underset{ \alpha \rightarrow +\infty}{ \longrightarrow} &amp;  0\\
\Longrightarrow     &amp; \pa{M_* -  L_* }      \Lambda_* &amp;   = &amp;  0\\
\Longrightarrow     &amp; M_* \Lambda_* -    \pa{  \sum_{j=2}^{N} \lambda_j   }   V_*   &amp;   = &amp;  0\\
\end{array}"/></p>
</div><p>Donc :</p>
<div class="math" id="equation-rn-coro-eq-5">
<p><span class="eqno">(7)<a class="headerlink" href="#equation-rn-coro-eq-5" title="Lien permanent vers cette équation">#</a></span><img src="../../_images/math/9c36a6e4dfe72c3c4a6289aeec59c0d4cef04c0f.svg" alt="\begin{eqnarray*}
M_* \Lambda_* -    \pa{  \sum_{j=2}^{N} \lambda_j   }   V_*   &amp;=&amp;  0
\end{eqnarray*}"/></p>
</div><p>D’après l’hypothèse de récurrence, <a class="reference internal" href="#equation-rn-coro-eq-5">(7)</a> implique que :
<img class="math" src="../../_images/math/69cd38d29275ef67fd8b33b50629bbb4f87cfc42.svg" alt="\forall i \in \ensemble{2}{N}, \; \lambda_i = 0"/>.
Il reste à montrer que <img class="math" src="../../_images/math/73a087d25af7a13483c39ff28ca01c3d9986b07a.svg" alt="\lambda_1"/>
est nécessairement nul ce qui est le cas losque <img class="math" src="../../_images/math/4e8a38a3459f3dc0db32df208b0b6c26361afd9e.svg" alt="\alpha \longrightarrow +\infty"/>,
alors <img class="math" src="../../_images/math/dba06ac43905cbaef199007b6037b0412b34bcd3.svg" alt="\lambda_1  m_{11}\pa{\alpha} \longrightarrow \lambda_1 = 0"/>.
La récurrence est démontrée.</p>
<p>A chaque fonction sigmoïde du corollaire <a class="reference internal" href="#corollaire-famille-libre"><span class="std std-ref">famille libre</span></a>
correspond un neurone de la couche cachée. Tous ont des rôles
symétriques les uns par rapport aux autres ce qui ne serait
pas le cas si les fonctions de transfert étaient des polynômes.
C’est une des raisons pour lesquelles les réseaux de neurones
ont du succès. Le théorème <a class="reference internal" href="#theoreme-densite"><span class="std std-ref">densité</span></a>
et le corollaire <a class="reference internal" href="#corollaire-famille-libre"><span class="std std-ref">famille libre</span></a>
sont aussi vraies pour des fonctions du type exponentielle :
<img class="math" src="../../_images/math/b20c62fa5b42d2cef59273359e8269d385679fca.svg" alt="\pa{y,b} \in \R^p \times \R \longrightarrow e^{-\pa{&lt;y,x&gt;+b}^2}"/>.
Maintenant qu’il est prouvé que les réseaux de neurones conviennent
pour modéliser <img class="math" src="../../_images/math/bd1e0600a66dbe0f8deddbd57953774419ba4e4f.svg" alt="f"/> dans l’équation <a class="reference internal" href="#equation-rn-eqn-regression-2">(2)</a>,
il reste à étudier les méthodes qui permettent de trouver
les paramètres <img class="math" src="../../_images/math/4d4f4910fb33f542260bd4f5593ffb800c330e49.svg" alt="W^*"/> optimaux de cette fonction.</p>
</section>
</section>


                </article>
              
              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="rn_3_clas.html"
       title="page précédente">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">précédent</p>
        <p class="prev-next-title">La classification</p>
      </div>
    </a>
    <a class="right-next"
       href="rn_5_newton.html"
       title="page suivante">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">suivant</p>
        <p class="prev-next-title">Descente de gradient</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Sur cette page
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#formulation-du-probleme-de-la-regression">Formulation du problème de la régression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#densite-des-reseaux-de-neurones">Densité des réseaux de neurones</a></li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">
  <div class="tocsection sourcelink">
    <a href="../../_sources/c_ml/rn/rn_4_densite.rst">
      <i class="fa-solid fa-file-lines"></i> Montrer le code source
    </a>
  </div>
</div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">
  <p class="copyright">
    
      © Copyright 2016-2023, Xavier Dupré.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">
  <p class="sphinx-version">
    Créé en utilisant <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.1.2.
    <br/>
  </p>
</div>
      
    </div>
  
  
    <div class="footer-items__end">
      
        <div class="footer-item"><p class="theme-version">
  Construit avec le <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">Thème PyData Sphinx</a> 0.13.3.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>