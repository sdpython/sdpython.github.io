
<!DOCTYPE html>


<html lang="fr" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Définition des réseaux de neurones multi-couches &#8212; Documentation mlstatpy 0.4.0</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css?v=fd3f3429" />
    <link rel="stylesheet" type="text/css" href="../../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=f45c5ce7"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/translations.js?v=041d0952"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"chtml": {"displayAlign": "left"}, "tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'c_ml/rn/rn_1_def';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Recherche" href="../../search.html" />
    <link rel="next" title="La régression" href="rn_2_reg.html" />
    <link rel="prev" title="Réseaux de neurones" href="rn.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="fr"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Passer au contenu principal</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Haut de page</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Navigation dans le site">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/project_ico.png" class="logo__image only-light" alt="Documentation mlstatpy 0.4.0 - Home"/>
    <script>document.write(`<img src="../../_static/project_ico.png" class="logo__image only-dark" alt="Documentation mlstatpy 0.4.0 - Home"/>`);</script>
  
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../c_clus/index.html">
    Clustering
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../index.html">
    Non linéaire
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../index_reg_lin.html">
    Régression linéaire
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../index_reg_log.html">
    Régression logistique
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../c_nlp/index.html">
    NLP
  </a>
</li>

            <li class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-controls="pst-nav-more-links">
                    More
                </button>
                <ul id="pst-nav-more-links" class="dropdown-menu">
                    
<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../c_metric/index.html">
    Métriques
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../c_algo/index.html">
    Algorithmes
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../c_garden/index.html">
    Pérégrinations
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../api/index.html">
    API
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../i_ex.html">
    Examples
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../defthe_index.html">
    Listes des définitions et théorèmes
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../auto_examples/index.html">
    Gallery of examples
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../notebooks/index.html">
    Galleries de notebooks
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../glossary.html">
    Glossary
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../CHANGELOGS.html">
    Change Logs
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../license.html">
    License
  </a>
</li>

                </ul>
            </li>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Recherche" aria-label="Recherche" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Recherche</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script>
        </div>
      
      
        <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="clair/sombre" aria-label="clair/sombre" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Recherche" aria-label="Recherche" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Recherche</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="Sur cette page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../c_clus/index.html">
    Clustering
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../index.html">
    Non linéaire
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../index_reg_lin.html">
    Régression linéaire
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../index_reg_log.html">
    Régression logistique
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../c_nlp/index.html">
    NLP
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../c_metric/index.html">
    Métriques
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../c_algo/index.html">
    Algorithmes
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../c_garden/index.html">
    Pérégrinations
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../api/index.html">
    API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../i_ex.html">
    Examples
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../defthe_index.html">
    Listes des définitions et théorèmes
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../auto_examples/index.html">
    Gallery of examples
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../notebooks/index.html">
    Galleries de notebooks
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../glossary.html">
    Glossary
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../CHANGELOGS.html">
    Change Logs
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../license.html">
    License
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="clair/sombre" aria-label="clair/sombre" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Navigation de la section">
  <p class="bd-links__title" role="heading" aria-level="1">Navigation de la section</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="rn.html">Réseaux de neurones</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Définition des réseaux de neurones multi-couches</a></li>
<li class="toctree-l2"><a class="reference internal" href="rn_2_reg.html">La régression</a></li>
<li class="toctree-l2"><a class="reference internal" href="rn_3_clas.html">La classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="rn_4_densite.html">Démonstration du théorème de la densité des réseaux de neurones</a></li>
<li class="toctree-l2"><a class="reference internal" href="rn_5_newton.html">Descente de gradient</a></li>
<li class="toctree-l2"><a class="reference internal" href="rn_6_apprentissage.html">Apprentissage d’un réseau de neurones</a></li>
<li class="toctree-l2"><a class="reference internal" href="rn_7_clas2.html">Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="rn_8_prol.html">Prolongements</a></li>
<li class="toctree-l2"><a class="reference internal" href="rn_9_auto.html">Analyse en composantes principales (ACP) et Auto Encoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="rn_biblio.html">Bibliographie</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../kppv.html">Classification à l’aide des plus proches voisins</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../missing_values_mf.html">Liens entre factorisation de matrices, ACP, k-means</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/ml/mf_acp.html">Factorisation et matrice et ACP</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/ml/valeurs_manquantes_mf.html">Valeurs manquantes et factorisation de matrices</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/ml/neural_tree.html">Un arbre de décision en réseaux de neurones</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/ml/neural_tree_onnx.html">NeuralTreeNet et ONNX</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/ml/neural_tree_cost.html">NeuralTreeNet et coût</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Fil d'Ariane" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../index.html" class="nav-link" aria-label="Accueil">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../index.html" class="nav-link">Non linéaire</a></li>
    
    
    <li class="breadcrumb-item"><a href="rn.html" class="nav-link">Réseaux de neurones</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">Définition...</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="definition-des-reseaux-de-neurones-multi-couches">
<h1>Définition des réseaux de neurones multi-couches<a class="headerlink" href="#definition-des-reseaux-de-neurones-multi-couches" title="Lien vers cette rubrique">#</a></h1>
<p>Les réseaux de neurones multi-couches (ou perceptrons) définissent une
classe de fonctions dont l’intérêt est de pouvoir approcher n’importe quelle
fonction continue à support compact
(voir théorème sur la <a class="reference internal" href="rn_4_densite.html#theoreme-densite"><span class="std std-ref">densité</span></a>).
Aucun autre type de réseau de neurones ne sera étudié et par la suite,
tout réseau de neurones sera considéré comme multi-couches
(donc pas les <a class="reference external" href="https://fr.wikipedia.org/wiki/Carte_auto_adaptative">réseau de Kohonen</a>).</p>
<section id="un-neurone">
<span id="l-rn-neurone"></span><h2>Un neurone<a class="headerlink" href="#un-neurone" title="Lien vers cette rubrique">#</a></h2>
<div class="admonition-mathdef admonition" id="indexmathe-Définition0">
<div class="docutils container">
</div>
<p class="admonition-title" id="def-neurone">Définition D1 : neurone</p>
<p>Un neurone à <span class="math notranslate nohighlight">\(p\)</span> entrées est une fonction
<span class="math notranslate nohighlight">\(f : \mathbb{R}^{p+1} \times \mathbb{R}^p \longrightarrow \mathbb{R}\)</span>
définie par :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(g : \mathbb{R} \longrightarrow \mathbb{R}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(W \in \mathbb{R}^{p+1}\)</span>, <span class="math notranslate nohighlight">\(W=\pa{w_1,\dots,w_{p+1}}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\forall x \in \mathbb{R}^p, \; f\pa{W,x} = g \pa { \sum_{i=1}^{p} w_i x_i + w_{p+1}}\)</span>
avec <span class="math notranslate nohighlight">\(x = \pa{x_1,\dots,x_p}\)</span></p></li>
</ul>
</div>
<p>Cette définition est inspirée du neurone biologique, les poids jouant le rôle
de synapses, le vecteur <span class="math notranslate nohighlight">\(x\)</span> celui des <em>entrées</em>
et <span class="math notranslate nohighlight">\(W\)</span> celui des <em>coefficients</em> ou <em>poids</em>.
Le coefficient <span class="math notranslate nohighlight">\(w_{p+1}\)</span> est appelé le <em>biais</em> et souvent noté <span class="math notranslate nohighlight">\(b\)</span>.
La fonction <em>g</em> est appelée <em>fonction de transfert</em> ou <em>fonction de seuil</em>.</p>
<div class="admonition-mathdef admonition" id="indexmathe-Figure0">
<div class="docutils container">
</div>
<p class="admonition-title" id="fig-nn-neurone">Figure F1 : neurone graphique</p>
<div class="math notranslate nohighlight">
\begin{picture}(100,80)(0,0)
\put(10,0)  {\circle{20}}
\put(10,25) {\circle{20}}
\put(10,50) {\circle{20}}

\put(10,0)  {\makebox(3,3){$x_1$}}
\put(10,25) {\makebox(3,3){$x_i$}}
\put(10,50) {\makebox(3,3){$x_p$}}

\put(80,25) {\circle{35}}
\put(78,25) {\makebox(6,3){$\;y \overset{f}{\rightarrow} z$}}

\put(20,25) {\line(1,0){43}}
\drawline(20,0)(63,25)
\drawline(20,50)(63,25)

\put(30,50)  {\makebox(3,3){$w_p$}}
\put(30,18)  {\makebox(3,3){$w_i$}}
\put(30,-2)  {\makebox(3,3){$w_1$}}

\put(48,20)  {\makebox(3,3){$\sum$}}

\put(50,-20)  {\circle{20}}
\put(50,-20)  {\makebox(3,3){$1$}}
\drawline(50,-10)(63,25)
\put(50,5)  {\makebox(3,3){$b$}}

\end{picture}</div><p>Le vecteur <span class="math notranslate nohighlight">\(\left(  x_1,...,x_p\right) \in \mathbb{R}^p\)</span>
joue le rôle des <em>entrées</em>.
<span class="math notranslate nohighlight">\(y\)</span> est appelé parfois le <em>potentiel</em>.
<span class="math notranslate nohighlight">\(y=\sum_{i=1}^{p} w_ix_i+b\)</span>.
<span class="math notranslate nohighlight">\(z\)</span> est appelée la sortie du neurone.
<span class="math notranslate nohighlight">\(f\)</span> est appelée la fonction de transfert ou de seuil.
<span class="math notranslate nohighlight">\(z=f \pa{y} = f \pa {   \sum_{i=1}^{p} w_ix_i+b }\)</span>.</p>
</div>
<p>La réprésentation <a class="reference internal" href="#fig-nn-neurone"><span class="std std-ref">graphique</span></a> est plus souvent
celle qu’on retient. Ce schéma est également plus proche de sa définition
biologique et dissocie mieux les rôles non symétriques
des entrées et des poids. Des exemples de fonctions de transfert
sont donnés par la table qui suit.
Les plus couramment utilisées sont les fonctions linéaire et sigmoïde.</p>
<div class="pst-scrollable-table-container"><table class="table-hover table">
<thead>
<tr class="row-odd"><th class="head"><p>exemples de fonction de transfert ou de seuil</p></th>
<th class="head"><p>expression</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>escalier</p></td>
<td><p><span class="math notranslate nohighlight">\(1_{\left[  0,+\infty\right[  }\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>linéaire</p></td>
<td><p><span class="math notranslate nohighlight">\(x\)</span></p></td>
</tr>
<tr class="row-even"><td><p>sigmoïde entre <span class="math notranslate nohighlight">\(\cro{0,1}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\dfrac{1}{1+e^{-x}}\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>sigmoïde entre <span class="math notranslate nohighlight">\(\cro{-1,1}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(1-\dfrac{2}{1+e^{x}}\)</span></p></td>
</tr>
<tr class="row-even"><td><p>normale</p></td>
<td><p><span class="math notranslate nohighlight">\(e^{-\frac{x^{2}}{2}}\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>exponentielle</p></td>
<td><p><span class="math notranslate nohighlight">\(e^{x}\)</span></p></td>
</tr>
<tr class="row-even"><td><p>relu</p></td>
<td><p><span class="math notranslate nohighlight">\(x \indicatrice{x \supegal 0}\)</span></p></td>
</tr>
</tbody>
</table>
</div>
<p>La plupart des fonctions utilisées sont dérivables et cette propriété
s’étend à tout assemblage de neurones, ce qui permet d’utiliser
l’algorithme de rétropropagation découvert par
<a class="reference internal" href="rn_biblio.html#rumelhart1986" id="id1"><span>[Rumelhart1986]</span></a>.
Ce dernier permet le calcul de la dérivée ouvre ainsi les portes
des méthodes d’optimisation basées sur cette propriété.
La fonction <a class="reference external" href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)">relu</a> a progressivement remplacé la fonction <em>sigmoïde</em>
sur les couches cachées car elle est non linéaire et
beaucoup plus rapide à calculer.</p>
</section>
<section id="une-couche-de-neurones">
<h2>Une couche de neurones<a class="headerlink" href="#une-couche-de-neurones" title="Lien vers cette rubrique">#</a></h2>
<div class="admonition-mathdef admonition" id="indexmathe-Définition1">
<div class="docutils container">
</div>
<p class="admonition-title" id="rn-definition-couche-neurone-1">Définition D2 : couche de neurones</p>
<p>Soit <span class="math notranslate nohighlight">\(p\)</span> et <span class="math notranslate nohighlight">\(n\)</span> deux entiers naturels,
on note <span class="math notranslate nohighlight">\(W \in \mathbb{R}^{n\pa{p+1}} = \pa{W_1,\dots,W_n}\)</span>
avec <span class="math notranslate nohighlight">\(\forall i \in \intervalle{1}{n}, \; W_i \in \mathbb{R}^{p+1}\)</span>.
Une couche de <span class="math notranslate nohighlight">\(n\)</span> neurones et <span class="math notranslate nohighlight">\(p\)</span> entrées est une fonction :</p>
<div class="math notranslate nohighlight">
\[F : \mathbb{R}^{n\pa{p+1}} \times \mathbb{R}^p \longrightarrow \mathbb{R}^n\]</div>
<p>vérfifiant :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\forall i \in \intervalle {1}{n}, \; f_i\)</span> est un neurone.</p></li>
<li><p><span class="math notranslate nohighlight">\(\forall W \in \mathbb{R}^{n\pa{p+1}} \times \mathbb{R}^p, \; F\pa{W,x} = \pa {f_1\pa{W_1,x}, \dots, f_n\pa{W_n,x}}\)</span></p></li>
</ul>
</div>
<p>Une couche de neurones représente la juxtaposition de plusieurs neurones
partageant les mêmes entrées mais ayant chacun leur propre vecteur de
coefficients et leur propre sortie.</p>
</section>
<section id="un-reseau-de-neurones-le-perceptron">
<h2>Un réseau de neurones : le perceptron<a class="headerlink" href="#un-reseau-de-neurones-le-perceptron" title="Lien vers cette rubrique">#</a></h2>
<div class="admonition-mathdef admonition" id="indexmathe-Définition2">
<div class="docutils container">
</div>
<p class="admonition-title" id="rn-definition-perpception-1">Définition D3 : réseau de neurones multi-couches ou perceptron</p>
<p>Un réseau de neurones multi-couches à <span class="math notranslate nohighlight">\(n\)</span> sorties,
<span class="math notranslate nohighlight">\(p\)</span> entrées et <span class="math notranslate nohighlight">\(C\)</span> couches est une liste de couches
<span class="math notranslate nohighlight">\(\vecteur{C_1}{C_C}\)</span> connectées les unes aux autres de telle sorte que :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\forall i \in \intervalle {1}{C}\)</span>,
chaque couche <span class="math notranslate nohighlight">\(C_i\)</span> possède <span class="math notranslate nohighlight">\(n_i\)</span> neurones et <span class="math notranslate nohighlight">\(p_i\)</span> entrées</p></li>
<li><p><span class="math notranslate nohighlight">\(\forall i \in \intervalle{1}{C-1}, \; n_i = p_{i+1}\)</span>,
de plus <span class="math notranslate nohighlight">\(p_1 = p\)</span> et <span class="math notranslate nohighlight">\(n_C = n\)</span></p></li>
</ul>
<p>Les coefficients de la couche <span class="math notranslate nohighlight">\(C_i\)</span> sont notés
<span class="math notranslate nohighlight">\(\pa {W_1^i,\dots,W_{n_i}^i}\)</span>, cette couche définit une fonction
<span class="math notranslate nohighlight">\(F_i\)</span>.
Soit la suite <span class="math notranslate nohighlight">\(\pa{Z_i}_{0\infegal i \infegal C}\)</span> définie par :</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{l}
Z_0 \in \mathbb{R}^p \\
\forall i \in \intervalle{1}{C}, \; Z_i = F_i \pa {W_1^i,\dots,W_{n_i}^i,Z_{i-1}}\end{array}\end{split}\]</div>
<p>On pose <span class="math notranslate nohighlight">\(M = M = \sum_{i=1}^{C}n_i\pa{p_i+1}\)</span>,
le réseau de neurones ainsi défini est une fonction <span class="math notranslate nohighlight">\(F\)</span> telle que :</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{lrll}
F : &amp; \mathbb{R} ^ M \times \mathbb{R}^p &amp; \longrightarrow &amp; \mathbb{R}^n \\
    &amp; \pa{W,Z_0} &amp; \longrightarrow &amp; Z_C
\end{array}\end{split}\]</div>
</div>
<div class="admonition-mathdef admonition" id="indexmathe-Figure1">
<div class="docutils container">
</div>
<p class="admonition-title" id="figure-peceptron-fig">Figure F2 : Modèle du perceptron multi-couche (multi-layer perceptron, MLP)</p>
<a class="reference internal image-reference" href="../../_images/rn_gradient.png"><img alt="../../_images/rn_gradient.png" src="../../_images/rn_gradient.png" style="width: 300px;" /></a>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\vecteur{x_1}{x_p}\)</span> : entrées</p></li>
<li><p><span class="math notranslate nohighlight">\(C_i\)</span> nombre de neurones sur la couche <span class="math notranslate nohighlight">\(i\)</span>, <span class="math notranslate nohighlight">\(C_0 = p\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(z_{c,i}\)</span> sortie du neurone <span class="math notranslate nohighlight">\(i\)</span>, de la couche <span class="math notranslate nohighlight">\(c\)</span>, par extension, <span class="math notranslate nohighlight">\(z_{0,i} = x_i\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(y_{c,i}\)</span> potentiel du neurone <span class="math notranslate nohighlight">\(i\)</span> de la couche <span class="math notranslate nohighlight">\(c\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(w_{c,i,j}\)</span> coefficient associé à l’entrée <span class="math notranslate nohighlight">\(j\)</span> du neurone <span class="math notranslate nohighlight">\(i\)</span> de la couche <span class="math notranslate nohighlight">\(c\)</span>,</p></li>
<li><p><span class="math notranslate nohighlight">\(b_{c,i}\)</span> biais du neurone <span class="math notranslate nohighlight">\(i\)</span> de la couche <span class="math notranslate nohighlight">\(c\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(f_{c,i}\)</span> fonction de seuil du neurone <span class="math notranslate nohighlight">\(i\)</span> de la couche <span class="math notranslate nohighlight">\(c\)</span></p></li>
</ul>
</div>
<p>On note <span class="math notranslate nohighlight">\(W_c\)</span> la matrice des poids associée à la couche <span class="math notranslate nohighlight">\(c\)</span>.
De la même manière, <span class="math notranslate nohighlight">\(B_c\)</span> est le vecteur des biais associée à la couche <span class="math notranslate nohighlight">\(c\)</span>,
<span class="math notranslate nohighlight">\(Z_c\)</span>, <span class="math notranslate nohighlight">\(Y_c\)</span> sont les objets vectoriels correspondant.
On considère que les entrées forment la couche <span class="math notranslate nohighlight">\(C_0\)</span> de
manière à simplifier les écritures. Ainsi,
chaque couche <span class="math notranslate nohighlight">\(C_i\)</span> du perceptron a pour entrées les sorties
de la couche <span class="math notranslate nohighlight">\(C_{i-1}\)</span>. Cette définition est plus facile
à illustrer qu’à énoncer (voir <a class="reference internal" href="#figure-peceptron-fig"><span class="std std-ref">Modèle du perceptron</span></a>)
et rappelle le rôle non symétrique des entrées et des poids.
Le mécanisme qui permet de calculer les sorties d’un réseau de neurones
sachant ses poids est appelé <em>propagation</em>.</p>
<div class="admonition-mathdef admonition" id="indexmathe-Algorithme0">
<div class="docutils container">
</div>
<p class="admonition-title" id="algo-propagation">Algorithme A1 : Propagation</p>
<p>Cet algorithme s’applique à un réseau de neurones vérifiant la
définition du <a class="reference internal" href="#rn-definition-perpception-1"><span class="std std-ref">perceptron</span></a>. Il s’agit
de calculer les sorties de ce réseau connaissant ses poids
<span class="math notranslate nohighlight">\(\pa{w_{c,i,j}}\)</span> et ses entrées <span class="math notranslate nohighlight">\(\pa{x_j}\)</span>.</p>
<div class="line-block">
<div class="line"><span class="math notranslate nohighlight">\(Z_c \longleftarrow X\)</span></div>
</div>
<p>Vient ensuite le calcul itératif de la suite
<span class="math notranslate nohighlight">\(\pa{Z_c}_{1 \infegal c \infegal C}\)</span> :</p>
<div class="line-block">
<div class="line">for c in <span class="math notranslate nohighlight">\(1..C\)</span> :</div>
<div class="line-block">
<div class="line"><span class="math notranslate nohighlight">\(Y_c \longleftarrow  W_c Z_{c-1} + B_c\)</span></div>
<div class="line"><span class="math notranslate nohighlight">\(Z_c \longleftarrow F\pa { Y_c }\)</span></div>
</div>
</div>
</div>
<p>Le nombre de couches d’un réseau de neurones n’est pas limité.
Les réseaux de deux couches (une couche pour les entrées, une couche de sortie)
sont rarement utilisés. Trois couches sont nécessaires (une couche pour
les entrées, une couche dite <em>cachée</em>, une couche de sortie) pour construire des
modèles avec une propriété intéressante de <a class="reference internal" href="rn_4_densite.html#theoreme-densite"><span class="std std-ref">densité</span></a>.</p>
</section>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="rn.html"
       title="page précédente">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">précédent</p>
        <p class="prev-next-title">Réseaux de neurones</p>
      </div>
    </a>
    <a class="right-next"
       href="rn_2_reg.html"
       title="page suivante">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">suivant</p>
        <p class="prev-next-title">La régression</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Sur cette page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#un-neurone">Un neurone</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#une-couche-de-neurones">Une couche de neurones</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#un-reseau-de-neurones-le-perceptron">Un réseau de neurones : le perceptron</a></li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">

  <div class="tocsection sourcelink">
    <a href="../../_sources/c_ml/rn/rn_1_def.rst">
      <i class="fa-solid fa-file-lines"></i> Montrer le code source
    </a>
  </div>
</div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2016-2024, Xavier Dupré.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Créé en utilisant <a href="https://www.sphinx-doc.org/">Sphinx</a> 8.0.2.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  Construit avec le <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">Thème PyData Sphinx</a> 0.15.4.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>