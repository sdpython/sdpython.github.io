
<!DOCTYPE html>


<html lang="fr" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Descente de gradient &#8212; Documentation mlstatpy 0.4.0</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=365ca57ee442770a23c6" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css?v=eafc0fe6" />
    <link rel="stylesheet" type="text/css" href="../../_static/plot_directive.css?v=7f9a90b1" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css?v=61a4c737" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=365ca57ee442770a23c6" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=365ca57ee442770a23c6" />
  <script src="../../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=365ca57ee442770a23c6"></script>

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js?v=9db00da4"></script>
    <script src="../../_static/doctools.js?v=888ff710"></script>
    <script src="../../_static/sphinx_highlight.js?v=4825356b"></script>
    <script src="../../_static/translations.js?v=d99ca74e"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'c_ml/rn/rn_5_newton';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Recherche" href="../../search.html" />
    <link rel="next" title="Apprentissage d’un réseau de neurones" href="rn_6_apprentissage.html" />
    <link rel="prev" title="Démonstration du théorème de la densité des réseaux de neurones" href="rn_4_densite.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="fr"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Passer au contenu principal</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
<div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
    <span class="fa-solid fa-bars"></span>
  </label>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/project_ico.png" class="logo__image only-light" alt="Documentation mlstatpy 0.4.0 - Home"/>
    <script>document.write(`<img src="../../_static/project_ico.png" class="logo__image only-dark" alt="Documentation mlstatpy 0.4.0 - Home"/>`);</script>
  
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item"><nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Navigation du site">
    Navigation du site
  </p>
  <ul class="bd-navbar-elements navbar-nav">
    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../c_clus/index.html">
                        Clustering
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="../index.html">
                        Non linéaire
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../index_reg_lin.html">
                        Régression linéaire
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../index_reg_log.html">
                        Régression logistique
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../c_nlp/index.html">
                        NLP
                      </a>
                    </li>
                
            <li class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-controls="pst-nav-more-links">
                    More
                </button>
                <ul id="pst-nav-more-links" class="dropdown-menu">
                    
                    <li class="nav-item">
                      <a class="nav-link dropdown-item nav-internal" href="../../c_metric/index.html">
                        Métriques
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link dropdown-item nav-internal" href="../../c_algo/index.html">
                        Algorithmes
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link dropdown-item nav-internal" href="../../c_garden/index.html">
                        Pérégrinations
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link dropdown-item nav-internal" href="../../api/index.html">
                        API
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link dropdown-item nav-internal" href="../../i_ex.html">
                        Examples
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link dropdown-item nav-internal" href="../../defthe_index.html">
                        Listes des définitions et théorèmes
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link dropdown-item nav-internal" href="../../auto_examples/index.html">
                        Gallery of examples
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link dropdown-item nav-internal" href="../../notebooks/index.html">
                        Galleries de notebooks
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link dropdown-item nav-internal" href="../../glossary.html">
                        Glossary
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link dropdown-item nav-internal" href="../../CHANGELOGS.html">
                        Change Logs
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link dropdown-item nav-internal" href="../../license.html">
                        License
                      </a>
                    </li>
                
                </ul>
            </li>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          
 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Recherche" aria-label="Recherche" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Recherche</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script>
        </div>
      
      
        <div class="navbar-item">
<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="clair/sombre" aria-label="clair/sombre" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">
 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Recherche" aria-label="Recherche" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Recherche</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script>
    </div>
  

  
    <label class="sidebar-toggle secondary-toggle" for="__secondary" tabindex="0">
      <span class="fa-solid fa-outdent"></span>
    </label>
  
</div>

    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          <div class="navbar-item"><nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Navigation du site">
    Navigation du site
  </p>
  <ul class="bd-navbar-elements navbar-nav">
    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../c_clus/index.html">
                        Clustering
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="../index.html">
                        Non linéaire
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../index_reg_lin.html">
                        Régression linéaire
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../index_reg_log.html">
                        Régression logistique
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../c_nlp/index.html">
                        NLP
                      </a>
                    </li>
                
            <li class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-controls="pst-nav-more-links-2">
                    More
                </button>
                <ul id="pst-nav-more-links-2" class="dropdown-menu">
                    
                    <li class="nav-item">
                      <a class="nav-link dropdown-item nav-internal" href="../../c_metric/index.html">
                        Métriques
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link dropdown-item nav-internal" href="../../c_algo/index.html">
                        Algorithmes
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link dropdown-item nav-internal" href="../../c_garden/index.html">
                        Pérégrinations
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link dropdown-item nav-internal" href="../../api/index.html">
                        API
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link dropdown-item nav-internal" href="../../i_ex.html">
                        Examples
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link dropdown-item nav-internal" href="../../defthe_index.html">
                        Listes des définitions et théorèmes
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link dropdown-item nav-internal" href="../../auto_examples/index.html">
                        Gallery of examples
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link dropdown-item nav-internal" href="../../notebooks/index.html">
                        Galleries de notebooks
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link dropdown-item nav-internal" href="../../glossary.html">
                        Glossary
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link dropdown-item nav-internal" href="../../CHANGELOGS.html">
                        Change Logs
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link dropdown-item nav-internal" href="../../license.html">
                        License
                      </a>
                    </li>
                
                </ul>
            </li>
            
  </ul>
</nav></div>
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="clair/sombre" aria-label="clair/sombre" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item"><nav class="bd-docs-nav bd-links"
     aria-label="Navigation de la section">
  <p class="bd-links__title" role="heading" aria-level="1">Navigation de la section</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="rn.html">Réseaux de neurones</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="rn_1_def.html">Définition des réseaux de neurones multi-couches</a></li>
<li class="toctree-l2"><a class="reference internal" href="rn_2_reg.html">La régression</a></li>
<li class="toctree-l2"><a class="reference internal" href="rn_3_clas.html">La classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="rn_4_densite.html">Démonstration du théorème de la densité des réseaux de neurones</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Descente de gradient</a></li>
<li class="toctree-l2"><a class="reference internal" href="rn_6_apprentissage.html">Apprentissage d’un réseau de neurones</a></li>
<li class="toctree-l2"><a class="reference internal" href="rn_7_clas2.html">Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="rn_8_prol.html">Prolongements</a></li>
<li class="toctree-l2"><a class="reference internal" href="rn_9_auto.html">Analyse en composantes principales (ACP) et Auto Encoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="rn_biblio.html">Bibliographie</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../kppv.html">Classification à l’aide des plus proches voisins</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../missing_values_mf.html">Liens entre factorisation de matrices, ACP, k-means</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/ml/mf_acp.html">Factorisation et matrice et ACP</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/ml/valeurs_manquantes_mf.html">Valeurs manquantes et factorisation de matrices</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/ml/neural_tree.html">Un arbre de décision en réseaux de neurones</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/ml/neural_tree_onnx.html">NeuralTreeNet et ONNX</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/ml/neural_tree_cost.html">NeuralTreeNet et coût</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Fil d'Ariane">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../index.html" class="nav-link" aria-label="Accueil">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../index.html" class="nav-link">Non linéaire</a></li>
    
    
    <li class="breadcrumb-item"><a href="rn.html" class="nav-link">Réseaux de neurones</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">Descente de gradient</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section id="descente-de-gradient">
<h1>Descente de gradient<a class="headerlink" href="#descente-de-gradient" title="Lien permanent vers cette rubrique">#</a></h1>
<nav class="contents local" id="sommaire">
<ul class="simple">
<li><p><a class="reference internal" href="#algorithme-et-convergence" id="id4">Algorithme et convergence</a></p></li>
<li><p><a class="reference internal" href="#calcul-du-gradient-ou-retropropagation" id="id5">Calcul du gradient ou <em>rétropropagation</em></a></p></li>
</ul>
</nav>
<p>Lorsqu’un problème d’optimisation n’est pas soluble de manière déterministe,
il existe des algorithmes permettant de trouver une solution approchée
à condition toutefois que la fonction à maximiser ou minimiser soit dérivable,
ce qui est le cas des réseaux de neurones. Plusieurs variantes seront proposées
regroupées sous le terme de descente de gradient.
Quelques lectures :</p>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/abs/1609.04747">An overview of gradient descent optimization algorithms</a></p></li>
<li><p><a class="reference external" href="http://www.wildml.com/2015/09/implementing-a-neural-network-from-scratch/">Implementing a Neural Network from Scratch in Python – An Introduction</a></p></li>
</ul>
<section id="algorithme-et-convergence">
<span id="optimisation-newton"></span><h2><a class="toc-backref" href="#id4" role="doc-backlink">Algorithme et convergence</a><a class="headerlink" href="#algorithme-et-convergence" title="Lien permanent vers cette rubrique">#</a></h2>
<p>Soit <img class="math" src="../../_images/math/93ad55f7ee64736abc243c506afa07c007a8bf7d.svg" alt="g : \R \dans \R"/> une fonction dérivable dont il faut trouver
<img class="math" src="../../_images/math/acb516cf7cffd3e347e4eac7fc62d453cf6771f2.svg" alt="\overset{*}{x} = \underset{x \in \R}{\arg \min} \; g\pa{x}"/>,
le schéma suivant illustre la méthode de descente de gradient
dans le cas où <img class="math" src="../../_images/math/4baf22cfd2e365ff213bc0428f4529fa4a0125dc.svg" alt="g \pa{x} = x^2"/>.</p>
<img alt="../../_images/rn_courbe.png" src="../../_images/rn_courbe.png" />
<p>On note <img class="math" src="../../_images/math/2a6647c190c1f3882346f640f09bf80ef93c8c51.svg" alt="x_{t}"/> l’abscisse à l’itération <img class="math" src="../../_images/math/09c7628f51842c683db31bd6826cff8cc447ece3.svg" alt="t"/>.
On note <img class="math" src="../../_images/math/caf9cd8c8d8e1d2b95e010576b552490aa24a652.svg" alt="\dfrac{\partial g\left(  x_{t}\right)  }{\partial x}"/> le
gradient de <img class="math" src="../../_images/math/7a54a90681e6eff57582d309653eabd2848813ce.svg" alt="g\left(  x\right)  =x^{2}"/>.
L’abscisse à l’itération <img class="math" src="../../_images/math/20a0ef7ca257843f3a625036da7c31d4a697742d.svg" alt="t+1"/> sera
<img class="math" src="../../_images/math/4e962ef2ec23db8d4423dcb0ec7fe7cab07e0891.svg" alt="x_{t+1}=x_{t}-\varepsilon_{t}\left[  \dfrac{\partial g\left(  x_{t}\right)}{\partial x}\right]"/>.
<img class="math" src="../../_images/math/cc414f6c1f459da7b319af86de89b346382b7ad7.svg" alt="\varepsilon_{t}"/> est le pas de gradient à l’itération <img class="math" src="../../_images/math/09c7628f51842c683db31bd6826cff8cc447ece3.svg" alt="t"/>.</p>
<p>On suppose maintenant que <img class="math" src="../../_images/math/3a8d8bad8d0f9dcf76fdcc134f09a2a698f2d77f.svg" alt="g"/> est une fonction dérivable
<img class="math" src="../../_images/math/abbce58de944d7d4fd76e55e8083978549ebfbb7.svg" alt="g : \R^q \dans \R"/> dont il faut trouver le minimum, le théorème suivant démontre
la convergence de l’algorithme de descente de gradient à condition
que certaines hypothèses soient vérifiées. Une généralisation de ce théorème est présentée dans
<a class="reference internal" href="rn_biblio.html#driancourt1996" id="id1"><span>[Driancourt1996]</span></a>.</p>
<div class="admonition-mathdef admonition" id="indexmathe-Théorème0">
<div class="docutils container">
</div>
<p class="admonition-title" id="theoreme-convergence">Théorème T1 : convergence de la méthode de Newton</p>
<p><a class="reference internal" href="rn_biblio.html#bottou1991" id="id2"><span>[Bottou1991]</span></a></p>
<p>Soit une fonction continue <img class="math" src="../../_images/math/74cea61bca10f452c94895b7d775297a7d08a5ae.svg" alt="g : W \in \R^M \dans \R"/>
de classe <img class="math" src="../../_images/math/93ddbae200e62b8dc66b770e92f0d5e908c7c773.svg" alt="C^{1}"/>.
On suppose les hypothèses suivantes vérifiées :</p>
<ul class="simple">
<li><p><strong>H1</strong> : <img class="math" src="../../_images/math/a1226b030410a971fa6cf502ee8029ae93386fb1.svg" alt="\underset{W\in \R^q}{\arg\min} \;
g\left(  W\right) =\left\{  W^{\ast}\right\}"/>
est un singleton</p></li>
<li><p><strong>H2</strong> : <img class="math" src="../../_images/math/cd5c8eeb11c1af5fd5a8957eef0148c34c6fbcbe.svg" alt="\forall\varepsilon&gt;0, \; \underset{\left|  W-W^{\ast}\right|
&gt;\varepsilon}{\inf}\left[  \left(  W-W^{\ast}\right)  ^{\prime}.\nabla
g\left(  W\right)  \right]  &gt;0"/></p></li>
<li><p><strong>H3</strong> : <img class="math" src="../../_images/math/9a624a3daf2cde1f80c169e7e1773f0cfac1e6c5.svg" alt="\exists\left(  A,B\right)  \in \R^2"/> tels que <img class="math" src="../../_images/math/83284b2417053a8cd16ef736d2d0a7fcdc7e28cf.svg" alt="\forall W\in\R^p,\; \left\|
\nabla g\left( W\right) \right\| ^{2}\leqslant A^{2}+B^{2}\left\|  W-W^{\ast}\right\|  ^{2}"/></p></li>
<li><p><strong>H4</strong> : la suite <img class="math" src="../../_images/math/ea1808cb77cfa4b21d651c17a0cf7af89a84884e.svg" alt="\left(  \varepsilon_{t}\right)_{t\geqslant0}"/> vérifie,
<img class="math" src="../../_images/math/c1e47cb46110d0937fc63db1971e2465610d5038.svg" alt="\forall t&gt;0, \; \varepsilon_{t}\in \R_{+}^{\ast}"/>
et <img class="math" src="../../_images/math/4f1caf6b2d6ac86464b714a3b552a3ea5b252b05.svg" alt="\sum_{t\geqslant 0}\varepsilon_{t}=+\infty"/>,
<img class="math" src="../../_images/math/1752b39bb5ef539b1712f0b87143b1d471a3ad29.svg" alt="\sum_{t\geqslant 0}\varepsilon_{t}^{2}&lt;+\infty"/></p></li>
</ul>
<p>Alors la suite <img class="math" src="../../_images/math/f0c4da8be421ec088ea3f128f120849a31816493.svg" alt="\left(  W_{t}\right)  _{t\geqslant 0}"/> construite de la manière suivante
<img class="math" src="../../_images/math/9726acd3a0008bfd971727cdd3979c2f6df943ad.svg" alt="W_{0} \in \R^M"/>, <img class="math" src="../../_images/math/1cefa8fa382334e8e056c94f19eff3e6c73cf1f4.svg" alt="\forall t\geqslant0"/> :
<img class="math" src="../../_images/math/5fe3fdecbfaa999a08fde37c971f6efa69233f40.svg" alt="W_{t+1}=W_{t}-\varepsilon_{t}\,\nabla g\left(  W_{t}\right)"/>
vérifie <img class="math" src="../../_images/math/9b28ad84d9798d47636e802b69fbf736d1e380fb.svg" alt="\lim_{ t \dans+\infty}W_{t}=W^{\ast}"/>.</p>
</div>
<p>L’hypothèse <strong>H1</strong> implique que le minimum de la fonction <img class="math" src="../../_images/math/3a8d8bad8d0f9dcf76fdcc134f09a2a698f2d77f.svg" alt="g"/>
est unique et l’hypothèse <strong>H2</strong> implique que le demi-espace défini par
l’opposé du gradient contienne toujours le minimum de la fonction <img class="math" src="../../_images/math/3a8d8bad8d0f9dcf76fdcc134f09a2a698f2d77f.svg" alt="g"/>.
L’hypothèse <strong>H3</strong> est vérifiée pour une fonction sigmoïde, elle l’est donc aussi pour toute somme finie
de fonctions sigmoïdes que sont les réseaux de neurones à une couche cachée.</p>
<p><strong>Démonstration du théorème</strong></p>
<p><em>Partie 1</em></p>
<p>Soit la suite <img class="math" src="../../_images/math/307f2ae1a78b8b6021512b1529a940e771a6717b.svg" alt="u_{t}=\ln\left(  1+\varepsilon_{t}^{2}x^{2}\right)"/>
avec <img class="math" src="../../_images/math/3af17315b6b2c13ae947ea3a46445e9eb441e477.svg" alt="x\in\R"/>, comme <img class="math" src="../../_images/math/60acecf94ec59fc40fabb64cc4c5d78ff4014cae.svg" alt="\sum_{t\geqslant 0} \varepsilon_{t}^{2} &lt; +\infty, \;
u_{t}\thicksim\varepsilon_{t}^{2}x^{2}"/>, on a <img class="math" src="../../_images/math/344ed507f13ae087d1f1701764fa15671f2f66e8.svg" alt="\sum_{t\geqslant 0} u_{t} &lt; +\infty"/>.</p>
<p>Par conséquent, si <img class="math" src="../../_images/math/c5a8c580cfeb29c37949aec3630236cdc9ee6138.svg" alt="v_{t}=e^{u_{t}}"/> alors <img class="math" src="../../_images/math/c0f35fa9eecb08cc43130cf9777ecb199234d9a9.svg" alt="\prod_{t=1}^T v_{t}\overset{T \rightarrow \infty}{\longrightarrow}D \in \R"/>.</p>
<p><em>Partie 2</em></p>
<p>On pose <img class="math" src="../../_images/math/cd0cfc0729c0ac6a2935a14d378d4923d2378078.svg" alt="h_{t}=\left\|  W_{t}-W^{\ast}\right\|  ^{2}"/>.
Donc :</p>
<div class="math" id="equation-equation-convergence-un">
<p><span class="eqno">(1)<a class="headerlink" href="#equation-equation-convergence-un" title="Lien permanent vers cette équation">#</a></span><img src="../../_images/math/962d6cdb16b649e49f10f32d407286f5c83a3540.svg" alt="\begin{eqnarray}
h_{t+1} -h_{t} &amp;=&amp;\left\|  W_{t}-\varepsilon_{t}\,\nabla g\left( W_{t}\right) -W^{\ast }\right\|
              ^{2}-\left\|W_{t}-W^{\ast}\right\| ^{2}
\end{eqnarray}"/></p>
</div><p>Par conséquent :</p>
<div class="math">
<p><img src="../../_images/math/86dd893526986ec4c2c6af8cd97c4e1e9e2ddcc5.svg" alt="h_{t+1}-h_{t}=-2\varepsilon_{t}\underset{&gt;0} {\underbrace{\left(  W_{t}-W^{\ast}\right)
 ^{\prime}\,\nabla g\left( W_{t}\right)
}}+\varepsilon_{t}^{2}\,\left\|  \,\nabla C\left( W_{t}\right) \right\|
^{2}\leqslant\varepsilon_{t}^{2}\,\left\|  \,\nabla g\left( W_{t}\right)
\right\|  ^{2}\leqslant\varepsilon_{t}^{2}\,\left(  A^{2}  +B^{2}h_{t}\right)"/></p>
</div><p>D’où :</p>
<div class="math">
<p><img src="../../_images/math/93a349310137477a9f1442fc085a5b3818db8c68.svg" alt="h_{t+1}-h_{t}\left(  1+\varepsilon_{t}^{2}B^{2}\right) \leqslant\varepsilon_{t}^{2}\,A^{2}"/></p>
</div><p>On pose <img class="math" src="../../_images/math/5cf5de79244d0859605164b550722d8fd298e5b7.svg" alt="\pi_{t}= \prod_{k=1}^t \left(  1+\varepsilon_{k}^{2}B^{2}\right)  ^{-1}"/>
alors en multipliant des deux côtés par <img class="math" src="../../_images/math/c4d50fe904829e3734946b723cb1b42cd1d743af.svg" alt="\pi_{t+1}"/>, on obtient :</p>
<div class="math">
<p><img src="../../_images/math/d3f022661e34a761ec2a4f128b35aced2ea2f325.svg" alt="\begin{array}{rcl}
\pi_{t+1}h_{t+1}-\pi_{t}h_{t} &amp;\leqslant&amp; \varepsilon_{t}^{2}\,A^{2}\pi_{t+1}\\
\text{d'où }\pi_{q+1}h_{q+1}-\pi_{p}h_{p} &amp;\leqslant&amp;
                \sum_{t=p}^q \varepsilon_{t}^{2}\,A^{2}\pi_{t+1} \leqslant
\sum_{t=p}^{q} \varepsilon_{t}^{2} \, A^{2}\Pi  \leqslant \sum_{t=p}^{q} \varepsilon_{t}^{2}\,A^{2}\Pi
             \underset{t \longrightarrow
\infty}{\longrightarrow} 0
\end{array}"/></p>
</div><p>Comme la série <img class="math" src="../../_images/math/4b7842c74eff1e8fe549330c67c2f0d1e2f7d7be.svg" alt="\sum_t \pa{\pi_{t+1}h_{t+1}-\pi_{t}h_{t}}"/> vérifie le critère de Cauchy, elle est convergente. Par conséquent :</p>
<div class="math">
<p><img src="../../_images/math/5c858cb478a6bcb37ec3d7d04ada5d4f055d9e5c.svg" alt="\underset{q\rightarrow\infty}{\lim}\pi_{q+1}h_{q+1}=0=\underset{q\rightarrow \infty}{\lim}\Pi h_{q+1}"/></p>
</div><p>D’où <img class="math" src="../../_images/math/751df7f1504b49f6c731ec0e53a7bdd9c3b6e487.svg" alt="\underset{q\rightarrow\infty}{\lim}h_{q}=0"/>.</p>
<p><em>Partie 3</em></p>
<p>La série <img class="math" src="../../_images/math/9ee3901c5b772d1d9cf05408d663ef2874aabe1f.svg" alt="\sum_t\pa{h_{t+1}-h_{t}}"/> est convergente car <img class="math" src="../../_images/math/d55a60812a31e336b4bf8fd86057c384843e4252.svg" alt="\Pi h_t \sim \pi_t h_t"/>.
<img class="math" src="../../_images/math/bee7c9d82230f68e02c032de2f0cfd969c9048a6.svg" alt="\sum_{t\geqslant0}\varepsilon_{t}^{2}\,\left\| \,\nabla g\left( W_{t}\right) \right\|  ^{2}"/>
l’est aussi (d’après <strong>H3</strong>).</p>
<p>D’après <a class="reference internal" href="#equation-equation-convergence-un">(1)</a>,
la série <img class="math" src="../../_images/math/e6723513c4ad0ed79e5e42ada33faeea093e1cfc.svg" alt="\sum_{t\geqslant 0}\varepsilon_{t}\left( W_{t}-W^{\ast }\right) ^{\prime} \,
\nabla g\left( W_{t}\right)"/> est donc convergente.
Or d’après les hypothèses <strong>H2</strong>, <strong>H4</strong>, elle ne peut l’être que si :</p>
<div class="math">
<p><img src="../../_images/math/e2ba2c96952c25e83830507a1f23765dec01c78c.svg" alt="\begin{eqnarray}
\underset{t\rightarrow\infty}{\lim}W_{t}&amp;=&amp;W^{\ast}
\end{eqnarray}"/></p>
</div><p>Si ce théorème prouve la convergence
de la méthode de Newton, il ne précise pas à quelle vitesse cette convergence
s’effectue et celle-ci peut parfois être très lente. Plusieurs variantes
ont été développées regroupées sous le terme de méthodes de quasi-Newton dans le but
d’améliorer la vitesse de convergence.</p>
<p>Ce théorème peut être étendu dans le cas où la fonction <img class="math" src="../../_images/math/3a8d8bad8d0f9dcf76fdcc134f09a2a698f2d77f.svg" alt="g"/>
n’a plus un seul minimum global mais plusieurs minima locaux (<a class="reference internal" href="rn_biblio.html#bottou1991" id="id3"><span>[Bottou1991]</span></a>),
dans ce cas, la suite <img class="math" src="../../_images/math/e04020f088afcb3079f52ce73c98181eba2bce00.svg" alt="\pa{W_{t}}"/> converge vers un mimimum local.
Dans le cas des réseaux de neurones, la fonction à optimiser est :</p>
<div class="math" id="equation-equation-fonction-erreur-g">
<p><span class="eqno">(2)<a class="headerlink" href="#equation-equation-fonction-erreur-g" title="Lien permanent vers cette équation">#</a></span><img src="../../_images/math/3999c975fbb87b2886ae455ab03773874f263327.svg" alt="\begin{eqnarray}
G\pa{W}   &amp;=&amp;   \sum_{i=1}^{N} e\pa {Y_{i}, \widehat{Y_{i}^W}}
                  =   \sum_{i=1}^{N} e\pa {Y_{i}, f \pa{W,X_{i}}} \nonumber
\end{eqnarray}"/></p>
</div><p>Dès que les fonctions de transfert ne sont pas linéaires,
il existe une multitude de minima locaux, ce nombre croissant avec celui des coefficients.</p>
</section>
<section id="calcul-du-gradient-ou-retropropagation">
<h2><a class="toc-backref" href="#id5" role="doc-backlink">Calcul du gradient ou <em>rétropropagation</em></a><a class="headerlink" href="#calcul-du-gradient-ou-retropropagation" title="Lien permanent vers cette rubrique">#</a></h2>
<p>Afin de minimiser la fonction <img class="math" src="../../_images/math/86a30eae2899d36dcee14ab62c5e4c8a68feed4d.svg" alt="G"/> décrite en <a class="reference internal" href="#equation-equation-fonction-erreur-g">(2)</a>,
l’algorithme de descente du gradient nécessite de calculer le gradient de
cette fonction <img class="math" src="../../_images/math/86a30eae2899d36dcee14ab62c5e4c8a68feed4d.svg" alt="G"/> qui est la somme des gradients <img class="math" src="../../_images/math/64d56f19776ae213076b68669aca623852fada2b.svg" alt="\partialfrac{e}{W}"/>
pour chaque couple <img class="math" src="../../_images/math/a8de9077442e02e179b58bb556da784983a74ff8.svg" alt="\pa{X_i,Y_i}"/> :</p>
<div class="math" id="equation-algo-retro-1">
<p><span class="eqno">(3)<a class="headerlink" href="#equation-algo-retro-1" title="Lien permanent vers cette équation">#</a></span><img src="../../_images/math/450b23541a846ab61c293f64867d40ae3cec2bd6.svg" alt="\begin{eqnarray}
\partialfrac{G}{W}\pa{W} &amp;=&amp; \sum_{i=1}^{N} \partialfrac{e\pa {Y_{i}, f \pa{W,X_{i}}}}{W} \nonumber\\
                         &amp;=&amp; \sum_{i=1}^{N} \sum_{k=1}^{C_C}
                                \partialfrac{e\pa {Y_{i}, f \pa{W,X_{i}}}}{z_{C,k}}
                                \partialfrac{z_{C,k}}{W} \nonumber
\end{eqnarray}"/></p>
</div><p>Les notations utilisées sont celles de la figure du <a class="reference internal" href="rn_1_def.html#figure-peceptron-fig"><span class="std std-ref">perceptron</span></a>.
Les résultats qui suivent sont pour <img class="math" src="../../_images/math/cb9ec97d6d1f083838199e221f70d3ca653cf8d5.svg" alt="X_i=X"/> donné appartenant à la suite
<img class="math" src="../../_images/math/146d79ee1ed6c74315411e2c3f72f53fe19ae507.svg" alt="\pa{X_i}"/>. On remarque tout d’abord que :</p>
<div class="math" id="equation-algo-retro-3">
<p><span class="eqno">(4)<a class="headerlink" href="#equation-algo-retro-3" title="Lien permanent vers cette équation">#</a></span><img src="../../_images/math/ee6ba3bce73b57c72b0582d536fe97f8d02d4c31.svg" alt="\begin{eqnarray}
\partialfrac{e}{w_{c,i,j}} \pa{W,X} &amp;=&amp;  z_{c-1,j} \partialfrac{e}{y_{c,i}} \pa{W,X} \nonumber \\
\partialfrac{e}{b_{c,i}} \pa{W,X}   &amp;=&amp; \partialfrac{e}{y_{c,i}} \pa{W,X} \nonumber
\end{eqnarray}"/></p>
</div><p>La rétropropagation du gradient consiste donc à calculer les termes :
<img class="math" src="../../_images/math/8163ff0ff7dcce88f6de58cd4ff293bc83e5e7e4.svg" alt="\partialfrac{e}{y_{.,.}}\pa{W,X}"/>
puisque le gradient s’en déduit facilement. La dernière couche du réseau de neurones nous permet d’obtenir :</p>
<div class="math" id="equation-algo-retro-4">
<p><span class="eqno">(5)<a class="headerlink" href="#equation-algo-retro-4" title="Lien permanent vers cette équation">#</a></span><img src="../../_images/math/585777222daa1efb533483053cb265020c9de614.svg" alt="\begin{eqnarray}
\partialfrac{e}{y_{C,i}} \pa{W,X} &amp;=&amp; \sum_{k=1}^{C_{C}} \partialfrac{e}{z_{C,k}} \pa{W,X} \partialfrac{z_{C,k}}{y_{C,i}}
                                        \pa{W,X} \nonumber\\
                                  &amp;=&amp; \partialfrac{e}{z_{C,i}} \pa{W,X} f'_{c,i}\pa{y_{C,i}} \nonumber
\end{eqnarray}"/></p>
</div><p>Pour les autres couches <img class="math" src="../../_images/math/166b6078b84a177dff3a50cf6a23450bbfc70c5f.svg" alt="c"/> telles que <img class="math" src="../../_images/math/e6dbf03ed35aafc34ca93473f6d7142cb881961c.svg" alt="1 \infegal c \infegal C-1"/>, on a :</p>
<div class="math" id="equation-retro-eq-nn-3">
<p><span class="eqno">(6)<a class="headerlink" href="#equation-retro-eq-nn-3" title="Lien permanent vers cette équation">#</a></span><img src="../../_images/math/49455d83bf7b75c5edb57cfe75f86a1c89edf3d8.svg" alt="\begin{eqnarray}
\partialfrac{e}{y_{c,i}}    &amp;=&amp; \sum_{l=1}^{C_{c+1}}              \partialfrac {e}{y_{c+1,l}}
                                                            \partialfrac{y_{c+1,l}}{y_{c,i}} \nonumber \\
                            &amp;=&amp; \sum_{l=1}^{C_{c+1}}              \partialfrac {e}{y_{c+1,l}}
                                \cro { \sum_{l=1}^{C_{c}}   \partialfrac {y_{c+1,l}}{z_{c,l}}
                                                                \underset{=0\,si\,l\neq i}{\underbrace{\partialfrac{z_{c,l}}{y_{c,i}}}} } \nonumber \\
                            &amp;=&amp; \sum_{l=1}^{C_{c+1}}              \partialfrac{e}{y_{c+1,l}}
                                                                \partialfrac{y_{c+1,l}}{z_{c,i}}
                                                                \partialfrac{z_{c,i}}{y_{c,i}}
                                                                \nonumber
\end{eqnarray}"/></p>
</div><p>Par conséquent :</p>
<div class="math" id="equation-algo-retro-5">
<p><span class="eqno">(7)<a class="headerlink" href="#equation-algo-retro-5" title="Lien permanent vers cette équation">#</a></span><img src="../../_images/math/f6efef9113e2f197dd3baf9f75e0e70522f62bf2.svg" alt="\begin{eqnarray}
\partialfrac{e}{y_{c,i}} &amp;=&amp;    \cro{ \sum_{l=1}^{C_{c+1}} \partialfrac{e}{y_{c+1,l}}w_{c+1,l,i} } \,
                                f_{c,i}^{\prime} \pa{y_{c,i}}  \nonumber
\end{eqnarray}"/></p>
</div><p id="index-0">Cette dernière formule permet d’obtenir par récurrence les dérivées
<img class="math" src="../../_images/math/d4737cd60dcd1c080b5b2325fa9760c0d53ffce5.svg" alt="\partialfrac{e}{y_{.,.}}"/> de la dernière couche <img class="math" src="../../_images/math/2c0e77bc741b692ecdf6e85966263a89422af4c8.svg" alt="C"/> à la première et ce,
quel que soit le nombre de couches. Cette récurrence inverse de la propagation est appelée <em>rétropropagation</em>.
Cet algorithme se déduit des équations <a class="reference internal" href="#equation-algo-retro-1">(3)</a>, <a class="reference internal" href="#equation-algo-retro-3">(4)</a>, <a class="reference internal" href="#equation-algo-retro-4">(5)</a> et <a class="reference internal" href="#equation-algo-retro-5">(7)</a> :</p>
<div class="admonition-mathdef admonition" id="indexmathe-Théorème1">
<div class="docutils container">
</div>
<p class="admonition-title" id="algo-retropropagation">Théorème T2 : rétropropagation</p>
<p>Cet algorithme s’applique à un réseau de neurones vérifiant la définition du <a class="reference internal" href="rn_1_def.html#rn-definition-perpception-1"><span class="std std-ref">perceptron</span></a>.
Il s’agit de calculer sa dérivée par rapport aux poids. Il se déduit des formules
<a class="reference internal" href="#equation-algo-retro-1">(3)</a>, <a class="reference internal" href="#equation-algo-retro-3">(4)</a>, <a class="reference internal" href="#equation-algo-retro-4">(5)</a> et <a class="reference internal" href="#equation-algo-retro-5">(7)</a>
et suppose que l’algorithme de <a class="reference internal" href="rn_1_def.html#algo-propagation"><span class="std std-ref">propagation</span></a> a été préalablement exécuté.
On note <img class="math" src="../../_images/math/3ebb48471baeb7ed91a16c5ca7c847928b284e35.svg" alt="y'_{c,i} = \partialfrac{e}{y_{c,i}}"/>, <img class="math" src="../../_images/math/3921a4a77039f66c3a91c415542ae8b1274f6467.svg" alt="w'_{c,i,j} = \partialfrac{e}{w_{c,i,j}}"/> et
<img class="math" src="../../_images/math/da4dfecc4f3aa4cb941496f6bacd028bdbaa5dbb.svg" alt="b'_{c,i} = \partialfrac{e}{b_{c,i}}"/>.</p>
<p><em>Initialisation</em></p>
<div class="line-block">
<div class="line">for i in <img class="math" src="../../_images/math/264c85993d6cd01736319b29489de16848190098.svg" alt="1..C_C"/></div>
<div class="line-block">
<div class="line"><img class="math" src="../../_images/math/3dc28aa4a1f0c732f8d8682cbd236f03d78f94f4.svg" alt="y'_{C,i} \longleftarrow \partialfrac{e}{z_{C,i}} \pa{W,X} f'_{c,i}\pa{y_{C,i}}"/></div>
</div>
</div>
<p><em>Récurrence</em></p>
<div class="line-block">
<div class="line">for c in <img class="math" src="../../_images/math/65bac269f2735cb77e2b4c74697aad358094469c.svg" alt="1..C-1"/></div>
<div class="line-block">
<div class="line">for i in <img class="math" src="../../_images/math/04ab3182119a37eb518b95fc9bef7bcef0bc70c6.svg" alt="1..C_c"/></div>
<div class="line-block">
<div class="line"><img class="math" src="../../_images/math/779098b4bf14e4c79dd77db6a6978ab0f3f15593.svg" alt="y'_{c,i} \longleftarrow 0"/></div>
<div class="line">for j in <img class="math" src="../../_images/math/77ed2a2718cceb4f305aeb7ede1cd38c1c98f082.svg" alt="1..C_{c+1}"/></div>
<div class="line-block">
<div class="line"><img class="math" src="../../_images/math/7d0304f3de7d2afcc2788d31b6bf99b1fe3850ad.svg" alt="y'_{c,i} \longleftarrow y'_{c,i} + y'_{c+1,j} \; w_{c+1,j,i}"/></div>
</div>
<div class="line"><img class="math" src="../../_images/math/4038b634fc70ad97052fed9861a66072ba0ce653.svg" alt="y'_{c,i} \longleftarrow y'_{c,i} \; f'_{c,i}\pa{y'_{c,i}}"/></div>
</div>
</div>
</div>
<p><em>Terminaison</em></p>
<div class="line-block">
<div class="line">for c in <img class="math" src="../../_images/math/f963c7631cb87c320d1687686f34c5e48b508b2d.svg" alt="1..C"/></div>
<div class="line-block">
<div class="line">for i in <img class="math" src="../../_images/math/04ab3182119a37eb518b95fc9bef7bcef0bc70c6.svg" alt="1..C_c"/></div>
<div class="line-block">
<div class="line">for j in <img class="math" src="../../_images/math/346f3fbfc25081d4908d056040c7360134f214b2.svg" alt="1..C_{c-1}"/></div>
<div class="line-block">
<div class="line"><img class="math" src="../../_images/math/08820146c4847e9c225ba1ee27cfb6a1079efb52.svg" alt="w'_{c,i,j} \longleftarrow z_{c-1,j} \; y'_{c,i}"/></div>
<div class="line"><img class="math" src="../../_images/math/f70cd15f99da4c70dbc48c877268fb5dbaff2fbc.svg" alt="b'_{c,i,j} \longleftarrow y'_{c,i}"/></div>
</div>
</div>
</div>
</div>
</div>
<p>Ces formules sont assez indigestes pour comprendre comment
la rétropropagation fonctionne. La figure suivante illustre
comme le gradient se propage d’un neurone au précédente de façon
récursive. Je la trouve plus simple à exploiter lorsqu’on dévie
du perceptron classique pour faire des choses hors des clous.
Je la laisse comme ça sans trop d’explications.</p>
<img alt="../../_images/neurone2.jpg" src="../../_images/neurone2.jpg" />
<p>L’idée de la rétropropagation : en supposant connu le gradient de l’erreur
par rapport à la sortie, comment en déduir le gradient par rapport
aux coefficients du réseau puis comment le propager à chaque entrée
de sorte qu’il puisse être transmis aux neurones de la couche inférieure.</p>
<img alt="../../_images/backp.png" src="../../_images/backp.png" />
</section>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="rn_4_densite.html"
       title="page précédente">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">précédent</p>
        <p class="prev-next-title">Démonstration du théorème de la densité des réseaux de neurones</p>
      </div>
    </a>
    <a class="right-next"
       href="rn_6_apprentissage.html"
       title="page suivante">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">suivant</p>
        <p class="prev-next-title">Apprentissage d’un réseau de neurones</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Sur cette page
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#algorithme-et-convergence">Algorithme et convergence</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#calcul-du-gradient-ou-retropropagation">Calcul du gradient ou <em>rétropropagation</em></a></li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">
  <div class="tocsection sourcelink">
    <a href="../../_sources/c_ml/rn/rn_5_newton.rst">
      <i class="fa-solid fa-file-lines"></i> Montrer le code source
    </a>
  </div>
</div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=365ca57ee442770a23c6"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=365ca57ee442770a23c6"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">
  <p class="copyright">
    
      © Copyright 2016-2023, Xavier Dupré.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">
  <p class="sphinx-version">
    Créé en utilisant <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.1.2.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item"><p class="theme-version">
  Construit avec le <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">Thème PyData Sphinx</a> 0.14.3.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>