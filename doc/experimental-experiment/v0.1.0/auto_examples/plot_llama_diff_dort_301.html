<!doctype html>
<html class="no-js" lang="en" data-content_root="../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="102: Measure LLAMA speed" href="plot_llama_bench_102.html" /><link rel="prev" title="301: Compares LLAMA exporters" href="plot_llama_diff_export_301.html" />

    <!-- Generated with Sphinx 8.1.3 and Furo 2024.08.06 -->
        <title>301: Compares LLAMA exporters for onnxrt backend - experimental-experiment 0.1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=354aac6f" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css?v=7f9a90b1" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css?v=4ae1632d" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=302659d7" />
    
    


<style>
  body {
    --color-code-background: #eeffcc;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">experimental-experiment 0.1.0 documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="../_static/logo.png" alt="Logo"/>
  </div>
  
  <span class="sidebar-brand-text">experimental-experiment 0.1.0 documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Contents</span></p>
<ul class="current">
<li class="toctree-l1 has-children"><a class="reference internal" href="../design/index.html">Design</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of Design</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../design/exporter.html">Custom Exporter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../design/optimizer.html">Pattern Optimizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../design/backends.html">Dynamo Backends</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../tutorial/index.html">Tutorial</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of Tutorial</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../tutorial/pytorch.html">pytorch and onnx</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorial/onnx.html">onnx</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../tutorial/exporter_recipes.html">Exporter Recipes</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of Exporter Recipes</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../tutorial/exporter_recipes_custom.html">Recipes with to_onnx</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tutorial/exporter_recipes_onnx_export.html">Recipes with torch.onnx.export</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tutorial/errors.html">Frequent Exceptions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../tutorial/docker.html">Start from a docker</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api/index.html">API</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of API</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/gradient/index.html">experimental_experiment.gradient</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of experimental_experiment.gradient</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/gradient/ops/index.html">experimental_experiment.gradient.ops</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle navigation of experimental_experiment.gradient.ops</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/gradient/ops/op_broadcast_gradient_args.html">experimental_experiment.gradient.ops.op_broadcast_gradient_args</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api/gradient/grad_helper.html">experimental_experiment.gradient.grad_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/gradient/loss_helper.html">experimental_experiment.gradient.loss_helper</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/reference/index.html">experimental_experiment.reference</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle navigation of experimental_experiment.reference</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/reference/ops/index.html">experimental_experiment.reference.ops</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle navigation of experimental_experiment.reference.ops</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_add_add_mul_mul.html">experimental_experiment.reference.ops.op_add_add_mul_mul</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_average_pool_grad.html">experimental_experiment.reference.ops.op_average_pool_grad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_cast_like.html">experimental_experiment.reference.ops.op_cast_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_concat.html">experimental_experiment.reference.ops.op_concat</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_constant_of_shape.html">experimental_experiment.reference.ops.op_constant_of_shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_fused_matmul.html">experimental_experiment.reference.ops.op_fused_matmul</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_gather_grad.html">experimental_experiment.reference.ops.op_gather_grad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_memcpy_host.html">experimental_experiment.reference.ops.op_memcpy_host</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_mul_sigmoid.html">experimental_experiment.reference.ops.op_mul_sigmoid</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_negxplus1.html">experimental_experiment.reference.ops.op_negxplus1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_quick_gelu.html">experimental_experiment.reference.ops.op_quick_gelu</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_replace_zero.html">experimental_experiment.reference.ops.op_replace_zero</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_rotary.html">experimental_experiment.reference.ops.op_rotary</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_scatter_elements.html">experimental_experiment.reference.ops.op_scatter_elements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_scatternd_of_shape.html">experimental_experiment.reference.ops.op_scatternd_of_shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_simplified_layer_normalization.html">experimental_experiment.reference.ops.op_simplified_layer_normalization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_slice.html">experimental_experiment.reference.ops.op_slice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_transpose_cast.html">experimental_experiment.reference.ops.op_transpose_cast</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_tri_matrix.html">experimental_experiment.reference.ops.op_tri_matrix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api/reference/evaluator.html">experimental_experiment.reference.evaluator</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/reference/ort_evaluator.html">experimental_experiment.reference.ort_evaluator</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/convert/index.html">experimental_experiment.convert</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle navigation of experimental_experiment.convert</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/convert/convert_helper.html">experimental_experiment.convert.convert_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/convert/ort_helper.html">experimental_experiment.convert.ort_helper</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/plotting/index.html">experimental_experiment.plotting</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle navigation of experimental_experiment.plotting</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/plotting/data.html">experimental_experiment.plotting.data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/plotting/memory.html">experimental_experiment.plotting.memory</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/torch_interpreter/index.html">experimental_experiment.torch_interpreter</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><div class="visually-hidden">Toggle navigation of experimental_experiment.torch_interpreter</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/_aten_functions.html">experimental_experiment.torch_interpreter._aten_functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/_aten_functions_attention.html">experimental_experiment.torch_interpreter._aten_functions_attention</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/_aten_methods.html">experimental_experiment.torch_interpreter._aten_methods</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/_doc_.html">experimental_experiment.torch_interpreter._doc_</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/_exceptions.html">experimental_experiment.torch_interpreter._exceptions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/_prims_functions.html">experimental_experiment.torch_interpreter._prims_functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/_torch_helper.html">experimental_experiment.torch_interpreter._torch_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/aten_functions.html">experimental_experiment.torch_interpreter.aten_functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/aten_methods.html">experimental_experiment.torch_interpreter.aten_methods</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/dispatcher.html">experimental_experiment.torch_interpreter.dispatcher</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/export_options.html">experimental_experiment.torch_interpreter.export_options</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/interpreter.html">experimental_experiment.torch_interpreter.interpreter</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/onnx_export.html">experimental_experiment.torch_interpreter.onnx_export</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/onnx_export_errors.html">experimental_experiment.torch_interpreter.onnx_export_errors</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/oxs_dispatcher.html">experimental_experiment.torch_interpreter.oxs_dispatcher</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/oxs_opset.html">experimental_experiment.torch_interpreter.oxs_opset</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/torch_models/index.html">experimental_experiment.torch_models</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><div class="visually-hidden">Toggle navigation of experimental_experiment.torch_models</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_models/diffusion_model_helper.html">experimental_experiment.torch_models.diffusion_model_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_models/dump_helper.html">experimental_experiment.torch_models.dump_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_models/llama_helper.html">experimental_experiment.torch_models.llama_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_models/llm_model_helper.html">experimental_experiment.torch_models.llm_model_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_models/mistral_helper.html">experimental_experiment.torch_models.mistral_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_models/phi3_helper.html">experimental_experiment.torch_models.phi3_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_models/phi_helper.html">experimental_experiment.torch_models.phi_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_models/training_helper.html">experimental_experiment.torch_models.training_helper</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/xbuilder/index.html">experimental_experiment.xbuilder</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" role="switch" type="checkbox"/><label for="toctree-checkbox-13"><div class="visually-hidden">Toggle navigation of experimental_experiment.xbuilder</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/xbuilder/_dtype_helper.html">experimental_experiment.xbuilder._dtype_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xbuilder/_graph_builder_runtime.html">experimental_experiment.xbuilder._graph_builder_runtime</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xbuilder/_onnx_helper.html">experimental_experiment.xbuilder._onnx_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xbuilder/_shape_helper.html">experimental_experiment.xbuilder._shape_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xbuilder/expression_dimension.html">experimental_experiment.xbuilder.expression_dimension</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xbuilder/graph_builder.html">experimental_experiment.xbuilder.graph_builder</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xbuilder/graph_builder_opset.html">experimental_experiment.xbuilder.graph_builder_opset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xbuilder/model_container.html">experimental_experiment.xbuilder.model_container</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xbuilder/optimization_options.html">experimental_experiment.xbuilder.optimization_options</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xbuilder/shape_type_compute.html">experimental_experiment.xbuilder.shape_type_compute</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xbuilder/type_inference.html">experimental_experiment.xbuilder.type_inference</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/xoptim/index.html">experimental_experiment.xoptim</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" role="switch" type="checkbox"/><label for="toctree-checkbox-14"><div class="visually-hidden">Toggle navigation of experimental_experiment.xoptim</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/xoptim/patterns_investigation/index.html">experimental_experiment.xoptim.patterns_investigation</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" role="switch" type="checkbox"/><label for="toctree-checkbox-15"><div class="visually-hidden">Toggle navigation of experimental_experiment.xoptim.patterns_investigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_investigation/element_wise.html">experimental_experiment.xoptim.patterns_investigation.element_wise</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/xoptim/patterns_ml/index.html">experimental_experiment.xoptim.patterns_ml</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" role="switch" type="checkbox"/><label for="toctree-checkbox-16"><div class="visually-hidden">Toggle navigation of experimental_experiment.xoptim.patterns_ml</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ml/tree_ensemble.html">experimental_experiment.xoptim.patterns_ml.tree_ensemble</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/xoptim/patterns_exp/index.html">experimental_experiment.xoptim.patterns_exp</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" role="switch" type="checkbox"/><label for="toctree-checkbox-17"><div class="visually-hidden">Toggle navigation of experimental_experiment.xoptim.patterns_exp</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_exp/binary_operators.html">experimental_experiment.xoptim.patterns_exp.binary_operators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_exp/constant_of_shape_scatter_nd.html">experimental_experiment.xoptim.patterns_exp.constant_of_shape_scatter_nd</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_exp/constants.html">experimental_experiment.xoptim.patterns_exp.constants</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_exp/simple_rotary.html">experimental_experiment.xoptim.patterns_exp.simple_rotary</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_exp/unary_operators.html">experimental_experiment.xoptim.patterns_exp.unary_operators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_exp/where_replace.html">experimental_experiment.xoptim.patterns_exp.where_replace</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/xoptim/patterns/index.html">experimental_experiment.xoptim.patterns</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" role="switch" type="checkbox"/><label for="toctree-checkbox-18"><div class="visually-hidden">Toggle navigation of experimental_experiment.xoptim.patterns</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_any.html">experimental_experiment.xoptim.patterns.onnx_any</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_cast.html">experimental_experiment.xoptim.patterns.onnx_cast</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_conv.html">experimental_experiment.xoptim.patterns.onnx_conv</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_dropout.html">experimental_experiment.xoptim.patterns.onnx_dropout</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_equal.html">experimental_experiment.xoptim.patterns.onnx_equal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_expand.html">experimental_experiment.xoptim.patterns.onnx_expand</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_functions.html">experimental_experiment.xoptim.patterns.onnx_functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_layer_normalization.html">experimental_experiment.xoptim.patterns.onnx_layer_normalization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_matmul.html">experimental_experiment.xoptim.patterns.onnx_matmul</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_mul.html">experimental_experiment.xoptim.patterns.onnx_mul</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_reduce.html">experimental_experiment.xoptim.patterns.onnx_reduce</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_reshape.html">experimental_experiment.xoptim.patterns.onnx_reshape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_rotary.html">experimental_experiment.xoptim.patterns.onnx_rotary</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_split.html">experimental_experiment.xoptim.patterns.onnx_split</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_sub.html">experimental_experiment.xoptim.patterns.onnx_sub</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_transpose.html">experimental_experiment.xoptim.patterns.onnx_transpose</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_unsqueeze.html">experimental_experiment.xoptim.patterns.onnx_unsqueeze</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/xoptim/patterns_ort/index.html">experimental_experiment.xoptim.patterns_ort</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" role="switch" type="checkbox"/><label for="toctree-checkbox-19"><div class="visually-hidden">Toggle navigation of experimental_experiment.xoptim.patterns_ort</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ort/activation.html">experimental_experiment.xoptim.patterns_ort.activation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ort/activation_grad.html">experimental_experiment.xoptim.patterns_ort.activation_grad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ort/fused_matmul.html">experimental_experiment.xoptim.patterns_ort.fused_matmul</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ort/gather_grad.html">experimental_experiment.xoptim.patterns_ort.gather_grad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ort/simplified_layer_normalization.html">experimental_experiment.xoptim.patterns_ort.simplified_layer_normalization</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/xoptim/patterns_fix/index.html">experimental_experiment.xoptim.patterns_fix</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" role="switch" type="checkbox"/><label for="toctree-checkbox-20"><div class="visually-hidden">Toggle navigation of experimental_experiment.xoptim.patterns_fix</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_fix/add_reduction_scatter_nd.html">experimental_experiment.xoptim.patterns_fix.add_reduction_scatter_nd</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api/xoptim/graph_builder_optim.html">experimental_experiment.xoptim.graph_builder_optim</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xoptim/order_optim.html">experimental_experiment.xoptim.order_optim</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xoptim/patterns_api.html">experimental_experiment.xoptim.patterns_api</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/torch_dynamo/index.html">experimental_experiment.torch_dynamo</a><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" role="switch" type="checkbox"/><label for="toctree-checkbox-21"><div class="visually-hidden">Toggle navigation of experimental_experiment.torch_dynamo</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_dynamo/_dynamo_exporter.html">experimental_experiment.torch_dynamo._dynamo_exporter</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_dynamo/backend_helper.html">experimental_experiment.torch_dynamo.backend_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_dynamo/debug_backend.html">experimental_experiment.torch_dynamo.debug_backend</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_dynamo/dynger_backend.html">experimental_experiment.torch_dynamo.dynger_backend</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_dynamo/fast_backend.html">experimental_experiment.torch_dynamo.fast_backend</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_dynamo/partition.html">experimental_experiment.torch_dynamo.partition</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/torch_bench/index.html">experimental_experiment.torch_bench</a><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" role="switch" type="checkbox"/><label for="toctree-checkbox-22"><div class="visually-hidden">Toggle navigation of experimental_experiment.torch_bench</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_benchmark_runner.html">experimental_experiment.torch_bench._bash_bench_benchmark_runner</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_benchmark_runner_agg.html">experimental_experiment.torch_bench._bash_bench_benchmark_runner_agg</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_benchmark_runner_agg_helper.html">experimental_experiment.torch_bench._bash_bench_benchmark_runner_agg_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_cmd.html">experimental_experiment.torch_bench._bash_bench_cmd</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_model_runner.html">experimental_experiment.torch_bench._bash_bench_model_runner</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_models_helper.html">experimental_experiment.torch_bench._bash_bench_models_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_set_dummies.html">experimental_experiment.torch_bench._bash_bench_set_dummies</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_set_explicit.html">experimental_experiment.torch_bench._bash_bench_set_explicit</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_set_huggingface.html">experimental_experiment.torch_bench._bash_bench_set_huggingface</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_set_huggingface_big.html">experimental_experiment.torch_bench._bash_bench_set_huggingface_big</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_set_issues.html">experimental_experiment.torch_bench._bash_bench_set_issues</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_set_timm.html">experimental_experiment.torch_bench._bash_bench_set_timm</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_set_torchbench.html">experimental_experiment.torch_bench._bash_bench_set_torchbench</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_set_torchbench_ado.html">experimental_experiment.torch_bench._bash_bench_set_torchbench_ado</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_suites.html">experimental_experiment.torch_bench._bash_bench_suites</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_dort_cmd_common.html">experimental_experiment.torch_bench._dort_cmd_common</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_dort_cmd_common_models.html">experimental_experiment.torch_bench._dort_cmd_common_models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/bash_bench_agg.html">experimental_experiment.torch_bench.bash_bench_agg</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/bash_bench_explicit.html">experimental_experiment.torch_bench.bash_bench_explicit</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/bash_bench_huggingface.html">experimental_experiment.torch_bench.bash_bench_huggingface</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/bash_bench_huggingface_big.html">experimental_experiment.torch_bench.bash_bench_huggingface_big</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/bash_bench_issues.html">experimental_experiment.torch_bench.bash_bench_issues</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/bash_bench_timm.html">experimental_experiment.torch_bench.bash_bench_timm</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/bash_bench_torchbench.html">experimental_experiment.torch_bench.bash_bench_torchbench</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/bash_bench_torchbench_ado.html">experimental_experiment.torch_bench.bash_bench_torchbench_ado</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/bash_bench_untrained.html">experimental_experiment.torch_bench.bash_bench_untrained</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/check_model.html">experimental_experiment.torch_bench.check_model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/dort_bench.html">experimental_experiment.torch_bench.dort_bench</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/dort_bench_profile.html">experimental_experiment.torch_bench.dort_bench_profile</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/dort_profile.html">experimental_experiment.torch_bench.dort_profile</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/export_model.html">experimental_experiment.torch_bench.export_model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/export_model_helper.html">experimental_experiment.torch_bench.export_model_helper</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api/_bench_test.html">experimental_experiment._bench_test</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/_command_lines_parser.html">experimental_experiment._command_lines_parser</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/args.html">experimental_experiment.args</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bench_run.html">experimental_experiment.bench_run</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/checks.html">experimental_experiment.checks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/ext_test_case.html">experimental_experiment.ext_test_case</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/helpers.html">experimental_experiment.helpers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/memory_peak.html">experimental_experiment.memory_peak</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/model_run.html">experimental_experiment.model_run</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/onnx_tools.html">experimental_experiment.onnx_tools</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/torch_test_helper.html">experimental_experiment.torch_test_helper</a></li>
</ul>
</li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="index.html">Example gallery</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" role="switch" type="checkbox"/><label for="toctree-checkbox-23"><div class="visually-hidden">Toggle navigation of Example gallery</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="plot_onnxscript_102.html">102: Examples with onnxscript</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_exporter_recipes_oe_custom_ops_inplace.html">torch.onnx.export and a custom operator inplace</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_exporter_recipes_oe_cond.html">torch.onnx.export and a model with a test</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_exporter_recipes_c_cond.html">to_onnx and a model with a test</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_exporter_recipes_oe_custom_ops_fct.html">torch.onnx.export and a custom operator registered with a function</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_optimize_101.html">101: Graph Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_exporter_recipes_c_custom_ops_inplace.html">to_onnx and a custom operator inplace</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_executorch_102.html">102: First test with ExecuTorch</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_exporter_recipes_c_custom_ops_fct.html">to_onnx and a custom operator registered with a function</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_torch_export_compile_102.html">102: Tweak onnx export</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_profile_existing_onnx_101.html">101: Profile an existing model with onnxruntime</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_rewrite_101.html">101: Onnx Model Rewriting</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_torch_linreg_101.html">101: Linear Regression and export to ONNX</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_torch_custom_backend_101.html">101: A custom backend for torch</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_torch_export_101.html">101: Some dummy examples with torch.export.export</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_convolutation_matmul_102.html">102: Convolution and Matrix Multiplication</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_custom_backend_llama_102.html">102: Fuse kernels in a small Llama Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_llama_diff_export_301.html">301: Compares LLAMA exporters</a></li>
<li class="toctree-l2 current current-page"><a class="current reference internal" href="#">301: Compares LLAMA exporters for onnxrt backend</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_llama_bench_102.html">102: Measure LLAMA speed</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_torch_aot_201.html">201: Evaluate DORT Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_torch_dort_201.html">201: Evaluate DORT</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_torch_export_201.html">201: Evaluate different ways to export a torch model to ONNX</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../models/index.html">Supported Models By the Custom Backend</a><input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" role="switch" type="checkbox"/><label for="toctree-checkbox-24"><div class="visually-hidden">Toggle navigation of Supported Models By the Custom Backend</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../models/llama.html">LLaMa</a></li>
<li class="toctree-l2"><a class="reference internal" href="../models/mistral.html">Mistral</a></li>
<li class="toctree-l2"><a class="reference internal" href="../models/phi.html">Phi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../models/phi3.html">Phi3</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../command_lines.html">Command Lines</a><input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" role="switch" type="checkbox"/><label for="toctree-checkbox-25"><div class="visually-hidden">Toggle navigation of Command Lines</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../bench/index.html">Benchmarks from the command line</a><input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" role="switch" type="checkbox"/><label for="toctree-checkbox-26"><div class="visually-hidden">Toggle navigation of Benchmarks from the command line</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../bench/dort_bench.html">experimental_experiment.torch_bench.dort_bench</a></li>
<li class="toctree-l3"><a class="reference internal" href="../bench/dort_profile.html">experimental_experiment.torch_bench.dort_profile</a></li>
<li class="toctree-l3"><a class="reference internal" href="../bench/scripts.html">Interesting scripts or command lines</a></li>
<li class="toctree-l3"><a class="reference internal" href="../bench/bash_bench.html">Measuring the exporters on a short list of sets of models</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../tools/index.html">Tools from the command line</a><input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" role="switch" type="checkbox"/><label for="toctree-checkbox-27"><div class="visually-hidden">Toggle navigation of Tools from the command line</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../tools/lighten.html">python -m experimental_experiment lighten and unlighten</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tools/optimize.html">python -m experimental_experiment optimize</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tools/run.html">python -m experimental_experiment run</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../miscellaneous/index.html">Miscellaneous</a><input class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" role="switch" type="checkbox"/><label for="toctree-checkbox-28"><div class="visually-hidden">Toggle navigation of Miscellaneous</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../miscellaneous/export_times.html">Export Times</a></li>
<li class="toctree-l2"><a class="reference internal" href="../miscellaneous/long_outputs.html">Long Outputs uneasy to read</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">More</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../CHANGELOGS.html">Change Logs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="../_sources/auto_examples/plot_llama_diff_dort_301.rst" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-auto-examples-plot-llama-diff-dort-301-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="compares-llama-exporters-for-onnxrt-backend">
<span id="l-plot-onnxrt-diff"></span><span id="sphx-glr-auto-examples-plot-llama-diff-dort-301-py"></span><h1>301: Compares LLAMA exporters for onnxrt backend<a class="headerlink" href="#compares-llama-exporters-for-onnxrt-backend" title="Link to this heading"></a></h1>
<p>The script compares exported models in <a class="reference external" href="https://pytorch.org/">pytorch</a>
using <a class="reference external" href="https://pytorch.org/docs/stable/onnx_dynamo_onnxruntime_backend.html">onnxrt backend</a>. It tries to do a side by side
of the execution of both models.</p>
<p>To run the script:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">_doc</span><span class="o">/</span><span class="n">examples</span><span class="o">/</span><span class="n">plot_llama_diff_dort</span> <span class="o">--</span><span class="n">help</span>
</pre></div>
</div>
<p>The following example compares the forward step for mixed precision on cuda
and produces all the intermediate onnx graphs.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">_doc</span><span class="o">/</span><span class="n">examples</span><span class="o">/</span><span class="n">plot_llama_diff_dort</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">part</span> <span class="n">model</span> <span class="o">--</span><span class="n">ortopt</span> <span class="mi">1</span> \
        <span class="o">--</span><span class="n">cuda</span> <span class="mi">1</span> <span class="o">--</span><span class="n">backward</span> <span class="mi">0</span> <span class="o">--</span><span class="n">mixed</span> <span class="mi">1</span>
</pre></div>
</div>
<p>You may use <code class="docutils literal notranslate"><span class="pre">--mixed=1</span></code> to compare the backward graphs.</p>
<section id="some-helpers">
<h2>Some helpers<a class="headerlink" href="#some-helpers" title="Link to this heading"></a></h2>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">experimental_experiment.args</span> <span class="kn">import</span> <span class="n">get_parsed_args</span>

<span class="n">script_args</span> <span class="o">=</span> <span class="n">get_parsed_args</span><span class="p">(</span>
    <span class="s2">&quot;plot_llama_diff_export&quot;</span><span class="p">,</span>
    <span class="n">description</span><span class="o">=</span><span class="vm">__doc__</span><span class="p">,</span>
    <span class="n">part</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;attention&quot;</span><span class="p">,</span> <span class="s2">&quot;one value among attention, decoder, model&quot;</span><span class="p">),</span>
    <span class="n">ortopt</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;run onnxruntime optimization&quot;</span><span class="p">),</span>
    <span class="n">backward</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;does one operator for backward&quot;</span><span class="p">),</span>
    <span class="n">cuda</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;use cuda or not&quot;</span><span class="p">),</span>
    <span class="n">mixed</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;use miwed precision&quot;</span><span class="p">),</span>
    <span class="n">opset</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="s2">&quot;onnx opset&quot;</span><span class="p">),</span>
    <span class="n">expose</span><span class="o">=</span><span class="s2">&quot;part,exporter,ortopt,cuda,mixed,opset&quot;</span><span class="p">,</span>
<span class="p">)</span>


<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">logging</span>

<span class="k">try</span><span class="p">:</span>
    <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
        <span class="kn">import</span> <span class="nn">onnxruntime</span>

        <span class="n">has_cuda</span> <span class="o">=</span> <span class="s2">&quot;CUDAExecutionProvider&quot;</span> <span class="ow">in</span> <span class="n">onnxruntime</span><span class="o">.</span><span class="n">get_available_providers</span><span class="p">()</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;onnxruntime not available.&quot;</span><span class="p">)</span>
    <span class="kn">import</span> <span class="nn">sys</span>

    <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">onnx</span>
<span class="kn">from</span> <span class="nn">onnx_array_api.reference</span> <span class="kn">import</span> <span class="n">compare_onnx_execution</span><span class="p">,</span> <span class="n">ExtendedReferenceEvaluator</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch._dynamo.backends.common</span> <span class="kn">import</span> <span class="n">aot_autograd</span>
<span class="kn">from</span> <span class="nn">experimental_experiment.ext_test_case</span> <span class="kn">import</span> <span class="n">unit_test_going</span>
<span class="kn">from</span> <span class="nn">experimental_experiment.convert.convert_helper</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">optimize_model_proto_oxs</span><span class="p">,</span>
    <span class="n">ort_optimize</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">experimental_experiment.torch_models.llama_helper</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">get_llama_model</span><span class="p">,</span>
    <span class="n">get_llama_attention</span><span class="p">,</span>
    <span class="n">get_llama_decoder</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">experimental_experiment.torch_models.dump_helper</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">assert_all_close</span><span class="p">,</span>
    <span class="n">dump_onnx</span><span class="p">,</span>
    <span class="n">reorder_functions_in_proto</span><span class="p">,</span>
    <span class="n">inputs_from_onnx_model</span><span class="p">,</span>
    <span class="n">build_matching_inputs</span><span class="p">,</span>
    <span class="n">results_to_string</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">experimental_experiment.torch_models.training_helper</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">train_loop</span><span class="p">,</span>
    <span class="n">make_aot_ort</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">experimental_experiment.torch_dynamo</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">onnx_debug_backend</span><span class="p">,</span>
    <span class="n">get_decomposition_table</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">has_cuda</span> <span class="o">=</span> <span class="n">has_cuda</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>
<span class="n">logging</span><span class="o">.</span><span class="n">disable</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">ERROR</span><span class="p">)</span>
<span class="n">provider</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">has_cuda</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>
</pre></div>
</div>
</section>
<section id="the-exporting-functions">
<h2>The exporting functions<a class="headerlink" href="#the-exporting-functions" title="Link to this heading"></a></h2>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;part=</span><span class="si">{</span><span class="n">script_args</span><span class="o">.</span><span class="n">part</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">ortopt</span> <span class="o">=</span> <span class="n">script_args</span><span class="o">.</span><span class="n">ortopt</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;1&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ortopt=</span><span class="si">{</span><span class="n">ortopt</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">backward</span> <span class="o">=</span> <span class="n">script_args</span><span class="o">.</span><span class="n">backward</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;1&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;backward=</span><span class="si">{</span><span class="n">backward</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">use_cuda</span> <span class="o">=</span> <span class="n">script_args</span><span class="o">.</span><span class="n">cuda</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;1&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;cuda=</span><span class="si">{</span><span class="n">use_cuda</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">use_mixed</span> <span class="o">=</span> <span class="n">script_args</span><span class="o">.</span><span class="n">mixed</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;1&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;mixed=</span><span class="si">{</span><span class="n">use_mixed</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">opset</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">script_args</span><span class="o">.</span><span class="n">opset</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;opset=</span><span class="si">{</span><span class="n">opset</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>part=attention
ortopt=True
backward=False
cuda=False
mixed=False
opset=18
</pre></div>
</div>
</section>
<section id="model-and-data">
<h2>Model and data<a class="headerlink" href="#model-and-data" title="Link to this heading"></a></h2>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">unit_test_going</span><span class="p">():</span>
    <span class="n">kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">input_dims</span><span class="o">=</span><span class="p">[(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1024</span><span class="p">)]</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
        <span class="n">input_dims</span><span class="o">=</span><span class="p">[(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1024</span><span class="p">)]</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span>
        <span class="n">_attn_implementation</span><span class="o">=</span><span class="s2">&quot;eager&quot;</span><span class="p">,</span>
        <span class="n">num_hidden_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">hidden_size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
        <span class="n">vocab_size</span><span class="o">=</span><span class="mi">4000</span><span class="p">,</span>
        <span class="n">intermediate_size</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span>
        <span class="n">max_position_embeddings</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span>
        <span class="n">num_attention_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="p">)</span>

<span class="k">if</span> <span class="n">script_args</span><span class="o">.</span><span class="n">part</span> <span class="o">==</span> <span class="s2">&quot;attention&quot;</span><span class="p">:</span>
    <span class="n">model</span><span class="p">,</span> <span class="n">inputs</span> <span class="o">=</span> <span class="n">get_llama_attention</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="k">elif</span> <span class="n">script_args</span><span class="o">.</span><span class="n">part</span> <span class="o">==</span> <span class="s2">&quot;decoder&quot;</span><span class="p">:</span>
    <span class="n">model</span><span class="p">,</span> <span class="n">inputs</span> <span class="o">=</span> <span class="n">get_llama_decoder</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="k">elif</span> <span class="n">script_args</span><span class="o">.</span><span class="n">part</span> <span class="o">==</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span>
    <span class="n">model</span><span class="p">,</span> <span class="n">inputs</span> <span class="o">=</span> <span class="n">get_llama_model</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unexpected value for part=</span><span class="si">{</span><span class="n">script_args</span><span class="o">.</span><span class="n">part</span><span class="si">!r}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="k">if</span> <span class="n">use_cuda</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="p">[[</span><span class="n">i</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">inp</span><span class="p">]</span> <span class="k">for</span> <span class="n">inp</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;simple run with </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span><span class="si">}</span><span class="s2"> inputs&quot;</span><span class="p">)</span>
<span class="k">if</span> <span class="n">backward</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">use_mixed</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">use_cuda</span><span class="p">,</span> <span class="s2">&quot;mixed precision only works with cuda&quot;</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span><span class="n">device_type</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">):</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
            <span class="n">expected</span> <span class="o">=</span> <span class="n">train_loop</span><span class="p">(</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="p">),</span> <span class="o">*</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">expected</span> <span class="o">=</span> <span class="n">train_loop</span><span class="p">(</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="p">),</span> <span class="o">*</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;-- eager mode worked, </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">expected</span><span class="p">)</span><span class="si">}</span><span class="s2"> gradients, first one is &quot;</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">expected</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">expected</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">use_mixed</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">use_cuda</span><span class="p">,</span> <span class="s2">&quot;mixed precision only works with cuda&quot;</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span><span class="n">device_type</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">):</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
            <span class="n">expected</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">*</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">expected</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">*</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">results_to_string</span><span class="p">(</span><span class="n">expected</span><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>simple run with 2 inputs
torch.float32 (2, 1024, 512) [sum=-117]
</pre></div>
</div>
</section>
<section id="exporting">
<h2>Exporting<a class="headerlink" href="#exporting" title="Link to this heading"></a></h2>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">_dynamo</span><span class="o">.</span><span class="n">variables</span><span class="o">.</span><span class="n">misc</span><span class="p">,</span> <span class="s2">&quot;LoggingLoggerVariable&quot;</span><span class="p">):</span>
    <span class="c1"># A tweak to make torch.export.export work.</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">_dynamo</span><span class="o">.</span><span class="n">variables</span><span class="o">.</span><span class="n">misc</span><span class="o">.</span><span class="n">LoggingLoggerVariable</span><span class="o">.</span><span class="n">call_method</span> <span class="o">=</span> <span class="k">lambda</span> <span class="o">*</span><span class="n">_</span><span class="p">,</span> <span class="o">**</span><span class="n">__</span><span class="p">:</span> <span class="kc">None</span>


<span class="n">folder</span> <span class="o">=</span> <span class="s2">&quot;dump_models&quot;</span>
<span class="n">storage</span> <span class="o">=</span> <span class="p">{}</span>

<span class="k">if</span> <span class="n">backward</span><span class="p">:</span>
    <span class="c1"># onnxrt backend</span>
    <span class="n">local_aot_ort</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">make_aot_ort</span><span class="p">(</span><span class="n">dynamic</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">rewrite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">optimized_mod</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
        <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="p">),</span> <span class="n">backend</span><span class="o">=</span><span class="n">local_aot_ort</span><span class="p">,</span> <span class="n">dynamic</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fullgraph</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>

    <span class="k">with</span> <span class="n">dump_onnx</span><span class="p">(</span><span class="s2">&quot;llama_onnxrt&quot;</span><span class="p">,</span> <span class="n">folder</span><span class="o">=</span><span class="n">folder</span><span class="p">,</span> <span class="n">clean</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">use_mixed</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span><span class="n">device_type</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">):</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
                <span class="n">expected_onnxrt</span> <span class="o">=</span> <span class="n">train_loop</span><span class="p">(</span><span class="n">optimized_mod</span><span class="p">,</span> <span class="o">*</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">expected_onnxrt</span> <span class="o">=</span> <span class="n">train_loop</span><span class="p">(</span><span class="n">optimized_mod</span><span class="p">,</span> <span class="o">*</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">assert_all_close</span><span class="p">(</span><span class="n">expected</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">expected_onnxrt</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;-- onnxrt backend worked, </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">expected_onnxrt</span><span class="p">)</span><span class="si">}</span><span class="s2"> gradients, first one is &quot;</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">expected_onnxrt</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">expected_onnxrt</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="p">)</span>

    <span class="c1"># debugging backend</span>
    <span class="n">aot_compiler</span> <span class="o">=</span> <span class="n">aot_autograd</span><span class="p">(</span>
        <span class="n">fw_compiler</span><span class="o">=</span><span class="k">lambda</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">onnx_debug_backend</span><span class="p">(</span>
            <span class="o">*</span><span class="n">args</span><span class="p">,</span>
            <span class="n">dump_prefix</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="s2">&quot;llama_debug&quot;</span><span class="p">),</span>
            <span class="n">target_opset</span><span class="o">=</span><span class="n">opset</span><span class="p">,</span>
            <span class="n">storage</span><span class="o">=</span><span class="n">storage</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="n">decompositions</span><span class="o">=</span><span class="n">get_decomposition_table</span><span class="p">(),</span>
    <span class="p">)</span>
    <span class="n">onnx_mod</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="p">),</span> <span class="n">backend</span><span class="o">=</span><span class="n">aot_compiler</span><span class="p">,</span> <span class="n">fullgraph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">use_mixed</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span><span class="n">device_type</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">):</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
            <span class="n">got</span> <span class="o">=</span> <span class="n">train_loop</span><span class="p">(</span><span class="n">onnx_mod</span><span class="p">,</span> <span class="o">*</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">got</span> <span class="o">=</span> <span class="n">train_loop</span><span class="p">(</span><span class="n">onnx_mod</span><span class="p">,</span> <span class="o">*</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">assert_all_close</span><span class="p">(</span><span class="n">expected</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">got</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-2</span> <span class="k">if</span> <span class="n">use_mixed</span> <span class="k">else</span> <span class="mf">1e-4</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;-- debug backend worked, </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">got</span><span class="p">)</span><span class="si">}</span><span class="s2"> gradients, first one is &quot;</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">got</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">got</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="p">)</span>

<span class="k">else</span><span class="p">:</span>
    <span class="c1"># onnxrt backend</span>
    <span class="n">local_aot_ort</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">make_aot_ort</span><span class="p">(</span><span class="n">dynamic</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">rewrite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">optimized_mod</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="n">local_aot_ort</span><span class="p">,</span> <span class="n">fullgraph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">dump_onnx</span><span class="p">(</span><span class="s2">&quot;llama_onnxrt&quot;</span><span class="p">,</span> <span class="n">folder</span><span class="o">=</span><span class="n">folder</span><span class="p">,</span> <span class="n">clean</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">use_mixed</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span><span class="n">device_type</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">):</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
                <span class="n">expected_onnxrt</span> <span class="o">=</span> <span class="n">optimized_mod</span><span class="p">(</span><span class="o">*</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">expected_onnxrt</span> <span class="o">=</span> <span class="n">optimized_mod</span><span class="p">(</span><span class="o">*</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">assert_all_close</span><span class="p">(</span><span class="n">expected</span><span class="p">,</span> <span class="n">expected_onnxrt</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">)</span>

    <span class="c1"># debugging backend</span>
    <span class="n">aot_compiler</span> <span class="o">=</span> <span class="n">aot_autograd</span><span class="p">(</span>
        <span class="n">fw_compiler</span><span class="o">=</span><span class="k">lambda</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">onnx_debug_backend</span><span class="p">(</span>
            <span class="o">*</span><span class="n">args</span><span class="p">,</span>
            <span class="n">dump_prefix</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="s2">&quot;llama_debug&quot;</span><span class="p">),</span>
            <span class="n">target_opset</span><span class="o">=</span><span class="mi">17</span><span class="p">,</span>
            <span class="n">storage</span><span class="o">=</span><span class="n">storage</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="p">)</span>

    <span class="n">onnx_mod</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="n">aot_compiler</span><span class="p">,</span> <span class="n">fullgraph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">use_mixed</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span><span class="n">device_type</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">):</span>
            <span class="n">got</span> <span class="o">=</span> <span class="n">onnx_mod</span><span class="p">(</span><span class="o">*</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">got</span> <span class="o">=</span> <span class="n">onnx_mod</span><span class="p">(</span><span class="o">*</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">assert_all_close</span><span class="p">(</span><span class="n">expected</span><span class="p">,</span> <span class="n">got</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mi">1</span> <span class="k">if</span> <span class="n">use_mixed</span> <span class="k">else</span> <span class="mf">1e-3</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>/home/xadupre/vv/this/lib/python3.10/site-packages/torch/onnx/_internal/_exporter_legacy.py:108: UserWarning: torch.onnx.dynamo_export only implements opset version 18 for now. If you need to use a different opset version, please register them with register_custom_op.
  warnings.warn(
Applied 3 of general pattern rewrite rules.
Applied 1 of general pattern rewrite rules.
</pre></div>
</div>
<p>For forward, there are two files, one onnx model and the graph module
printed in a txt file. For backward, there are two onnx models.
Then it is multiplied by the number of backends.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">models</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">folder</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;exported models: </span><span class="si">{</span><span class="n">models</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>exported models: [&#39;llama_debug_0.onnx&#39;, &#39;llama_onnxrt_0.txt&#39;, &#39;llama_debug_0.txt&#39;, &#39;llama_onnxrt_0.onnx&#39;]
</pre></div>
</div>
<p>Inputs used by the debug backend</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">feeds</span> <span class="o">=</span> <span class="n">storage</span><span class="p">[</span><span class="s2">&quot;instance&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;inputs&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">feeds</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;-- </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">v</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>-- input0 float32 (2, 1024, 512)
-- input1 float32 (512, 512)
-- input2 float32 (512, 512)
-- input3 float32 (512, 512)
-- input4 float32 (32,)
-- input5 int64 (1, 1024)
-- input6 float32 (2, 1, 1024, 1024)
-- input7 float32 (512, 512)
</pre></div>
</div>
<p>Lets the first line of the graph module</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">graph_module</span> <span class="o">=</span> <span class="n">storage</span><span class="p">[</span><span class="s2">&quot;instance&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;graph_module&quot;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">graph_module</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)[:</span><span class="mi">10</span><span class="p">]))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>graph():
    %primals_1 : [num_users=3] = placeholder[target=primals_1]
    %primals_2 : [num_users=1] = placeholder[target=primals_2]
    %primals_3 : [num_users=1] = placeholder[target=primals_3]
    %primals_4 : [num_users=1] = placeholder[target=primals_4]
    %primals_5 : [num_users=1] = placeholder[target=primals_5]
    %primals_6 : [num_users=1] = placeholder[target=primals_6]
    %primals_7 : [num_users=1] = placeholder[target=primals_7]
    %primals_8 : [num_users=1] = placeholder[target=primals_8]
    %t : [num_users=1] = call_function[target=torch.ops.aten.t.default](args = (%primals_2,), kwargs = {})
</pre></div>
</div>
</section>
<section id="comparison-and-execution">
<h2>Comparison and execution<a class="headerlink" href="#comparison-and-execution" title="Link to this heading"></a></h2>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">backward</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;-- </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">storage</span><span class="p">[</span><span class="s1">&#39;instance&#39;</span><span class="p">])</span><span class="si">}</span><span class="s2"> onnx models were creates&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">inst</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">storage</span><span class="p">[</span><span class="s2">&quot;instance&quot;</span><span class="p">]):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  model </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">inst</span><span class="p">[</span><span class="s1">&#39;inputs&#39;</span><span class="p">])</span><span class="si">}</span><span class="s2"> runs&quot;</span><span class="p">)</span>

    <span class="c1"># deal with backward</span>
    <span class="n">onnx_models</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">sorted</span><span class="p">([</span><span class="n">m</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">models</span> <span class="k">if</span> <span class="n">m</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.onnx&quot;</span><span class="p">)]))</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">onnx_models</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;unexpected value </span><span class="si">{</span><span class="n">onnx_models</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="n">onnx_models</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">sorted</span><span class="p">([</span><span class="n">m</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">models</span> <span class="k">if</span> <span class="n">m</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.onnx&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="s2">&quot;_1&quot;</span> <span class="ow">in</span> <span class="n">m</span><span class="p">]))</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">onnx_models</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;unexpected value </span><span class="si">{</span><span class="n">onnx_models</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="n">model_onnxrt</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">onnx_models</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">model_debug</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">onnx_models</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">onnx_models</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">sorted</span><span class="p">([</span><span class="n">m</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">models</span> <span class="k">if</span> <span class="n">m</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.onnx&quot;</span><span class="p">)]))</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">onnx_models</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">model_onnxrt</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">onnx_models</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">model_debug</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">onnx_models</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">model_debug</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">onnx_models</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="c1"># the following error may appear:</span>
        <span class="c1"># Node type &#39;Rank&#39; from domain &#39;pkg.onnxscript.torch_lib.common&#39; is unknown</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;One model is missing, onnx_models=</span><span class="si">{</span><span class="n">onnx_models</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">model_onnxrt</span> <span class="o">=</span> <span class="n">model_debug</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;model_onnxrt=</span><span class="si">{</span><span class="n">model_onnxrt</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;model_debug=</span><span class="si">{</span><span class="n">model_debug</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>model_onnxrt=dump_models/llama_onnxrt_0.onnx
model_debug=dump_models/llama_debug_0.onnx
</pre></div>
</div>
<p>The inputs of both models</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;onnxrt:&quot;</span><span class="p">,</span> <span class="n">inputs_from_onnx_model</span><span class="p">(</span><span class="n">model_onnxrt</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;debug:&quot;</span><span class="p">,</span> <span class="n">inputs_from_onnx_model</span><span class="p">(</span><span class="n">model_debug</span><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>onnxrt: [(&#39;INPUT&#39;, &#39;primals_2&#39;, 1, (512, 512)), (&#39;INPUT&#39;, &#39;primals_1&#39;, 1, (2, 1024, 512)), (&#39;INPUT&#39;, &#39;primals_3&#39;, 1, (512, 512)), (&#39;INPUT&#39;, &#39;primals_4&#39;, 1, (512, 512)), (&#39;INPUT&#39;, &#39;primals_5&#39;, 1, (32,)), (&#39;INPUT&#39;, &#39;primals_6&#39;, 7, (1, 1024)), (&#39;INPUT&#39;, &#39;primals_7&#39;, 1, (2, 1, 1024, 1024)), (&#39;INPUT&#39;, &#39;primals_8&#39;, 1, (512, 512))]
debug: [(&#39;INPUT&#39;, &#39;input0&#39;, 1, (2, 1024, 512)), (&#39;INPUT&#39;, &#39;input1&#39;, 1, (512, 512)), (&#39;INPUT&#39;, &#39;input2&#39;, 1, (512, 512)), (&#39;INPUT&#39;, &#39;input3&#39;, 1, (512, 512)), (&#39;INPUT&#39;, &#39;input4&#39;, 1, (32,)), (&#39;INPUT&#39;, &#39;input5&#39;, 7, (1, 1024)), (&#39;INPUT&#39;, &#39;input6&#39;, 1, (2, 1, 1024, 1024)), (&#39;INPUT&#39;, &#39;input7&#39;, 1, (512, 512))]
</pre></div>
</div>
<p>Inputs are not the same. The first model has more and some inputs were
moved into the initializer list into for <cite>model_debug</cite>.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;debug:&quot;</span><span class="p">,</span> <span class="n">inputs_from_onnx_model</span><span class="p">(</span><span class="n">model_debug</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>debug: [(&#39;INPUT&#39;, &#39;input0&#39;, 1, (2, 1024, 512)), (&#39;INPUT&#39;, &#39;input1&#39;, 1, (512, 512)), (&#39;INPUT&#39;, &#39;input2&#39;, 1, (512, 512)), (&#39;INPUT&#39;, &#39;input3&#39;, 1, (512, 512)), (&#39;INPUT&#39;, &#39;input4&#39;, 1, (32,)), (&#39;INPUT&#39;, &#39;input5&#39;, 7, (1, 1024)), (&#39;INPUT&#39;, &#39;input6&#39;, 1, (2, 1, 1024, 1024)), (&#39;INPUT&#39;, &#39;input7&#39;, 1, (512, 512)), (&#39;INIT&#39;, &#39;init7_s2_2048_512&#39;, 7, (2,)), (&#39;INIT&#39;, &#39;init7_s3_2_1024_512&#39;, 7, (3,)), (&#39;INIT&#39;, &#39;init7_s4_2_1024_8_64&#39;, 7, (4,)), (&#39;INIT&#39;, &#39;init7_s1_1&#39;, 7, (1,)), (&#39;INIT&#39;, &#39;init7_s3_16_1024_64&#39;, 7, (3,)), (&#39;INIT&#39;, &#39;init7_s3_16_64_1024&#39;, 7, (3,)), (&#39;INIT&#39;, &#39;init1_s_2&#39;, 1, ()), (&#39;INIT&#39;, &#39;init7_s3_16_1024_1024&#39;, 7, (3,)), (&#39;INIT&#39;, &#39;init7_s2_0_2&#39;, 7, (2,)), (&#39;INIT&#39;, &#39;init7_s2_32_32&#39;, 7, (2,))]
</pre></div>
</div>
</section>
<section id="optimization-and-verification">
<h2>Optimization and Verification<a class="headerlink" href="#optimization-and-verification" title="Link to this heading"></a></h2>
<p>Lets try the model with a python backend (reference implementation).
First step, onnxscript uses many functions. The reference evaluation expects
every function to be defined so the order of functions in the model matters.
No recursivity is allowed by this runtime.
We need to reorder as function Rank is usually placed
at the end of the model.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">reorder_functions_in_proto</span><span class="p">(</span><span class="n">model_onnxrt</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&#39;dump_models/llama_onnxrt_0.onnx&#39;
</pre></div>
</div>
<p>Lets load the model and optimize them.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">debug</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">model_debug</span><span class="p">)</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">onnxrt</span> <span class="o">=</span> <span class="n">optimize_model_proto_oxs</span><span class="p">(</span><span class="n">onnx</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">model_onnxrt</span><span class="p">))</span>
<span class="k">except</span> <span class="ne">ImportError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;missing library&quot;</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span>
    <span class="n">onnxrt</span> <span class="o">=</span> <span class="n">debug</span>
</pre></div>
</div>
<p>Lets apply onnxruntime optimization</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">ortopt</span><span class="p">:</span>
    <span class="n">providers</span> <span class="o">=</span> <span class="p">(</span>
        <span class="p">[(</span><span class="s2">&quot;CUDAExecutionProvider&quot;</span><span class="p">,</span> <span class="p">{}),</span> <span class="p">(</span><span class="s2">&quot;CPUExecutionProvider&quot;</span><span class="p">,</span> <span class="p">{})]</span>
        <span class="k">if</span> <span class="n">use_cuda</span>
        <span class="k">else</span> <span class="p">[</span><span class="s2">&quot;CPUExecutionProvider&quot;</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">model_onnxrt</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;.onnx&quot;</span><span class="p">,</span> <span class="s2">&quot;.before.opt.onnx&quot;</span><span class="p">),</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">onnxrt</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">())</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;run onnxruntime optimization on </span><span class="si">{</span><span class="n">model_onnxrt</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">optimized</span> <span class="o">=</span> <span class="n">model_onnxrt</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;.onnx&quot;</span><span class="p">,</span> <span class="s2">&quot;.opt.onnx&quot;</span><span class="p">)</span>
    <span class="n">ort_optimize</span><span class="p">(</span><span class="n">onnxrt</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="n">optimized</span><span class="p">,</span> <span class="n">providers</span><span class="o">=</span><span class="n">providers</span><span class="p">)</span>
    <span class="n">onnxrt</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">optimized</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;run onnxruntime optimization on </span><span class="si">{</span><span class="n">model_debug</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">optimized</span> <span class="o">=</span> <span class="n">model_debug</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;.onnx&quot;</span><span class="p">,</span> <span class="s2">&quot;.opt.onnx&quot;</span><span class="p">)</span>
    <span class="n">ort_optimize</span><span class="p">(</span><span class="n">debug</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="n">optimized</span><span class="p">,</span> <span class="n">disable_aot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">providers</span><span class="o">=</span><span class="n">providers</span><span class="p">)</span>
    <span class="n">debug</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">optimized</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>run onnxruntime optimization on dump_models/llama_onnxrt_0.onnx
run onnxruntime optimization on dump_models/llama_debug_0.onnx
</pre></div>
</div>
<p>For whats following, we need to build two lists of matching inputs.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;build_matching_inputs&quot;</span><span class="p">)</span>
<span class="n">feedsrt</span> <span class="o">=</span> <span class="n">build_matching_inputs</span><span class="p">(</span><span class="n">model_debug</span><span class="p">,</span> <span class="n">feeds</span><span class="p">,</span> <span class="n">model_onnxrt</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;done&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>build_matching_inputs
done
</pre></div>
</div>
<p>We check both models are running.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">out_onnxrt</span> <span class="o">=</span> <span class="n">ExtendedReferenceEvaluator</span><span class="p">(</span><span class="n">onnxrt</span><span class="p">)</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">feedsrt</span><span class="p">)</span>
<span class="n">out_debug</span> <span class="o">=</span> <span class="n">ExtendedReferenceEvaluator</span><span class="p">(</span><span class="n">debug</span><span class="p">)</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">feeds</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">out_onnxrt</span>
<span class="k">assert</span> <span class="n">out_debug</span>

<span class="c1"># assert_all_close(out_onnxrt, out_debug)</span>
</pre></div>
</div>
<p>Side by side</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">res1</span><span class="p">,</span> <span class="n">res2</span><span class="p">,</span> <span class="n">align</span><span class="p">,</span> <span class="n">dc</span> <span class="o">=</span> <span class="n">compare_onnx_execution</span><span class="p">(</span>
    <span class="n">onnxrt</span><span class="p">,</span>
    <span class="n">debug</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">raise_exc</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">(</span><span class="n">feedsrt</span><span class="p">,</span> <span class="n">feeds</span><span class="p">),</span>
<span class="p">)</span>
<span class="n">text</span> <span class="o">=</span> <span class="n">dc</span><span class="o">.</span><span class="n">to_str</span><span class="p">(</span><span class="n">res1</span><span class="p">,</span> <span class="n">res2</span><span class="p">,</span> <span class="n">align</span><span class="p">,</span> <span class="n">column_size</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[compare_onnx_execution] execute with 2 inputs
[compare_onnx_execution] execute first model
[compare_onnx_execution] got 99 results
[compare_onnx_execution] execute second model
[compare_onnx_execution] got 99 results (first model)
[compare_onnx_execution] got 82 results (second model)
[compare_onnx_execution] compute edit distance
[compare_onnx_execution] got 110 pairs
[compare_onnx_execution] done
001 ~ | INITIA int64    1:4                  CKIM                 _val_140                         | INITIA int64    1:2                  USAA                 init7_s2_2048_512
002 - | INITIA int64                         AAAA                 aten_unsqueeze_75_dim_0          |
003 - | INITIA int64    1:1                  AAAA                 _val_18                          |
004 ~ | INITIA int64    1:3                  QKMA                 _val_264                         | INITIA int64    1:3                  CKSA                 init7_s3_2_1024_512
005 - | INITIA int64    1:2                  USAA                 _val_301                         |
006 - | INITIA int64                         CAAA                 aten_unsqueeze_159_dim_0         |
007 ~ | INITIA int64    1:3                  CKSA                 _val_90                          | INITIA int64    1:4                  CKIM                 init7_s4_2_1024_8_64
008 ~ | INITIA int64    1:1                  ?AAA                 _val_39                          | INITIA int64    1:1                  BAAA                 init7_s1_1
009 ~ | INITIA int64    1:3                  QKKA                 _val_287                         | INITIA int64    1:3                  QKMA                 init7_s3_16_1024_64
010 - | INITIA int64    1:1                  BAAA                 _val_167                         |
011 ~ | INITIA int64    1:3                  CKZA                 _val_298                         | INITIA int64    1:3                  QMKA                 init7_s3_16_64_1024
012 - | INITIA int64    1:4                  CIKM                 _val_293                         |
013 ~ | INITIA int64    1:4                  CIKK                 _val_274                         | INITIA int64    1:2                  GGAA                 init7_s2_32_32
014 ~ | INITIA int64    1:3                  QMKA                 _val_269                         | INITIA int64    1:3                  QKKA                 init7_s3_16_1024_1024
015 - | INITIA int64                         BAAA                 aten_unsqueeze_131_dim_0         |
016 ~ | INITIA int64    1:2                  GGAA                 splits_token_9                   | INITIA int64    1:2                  ACAA                 init7_s2_0_2
017 + |                                                                                            | INPUT  float32  3:2x1024x512         AQFY                 input0
018 - | INITIA float32                       IAAA                 _val_276                         |
019 - | INITIA int64    1:2                  GGAA                 splits                           |
020 = | INPUT  float32  2:512x512            VVWT                 primals_2                        | INPUT  float32  2:512x512            VVWT                 input1
021 - | INPUT  float32  3:2x1024x512         AQFY                 primals_1                        |
022 = | INPUT  float32  2:512x512            TPJA                 primals_3                        | INPUT  float32  2:512x512            TPJA                 input2
023 = | INPUT  float32  2:512x512            BLYZ                 primals_4                        | INPUT  float32  2:512x512            BLYZ                 input3
024 = | INPUT  float32  1:32                 DAAA                 primals_5                        | INPUT  float32  1:32                 DAAA                 input4
025 = | INPUT  int64    2:1x1024             KAQG                 primals_6                        | INPUT  int64    2:1x1024             KAQG                 input5
026 = | INPUT  float32  4:2x1x1024x1024      AAAA                 primals_7                        | INPUT  float32  4:2x1x1024x1024      AAAA                 input6
027 = | INPUT  float32  2:512x512            UBAA                 primals_8                        | INPUT  float32  2:512x512            UBAA                 input7
028 - | RESULT float32  2:512x512            UBAA Identity        t_6                              |
029 - | RESULT int64    2:1x1024             KAQG Slice           slice_2                          |
030 = | RESULT int64    3:1x1x1024           KAQG Unsqueeze       unsqueeze_2                      | RESULT int64    3:1x1x1024           KAQG Unsqueeze       unsqueeze_2
031 = | RESULT float32  3:1x1x1024           KAQG Cast            _to_copy                         | RESULT float32  3:1x1x1024           KAQG Cast            _to_copy
032 - | RESULT float32  2:1x32               DAAA Unsqueeze       unsqueeze                        |
033 = | RESULT float32  3:1x32x1             DAAA Unsqueeze       unsqueeze_1                      | RESULT float32  3:1x32x1             DAAA Unsqueeze       unsqueeze_1
034 + |                                                                                            | RESULT float32  3:1x32x1024          EFXM MatMul          bmm
035 - | RESULT float32  3:1x1024x32          XCHM FusedMatMul     transpose_3                      |
036 - | RESULT float32  3:1x1024x64          VFPY Concat          cat                              |
037 ~ | RESULT float32  3:1x1024x64          GSEC Sin             sin                              | RESULT float32  3:1x64x1024          JKJK Concat          cat_token_5
038 ~ | RESULT float32  4:1x1x1024x64        GSEC Unsqueeze       unsqueeze_4                      | RESULT float32  3:1x64x1024          RMRM Sin             sin_token_7
039 + |                                                                                            | RESULT float32  4:1x1x64x1024        RMRM Unsqueeze       Opset8
040 = | RESULT float32  4:1x1024x1x64        GSEC Transpose       Transpose_token_4_out0           | RESULT float32  4:1x1024x1x64        GSEC Transpose       Transpose_token_9_out0
041 = | RESULT float32  2:2048x512           AQFY Reshape         view                             | RESULT float32  2:2048x512           AQFY Reshape         output_2
042 ~ | RESULT float32  2:2048x512           FCFK FusedMatMul     mm_1                             | RESULT float32  2:2048x512           FCFK Gemm            mm_1
043 - | RESULT float32  3:2x1024x512         FCFK Reshape         _unsafe_view_1                   |
044 = | RESULT float32  4:2x1024x8x64        FCFK Reshape         view_4                           | RESULT float32  4:2x1024x8x64        FCFK Reshape         view_4
045 = | RESULT float32  4:2x1024x8x32        HKXW Split           Slice_263                        | RESULT float32  4:2x1024x8x32        HKXW Split           SlicesSplitPattern--slice_Tensor
046 = | RESULT float32  4:2x1024x8x32        YTIP Split           Slice_280                        | RESULT float32  4:2x1024x8x32        YTIP Split           SlicesSplitPattern--slice_Tensor
047 = | RESULT float32  4:2x1024x8x32        CHSL Neg             aten_neg_290_n0                  | RESULT float32  4:2x1024x8x32        CHSL Neg             neg2
048 = | RESULT float32  4:2x1024x8x64        JSPH Concat          Concat_294                       | RESULT float32  4:2x1024x8x64        JSPH Concat          cat3
049 = | RESULT float32  4:2x1024x8x64        DEIF Mul             Mul_315                          | RESULT float32  4:2x1024x8x64        DEIF Mul             mul_Tensor10
050 + |                                                                                            | RESULT float32  3:1x64x1024          NHNH Cos             cos_token_12
051 ~ | RESULT float32  3:1x1024x64          CJYF Cos             cos                              | RESULT float32  4:1x1x64x1024        NHNH Unsqueeze       Opset7
052 - | RESULT float32  4:1x1x1024x64        CJYF Unsqueeze       unsqueeze_3                      |
053 = | RESULT float32  4:1x1024x1x64        CJYF Transpose       Transpose_token_6_out0           | RESULT float32  4:1x1024x1x64        CJYF Transpose       Transpose_token_14_out0
054 = | RESULT float32  4:2x1024x8x64        VAAN Mul             Mul_313                          | RESULT float32  4:2x1024x8x64        VAAN Mul             mul_Tensor9
055 = | RESULT float32  4:2x1024x8x64        YFIS Add             Add_317                          | RESULT float32  4:2x1024x8x64        YFIS Add             add_Tensor2
056 = | RESULT float32  4:2x8x64x1024        GYLP Transpose       transpose_4                      | RESULT float32  4:2x8x64x1024        GYLP Transpose       transpose_4
057 + |                                                                                            | RESULT float32  4:1x1x1024x64        GSEC Transpose       output_5
058 ~ | RESULT float32  3:16x64x1024         GYLP Reshape         _unsafe_view_4                   | RESULT float32  2:2048x512           AQFY Reshape         output_1
059 ~ | RESULT float32  2:2048x512           NOEE FusedMatMul     mm                               | RESULT float32  2:2048x512           NOEE Gemm            mm
060 - | RESULT float32  3:2x1024x512         NOEE Reshape         _unsafe_view                     |
061 = | RESULT float32  4:2x1024x8x64        NOEE Reshape         view_3                           | RESULT float32  4:2x1024x8x64        NOEE Reshape         view_3
062 = | RESULT float32  4:2x8x1024x64        ISFD Transpose       transpose                        | RESULT float32  4:2x8x1024x64        ISFD Transpose       transpose
063 = | RESULT float32  4:2x8x1024x32        VJCW Split           slice_4                          | RESULT float32  4:2x8x1024x32        VJCW Split           slice_4
064 = | RESULT float32  4:2x8x1024x32        NJCI Split           slice_5                          | RESULT float32  4:2x8x1024x32        NJCI Split           slice_5
065 = | RESULT float32  4:2x8x1024x32        NRYS Neg             neg                              | RESULT float32  4:2x8x1024x32        NRYS Neg             neg
066 = | RESULT float32  4:2x8x1024x64        IAAO Concat          cat_1                            | RESULT float32  4:2x8x1024x64        IAAO Concat          cat_1
067 = | RESULT float32  4:2x8x1024x64        GPXJ Mul             mul_3                            | RESULT float32  4:2x8x1024x64        GPXJ Mul             mul_3
068 + |                                                                                            | RESULT float32  4:1x1x1024x64        CJYF Transpose       output_4
069 = | RESULT float32  4:2x8x1024x64        ZVIJ Mul             mul_2                            | RESULT float32  4:2x8x1024x64        ZVIJ Mul             mul_2
070 = | RESULT float32  4:2x8x1024x64        FLET Add             add                              | RESULT float32  4:2x8x1024x64        FLET Add             add
071 - | RESULT float32  3:16x1024x64         FLET Reshape         _unsafe_view_3                   |
072 - | RESULT float32  3:16x1024x1024       SCDJ MatMul          bmm_1                            |
073 - | RESULT float32  4:2x8x1024x1024      SCDJ Reshape         view_9                           |
074 ~ | RESULT float32  4:2x8x1024x1024      MUUK Div             div                              | RESULT float32  4:2x8x1024x1024      MUUK FusedMatMul     div
075 - | RESULT float32  4:2x1x1024x1024      AAAA Slice           slice_8                          |
076 = | RESULT float32  4:2x8x1024x1024      MUUK Add             add_2                            | RESULT float32  4:2x8x1024x1024      MUUK Add             add_2
077 = | RESULT float32  4:2x8x1024x1024      NONO Softmax         _softmax                         | RESULT float32  4:2x8x1024x1024      NONO Softmax         output_8
078 - | RESULT float32  3:16x1024x1024       NONO Reshape         view_10                          |
079 ~ | RESULT float32  2:2048x512           AJXE FusedMatMul     mm_2                             | RESULT float32  2:2048x512           AQFY Reshape         output_3
080 ~ | RESULT float32  3:2x1024x512         AJXE Reshape         _unsafe_view_2                   | RESULT float32  2:2048x512           AJXE Gemm            mm_2
081 = | RESULT float32  4:2x1024x8x64        AJXE Reshape         view_5                           | RESULT float32  4:2x1024x8x64        AJXE Reshape         view_5
082 = | RESULT float32  4:2x8x1024x64        ZJPN Transpose       transpose_2                      | RESULT float32  4:2x8x1024x64        ZJPN Transpose       transpose_2
083 ~ | RESULT float32  3:16x1024x64         ZJPN Reshape         _unsafe_view_5                   | RESULT float32  4:2x8x1024x64        SVOJ MatMul          view_11
084 ~ | RESULT float32  3:16x1024x64         SVOJ MatMul          bmm_2                            | RESULT float32  4:2x1024x8x64        HFNK Transpose       transpose_5
085 ~ | RESULT float32  4:2x8x1024x64        SVOJ Reshape         view_11                          | RESULT float32  2:2048x512           HFNK Reshape         output_12
086 ~ | RESULT float32  4:2x1024x8x64        HFNK Transpose       transpose_5                      | RESULT float32  2:2048x512           IENO Gemm            mm_3
087 ~ | RESULT float32  3:2x1024x512         HFNK Reshape         view_12                          | RESULT float32  3:2x1024x512         IENO Reshape         output_0
088 + |                                                                                            | RESULT float32  3:16x1024x1024       NONO Reshape         output_9
089 ~ | RESULT float32  2:2048x512           HFNK Reshape         view_13                          | RESULT float32  3:16x64x1024         GYLP Reshape         output_7
090 ~ | RESULT float32  2:2048x512           IENO FusedMatMul     mm_3                             | RESULT float32  3:16x1024x64         FLET Reshape         output_6
091 ~ | RESULT float32  3:2x1024x512         IENO Reshape         _unsafe_view_6                   | RESULT float32  3:16x1024x64         ZJPN Reshape         output_10
092 + |                                                                                            | RESULT float32  2:512x512            BAUA Transpose       output_11
093 - | RESULT float32  3:16x1024x1024       NONO Transpose       transpose_7                      |
094 - | RESULT float32  4:2x8x1024x1024      NONO Identity        detach_3                         |
095 ~ | RESULT float32  3:16x1024x64         GYLP Transpose       transpose_10                     | OUTPUT float32  3:2x1024x512         IENO                 output_0
096 ~ | RESULT float32  3:16x64x1024         FLET Transpose       transpose_9                      | OUTPUT float32  2:2048x512           AQFY                 output_1
097 - | RESULT float32  3:16x64x1024         ZJPN Transpose       transpose_8                      |
098 = | OUTPUT float32  2:2048x512           AQFY                 view                             | OUTPUT float32  2:2048x512           AQFY                 output_2
099 - | OUTPUT float32  2:512x512            UBAA                 t_6                              |
100 ~ | OUTPUT float32  3:16x64x1024         ZJPN                 transpose_8                      | OUTPUT float32  2:2048x512           AQFY                 output_3
101 ~ | OUTPUT float32  3:1x1024x64          VFPY                 cat                              | OUTPUT float32  4:1x1x1024x64        CJYF                 output_4
102 + |                                                                                            | OUTPUT float32  4:1x1x1024x64        GSEC                 output_5
103 + |                                                                                            | OUTPUT float32  3:16x1024x64         FLET                 output_6
104 ~ | OUTPUT float32  3:16x64x1024         FLET                 transpose_9                      | OUTPUT float32  3:16x64x1024         GYLP                 output_7
105 - | OUTPUT float32  3:16x1024x64         GYLP                 transpose_10                     |
106 = | OUTPUT float32  4:2x8x1024x1024      NONO                 detach_3                         | OUTPUT float32  4:2x8x1024x1024      NONO                 output_8
107 = | OUTPUT float32  3:16x1024x1024       NONO                 transpose_7                      | OUTPUT float32  3:16x1024x1024       NONO                 output_9
108 ~ | OUTPUT float32  2:2048x512           HFNK                 view_13                          | OUTPUT float32  3:16x1024x64         ZJPN                 output_10
109 + |                                                                                            | OUTPUT float32  2:512x512            BAUA                 output_11
110 ~ | OUTPUT float32  3:2x1024x512         IENO                 _unsafe_view_6                   | OUTPUT float32  2:2048x512           HFNK                 output_12
</pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (0 minutes 9.059 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-plot-llama-diff-dort-301-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/07848d67c63402eb50188bccdae8294c/plot_llama_diff_dort_301.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_llama_diff_dort_301.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/91e7afc966f0756ee964af12f62c49a7/plot_llama_diff_dort_301.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_llama_diff_dort_301.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../_downloads/9f91242a146dfb8f7aabc9f1d092900a/plot_llama_diff_dort_301.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">plot_llama_diff_dort_301.zip</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="plot_llama_bench_102.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">102: Measure LLAMA speed</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="plot_llama_diff_export_301.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">301: Compares LLAMA exporters</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2023-2024
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">301: Compares LLAMA exporters for onnxrt backend</a><ul>
<li><a class="reference internal" href="#some-helpers">Some helpers</a></li>
<li><a class="reference internal" href="#the-exporting-functions">The exporting functions</a></li>
<li><a class="reference internal" href="#model-and-data">Model and data</a></li>
<li><a class="reference internal" href="#exporting">Exporting</a></li>
<li><a class="reference internal" href="#comparison-and-execution">Comparison and execution</a></li>
<li><a class="reference internal" href="#optimization-and-verification">Optimization and Verification</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../_static/documentation_options.js?v=a1637f0b"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/furo.js?v=5fa4622c"></script>
    </body>
</html>