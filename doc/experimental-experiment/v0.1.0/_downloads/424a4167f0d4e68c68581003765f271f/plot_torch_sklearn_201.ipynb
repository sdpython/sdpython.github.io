{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# 201: Use torch to export a scikit-learn model into ONNX\n\nWhen :epkg:`sklearn-onnx` is missing a converter, :epkg:`torch` can be used\nto write it. We use :class:`sklearn.impute.KNNImputer` as an example.\nThe first step is to rewrite the scikit-learn model with torch functions.\nThe code is then refactored and split into submodules to be able\nto bypass some pieces :func:`torch.export.export` cannot process.\n\n## torch implementation of nan_euclidean\n\nLet's start with a simple case, a pairwise distance.\nSee :func:`sklearn.metrics.nan_euclidean`.\n\n### Module\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import contextlib\nimport io\nimport logging\nimport math\nimport numbers\nimport subprocess\nimport sys\nimport warnings\nfrom typing import Any, Dict, List, Optional\nimport numpy as np\nimport onnx\nfrom onnx.reference.ops.op_topk import TopK_11 as TopK\nimport sklearn\nimport torch\nimport onnxruntime\nfrom experimental_experiment.reference import ExtendedReferenceEvaluator\nfrom experimental_experiment.xbuilder import GraphBuilder\nfrom experimental_experiment.helpers import max_diff, pretty_onnx\nfrom experimental_experiment.skl.helpers import flatnonzero, _get_weights\nfrom experimental_experiment.torch_interpreter import make_undefined_dimension, Dispatcher\nfrom experimental_experiment.torch_interpreter.onnx_export_errors import (\n    bypass_export_some_errors,\n)\nfrom experimental_experiment.torch_interpreter.piece_by_piece import (\n    trace_execution_piece_by_piece,\n    CustomOpStrategy,\n)\nfrom experimental_experiment.xbuilder.reverse_graph_builder import to_graph_builder_code\n\n\nclass NanEuclidean(torch.nn.Module):\n    \"\"\"Implements :func:`sklearn.metrics.nan_euclidean`.\"\"\"\n\n    def __init__(self, squared=False, copy=True):\n        super().__init__()\n        self.squared = squared\n        self.copy = copy\n\n    def forward(self, X, Y):\n        X = X.clone()\n        Y = Y.to(X.dtype).clone()\n\n        missing_X = torch.isnan(X)\n        missing_Y = torch.isnan(Y)\n\n        # set missing values to zero\n        X[missing_X] = 0\n        Y[missing_Y] = 0\n\n        # Adjust distances for missing values\n        XX = X * X\n        YY = Y * Y\n\n        distances = -2 * X @ Y.T + XX.sum(1, keepdim=True) + YY.sum(1, keepdim=True).T\n\n        distances -= XX @ missing_Y.to(X.dtype).T\n        distances -= missing_X.to(X.dtype) @ YY.T\n\n        distances = torch.clip(distances, 0, None)\n\n        present_X = 1 - missing_X.to(X.dtype)\n        present_Y = ~missing_Y\n        present_count = present_X @ present_Y.to(X.dtype).T\n        distances[present_count == 0] = torch.nan\n        # avoid divide by zero\n        present_count = torch.maximum(\n            torch.tensor([1], dtype=present_count.dtype), present_count\n        )\n        distances /= present_count\n        distances *= X.shape[1]\n\n        if not self.squared:\n            distances = distances.sqrt()\n\n        return distances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Validation\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = NanEuclidean()\nX = torch.randn((5, 3))\nY = torch.randn((5, 3))\nfor i in range(5):\n    X[i, i % X.shape[1]] = torch.nan\nfor i in range(4):\n    Y[i + 1, i % X.shape[1]] = torch.nan\n\nd1 = sklearn.metrics.nan_euclidean_distances(X.numpy(), Y.numpy())\nd2 = model(X, Y)\nprint(f\"discrepancies: {max_diff(d1, d2)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## torch implementation of KNNImputer\n\nSee :class:`sklearn.impute.KNNImputer`.\nThe code is split into several :class:`torch.nn.Module`\nand refactored to avoid control flow.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def _get_mask(X, value_to_mask):\n    return (\n        torch.isnan(X)\n        if (  # sklearn.utils._missing.is_scalar_nan(value_to_mask)\n            not isinstance(value_to_mask, numbers.Integral)\n            and isinstance(value_to_mask, numbers.Real)\n            and math.isnan(value_to_mask)\n        )\n        else (value_to_mask == X)\n    )\n\n\nclass SubTopKIndices(torch.nn.Module):\n    def forward(self, x, k):\n        # torch does not like nans\n        xn = torch.nan_to_num(x, nan=1.0e10)\n        return torch.topk(xn, k, dim=1, largest=False, sorted=True).indices\n\n\nclass SubWeightMatrix(torch.nn.Module):\n    def __init__(self, weights):\n        super().__init__()\n        self.weights = weights\n\n    def forward(self, donors_dist):\n        weight_matrix = _get_weights(donors_dist, self.weights)\n        if weight_matrix is not None:\n            weight_matrix = weight_matrix.clone()\n            weight_matrix[torch.isnan(weight_matrix)] = 0.0\n        else:\n            weight_matrix = torch.ones_like(donors_dist)\n            weight_matrix[torch.isnan(donors_dist)] = 0.0\n        return weight_matrix\n\n\nclass SubDonorsIdx(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self._topk = SubTopKIndices()\n\n    def forward(self, dist_pot_donors, n_neighbors):\n        donors_idx = self._topk(dist_pot_donors, n_neighbors)\n        indices = torch.arange(donors_idx.shape[0])\n        indices_extended = indices[:, None]\n        donors_dist = dist_pot_donors[indices_extended, donors_idx]\n        return donors_idx, donors_dist\n\n\nclass MakeNewWeights(torch.nn.Module):\n    def forward(self, donors_mask, donors, weight_matrix):\n        return donors_mask.to(donors.dtype) * weight_matrix.to(donors.dtype)\n\n\nclass CalcImpute(torch.nn.Module):\n    \"\"\"Implements :meth:`sklearn.impute.KNNImputer._calc_impute`.\"\"\"\n\n    def __init__(self, weights):\n        super().__init__()\n        self._weights = SubWeightMatrix(weights)\n        self._donors_idx = SubDonorsIdx()\n        self._make_new_neights = MakeNewWeights()\n\n    def _calc_impute(self, dist_pot_donors, n_neighbors, fit_X_col, mask_fit_X_col):\n        donors_idx, donors_dist = self._donors_idx(dist_pot_donors, n_neighbors)\n        weight_matrix = self._weights(donors_dist)\n        # Retrieve donor values and calculate kNN average\n        donors = fit_X_col.take(donors_idx)\n        donors_mask = torch.tensor([1], dtype=donors_idx.dtype) - (\n            mask_fit_X_col.take(donors_idx)\n        ).to(donors_idx.dtype)\n\n        new_weights = self._make_new_neights(donors_mask, donors, weight_matrix)\n\n        weights_sum = new_weights.sum(axis=1, keepdim=True)\n        div = torch.where(\n            weights_sum == 0, torch.tensor([1], dtype=weights_sum.dtype), weights_sum\n        )\n        res = (donors * new_weights).sum(axis=1, keepdim=True) / div\n        return res.squeeze(dim=1).to(dist_pot_donors.dtype)\n\n    def forward(self, dist_pot_donors, n_neighbors, fit_X_col, mask_fit_X_col):\n        return self._calc_impute(dist_pot_donors, n_neighbors, fit_X_col, mask_fit_X_col)\n\n\nclass ColProcessor(torch.nn.Module):\n    \"\"\"Processes one column (= one feature).\"\"\"\n\n    def __init__(self, col, n_neighbors, weights):\n        super().__init__()\n        self._calc_impute = CalcImpute(weights)\n        self.col = col\n        self.n_neighbors = n_neighbors\n\n    def process_one_col(\n        self,\n        X,\n        dist_chunk,\n        non_missing_fix_X,\n        mask_fit_X,\n        dist_idx_map,\n        mask,\n        row_missing_idx,\n        _fit_X,\n    ):\n        col = self.col\n        X = X.clone()\n        row_missing_chunk = row_missing_idx\n        col_mask = mask[row_missing_chunk, col]\n\n        potential_donors_idx = torch.nonzero(non_missing_fix_X[:, col], as_tuple=True)[0]\n\n        # receivers_idx are indices in X\n        receivers_idx = row_missing_chunk[flatnonzero(col_mask)]\n\n        # distances for samples that needed imputation for column\n        dist_subset = dist_chunk[dist_idx_map[receivers_idx]][:, potential_donors_idx]\n\n        # receivers with all nan distances impute with mean\n        all_nan_dist_mask = torch.isnan(dist_subset).all(axis=1)\n        all_nan_receivers_idx = receivers_idx[all_nan_dist_mask]\n\n        # when all_nan_receivers_idx is not empty (training set is small)\n        mask_ = (~mask_fit_X[:, col]).to(_fit_X.dtype)\n        mask_sum = mask_.to(X.dtype).sum()\n\n        col_sum = (_fit_X[mask_ == 1, col]).sum().to(X.dtype)\n        div = torch.where(mask_sum > 0, mask_sum, torch.tensor([1], dtype=mask_sum.dtype))\n        X[all_nan_receivers_idx, col] = col_sum / div\n\n        # receivers with at least one defined distance\n        receivers_idx = receivers_idx[~all_nan_dist_mask]\n        dist_subset = dist_chunk[dist_idx_map[receivers_idx]][:, potential_donors_idx]\n\n        # when all_nan_receivers_idx is not empty (training set is big)\n        tn = torch.tensor(self.n_neighbors)\n        n_neighbors = torch.where(\n            tn < potential_donors_idx.shape[0], tn, potential_donors_idx.shape[0]\n        )\n        # to make sure n_neighbors > 0\n        n_neighbors = torch.where(\n            n_neighbors <= 0, torch.tensor([1], dtype=n_neighbors.dtype), n_neighbors\n        )\n        value = self._calc_impute(\n            dist_subset,\n            n_neighbors,\n            _fit_X[potential_donors_idx, col],\n            mask_fit_X[potential_donors_idx, col],\n        )\n        X[receivers_idx, col] = value.to(X.dtype)\n        return X\n\n    def forward(\n        self,\n        X,\n        dist_chunk,\n        non_missing_fix_X,\n        mask_fit_X,\n        dist_idx_map,\n        mask,\n        row_missing_idx,\n        _fit_X,\n    ):\n        return self.process_one_col(\n            X,\n            dist_chunk,\n            non_missing_fix_X,\n            mask_fit_X,\n            dist_idx_map,\n            mask,\n            row_missing_idx,\n            _fit_X,\n        )\n\n\nclass MakeDictIdxMap(torch.nn.Module):\n    def forward(self, X, row_missing_idx):\n        dist_idx_map = torch.zeros(X.shape[0], dtype=int)\n        dist_idx_map[row_missing_idx] = torch.arange(row_missing_idx.shape[0])\n        return dist_idx_map\n\n\nclass TorchKNNImputer(torch.nn.Module):\n    def __init__(self, knn_imputer):\n        super().__init__()\n        assert (\n            knn_imputer.metric == \"nan_euclidean\"\n        ), f\"Not implemented for metric={knn_imputer.metric!r}\"\n        self.dist = NanEuclidean()\n        cols = []\n        for col in range(knn_imputer._fit_X.shape[1]):\n            cols.append(ColProcessor(col, knn_imputer.n_neighbors, knn_imputer.weights))\n        self.columns = torch.nn.ModuleList(cols)\n        # refactoring\n        self._make_dict_idx_map = MakeDictIdxMap()\n        # knn imputer\n        self.missing_values = knn_imputer.missing_values\n        self.n_neighbors = knn_imputer.n_neighbors\n        self.weights = knn_imputer.weights\n        self.metric = knn_imputer.metric\n        self.keep_empty_features = knn_imputer.keep_empty_features\n        self.add_indicator = knn_imputer.add_indicator\n        # results of fitting\n        self.indicator_ = knn_imputer.indicator_\n        # The training results.\n        # self._fit_X = torch.from_numpy(knn_imputer._fit_X.astype(np.float32))\n        # self._mask_fit_X = torch.from_numpy(knn_imputer._mask_fit_X)\n        # self._valid_mask = torch.from_numpy(knn_imputer._valid_mask)\n\n    def _transform_indicator(self, X):\n        if self.add_indicator:\n            if not hasattr(self, \"indicator_\"):\n                raise ValueError(\n                    \"Make sure to call _fit_indicator before _transform_indicator\"\n                )\n            raise NotImplementedError(type(self.indicator_))\n            # return self.indicator_.transform(X)\n        return None\n\n    def _concatenate_indicator(self, X_imputed, X_indicator):\n        if not self.add_indicator:\n            return X_imputed\n        if X_indicator is None:\n            raise ValueError(\n                \"Data from the missing indicator are not provided. Call \"\n                \"_fit_indicator and _transform_indicator in the imputer \"\n                \"implementation.\"\n            )\n        return torch.cat([X_imputed, X_indicator], dim=0)\n\n    def transform(self, mask_fit_X, _valid_mask, _fit_X, X):\n        X = X.clone()\n        mask = _get_mask(X, self.missing_values)\n\n        X_indicator = self._transform_indicator(mask)\n\n        row_missing_idx = flatnonzero(mask[:, _valid_mask].any(axis=1))\n        non_missing_fix_X = torch.logical_not(mask_fit_X)\n\n        # Maps from indices from X to indices in dist matrix\n        dist_idx_map = self._make_dict_idx_map(X, row_missing_idx)\n\n        # process in fixed-memory chunks\n        pairwise_distances = self.dist(X[row_missing_idx, :], _fit_X)\n\n        # The export unfold the loop as it depends on the number of features.\n        # Fixed in this case.\n        for col_processor in self.columns:\n            X = col_processor(\n                X,\n                pairwise_distances,\n                non_missing_fix_X,\n                mask_fit_X,\n                dist_idx_map,\n                mask,\n                row_missing_idx,\n                _fit_X,\n            )\n\n        if self.keep_empty_features:\n            Xc = X.clone()\n            Xc[:, ~_valid_mask] = 0\n        else:\n            Xc = X[:, _valid_mask]\n\n        return self._concatenate_indicator(Xc, X_indicator)\n\n    def forward(self, _mask_fit_X, _valid_mask, _fit_X, X):\n        return self.transform(_mask_fit_X, _valid_mask, _fit_X, X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Validation\n\nWe need to do that with different sizes of training set.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def validate(size, sizey):\n    X = torch.randn((size, 3))\n    Y = torch.randn((sizey, 3))\n    for i in range(X.shape[0]):\n        X[i, i % X.shape[1]] = torch.nan\n    for i in range(Y.shape[0] - 1):\n        Y[i + 1, i % X.shape[1]] = torch.nan\n\n    knn_imputer = sklearn.impute.KNNImputer(n_neighbors=3)\n    knn_imputer.fit(X)\n\n    model = TorchKNNImputer(knn_imputer)\n\n    p1 = knn_imputer.transform(Y)\n    p2 = model.transform(\n        torch.from_numpy(knn_imputer._mask_fit_X),\n        torch.from_numpy(knn_imputer._valid_mask),\n        torch.from_numpy(knn_imputer._fit_X.astype(np.float32)),\n        Y,\n    )\n    d = max_diff(p1, p2)\n    assert d[\"abs\"] < 1e-5, f\"Discrepancies for size={size} and sizey={sizey}, d={d}\"\n    print(f\"knn discrepancies for size={size}: {d}\")\n\n    p1 = knn_imputer.transform(Y[1:2])\n    p2 = model.transform(\n        torch.from_numpy(knn_imputer._mask_fit_X),\n        torch.from_numpy(knn_imputer._valid_mask),\n        torch.from_numpy(knn_imputer._fit_X.astype(np.float32)),\n        Y[1:2],\n    )\n    d = max_diff(p1, p2)\n    assert d[\"abs\"] < 1e-5, f\"Discrepancies for size={size} and sizey={sizey}, d={d}\"\n    print(f\"knn discrepancies for size={size}: {d}\")\n    return knn_imputer, Y\n\n\nknn5, Y10 = validate(5, 10)\nknn50, Y40 = validate(50, 40)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export to ONNX\n\nThe module cannot be exported as is because one operator :func:`torch.topk`\nexpects a fixed number of neighbour but the model makes it variable.\nThis is case not supported by :func:`torch.export.export`.\nWe need to isolate that part before exporting the model.\nIt is done by replacing it with a custom op.\nThis is automatically done by function :func:`trace_execution_piece_by_piece`.\n\nFirst step, we create two sets of inputs. A function will use this\nto infer the dynamic shapes.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inputs = [\n    (\n        (\n            torch.from_numpy(knn50._mask_fit_X),\n            torch.from_numpy(knn50._valid_mask),\n            torch.from_numpy(knn50._fit_X.astype(np.float32)),\n            Y40,\n        ),\n        {},\n    ),\n    (\n        (\n            torch.from_numpy(knn5._mask_fit_X),\n            torch.from_numpy(knn5._valid_mask),\n            torch.from_numpy(knn5._fit_X.astype(np.float32)),\n            Y10,\n        ),\n        {},\n    ),\n]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we trace the execution to capture every input and output of every submodule.\nThe model implementation was refactored to introduce many tiny one and get\na fine-grained evaluation of the exportability.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trace = trace_execution_piece_by_piece(TorchKNNImputer(knn5), inputs, verbose=0)\npretty = trace.get_export_report()\nprint(pretty)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The dynamic shapes for the whole model:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"dynamic shapes:\")\nprint(trace.guess_dynamic_shapes())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The method ``try_export`` cannot infer all links between input shapes and output shapes\nfor every submodule. The following function fills this gap.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "shape_functions = {\n    \"NanEuclidean\": {\n        0: lambda *args, **kwargs: torch.empty(\n            (args[0].shape[0], args[1].shape[0]), dtype=args[0].dtype\n        )\n    },\n    \"CalcImpute\": {\n        0: lambda *args, **kwargs: torch.empty((args[0].shape[0],), dtype=args[0].dtype)\n    },\n    \"SubTopKIndices\": {\n        0: lambda *args, **kwargs: torch.empty(\n            (\n                args[0].shape[0],\n                make_undefined_dimension(min(args[0].shape[1], knn5.n_neighbors)),\n            ),\n            dtype=args[0].dtype,\n        )\n    },\n    \"SubDonorsIdx\": {\n        0: lambda *args, **kwargs: torch.empty(\n            (\n                args[0].shape[0],\n                make_undefined_dimension(min(args[0].shape[1], knn5.n_neighbors)),\n            ),\n            dtype=args[0].dtype,\n        ),\n        1: lambda *args, **kwargs: torch.empty(\n            (\n                args[0].shape[0],\n                make_undefined_dimension(min(args[0].shape[1], knn5.n_neighbors)),\n            ),\n            dtype=torch.float32,\n        ),\n    },\n    \"MakeDictIdxMap\": {\n        0: lambda *args, **kwargs: torch.empty((args[0].shape[0],), dtype=args[1].dtype),\n    },\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we we try to export piece by piece.\nWe capture the standard output to avoid being overwhelmed\nand we use function :func:`bypass_export_some_errors` to skip some\nerrors with shape checking made by :mod:`torch`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "logging.disable(logging.CRITICAL)\n\nwith contextlib.redirect_stderr(io.StringIO()), bypass_export_some_errors():\n    ep = trace.try_export(\n        exporter=\"fx\",\n        use_dynamic_shapes=True,\n        exporter_kwargs=dict(strict=False),\n        replace_by_custom_op=CustomOpStrategy.LOCAL,\n        verbose=0,\n        shape_functions=shape_functions,\n    )\n\nassert ep.status in (\n    ep.status.OK,\n    ep.status.OK_CHILDC,\n), f\"FAIL: {ep}\\n-- report --\\n{trace.get_export_report()}\"\nprint(trace.get_export_report())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``OK`` means the module is exportable. ``OK_CHILDC`` means the module\ncan be exported after its submodules are replaced by custom ops.\nIt works except for the topk function. ``FAIL`` means\nthe submodule cannot be exported at all but that\nmodule is simple enough and its ONNX conversion can be provided.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Final step\n\nWe first start by running the decompositions on every exported program.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "with warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n\n    for t in trace:\n        if t.exporter_status.exported is None:\n            print(f\"[run_decompositions] {t.dot_name} - skipped\")\n            continue\n        print(f\"[run_decompositions] {t.dot_name}\")\n        t.exporter_status.exported = t.exporter_status.exported.run_decompositions({})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's export everything. Every submodule is exported as a local function\nexcept topk for which we must provide an ONNX conversion.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "T = str\n\n\ndef onnx_topk_indices(\n    g: GraphBuilder,\n    sts: Optional[Dict[str, Any]],\n    outputs: List[str],\n    x: T,\n    k: T,\n    name: str = \"topk\",\n):\n    assert len(outputs) == 1, f\"Only one output is expected but outputs={outputs}\"\n    unique_name = g.unique_name(\"unused_topk_values\")\n    g.op.TopK(x, k, name=name, outputs=[unique_name, *outputs], largest=False, sorted=True)\n    return outputs[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's check it is working somehow.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x = torch.tensor([[0, 1, 2], [6, 5, 4]], dtype=torch.float32)\nprint(\"torch.topk\", torch.topk(x, k=2).indices)\nprint(\"onnx.topk\", TopK.eval(x.numpy(), np.array([2], dtype=np.int64))[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And with nan values\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x = torch.tensor([[0, np.nan, 2], [6, np.nan, 4]], dtype=torch.float32)\nprint(\"torch.topk\", torch.topk(torch.nan_to_num(x, nan=-1.0e10), k=2).indices)\nprint(\"onnx.topk\", TopK.eval(x.numpy(), np.array([2], dtype=np.int64))[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "That works. Then the dispatcher maps the custom ops calling topk to\nthe previous converter functions.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dispatcher = Dispatcher(\n    {\n        (\n            \"diag_lib::C_TorchKNNImputer_columns_0___calc_impute__donors_idx__topk\"\n        ): onnx_topk_indices,\n        (\n            \"diag_lib::C_TorchKNNImputer_columns_1___calc_impute__donors_idx__topk\"\n        ): onnx_topk_indices,\n        (\n            \"diag_lib::C_TorchKNNImputer_columns_2___calc_impute__donors_idx__topk\"\n        ): onnx_topk_indices,\n    }\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's run the conversion. We also check the conversion into ONNX\nis accurate. It is doable because every intermediate results\nwere previously traced.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "onx = trace.to_onnx_local(\n    verbose=1,\n    dispatcher=dispatcher,\n    check_conversion_cls=dict(cls=ExtendedReferenceEvaluator, atol=1e-5, rtol=1e-5),\n    inline=False,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's save it.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "onnx.save(onx, \"plot_torch_sklearn_201.onnx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also print it.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(pretty_onnx(onx))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Validation\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def validate_onnx(size, sizey, onx, verbose: int = 1, use_ort: bool = False):\n    X = torch.randn((size, 3))\n    Y = torch.randn((sizey, 3))\n    for i in range(X.shape[0]):\n        X[i, i % X.shape[1]] = torch.nan\n    for i in range(Y.shape[0] - 1):\n        Y[i + 1, i % X.shape[1]] = torch.nan\n\n    knn_imputer = sklearn.impute.KNNImputer(n_neighbors=3)\n    knn_imputer.fit(X)\n\n    model = TorchKNNImputer(knn_imputer)\n\n    expected = p1 = knn_imputer.transform(Y)\n\n    model_inputs = (\n        torch.from_numpy(knn_imputer._mask_fit_X),\n        torch.from_numpy(knn_imputer._valid_mask),\n        torch.from_numpy(knn_imputer._fit_X.astype(np.float32)),\n        Y,\n    )\n    p2 = model.transform(*model_inputs)\n    d = max_diff(p1, p2)\n    assert d[\"abs\"] < 1e-5, f\"Discrepancies for size={size} and sizey={sizey}, d={d}\"\n    if verbose:\n        print(f\"Torch Discrepancies for size={size} and sizey={sizey}, d={d}\")\n\n    input_names = [i.name for i in onx.graph.input]\n    feeds = feeds0 = dict(zip(input_names, [t.numpy() for t in model_inputs]))\n\n    if verbose:\n        print(\"python: loading the model...\")\n    sess = ExtendedReferenceEvaluator(onx, verbose=0)\n    if verbose:\n        print(\"python: running the model...\")\n    got = sess.run(None, feeds)\n    d = max_diff(p1, got[0])\n    assert d[\"abs\"] < 1e-5, f\"ONNX Discrepancies for size={size} and sizey={sizey}, d={d}\"\n    if verbose:\n        print(f\"ONNX Discrepancies for size={size} and sizey={sizey}, d={d}\")\n\n    if use_ort:\n        if verbose:\n            print(\"onnxruntime: loading the model...\")\n        opts = onnxruntime.SessionOptions()\n        opts.optimized_model_filepath = \"plot_torch_sklearn_201.ort.onnx\"\n        opts.log_severity_level = 0\n        opts.log_verbosity_level = 0\n        sess = onnxruntime.InferenceSession(\n            onx.SerializeToString(), opts, providers=[\"CPUExecutionProvider\"]\n        )\n        if verbose:\n            print(\"onnxruntime: running the model...\")\n        got = sess.run(None, feeds)\n        d = max_diff(p1, got[0])\n        assert d[\"abs\"] < 1e-5, f\"ONNX Discrepancies for size={size} and sizey={sizey}, d={d}\"\n        if verbose:\n            print(f\"ONNX Discrepancies for size={size} and sizey={sizey}, d={d}\")\n\n    model_inputs = (\n        torch.from_numpy(knn_imputer._mask_fit_X),\n        torch.from_numpy(knn_imputer._valid_mask),\n        torch.from_numpy(knn_imputer._fit_X.astype(np.float32)),\n        Y[1:2],\n    )\n    p1 = knn_imputer.transform(Y[1:2])\n    p2 = model.transform(*model_inputs)\n    d = max_diff(p1, p2)\n    assert d[\"abs\"] < 1e-5, f\"Discrepancies for size={size} and sizey={sizey}, d={d}\"\n    feeds = dict(zip(input_names, [t.numpy() for t in model_inputs]))\n    if verbose:\n        print(\"ReferenceEvaluator: running the model...\")\n    got = sess.run(None, feeds)\n    d = max_diff(p1, got[0])\n    assert d[\"abs\"] < 1e-5, f\"ONNX Discrepancies for size={size} and sizey={sizey}, d={d}\"\n    if verbose:\n        print(\"done\")\n    return feeds0, expected\n\n\n# This does not work yet.\nfeeds, expected = validate_onnx(5, 10, onx)\nvalidate_onnx(50, 40, onx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ModelProto to python Code\n\nWe finally call function :func:`to_graph_builder_code\n<experimental_experiment.xbuilder.reverse_graph_builder.to_graph_builder_code>`\nto convert the onnx model into pseudo code if that helps moving that code\nto a converter library (:epkg:`sklearn-onnx`).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "code = to_graph_builder_code(onx)\naddition = (\n    f\"\"\"\n\nfeeds = {feeds!r}\nexpected = {expected!r}\nref = ExtendedReferenceEvaluator(model)\ngot = ref.run(None, feeds)\nprint(\"disrepancies:\", max_diff(expected, got[0]))\n\"\"\".replace(\n        \"nan\", \"np.nan\"\n    )\n    .replace(\"array\", \"np.array\")\n    .replace(\"float32\", \"np.float32\")\n)\ncode = f\"\"\"\nfrom experimental_experiment.reference import ExtendedReferenceEvaluator\nfrom experimental_experiment.helpers import max_diff\n{code}\n{addition}\n\"\"\"\nprint(code)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's finally check it produces the same results.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "with open(\"_plot_torch_sklearn_201_knnpy.py\", \"w\") as f:\n    f.write(code)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's run it...\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "subprocess.run([sys.executable, \"_plot_torch_sklearn_201_knnpy.py\"])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}