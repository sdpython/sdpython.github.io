{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# 101: Profile an existing model with onnxruntime\n\nProfiles any onnx model on CPU.\n\n## Preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom experimental_experiment.args import get_parsed_args\n\ntry:\n    from onnx_extended.tools.js_profile import (\n        js_profile_to_dataframe,\n        plot_ort_profile,\n    )\nexcept ImportError:\n    js_profile_to_dataframe = None\n\ntry:\n    filename = os.path.join(\n        os.path.dirname(__file__ or \"\"), \"data\", \"example_4700-CPUep-opt.onnx\"\n    )\nexcept NameError:\n    filename = \"data/example_4700-CPUep-opt.onnx\"\n\nscript_args = get_parsed_args(\n    \"plot_profile_existing_onnx\",\n    filename=(filename, \"input file\"),\n    repeat=10,\n    expose=\"\",\n)\n\n\nfor att in \"filename,repeat\".split(\",\"):\n    print(f\"{att}={getattr(script_args, att)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Random inputs.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def create_random_input(sess):\n    feeds = {}\n    for i in sess.get_inputs():\n        shape = i.shape\n        ot = i.type\n        if ot == \"tensor(float)\":\n            dtype = np.float32\n        else:\n            raise ValueError(f\"Unsupposed onnx type {ot}.\")\n        t = np.random.rand(*shape).astype(dtype)\n        feeds[i.name] = t\n    return feeds\n\n\ndef create_session(filename, profiling=False):\n    from onnxruntime import InferenceSession, SessionOptions\n\n    if not profiling:\n        return InferenceSession(filename, providers=[\"CPUExecutionProvider\"])\n    opts = SessionOptions()\n    opts.enable_profiling = True\n    return InferenceSession(filename, opts, providers=[\"CPUExecutionProvider\"])\n\n\nsess = create_session(script_args.filename)\nfeeds = create_random_input(sess)\nsess.run(None, feeds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Profiling\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sess = create_session(script_args.filename, profiling=True)\n\nfor _ in range(script_args.repeat):\n    sess.run(None, feeds)\n\nprof = sess.end_profiling()\nif js_profile_to_dataframe is not None:\n    df = js_profile_to_dataframe(prof, first_it_out=True)\n    print(df.columns)\n    df.to_csv(\"plot_profile_existing_onnx.csv\")\n    df.to_excel(\"plot_profile_existing_onnx.xlsx\")\n    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n\n    plot_ort_profile(df, ax[0], ax[1], \"dort\")\n    fig.tight_layout()\n    fig.savefig(\"plot_profile_existing_onnx.png\")\nelse:\n    print(\"Install onnx-extended first.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}