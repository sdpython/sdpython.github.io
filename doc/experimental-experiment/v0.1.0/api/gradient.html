<!doctype html>
<html class="no-js" lang="en" data-content_root="../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="graph_builder" href="graph_builder.html" /><link rel="prev" title="API" href="index.html" />

    <!-- Generated with Sphinx 7.2.6 and Furo 2024.01.29 -->
        <title>gradient - experimental-experiment 0.1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=135e06be" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css?v=7f9a90b1" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css?v=eafc0fe6" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=61a4c737" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=36a5483c" />
    
    


<style>
  body {
    --color-code-background: #eeffcc;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">experimental-experiment 0.1.0 documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="../_static/logo.png" alt="Logo"/>
  </div>
  
  <span class="sidebar-brand-text">experimental-experiment 0.1.0 documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Contents</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../tutorial/index.html">Tutorial</a></li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="index.html">API</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of API</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2 current current-page"><a class="current reference internal" href="#">gradient</a></li>
<li class="toctree-l2"><a class="reference internal" href="graph_builder.html">graph_builder</a></li>
<li class="toctree-l2"><a class="reference internal" href="graph_builder_pattern.html">graph_builder_optim</a></li>
<li class="toctree-l2"><a class="reference internal" href="interpreter.html">interpreter</a></li>
<li class="toctree-l2"><a class="reference internal" href="onnx_export.html">onnx_export</a></li>
<li class="toctree-l2"><a class="reference internal" href="aten_function.html">aten_functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="convert.html">convert</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch_helper.html">torch_helper</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch_dynamo.html">torch_dynamo</a></li>
<li class="toctree-l2"><a class="reference internal" href="misc.html">Othersâ€¦</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../auto_examples/index.html">Example gallery</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of Example gallery</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_optimize.html">Graph Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/bug_dort.html">To ignore</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_profile_existing_onnx.html">Profile an existing model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_torch_linreg.html">Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_torch_custom_backend.html">A custom backend for torch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_convolutation_matmul.html">Convolution and Matrix Multiplication</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_llama_diff_export.html">Compares LLAMA exporters</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_llama_bench.html">Measure LLAMA speed</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_llama_diff_dort.html">Compares LLAMA exporters for onnxrt backend</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_torch_dort.html">Evaluate DORT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_torch_aot.html">Evaluate DORT Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_torch_export.html">Evaluate different ways to export a torch model to ONNX</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">More</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../CHANGELOGS.html">Change Logs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
<li class="toctree-l1"><a class="reference internal" href="../long_outputs.html">Long Outputs uneasy to read</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <section id="gradient">
<h1>gradient<a class="headerlink" href="#gradient" title="Link to this heading">#</a></h1>
<section id="gradient-grad-helper">
<h2>gradient.grad_helper<a class="headerlink" href="#gradient-grad-helper" title="Link to this heading">#</a></h2>
<section id="derivativeoptions">
<h3>DerivativeOptions<a class="headerlink" href="#derivativeoptions" title="Link to this heading">#</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="experimental_experiment.gradient.grad_helper.DerivativeOptions">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">experimental_experiment.gradient.grad_helper.</span></span><span class="sig-name descname"><span class="pre">DerivativeOptions</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/experimental_experiment/gradient/grad_helper.html#DerivativeOptions"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#experimental_experiment.gradient.grad_helper.DerivativeOptions" title="Link to this definition">#</a></dt>
<dd><p>Options defining how to build the onnx graph of the
gradients.</p>
<ul class="simple">
<li><p><cite>Zero</cite>: default option, all options are disabled</p></li>
<li><p><cite>KeepYieldOp</cite>: keeps the operator <em>YieldOp</em> in the graph,
see &#64;see fn onnx_derivative</p></li>
<li><p><cite>KeepOutputs</cite>: keeps the output of the original graph</p></li>
<li><p><cite>FillGrad</cite>: does not add any output to specify the gradient
of the output but assumes it is one</p></li>
<li><p><cite>Loss</cite>: the function assumes the loss was added to the graph</p></li>
</ul>
</dd></dl>

</section>
<section id="onnx-derivative">
<h3>onnx_derivative<a class="headerlink" href="#onnx-derivative" title="Link to this heading">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="experimental_experiment.gradient.grad_helper.onnx_derivative">
<span class="sig-prename descclassname"><span class="pre">experimental_experiment.gradient.grad_helper.</span></span><span class="sig-name descname"><span class="pre">onnx_derivative</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">onx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="(in ONNX v1.17.0)"><span class="pre">ModelProto</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#experimental_experiment.gradient.grad_helper.DerivativeOptions" title="experimental_experiment.gradient.grad_helper.DerivativeOptions"><span class="pre">DerivativeOptions</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">DerivativeOptions.Zero</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">path_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="(in ONNX v1.17.0)"><span class="pre">ModelProto</span></a></span></span><a class="reference internal" href="../_modules/experimental_experiment/gradient/grad_helper.html#onnx_derivative"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#experimental_experiment.gradient.grad_helper.onnx_derivative" title="Link to this definition">#</a></dt>
<dd><p>Builds the gradient for an onnx graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>onx</strong> â€“ onnx graph</p></li>
<li><p><strong>weights</strong> â€“ gradient against those weights, None for all real weights</p></li>
<li><p><strong>inputs</strong> â€“ gradient against inputs, None for all real inputs</p></li>
<li><p><strong>options</strong> â€“ options of type &#64;see cl DerivativeOptions</p></li>
<li><p><strong>loss</strong> â€“ loss output in case a loss was added in the graph,
<em>options</em> must be equal to <cite>DerivativeOptions.Loss</cite></p></li>
<li><p><strong>label</strong> â€“ if <em>loss</em> is specified, then the label must be
specified as well</p></li>
<li><p><strong>path_name</strong> â€“ if <em>options</em> equal to <cite>DerivativeOptions.Loss</cite>,
the gradient is saved to that path</p></li>
<li><p><strong>verbose</strong> â€“ verbosity</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>onnx graph</p>
</dd>
</dl>
<p>The function calls <em>OrtModuleGraphBuilderConfiguration</em>
from <a class="reference external" href="https://onnxruntime.ai/docs/get-started/training-on-device.html">onnxruntime-training</a>. This graph is meant to be used
with &#64;see cl OrtGradientForwardBackward and includes
operator <cite>YieldOp</cite>. Thatâ€™s the graph looks this way:</p>
<div class="graphviz"><img src="../_images/graphviz-a1d2865f8e64efb5238cdb5a26a68598efd03e47.png" alt="digraph{
  ranksep=0.25;
  size=7;
  orientation=portrait;
  nodesep=0.05;

  X [shape=box color=red label=&quot;X\nTensorProto.FLOAT\nshape=['', 10]&quot; fontsize=10];
  Ad_Addcst [shape=box color=red label=&quot;Ad_Addcst\nTensorProto.FLOAT\nshape=[1]&quot; fontsize=10];

  X_grad [shape=box color=green label=&quot;X_grad\nTensorProto.FLOAT\nshape=['', 10]&quot; fontsize=10];
  Ad_Addcst_grad [shape=box color=green label=&quot;Ad_Addcst_grad\nTensorProto.FLOAT\nshape=[1]&quot; fontsize=10];


  Y [shape=box label=&quot;Y&quot; fontsize=10];
  Ad_Add [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Add&quot; fontsize=10];
  X -&gt; Ad_Add;
  Ad_Addcst -&gt; Ad_Add;
  Ad_Add -&gt; Y;

  Y_grad [shape=box label=&quot;Y_grad&quot; fontsize=10];
  YieldOp [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;YieldOp\nfull_shape_outputs=[0]&quot; fontsize=10];
  Y -&gt; YieldOp;
  YieldOp -&gt; Y_grad;

  Ad_Add_Grad_Shape_Ad_Addcst [shape=box label=&quot;Ad_Add_Grad_Shape_Ad_Addcst&quot; fontsize=10];
  Ad_Add_Grad_Shape_Ad_Addcst_rhs [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Shape&quot; fontsize=10];
  Ad_Addcst -&gt; Ad_Add_Grad_Shape_Ad_Addcst_rhs;
  Ad_Add_Grad_Shape_Ad_Addcst_rhs -&gt; Ad_Add_Grad_Shape_Ad_Addcst;

  Ad_Add_Grad_Shape_X [shape=box label=&quot;Ad_Add_Grad_Shape_X&quot; fontsize=10];
  Ad_Add_Grad_Shape_X_lhs [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Shape&quot; fontsize=10];
  X -&gt; Ad_Add_Grad_Shape_X_lhs;
  Ad_Add_Grad_Shape_X_lhs -&gt; Ad_Add_Grad_Shape_X;

  Ad_Add_Grad_ReduceAxes_X [shape=box label=&quot;Ad_Add_Grad_ReduceAxes_X&quot; fontsize=10];
  Ad_Add_Grad_ReduceAxes_Ad_Addcst [shape=box label=&quot;Ad_Add_Grad_ReduceAxes_Ad_Addcst&quot; fontsize=10];
  Ad_Add_Grad_BroadcastGradientArgs_2 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;BroadcastGradientArgs&quot; fontsize=10];
  Ad_Add_Grad_Shape_X -&gt; Ad_Add_Grad_BroadcastGradientArgs_2;
  Ad_Add_Grad_Shape_Ad_Addcst -&gt; Ad_Add_Grad_BroadcastGradientArgs_2;
  Ad_Add_Grad_BroadcastGradientArgs_2 -&gt; Ad_Add_Grad_ReduceAxes_X;
  Ad_Add_Grad_BroadcastGradientArgs_2 -&gt; Ad_Add_Grad_ReduceAxes_Ad_Addcst;

  Ad_Add_Grad_ReduceSum_Y_grad_for_Ad_Addcst [shape=box label=&quot;Ad_Add_Grad_ReduceSum_Y_grad_for_Ad_Addcst&quot; fontsize=10];
  Ad_Add_Grad_ReduceSum_5 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;ReduceSum\nkeepdims=1\nnoop_with_empty_axes=1&quot; fontsize=10];
  Y_grad -&gt; Ad_Add_Grad_ReduceSum_5;
  Ad_Add_Grad_ReduceAxes_Ad_Addcst -&gt; Ad_Add_Grad_ReduceSum_5;
  Ad_Add_Grad_ReduceSum_5 -&gt; Ad_Add_Grad_ReduceSum_Y_grad_for_Ad_Addcst;

  Ad_Add_Grad_Reshape_6 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Reshape\nallowzero=0&quot; fontsize=10];
  Ad_Add_Grad_ReduceSum_Y_grad_for_Ad_Addcst -&gt; Ad_Add_Grad_Reshape_6;
  Ad_Add_Grad_Shape_Ad_Addcst -&gt; Ad_Add_Grad_Reshape_6;
  Ad_Add_Grad_Reshape_6 -&gt; Ad_Addcst_grad;

  Ad_Add_Grad_ReduceSum_Y_grad_for_X [shape=box label=&quot;Ad_Add_Grad_ReduceSum_Y_grad_for_X&quot; fontsize=10];
  Ad_Add_Grad_ReduceSum_3 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;ReduceSum\nkeepdims=1\nnoop_with_empty_axes=1&quot; fontsize=10];
  Y_grad -&gt; Ad_Add_Grad_ReduceSum_3;
  Ad_Add_Grad_ReduceAxes_X -&gt; Ad_Add_Grad_ReduceSum_3;
  Ad_Add_Grad_ReduceSum_3 -&gt; Ad_Add_Grad_ReduceSum_Y_grad_for_X;

  Ad_Add_Grad_Reshape_4 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Reshape\nallowzero=0&quot; fontsize=10];
  Ad_Add_Grad_ReduceSum_Y_grad_for_X -&gt; Ad_Add_Grad_Reshape_4;
  Ad_Add_Grad_Shape_X -&gt; Ad_Add_Grad_Reshape_4;
  Ad_Add_Grad_Reshape_4 -&gt; X_grad;
}" class="graphviz" /></div>
<p>These operators are the outputs of the
initial graph and must be replaced by the gradient of these
outputs to compute the gradient of the weights and the inputs.
After they are replaced, it looks this way:</p>
<div class="graphviz"><img src="../_images/graphviz-a3fc4269ebf12fcb7581541fe4e4afb2df732989.png" alt="digraph{
  ranksep=0.25;
  size=7;
  orientation=portrait;
  nodesep=0.05;

  X [shape=box color=red label=&quot;X\nTensorProto.FLOAT\nshape=['', 10]&quot; fontsize=10];
  Ad_Addcst [shape=box color=red label=&quot;Ad_Addcst\nTensorProto.FLOAT\nshape=[1]&quot; fontsize=10];
  Y_grad [shape=box color=red label=&quot;Y_grad\nTensorProto.FLOAT\nshape=['', 10]&quot; fontsize=10];

  X_grad [shape=box color=green label=&quot;X_grad\nTensorProto.FLOAT\nshape=['', 10]&quot; fontsize=10];
  Ad_Addcst_grad [shape=box color=green label=&quot;Ad_Addcst_grad\nTensorProto.FLOAT\nshape=[1]&quot; fontsize=10];


  Ad_Add_Grad_Shape_Ad_Addcst [shape=box label=&quot;Ad_Add_Grad_Shape_Ad_Addcst&quot; fontsize=10];
  Ad_Add_Grad_Shape_Ad_Addcst_rhs [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Shape&quot; fontsize=10];
  Ad_Addcst -&gt; Ad_Add_Grad_Shape_Ad_Addcst_rhs;
  Ad_Add_Grad_Shape_Ad_Addcst_rhs -&gt; Ad_Add_Grad_Shape_Ad_Addcst;

  Ad_Add_Grad_Shape_X [shape=box label=&quot;Ad_Add_Grad_Shape_X&quot; fontsize=10];
  Ad_Add_Grad_Shape_X_lhs [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Shape&quot; fontsize=10];
  X -&gt; Ad_Add_Grad_Shape_X_lhs;
  Ad_Add_Grad_Shape_X_lhs -&gt; Ad_Add_Grad_Shape_X;

  Ad_Add_Grad_ReduceAxes_X [shape=box label=&quot;Ad_Add_Grad_ReduceAxes_X&quot; fontsize=10];
  Ad_Add_Grad_ReduceAxes_Ad_Addcst [shape=box label=&quot;Ad_Add_Grad_ReduceAxes_Ad_Addcst&quot; fontsize=10];
  Ad_Add_Grad_BroadcastGradientArgs_2 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;BroadcastGradientArgs&quot; fontsize=10];
  Ad_Add_Grad_Shape_X -&gt; Ad_Add_Grad_BroadcastGradientArgs_2;
  Ad_Add_Grad_Shape_Ad_Addcst -&gt; Ad_Add_Grad_BroadcastGradientArgs_2;
  Ad_Add_Grad_BroadcastGradientArgs_2 -&gt; Ad_Add_Grad_ReduceAxes_X;
  Ad_Add_Grad_BroadcastGradientArgs_2 -&gt; Ad_Add_Grad_ReduceAxes_Ad_Addcst;

  Ad_Add_Grad_ReduceSum_Y_grad_for_Ad_Addcst [shape=box label=&quot;Ad_Add_Grad_ReduceSum_Y_grad_for_Ad_Addcst&quot; fontsize=10];
  Ad_Add_Grad_ReduceSum_5 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;ReduceSum\nkeepdims=1\nnoop_with_empty_axes=1&quot; fontsize=10];
  Y_grad -&gt; Ad_Add_Grad_ReduceSum_5;
  Ad_Add_Grad_ReduceAxes_Ad_Addcst -&gt; Ad_Add_Grad_ReduceSum_5;
  Ad_Add_Grad_ReduceSum_5 -&gt; Ad_Add_Grad_ReduceSum_Y_grad_for_Ad_Addcst;

  Ad_Add_Grad_Reshape_6 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Reshape\nallowzero=0&quot; fontsize=10];
  Ad_Add_Grad_ReduceSum_Y_grad_for_Ad_Addcst -&gt; Ad_Add_Grad_Reshape_6;
  Ad_Add_Grad_Shape_Ad_Addcst -&gt; Ad_Add_Grad_Reshape_6;
  Ad_Add_Grad_Reshape_6 -&gt; Ad_Addcst_grad;

  Ad_Add_Grad_ReduceSum_Y_grad_for_X [shape=box label=&quot;Ad_Add_Grad_ReduceSum_Y_grad_for_X&quot; fontsize=10];
  Ad_Add_Grad_ReduceSum_3 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;ReduceSum\nkeepdims=1\nnoop_with_empty_axes=1&quot; fontsize=10];
  Y_grad -&gt; Ad_Add_Grad_ReduceSum_3;
  Ad_Add_Grad_ReduceAxes_X -&gt; Ad_Add_Grad_ReduceSum_3;
  Ad_Add_Grad_ReduceSum_3 -&gt; Ad_Add_Grad_ReduceSum_Y_grad_for_X;

  Ad_Add_Grad_Reshape_4 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Reshape\nallowzero=0&quot; fontsize=10];
  Ad_Add_Grad_ReduceSum_Y_grad_for_X -&gt; Ad_Add_Grad_Reshape_4;
  Ad_Add_Grad_Shape_X -&gt; Ad_Add_Grad_Reshape_4;
  Ad_Add_Grad_Reshape_4 -&gt; X_grad;
}" class="graphviz" /></div>
<p>The user can still compute the outputs.</p>
<div class="graphviz"><img src="../_images/graphviz-b633b633ac285c592b6468d36e94bc781cdfac6f.png" alt="digraph{
  ranksep=0.25;
  size=7;
  orientation=portrait;
  nodesep=0.05;

  X [shape=box color=red label=&quot;X\nTensorProto.FLOAT\nshape=['', 10]&quot; fontsize=10];
  Ad_Addcst [shape=box color=red label=&quot;Ad_Addcst\nTensorProto.FLOAT\nshape=[1]&quot; fontsize=10];
  Y_grad [shape=box color=red label=&quot;Y_grad\nTensorProto.FLOAT\nshape=['', 10]&quot; fontsize=10];

  X_grad [shape=box color=green label=&quot;X_grad\nTensorProto.FLOAT\nshape=['', 10]&quot; fontsize=10];
  Ad_Addcst_grad [shape=box color=green label=&quot;Ad_Addcst_grad\nTensorProto.FLOAT\nshape=[1]&quot; fontsize=10];
  Y [shape=box color=green label=&quot;Y\nTensorProto.FLOAT\nshape=['', 10]&quot; fontsize=10];


  Ad_Add [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Add&quot; fontsize=10];
  X -&gt; Ad_Add;
  Ad_Addcst -&gt; Ad_Add;
  Ad_Add -&gt; Y;

  Ad_Add_Grad_Shape_Ad_Addcst [shape=box label=&quot;Ad_Add_Grad_Shape_Ad_Addcst&quot; fontsize=10];
  Ad_Add_Grad_Shape_Ad_Addcst_rhs [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Shape&quot; fontsize=10];
  Ad_Addcst -&gt; Ad_Add_Grad_Shape_Ad_Addcst_rhs;
  Ad_Add_Grad_Shape_Ad_Addcst_rhs -&gt; Ad_Add_Grad_Shape_Ad_Addcst;

  Ad_Add_Grad_Shape_X [shape=box label=&quot;Ad_Add_Grad_Shape_X&quot; fontsize=10];
  Ad_Add_Grad_Shape_X_lhs [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Shape&quot; fontsize=10];
  X -&gt; Ad_Add_Grad_Shape_X_lhs;
  Ad_Add_Grad_Shape_X_lhs -&gt; Ad_Add_Grad_Shape_X;

  Ad_Add_Grad_ReduceAxes_X [shape=box label=&quot;Ad_Add_Grad_ReduceAxes_X&quot; fontsize=10];
  Ad_Add_Grad_ReduceAxes_Ad_Addcst [shape=box label=&quot;Ad_Add_Grad_ReduceAxes_Ad_Addcst&quot; fontsize=10];
  Ad_Add_Grad_BroadcastGradientArgs_2 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;BroadcastGradientArgs&quot; fontsize=10];
  Ad_Add_Grad_Shape_X -&gt; Ad_Add_Grad_BroadcastGradientArgs_2;
  Ad_Add_Grad_Shape_Ad_Addcst -&gt; Ad_Add_Grad_BroadcastGradientArgs_2;
  Ad_Add_Grad_BroadcastGradientArgs_2 -&gt; Ad_Add_Grad_ReduceAxes_X;
  Ad_Add_Grad_BroadcastGradientArgs_2 -&gt; Ad_Add_Grad_ReduceAxes_Ad_Addcst;

  Ad_Add_Grad_ReduceSum_Y_grad_for_Ad_Addcst [shape=box label=&quot;Ad_Add_Grad_ReduceSum_Y_grad_for_Ad_Addcst&quot; fontsize=10];
  Ad_Add_Grad_ReduceSum_5 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;ReduceSum\nkeepdims=1\nnoop_with_empty_axes=1&quot; fontsize=10];
  Y_grad -&gt; Ad_Add_Grad_ReduceSum_5;
  Ad_Add_Grad_ReduceAxes_Ad_Addcst -&gt; Ad_Add_Grad_ReduceSum_5;
  Ad_Add_Grad_ReduceSum_5 -&gt; Ad_Add_Grad_ReduceSum_Y_grad_for_Ad_Addcst;

  Ad_Add_Grad_Reshape_6 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Reshape\nallowzero=0&quot; fontsize=10];
  Ad_Add_Grad_ReduceSum_Y_grad_for_Ad_Addcst -&gt; Ad_Add_Grad_Reshape_6;
  Ad_Add_Grad_Shape_Ad_Addcst -&gt; Ad_Add_Grad_Reshape_6;
  Ad_Add_Grad_Reshape_6 -&gt; Ad_Addcst_grad;

  Ad_Add_Grad_ReduceSum_Y_grad_for_X [shape=box label=&quot;Ad_Add_Grad_ReduceSum_Y_grad_for_X&quot; fontsize=10];
  Ad_Add_Grad_ReduceSum_3 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;ReduceSum\nkeepdims=1\nnoop_with_empty_axes=1&quot; fontsize=10];
  Y_grad -&gt; Ad_Add_Grad_ReduceSum_3;
  Ad_Add_Grad_ReduceAxes_X -&gt; Ad_Add_Grad_ReduceSum_3;
  Ad_Add_Grad_ReduceSum_3 -&gt; Ad_Add_Grad_ReduceSum_Y_grad_for_X;

  Ad_Add_Grad_Reshape_4 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Reshape\nallowzero=0&quot; fontsize=10];
  Ad_Add_Grad_ReduceSum_Y_grad_for_X -&gt; Ad_Add_Grad_Reshape_4;
  Ad_Add_Grad_Shape_X -&gt; Ad_Add_Grad_Reshape_4;
  Ad_Add_Grad_Reshape_4 -&gt; X_grad;
}" class="graphviz" /></div>
<p>The input gradient can be filled with a constant matrix
filled with one and with the expected shape.</p>
<div class="graphviz"><img src="../_images/graphviz-338f95d99698ce28c04b05b480cca13935c208a2.png" alt="digraph{
  ranksep=0.25;
  size=7;
  orientation=portrait;
  nodesep=0.05;

  X [shape=box color=red label=&quot;X\nTensorProto.FLOAT\nshape=['', 10]&quot; fontsize=10];
  Ad_Addcst [shape=box color=red label=&quot;Ad_Addcst\nTensorProto.FLOAT\nshape=[1]&quot; fontsize=10];

  X_grad [shape=box color=green label=&quot;X_grad\nTensorProto.FLOAT\nshape=['', 10]&quot; fontsize=10];
  Ad_Addcst_grad [shape=box color=green label=&quot;Ad_Addcst_grad\nTensorProto.FLOAT\nshape=[1]&quot; fontsize=10];
  Y [shape=box color=green label=&quot;Y\nTensorProto.FLOAT\nshape=['', 10]&quot; fontsize=10];


  Ad_Add [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Add&quot; fontsize=10];
  X -&gt; Ad_Add;
  Ad_Addcst -&gt; Ad_Add;
  Ad_Add -&gt; Y;

  Y_shape [shape=box label=&quot;Y_shape&quot; fontsize=10];
  Shape [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Shape&quot; fontsize=10];
  Y -&gt; Shape;
  Shape -&gt; Y_shape;

  Y_grad [shape=box label=&quot;Y_grad&quot; fontsize=10];
  ConstantOfShape [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;ConstantOfShape\nvalue=[1.]&quot; fontsize=10];
  Y_shape -&gt; ConstantOfShape;
  ConstantOfShape -&gt; Y_grad;

  Ad_Add_Grad_Shape_Ad_Addcst [shape=box label=&quot;Ad_Add_Grad_Shape_Ad_Addcst&quot; fontsize=10];
  Ad_Add_Grad_Shape_Ad_Addcst_rhs [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Shape&quot; fontsize=10];
  Ad_Addcst -&gt; Ad_Add_Grad_Shape_Ad_Addcst_rhs;
  Ad_Add_Grad_Shape_Ad_Addcst_rhs -&gt; Ad_Add_Grad_Shape_Ad_Addcst;

  Ad_Add_Grad_Shape_X [shape=box label=&quot;Ad_Add_Grad_Shape_X&quot; fontsize=10];
  Ad_Add_Grad_Shape_X_lhs [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Shape&quot; fontsize=10];
  X -&gt; Ad_Add_Grad_Shape_X_lhs;
  Ad_Add_Grad_Shape_X_lhs -&gt; Ad_Add_Grad_Shape_X;

  Ad_Add_Grad_ReduceAxes_X [shape=box label=&quot;Ad_Add_Grad_ReduceAxes_X&quot; fontsize=10];
  Ad_Add_Grad_ReduceAxes_Ad_Addcst [shape=box label=&quot;Ad_Add_Grad_ReduceAxes_Ad_Addcst&quot; fontsize=10];
  Ad_Add_Grad_BroadcastGradientArgs_2 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;BroadcastGradientArgs&quot; fontsize=10];
  Ad_Add_Grad_Shape_X -&gt; Ad_Add_Grad_BroadcastGradientArgs_2;
  Ad_Add_Grad_Shape_Ad_Addcst -&gt; Ad_Add_Grad_BroadcastGradientArgs_2;
  Ad_Add_Grad_BroadcastGradientArgs_2 -&gt; Ad_Add_Grad_ReduceAxes_X;
  Ad_Add_Grad_BroadcastGradientArgs_2 -&gt; Ad_Add_Grad_ReduceAxes_Ad_Addcst;

  Ad_Add_Grad_ReduceSum_Y_grad_for_Ad_Addcst [shape=box label=&quot;Ad_Add_Grad_ReduceSum_Y_grad_for_Ad_Addcst&quot; fontsize=10];
  Ad_Add_Grad_ReduceSum_5 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;ReduceSum\nkeepdims=1\nnoop_with_empty_axes=1&quot; fontsize=10];
  Y_grad -&gt; Ad_Add_Grad_ReduceSum_5;
  Ad_Add_Grad_ReduceAxes_Ad_Addcst -&gt; Ad_Add_Grad_ReduceSum_5;
  Ad_Add_Grad_ReduceSum_5 -&gt; Ad_Add_Grad_ReduceSum_Y_grad_for_Ad_Addcst;

  Ad_Add_Grad_Reshape_6 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Reshape\nallowzero=0&quot; fontsize=10];
  Ad_Add_Grad_ReduceSum_Y_grad_for_Ad_Addcst -&gt; Ad_Add_Grad_Reshape_6;
  Ad_Add_Grad_Shape_Ad_Addcst -&gt; Ad_Add_Grad_Reshape_6;
  Ad_Add_Grad_Reshape_6 -&gt; Ad_Addcst_grad;

  Ad_Add_Grad_ReduceSum_Y_grad_for_X [shape=box label=&quot;Ad_Add_Grad_ReduceSum_Y_grad_for_X&quot; fontsize=10];
  Ad_Add_Grad_ReduceSum_3 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;ReduceSum\nkeepdims=1\nnoop_with_empty_axes=1&quot; fontsize=10];
  Y_grad -&gt; Ad_Add_Grad_ReduceSum_3;
  Ad_Add_Grad_ReduceAxes_X -&gt; Ad_Add_Grad_ReduceSum_3;
  Ad_Add_Grad_ReduceSum_3 -&gt; Ad_Add_Grad_ReduceSum_Y_grad_for_X;

  Ad_Add_Grad_Reshape_4 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Reshape\nallowzero=0&quot; fontsize=10];
  Ad_Add_Grad_ReduceSum_Y_grad_for_X -&gt; Ad_Add_Grad_Reshape_4;
  Ad_Add_Grad_Shape_X -&gt; Ad_Add_Grad_Reshape_4;
  Ad_Add_Grad_Reshape_4 -&gt; X_grad;
}" class="graphviz" /></div>
</dd></dl>

</section>
</section>
<section id="gradient-loss-helper">
<h2>gradient.loss_helper<a class="headerlink" href="#gradient-loss-helper" title="Link to this heading">#</a></h2>
<section id="add-loss-output">
<h3>add_loss_output<a class="headerlink" href="#add-loss-output" title="Link to this heading">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="experimental_experiment.gradient.loss_helper.add_loss_output">
<span class="sig-prename descclassname"><span class="pre">experimental_experiment.gradient.loss_helper.</span></span><span class="sig-name descname"><span class="pre">add_loss_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">onx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="(in ONNX v1.17.0)"><span class="pre">ModelProto</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">score_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'squared_error'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'label'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">penalty</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.12)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_index</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.12)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.12)"><span class="pre">Any</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="(in ONNX v1.17.0)"><span class="pre">ModelProto</span></a></span></span><a class="reference internal" href="../_modules/experimental_experiment/gradient/loss_helper.html#add_loss_output"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#experimental_experiment.gradient.loss_helper.add_loss_output" title="Link to this definition">#</a></dt>
<dd><p>Modifies an ONNX graph to add operators to score and allow training.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>onx</strong> â€“ onx graph</p></li>
<li><p><strong>score_name</strong> â€“ name of the score</p></li>
<li><p><strong>loss_name</strong> â€“ name of the output loss</p></li>
<li><p><strong>label_name</strong> â€“ name of the label input</p></li>
<li><p><strong>weight_name</strong> â€“ None or any value to consider weight
while computing loss</p></li>
<li><p><strong>penalty</strong> â€“ dictionary similar to the
following one <cite>{ weight_name: {â€˜l1â€™: alpha, â€˜l2â€™: beta} }</cite>
or <cite>{ weight_name: beta}</cite>,
it adds a L1 and/or L2 penalty to one input or initializer,
penalty = <img class="math" src="../_images/math/a207af79dec28e31235f24b863f4b517d14e1b72.svg" alt="|w| \alpha + w^2 \beta"/></p></li>
<li><p><strong>output_index</strong> â€“ the output used to compute the loss,
if None, the function assumes there is only one output,
it must be specified if there are more than 1,
it can be an integer or a string (output name)</p></li>
<li><p><strong>kwargs</strong> â€“ additional arguments for losses (see below)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>modified graph</p>
</dd>
</dl>
<p>Possible values for <em>score_name</em>:</p>
<ul class="simple">
<li><p><cite>â€˜squared_errorâ€™</cite> or <cite>â€˜l2</cite>â€™: <img class="math" src="../_images/math/fda83dd62e67baf9cc305a5f94d4bcbb6de7a0c5.svg" alt="\sum_i{(f(x_i)-y_i)^2}"/> or
<img class="math" src="../_images/math/ad78d5ce2e8a9a5edf7c4be8b5f2b234752749c1.svg" alt="\sum_i{w_i (f(x_i)-y_i)^2}"/> if <em>weight_name</em>
is not None</p></li>
<li><p><cite>â€˜absolute_errorâ€™</cite> or <cite>â€˜l1</cite>â€™: <img class="math" src="../_images/math/fdce38550afa91537ebfb2ec1111df9c2e12c6d0.svg" alt="\sum_i{|f(x_i)-y_i|}"/> or
<img class="math" src="../_images/math/83d12e4a04ce5ccd515ea0d42dbc81c047098d8d.svg" alt="\sum_i{w_i |f(x_i)-y_i|}"/> if <em>weight_name</em>
is not None</p></li>
<li><p><cite>â€˜elasticâ€™</cite>: mixture of losses, kwargs must define
<em>l1_weight</em> and <em>l2_weight</em>, undefined, default value are 0.5</p></li>
<li><dl class="simple">
<dt><cite>â€˜logâ€™</cite>: log loss <img class="math" src="../_images/math/87c56cacefc81b3c51cbc2dda8f9a2ac6002f83e.svg" alt="(1-yt)\log(1-yp) - yt\log(yp)"/>,</dt><dd><p>this only works for a binary classification where <em>yp</em> is the
predicted probability, <em>yt</em> is the expected probability.
<em>yt</em> is expected to be binary, <em>yp</em> is a matrix with two
columns, the sum on every line is 1.</p>
</dd>
</dl>
</li>
</ul>
<p>Next example shows the loss with L1 and L2 loss.</p>
<div class="graphviz"><img src="../_images/graphviz-2e6da18a96de35fee996d95ace6a0fff3af2f3e5.png" alt="digraph{
  ranksep=0.25;
  size=7;
  orientation=portrait;
  nodesep=0.05;

  X [shape=box color=red label=&quot;X\nTensorProto.FLOAT\nshape=['', 10]&quot; fontsize=10];
  label [shape=box color=red label=&quot;label\nTensorProto.FLOAT\nshape=['', 1]&quot; fontsize=10];
  weight [shape=box color=red label=&quot;weight\nTensorProto.FLOAT\nshape=['']&quot; fontsize=10];

  loss [shape=box color=green label=&quot;loss\nTensorProto.FLOAT\nshape=[1, 1]&quot; fontsize=10];
  variable [shape=box color=green label=&quot;variable\nTensorProto.FLOAT\nshape=['', 1]&quot; fontsize=10];

  coef [shape=box label=&quot;coef\nfloat32((10, 1))\n[[77.47474  ]\n [ 1.4251506]\n [34.210354 ]\n [61.477...&quot; fontsize=10];
  intercept [shape=box label=&quot;intercept\nfloat32((1,))\n[1.9999847]&quot; fontsize=10];
  l1_name [shape=box label=&quot;l1_name\nfloat32((1,))\n[0.1]&quot; fontsize=10];
  l2_name [shape=box label=&quot;l2_name\nfloat32((1,))\n[0.9]&quot; fontsize=10];
  shape_tensor [shape=box label=&quot;shape_tensor\nint64((2,))\n[-1  1]&quot; fontsize=10];

  multiplied [shape=box label=&quot;multiplied&quot; fontsize=10];
  MatMul [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;MatMul&quot; fontsize=10];
  X -&gt; MatMul;
  coef -&gt; MatMul;
  MatMul -&gt; multiplied;

  resh [shape=box label=&quot;resh&quot; fontsize=10];
  Add [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Add&quot; fontsize=10];
  multiplied -&gt; Add;
  intercept -&gt; Add;
  Add -&gt; resh;

  Reshape [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Reshape&quot; fontsize=10];
  resh -&gt; Reshape;
  shape_tensor -&gt; Reshape;
  Reshape -&gt; variable;

  loss_diff [shape=box label=&quot;loss_diff&quot; fontsize=10];
  Sub [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Sub&quot; fontsize=10];
  variable -&gt; Sub;
  label -&gt; Sub;
  Sub -&gt; loss_diff;

  loss_l2 [shape=box label=&quot;loss_l2&quot; fontsize=10];
  Mul [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Mul&quot; fontsize=10];
  loss_diff -&gt; Mul;
  loss_diff -&gt; Mul;
  Mul -&gt; loss_l2;

  loss_l1 [shape=box label=&quot;loss_l1&quot; fontsize=10];
  Abs [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Abs&quot; fontsize=10];
  loss_diff -&gt; Abs;
  Abs -&gt; loss_l1;

  loss_l1_2 [shape=box label=&quot;loss_l1_2&quot; fontsize=10];
  Mul1 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Mul&quot; fontsize=10];
  loss_l1 -&gt; Mul1;
  l1_name -&gt; Mul1;
  Mul1 -&gt; loss_l1_2;

  loss_l2_2 [shape=box label=&quot;loss_l2_2&quot; fontsize=10];
  Mul12 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Mul&quot; fontsize=10];
  loss_l2 -&gt; Mul12;
  l2_name -&gt; Mul12;
  Mul12 -&gt; loss_l2_2;

  final_loss [shape=box label=&quot;final_loss&quot; fontsize=10];
  Add [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Add&quot; fontsize=10];
  loss_l1_2 -&gt; Add;
  loss_l2_2 -&gt; Add;
  Add -&gt; final_loss;

  loss_diff_weight [shape=box label=&quot;loss_diff_weight&quot; fontsize=10];
  Mul123 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Mul&quot; fontsize=10];
  final_loss -&gt; Mul123;
  weight -&gt; Mul123;
  Mul123 -&gt; loss_diff_weight;

  ReduceSum [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;ReduceSum&quot; fontsize=10];
  loss_diff_weight -&gt; ReduceSum;
  ReduceSum -&gt; loss;
}" class="graphviz" /></div>
<p>Next example shows how to add a L2 loss with L1 and L2 penalties
on the coefficients.</p>
<div class="graphviz"><img src="../_images/graphviz-efbba06ac498e9a72d17227bfbd5ffc1336df278.png" alt="digraph{
  ranksep=0.25;
  size=7;
  orientation=portrait;
  nodesep=0.05;

  X [shape=box color=red label=&quot;X\nTensorProto.FLOAT\nshape=['', 10]&quot; fontsize=10];
  label [shape=box color=red label=&quot;label\nTensorProto.FLOAT\nshape=['', 1]&quot; fontsize=10];
  weight [shape=box color=red label=&quot;weight\nTensorProto.FLOAT\nshape=['']&quot; fontsize=10];

  loss [shape=box color=green label=&quot;loss\nTensorProto.FLOAT\nshape=[1, 1]&quot; fontsize=10];
  variable [shape=box color=green label=&quot;variable\nTensorProto.FLOAT\nshape=['', 1]&quot; fontsize=10];

  coef [shape=box label=&quot;coef\nfloat32((10, 1))\n[[77.474724 ]\n [ 1.4251506]\n [34.21043  ]\n [61.476...&quot; fontsize=10];
  intercept [shape=box label=&quot;intercept\nfloat32((1,))\n[1.9999771]&quot; fontsize=10];
  l1_name [shape=box label=&quot;l1_name\nfloat32((1,))\n[0.5]&quot; fontsize=10];
  l1_weight_coef [shape=box label=&quot;l1_weight_coef\nfloat32((1,))\n[0.5]&quot; fontsize=10];
  l1_weight_intercept [shape=box label=&quot;l1_weight_intercept\nfloat32((1,))\n[0.5]&quot; fontsize=10];
  l2_name [shape=box label=&quot;l2_name\nfloat32((1,))\n[0.5]&quot; fontsize=10];
  l2_weight_coef [shape=box label=&quot;l2_weight_coef\nfloat32((1,))\n[0.5]&quot; fontsize=10];
  l2_weight_intercept [shape=box label=&quot;l2_weight_intercept\nfloat32((1,))\n[0.5]&quot; fontsize=10];
  shape_coef [shape=box label=&quot;shape_coef\nint64((1,))\n[-1]&quot; fontsize=10];
  shape_intercept [shape=box label=&quot;shape_intercept\nint64((1,))\n[-1]&quot; fontsize=10];
  shape_tensor [shape=box label=&quot;shape_tensor\nint64((2,))\n[-1  1]&quot; fontsize=10];
  shapevect [shape=box label=&quot;shapevect\nint64((2,))\n[-1  1]&quot; fontsize=10];

  multiplied [shape=box label=&quot;multiplied&quot; fontsize=10];
  MatMul [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;MatMul&quot; fontsize=10];
  X -&gt; MatMul;
  coef -&gt; MatMul;
  MatMul -&gt; multiplied;

  resh [shape=box label=&quot;resh&quot; fontsize=10];
  Add [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Add&quot; fontsize=10];
  multiplied -&gt; Add;
  intercept -&gt; Add;
  Add -&gt; resh;

  Reshape [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Reshape&quot; fontsize=10];
  resh -&gt; Reshape;
  shape_tensor -&gt; Reshape;
  Reshape -&gt; variable;

  loss_diff [shape=box label=&quot;loss_diff&quot; fontsize=10];
  Sub [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Sub&quot; fontsize=10];
  variable -&gt; Sub;
  label -&gt; Sub;
  Sub -&gt; loss_diff;

  loss_l2 [shape=box label=&quot;loss_l2&quot; fontsize=10];
  Mul [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Mul&quot; fontsize=10];
  loss_diff -&gt; Mul;
  loss_diff -&gt; Mul;
  Mul -&gt; loss_l2;

  loss_l1 [shape=box label=&quot;loss_l1&quot; fontsize=10];
  Abs [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Abs&quot; fontsize=10];
  loss_diff -&gt; Abs;
  Abs -&gt; loss_l1;

  loss_l1_2 [shape=box label=&quot;loss_l1_2&quot; fontsize=10];
  Mul1 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Mul&quot; fontsize=10];
  loss_l1 -&gt; Mul1;
  l1_name -&gt; Mul1;
  Mul1 -&gt; loss_l1_2;

  loss_l2_2 [shape=box label=&quot;loss_l2_2&quot; fontsize=10];
  Mul12 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Mul&quot; fontsize=10];
  loss_l2 -&gt; Mul12;
  l2_name -&gt; Mul12;
  Mul12 -&gt; loss_l2_2;

  final_loss [shape=box label=&quot;final_loss&quot; fontsize=10];
  Add [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Add&quot; fontsize=10];
  loss_l1_2 -&gt; Add;
  loss_l2_2 -&gt; Add;
  Add -&gt; final_loss;

  loss_diff_weight [shape=box label=&quot;loss_diff_weight&quot; fontsize=10];
  Mul123 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Mul&quot; fontsize=10];
  final_loss -&gt; Mul123;
  weight -&gt; Mul123;
  Mul123 -&gt; loss_diff_weight;

  loss_diff_2 [shape=box label=&quot;loss_diff_2&quot; fontsize=10];
  ReduceSum [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;ReduceSum&quot; fontsize=10];
  loss_diff_weight -&gt; ReduceSum;
  ReduceSum -&gt; loss_diff_2;

  reshaped_coef [shape=box label=&quot;reshaped_coef&quot; fontsize=10];
  Reshape [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Reshape&quot; fontsize=10];
  coef -&gt; Reshape;
  shape_coef -&gt; Reshape;
  Reshape -&gt; reshaped_coef;

  reducedm_coef [shape=box label=&quot;reducedm_coef&quot; fontsize=10];
  Mul1234 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Mul&quot; fontsize=10];
  reshaped_coef -&gt; Mul1234;
  reshaped_coef -&gt; Mul1234;
  Mul1234 -&gt; reducedm_coef;

  reduced2_coef [shape=box label=&quot;reduced2_coef&quot; fontsize=10];
  ReduceSum1 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;ReduceSum&quot; fontsize=10];
  reducedm_coef -&gt; ReduceSum1;
  ReduceSum1 -&gt; reduced2_coef;

  penalty2_coef [shape=box label=&quot;penalty2_coef&quot; fontsize=10];
  Mul12345 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Mul&quot; fontsize=10];
  reduced2_coef -&gt; Mul12345;
  l2_weight_coef -&gt; Mul12345;
  Mul12345 -&gt; penalty2_coef;

  absolute_coef [shape=box label=&quot;absolute_coef&quot; fontsize=10];
  Abs1 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Abs&quot; fontsize=10];
  reshaped_coef -&gt; Abs1;
  Abs1 -&gt; absolute_coef;

  reduced1_coef [shape=box label=&quot;reduced1_coef&quot; fontsize=10];
  ReduceSum12 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;ReduceSum&quot; fontsize=10];
  absolute_coef -&gt; ReduceSum12;
  ReduceSum12 -&gt; reduced1_coef;

  penalty1_coef [shape=box label=&quot;penalty1_coef&quot; fontsize=10];
  Mul123456 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Mul&quot; fontsize=10];
  reduced1_coef -&gt; Mul123456;
  l1_weight_coef -&gt; Mul123456;
  Mul123456 -&gt; penalty1_coef;

  penalty_coef [shape=box label=&quot;penalty_coef&quot; fontsize=10];
  Add1 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Add&quot; fontsize=10];
  penalty1_coef -&gt; Add1;
  penalty2_coef -&gt; Add1;
  Add1 -&gt; penalty_coef;

  reshaped_intercept [shape=box label=&quot;reshaped_intercept&quot; fontsize=10];
  Reshape1 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Reshape&quot; fontsize=10];
  intercept -&gt; Reshape1;
  shape_intercept -&gt; Reshape1;
  Reshape1 -&gt; reshaped_intercept;

  reducedm_intercept [shape=box label=&quot;reducedm_intercept&quot; fontsize=10];
  Mul1234567 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Mul&quot; fontsize=10];
  reshaped_intercept -&gt; Mul1234567;
  reshaped_intercept -&gt; Mul1234567;
  Mul1234567 -&gt; reducedm_intercept;

  reduced2_intercept [shape=box label=&quot;reduced2_intercept&quot; fontsize=10];
  ReduceSum123 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;ReduceSum&quot; fontsize=10];
  reducedm_intercept -&gt; ReduceSum123;
  ReduceSum123 -&gt; reduced2_intercept;

  penalty2_intercept [shape=box label=&quot;penalty2_intercept&quot; fontsize=10];
  Mul12345678 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Mul&quot; fontsize=10];
  reduced2_intercept -&gt; Mul12345678;
  l2_weight_intercept -&gt; Mul12345678;
  Mul12345678 -&gt; penalty2_intercept;

  absolute_intercept [shape=box label=&quot;absolute_intercept&quot; fontsize=10];
  Abs12 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Abs&quot; fontsize=10];
  reshaped_intercept -&gt; Abs12;
  Abs12 -&gt; absolute_intercept;

  reduced1_intercept [shape=box label=&quot;reduced1_intercept&quot; fontsize=10];
  ReduceSum1234 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;ReduceSum&quot; fontsize=10];
  absolute_intercept -&gt; ReduceSum1234;
  ReduceSum1234 -&gt; reduced1_intercept;

  penalty1_intercept [shape=box label=&quot;penalty1_intercept&quot; fontsize=10];
  Mul123456789 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Mul&quot; fontsize=10];
  reduced1_intercept -&gt; Mul123456789;
  l1_weight_intercept -&gt; Mul123456789;
  Mul123456789 -&gt; penalty1_intercept;

  penalty_intercept [shape=box label=&quot;penalty_intercept&quot; fontsize=10];
  Add12 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Add&quot; fontsize=10];
  penalty1_intercept -&gt; Add12;
  penalty2_intercept -&gt; Add12;
  Add12 -&gt; penalty_intercept;

  sumop [shape=box label=&quot;sumop&quot; fontsize=10];
  Add123 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Add&quot; fontsize=10];
  penalty_coef -&gt; Add123;
  penalty_intercept -&gt; Add123;
  Add123 -&gt; sumop;

  penalty_reshape [shape=box label=&quot;penalty_reshape&quot; fontsize=10];
  Reshape12 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Reshape&quot; fontsize=10];
  sumop -&gt; Reshape12;
  shapevect -&gt; Reshape12;
  Reshape12 -&gt; penalty_reshape;

  loss_reshape [shape=box label=&quot;loss_reshape&quot; fontsize=10];
  Reshape123 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Reshape&quot; fontsize=10];
  loss_diff_2 -&gt; Reshape123;
  shapevect -&gt; Reshape123;
  Reshape123 -&gt; loss_reshape;

  Add1234 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Add&quot; fontsize=10];
  penalty_reshape -&gt; Add1234;
  loss_reshape -&gt; Add1234;
  Add1234 -&gt; loss;
}" class="graphviz" /></div>
</dd></dl>

</section>
<section id="get-train-initializer">
<h3>get_train_initializer<a class="headerlink" href="#get-train-initializer" title="Link to this heading">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="experimental_experiment.gradient.loss_helper.get_train_initializer">
<span class="sig-prename descclassname"><span class="pre">experimental_experiment.gradient.loss_helper.</span></span><span class="sig-name descname"><span class="pre">get_train_initializer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">onx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="(in ONNX v1.17.0)"><span class="pre">ModelProto</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/experimental_experiment/gradient/loss_helper.html#get_train_initializer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#experimental_experiment.gradient.loss_helper.get_train_initializer" title="Link to this definition">#</a></dt>
<dd><p>Returns the list of initializers to train.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>dictionary <cite>{name: (value, tensor)}</cite></p>
</dd>
</dl>
<p>The function walk through the list of initializers and
returns all tensors with elements from types float or double.</p>
</dd></dl>

</section>
<section id="penalty-loss-onnx">
<h3>penalty_loss_onnx<a class="headerlink" href="#penalty-loss-onnx" title="Link to this heading">#</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="experimental_experiment.gradient.loss_helper.penalty_loss_onnx">
<span class="sig-prename descclassname"><span class="pre">experimental_experiment.gradient.loss_helper.</span></span><span class="sig-name descname"><span class="pre">penalty_loss_onnx</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.12)"><span class="pre">Any</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">l1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><span class="pre">float</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">l2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><span class="pre">float</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">existing_names</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/experimental_experiment/gradient/loss_helper.html#penalty_loss_onnx"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#experimental_experiment.gradient.loss_helper.penalty_loss_onnx" title="Link to this definition">#</a></dt>
<dd><p>Returns onnx nodes to compute
<img class="math" src="../_images/math/a207af79dec28e31235f24b863f4b517d14e1b72.svg" alt="|w| \alpha + w^2 \beta"/>
where <img class="math" src="../_images/math/ed9deb51f7d00a7daa384b2f0be9f2e17f72b2f4.svg" alt="\alpha=l1"/> and <img class="math" src="../_images/math/8ce705d3bcac00e5740e35c4825a3aff91de85b0.svg" alt="\beta=l2"/>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> â€“ name of weights</p></li>
<li><p><strong>dtype</strong> â€“ numpy dtype</p></li>
<li><p><strong>l1</strong> â€“ coefficient for L1 norm</p></li>
<li><p><strong>l2</strong> â€“ coefficient for L2 norm</p></li>
<li><p><strong>existing_names</strong> â€“ names already taken in the ONNX graph</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>initializer, nodes</p>
</dd>
</dl>
</dd></dl>

</section>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="graph_builder.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">graph_builder</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="index.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">API</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2023-2024
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">gradient</a><ul>
<li><a class="reference internal" href="#gradient-grad-helper">gradient.grad_helper</a><ul>
<li><a class="reference internal" href="#derivativeoptions">DerivativeOptions</a><ul>
<li><a class="reference internal" href="#experimental_experiment.gradient.grad_helper.DerivativeOptions"><code class="docutils literal notranslate"><span class="pre">DerivativeOptions</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#onnx-derivative">onnx_derivative</a><ul>
<li><a class="reference internal" href="#experimental_experiment.gradient.grad_helper.onnx_derivative"><code class="docutils literal notranslate"><span class="pre">onnx_derivative()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#gradient-loss-helper">gradient.loss_helper</a><ul>
<li><a class="reference internal" href="#add-loss-output">add_loss_output</a><ul>
<li><a class="reference internal" href="#experimental_experiment.gradient.loss_helper.add_loss_output"><code class="docutils literal notranslate"><span class="pre">add_loss_output()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#get-train-initializer">get_train_initializer</a><ul>
<li><a class="reference internal" href="#experimental_experiment.gradient.loss_helper.get_train_initializer"><code class="docutils literal notranslate"><span class="pre">get_train_initializer()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#penalty-loss-onnx">penalty_loss_onnx</a><ul>
<li><a class="reference internal" href="#experimental_experiment.gradient.loss_helper.penalty_loss_onnx"><code class="docutils literal notranslate"><span class="pre">penalty_loss_onnx()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../_static/documentation_options.js?v=a1637f0b"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/furo.js?v=32e29ea5"></script>
    </body>
</html>