<!doctype html>
<html class="no-js" lang="en" data-content_root="../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="A script to report a bug" href="example_bug.html" /><link rel="prev" title="Tries with Undocumented" href="torchtry.html" />

    <!-- Generated with Sphinx 7.2.6 and Furo 2024.04.27 -->
        <title>Use the custom exporter in torch - experimental-experiment 0.1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=437aa6ec" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css?v=eafc0fe6" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=61a4c737" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=36a5483c" />
    
    


<style>
  body {
    --color-code-background: #eeffcc;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">experimental-experiment 0.1.0 documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="../_static/logo.png" alt="Logo"/>
  </div>
  
  <span class="sidebar-brand-text">experimental-experiment 0.1.0 documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Contents</span></p>
<ul class="current">
<li class="toctree-l1 has-children"><a class="reference internal" href="../tutorial/index.html">Tutorial</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of Tutorial</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../tutorial/pytorch.html">pytorch and onnx</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of pytorch and onnx</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_linreg_101.html">101: Linear Regression and export to ONNX</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_custom_backend_101.html">101: A custom backend for torch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_optimize_101.html">101: Graph Optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_convolutation_matmul_102.html">102: Convolution and Matrix Multiplication</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_llama_bench_102.html">102: Measure LLAMA speed</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_export_201.html">201: Evaluate different ways to export a torch model to ONNX</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_dort_201.html">201: Evaluate DORT</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_aot_201.html">201: Evaluate DORT Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_llama_diff_export_301.html">301: Compares LLAMA exporters</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_llama_diff_dort_301.html">301: Compares LLAMA exporters for onnxrt backend</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../tutorial/onnx.html">onnx</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of onnx</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_profile_existing_onnx_101.html">101: Profile an existing model with onnxruntime</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../tutorial/errors.html">Frequent Exceptions</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../design/index.html">Design</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of Design</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../design/exporter.html">Custom Exporter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../design/optimizer.html">Pattern Optimizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../design/backends.html">Dynamo Backends</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api/index.html">API</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of API</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../api/gradient.html">gradient</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/reference.html">reference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/graph_builder.html">graph_builder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/graph_builder_pattern.html">graph_builder_optim</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/graph_builder_patterns.html">Optimization Patterns</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/order_optimization.html">order_optim</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/interpreter.html">interpreter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/onnx_export.html">onnx_export</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/aten_function.html">aten_functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/aten_method.html">aten_methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/prims_function.html">aten_prims</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/convert.html">convert_tools</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/torch_dynamo.html">torch_dynamo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/misc.html">Others…</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/torch_helper.html">torch_models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/dimension.html">Dimension</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/torch_test.html">Testing</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../auto_examples/index.html">Example gallery</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle navigation of Example gallery</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_optimize_101.html">101: Graph Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_profile_existing_onnx_101.html">101: Profile an existing model with onnxruntime</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_torch_linreg_101.html">101: Linear Regression and export to ONNX</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_torch_custom_backend_101.html">101: A custom backend for torch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_convolutation_matmul_102.html">102: Convolution and Matrix Multiplication</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_llama_diff_export_301.html">301: Compares LLAMA exporters</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_llama_diff_dort_301.html">301: Compares LLAMA exporters for onnxrt backend</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_llama_bench_102.html">102: Measure LLAMA speed</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_torch_aot_201.html">201: Evaluate DORT Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_torch_dort_201.html">201: Evaluate DORT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_torch_export_201.html">201: Evaluate different ways to export a torch model to ONNX</a></li>
</ul>
</li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="index.html">Supported Models</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle navigation of Supported Models</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="torchtry.html">Tries with Undocumented</a></li>
<li class="toctree-l2 current current-page"><a class="current reference internal" href="#">Use the custom exporter in torch</a></li>
<li class="toctree-l2"><a class="reference internal" href="example_bug.html">A script to report a bug</a></li>
<li class="toctree-l2"><a class="reference internal" href="llama.html">LLaMa</a></li>
<li class="toctree-l2"><a class="reference internal" href="mistral.html">Mistral</a></li>
<li class="toctree-l2"><a class="reference internal" href="phi.html">Phi</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../bench/index.html">Benchmark from the command line</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle navigation of Benchmark from the command line</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../bench/dort_bench.html">experimental_experiment.torch_bench.dort_bench</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bench/dort_profile.html">experimental_experiment.torch_bench.dort_profile</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bench/scripts.html">Interesting scripts or command lines</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../times.html">Times</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">More</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../CHANGELOGS.html">Change Logs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
<li class="toctree-l1"><a class="reference internal" href="../long_outputs.html">Long Outputs uneasy to read</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="use-the-custom-exporter-in-torch">
<h1>Use the custom exporter in torch<a class="headerlink" href="#use-the-custom-exporter-in-torch" title="Link to this heading">¶</a></h1>
<p><em>Subject to change</em></p>
<section id="file-onnxruntime-py">
<h2>File <cite>onnxruntime.py</cite><a class="headerlink" href="#file-onnxruntime-py" title="Link to this heading">¶</a></h2>
<p>This change enables the custom rewriter is an environment variable is enabled.
Look for substring <code class="docutils literal notranslate"><span class="pre">TODO:</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">_ort_acclerated_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph_module</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">GraphModule</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;This function replaces GraphModule._wrapped_call in compiled model.</span>

<span class="sd">    The _wrapped_call is the underlying implementation of forward method. Replacing</span>
<span class="sd">    it means we delegate the computation to _ort_acclerated_call and therefore</span>
<span class="sd">    onnxruntime.InferenceSession.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">cached_execution_info_per_session</span> <span class="o">=</span> <span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_all_ort_execution_info</span><span class="o">.</span><span class="n">search_reusable_session_execution_info</span><span class="p">(</span>
            <span class="n">graph_module</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span>
        <span class="p">)</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">cached_execution_info_per_session</span><span class="p">:</span>
        <span class="n">onnx_session</span> <span class="o">=</span> <span class="n">cached_execution_info_per_session</span><span class="o">.</span><span class="n">session</span>
        <span class="n">input_names</span> <span class="o">=</span> <span class="n">cached_execution_info_per_session</span><span class="o">.</span><span class="n">input_names</span>
        <span class="n">output_names</span> <span class="o">=</span> <span class="n">cached_execution_info_per_session</span><span class="o">.</span><span class="n">output_names</span>
        <span class="n">input_value_infos</span> <span class="o">=</span> <span class="n">cached_execution_info_per_session</span><span class="o">.</span><span class="n">input_value_infos</span>
        <span class="n">output_value_infos</span> <span class="o">=</span> <span class="n">cached_execution_info_per_session</span><span class="o">.</span><span class="n">output_value_infos</span>
        <span class="n">input_devices</span> <span class="o">=</span> <span class="n">cached_execution_info_per_session</span><span class="o">.</span><span class="n">input_devices</span>
        <span class="n">output_devices</span> <span class="o">=</span> <span class="n">cached_execution_info_per_session</span><span class="o">.</span><span class="n">output_devices</span>
        <span class="n">prim_outputs</span> <span class="o">=</span> <span class="n">cached_execution_info_per_session</span><span class="o">.</span><span class="n">example_outputs</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># It&#39;s first time seeing such as graph. Let&#39;s make a new session</span>
        <span class="c1"># (type: onnxruntime.InferenceSession) for it.</span>

        <span class="c1">##########################</span>
        <span class="c1"># TODO: Insert these lines</span>
        <span class="c1">##########################</span>

        <span class="n">use_other_rewriter</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;ONNXRT_CHANGE_REWRITER&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;1&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">use_other_rewriter</span><span class="p">:</span>
            <span class="kn">from</span> <span class="nn">experimental_experiment.torch_interpreter</span> <span class="kn">import</span> <span class="n">to_onnx</span>
            <span class="kn">from</span> <span class="nn">experimental_experiment.torch_interpreter._torch_models</span> <span class="kn">import</span> <span class="n">create_input_names</span>
            <span class="kn">from</span> <span class="nn">experimental_experiment.xbuilder</span> <span class="kn">import</span> <span class="n">OptimizationOptions</span>
            <span class="kn">from</span> <span class="nn">experimental_experiment.torch_interpreter.oxs_dispatcher</span> <span class="kn">import</span> <span class="n">OxsDispatcher</span>

            <span class="n">input_names</span> <span class="o">=</span> <span class="n">input_names</span> <span class="o">=</span> <span class="n">create_input_names</span><span class="p">(</span><span class="n">graph_module</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span>
            <span class="n">dispatcher</span> <span class="o">=</span> <span class="n">OxsDispatcher</span><span class="p">()</span>
            <span class="n">target_opset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_resolved_onnx_exporter_options</span><span class="o">.</span><span class="n">onnx_registry</span><span class="o">.</span><span class="n">opset_version</span>
            <span class="n">options</span> <span class="o">=</span> <span class="n">OptimizationOptions</span><span class="p">(</span>
                <span class="n">remove_unused</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">constant_folding</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">patterns</span><span class="o">=</span><span class="s2">&quot;default&quot;</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">onnx_model</span><span class="p">,</span> <span class="n">builder</span> <span class="o">=</span> <span class="n">to_onnx</span><span class="p">(</span>
                <span class="n">graph_module</span><span class="p">,</span>
                <span class="nb">tuple</span><span class="p">(</span><span class="n">args</span><span class="p">),</span>
                <span class="n">input_names</span><span class="o">=</span><span class="n">input_names</span><span class="p">,</span>
                <span class="n">options</span><span class="o">=</span><span class="n">options</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">target_opset</span><span class="o">=</span><span class="n">target_opset</span><span class="p">,</span>
                <span class="n">return_builder</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dispatcher</span><span class="o">=</span><span class="n">dispatcher</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="k">def</span> <span class="nf">maybe_map_to_meta_val</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="s2">&quot;meta&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="s2">&quot;val&quot;</span> <span class="ow">in</span> <span class="n">value</span><span class="o">.</span><span class="n">meta</span><span class="p">:</span>
                    <span class="c1"># Select outputs with &quot;val&quot; information. Without &quot;val&quot;,</span>
                    <span class="c1"># it&#39;s not possible access output_arg.meta[&quot;val&quot;].device.</span>
                    <span class="k">return</span> <span class="n">value</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s2">&quot;val&quot;</span><span class="p">]</span>
                <span class="k">return</span> <span class="n">value</span>

            <span class="n">extracted_outputs</span> <span class="o">=</span> <span class="n">_extract_graph_module_outputs</span><span class="p">(</span><span class="n">graph_module</span><span class="p">)</span>
            <span class="n">prim_outputs</span> <span class="o">=</span> <span class="n">_pytree</span><span class="o">.</span><span class="n">tree_map</span><span class="p">(</span><span class="n">maybe_map_to_meta_val</span><span class="p">,</span> <span class="n">extracted_outputs</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>

        <span class="c1">####################################</span>
        <span class="c1"># TODO: end of the insertion</span>
        <span class="c1"># TODO: indent what follows</span>
        <span class="c1">####################################</span>

            <span class="n">graph_module</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">_internal</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">passes</span><span class="o">.</span><span class="n">MovePlaceholderToFront</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_resolved_onnx_exporter_options</span><span class="o">.</span><span class="n">diagnostic_context</span><span class="p">,</span>
                <span class="n">graph_module</span><span class="p">,</span>
            <span class="p">)</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
            <span class="c1"># Generate reference outputs. They are used to indicate output</span>
            <span class="c1"># tensors&#39; types and devices when calling ORT.</span>
            <span class="c1">#</span>
            <span class="c1"># WARNING: The downstream code should not change prim_outputs and</span>
            <span class="c1"># this backend should always produces output with schema identical to prim_outputs&#39;.</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_resolved_onnx_exporter_options</span><span class="o">.</span><span class="n">dynamic_shapes</span><span class="p">:</span>
                <span class="c1"># No pre-allocation when dynamic shape is enabled.</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">preallocate_output</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="n">extracted_outputs</span> <span class="o">=</span> <span class="n">_extract_graph_module_outputs</span><span class="p">(</span><span class="n">graph_module</span><span class="p">)</span>

                <span class="k">def</span> <span class="nf">maybe_map_to_meta_val</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="s2">&quot;meta&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="s2">&quot;val&quot;</span> <span class="ow">in</span> <span class="n">value</span><span class="o">.</span><span class="n">meta</span><span class="p">:</span>
                        <span class="c1"># Select outputs with &quot;val&quot; information. Without &quot;val&quot;,</span>
                        <span class="c1"># it&#39;s not possible access output_arg.meta[&quot;val&quot;].device.</span>
                        <span class="k">return</span> <span class="n">value</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s2">&quot;val&quot;</span><span class="p">]</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">return</span> <span class="n">value</span>

                <span class="n">prim_outputs</span> <span class="o">=</span> <span class="n">_pytree</span><span class="o">.</span><span class="n">tree_map</span><span class="p">(</span>
                    <span class="n">maybe_map_to_meta_val</span><span class="p">,</span> <span class="n">extracted_outputs</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">prim_outputs</span> <span class="o">=</span> <span class="n">FakeTensorProp</span><span class="p">(</span><span class="n">graph_module</span><span class="p">)</span><span class="o">.</span><span class="n">propagate</span><span class="p">(</span>
                        <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
                    <span class="p">)</span>
                <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;FakeTensorProb failed for </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">graph_module</span><span class="p">)</span>
                    <span class="c1"># When FakeTensorProp fails, it is not possible to preallocate output buffers</span>
                    <span class="c1"># because the output shapes are not inferred.</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">preallocate_output</span> <span class="o">=</span> <span class="kc">False</span>

                    <span class="c1"># rethrow FakeTensorProb failure because it is not yet currently handled.</span>
                    <span class="k">raise</span>

            <span class="c1"># Create the object to iterate through the nodes in graph one-by-one</span>
            <span class="c1"># and calls the corresponding ONNX exporter for each node.</span>
            <span class="n">fx_interpreter</span> <span class="o">=</span> <span class="n">fx_onnx_interpreter</span><span class="o">.</span><span class="n">FxOnnxInterpreter</span><span class="p">(</span>
                <span class="n">diagnostic_context</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_resolved_onnx_exporter_options</span><span class="o">.</span><span class="n">diagnostic_context</span>
            <span class="p">)</span>
            <span class="c1"># Cast FX variables if they will result schema-mismatch when searching</span>
            <span class="c1"># for ONNX operator. E.g., add(double_tensor, int_tensor) is fine in PyTorch,</span>
            <span class="c1"># but ONNX expects add(double_tensor, double_tensor).</span>
            <span class="n">graph_module</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">_internal</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">passes</span><span class="o">.</span><span class="n">InsertTypePromotion</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_resolved_onnx_exporter_options</span><span class="o">.</span><span class="n">diagnostic_context</span><span class="p">,</span> <span class="n">graph_module</span>
            <span class="p">)</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
            <span class="c1"># Start the per-node exporting process. It&#39;s conceptually a for loop</span>
            <span class="c1"># scanning through the nodes in the graph.</span>
            <span class="n">exported</span> <span class="o">=</span> <span class="n">fx_interpreter</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                <span class="n">fx_graph_module</span><span class="o">=</span><span class="n">graph_module</span><span class="p">,</span>
                <span class="n">onnxfunction_dispatcher</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_resolved_onnx_exporter_options</span><span class="o">.</span><span class="n">onnxfunction_dispatcher</span><span class="p">,</span>
                <span class="n">op_level_debug</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_resolved_onnx_exporter_options</span><span class="o">.</span><span class="n">op_level_debug</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="c1"># Convert the exported result to ONNX ModelProto.</span>
            <span class="n">onnx_model</span> <span class="o">=</span> <span class="n">exported</span><span class="o">.</span><span class="n">to_model_proto</span><span class="p">(</span>
                <span class="n">opset_version</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_resolved_onnx_exporter_options</span><span class="o">.</span><span class="n">onnx_registry</span><span class="o">.</span><span class="n">opset_version</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1">####################################</span>
        <span class="c1"># TODO: end of the modification</span>
        <span class="c1">####################################</span>

        <span class="c1"># Modify ONNX model using pre-registered graph transforms.</span>
        <span class="c1"># They are in-place modifications for avoiding unnecessary</span>
        <span class="c1"># copy of ONNX initializers.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_options</span><span class="o">.</span><span class="n">pre_ort_model_transforms</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">transform</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_options</span><span class="o">.</span><span class="n">pre_ort_model_transforms</span><span class="p">:</span>
                <span class="n">transform</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">)</span>

        <span class="n">onnx_model_bytes</span> <span class="o">=</span> <span class="n">onnx_model</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;ONNXRT_DUMP_PATH&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">):</span>
            <span class="c1"># If not empty, environment variable ONNXRT_DUMP_PATH defined the path</span>
            <span class="c1"># where generated onnx files should be stored.</span>
            <span class="c1"># This module keeps a global variables keeping track of the</span>
            <span class="c1"># stored models.</span>
            <span class="c1"># If ONNXRT_DUMP_PATH=&quot;dumped/dumped_model_&quot;</span>
            <span class="c1"># The first file name will be &#39;dumped/dumped_model_0.onnx&#39;.</span>
            <span class="c1"># For every dumped model, a text file &#39;dumped/dumped_model_0.txt&#39;</span>
            <span class="c1"># is created as well to contain the string representing the graph_module.</span>
            <span class="n">_dump_onnx_model</span><span class="p">(</span><span class="n">onnx_model_bytes</span><span class="p">,</span> <span class="n">graph_module</span><span class="o">=</span><span class="n">graph_module</span><span class="p">)</span>

        <span class="c1"># Initialize a ORT session to execute this ONNX model.</span>
        <span class="c1"># Note that TorchDynamo assumes all inputs/outputs are on the</span>
        <span class="c1"># same device, but it&#39;s subject to change (very likely with</span>
        <span class="c1"># dynamic shape support), so we add execution providers</span>
        <span class="c1"># based on the logic in _select_eps: (explicitly preferred EPs,</span>
        <span class="c1"># EPs inferred from inputs or graph, and the fallback default EP)/</span>
        <span class="c1">#</span>
        <span class="c1"># TODO(wschin): enable external allocators.</span>
        <span class="c1"># See https://github.com/pytorch/pytorch/issues/106867</span>
        <span class="n">onnx_session</span> <span class="o">=</span> <span class="n">onnxruntime</span><span class="o">.</span><span class="n">InferenceSession</span><span class="p">(</span>
            <span class="n">path_or_bytes</span><span class="o">=</span><span class="n">onnx_model_bytes</span><span class="p">,</span>
            <span class="n">sess_options</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_options</span><span class="o">.</span><span class="n">ort_session_options</span><span class="p">,</span>
            <span class="n">providers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_select_eps</span><span class="p">(</span><span class="n">graph_module</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="c1"># Cache ORT session. It&#39;s reused for the same &quot;graph_module&quot;.</span>
        <span class="c1"># Generate ONNX model and extract its input and output names.</span>
        <span class="n">input_names</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">input</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="nb">input</span> <span class="ow">in</span> <span class="n">onnx_model</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">input</span><span class="p">)</span>
        <span class="n">output_names</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">onnx_model</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>
        <span class="n">input_devices</span> <span class="o">=</span> <span class="n">_get_onnx_devices</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
        <span class="c1"># Cache devices for inputs and outputs. They are used to invoke</span>
        <span class="c1"># ORT session. Output devices indicate where (e.g., GPU or CPU)</span>
        <span class="c1"># to store outputs</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prim_outputs</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">output_devices</span> <span class="o">=</span> <span class="n">_get_onnx_devices</span><span class="p">(</span><span class="n">prim_outputs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">output_devices</span> <span class="o">=</span> <span class="n">_get_onnx_devices</span><span class="p">((</span><span class="n">prim_outputs</span><span class="p">,))</span>

        <span class="n">input_value_infos</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">input</span> <span class="k">for</span> <span class="nb">input</span> <span class="ow">in</span> <span class="n">onnx_model</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">input</span><span class="p">)</span>
        <span class="n">output_value_infos</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">output</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">onnx_model</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>

        <span class="n">execution_info_per_session</span> <span class="o">=</span> <span class="n">OrtExecutionInfoPerSession</span><span class="p">(</span>
            <span class="n">session</span><span class="o">=</span><span class="n">onnx_session</span><span class="p">,</span>
            <span class="n">input_names</span><span class="o">=</span><span class="n">input_names</span><span class="p">,</span>
            <span class="n">input_value_infos</span><span class="o">=</span><span class="n">input_value_infos</span><span class="p">,</span>
            <span class="n">output_names</span><span class="o">=</span><span class="n">output_names</span><span class="p">,</span>
            <span class="n">output_value_infos</span><span class="o">=</span><span class="n">output_value_infos</span><span class="p">,</span>
            <span class="n">input_devices</span><span class="o">=</span><span class="n">input_devices</span><span class="p">,</span>
            <span class="n">output_devices</span><span class="o">=</span><span class="n">output_devices</span><span class="p">,</span>
            <span class="n">example_outputs</span><span class="o">=</span><span class="n">prim_outputs</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_all_ort_execution_info</span><span class="o">.</span><span class="n">cache_session_execution_info</span><span class="p">(</span>
            <span class="n">graph_module</span><span class="p">,</span> <span class="n">execution_info_per_session</span>
        <span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">execution_count</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="c1"># ORT always returns a tuple of outputs. If the original output is a tensor,</span>
    <span class="c1"># ORT output&#39;s first element must be extracted and returned. Otherwise, type</span>
    <span class="c1"># mismatch may happen in downstream computation.</span>
    <span class="n">is_single_tensor_output</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prim_outputs</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
    <span class="n">normalized_prim_outputs</span> <span class="o">=</span> <span class="p">(</span>
        <span class="p">(</span><span class="n">prim_outputs</span><span class="p">,)</span> <span class="k">if</span> <span class="n">is_single_tensor_output</span> <span class="k">else</span> <span class="n">prim_outputs</span>
    <span class="p">)</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">normalized_prim_outputs</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span>
        <span class="nb">isinstance</span><span class="p">(</span><span class="n">elem</span><span class="p">,</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">SymInt</span><span class="p">,</span> <span class="nb">int</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">normalized_prim_outputs</span>
    <span class="p">)</span>

    <span class="n">_nvtx_range_push</span><span class="p">(</span><span class="s2">&quot;run_onnx_session_with_ortvaluevector&quot;</span><span class="p">)</span>
    <span class="n">onnx_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
        <span class="n">onnx_session</span><span class="p">,</span>
        <span class="n">input_names</span><span class="p">,</span>
        <span class="n">args</span><span class="p">,</span>
        <span class="n">input_devices</span><span class="p">,</span>
        <span class="n">output_names</span><span class="p">,</span>
        <span class="n">normalized_prim_outputs</span><span class="p">,</span>
        <span class="n">output_devices</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_options</span><span class="o">.</span><span class="n">preallocate_output</span><span class="p">,</span>
        <span class="n">input_value_infos</span><span class="p">,</span>
        <span class="n">normalized_prim_outputs</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">_nvtx_range_pop</span><span class="p">()</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_assert_allclose_to_baseline</span><span class="p">:</span>
        <span class="c1"># Compute baseline.</span>
        <span class="n">baseline_outputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_prims</span><span class="o">.</span><span class="n">executor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span>
            <span class="n">graph_module</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">executor</span><span class="o">=</span><span class="s2">&quot;aten&quot;</span>
        <span class="p">)</span>
        <span class="n">normalized_baseline_ouptuts</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">(</span><span class="n">baseline_outputs</span><span class="p">,)</span> <span class="k">if</span> <span class="n">is_single_tensor_output</span> <span class="k">else</span> <span class="n">baseline_outputs</span>
        <span class="p">)</span>
        <span class="c1"># Ensure every output tensor is close to the corresponding baseline.</span>
        <span class="k">for</span> <span class="n">onnx_output</span><span class="p">,</span> <span class="n">baseline_output</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
            <span class="n">onnx_outputs</span><span class="p">,</span> <span class="n">normalized_baseline_ouptuts</span>
        <span class="p">):</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_close</span><span class="p">(</span><span class="n">onnx_output</span><span class="p">,</span> <span class="n">baseline_output</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">onnx_outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">is_single_tensor_output</span> <span class="k">else</span> <span class="n">onnx_outputs</span>
</pre></div>
</div>
</section>
<section id="examples">
<h2>Examples<a class="headerlink" href="#examples" title="Link to this heading">¶</a></h2>
<section id="baseline">
<h3>Baseline<a class="headerlink" href="#baseline" title="Link to this heading">¶</a></h3>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">onnx</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.onnx</span>
<span class="kn">from</span> <span class="nn">experimental_experiment.torch_models.training_helper</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">make_aot_ort</span><span class="p">,</span>
    <span class="n">train_loop</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">experimental_experiment.torch_models.dump_helper</span> <span class="kn">import</span> <span class="n">dump_onnx</span>

<span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
    <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">LlamaConfig</span>
    <span class="kn">from</span> <span class="nn">transformers.models.llama.modeling_llama</span> <span class="kn">import</span> <span class="n">LlamaModel</span>


<span class="k">def</span> <span class="nf">ids_tensor</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">):</span>
    <span class="n">total_dims</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="n">shape</span><span class="p">:</span>
        <span class="n">total_dims</span> <span class="o">*=</span> <span class="n">dim</span>

    <span class="n">values</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">total_dims</span><span class="p">):</span>
        <span class="n">values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">vocab_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>


<span class="n">config</span> <span class="o">=</span> <span class="n">LlamaConfig</span><span class="p">(</span>
    <span class="n">hidden_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">num_hidden_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">vocab_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
    <span class="n">intermediate_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">max_position_embeddings</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
    <span class="n">num_attention_heads</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">config</span><span class="o">.</span><span class="n">_attn_implementation</span> <span class="o">=</span> <span class="s2">&quot;eager&quot;</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">LlamaModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

<span class="n">batch</span><span class="p">,</span> <span class="n">seq</span><span class="p">,</span> <span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span>

<span class="n">input_ids</span> <span class="o">=</span> <span class="n">ids_tensor</span><span class="p">([</span><span class="n">batch</span><span class="p">,</span> <span class="n">seq</span><span class="p">],</span> <span class="n">vocab_size</span><span class="p">)</span>
<span class="n">input_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tril</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">seq</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

<span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">input_mask</span><span class="p">)</span>

<span class="n">local_aot_ort</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">make_aot_ort</span><span class="p">(</span>
    <span class="n">dynamic</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">rewrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>

<span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
    <span class="n">optimized_mod</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="n">local_aot_ort</span><span class="p">,</span> <span class="n">fullgraph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">dump_onnx</span><span class="p">(</span><span class="s2">&quot;dort-llama-ort&quot;</span><span class="p">,</span> <span class="n">folder</span><span class="o">=</span><span class="s2">&quot;dump_llama&quot;</span><span class="p">,</span> <span class="n">clean</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="n">train_loop</span><span class="p">(</span><span class="n">optimized_mod</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">input_mask</span><span class="p">)</span>

<span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="n">_</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s2">&quot;dump_llama&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">_</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.onnx&quot;</span><span class="p">)]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------------------------&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;exported model: </span><span class="si">{</span><span class="n">names</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">names</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;NODES in </span><span class="si">{name!r}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">onx</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">&quot;dump_llama&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">node</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">onx</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">onx</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="p">)</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">node</span><span class="o">.</span><span class="n">op_type</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="si">}</span><span class="s2"> -&gt; </span><span class="si">{</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    [2024-04-30 15:23:16,345] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
    Applied 0 of general pattern rewrite rules.
    Applied 0 of general pattern rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific pattern rewrite rules.
    Applied 0 of general pattern rewrite rules.
    Applied 0 of general pattern rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific pattern rewrite rules.
    ------------------------------------------
    exported model: [&#39;dort-llama-ort_1.onnx&#39;, &#39;dort-llama-ort_0.onnx&#39;]
    
    NODES in {name!r}
    1/321: Constant [] -&gt; [&#39;_val_34&#39;]
    2/321: Equal [&#39;primals_14&#39;, &#39;_val_34&#39;] -&gt; [&#39;eq&#39;]
    3/321: Mul [&#39;add_7&#39;, &#39;rsqrt_2&#39;] -&gt; [&#39;mul_10&#39;]
    4/321: Mul [&#39;tangents_1&#39;, &#39;primals_3&#39;] -&gt; [&#39;mul_12&#39;]
    5/321: Constant [] -&gt; [&#39;_val_41&#39;]
    6/321: Constant [] -&gt; [&#39;_val_45&#39;]
    7/321: Constant [] -&gt; [&#39;_val_49&#39;]
    8/321: Constant [] -&gt; [&#39;_val_53&#39;]
    9/321: Slice [&#39;primals_13&#39;, &#39;_val_41&#39;, &#39;_val_45&#39;, &#39;_val_49&#39;, &#39;_val_53&#39;] -&gt; [&#39;slice_8&#39;]
    10/321: Constant [] -&gt; [&#39;_val_66&#39;]
    11/321: Constant [] -&gt; [&#39;_val_70&#39;]
    12/321: Constant [] -&gt; [&#39;_val_74&#39;]
    13/321: Constant [] -&gt; [&#39;_val_78&#39;]
    14/321: Slice [&#39;primals_12&#39;, &#39;_val_66&#39;, &#39;_val_70&#39;, &#39;_val_74&#39;, &#39;_val_78&#39;] -&gt; [&#39;slice_7&#39;]
    15/321: Constant [] -&gt; [&#39;_val_80&#39;]
    16/321: Pow [&#39;add_7&#39;, &#39;_val_80&#39;] -&gt; [&#39;pow_5&#39;]
    17/321: Constant [] -&gt; [&#39;aten_view_172_size_0&#39;]
    18/321: Reshape [&#39;mm_4&#39;, &#39;aten_view_172_size_0&#39;] -&gt; [&#39;view_20&#39;]
    19/321: Constant [] -&gt; [&#39;aten_view_174_size_0&#39;]
    20/321: Reshape [&#39;mm_5&#39;, &#39;aten_view_174_size_0&#39;] -&gt; [&#39;view_22&#39;]
    21/321: Constant [] -&gt; [&#39;aten_view_179_size_0&#39;]
    22/321: Reshape [&#39;mm_3&#39;, &#39;aten_view_179_size_0&#39;] -&gt; [&#39;view_18&#39;]
    23/321: Mul [&#39;embedding&#39;, &#39;rsqrt&#39;] -&gt; [&#39;mul&#39;]
    24/321: Constant [] -&gt; [&#39;_val_94&#39;]
    25/321: Pow [&#39;embedding&#39;, &#39;_val_94&#39;] -&gt; [&#39;pow_9&#39;]
    26/321: Constant [] -&gt; [&#39;aten_unsqueeze_185_dim_0&#39;]
    27/321: Unsqueeze [&#39;eq&#39;, &#39;aten_unsqueeze_185_dim_0&#39;] -&gt; [&#39;unsqueeze_9&#39;]
    28/321: Mul [&#39;tangents_1&#39;, &#39;mul_10&#39;] -&gt; [&#39;mul_13&#39;]
    29/321: Mul [&#39;mul_12&#39;, &#39;add_7&#39;] -&gt; [&#39;mul_14&#39;]
    30/321: Mul [&#39;mul_12&#39;, &#39;rsqrt_2&#39;] -&gt; [&#39;mul_15&#39;]
    31/321: Constant [] -&gt; [&#39;_val_102&#39;]
    32/321: Mul [&#39;pow_5&#39;, &#39;_val_102&#39;] -&gt; [&#39;mul_18&#39;]
    33/321: Mul [&#39;view_20&#39;, &#39;sigmoid&#39;] -&gt; [&#39;mul_8&#39;]
    34/321: Constant [] -&gt; [&#39;fill&#39;]
    35/321: Constant [] -&gt; [&#39;alpha__1&#39;]
    36/321: Mul [&#39;view_18&#39;, &#39;alpha__1&#39;] -&gt; [&#39;other_1__1&#39;]
    37/321: Add [&#39;embedding&#39;, &#39;other_1__1&#39;] -&gt; [&#39;add_5&#39;]
    38/321: Constant [] -&gt; [&#39;_val_110&#39;]
    39/321: Mul [&#39;pow_9&#39;, &#39;_val_110&#39;] -&gt; [&#39;mul_45&#39;]
    40/321: Constant [] -&gt; [&#39;_val_112&#39;]
    41/321: ReduceSum [&#39;mul_13&#39;, &#39;_val_112&#39;] -&gt; [&#39;sum_1&#39;]
    42/321: Constant [] -&gt; [&#39;_val_114&#39;]
    43/321: ReduceSum [&#39;mul_14&#39;, &#39;_val_114&#39;] -&gt; [&#39;sum_2&#39;]
    44/321: Transpose [&#39;slice_8&#39;] -&gt; [&#39;_val_116&#39;]
    45/321: Constant [] -&gt; [&#39;_val_122&#39;]
    46/321: GatherND [&#39;_val_116&#39;, &#39;_val_122&#39;] -&gt; [&#39;_val_123&#39;]
    47/321: Transpose [&#39;_val_123&#39;] -&gt; [&#39;index_1&#39;]
    48/321: Transpose [&#39;slice_7&#39;] -&gt; [&#39;_val_125&#39;]
    49/321: Constant [] -&gt; [&#39;_val_131&#39;]
    50/321: GatherND [&#39;_val_125&#39;, &#39;_val_131&#39;] -&gt; [&#39;_val_132&#39;]
    51/321: Transpose [&#39;_val_132&#39;] -&gt; [&#39;index&#39;]
    52/321: Constant [] -&gt; [&#39;alpha__2&#39;]
    53/321: Mul [&#39;sigmoid&#39;, &#39;alpha__2&#39;] -&gt; [&#39;other_1__2&#39;]
    54/321: Sub [&#39;fill&#39;, &#39;other_1__2&#39;] -&gt; [&#39;sub&#39;]
    55/321: Mul [&#39;add_5&#39;, &#39;rsqrt_1&#39;] -&gt; [&#39;mul_6&#39;]
    56/321: Constant [] -&gt; [&#39;_val_137&#39;]
    57/321: Pow [&#39;add_5&#39;, &#39;_val_137&#39;] -&gt; [&#39;pow_7&#39;]
    58/321: Constant [] -&gt; [&#39;aten_view_231_size_0&#39;]
    59/321: Reshape [&#39;sum_1&#39;, &#39;aten_view_231_size_0&#39;] -&gt; [&#39;view_25&#39;]
    60/321: Constant [] -&gt; [&#39;_val_143&#39;]
    61/321: Mul [&#39;sum_2&#39;, &#39;_val_143&#39;] -&gt; [&#39;mul_16&#39;]
    62/321: Constant [] -&gt; [&#39;aten_unsqueeze_234_dim_0&#39;]
    63/321: Unsqueeze [&#39;index_1&#39;, &#39;aten_unsqueeze_234_dim_0&#39;] -&gt; [&#39;unsqueeze_8&#39;]
    64/321: Constant [] -&gt; [&#39;aten_unsqueeze_235_dim_0&#39;]
    65/321: Unsqueeze [&#39;index&#39;, &#39;aten_unsqueeze_235_dim_0&#39;] -&gt; [&#39;unsqueeze_7&#39;]
    66/321: Mul [&#39;view_20&#39;, &#39;sub&#39;] -&gt; [&#39;mul_22&#39;]
    67/321: Constant [] -&gt; [&#39;_val_149&#39;]
    68/321: Mul [&#39;pow_7&#39;, &#39;_val_149&#39;] -&gt; [&#39;mul_31&#39;]
    69/321: Constant [] -&gt; [&#39;scalar_tensor_default&#39;]
    70/321: Pow [&#39;rsqrt_2&#39;, &#39;scalar_tensor_default&#39;] -&gt; [&#39;pow_4&#39;]
    71/321: Constant [] -&gt; [&#39;aten_add_247_other_1&#39;]
    72/321: Add [&#39;mul_22&#39;, &#39;aten_add_247_other_1&#39;] -&gt; [&#39;add_10&#39;]
    73/321: Constant [] -&gt; [&#39;scalar_tensor_default_2&#39;]
    74/321: Pow [&#39;rsqrt_1&#39;, &#39;scalar_tensor_default_2&#39;] -&gt; [&#39;pow_6&#39;]
    75/321: Constant [] -&gt; [&#39;scalar_tensor_default_3&#39;]
    76/321: Pow [&#39;rsqrt&#39;, &#39;scalar_tensor_default_3&#39;] -&gt; [&#39;pow_8&#39;]
    77/321: Mul [&#39;mul_16&#39;, &#39;pow_4&#39;] -&gt; [&#39;mul_17&#39;]
    78/321: Mul [&#39;sigmoid&#39;, &#39;add_10&#39;] -&gt; [&#39;mul_23&#39;]
    79/321: Constant [] -&gt; [&#39;aten_expand_257_size_1&#39;]
    80/321: Expand [&#39;mul_17&#39;, &#39;aten_expand_257_size_1&#39;] -&gt; [&#39;expand_7&#39;]
    81/321: Constant [] -&gt; [&#39;scalar_tensor_default_4&#39;]
    82/321: Div [&#39;expand_7&#39;, &#39;scalar_tensor_default_4&#39;] -&gt; [&#39;div_1&#39;]
    83/321: Mul [&#39;div_1&#39;, &#39;mul_18&#39;] -&gt; [&#39;mul_19&#39;]
    84/321: Constant [] -&gt; [&#39;alpha__3&#39;]
    85/321: Mul [&#39;mul_19&#39;, &#39;alpha__3&#39;] -&gt; [&#39;other_1__3&#39;]
    86/321: Add [&#39;mul_15&#39;, &#39;other_1__3&#39;] -&gt; [&#39;add_9&#39;]
    87/321: Constant [] -&gt; [&#39;aten_view_264_size_0&#39;]
    88/321: Reshape [&#39;add_9&#39;, &#39;aten_view_264_size_0&#39;] -&gt; [&#39;view_26&#39;]
    89/321: Transpose [&#39;view_26&#39;] -&gt; [&#39;t_7&#39;]
    90/321: MatMul [&#39;view_26&#39;, &#39;t_9&#39;] -&gt; [&#39;mm_8&#39;]
    91/321: MatMul [&#39;t_7&#39;, &#39;view_23&#39;] -&gt; [&#39;mm_7&#39;]
    92/321: Constant [] -&gt; [&#39;aten_view_269_size_0&#39;]
    93/321: Reshape [&#39;mm_8&#39;, &#39;aten_view_269_size_0&#39;] -&gt; [&#39;view_27&#39;]
    94/321: Transpose [&#39;mm_7&#39;] -&gt; [&#39;t_8&#39;]
    95/321: Mul [&#39;view_27&#39;, &#39;mul_8&#39;] -&gt; [&#39;mul_20&#39;]
    96/321: Mul [&#39;view_27&#39;, &#39;view_22&#39;] -&gt; [&#39;mul_21&#39;]
    97/321: Transpose [&#39;t_8&#39;] -&gt; [&#39;t_10&#39;]
    98/321: Constant [] -&gt; [&#39;aten_view_275_size_0&#39;]
    99/321: Reshape [&#39;mul_20&#39;, &#39;aten_view_275_size_0&#39;] -&gt; [&#39;view_28&#39;]
    100/321: Mul [&#39;mul_21&#39;, &#39;mul_23&#39;] -&gt; [&#39;mul_24&#39;]
    101/321: Transpose [&#39;view_28&#39;] -&gt; [&#39;t_11&#39;]
    102/321: MatMul [&#39;view_28&#39;, &#39;t_13&#39;] -&gt; [&#39;mm_10&#39;]
    103/321: Constant [] -&gt; [&#39;aten_view_280_size_0&#39;]
    104/321: Reshape [&#39;mul_24&#39;, &#39;aten_view_280_size_0&#39;] -&gt; [&#39;view_30&#39;]
    105/321: MatMul [&#39;t_11&#39;, &#39;view_19&#39;] -&gt; [&#39;mm_9&#39;]
    106/321: Constant [] -&gt; [&#39;aten_view_283_size_0&#39;]
    107/321: Reshape [&#39;mm_10&#39;, &#39;aten_view_283_size_0&#39;] -&gt; [&#39;view_29&#39;]
    108/321: Transpose [&#39;view_30&#39;] -&gt; [&#39;t_15&#39;]
    109/321: MatMul [&#39;view_30&#39;, &#39;t_17&#39;] -&gt; [&#39;mm_12&#39;]
    110/321: Transpose [&#39;mm_9&#39;] -&gt; [&#39;t_12&#39;]
    111/321: MatMul [&#39;t_15&#39;, &#39;view_19&#39;] -&gt; [&#39;mm_11&#39;]
    112/321: Constant [] -&gt; [&#39;aten_view_289_size_0&#39;]
    113/321: Reshape [&#39;mm_12&#39;, &#39;aten_view_289_size_0&#39;] -&gt; [&#39;view_31&#39;]
    114/321: Transpose [&#39;t_12&#39;] -&gt; [&#39;t_14&#39;]
    115/321: Transpose [&#39;mm_11&#39;] -&gt; [&#39;t_16&#39;]
    116/321: Constant [] -&gt; [&#39;alpha__4&#39;]
    117/321: Mul [&#39;view_31&#39;, &#39;alpha__4&#39;] -&gt; [&#39;other_1__4&#39;]
    118/321: Add [&#39;view_29&#39;, &#39;other_1__4&#39;] -&gt; [&#39;add_11&#39;]
    119/321: Transpose [&#39;t_16&#39;] -&gt; [&#39;t_18&#39;]
    120/321: Mul [&#39;add_11&#39;, &#39;primals_2&#39;] -&gt; [&#39;mul_25&#39;]
    121/321: Mul [&#39;add_11&#39;, &#39;mul_6&#39;] -&gt; [&#39;mul_26&#39;]
    122/321: Mul [&#39;mul_25&#39;, &#39;add_5&#39;] -&gt; [&#39;mul_27&#39;]
    123/321: Mul [&#39;mul_25&#39;, &#39;rsqrt_1&#39;] -&gt; [&#39;mul_28&#39;]
    124/321: Constant [] -&gt; [&#39;_val_209&#39;]
    125/321: ReduceSum [&#39;mul_26&#39;, &#39;_val_209&#39;] -&gt; [&#39;sum_3&#39;]
    126/321: Constant [] -&gt; [&#39;_val_211&#39;]
    127/321: ReduceSum [&#39;mul_27&#39;, &#39;_val_211&#39;] -&gt; [&#39;sum_4&#39;]
    128/321: Constant [] -&gt; [&#39;alpha__5&#39;]
    129/321: Mul [&#39;mul_28&#39;, &#39;alpha__5&#39;] -&gt; [&#39;other_1__5&#39;]
    130/321: Add [&#39;add_9&#39;, &#39;other_1__5&#39;] -&gt; [&#39;add_12&#39;]
    131/321: Constant [] -&gt; [&#39;aten_view_304_size_0&#39;]
    132/321: Reshape [&#39;sum_3&#39;, &#39;aten_view_304_size_0&#39;] -&gt; [&#39;view_32&#39;]
    133/321: Constant [] -&gt; [&#39;_val_216&#39;]
    134/321: Mul [&#39;sum_4&#39;, &#39;_val_216&#39;] -&gt; [&#39;mul_29&#39;]
    135/321: Mul [&#39;mul_29&#39;, &#39;pow_6&#39;] -&gt; [&#39;mul_30&#39;]
    136/321: Constant [] -&gt; [&#39;aten_expand_309_size_1&#39;]
    137/321: Expand [&#39;mul_30&#39;, &#39;aten_expand_309_size_1&#39;] -&gt; [&#39;expand_8&#39;]
    138/321: Constant [] -&gt; [&#39;scalar_tensor_default_5&#39;]
    139/321: Div [&#39;expand_8&#39;, &#39;scalar_tensor_default_5&#39;] -&gt; [&#39;div_2&#39;]
    140/321: Mul [&#39;div_2&#39;, &#39;mul_31&#39;] -&gt; [&#39;mul_32&#39;]
    141/321: Constant [] -&gt; [&#39;alpha__6&#39;]
    142/321: Mul [&#39;mul_32&#39;, &#39;alpha__6&#39;] -&gt; [&#39;other_1__6&#39;]
    143/321: Add [&#39;add_12&#39;, &#39;other_1__6&#39;] -&gt; [&#39;add_13&#39;]
    144/321: Constant [] -&gt; [&#39;aten_view_316_size_0&#39;]
    145/321: Reshape [&#39;add_13&#39;, &#39;aten_view_316_size_0&#39;] -&gt; [&#39;view_33&#39;]
    146/321: Transpose [&#39;view_33&#39;] -&gt; [&#39;t_19&#39;]
    147/321: MatMul [&#39;view_33&#39;, &#39;t_21&#39;] -&gt; [&#39;mm_14&#39;]
    148/321: MatMul [&#39;t_19&#39;, &#39;view_17&#39;] -&gt; [&#39;mm_13&#39;]
    149/321: Constant [] -&gt; [&#39;aten_view_321_size_0&#39;]
    150/321: Reshape [&#39;mm_14&#39;, &#39;aten_view_321_size_0&#39;] -&gt; [&#39;view_34&#39;]
    151/321: Transpose [&#39;mm_13&#39;] -&gt; [&#39;t_20&#39;]
    152/321: Constant [] -&gt; [&#39;aten_view_324_size_0&#39;]
    153/321: Reshape [&#39;view_34&#39;, &#39;aten_view_324_size_0&#39;] -&gt; [&#39;view_35&#39;]
    154/321: Transpose [&#39;t_20&#39;] -&gt; [&#39;t_22&#39;]
    155/321: Transpose [&#39;view_35&#39;] -&gt; [&#39;transpose_5&#39;]
    156/321: Constant [] -&gt; [&#39;aten_view_329_size_0&#39;]
    157/321: Reshape [&#39;transpose_5&#39;, &#39;aten_view_329_size_0&#39;] -&gt; [&#39;view_36&#39;]
    158/321: MatMul [&#39;transpose_6&#39;, &#39;view_36&#39;] -&gt; [&#39;bmm_2&#39;]
    159/321: MatMul [&#39;view_36&#39;, &#39;transpose_7&#39;] -&gt; [&#39;bmm_3&#39;]
    160/321: Constant [] -&gt; [&#39;aten_view_333_size_0&#39;]
    161/321: Reshape [&#39;bmm_2&#39;, &#39;aten_view_333_size_0&#39;] -&gt; [&#39;view_37&#39;]
    162/321: Constant [] -&gt; [&#39;aten_view_335_size_0&#39;]
    163/321: Reshape [&#39;bmm_3&#39;, &#39;aten_view_335_size_0&#39;] -&gt; [&#39;view_38&#39;]
    164/321: Constant [] -&gt; [&#39;alpha__7&#39;]
    165/321: Mul [&#39;view_37&#39;, &#39;alpha__7&#39;] -&gt; [&#39;other_1__7&#39;]
    166/321: Add [&#39;tangents_3&#39;, &#39;other_1__7&#39;] -&gt; [&#39;add_14&#39;]
    167/321: Mul [&#39;view_38&#39;, &#39;detach_13&#39;] -&gt; [&#39;mul_33&#39;]
    168/321: Transpose [&#39;add_14&#39;] -&gt; [&#39;transpose_11&#39;]
    169/321: Constant [] -&gt; [&#39;_val_250&#39;]
    170/321: ReduceSum [&#39;mul_33&#39;, &#39;_val_250&#39;] -&gt; [&#39;sum_5&#39;]
    171/321: Mul [&#39;detach_13&#39;, &#39;sum_5&#39;] -&gt; [&#39;mul_34&#39;]
    172/321: Constant [] -&gt; [&#39;aten_view_344_size_0&#39;]
    173/321: Reshape [&#39;transpose_11&#39;, &#39;aten_view_344_size_0&#39;] -&gt; [&#39;view_42&#39;]
    174/321: Constant [] -&gt; [&#39;alpha__8&#39;]
    175/321: Mul [&#39;mul_34&#39;, &#39;alpha__8&#39;] -&gt; [&#39;other_1__8&#39;]
    176/321: Sub [&#39;mul_33&#39;, &#39;other_1__8&#39;] -&gt; [&#39;sub_1&#39;]
    177/321: Constant [] -&gt; [&#39;aten_view_347_size_0&#39;]
    178/321: Reshape [&#39;view_42&#39;, &#39;aten_view_347_size_0&#39;] -&gt; [&#39;view_45&#39;]
    179/321: Constant [] -&gt; [&#39;_val_259&#39;]
    180/321: Div [&#39;sub_1&#39;, &#39;_val_259&#39;] -&gt; [&#39;div_3&#39;]
    181/321: Transpose [&#39;view_45&#39;] -&gt; [&#39;t_23&#39;]
    182/321: MatMul [&#39;view_45&#39;, &#39;t_25&#39;] -&gt; [&#39;mm_16&#39;]
    183/321: Constant [] -&gt; [&#39;aten_view_353_size_0&#39;]
    184/321: Reshape [&#39;div_3&#39;, &#39;aten_view_353_size_0&#39;] -&gt; [&#39;view_39&#39;]
    185/321: MatMul [&#39;t_23&#39;, &#39;view_1&#39;] -&gt; [&#39;mm_15&#39;]
    186/321: Constant [] -&gt; [&#39;aten_view_356_size_0&#39;]
    187/321: Reshape [&#39;mm_16&#39;, &#39;aten_view_356_size_0&#39;] -&gt; [&#39;view_46&#39;]
    188/321: MatMul [&#39;transpose_8&#39;, &#39;view_39&#39;] -&gt; [&#39;bmm_4&#39;]
    189/321: MatMul [&#39;view_39&#39;, &#39;transpose_9&#39;] -&gt; [&#39;bmm_5&#39;]
    190/321: Transpose [&#39;mm_15&#39;] -&gt; [&#39;t_24&#39;]
    191/321: Constant [] -&gt; [&#39;aten_view_361_size_0&#39;]
    192/321: Reshape [&#39;bmm_4&#39;, &#39;aten_view_361_size_0&#39;] -&gt; [&#39;view_40&#39;]
    193/321: Constant [] -&gt; [&#39;aten_view_363_size_0&#39;]
    194/321: Reshape [&#39;bmm_5&#39;, &#39;aten_view_363_size_0&#39;] -&gt; [&#39;view_41&#39;]
    195/321: Transpose [&#39;t_24&#39;] -&gt; [&#39;t_26&#39;]
    196/321: Transpose [&#39;view_40&#39;] -&gt; [&#39;transpose_10&#39;]
    197/321: Mul [&#39;view_41&#39;, &#39;unsqueeze_8&#39;] -&gt; [&#39;mul_37&#39;]
    198/321: Mul [&#39;view_41&#39;, &#39;unsqueeze_7&#39;] -&gt; [&#39;mul_38&#39;]
    199/321: Constant [] -&gt; [&#39;alpha__9&#39;]
    200/321: Mul [&#39;transpose_10&#39;, &#39;alpha__9&#39;] -&gt; [&#39;other_1__9&#39;]
    201/321: Add [&#39;tangents_2&#39;, &#39;other_1__9&#39;] -&gt; [&#39;add_15&#39;]
    202/321: Constant [] -&gt; [&#39;_val_283&#39;]
    203/321: Constant [] -&gt; [&#39;_val_287&#39;]
    204/321: Constant [] -&gt; [&#39;_val_291&#39;]
    205/321: Constant [] -&gt; [&#39;_val_295&#39;]
    206/321: Slice [&#39;mul_37&#39;, &#39;_val_283&#39;, &#39;_val_287&#39;, &#39;_val_291&#39;, &#39;_val_295&#39;] -&gt; [&#39;slice_15&#39;]
    207/321: Constant [] -&gt; [&#39;_val_300&#39;]
    208/321: Constant [] -&gt; [&#39;_val_304&#39;]
    209/321: Constant [] -&gt; [&#39;_val_308&#39;]
    210/321: Constant [] -&gt; [&#39;_val_312&#39;]
    211/321: Slice [&#39;mul_37&#39;, &#39;_val_300&#39;, &#39;_val_304&#39;, &#39;_val_308&#39;, &#39;_val_312&#39;] -&gt; [&#39;slice_16&#39;]
    212/321: Mul [&#39;add_15&#39;, &#39;unsqueeze_8&#39;] -&gt; [&#39;mul_35&#39;]
    213/321: Mul [&#39;add_15&#39;, &#39;unsqueeze_7&#39;] -&gt; [&#39;mul_36&#39;]
    214/321: Neg [&#39;slice_15&#39;] -&gt; [&#39;neg_3&#39;]
    215/321: Constant [] -&gt; [&#39;_val_322&#39;]
    216/321: Constant [] -&gt; [&#39;_val_326&#39;]
    217/321: Constant [] -&gt; [&#39;_val_330&#39;]
    218/321: Constant [] -&gt; [&#39;_val_334&#39;]
    219/321: Slice [&#39;mul_35&#39;, &#39;_val_322&#39;, &#39;_val_326&#39;, &#39;_val_330&#39;, &#39;_val_334&#39;] -&gt; [&#39;slice_13&#39;]
    220/321: Constant [] -&gt; [&#39;_val_339&#39;]
    221/321: Constant [] -&gt; [&#39;_val_343&#39;]
    222/321: Constant [] -&gt; [&#39;_val_347&#39;]
    223/321: Constant [] -&gt; [&#39;_val_351&#39;]
    224/321: Slice [&#39;mul_35&#39;, &#39;_val_339&#39;, &#39;_val_343&#39;, &#39;_val_347&#39;, &#39;_val_351&#39;] -&gt; [&#39;slice_14&#39;]
    225/321: Constant [] -&gt; [&#39;_val_370&#39;]
    226/321: Transpose [&#39;slice_16&#39;] -&gt; [&#39;_val_371&#39;]
    227/321: Constant [] -&gt; [&#39;_val_372&#39;]
    228/321: ScatterND [&#39;_val_372&#39;, &#39;_val_370&#39;, &#39;_val_371&#39;] -&gt; [&#39;_val_373&#39;]
    229/321: Transpose [&#39;_val_373&#39;] -&gt; [&#39;slice_scatter_3&#39;]
    230/321: Neg [&#39;slice_13&#39;] -&gt; [&#39;neg_2&#39;]
    231/321: Constant [] -&gt; [&#39;_val_393&#39;]
    232/321: Transpose [&#39;neg_3&#39;] -&gt; [&#39;_val_394&#39;]
    233/321: Constant [] -&gt; [&#39;_val_395&#39;]
    234/321: ScatterND [&#39;_val_395&#39;, &#39;_val_393&#39;, &#39;_val_394&#39;] -&gt; [&#39;_val_396&#39;]
    235/321: Transpose [&#39;_val_396&#39;] -&gt; [&#39;slice_scatter_2&#39;]
    236/321: Constant [] -&gt; [&#39;_val_415&#39;]
    237/321: Transpose [&#39;slice_14&#39;] -&gt; [&#39;_val_416&#39;]
    238/321: Constant [] -&gt; [&#39;_val_417&#39;]
    239/321: ScatterND [&#39;_val_417&#39;, &#39;_val_415&#39;, &#39;_val_416&#39;] -&gt; [&#39;_val_418&#39;]
    240/321: Transpose [&#39;_val_418&#39;] -&gt; [&#39;slice_scatter_1&#39;]
    241/321: Constant [] -&gt; [&#39;alpha__10&#39;]
    242/321: Mul [&#39;slice_scatter_3&#39;, &#39;alpha__10&#39;] -&gt; [&#39;other_1__10&#39;]
    243/321: Add [&#39;slice_scatter_2&#39;, &#39;other_1__10&#39;] -&gt; [&#39;add_18&#39;]
    244/321: Constant [] -&gt; [&#39;_val_436&#39;]
    245/321: Transpose [&#39;neg_2&#39;] -&gt; [&#39;_val_437&#39;]
    246/321: Constant [] -&gt; [&#39;_val_438&#39;]
    247/321: ScatterND [&#39;_val_438&#39;, &#39;_val_436&#39;, &#39;_val_437&#39;] -&gt; [&#39;_val_439&#39;]
    248/321: Transpose [&#39;_val_439&#39;] -&gt; [&#39;slice_scatter&#39;]
    249/321: Constant [] -&gt; [&#39;alpha__11&#39;]
    250/321: Mul [&#39;mul_38&#39;, &#39;alpha__11&#39;] -&gt; [&#39;other_1__11&#39;]
    251/321: Add [&#39;add_18&#39;, &#39;other_1__11&#39;] -&gt; [&#39;add_19&#39;]
    252/321: Constant [] -&gt; [&#39;alpha__12&#39;]
    253/321: Mul [&#39;slice_scatter_1&#39;, &#39;alpha__12&#39;] -&gt; [&#39;other_1__12&#39;]
    254/321: Add [&#39;slice_scatter&#39;, &#39;other_1__12&#39;] -&gt; [&#39;add_16&#39;]
    255/321: Transpose [&#39;add_19&#39;] -&gt; [&#39;transpose_13&#39;]
    256/321: Constant [] -&gt; [&#39;alpha__13&#39;]
    257/321: Mul [&#39;mul_36&#39;, &#39;alpha__13&#39;] -&gt; [&#39;other_1__13&#39;]
    258/321: Add [&#39;add_16&#39;, &#39;other_1__13&#39;] -&gt; [&#39;add_17&#39;]
    259/321: Transpose [&#39;add_17&#39;] -&gt; [&#39;transpose_12&#39;]
    260/321: Constant [] -&gt; [&#39;aten_view_537_size_0&#39;]
    261/321: Reshape [&#39;transpose_13&#39;, &#39;aten_view_537_size_0&#39;] -&gt; [&#39;view_44&#39;]
    262/321: Constant [] -&gt; [&#39;aten_view_540_size_0&#39;]
    263/321: Reshape [&#39;view_44&#39;, &#39;aten_view_540_size_0&#39;] -&gt; [&#39;view_49&#39;]
    264/321: Constant [] -&gt; [&#39;aten_view_542_size_0&#39;]
    265/321: Reshape [&#39;transpose_12&#39;, &#39;aten_view_542_size_0&#39;] -&gt; [&#39;view_43&#39;]
    266/321: Transpose [&#39;view_49&#39;] -&gt; [&#39;t_31&#39;]
    267/321: MatMul [&#39;view_49&#39;, &#39;t_33&#39;] -&gt; [&#39;mm_20&#39;]
    268/321: Constant [] -&gt; [&#39;aten_view_546_size_0&#39;]
    269/321: Reshape [&#39;view_43&#39;, &#39;aten_view_546_size_0&#39;] -&gt; [&#39;view_47&#39;]
    270/321: MatMul [&#39;t_31&#39;, &#39;view_1&#39;] -&gt; [&#39;mm_19&#39;]
    271/321: Constant [] -&gt; [&#39;aten_view_549_size_0&#39;]
    272/321: Reshape [&#39;mm_20&#39;, &#39;aten_view_549_size_0&#39;] -&gt; [&#39;view_50&#39;]
    273/321: Transpose [&#39;view_47&#39;] -&gt; [&#39;t_27&#39;]
    274/321: MatMul [&#39;view_47&#39;, &#39;t_29&#39;] -&gt; [&#39;mm_18&#39;]
    275/321: Transpose [&#39;mm_19&#39;] -&gt; [&#39;t_32&#39;]
    276/321: MatMul [&#39;t_27&#39;, &#39;view_1&#39;] -&gt; [&#39;mm_17&#39;]
    277/321: Constant [] -&gt; [&#39;aten_view_555_size_0&#39;]
    278/321: Reshape [&#39;mm_18&#39;, &#39;aten_view_555_size_0&#39;] -&gt; [&#39;view_48&#39;]
    279/321: Transpose [&#39;t_32&#39;] -&gt; [&#39;t_34&#39;]
    280/321: Transpose [&#39;mm_17&#39;] -&gt; [&#39;t_28&#39;]
    281/321: Constant [] -&gt; [&#39;alpha__14&#39;]
    282/321: Mul [&#39;view_48&#39;, &#39;alpha__14&#39;] -&gt; [&#39;other_1__14&#39;]
    283/321: Add [&#39;view_46&#39;, &#39;other_1__14&#39;] -&gt; [&#39;add_20&#39;]
    284/321: Transpose [&#39;t_28&#39;] -&gt; [&#39;t_30&#39;]
    285/321: Constant [] -&gt; [&#39;alpha__15&#39;]
    286/321: Mul [&#39;view_50&#39;, &#39;alpha__15&#39;] -&gt; [&#39;other_1__15&#39;]
    287/321: Add [&#39;add_20&#39;, &#39;other_1__15&#39;] -&gt; [&#39;add_21&#39;]
    288/321: Mul [&#39;add_21&#39;, &#39;primals_1&#39;] -&gt; [&#39;mul_39&#39;]
    289/321: Mul [&#39;add_21&#39;, &#39;mul&#39;] -&gt; [&#39;mul_40&#39;]
    290/321: Mul [&#39;mul_39&#39;, &#39;embedding&#39;] -&gt; [&#39;mul_41&#39;]
    291/321: Mul [&#39;mul_39&#39;, &#39;rsqrt&#39;] -&gt; [&#39;mul_42&#39;]
    292/321: Constant [] -&gt; [&#39;_val_476&#39;]
    293/321: ReduceSum [&#39;mul_40&#39;, &#39;_val_476&#39;] -&gt; [&#39;sum_6&#39;]
    294/321: Constant [] -&gt; [&#39;_val_478&#39;]
    295/321: ReduceSum [&#39;mul_41&#39;, &#39;_val_478&#39;] -&gt; [&#39;sum_7&#39;]
    296/321: Constant [] -&gt; [&#39;alpha__16&#39;]
    297/321: Mul [&#39;mul_42&#39;, &#39;alpha__16&#39;] -&gt; [&#39;other_1__16&#39;]
    298/321: Add [&#39;add_13&#39;, &#39;other_1__16&#39;] -&gt; [&#39;add_22&#39;]
    299/321: Constant [] -&gt; [&#39;aten_view_571_size_0&#39;]
    300/321: Reshape [&#39;sum_6&#39;, &#39;aten_view_571_size_0&#39;] -&gt; [&#39;view_51&#39;]
    301/321: Constant [] -&gt; [&#39;_val_483&#39;]
    302/321: Mul [&#39;sum_7&#39;, &#39;_val_483&#39;] -&gt; [&#39;mul_43&#39;]
    303/321: Mul [&#39;mul_43&#39;, &#39;pow_8&#39;] -&gt; [&#39;mul_44&#39;]
    304/321: Constant [] -&gt; [&#39;aten_expand_576_size_1&#39;]
    305/321: Expand [&#39;mul_44&#39;, &#39;aten_expand_576_size_1&#39;] -&gt; [&#39;expand_9&#39;]
    306/321: Constant [] -&gt; [&#39;scalar_tensor_default_6&#39;]
    307/321: Div [&#39;expand_9&#39;, &#39;scalar_tensor_default_6&#39;] -&gt; [&#39;div_4&#39;]
    308/321: Mul [&#39;div_4&#39;, &#39;mul_45&#39;] -&gt; [&#39;mul_46&#39;]
    309/321: Constant [] -&gt; [&#39;alpha__17&#39;]
    310/321: Mul [&#39;mul_46&#39;, &#39;alpha__17&#39;] -&gt; [&#39;other_1__17&#39;]
    311/321: Add [&#39;add_22&#39;, &#39;other_1__17&#39;] -&gt; [&#39;add_23&#39;]
    312/321: Constant [] -&gt; [&#39;aten_masked_fill_583_value_cast&#39;]
    313/321: Where [&#39;unsqueeze_9&#39;, &#39;aten_masked_fill_583_value_cast&#39;, &#39;add_23&#39;] -&gt; [&#39;masked_fill_3&#39;]
    314/321: Constant [] -&gt; [&#39;_val_495&#39;]
    315/321: ConstantOfShape [&#39;_val_495&#39;] -&gt; [&#39;aten_new_zeros_585_result&#39;]
    316/321: SequenceConstruct [&#39;primals_14&#39;] -&gt; [&#39;497&#39;]
    317/321: Constant [] -&gt; [&#39;int64_0__18&#39;]
    318/321: SequenceAt [&#39;497&#39;, &#39;int64_0__18&#39;] -&gt; [&#39;index__18&#39;]
    319/321: Constant [] -&gt; [&#39;int64_m1_1d__18&#39;]
    320/321: Unsqueeze [&#39;index__18&#39;, &#39;int64_m1_1d__18&#39;] -&gt; [&#39;new_index__18&#39;]
    321/321: ScatterND [&#39;aten_new_zeros_585_result&#39;, &#39;new_index__18&#39;, &#39;masked_fill_3&#39;] -&gt; [&#39;_unsafe_index_put&#39;]
    
    NODES in {name!r}
    1/235: Transpose [&#39;primals_9&#39;] -&gt; [&#39;t_4&#39;]
    2/235: Gather [&#39;primals_4&#39;, &#39;primals_14&#39;] -&gt; [&#39;embedding&#39;]
    3/235: Constant [] -&gt; [&#39;_val_24&#39;]
    4/235: Constant [] -&gt; [&#39;_val_25&#39;]
    5/235: Constant [] -&gt; [&#39;size_0__1&#39;]
    6/235: Constant [] -&gt; [&#39;fill_value_1__1&#39;]
    7/235: Expand [&#39;fill_value_1__1&#39;, &#39;size_0__1&#39;] -&gt; [&#39;full&#39;]
    8/235: Transpose [&#39;primals_10&#39;] -&gt; [&#39;t_5&#39;]
    9/235: Constant [] -&gt; [&#39;_val_39&#39;]
    10/235: Constant [] -&gt; [&#39;_val_43&#39;]
    11/235: Constant [] -&gt; [&#39;_val_47&#39;]
    12/235: Constant [] -&gt; [&#39;_val_51&#39;]
    13/235: Slice [&#39;primals_15&#39;, &#39;_val_39&#39;, &#39;_val_43&#39;, &#39;_val_47&#39;, &#39;_val_51&#39;] -&gt; [&#39;slice_3&#39;]
    14/235: Transpose [&#39;primals_11&#39;] -&gt; [&#39;t_6&#39;]
    15/235: Transpose [&#39;primals_5&#39;] -&gt; [&#39;t&#39;]
    16/235: Transpose [&#39;primals_6&#39;] -&gt; [&#39;t_1&#39;]
    17/235: Transpose [&#39;primals_7&#39;] -&gt; [&#39;t_2&#39;]
    18/235: Constant [] -&gt; [&#39;_val_60&#39;]
    19/235: Constant [] -&gt; [&#39;_val_64&#39;]
    20/235: Constant [] -&gt; [&#39;_val_68&#39;]
    21/235: Constant [] -&gt; [&#39;_val_72&#39;]
    22/235: Slice [&#39;primals_12&#39;, &#39;_val_60&#39;, &#39;_val_64&#39;, &#39;_val_68&#39;, &#39;_val_72&#39;] -&gt; [&#39;slice_7&#39;]
    23/235: Constant [] -&gt; [&#39;_val_77&#39;]
    24/235: Constant [] -&gt; [&#39;_val_81&#39;]
    25/235: Constant [] -&gt; [&#39;_val_85&#39;]
    26/235: Constant [] -&gt; [&#39;_val_89&#39;]
    27/235: Slice [&#39;primals_13&#39;, &#39;_val_77&#39;, &#39;_val_81&#39;, &#39;_val_85&#39;, &#39;_val_89&#39;] -&gt; [&#39;slice_8&#39;]
    28/235: Transpose [&#39;primals_8&#39;] -&gt; [&#39;t_3&#39;]
    29/235: Transpose [&#39;t_4&#39;] -&gt; [&#39;t_17&#39;]
    30/235: Constant [] -&gt; [&#39;scalar_tensor_default&#39;]
    31/235: Pow [&#39;embedding&#39;, &#39;scalar_tensor_default&#39;] -&gt; [&#39;pow_1&#39;]
    32/235: Transpose [&#39;t_5&#39;] -&gt; [&#39;t_13&#39;]
    33/235: Constant [] -&gt; [&#39;aten_unsqueeze_180_dim_0&#39;]
    34/235: Unsqueeze [&#39;slice_3&#39;, &#39;aten_unsqueeze_180_dim_0&#39;] -&gt; [&#39;unsqueeze_3&#39;]
    35/235: Transpose [&#39;t_6&#39;] -&gt; [&#39;t_9&#39;]
    36/235: Transpose [&#39;t&#39;] -&gt; [&#39;t_33&#39;]
    37/235: Transpose [&#39;t_1&#39;] -&gt; [&#39;t_29&#39;]
    38/235: Transpose [&#39;t_2&#39;] -&gt; [&#39;t_25&#39;]
    39/235: Transpose [&#39;t_3&#39;] -&gt; [&#39;t_21&#39;]
    40/235: Transpose [&#39;slice_7&#39;] -&gt; [&#39;_val_106&#39;]
    41/235: Constant [] -&gt; [&#39;_val_112&#39;]
    42/235: GatherND [&#39;_val_106&#39;, &#39;_val_112&#39;] -&gt; [&#39;_val_113&#39;]
    43/235: Transpose [&#39;_val_113&#39;] -&gt; [&#39;index&#39;]
    44/235: Transpose [&#39;slice_8&#39;] -&gt; [&#39;_val_115&#39;]
    45/235: Constant [] -&gt; [&#39;_val_121&#39;]
    46/235: GatherND [&#39;_val_115&#39;, &#39;_val_121&#39;] -&gt; [&#39;_val_122&#39;]
    47/235: Transpose [&#39;_val_122&#39;] -&gt; [&#39;index_1&#39;]
    48/235: Constant [] -&gt; [&#39;_val_124&#39;]
    49/235: ReduceMean [&#39;pow_1&#39;, &#39;_val_124&#39;] -&gt; [&#39;mean&#39;]
    50/235: Constant [] -&gt; [&#39;aten_unsqueeze_208_dim_0&#39;]
    51/235: Unsqueeze [&#39;unsqueeze_3&#39;, &#39;aten_unsqueeze_208_dim_0&#39;] -&gt; [&#39;unsqueeze_4&#39;]
    52/235: Constant [] -&gt; [&#39;aten_unsqueeze_209_dim_0&#39;]
    53/235: Unsqueeze [&#39;index&#39;, &#39;aten_unsqueeze_209_dim_0&#39;] -&gt; [&#39;unsqueeze_7&#39;]
    54/235: Constant [] -&gt; [&#39;aten_unsqueeze_210_dim_0&#39;]
    55/235: Unsqueeze [&#39;index_1&#39;, &#39;aten_unsqueeze_210_dim_0&#39;] -&gt; [&#39;unsqueeze_8&#39;]
    56/235: Constant [] -&gt; [&#39;aten_add_212_other_1&#39;]
    57/235: Add [&#39;mean&#39;, &#39;aten_add_212_other_1&#39;] -&gt; [&#39;add_1&#39;]
    58/235: Constant [] -&gt; [&#39;lt&#39;]
    59/235: Constant [] -&gt; [&#39;_val_137&#39;]
    60/235: Constant [] -&gt; [&#39;_val_141&#39;]
    61/235: Constant [] -&gt; [&#39;_val_145&#39;]
    62/235: Constant [] -&gt; [&#39;_val_149&#39;]
    63/235: Slice [&#39;unsqueeze_4&#39;, &#39;_val_137&#39;, &#39;_val_141&#39;, &#39;_val_145&#39;, &#39;_val_149&#39;] -&gt; [&#39;slice_4&#39;]
    64/235: Sqrt [&#39;add_1&#39;] -&gt; [&#39;aten_rsqrt_231_tmp&#39;]
    65/235: Reciprocal [&#39;aten_rsqrt_231_tmp&#39;] -&gt; [&#39;rsqrt&#39;]
    66/235: Constant [] -&gt; [&#39;aten_masked_fill_233_value_cast&#39;]
    67/235: Where [&#39;lt&#39;, &#39;aten_masked_fill_233_value_cast&#39;, &#39;full&#39;] -&gt; [&#39;masked_fill&#39;]
    68/235: Constant [] -&gt; [&#39;aten_expand_235_size_1&#39;]
    69/235: Expand [&#39;slice_4&#39;, &#39;aten_expand_235_size_1&#39;] -&gt; [&#39;expand_1&#39;]
    70/235: Mul [&#39;embedding&#39;, &#39;rsqrt&#39;] -&gt; [&#39;mul&#39;]
    71/235: Constant [] -&gt; [&#39;aten_unsqueeze_237_dim_0&#39;]
    72/235: Unsqueeze [&#39;masked_fill&#39;, &#39;aten_unsqueeze_237_dim_0&#39;] -&gt; [&#39;unsqueeze_5&#39;]
    73/235: Constant [] -&gt; [&#39;_val_158&#39;]
    74/235: Constant [] -&gt; [&#39;alpha__2&#39;]
    75/235: Mul [&#39;expand_1&#39;, &#39;alpha__2&#39;] -&gt; [&#39;tmp__2&#39;]
    76/235: Sub [&#39;_val_158&#39;, &#39;tmp__2&#39;] -&gt; [&#39;rsub&#39;]
    77/235: Mul [&#39;primals_1&#39;, &#39;mul&#39;] -&gt; [&#39;mul_1&#39;]
    78/235: Constant [] -&gt; [&#39;aten_unsqueeze_241_dim_0&#39;]
    79/235: Unsqueeze [&#39;unsqueeze_5&#39;, &#39;aten_unsqueeze_241_dim_0&#39;] -&gt; [&#39;unsqueeze_6&#39;]
    80/235: Cast [&#39;rsub&#39;] -&gt; [&#39;_to_copy&#39;]
    81/235: Constant [] -&gt; [&#39;aten_view_244_size_0&#39;]
    82/235: Reshape [&#39;mul_1&#39;, &#39;aten_view_244_size_0&#39;] -&gt; [&#39;view_1&#39;]
    83/235: Constant [] -&gt; [&#39;_val_168&#39;]
    84/235: Constant [] -&gt; [&#39;_val_172&#39;]
    85/235: Constant [] -&gt; [&#39;_val_176&#39;]
    86/235: Constant [] -&gt; [&#39;_val_180&#39;]
    87/235: Slice [&#39;unsqueeze_6&#39;, &#39;_val_168&#39;, &#39;_val_172&#39;, &#39;_val_176&#39;, &#39;_val_180&#39;] -&gt; [&#39;slice_5&#39;]
    88/235: Constant [] -&gt; [&#39;_val_182&#39;]
    89/235: Where [&#39;_to_copy&#39;, &#39;_val_182&#39;, &#39;rsub&#39;] -&gt; [&#39;masked_fill_1&#39;]
    90/235: MatMul [&#39;view_1&#39;, &#39;t&#39;] -&gt; [&#39;mm&#39;]
    91/235: MatMul [&#39;view_1&#39;, &#39;t_1&#39;] -&gt; [&#39;mm_1&#39;]
    92/235: MatMul [&#39;view_1&#39;, &#39;t_2&#39;] -&gt; [&#39;mm_2&#39;]
    93/235: Constant [] -&gt; [&#39;_val_190&#39;]
    94/235: Constant [] -&gt; [&#39;_val_194&#39;]
    95/235: Constant [] -&gt; [&#39;_val_198&#39;]
    96/235: Constant [] -&gt; [&#39;_val_202&#39;]
    97/235: Slice [&#39;slice_5&#39;, &#39;_val_190&#39;, &#39;_val_194&#39;, &#39;_val_198&#39;, &#39;_val_202&#39;] -&gt; [&#39;slice_6&#39;]
    98/235: Cast [&#39;masked_fill_1&#39;] -&gt; [&#39;_to_copy_1&#39;]
    99/235: Constant [] -&gt; [&#39;aten_view_286_size_0&#39;]
    100/235: Reshape [&#39;mm&#39;, &#39;aten_view_286_size_0&#39;] -&gt; [&#39;view_2&#39;]
    101/235: Constant [] -&gt; [&#39;aten_view_288_size_0&#39;]
    102/235: Reshape [&#39;mm_1&#39;, &#39;aten_view_288_size_0&#39;] -&gt; [&#39;view_4&#39;]
    103/235: Constant [] -&gt; [&#39;aten_view_290_size_0&#39;]
    104/235: Reshape [&#39;mm_2&#39;, &#39;aten_view_290_size_0&#39;] -&gt; [&#39;view_6&#39;]
    105/235: Constant [] -&gt; [&#39;aten_expand_292_size_1&#39;]
    106/235: Expand [&#39;slice_6&#39;, &#39;aten_expand_292_size_1&#39;] -&gt; [&#39;expand_2&#39;]
    107/235: Constant [] -&gt; [&#39;aten_view_294_size_0&#39;]
    108/235: Reshape [&#39;view_2&#39;, &#39;aten_view_294_size_0&#39;] -&gt; [&#39;view_7&#39;]
    109/235: Constant [] -&gt; [&#39;aten_view_296_size_0&#39;]
    110/235: Reshape [&#39;view_4&#39;, &#39;aten_view_296_size_0&#39;] -&gt; [&#39;view_8&#39;]
    111/235: Constant [] -&gt; [&#39;aten_view_298_size_0&#39;]
    112/235: Reshape [&#39;view_6&#39;, &#39;aten_view_298_size_0&#39;] -&gt; [&#39;view_9&#39;]
    113/235: Constant [] -&gt; [&#39;_val_219&#39;]
    114/235: Where [&#39;_to_copy_1&#39;, &#39;_val_219&#39;, &#39;expand_2&#39;] -&gt; [&#39;masked_fill_2&#39;]
    115/235: Transpose [&#39;view_7&#39;] -&gt; [&#39;transpose&#39;]
    116/235: Transpose [&#39;view_8&#39;] -&gt; [&#39;transpose_1&#39;]
    117/235: Transpose [&#39;view_9&#39;] -&gt; [&#39;transpose_2&#39;]
    118/235: Mul [&#39;transpose&#39;, &#39;unsqueeze_7&#39;] -&gt; [&#39;mul_2&#39;]
    119/235: Constant [] -&gt; [&#39;_val_228&#39;]
    120/235: Constant [] -&gt; [&#39;_val_232&#39;]
    121/235: Constant [] -&gt; [&#39;_val_236&#39;]
    122/235: Constant [] -&gt; [&#39;_val_240&#39;]
    123/235: Slice [&#39;transpose&#39;, &#39;_val_228&#39;, &#39;_val_232&#39;, &#39;_val_236&#39;, &#39;_val_240&#39;] -&gt; [&#39;slice_9&#39;]
    124/235: Constant [] -&gt; [&#39;_val_245&#39;]
    125/235: Constant [] -&gt; [&#39;_val_249&#39;]
    126/235: Constant [] -&gt; [&#39;_val_253&#39;]
    127/235: Constant [] -&gt; [&#39;_val_257&#39;]
    128/235: Slice [&#39;transpose&#39;, &#39;_val_245&#39;, &#39;_val_249&#39;, &#39;_val_253&#39;, &#39;_val_257&#39;] -&gt; [&#39;slice_10&#39;]
    129/235: Mul [&#39;transpose_1&#39;, &#39;unsqueeze_7&#39;] -&gt; [&#39;mul_4&#39;]
    130/235: Constant [] -&gt; [&#39;_val_263&#39;]
    131/235: Constant [] -&gt; [&#39;_val_267&#39;]
    132/235: Constant [] -&gt; [&#39;_val_271&#39;]
    133/235: Constant [] -&gt; [&#39;_val_275&#39;]
    134/235: Slice [&#39;transpose_1&#39;, &#39;_val_263&#39;, &#39;_val_267&#39;, &#39;_val_271&#39;, &#39;_val_275&#39;] -&gt; [&#39;slice_11&#39;]
    135/235: Constant [] -&gt; [&#39;_val_280&#39;]
    136/235: Constant [] -&gt; [&#39;_val_284&#39;]
    137/235: Constant [] -&gt; [&#39;_val_288&#39;]
    138/235: Constant [] -&gt; [&#39;_val_292&#39;]
    139/235: Slice [&#39;transpose_1&#39;, &#39;_val_280&#39;, &#39;_val_284&#39;, &#39;_val_288&#39;, &#39;_val_292&#39;] -&gt; [&#39;slice_12&#39;]
    140/235: Constant [] -&gt; [&#39;aten_expand_375_size_1&#39;]
    141/235: Expand [&#39;transpose_2&#39;, &#39;aten_expand_375_size_1&#39;] -&gt; [&#39;expand_6&#39;]
    142/235: Neg [&#39;slice_10&#39;] -&gt; [&#39;neg&#39;]
    143/235: Neg [&#39;slice_12&#39;] -&gt; [&#39;neg_1&#39;]
    144/235: Concat [&#39;neg&#39;, &#39;slice_9&#39;] -&gt; [&#39;cat&#39;]
    145/235: Concat [&#39;neg_1&#39;, &#39;slice_11&#39;] -&gt; [&#39;cat_1&#39;]
    146/235: Constant [] -&gt; [&#39;aten_view_384_size_0&#39;]
    147/235: Reshape [&#39;expand_6&#39;, &#39;aten_view_384_size_0&#39;] -&gt; [&#39;view_14&#39;]
    148/235: Mul [&#39;cat&#39;, &#39;unsqueeze_8&#39;] -&gt; [&#39;mul_3&#39;]
    149/235: Mul [&#39;cat_1&#39;, &#39;unsqueeze_8&#39;] -&gt; [&#39;mul_5&#39;]
    150/235: Transpose [&#39;view_14&#39;] -&gt; [&#39;transpose_7&#39;]
    151/235: Constant [] -&gt; [&#39;alpha__3&#39;]
    152/235: Mul [&#39;mul_3&#39;, &#39;alpha__3&#39;] -&gt; [&#39;other_1__3&#39;]
    153/235: Add [&#39;mul_2&#39;, &#39;other_1__3&#39;] -&gt; [&#39;add_2&#39;]
    154/235: Constant [] -&gt; [&#39;alpha__4&#39;]
    155/235: Mul [&#39;mul_5&#39;, &#39;alpha__4&#39;] -&gt; [&#39;other_1__4&#39;]
    156/235: Add [&#39;mul_4&#39;, &#39;other_1__4&#39;] -&gt; [&#39;add_3&#39;]
    157/235: Constant [] -&gt; [&#39;aten_expand_391_size_1&#39;]
    158/235: Expand [&#39;add_2&#39;, &#39;aten_expand_391_size_1&#39;] -&gt; [&#39;expand_3&#39;]
    159/235: Transpose [&#39;add_3&#39;] -&gt; [&#39;transpose_3&#39;]
    160/235: Constant [] -&gt; [&#39;aten_expand_395_size_1&#39;]
    161/235: Expand [&#39;transpose_3&#39;, &#39;aten_expand_395_size_1&#39;] -&gt; [&#39;expand_4&#39;]
    162/235: Constant [] -&gt; [&#39;aten_view_397_size_0&#39;]
    163/235: Reshape [&#39;expand_3&#39;, &#39;aten_view_397_size_0&#39;] -&gt; [&#39;view_10&#39;]
    164/235: Transpose [&#39;view_10&#39;] -&gt; [&#39;transpose_8&#39;]
    165/235: Constant [] -&gt; [&#39;aten_view_401_size_0&#39;]
    166/235: Reshape [&#39;expand_4&#39;, &#39;aten_view_401_size_0&#39;] -&gt; [&#39;view_11&#39;]
    167/235: MatMul [&#39;view_10&#39;, &#39;view_11&#39;] -&gt; [&#39;bmm&#39;]
    168/235: Transpose [&#39;view_11&#39;] -&gt; [&#39;transpose_9&#39;]
    169/235: Constant [] -&gt; [&#39;aten_view_405_size_0&#39;]
    170/235: Reshape [&#39;bmm&#39;, &#39;aten_view_405_size_0&#39;] -&gt; [&#39;view_12&#39;]
    171/235: Constant [] -&gt; [&#39;_val_326&#39;]
    172/235: Div [&#39;view_12&#39;, &#39;_val_326&#39;] -&gt; [&#39;div&#39;]
    173/235: Constant [] -&gt; [&#39;alpha__5&#39;]
    174/235: Mul [&#39;masked_fill_2&#39;, &#39;alpha__5&#39;] -&gt; [&#39;other_1__5&#39;]
    175/235: Add [&#39;div&#39;, &#39;other_1__5&#39;] -&gt; [&#39;add_4&#39;]
    176/235: Softmax [&#39;add_4&#39;] -&gt; [&#39;_softmax&#39;]
    177/235: Constant [] -&gt; [&#39;aten_expand_414_size_1&#39;]
    178/235: Expand [&#39;_softmax&#39;, &#39;aten_expand_414_size_1&#39;] -&gt; [&#39;expand_5&#39;]
    179/235: Constant [] -&gt; [&#39;aten_view_417_size_0&#39;]
    180/235: Reshape [&#39;expand_5&#39;, &#39;aten_view_417_size_0&#39;] -&gt; [&#39;view_13&#39;]
    181/235: Identity [&#39;_softmax&#39;] -&gt; [&#39;detach_13&#39;]
    182/235: MatMul [&#39;view_13&#39;, &#39;view_14&#39;] -&gt; [&#39;bmm_1&#39;]
    183/235: Transpose [&#39;view_13&#39;] -&gt; [&#39;transpose_6&#39;]
    184/235: Constant [] -&gt; [&#39;aten_view_422_size_0&#39;]
    185/235: Reshape [&#39;bmm_1&#39;, &#39;aten_view_422_size_0&#39;] -&gt; [&#39;view_15&#39;]
    186/235: Transpose [&#39;view_15&#39;] -&gt; [&#39;transpose_4&#39;]
    187/235: Constant [] -&gt; [&#39;aten_view_426_size_0&#39;]
    188/235: Reshape [&#39;transpose_4&#39;, &#39;aten_view_426_size_0&#39;] -&gt; [&#39;view_16&#39;]
    189/235: Constant [] -&gt; [&#39;aten_view_428_size_0&#39;]
    190/235: Reshape [&#39;view_16&#39;, &#39;aten_view_428_size_0&#39;] -&gt; [&#39;view_17&#39;]
    191/235: MatMul [&#39;view_17&#39;, &#39;t_3&#39;] -&gt; [&#39;mm_3&#39;]
    192/235: Constant [] -&gt; [&#39;aten_view_431_size_0&#39;]
    193/235: Reshape [&#39;mm_3&#39;, &#39;aten_view_431_size_0&#39;] -&gt; [&#39;view_18&#39;]
    194/235: Constant [] -&gt; [&#39;alpha__6&#39;]
    195/235: Mul [&#39;view_18&#39;, &#39;alpha__6&#39;] -&gt; [&#39;other_1__6&#39;]
    196/235: Add [&#39;embedding&#39;, &#39;other_1__6&#39;] -&gt; [&#39;add_5&#39;]
    197/235: Constant [] -&gt; [&#39;scalar_tensor_default_1&#39;]
    198/235: Pow [&#39;add_5&#39;, &#39;scalar_tensor_default_1&#39;] -&gt; [&#39;pow_2&#39;]
    199/235: Constant [] -&gt; [&#39;_val_356&#39;]
    200/235: ReduceMean [&#39;pow_2&#39;, &#39;_val_356&#39;] -&gt; [&#39;mean_1&#39;]
    201/235: Constant [] -&gt; [&#39;aten_add_439_other_1&#39;]
    202/235: Add [&#39;mean_1&#39;, &#39;aten_add_439_other_1&#39;] -&gt; [&#39;add_6&#39;]
    203/235: Sqrt [&#39;add_6&#39;] -&gt; [&#39;aten_rsqrt_440_tmp&#39;]
    204/235: Reciprocal [&#39;aten_rsqrt_440_tmp&#39;] -&gt; [&#39;rsqrt_1&#39;]
    205/235: Mul [&#39;add_5&#39;, &#39;rsqrt_1&#39;] -&gt; [&#39;mul_6&#39;]
    206/235: Mul [&#39;primals_2&#39;, &#39;mul_6&#39;] -&gt; [&#39;mul_7&#39;]
    207/235: Constant [] -&gt; [&#39;aten_view_444_size_0&#39;]
    208/235: Reshape [&#39;mul_7&#39;, &#39;aten_view_444_size_0&#39;] -&gt; [&#39;view_19&#39;]
    209/235: MatMul [&#39;view_19&#39;, &#39;t_4&#39;] -&gt; [&#39;mm_4&#39;]
    210/235: MatMul [&#39;view_19&#39;, &#39;t_5&#39;] -&gt; [&#39;mm_5&#39;]
    211/235: Constant [] -&gt; [&#39;aten_view_448_size_0&#39;]
    212/235: Reshape [&#39;mm_4&#39;, &#39;aten_view_448_size_0&#39;] -&gt; [&#39;view_20&#39;]
    213/235: Constant [] -&gt; [&#39;aten_view_450_size_0&#39;]
    214/235: Reshape [&#39;mm_5&#39;, &#39;aten_view_450_size_0&#39;] -&gt; [&#39;view_22&#39;]
    215/235: Sigmoid [&#39;view_20&#39;] -&gt; [&#39;sigmoid&#39;]
    216/235: Mul [&#39;view_20&#39;, &#39;sigmoid&#39;] -&gt; [&#39;mul_8&#39;]
    217/235: Mul [&#39;mul_8&#39;, &#39;view_22&#39;] -&gt; [&#39;mul_9&#39;]
    218/235: Constant [] -&gt; [&#39;aten_view_455_size_0&#39;]
    219/235: Reshape [&#39;mul_9&#39;, &#39;aten_view_455_size_0&#39;] -&gt; [&#39;view_23&#39;]
    220/235: MatMul [&#39;view_23&#39;, &#39;t_6&#39;] -&gt; [&#39;mm_6&#39;]
    221/235: Constant [] -&gt; [&#39;aten_view_458_size_0&#39;]
    222/235: Reshape [&#39;mm_6&#39;, &#39;aten_view_458_size_0&#39;] -&gt; [&#39;view_24&#39;]
    223/235: Constant [] -&gt; [&#39;alpha__7&#39;]
    224/235: Mul [&#39;view_24&#39;, &#39;alpha__7&#39;] -&gt; [&#39;other_1__7&#39;]
    225/235: Add [&#39;add_5&#39;, &#39;other_1__7&#39;] -&gt; [&#39;add_7&#39;]
    226/235: Constant [] -&gt; [&#39;scalar_tensor_default_2&#39;]
    227/235: Pow [&#39;add_7&#39;, &#39;scalar_tensor_default_2&#39;] -&gt; [&#39;pow_3&#39;]
    228/235: Constant [] -&gt; [&#39;_val_383&#39;]
    229/235: ReduceMean [&#39;pow_3&#39;, &#39;_val_383&#39;] -&gt; [&#39;mean_2&#39;]
    230/235: Constant [] -&gt; [&#39;aten_add_466_other_1&#39;]
    231/235: Add [&#39;mean_2&#39;, &#39;aten_add_466_other_1&#39;] -&gt; [&#39;add_8&#39;]
    232/235: Sqrt [&#39;add_8&#39;] -&gt; [&#39;aten_rsqrt_467_tmp&#39;]
    233/235: Reciprocal [&#39;aten_rsqrt_467_tmp&#39;] -&gt; [&#39;rsqrt_2&#39;]
    234/235: Mul [&#39;add_7&#39;, &#39;rsqrt_2&#39;] -&gt; [&#39;mul_10&#39;]
    235/235: Mul [&#39;primals_3&#39;, &#39;mul_10&#39;] -&gt; [&#39;mul_11&#39;]
    [runpythonerror]
    /home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/exporter.py:137: UserWarning: torch.onnx.dynamo_export only implements opset version 18 for now. If you need to use a different opset version, please register them with register_custom_op.
      warnings.warn(
    2024-04-30 15:23:23,321 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue return_val due to large size 4194304.
    2024-04-30 15:23:23,322 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue full due to large size 4194304.
    2024-04-30 15:23:23,472 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue masked_fill due to large size 4194304.
    2024-04-30 15:23:23,476 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue return_val due to large size 4194304.
    2024-04-30 15:23:23,476 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue unsqueeze_5 due to large size 4194304.
    2024-04-30 15:23:23,480 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue return_val due to large size 4194304.
    2024-04-30 15:23:23,480 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue unsqueeze_6 due to large size 4194304.
    2024-04-30 15:23:23,490 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue slice_5 due to large size 4194304.
    2024-04-30 15:23:23,499 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue slice_6 due to large size 4194304.
    2024-04-30 15:23:23,510 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue return_val due to large size 8388608.
    2024-04-30 15:23:23,510 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue expand_2 due to large size 8388608.
    2024-04-30 15:23:23,761 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue return_val due to large size 4194304.
    2024-04-30 15:23:23,762 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue full due to large size 4194304.
    2024-04-30 15:23:23,788 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue masked_fill due to large size 4194304.
    2024-04-30 15:23:23,791 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue unsqueeze_5 due to large size 4194304.
    2024-04-30 15:23:23,794 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue unsqueeze_6 due to large size 4194304.
    2024-04-30 15:23:23,798 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue slice_5 due to large size 4194304.
    2024-04-30 15:23:23,802 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue slice_6 due to large size 4194304.
    2024-04-30 15:23:23,812 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue expand_2 due to large size 8388608.
    [0;93m2024-04-30 15:23:23.955925500 [W:onnxruntime:, graph.cc:4051 CleanUnusedInitializersAndNodeArgs] Removing initializer &#39;_val_24&#39;. It is not used by any node and should be removed from the model.[m
    [0;93m2024-04-30 15:23:23.956125400 [W:onnxruntime:, graph.cc:4051 CleanUnusedInitializersAndNodeArgs] Removing initializer &#39;_val_25&#39;. It is not used by any node and should be removed from the model.[m
</pre></div>
</div>
</section>
<section id="with-the-custom-exporter">
<h3>With the custom exporter<a class="headerlink" href="#with-the-custom-exporter" title="Link to this heading">¶</a></h3>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">onnx</span>

<span class="c1"># from onnx_array_api.plotting.text_plot import onnx_simple_text_plot</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.onnx</span>
<span class="kn">from</span> <span class="nn">experimental_experiment.torch_models.training_helper</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">make_aot_ort</span><span class="p">,</span>
    <span class="n">train_loop</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">experimental_experiment.torch_models.dump_helper</span> <span class="kn">import</span> <span class="n">dump_onnx</span>

<span class="c1"># from experimental_experiment.torch_interpreter import to_onnx</span>

<span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
    <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">LlamaConfig</span>
    <span class="kn">from</span> <span class="nn">transformers.models.llama.modeling_llama</span> <span class="kn">import</span> <span class="n">LlamaModel</span>


<span class="k">def</span> <span class="nf">ids_tensor</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">):</span>
    <span class="n">total_dims</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="n">shape</span><span class="p">:</span>
        <span class="n">total_dims</span> <span class="o">*=</span> <span class="n">dim</span>

    <span class="n">values</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">total_dims</span><span class="p">):</span>
        <span class="n">values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">vocab_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>


<span class="n">config</span> <span class="o">=</span> <span class="n">LlamaConfig</span><span class="p">(</span>
    <span class="n">hidden_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">num_hidden_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">vocab_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
    <span class="n">intermediate_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">max_position_embeddings</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
    <span class="n">num_attention_heads</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">config</span><span class="o">.</span><span class="n">_attn_implementation</span> <span class="o">=</span> <span class="s2">&quot;eager&quot;</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">LlamaModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

<span class="n">batch</span><span class="p">,</span> <span class="n">seq</span><span class="p">,</span> <span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span>

<span class="n">input_ids</span> <span class="o">=</span> <span class="n">ids_tensor</span><span class="p">([</span><span class="n">batch</span><span class="p">,</span> <span class="n">seq</span><span class="p">],</span> <span class="n">vocab_size</span><span class="p">)</span>
<span class="n">input_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tril</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">seq</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

<span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">input_mask</span><span class="p">)</span>

<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;ONNXRT_CHANGE_REWRITER&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;1&quot;</span>

<span class="n">local_aot_ort</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">make_aot_ort</span><span class="p">(</span>
    <span class="n">dynamic</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>

<span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
    <span class="n">optimized_mod</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="n">local_aot_ort</span><span class="p">,</span> <span class="n">fullgraph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">dump_onnx</span><span class="p">(</span><span class="s2">&quot;dort-llama-ort&quot;</span><span class="p">,</span> <span class="n">folder</span><span class="o">=</span><span class="s2">&quot;dump_llama&quot;</span><span class="p">,</span> <span class="n">clean</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="n">train_loop</span><span class="p">(</span><span class="n">optimized_mod</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">input_mask</span><span class="p">)</span>

<span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="n">_</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s2">&quot;dump_llama&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">_</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.onnx&quot;</span><span class="p">)]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------------------------&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;exported model: </span><span class="si">{</span><span class="n">names</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">names</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;NODES in </span><span class="si">{name!r}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">onx</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">&quot;dump_llama&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">node</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">onx</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">onx</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="p">)</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">node</span><span class="o">.</span><span class="n">op_type</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="si">}</span><span class="s2"> -&gt; </span><span class="si">{</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;ONNXRT_CHANGE_REWRITER&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;0&quot;</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    [2024-04-30 15:23:32,552] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
    Applied 0 of general pattern rewrite rules.
    Applied 0 of general pattern rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific pattern rewrite rules.
    Applied 0 of general pattern rewrite rules.
    Applied 0 of general pattern rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific pattern rewrite rules.
    ------------------------------------------
    exported model: [&#39;dort-llama-ort_1.onnx&#39;, &#39;dort-llama-ort_0.onnx&#39;]
    
    NODES in {name!r}
    1/321: Constant [] -&gt; [&#39;_val_34&#39;]
    2/321: Pow [&#39;embedding&#39;, &#39;_val_34&#39;] -&gt; [&#39;pow_9&#39;]
    3/321: Constant [] -&gt; [&#39;_val_36&#39;]
    4/321: Equal [&#39;primals_14&#39;, &#39;_val_36&#39;] -&gt; [&#39;eq&#39;]
    5/321: Mul [&#39;add_7&#39;, &#39;rsqrt_2&#39;] -&gt; [&#39;mul_10&#39;]
    6/321: Mul [&#39;tangents_1&#39;, &#39;primals_3&#39;] -&gt; [&#39;mul_12&#39;]
    7/321: Constant [] -&gt; [&#39;_val_43&#39;]
    8/321: Constant [] -&gt; [&#39;_val_47&#39;]
    9/321: Constant [] -&gt; [&#39;_val_51&#39;]
    10/321: Constant [] -&gt; [&#39;_val_55&#39;]
    11/321: Slice [&#39;primals_13&#39;, &#39;_val_43&#39;, &#39;_val_47&#39;, &#39;_val_51&#39;, &#39;_val_55&#39;] -&gt; [&#39;slice_8&#39;]
    12/321: Constant [] -&gt; [&#39;_val_68&#39;]
    13/321: Constant [] -&gt; [&#39;_val_72&#39;]
    14/321: Constant [] -&gt; [&#39;_val_76&#39;]
    15/321: Constant [] -&gt; [&#39;_val_80&#39;]
    16/321: Slice [&#39;primals_12&#39;, &#39;_val_68&#39;, &#39;_val_72&#39;, &#39;_val_76&#39;, &#39;_val_80&#39;] -&gt; [&#39;slice_7&#39;]
    17/321: Constant [] -&gt; [&#39;_val_82&#39;]
    18/321: Pow [&#39;add_7&#39;, &#39;_val_82&#39;] -&gt; [&#39;pow_5&#39;]
    19/321: Constant [] -&gt; [&#39;aten_view_174_size_0&#39;]
    20/321: Reshape [&#39;mm_4&#39;, &#39;aten_view_174_size_0&#39;] -&gt; [&#39;view_20&#39;]
    21/321: Constant [] -&gt; [&#39;aten_view_176_size_0&#39;]
    22/321: Reshape [&#39;mm_5&#39;, &#39;aten_view_176_size_0&#39;] -&gt; [&#39;view_22&#39;]
    23/321: Constant [] -&gt; [&#39;aten_view_181_size_0&#39;]
    24/321: Reshape [&#39;mm_3&#39;, &#39;aten_view_181_size_0&#39;] -&gt; [&#39;view_18&#39;]
    25/321: Mul [&#39;embedding&#39;, &#39;rsqrt&#39;] -&gt; [&#39;mul&#39;]
    26/321: Constant [] -&gt; [&#39;_val_96&#39;]
    27/321: Mul [&#39;pow_9&#39;, &#39;_val_96&#39;] -&gt; [&#39;mul_45&#39;]
    28/321: Constant [] -&gt; [&#39;aten_unsqueeze_187_dim_0&#39;]
    29/321: Unsqueeze [&#39;eq&#39;, &#39;aten_unsqueeze_187_dim_0&#39;] -&gt; [&#39;unsqueeze_9&#39;]
    30/321: Mul [&#39;tangents_1&#39;, &#39;mul_10&#39;] -&gt; [&#39;mul_13&#39;]
    31/321: Mul [&#39;mul_12&#39;, &#39;add_7&#39;] -&gt; [&#39;mul_14&#39;]
    32/321: Mul [&#39;mul_12&#39;, &#39;rsqrt_2&#39;] -&gt; [&#39;mul_15&#39;]
    33/321: Constant [] -&gt; [&#39;_val_104&#39;]
    34/321: Mul [&#39;pow_5&#39;, &#39;_val_104&#39;] -&gt; [&#39;mul_18&#39;]
    35/321: Mul [&#39;view_20&#39;, &#39;sigmoid&#39;] -&gt; [&#39;mul_8&#39;]
    36/321: Constant [] -&gt; [&#39;fill&#39;]
    37/321: Constant [] -&gt; [&#39;alpha__1&#39;]
    38/321: Mul [&#39;view_18&#39;, &#39;alpha__1&#39;] -&gt; [&#39;other_1__1&#39;]
    39/321: Add [&#39;embedding&#39;, &#39;other_1__1&#39;] -&gt; [&#39;add_5&#39;]
    40/321: Constant [] -&gt; [&#39;_val_112&#39;]
    41/321: ReduceSum [&#39;mul_13&#39;, &#39;_val_112&#39;] -&gt; [&#39;sum_1&#39;]
    42/321: Constant [] -&gt; [&#39;_val_114&#39;]
    43/321: ReduceSum [&#39;mul_14&#39;, &#39;_val_114&#39;] -&gt; [&#39;sum_2&#39;]
    44/321: Transpose [&#39;slice_8&#39;] -&gt; [&#39;_val_116&#39;]
    45/321: Constant [] -&gt; [&#39;_val_122&#39;]
    46/321: GatherND [&#39;_val_116&#39;, &#39;_val_122&#39;] -&gt; [&#39;_val_123&#39;]
    47/321: Transpose [&#39;_val_123&#39;] -&gt; [&#39;index_1&#39;]
    48/321: Transpose [&#39;slice_7&#39;] -&gt; [&#39;_val_125&#39;]
    49/321: Constant [] -&gt; [&#39;_val_131&#39;]
    50/321: GatherND [&#39;_val_125&#39;, &#39;_val_131&#39;] -&gt; [&#39;_val_132&#39;]
    51/321: Transpose [&#39;_val_132&#39;] -&gt; [&#39;index&#39;]
    52/321: Constant [] -&gt; [&#39;alpha__2&#39;]
    53/321: Mul [&#39;sigmoid&#39;, &#39;alpha__2&#39;] -&gt; [&#39;other_1__2&#39;]
    54/321: Sub [&#39;fill&#39;, &#39;other_1__2&#39;] -&gt; [&#39;sub&#39;]
    55/321: Mul [&#39;add_5&#39;, &#39;rsqrt_1&#39;] -&gt; [&#39;mul_6&#39;]
    56/321: Constant [] -&gt; [&#39;_val_137&#39;]
    57/321: Pow [&#39;add_5&#39;, &#39;_val_137&#39;] -&gt; [&#39;pow_7&#39;]
    58/321: Constant [] -&gt; [&#39;aten_view_231_size_0&#39;]
    59/321: Reshape [&#39;sum_1&#39;, &#39;aten_view_231_size_0&#39;] -&gt; [&#39;view_25&#39;]
    60/321: Constant [] -&gt; [&#39;_val_143&#39;]
    61/321: Mul [&#39;sum_2&#39;, &#39;_val_143&#39;] -&gt; [&#39;mul_16&#39;]
    62/321: Constant [] -&gt; [&#39;aten_unsqueeze_234_dim_0&#39;]
    63/321: Unsqueeze [&#39;index_1&#39;, &#39;aten_unsqueeze_234_dim_0&#39;] -&gt; [&#39;unsqueeze_8&#39;]
    64/321: Constant [] -&gt; [&#39;aten_unsqueeze_235_dim_0&#39;]
    65/321: Unsqueeze [&#39;index&#39;, &#39;aten_unsqueeze_235_dim_0&#39;] -&gt; [&#39;unsqueeze_7&#39;]
    66/321: Mul [&#39;view_20&#39;, &#39;sub&#39;] -&gt; [&#39;mul_22&#39;]
    67/321: Constant [] -&gt; [&#39;_val_149&#39;]
    68/321: Mul [&#39;pow_7&#39;, &#39;_val_149&#39;] -&gt; [&#39;mul_31&#39;]
    69/321: Constant [] -&gt; [&#39;scalar_tensor_default&#39;]
    70/321: Pow [&#39;rsqrt_2&#39;, &#39;scalar_tensor_default&#39;] -&gt; [&#39;pow_4&#39;]
    71/321: Constant [] -&gt; [&#39;aten_add_247_other_1&#39;]
    72/321: Add [&#39;mul_22&#39;, &#39;aten_add_247_other_1&#39;] -&gt; [&#39;add_10&#39;]
    73/321: Constant [] -&gt; [&#39;scalar_tensor_default_2&#39;]
    74/321: Pow [&#39;rsqrt_1&#39;, &#39;scalar_tensor_default_2&#39;] -&gt; [&#39;pow_6&#39;]
    75/321: Constant [] -&gt; [&#39;scalar_tensor_default_3&#39;]
    76/321: Pow [&#39;rsqrt&#39;, &#39;scalar_tensor_default_3&#39;] -&gt; [&#39;pow_8&#39;]
    77/321: Mul [&#39;mul_16&#39;, &#39;pow_4&#39;] -&gt; [&#39;mul_17&#39;]
    78/321: Mul [&#39;sigmoid&#39;, &#39;add_10&#39;] -&gt; [&#39;mul_23&#39;]
    79/321: Constant [] -&gt; [&#39;aten_expand_257_size_1&#39;]
    80/321: Expand [&#39;mul_17&#39;, &#39;aten_expand_257_size_1&#39;] -&gt; [&#39;expand_7&#39;]
    81/321: Constant [] -&gt; [&#39;scalar_tensor_default_4&#39;]
    82/321: Div [&#39;expand_7&#39;, &#39;scalar_tensor_default_4&#39;] -&gt; [&#39;div_1&#39;]
    83/321: Mul [&#39;div_1&#39;, &#39;mul_18&#39;] -&gt; [&#39;mul_19&#39;]
    84/321: Constant [] -&gt; [&#39;alpha__3&#39;]
    85/321: Mul [&#39;mul_19&#39;, &#39;alpha__3&#39;] -&gt; [&#39;other_1__3&#39;]
    86/321: Add [&#39;mul_15&#39;, &#39;other_1__3&#39;] -&gt; [&#39;add_9&#39;]
    87/321: Constant [] -&gt; [&#39;aten_view_264_size_0&#39;]
    88/321: Reshape [&#39;add_9&#39;, &#39;aten_view_264_size_0&#39;] -&gt; [&#39;view_26&#39;]
    89/321: Transpose [&#39;view_26&#39;] -&gt; [&#39;t_7&#39;]
    90/321: MatMul [&#39;view_26&#39;, &#39;t_9&#39;] -&gt; [&#39;mm_8&#39;]
    91/321: MatMul [&#39;t_7&#39;, &#39;view_23&#39;] -&gt; [&#39;mm_7&#39;]
    92/321: Constant [] -&gt; [&#39;aten_view_269_size_0&#39;]
    93/321: Reshape [&#39;mm_8&#39;, &#39;aten_view_269_size_0&#39;] -&gt; [&#39;view_27&#39;]
    94/321: Transpose [&#39;mm_7&#39;] -&gt; [&#39;t_8&#39;]
    95/321: Mul [&#39;view_27&#39;, &#39;mul_8&#39;] -&gt; [&#39;mul_20&#39;]
    96/321: Mul [&#39;view_27&#39;, &#39;view_22&#39;] -&gt; [&#39;mul_21&#39;]
    97/321: Transpose [&#39;t_8&#39;] -&gt; [&#39;t_10&#39;]
    98/321: Constant [] -&gt; [&#39;aten_view_275_size_0&#39;]
    99/321: Reshape [&#39;mul_20&#39;, &#39;aten_view_275_size_0&#39;] -&gt; [&#39;view_28&#39;]
    100/321: Mul [&#39;mul_21&#39;, &#39;mul_23&#39;] -&gt; [&#39;mul_24&#39;]
    101/321: Transpose [&#39;view_28&#39;] -&gt; [&#39;t_11&#39;]
    102/321: MatMul [&#39;view_28&#39;, &#39;t_13&#39;] -&gt; [&#39;mm_10&#39;]
    103/321: Constant [] -&gt; [&#39;aten_view_280_size_0&#39;]
    104/321: Reshape [&#39;mul_24&#39;, &#39;aten_view_280_size_0&#39;] -&gt; [&#39;view_30&#39;]
    105/321: MatMul [&#39;t_11&#39;, &#39;view_19&#39;] -&gt; [&#39;mm_9&#39;]
    106/321: Constant [] -&gt; [&#39;aten_view_283_size_0&#39;]
    107/321: Reshape [&#39;mm_10&#39;, &#39;aten_view_283_size_0&#39;] -&gt; [&#39;view_29&#39;]
    108/321: Transpose [&#39;view_30&#39;] -&gt; [&#39;t_15&#39;]
    109/321: MatMul [&#39;view_30&#39;, &#39;t_17&#39;] -&gt; [&#39;mm_12&#39;]
    110/321: Transpose [&#39;mm_9&#39;] -&gt; [&#39;t_12&#39;]
    111/321: MatMul [&#39;t_15&#39;, &#39;view_19&#39;] -&gt; [&#39;mm_11&#39;]
    112/321: Constant [] -&gt; [&#39;aten_view_289_size_0&#39;]
    113/321: Reshape [&#39;mm_12&#39;, &#39;aten_view_289_size_0&#39;] -&gt; [&#39;view_31&#39;]
    114/321: Transpose [&#39;t_12&#39;] -&gt; [&#39;t_14&#39;]
    115/321: Transpose [&#39;mm_11&#39;] -&gt; [&#39;t_16&#39;]
    116/321: Constant [] -&gt; [&#39;alpha__4&#39;]
    117/321: Mul [&#39;view_31&#39;, &#39;alpha__4&#39;] -&gt; [&#39;other_1__4&#39;]
    118/321: Add [&#39;view_29&#39;, &#39;other_1__4&#39;] -&gt; [&#39;add_11&#39;]
    119/321: Transpose [&#39;t_16&#39;] -&gt; [&#39;t_18&#39;]
    120/321: Mul [&#39;add_11&#39;, &#39;primals_2&#39;] -&gt; [&#39;mul_25&#39;]
    121/321: Mul [&#39;add_11&#39;, &#39;mul_6&#39;] -&gt; [&#39;mul_26&#39;]
    122/321: Mul [&#39;mul_25&#39;, &#39;add_5&#39;] -&gt; [&#39;mul_27&#39;]
    123/321: Mul [&#39;mul_25&#39;, &#39;rsqrt_1&#39;] -&gt; [&#39;mul_28&#39;]
    124/321: Constant [] -&gt; [&#39;_val_209&#39;]
    125/321: ReduceSum [&#39;mul_26&#39;, &#39;_val_209&#39;] -&gt; [&#39;sum_3&#39;]
    126/321: Constant [] -&gt; [&#39;_val_211&#39;]
    127/321: ReduceSum [&#39;mul_27&#39;, &#39;_val_211&#39;] -&gt; [&#39;sum_4&#39;]
    128/321: Constant [] -&gt; [&#39;alpha__5&#39;]
    129/321: Mul [&#39;mul_28&#39;, &#39;alpha__5&#39;] -&gt; [&#39;other_1__5&#39;]
    130/321: Add [&#39;add_9&#39;, &#39;other_1__5&#39;] -&gt; [&#39;add_12&#39;]
    131/321: Constant [] -&gt; [&#39;aten_view_304_size_0&#39;]
    132/321: Reshape [&#39;sum_3&#39;, &#39;aten_view_304_size_0&#39;] -&gt; [&#39;view_32&#39;]
    133/321: Constant [] -&gt; [&#39;_val_216&#39;]
    134/321: Mul [&#39;sum_4&#39;, &#39;_val_216&#39;] -&gt; [&#39;mul_29&#39;]
    135/321: Mul [&#39;mul_29&#39;, &#39;pow_6&#39;] -&gt; [&#39;mul_30&#39;]
    136/321: Constant [] -&gt; [&#39;aten_expand_309_size_1&#39;]
    137/321: Expand [&#39;mul_30&#39;, &#39;aten_expand_309_size_1&#39;] -&gt; [&#39;expand_8&#39;]
    138/321: Constant [] -&gt; [&#39;scalar_tensor_default_5&#39;]
    139/321: Div [&#39;expand_8&#39;, &#39;scalar_tensor_default_5&#39;] -&gt; [&#39;div_2&#39;]
    140/321: Mul [&#39;div_2&#39;, &#39;mul_31&#39;] -&gt; [&#39;mul_32&#39;]
    141/321: Constant [] -&gt; [&#39;alpha__6&#39;]
    142/321: Mul [&#39;mul_32&#39;, &#39;alpha__6&#39;] -&gt; [&#39;other_1__6&#39;]
    143/321: Add [&#39;add_12&#39;, &#39;other_1__6&#39;] -&gt; [&#39;add_13&#39;]
    144/321: Constant [] -&gt; [&#39;aten_view_316_size_0&#39;]
    145/321: Reshape [&#39;add_13&#39;, &#39;aten_view_316_size_0&#39;] -&gt; [&#39;view_33&#39;]
    146/321: Transpose [&#39;view_33&#39;] -&gt; [&#39;t_19&#39;]
    147/321: MatMul [&#39;view_33&#39;, &#39;t_21&#39;] -&gt; [&#39;mm_14&#39;]
    148/321: MatMul [&#39;t_19&#39;, &#39;view_17&#39;] -&gt; [&#39;mm_13&#39;]
    149/321: Constant [] -&gt; [&#39;aten_view_321_size_0&#39;]
    150/321: Reshape [&#39;mm_14&#39;, &#39;aten_view_321_size_0&#39;] -&gt; [&#39;view_34&#39;]
    151/321: Transpose [&#39;mm_13&#39;] -&gt; [&#39;t_20&#39;]
    152/321: Constant [] -&gt; [&#39;aten_view_324_size_0&#39;]
    153/321: Reshape [&#39;view_34&#39;, &#39;aten_view_324_size_0&#39;] -&gt; [&#39;view_35&#39;]
    154/321: Transpose [&#39;t_20&#39;] -&gt; [&#39;t_22&#39;]
    155/321: Transpose [&#39;view_35&#39;] -&gt; [&#39;transpose_5&#39;]
    156/321: Constant [] -&gt; [&#39;aten_view_329_size_0&#39;]
    157/321: Reshape [&#39;transpose_5&#39;, &#39;aten_view_329_size_0&#39;] -&gt; [&#39;view_36&#39;]
    158/321: MatMul [&#39;transpose_6&#39;, &#39;view_36&#39;] -&gt; [&#39;bmm_2&#39;]
    159/321: MatMul [&#39;view_36&#39;, &#39;transpose_7&#39;] -&gt; [&#39;bmm_3&#39;]
    160/321: Constant [] -&gt; [&#39;aten_view_333_size_0&#39;]
    161/321: Reshape [&#39;bmm_2&#39;, &#39;aten_view_333_size_0&#39;] -&gt; [&#39;view_37&#39;]
    162/321: Constant [] -&gt; [&#39;aten_view_335_size_0&#39;]
    163/321: Reshape [&#39;bmm_3&#39;, &#39;aten_view_335_size_0&#39;] -&gt; [&#39;view_38&#39;]
    164/321: Constant [] -&gt; [&#39;alpha__7&#39;]
    165/321: Mul [&#39;view_37&#39;, &#39;alpha__7&#39;] -&gt; [&#39;other_1__7&#39;]
    166/321: Add [&#39;tangents_3&#39;, &#39;other_1__7&#39;] -&gt; [&#39;add_14&#39;]
    167/321: Mul [&#39;view_38&#39;, &#39;detach_13&#39;] -&gt; [&#39;mul_33&#39;]
    168/321: Transpose [&#39;add_14&#39;] -&gt; [&#39;transpose_11&#39;]
    169/321: Constant [] -&gt; [&#39;_val_250&#39;]
    170/321: ReduceSum [&#39;mul_33&#39;, &#39;_val_250&#39;] -&gt; [&#39;sum_5&#39;]
    171/321: Mul [&#39;detach_13&#39;, &#39;sum_5&#39;] -&gt; [&#39;mul_34&#39;]
    172/321: Constant [] -&gt; [&#39;aten_view_344_size_0&#39;]
    173/321: Reshape [&#39;transpose_11&#39;, &#39;aten_view_344_size_0&#39;] -&gt; [&#39;view_42&#39;]
    174/321: Constant [] -&gt; [&#39;alpha__8&#39;]
    175/321: Mul [&#39;mul_34&#39;, &#39;alpha__8&#39;] -&gt; [&#39;other_1__8&#39;]
    176/321: Sub [&#39;mul_33&#39;, &#39;other_1__8&#39;] -&gt; [&#39;sub_1&#39;]
    177/321: Constant [] -&gt; [&#39;aten_view_347_size_0&#39;]
    178/321: Reshape [&#39;view_42&#39;, &#39;aten_view_347_size_0&#39;] -&gt; [&#39;view_45&#39;]
    179/321: Constant [] -&gt; [&#39;_val_259&#39;]
    180/321: Div [&#39;sub_1&#39;, &#39;_val_259&#39;] -&gt; [&#39;div_3&#39;]
    181/321: Transpose [&#39;view_45&#39;] -&gt; [&#39;t_23&#39;]
    182/321: MatMul [&#39;view_45&#39;, &#39;t_25&#39;] -&gt; [&#39;mm_16&#39;]
    183/321: Constant [] -&gt; [&#39;aten_view_353_size_0&#39;]
    184/321: Reshape [&#39;div_3&#39;, &#39;aten_view_353_size_0&#39;] -&gt; [&#39;view_39&#39;]
    185/321: MatMul [&#39;t_23&#39;, &#39;view_1&#39;] -&gt; [&#39;mm_15&#39;]
    186/321: Constant [] -&gt; [&#39;aten_view_356_size_0&#39;]
    187/321: Reshape [&#39;mm_16&#39;, &#39;aten_view_356_size_0&#39;] -&gt; [&#39;view_46&#39;]
    188/321: MatMul [&#39;transpose_8&#39;, &#39;view_39&#39;] -&gt; [&#39;bmm_4&#39;]
    189/321: MatMul [&#39;view_39&#39;, &#39;transpose_9&#39;] -&gt; [&#39;bmm_5&#39;]
    190/321: Transpose [&#39;mm_15&#39;] -&gt; [&#39;t_24&#39;]
    191/321: Constant [] -&gt; [&#39;aten_view_361_size_0&#39;]
    192/321: Reshape [&#39;bmm_4&#39;, &#39;aten_view_361_size_0&#39;] -&gt; [&#39;view_40&#39;]
    193/321: Constant [] -&gt; [&#39;aten_view_363_size_0&#39;]
    194/321: Reshape [&#39;bmm_5&#39;, &#39;aten_view_363_size_0&#39;] -&gt; [&#39;view_41&#39;]
    195/321: Transpose [&#39;t_24&#39;] -&gt; [&#39;t_26&#39;]
    196/321: Transpose [&#39;view_40&#39;] -&gt; [&#39;transpose_10&#39;]
    197/321: Mul [&#39;view_41&#39;, &#39;unsqueeze_8&#39;] -&gt; [&#39;mul_37&#39;]
    198/321: Mul [&#39;view_41&#39;, &#39;unsqueeze_7&#39;] -&gt; [&#39;mul_38&#39;]
    199/321: Constant [] -&gt; [&#39;alpha__9&#39;]
    200/321: Mul [&#39;transpose_10&#39;, &#39;alpha__9&#39;] -&gt; [&#39;other_1__9&#39;]
    201/321: Add [&#39;tangents_2&#39;, &#39;other_1__9&#39;] -&gt; [&#39;add_15&#39;]
    202/321: Constant [] -&gt; [&#39;_val_283&#39;]
    203/321: Constant [] -&gt; [&#39;_val_287&#39;]
    204/321: Constant [] -&gt; [&#39;_val_291&#39;]
    205/321: Constant [] -&gt; [&#39;_val_295&#39;]
    206/321: Slice [&#39;mul_37&#39;, &#39;_val_283&#39;, &#39;_val_287&#39;, &#39;_val_291&#39;, &#39;_val_295&#39;] -&gt; [&#39;slice_15&#39;]
    207/321: Constant [] -&gt; [&#39;_val_300&#39;]
    208/321: Constant [] -&gt; [&#39;_val_304&#39;]
    209/321: Constant [] -&gt; [&#39;_val_308&#39;]
    210/321: Constant [] -&gt; [&#39;_val_312&#39;]
    211/321: Slice [&#39;mul_37&#39;, &#39;_val_300&#39;, &#39;_val_304&#39;, &#39;_val_308&#39;, &#39;_val_312&#39;] -&gt; [&#39;slice_16&#39;]
    212/321: Mul [&#39;add_15&#39;, &#39;unsqueeze_8&#39;] -&gt; [&#39;mul_35&#39;]
    213/321: Mul [&#39;add_15&#39;, &#39;unsqueeze_7&#39;] -&gt; [&#39;mul_36&#39;]
    214/321: Neg [&#39;slice_15&#39;] -&gt; [&#39;neg_3&#39;]
    215/321: Constant [] -&gt; [&#39;_val_322&#39;]
    216/321: Constant [] -&gt; [&#39;_val_326&#39;]
    217/321: Constant [] -&gt; [&#39;_val_330&#39;]
    218/321: Constant [] -&gt; [&#39;_val_334&#39;]
    219/321: Slice [&#39;mul_35&#39;, &#39;_val_322&#39;, &#39;_val_326&#39;, &#39;_val_330&#39;, &#39;_val_334&#39;] -&gt; [&#39;slice_13&#39;]
    220/321: Constant [] -&gt; [&#39;_val_339&#39;]
    221/321: Constant [] -&gt; [&#39;_val_343&#39;]
    222/321: Constant [] -&gt; [&#39;_val_347&#39;]
    223/321: Constant [] -&gt; [&#39;_val_351&#39;]
    224/321: Slice [&#39;mul_35&#39;, &#39;_val_339&#39;, &#39;_val_343&#39;, &#39;_val_347&#39;, &#39;_val_351&#39;] -&gt; [&#39;slice_14&#39;]
    225/321: Constant [] -&gt; [&#39;_val_370&#39;]
    226/321: Transpose [&#39;slice_16&#39;] -&gt; [&#39;_val_371&#39;]
    227/321: Constant [] -&gt; [&#39;_val_372&#39;]
    228/321: ScatterND [&#39;_val_372&#39;, &#39;_val_370&#39;, &#39;_val_371&#39;] -&gt; [&#39;_val_373&#39;]
    229/321: Transpose [&#39;_val_373&#39;] -&gt; [&#39;slice_scatter_3&#39;]
    230/321: Neg [&#39;slice_13&#39;] -&gt; [&#39;neg_2&#39;]
    231/321: Constant [] -&gt; [&#39;_val_393&#39;]
    232/321: Transpose [&#39;neg_3&#39;] -&gt; [&#39;_val_394&#39;]
    233/321: Constant [] -&gt; [&#39;_val_395&#39;]
    234/321: ScatterND [&#39;_val_395&#39;, &#39;_val_393&#39;, &#39;_val_394&#39;] -&gt; [&#39;_val_396&#39;]
    235/321: Transpose [&#39;_val_396&#39;] -&gt; [&#39;slice_scatter_2&#39;]
    236/321: Constant [] -&gt; [&#39;_val_415&#39;]
    237/321: Transpose [&#39;slice_14&#39;] -&gt; [&#39;_val_416&#39;]
    238/321: Constant [] -&gt; [&#39;_val_417&#39;]
    239/321: ScatterND [&#39;_val_417&#39;, &#39;_val_415&#39;, &#39;_val_416&#39;] -&gt; [&#39;_val_418&#39;]
    240/321: Transpose [&#39;_val_418&#39;] -&gt; [&#39;slice_scatter_1&#39;]
    241/321: Constant [] -&gt; [&#39;alpha__10&#39;]
    242/321: Mul [&#39;slice_scatter_3&#39;, &#39;alpha__10&#39;] -&gt; [&#39;other_1__10&#39;]
    243/321: Add [&#39;slice_scatter_2&#39;, &#39;other_1__10&#39;] -&gt; [&#39;add_18&#39;]
    244/321: Constant [] -&gt; [&#39;_val_436&#39;]
    245/321: Transpose [&#39;neg_2&#39;] -&gt; [&#39;_val_437&#39;]
    246/321: Constant [] -&gt; [&#39;_val_438&#39;]
    247/321: ScatterND [&#39;_val_438&#39;, &#39;_val_436&#39;, &#39;_val_437&#39;] -&gt; [&#39;_val_439&#39;]
    248/321: Transpose [&#39;_val_439&#39;] -&gt; [&#39;slice_scatter&#39;]
    249/321: Constant [] -&gt; [&#39;alpha__11&#39;]
    250/321: Mul [&#39;mul_38&#39;, &#39;alpha__11&#39;] -&gt; [&#39;other_1__11&#39;]
    251/321: Add [&#39;add_18&#39;, &#39;other_1__11&#39;] -&gt; [&#39;add_19&#39;]
    252/321: Constant [] -&gt; [&#39;alpha__12&#39;]
    253/321: Mul [&#39;slice_scatter_1&#39;, &#39;alpha__12&#39;] -&gt; [&#39;other_1__12&#39;]
    254/321: Add [&#39;slice_scatter&#39;, &#39;other_1__12&#39;] -&gt; [&#39;add_16&#39;]
    255/321: Transpose [&#39;add_19&#39;] -&gt; [&#39;transpose_13&#39;]
    256/321: Constant [] -&gt; [&#39;alpha__13&#39;]
    257/321: Mul [&#39;mul_36&#39;, &#39;alpha__13&#39;] -&gt; [&#39;other_1__13&#39;]
    258/321: Add [&#39;add_16&#39;, &#39;other_1__13&#39;] -&gt; [&#39;add_17&#39;]
    259/321: Transpose [&#39;add_17&#39;] -&gt; [&#39;transpose_12&#39;]
    260/321: Constant [] -&gt; [&#39;aten_view_537_size_0&#39;]
    261/321: Reshape [&#39;transpose_13&#39;, &#39;aten_view_537_size_0&#39;] -&gt; [&#39;view_44&#39;]
    262/321: Constant [] -&gt; [&#39;aten_view_540_size_0&#39;]
    263/321: Reshape [&#39;view_44&#39;, &#39;aten_view_540_size_0&#39;] -&gt; [&#39;view_49&#39;]
    264/321: Constant [] -&gt; [&#39;aten_view_542_size_0&#39;]
    265/321: Reshape [&#39;transpose_12&#39;, &#39;aten_view_542_size_0&#39;] -&gt; [&#39;view_43&#39;]
    266/321: Transpose [&#39;view_49&#39;] -&gt; [&#39;t_31&#39;]
    267/321: MatMul [&#39;view_49&#39;, &#39;t_33&#39;] -&gt; [&#39;mm_20&#39;]
    268/321: Constant [] -&gt; [&#39;aten_view_546_size_0&#39;]
    269/321: Reshape [&#39;view_43&#39;, &#39;aten_view_546_size_0&#39;] -&gt; [&#39;view_47&#39;]
    270/321: MatMul [&#39;t_31&#39;, &#39;view_1&#39;] -&gt; [&#39;mm_19&#39;]
    271/321: Constant [] -&gt; [&#39;aten_view_549_size_0&#39;]
    272/321: Reshape [&#39;mm_20&#39;, &#39;aten_view_549_size_0&#39;] -&gt; [&#39;view_50&#39;]
    273/321: Transpose [&#39;view_47&#39;] -&gt; [&#39;t_27&#39;]
    274/321: MatMul [&#39;view_47&#39;, &#39;t_29&#39;] -&gt; [&#39;mm_18&#39;]
    275/321: Transpose [&#39;mm_19&#39;] -&gt; [&#39;t_32&#39;]
    276/321: MatMul [&#39;t_27&#39;, &#39;view_1&#39;] -&gt; [&#39;mm_17&#39;]
    277/321: Constant [] -&gt; [&#39;aten_view_555_size_0&#39;]
    278/321: Reshape [&#39;mm_18&#39;, &#39;aten_view_555_size_0&#39;] -&gt; [&#39;view_48&#39;]
    279/321: Transpose [&#39;t_32&#39;] -&gt; [&#39;t_34&#39;]
    280/321: Transpose [&#39;mm_17&#39;] -&gt; [&#39;t_28&#39;]
    281/321: Constant [] -&gt; [&#39;alpha__14&#39;]
    282/321: Mul [&#39;view_48&#39;, &#39;alpha__14&#39;] -&gt; [&#39;other_1__14&#39;]
    283/321: Add [&#39;view_46&#39;, &#39;other_1__14&#39;] -&gt; [&#39;add_20&#39;]
    284/321: Transpose [&#39;t_28&#39;] -&gt; [&#39;t_30&#39;]
    285/321: Constant [] -&gt; [&#39;alpha__15&#39;]
    286/321: Mul [&#39;view_50&#39;, &#39;alpha__15&#39;] -&gt; [&#39;other_1__15&#39;]
    287/321: Add [&#39;add_20&#39;, &#39;other_1__15&#39;] -&gt; [&#39;add_21&#39;]
    288/321: Mul [&#39;add_21&#39;, &#39;primals_1&#39;] -&gt; [&#39;mul_39&#39;]
    289/321: Mul [&#39;add_21&#39;, &#39;mul&#39;] -&gt; [&#39;mul_40&#39;]
    290/321: Mul [&#39;mul_39&#39;, &#39;embedding&#39;] -&gt; [&#39;mul_41&#39;]
    291/321: Mul [&#39;mul_39&#39;, &#39;rsqrt&#39;] -&gt; [&#39;mul_42&#39;]
    292/321: Constant [] -&gt; [&#39;_val_476&#39;]
    293/321: ReduceSum [&#39;mul_40&#39;, &#39;_val_476&#39;] -&gt; [&#39;sum_6&#39;]
    294/321: Constant [] -&gt; [&#39;_val_478&#39;]
    295/321: ReduceSum [&#39;mul_41&#39;, &#39;_val_478&#39;] -&gt; [&#39;sum_7&#39;]
    296/321: Constant [] -&gt; [&#39;alpha__16&#39;]
    297/321: Mul [&#39;mul_42&#39;, &#39;alpha__16&#39;] -&gt; [&#39;other_1__16&#39;]
    298/321: Add [&#39;add_13&#39;, &#39;other_1__16&#39;] -&gt; [&#39;add_22&#39;]
    299/321: Constant [] -&gt; [&#39;aten_view_571_size_0&#39;]
    300/321: Reshape [&#39;sum_6&#39;, &#39;aten_view_571_size_0&#39;] -&gt; [&#39;view_51&#39;]
    301/321: Constant [] -&gt; [&#39;_val_483&#39;]
    302/321: Mul [&#39;sum_7&#39;, &#39;_val_483&#39;] -&gt; [&#39;mul_43&#39;]
    303/321: Mul [&#39;mul_43&#39;, &#39;pow_8&#39;] -&gt; [&#39;mul_44&#39;]
    304/321: Constant [] -&gt; [&#39;aten_expand_576_size_1&#39;]
    305/321: Expand [&#39;mul_44&#39;, &#39;aten_expand_576_size_1&#39;] -&gt; [&#39;expand_9&#39;]
    306/321: Constant [] -&gt; [&#39;scalar_tensor_default_6&#39;]
    307/321: Div [&#39;expand_9&#39;, &#39;scalar_tensor_default_6&#39;] -&gt; [&#39;div_4&#39;]
    308/321: Mul [&#39;div_4&#39;, &#39;mul_45&#39;] -&gt; [&#39;mul_46&#39;]
    309/321: Constant [] -&gt; [&#39;alpha__17&#39;]
    310/321: Mul [&#39;mul_46&#39;, &#39;alpha__17&#39;] -&gt; [&#39;other_1__17&#39;]
    311/321: Add [&#39;add_22&#39;, &#39;other_1__17&#39;] -&gt; [&#39;add_23&#39;]
    312/321: Constant [] -&gt; [&#39;aten_masked_fill_583_value_cast&#39;]
    313/321: Where [&#39;unsqueeze_9&#39;, &#39;aten_masked_fill_583_value_cast&#39;, &#39;add_23&#39;] -&gt; [&#39;masked_fill_3&#39;]
    314/321: Constant [] -&gt; [&#39;_val_495&#39;]
    315/321: ConstantOfShape [&#39;_val_495&#39;] -&gt; [&#39;aten_new_zeros_585_result&#39;]
    316/321: SequenceConstruct [&#39;primals_14&#39;] -&gt; [&#39;497&#39;]
    317/321: Constant [] -&gt; [&#39;int64_0__18&#39;]
    318/321: SequenceAt [&#39;497&#39;, &#39;int64_0__18&#39;] -&gt; [&#39;index__18&#39;]
    319/321: Constant [] -&gt; [&#39;int64_m1_1d__18&#39;]
    320/321: Unsqueeze [&#39;index__18&#39;, &#39;int64_m1_1d__18&#39;] -&gt; [&#39;new_index__18&#39;]
    321/321: ScatterND [&#39;aten_new_zeros_585_result&#39;, &#39;new_index__18&#39;, &#39;masked_fill_3&#39;] -&gt; [&#39;_unsafe_index_put&#39;]
    
    NODES in {name!r}
    1/235: Transpose [&#39;primals_8&#39;] -&gt; [&#39;t_3&#39;]
    2/235: Transpose [&#39;primals_9&#39;] -&gt; [&#39;t_4&#39;]
    3/235: Gather [&#39;primals_4&#39;, &#39;primals_14&#39;] -&gt; [&#39;embedding&#39;]
    4/235: Constant [] -&gt; [&#39;_val_25&#39;]
    5/235: Constant [] -&gt; [&#39;_val_26&#39;]
    6/235: Constant [] -&gt; [&#39;size_0__1&#39;]
    7/235: Constant [] -&gt; [&#39;fill_value_1__1&#39;]
    8/235: Expand [&#39;fill_value_1__1&#39;, &#39;size_0__1&#39;] -&gt; [&#39;full&#39;]
    9/235: Transpose [&#39;primals_10&#39;] -&gt; [&#39;t_5&#39;]
    10/235: Constant [] -&gt; [&#39;_val_40&#39;]
    11/235: Constant [] -&gt; [&#39;_val_44&#39;]
    12/235: Constant [] -&gt; [&#39;_val_48&#39;]
    13/235: Constant [] -&gt; [&#39;_val_52&#39;]
    14/235: Slice [&#39;primals_15&#39;, &#39;_val_40&#39;, &#39;_val_44&#39;, &#39;_val_48&#39;, &#39;_val_52&#39;] -&gt; [&#39;slice_3&#39;]
    15/235: Transpose [&#39;primals_11&#39;] -&gt; [&#39;t_6&#39;]
    16/235: Transpose [&#39;primals_5&#39;] -&gt; [&#39;t&#39;]
    17/235: Transpose [&#39;primals_6&#39;] -&gt; [&#39;t_1&#39;]
    18/235: Transpose [&#39;primals_7&#39;] -&gt; [&#39;t_2&#39;]
    19/235: Constant [] -&gt; [&#39;_val_61&#39;]
    20/235: Constant [] -&gt; [&#39;_val_65&#39;]
    21/235: Constant [] -&gt; [&#39;_val_69&#39;]
    22/235: Constant [] -&gt; [&#39;_val_73&#39;]
    23/235: Slice [&#39;primals_12&#39;, &#39;_val_61&#39;, &#39;_val_65&#39;, &#39;_val_69&#39;, &#39;_val_73&#39;] -&gt; [&#39;slice_7&#39;]
    24/235: Constant [] -&gt; [&#39;_val_78&#39;]
    25/235: Constant [] -&gt; [&#39;_val_82&#39;]
    26/235: Constant [] -&gt; [&#39;_val_86&#39;]
    27/235: Constant [] -&gt; [&#39;_val_90&#39;]
    28/235: Slice [&#39;primals_13&#39;, &#39;_val_78&#39;, &#39;_val_82&#39;, &#39;_val_86&#39;, &#39;_val_90&#39;] -&gt; [&#39;slice_8&#39;]
    29/235: Transpose [&#39;t_3&#39;] -&gt; [&#39;t_21&#39;]
    30/235: Transpose [&#39;t_4&#39;] -&gt; [&#39;t_17&#39;]
    31/235: Constant [] -&gt; [&#39;scalar_tensor_default&#39;]
    32/235: Pow [&#39;embedding&#39;, &#39;scalar_tensor_default&#39;] -&gt; [&#39;pow_1&#39;]
    33/235: Transpose [&#39;t_5&#39;] -&gt; [&#39;t_13&#39;]
    34/235: Constant [] -&gt; [&#39;aten_unsqueeze_181_dim_0&#39;]
    35/235: Unsqueeze [&#39;slice_3&#39;, &#39;aten_unsqueeze_181_dim_0&#39;] -&gt; [&#39;unsqueeze_3&#39;]
    36/235: Transpose [&#39;t_6&#39;] -&gt; [&#39;t_9&#39;]
    37/235: Transpose [&#39;t&#39;] -&gt; [&#39;t_33&#39;]
    38/235: Transpose [&#39;t_1&#39;] -&gt; [&#39;t_29&#39;]
    39/235: Transpose [&#39;t_2&#39;] -&gt; [&#39;t_25&#39;]
    40/235: Transpose [&#39;slice_7&#39;] -&gt; [&#39;_val_106&#39;]
    41/235: Constant [] -&gt; [&#39;_val_112&#39;]
    42/235: GatherND [&#39;_val_106&#39;, &#39;_val_112&#39;] -&gt; [&#39;_val_113&#39;]
    43/235: Transpose [&#39;_val_113&#39;] -&gt; [&#39;index&#39;]
    44/235: Transpose [&#39;slice_8&#39;] -&gt; [&#39;_val_115&#39;]
    45/235: Constant [] -&gt; [&#39;_val_121&#39;]
    46/235: GatherND [&#39;_val_115&#39;, &#39;_val_121&#39;] -&gt; [&#39;_val_122&#39;]
    47/235: Transpose [&#39;_val_122&#39;] -&gt; [&#39;index_1&#39;]
    48/235: Constant [] -&gt; [&#39;_val_124&#39;]
    49/235: ReduceMean [&#39;pow_1&#39;, &#39;_val_124&#39;] -&gt; [&#39;mean&#39;]
    50/235: Constant [] -&gt; [&#39;aten_unsqueeze_208_dim_0&#39;]
    51/235: Unsqueeze [&#39;unsqueeze_3&#39;, &#39;aten_unsqueeze_208_dim_0&#39;] -&gt; [&#39;unsqueeze_4&#39;]
    52/235: Constant [] -&gt; [&#39;aten_unsqueeze_209_dim_0&#39;]
    53/235: Unsqueeze [&#39;index&#39;, &#39;aten_unsqueeze_209_dim_0&#39;] -&gt; [&#39;unsqueeze_7&#39;]
    54/235: Constant [] -&gt; [&#39;aten_unsqueeze_210_dim_0&#39;]
    55/235: Unsqueeze [&#39;index_1&#39;, &#39;aten_unsqueeze_210_dim_0&#39;] -&gt; [&#39;unsqueeze_8&#39;]
    56/235: Constant [] -&gt; [&#39;aten_add_212_other_1&#39;]
    57/235: Add [&#39;mean&#39;, &#39;aten_add_212_other_1&#39;] -&gt; [&#39;add_1&#39;]
    58/235: Constant [] -&gt; [&#39;lt&#39;]
    59/235: Constant [] -&gt; [&#39;_val_137&#39;]
    60/235: Constant [] -&gt; [&#39;_val_141&#39;]
    61/235: Constant [] -&gt; [&#39;_val_145&#39;]
    62/235: Constant [] -&gt; [&#39;_val_149&#39;]
    63/235: Slice [&#39;unsqueeze_4&#39;, &#39;_val_137&#39;, &#39;_val_141&#39;, &#39;_val_145&#39;, &#39;_val_149&#39;] -&gt; [&#39;slice_4&#39;]
    64/235: Sqrt [&#39;add_1&#39;] -&gt; [&#39;aten_rsqrt_231_tmp&#39;]
    65/235: Reciprocal [&#39;aten_rsqrt_231_tmp&#39;] -&gt; [&#39;rsqrt&#39;]
    66/235: Constant [] -&gt; [&#39;aten_masked_fill_233_value_cast&#39;]
    67/235: Where [&#39;lt&#39;, &#39;aten_masked_fill_233_value_cast&#39;, &#39;full&#39;] -&gt; [&#39;masked_fill&#39;]
    68/235: Constant [] -&gt; [&#39;aten_expand_235_size_1&#39;]
    69/235: Expand [&#39;slice_4&#39;, &#39;aten_expand_235_size_1&#39;] -&gt; [&#39;expand_1&#39;]
    70/235: Mul [&#39;embedding&#39;, &#39;rsqrt&#39;] -&gt; [&#39;mul&#39;]
    71/235: Constant [] -&gt; [&#39;aten_unsqueeze_237_dim_0&#39;]
    72/235: Unsqueeze [&#39;masked_fill&#39;, &#39;aten_unsqueeze_237_dim_0&#39;] -&gt; [&#39;unsqueeze_5&#39;]
    73/235: Constant [] -&gt; [&#39;_val_158&#39;]
    74/235: Constant [] -&gt; [&#39;alpha__2&#39;]
    75/235: Mul [&#39;expand_1&#39;, &#39;alpha__2&#39;] -&gt; [&#39;tmp__2&#39;]
    76/235: Sub [&#39;_val_158&#39;, &#39;tmp__2&#39;] -&gt; [&#39;rsub&#39;]
    77/235: Mul [&#39;primals_1&#39;, &#39;mul&#39;] -&gt; [&#39;mul_1&#39;]
    78/235: Constant [] -&gt; [&#39;aten_unsqueeze_241_dim_0&#39;]
    79/235: Unsqueeze [&#39;unsqueeze_5&#39;, &#39;aten_unsqueeze_241_dim_0&#39;] -&gt; [&#39;unsqueeze_6&#39;]
    80/235: Cast [&#39;rsub&#39;] -&gt; [&#39;_to_copy&#39;]
    81/235: Constant [] -&gt; [&#39;aten_view_244_size_0&#39;]
    82/235: Reshape [&#39;mul_1&#39;, &#39;aten_view_244_size_0&#39;] -&gt; [&#39;view_1&#39;]
    83/235: Constant [] -&gt; [&#39;_val_168&#39;]
    84/235: Constant [] -&gt; [&#39;_val_172&#39;]
    85/235: Constant [] -&gt; [&#39;_val_176&#39;]
    86/235: Constant [] -&gt; [&#39;_val_180&#39;]
    87/235: Slice [&#39;unsqueeze_6&#39;, &#39;_val_168&#39;, &#39;_val_172&#39;, &#39;_val_176&#39;, &#39;_val_180&#39;] -&gt; [&#39;slice_5&#39;]
    88/235: Constant [] -&gt; [&#39;_val_182&#39;]
    89/235: Where [&#39;_to_copy&#39;, &#39;_val_182&#39;, &#39;rsub&#39;] -&gt; [&#39;masked_fill_1&#39;]
    90/235: MatMul [&#39;view_1&#39;, &#39;t&#39;] -&gt; [&#39;mm&#39;]
    91/235: MatMul [&#39;view_1&#39;, &#39;t_1&#39;] -&gt; [&#39;mm_1&#39;]
    92/235: MatMul [&#39;view_1&#39;, &#39;t_2&#39;] -&gt; [&#39;mm_2&#39;]
    93/235: Constant [] -&gt; [&#39;_val_190&#39;]
    94/235: Constant [] -&gt; [&#39;_val_194&#39;]
    95/235: Constant [] -&gt; [&#39;_val_198&#39;]
    96/235: Constant [] -&gt; [&#39;_val_202&#39;]
    97/235: Slice [&#39;slice_5&#39;, &#39;_val_190&#39;, &#39;_val_194&#39;, &#39;_val_198&#39;, &#39;_val_202&#39;] -&gt; [&#39;slice_6&#39;]
    98/235: Cast [&#39;masked_fill_1&#39;] -&gt; [&#39;_to_copy_1&#39;]
    99/235: Constant [] -&gt; [&#39;aten_view_286_size_0&#39;]
    100/235: Reshape [&#39;mm&#39;, &#39;aten_view_286_size_0&#39;] -&gt; [&#39;view_2&#39;]
    101/235: Constant [] -&gt; [&#39;aten_view_288_size_0&#39;]
    102/235: Reshape [&#39;mm_1&#39;, &#39;aten_view_288_size_0&#39;] -&gt; [&#39;view_4&#39;]
    103/235: Constant [] -&gt; [&#39;aten_view_290_size_0&#39;]
    104/235: Reshape [&#39;mm_2&#39;, &#39;aten_view_290_size_0&#39;] -&gt; [&#39;view_6&#39;]
    105/235: Constant [] -&gt; [&#39;aten_expand_292_size_1&#39;]
    106/235: Expand [&#39;slice_6&#39;, &#39;aten_expand_292_size_1&#39;] -&gt; [&#39;expand_2&#39;]
    107/235: Constant [] -&gt; [&#39;aten_view_294_size_0&#39;]
    108/235: Reshape [&#39;view_2&#39;, &#39;aten_view_294_size_0&#39;] -&gt; [&#39;view_7&#39;]
    109/235: Constant [] -&gt; [&#39;aten_view_296_size_0&#39;]
    110/235: Reshape [&#39;view_4&#39;, &#39;aten_view_296_size_0&#39;] -&gt; [&#39;view_8&#39;]
    111/235: Constant [] -&gt; [&#39;aten_view_298_size_0&#39;]
    112/235: Reshape [&#39;view_6&#39;, &#39;aten_view_298_size_0&#39;] -&gt; [&#39;view_9&#39;]
    113/235: Constant [] -&gt; [&#39;_val_219&#39;]
    114/235: Where [&#39;_to_copy_1&#39;, &#39;_val_219&#39;, &#39;expand_2&#39;] -&gt; [&#39;masked_fill_2&#39;]
    115/235: Transpose [&#39;view_7&#39;] -&gt; [&#39;transpose&#39;]
    116/235: Transpose [&#39;view_8&#39;] -&gt; [&#39;transpose_1&#39;]
    117/235: Transpose [&#39;view_9&#39;] -&gt; [&#39;transpose_2&#39;]
    118/235: Mul [&#39;transpose&#39;, &#39;unsqueeze_7&#39;] -&gt; [&#39;mul_2&#39;]
    119/235: Constant [] -&gt; [&#39;_val_228&#39;]
    120/235: Constant [] -&gt; [&#39;_val_232&#39;]
    121/235: Constant [] -&gt; [&#39;_val_236&#39;]
    122/235: Constant [] -&gt; [&#39;_val_240&#39;]
    123/235: Slice [&#39;transpose&#39;, &#39;_val_228&#39;, &#39;_val_232&#39;, &#39;_val_236&#39;, &#39;_val_240&#39;] -&gt; [&#39;slice_9&#39;]
    124/235: Constant [] -&gt; [&#39;_val_245&#39;]
    125/235: Constant [] -&gt; [&#39;_val_249&#39;]
    126/235: Constant [] -&gt; [&#39;_val_253&#39;]
    127/235: Constant [] -&gt; [&#39;_val_257&#39;]
    128/235: Slice [&#39;transpose&#39;, &#39;_val_245&#39;, &#39;_val_249&#39;, &#39;_val_253&#39;, &#39;_val_257&#39;] -&gt; [&#39;slice_10&#39;]
    129/235: Mul [&#39;transpose_1&#39;, &#39;unsqueeze_7&#39;] -&gt; [&#39;mul_4&#39;]
    130/235: Constant [] -&gt; [&#39;_val_263&#39;]
    131/235: Constant [] -&gt; [&#39;_val_267&#39;]
    132/235: Constant [] -&gt; [&#39;_val_271&#39;]
    133/235: Constant [] -&gt; [&#39;_val_275&#39;]
    134/235: Slice [&#39;transpose_1&#39;, &#39;_val_263&#39;, &#39;_val_267&#39;, &#39;_val_271&#39;, &#39;_val_275&#39;] -&gt; [&#39;slice_11&#39;]
    135/235: Constant [] -&gt; [&#39;_val_280&#39;]
    136/235: Constant [] -&gt; [&#39;_val_284&#39;]
    137/235: Constant [] -&gt; [&#39;_val_288&#39;]
    138/235: Constant [] -&gt; [&#39;_val_292&#39;]
    139/235: Slice [&#39;transpose_1&#39;, &#39;_val_280&#39;, &#39;_val_284&#39;, &#39;_val_288&#39;, &#39;_val_292&#39;] -&gt; [&#39;slice_12&#39;]
    140/235: Constant [] -&gt; [&#39;aten_expand_375_size_1&#39;]
    141/235: Expand [&#39;transpose_2&#39;, &#39;aten_expand_375_size_1&#39;] -&gt; [&#39;expand_6&#39;]
    142/235: Neg [&#39;slice_10&#39;] -&gt; [&#39;neg&#39;]
    143/235: Neg [&#39;slice_12&#39;] -&gt; [&#39;neg_1&#39;]
    144/235: Concat [&#39;neg&#39;, &#39;slice_9&#39;] -&gt; [&#39;cat&#39;]
    145/235: Concat [&#39;neg_1&#39;, &#39;slice_11&#39;] -&gt; [&#39;cat_1&#39;]
    146/235: Constant [] -&gt; [&#39;aten_view_384_size_0&#39;]
    147/235: Reshape [&#39;expand_6&#39;, &#39;aten_view_384_size_0&#39;] -&gt; [&#39;view_14&#39;]
    148/235: Mul [&#39;cat&#39;, &#39;unsqueeze_8&#39;] -&gt; [&#39;mul_3&#39;]
    149/235: Mul [&#39;cat_1&#39;, &#39;unsqueeze_8&#39;] -&gt; [&#39;mul_5&#39;]
    150/235: Transpose [&#39;view_14&#39;] -&gt; [&#39;transpose_7&#39;]
    151/235: Constant [] -&gt; [&#39;alpha__3&#39;]
    152/235: Mul [&#39;mul_3&#39;, &#39;alpha__3&#39;] -&gt; [&#39;other_1__3&#39;]
    153/235: Add [&#39;mul_2&#39;, &#39;other_1__3&#39;] -&gt; [&#39;add_2&#39;]
    154/235: Constant [] -&gt; [&#39;alpha__4&#39;]
    155/235: Mul [&#39;mul_5&#39;, &#39;alpha__4&#39;] -&gt; [&#39;other_1__4&#39;]
    156/235: Add [&#39;mul_4&#39;, &#39;other_1__4&#39;] -&gt; [&#39;add_3&#39;]
    157/235: Constant [] -&gt; [&#39;aten_expand_391_size_1&#39;]
    158/235: Expand [&#39;add_2&#39;, &#39;aten_expand_391_size_1&#39;] -&gt; [&#39;expand_3&#39;]
    159/235: Transpose [&#39;add_3&#39;] -&gt; [&#39;transpose_3&#39;]
    160/235: Constant [] -&gt; [&#39;aten_expand_395_size_1&#39;]
    161/235: Expand [&#39;transpose_3&#39;, &#39;aten_expand_395_size_1&#39;] -&gt; [&#39;expand_4&#39;]
    162/235: Constant [] -&gt; [&#39;aten_view_397_size_0&#39;]
    163/235: Reshape [&#39;expand_3&#39;, &#39;aten_view_397_size_0&#39;] -&gt; [&#39;view_10&#39;]
    164/235: Transpose [&#39;view_10&#39;] -&gt; [&#39;transpose_8&#39;]
    165/235: Constant [] -&gt; [&#39;aten_view_401_size_0&#39;]
    166/235: Reshape [&#39;expand_4&#39;, &#39;aten_view_401_size_0&#39;] -&gt; [&#39;view_11&#39;]
    167/235: MatMul [&#39;view_10&#39;, &#39;view_11&#39;] -&gt; [&#39;bmm&#39;]
    168/235: Transpose [&#39;view_11&#39;] -&gt; [&#39;transpose_9&#39;]
    169/235: Constant [] -&gt; [&#39;aten_view_405_size_0&#39;]
    170/235: Reshape [&#39;bmm&#39;, &#39;aten_view_405_size_0&#39;] -&gt; [&#39;view_12&#39;]
    171/235: Constant [] -&gt; [&#39;_val_326&#39;]
    172/235: Div [&#39;view_12&#39;, &#39;_val_326&#39;] -&gt; [&#39;div&#39;]
    173/235: Constant [] -&gt; [&#39;alpha__5&#39;]
    174/235: Mul [&#39;masked_fill_2&#39;, &#39;alpha__5&#39;] -&gt; [&#39;other_1__5&#39;]
    175/235: Add [&#39;div&#39;, &#39;other_1__5&#39;] -&gt; [&#39;add_4&#39;]
    176/235: Softmax [&#39;add_4&#39;] -&gt; [&#39;_softmax&#39;]
    177/235: Constant [] -&gt; [&#39;aten_expand_414_size_1&#39;]
    178/235: Expand [&#39;_softmax&#39;, &#39;aten_expand_414_size_1&#39;] -&gt; [&#39;expand_5&#39;]
    179/235: Constant [] -&gt; [&#39;aten_view_417_size_0&#39;]
    180/235: Reshape [&#39;expand_5&#39;, &#39;aten_view_417_size_0&#39;] -&gt; [&#39;view_13&#39;]
    181/235: Identity [&#39;_softmax&#39;] -&gt; [&#39;detach_13&#39;]
    182/235: MatMul [&#39;view_13&#39;, &#39;view_14&#39;] -&gt; [&#39;bmm_1&#39;]
    183/235: Transpose [&#39;view_13&#39;] -&gt; [&#39;transpose_6&#39;]
    184/235: Constant [] -&gt; [&#39;aten_view_422_size_0&#39;]
    185/235: Reshape [&#39;bmm_1&#39;, &#39;aten_view_422_size_0&#39;] -&gt; [&#39;view_15&#39;]
    186/235: Transpose [&#39;view_15&#39;] -&gt; [&#39;transpose_4&#39;]
    187/235: Constant [] -&gt; [&#39;aten_view_426_size_0&#39;]
    188/235: Reshape [&#39;transpose_4&#39;, &#39;aten_view_426_size_0&#39;] -&gt; [&#39;view_16&#39;]
    189/235: Constant [] -&gt; [&#39;aten_view_428_size_0&#39;]
    190/235: Reshape [&#39;view_16&#39;, &#39;aten_view_428_size_0&#39;] -&gt; [&#39;view_17&#39;]
    191/235: MatMul [&#39;view_17&#39;, &#39;t_3&#39;] -&gt; [&#39;mm_3&#39;]
    192/235: Constant [] -&gt; [&#39;aten_view_431_size_0&#39;]
    193/235: Reshape [&#39;mm_3&#39;, &#39;aten_view_431_size_0&#39;] -&gt; [&#39;view_18&#39;]
    194/235: Constant [] -&gt; [&#39;alpha__6&#39;]
    195/235: Mul [&#39;view_18&#39;, &#39;alpha__6&#39;] -&gt; [&#39;other_1__6&#39;]
    196/235: Add [&#39;embedding&#39;, &#39;other_1__6&#39;] -&gt; [&#39;add_5&#39;]
    197/235: Constant [] -&gt; [&#39;scalar_tensor_default_1&#39;]
    198/235: Pow [&#39;add_5&#39;, &#39;scalar_tensor_default_1&#39;] -&gt; [&#39;pow_2&#39;]
    199/235: Constant [] -&gt; [&#39;_val_356&#39;]
    200/235: ReduceMean [&#39;pow_2&#39;, &#39;_val_356&#39;] -&gt; [&#39;mean_1&#39;]
    201/235: Constant [] -&gt; [&#39;aten_add_439_other_1&#39;]
    202/235: Add [&#39;mean_1&#39;, &#39;aten_add_439_other_1&#39;] -&gt; [&#39;add_6&#39;]
    203/235: Sqrt [&#39;add_6&#39;] -&gt; [&#39;aten_rsqrt_440_tmp&#39;]
    204/235: Reciprocal [&#39;aten_rsqrt_440_tmp&#39;] -&gt; [&#39;rsqrt_1&#39;]
    205/235: Mul [&#39;add_5&#39;, &#39;rsqrt_1&#39;] -&gt; [&#39;mul_6&#39;]
    206/235: Mul [&#39;primals_2&#39;, &#39;mul_6&#39;] -&gt; [&#39;mul_7&#39;]
    207/235: Constant [] -&gt; [&#39;aten_view_444_size_0&#39;]
    208/235: Reshape [&#39;mul_7&#39;, &#39;aten_view_444_size_0&#39;] -&gt; [&#39;view_19&#39;]
    209/235: MatMul [&#39;view_19&#39;, &#39;t_4&#39;] -&gt; [&#39;mm_4&#39;]
    210/235: MatMul [&#39;view_19&#39;, &#39;t_5&#39;] -&gt; [&#39;mm_5&#39;]
    211/235: Constant [] -&gt; [&#39;aten_view_448_size_0&#39;]
    212/235: Reshape [&#39;mm_4&#39;, &#39;aten_view_448_size_0&#39;] -&gt; [&#39;view_20&#39;]
    213/235: Constant [] -&gt; [&#39;aten_view_450_size_0&#39;]
    214/235: Reshape [&#39;mm_5&#39;, &#39;aten_view_450_size_0&#39;] -&gt; [&#39;view_22&#39;]
    215/235: Sigmoid [&#39;view_20&#39;] -&gt; [&#39;sigmoid&#39;]
    216/235: Mul [&#39;view_20&#39;, &#39;sigmoid&#39;] -&gt; [&#39;mul_8&#39;]
    217/235: Mul [&#39;mul_8&#39;, &#39;view_22&#39;] -&gt; [&#39;mul_9&#39;]
    218/235: Constant [] -&gt; [&#39;aten_view_455_size_0&#39;]
    219/235: Reshape [&#39;mul_9&#39;, &#39;aten_view_455_size_0&#39;] -&gt; [&#39;view_23&#39;]
    220/235: MatMul [&#39;view_23&#39;, &#39;t_6&#39;] -&gt; [&#39;mm_6&#39;]
    221/235: Constant [] -&gt; [&#39;aten_view_458_size_0&#39;]
    222/235: Reshape [&#39;mm_6&#39;, &#39;aten_view_458_size_0&#39;] -&gt; [&#39;view_24&#39;]
    223/235: Constant [] -&gt; [&#39;alpha__7&#39;]
    224/235: Mul [&#39;view_24&#39;, &#39;alpha__7&#39;] -&gt; [&#39;other_1__7&#39;]
    225/235: Add [&#39;add_5&#39;, &#39;other_1__7&#39;] -&gt; [&#39;add_7&#39;]
    226/235: Constant [] -&gt; [&#39;scalar_tensor_default_2&#39;]
    227/235: Pow [&#39;add_7&#39;, &#39;scalar_tensor_default_2&#39;] -&gt; [&#39;pow_3&#39;]
    228/235: Constant [] -&gt; [&#39;_val_383&#39;]
    229/235: ReduceMean [&#39;pow_3&#39;, &#39;_val_383&#39;] -&gt; [&#39;mean_2&#39;]
    230/235: Constant [] -&gt; [&#39;aten_add_466_other_1&#39;]
    231/235: Add [&#39;mean_2&#39;, &#39;aten_add_466_other_1&#39;] -&gt; [&#39;add_8&#39;]
    232/235: Sqrt [&#39;add_8&#39;] -&gt; [&#39;aten_rsqrt_467_tmp&#39;]
    233/235: Reciprocal [&#39;aten_rsqrt_467_tmp&#39;] -&gt; [&#39;rsqrt_2&#39;]
    234/235: Mul [&#39;add_7&#39;, &#39;rsqrt_2&#39;] -&gt; [&#39;mul_10&#39;]
    235/235: Mul [&#39;primals_3&#39;, &#39;mul_10&#39;] -&gt; [&#39;mul_11&#39;]
    [runpythonerror]
    /home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/exporter.py:137: UserWarning: torch.onnx.dynamo_export only implements opset version 18 for now. If you need to use a different opset version, please register them with register_custom_op.
      warnings.warn(
    2024-04-30 15:23:38,506 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue return_val due to large size 4194304.
    2024-04-30 15:23:38,506 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue full due to large size 4194304.
    2024-04-30 15:23:38,599 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue masked_fill due to large size 4194304.
    2024-04-30 15:23:38,603 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue return_val due to large size 4194304.
    2024-04-30 15:23:38,603 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue unsqueeze_5 due to large size 4194304.
    2024-04-30 15:23:38,606 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue return_val due to large size 4194304.
    2024-04-30 15:23:38,606 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue unsqueeze_6 due to large size 4194304.
    2024-04-30 15:23:38,615 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue slice_5 due to large size 4194304.
    2024-04-30 15:23:38,623 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue slice_6 due to large size 4194304.
    2024-04-30 15:23:38,631 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue return_val due to large size 8388608.
    2024-04-30 15:23:38,631 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue expand_2 due to large size 8388608.
    2024-04-30 15:23:38,908 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue return_val due to large size 4194304.
    2024-04-30 15:23:38,908 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue full due to large size 4194304.
    2024-04-30 15:23:38,924 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue masked_fill due to large size 4194304.
    2024-04-30 15:23:38,925 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue unsqueeze_5 due to large size 4194304.
    2024-04-30 15:23:38,927 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue unsqueeze_6 due to large size 4194304.
    2024-04-30 15:23:38,929 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue slice_5 due to large size 4194304.
    2024-04-30 15:23:38,931 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue slice_6 due to large size 4194304.
    2024-04-30 15:23:38,938 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue expand_2 due to large size 8388608.
    [0;93m2024-04-30 15:23:39.064077900 [W:onnxruntime:, graph.cc:4051 CleanUnusedInitializersAndNodeArgs] Removing initializer &#39;_val_26&#39;. It is not used by any node and should be removed from the model.[m
    [0;93m2024-04-30 15:23:39.064167100 [W:onnxruntime:, graph.cc:4051 CleanUnusedInitializersAndNodeArgs] Removing initializer &#39;_val_25&#39;. It is not used by any node and should be removed from the model.[m
</pre></div>
</div>
</section>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="example_bug.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">A script to report a bug</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="torchtry.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Tries with Undocumented</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2023-2024
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Use the custom exporter in torch</a><ul>
<li><a class="reference internal" href="#file-onnxruntime-py">File <cite>onnxruntime.py</cite></a></li>
<li><a class="reference internal" href="#examples">Examples</a><ul>
<li><a class="reference internal" href="#baseline">Baseline</a></li>
<li><a class="reference internal" href="#with-the-custom-exporter">With the custom exporter</a></li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../_static/documentation_options.js?v=a1637f0b"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/furo.js?v=4e2eecee"></script>
    </body>
</html>