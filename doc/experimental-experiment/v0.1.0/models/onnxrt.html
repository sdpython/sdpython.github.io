<!doctype html>
<html class="no-js" lang="en" data-content_root="../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="LLaMa" href="llama.html" /><link rel="prev" title="Tries with Undocumented" href="torchtry.html" />

    <!-- Generated with Sphinx 7.2.6 and Furo 2024.01.29 -->
        <title>Use the custom exporter in torch - experimental-experiment 0.1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=135e06be" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css?v=7f9a90b1" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css?v=eafc0fe6" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=61a4c737" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=36a5483c" />
    
    


<style>
  body {
    --color-code-background: #eeffcc;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">experimental-experiment 0.1.0 documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="../_static/logo.png" alt="Logo"/>
  </div>
  
  <span class="sidebar-brand-text">experimental-experiment 0.1.0 documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Contents</span></p>
<ul class="current">
<li class="toctree-l1 has-children"><a class="reference internal" href="../tutorial/index.html">Tutorial</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of Tutorial</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../tutorial/pytorch.html">pytorch and onnx</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of pytorch and onnx</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_linreg_101.html">101: Linear Regression and export to ONNX</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_custom_backend_101.html">101: A custom backend for torch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_optimize_101.html">101: Graph Optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_convolutation_matmul_102.html">102: Convolution and Matrix Multiplication</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_llama_bench_102.html">102: Measure LLAMA speed</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_export_201.html">201: Evaluate different ways to export a torch model to ONNX</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_dort_201.html">201: Evaluate DORT</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_aot_201.html">201: Evaluate DORT Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_llama_diff_export_301.html">301: Compares LLAMA exporters</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_llama_diff_dort_301.html">301: Compares LLAMA exporters for onnxrt backend</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../tutorial/onnx.html">onnx</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of onnx</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_profile_existing_onnx_101.html">101: Profile an existing model with onnxruntime</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../tutorial/errors.html">Frequent Exceptions</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../design/index.html">Design</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of Design</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../design/exporter.html">Custom Exporter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../design/optimizer.html">Pattern Optimizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../design/backends.html">Dynamo Backends</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api/index.html">API</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of API</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../api/gradient.html">gradient</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/reference.html">reference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/graph_builder.html">graph_builder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/graph_builder_pattern.html">graph_builder_optim</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/interpreter.html">interpreter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/onnx_export.html">onnx_export</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/aten_function.html">aten_functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/aten_method.html">aten_methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/prims_function.html">aten_prims</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/convert.html">convert</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/torch_helper.html">torch_helper</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/torch_dynamo.html">torch_dynamo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/misc.html">Othersâ€¦</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/dimension.html">Dimension</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/torch_test.html">Testing</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../auto_examples/index.html">Example gallery</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle navigation of Example gallery</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_optimize_101.html">101: Graph Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_profile_existing_onnx_101.html">101: Profile an existing model with onnxruntime</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_torch_linreg_101.html">101: Linear Regression and export to ONNX</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_torch_custom_backend_101.html">101: A custom backend for torch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_convolutation_matmul_102.html">102: Convolution and Matrix Multiplication</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_llama_diff_export_301.html">301: Compares LLAMA exporters</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_llama_bench_102.html">102: Measure LLAMA speed</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_llama_diff_dort_301.html">301: Compares LLAMA exporters for onnxrt backend</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_torch_aot_201.html">201: Evaluate DORT Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_torch_dort_201.html">201: Evaluate DORT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_torch_export_201.html">201: Evaluate different ways to export a torch model to ONNX</a></li>
</ul>
</li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="index.html">Supported Models</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle navigation of Supported Models</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="torchtry.html">Tries with Undocumented</a></li>
<li class="toctree-l2 current current-page"><a class="current reference internal" href="#">Use the custom exporter in torch</a></li>
<li class="toctree-l2"><a class="reference internal" href="llama.html">LLaMa</a></li>
<li class="toctree-l2"><a class="reference internal" href="mistral.html">Mistral</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../bench/index.html">Benchmark from the command line</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle navigation of Benchmark from the command line</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../bench/dort_bench.html">experimental_experiment.torch_bench.dort_bench</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bench/dort_profile.html">experimental_experiment.torch_bench.dort_profile</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../times.html">Times</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">More</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../CHANGELOGS.html">Change Logs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
<li class="toctree-l1"><a class="reference internal" href="../long_outputs.html">Long Outputs uneasy to read</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <section id="use-the-custom-exporter-in-torch">
<h1>Use the custom exporter in torch<a class="headerlink" href="#use-the-custom-exporter-in-torch" title="Link to this heading">#</a></h1>
<p><em>Subject to change</em></p>
<section id="file-onnxruntime-py">
<h2>File <cite>onnxruntime.py</cite><a class="headerlink" href="#file-onnxruntime-py" title="Link to this heading">#</a></h2>
<p>This change enables the custom rewriter is an environment variable is enabled.
Look for substring <code class="docutils literal notranslate"><span class="pre">TODO:</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">_ort_acclerated_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph_module</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">GraphModule</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;This function replaces GraphModule._wrapped_call in compiled model.</span>

<span class="sd">    The _wrapped_call is the underlying implementation of forward method. Replacing</span>
<span class="sd">    it means we delegate the computation to _ort_acclerated_call and therefore</span>
<span class="sd">    onnxruntime.InferenceSession.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">cached_execution_info_per_session</span> <span class="o">=</span> <span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_all_ort_execution_info</span><span class="o">.</span><span class="n">search_reusable_session_execution_info</span><span class="p">(</span>
            <span class="n">graph_module</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span>
        <span class="p">)</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">cached_execution_info_per_session</span><span class="p">:</span>
        <span class="n">onnx_session</span> <span class="o">=</span> <span class="n">cached_execution_info_per_session</span><span class="o">.</span><span class="n">session</span>
        <span class="n">input_names</span> <span class="o">=</span> <span class="n">cached_execution_info_per_session</span><span class="o">.</span><span class="n">input_names</span>
        <span class="n">output_names</span> <span class="o">=</span> <span class="n">cached_execution_info_per_session</span><span class="o">.</span><span class="n">output_names</span>
        <span class="n">input_value_infos</span> <span class="o">=</span> <span class="n">cached_execution_info_per_session</span><span class="o">.</span><span class="n">input_value_infos</span>
        <span class="n">output_value_infos</span> <span class="o">=</span> <span class="n">cached_execution_info_per_session</span><span class="o">.</span><span class="n">output_value_infos</span>
        <span class="n">input_devices</span> <span class="o">=</span> <span class="n">cached_execution_info_per_session</span><span class="o">.</span><span class="n">input_devices</span>
        <span class="n">output_devices</span> <span class="o">=</span> <span class="n">cached_execution_info_per_session</span><span class="o">.</span><span class="n">output_devices</span>
        <span class="n">prim_outputs</span> <span class="o">=</span> <span class="n">cached_execution_info_per_session</span><span class="o">.</span><span class="n">example_outputs</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># It&#39;s first time seeing such as graph. Let&#39;s make a new session</span>
        <span class="c1"># (type: onnxruntime.InferenceSession) for it.</span>

        <span class="c1">##########################</span>
        <span class="c1"># TODO: Insert these lines</span>
        <span class="c1">##########################</span>

        <span class="n">use_other_rewriter</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;ONNXRT_CHANGE_REWRITER&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;1&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">use_other_rewriter</span><span class="p">:</span>
            <span class="kn">from</span> <span class="nn">experimental_experiment.torch_interpreter</span> <span class="kn">import</span> <span class="n">to_onnx</span>
            <span class="kn">from</span> <span class="nn">experimental_experiment.torch_interpreter._torch_helper</span> <span class="kn">import</span> <span class="n">create_input_names</span>
            <span class="kn">from</span> <span class="nn">experimental_experiment.xbuilder</span> <span class="kn">import</span> <span class="n">OptimizationOptions</span>
            <span class="kn">from</span> <span class="nn">experimental_experiment.torch_interpreter.oxs_dispatcher</span> <span class="kn">import</span> <span class="n">OxsDispatcher</span>

            <span class="n">input_names</span> <span class="o">=</span> <span class="n">input_names</span> <span class="o">=</span> <span class="n">create_input_names</span><span class="p">(</span><span class="n">graph_module</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span>
            <span class="n">dispatcher</span> <span class="o">=</span> <span class="n">OxsDispatcher</span><span class="p">()</span>
            <span class="n">target_opset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_resolved_onnx_exporter_options</span><span class="o">.</span><span class="n">onnx_registry</span><span class="o">.</span><span class="n">opset_version</span>
            <span class="n">options</span> <span class="o">=</span> <span class="n">OptimizationOptions</span><span class="p">(</span>
                <span class="n">remove_unused</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">constant_folding</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">patterns</span><span class="o">=</span><span class="s2">&quot;default&quot;</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">onnx_model</span><span class="p">,</span> <span class="n">builder</span> <span class="o">=</span> <span class="n">to_onnx</span><span class="p">(</span>
                <span class="n">graph_module</span><span class="p">,</span>
                <span class="nb">tuple</span><span class="p">(</span><span class="n">args</span><span class="p">),</span>
                <span class="n">input_names</span><span class="o">=</span><span class="n">input_names</span><span class="p">,</span>
                <span class="n">options</span><span class="o">=</span><span class="n">options</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">target_opset</span><span class="o">=</span><span class="n">target_opset</span><span class="p">,</span>
                <span class="n">return_builder</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dispatcher</span><span class="o">=</span><span class="n">dispatcher</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="k">def</span> <span class="nf">maybe_map_to_meta_val</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="s2">&quot;meta&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="s2">&quot;val&quot;</span> <span class="ow">in</span> <span class="n">value</span><span class="o">.</span><span class="n">meta</span><span class="p">:</span>
                    <span class="c1"># Select outputs with &quot;val&quot; information. Without &quot;val&quot;,</span>
                    <span class="c1"># it&#39;s not possible access output_arg.meta[&quot;val&quot;].device.</span>
                    <span class="k">return</span> <span class="n">value</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s2">&quot;val&quot;</span><span class="p">]</span>
                <span class="k">return</span> <span class="n">value</span>

            <span class="n">extracted_outputs</span> <span class="o">=</span> <span class="n">_extract_graph_module_outputs</span><span class="p">(</span><span class="n">graph_module</span><span class="p">)</span>
            <span class="n">prim_outputs</span> <span class="o">=</span> <span class="n">_pytree</span><span class="o">.</span><span class="n">tree_map</span><span class="p">(</span><span class="n">maybe_map_to_meta_val</span><span class="p">,</span> <span class="n">extracted_outputs</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>

        <span class="c1">####################################</span>
        <span class="c1"># TODO: end of the insertion</span>
        <span class="c1"># TODO: indent what follows</span>
        <span class="c1">####################################</span>

            <span class="n">graph_module</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">_internal</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">passes</span><span class="o">.</span><span class="n">MovePlaceholderToFront</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_resolved_onnx_exporter_options</span><span class="o">.</span><span class="n">diagnostic_context</span><span class="p">,</span>
                <span class="n">graph_module</span><span class="p">,</span>
            <span class="p">)</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
            <span class="c1"># Generate reference outputs. They are used to indicate output</span>
            <span class="c1"># tensors&#39; types and devices when calling ORT.</span>
            <span class="c1">#</span>
            <span class="c1"># WARNING: The downstream code should not change prim_outputs and</span>
            <span class="c1"># this backend should always produces output with schema identical to prim_outputs&#39;.</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_resolved_onnx_exporter_options</span><span class="o">.</span><span class="n">dynamic_shapes</span><span class="p">:</span>
                <span class="c1"># No pre-allocation when dynamic shape is enabled.</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">preallocate_output</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="n">extracted_outputs</span> <span class="o">=</span> <span class="n">_extract_graph_module_outputs</span><span class="p">(</span><span class="n">graph_module</span><span class="p">)</span>

                <span class="k">def</span> <span class="nf">maybe_map_to_meta_val</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="s2">&quot;meta&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="s2">&quot;val&quot;</span> <span class="ow">in</span> <span class="n">value</span><span class="o">.</span><span class="n">meta</span><span class="p">:</span>
                        <span class="c1"># Select outputs with &quot;val&quot; information. Without &quot;val&quot;,</span>
                        <span class="c1"># it&#39;s not possible access output_arg.meta[&quot;val&quot;].device.</span>
                        <span class="k">return</span> <span class="n">value</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s2">&quot;val&quot;</span><span class="p">]</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">return</span> <span class="n">value</span>

                <span class="n">prim_outputs</span> <span class="o">=</span> <span class="n">_pytree</span><span class="o">.</span><span class="n">tree_map</span><span class="p">(</span>
                    <span class="n">maybe_map_to_meta_val</span><span class="p">,</span> <span class="n">extracted_outputs</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">prim_outputs</span> <span class="o">=</span> <span class="n">FakeTensorProp</span><span class="p">(</span><span class="n">graph_module</span><span class="p">)</span><span class="o">.</span><span class="n">propagate</span><span class="p">(</span>
                        <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
                    <span class="p">)</span>
                <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;FakeTensorProb failed for </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">graph_module</span><span class="p">)</span>
                    <span class="c1"># When FakeTensorProp fails, it is not possible to preallocate output buffers</span>
                    <span class="c1"># because the output shapes are not inferred.</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">preallocate_output</span> <span class="o">=</span> <span class="kc">False</span>

                    <span class="c1"># rethrow FakeTensorProb failure because it is not yet currently handled.</span>
                    <span class="k">raise</span>

            <span class="c1"># Create the object to iterate through the nodes in graph one-by-one</span>
            <span class="c1"># and calls the corresponding ONNX exporter for each node.</span>
            <span class="n">fx_interpreter</span> <span class="o">=</span> <span class="n">fx_onnx_interpreter</span><span class="o">.</span><span class="n">FxOnnxInterpreter</span><span class="p">(</span>
                <span class="n">diagnostic_context</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_resolved_onnx_exporter_options</span><span class="o">.</span><span class="n">diagnostic_context</span>
            <span class="p">)</span>
            <span class="c1"># Cast FX variables if they will result schema-mismatch when searching</span>
            <span class="c1"># for ONNX operator. E.g., add(double_tensor, int_tensor) is fine in PyTorch,</span>
            <span class="c1"># but ONNX expects add(double_tensor, double_tensor).</span>
            <span class="n">graph_module</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">_internal</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">passes</span><span class="o">.</span><span class="n">InsertTypePromotion</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_resolved_onnx_exporter_options</span><span class="o">.</span><span class="n">diagnostic_context</span><span class="p">,</span> <span class="n">graph_module</span>
            <span class="p">)</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
            <span class="c1"># Start the per-node exporting process. It&#39;s conceptually a for loop</span>
            <span class="c1"># scanning through the nodes in the graph.</span>
            <span class="n">exported</span> <span class="o">=</span> <span class="n">fx_interpreter</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                <span class="n">fx_graph_module</span><span class="o">=</span><span class="n">graph_module</span><span class="p">,</span>
                <span class="n">onnxfunction_dispatcher</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_resolved_onnx_exporter_options</span><span class="o">.</span><span class="n">onnxfunction_dispatcher</span><span class="p">,</span>
                <span class="n">op_level_debug</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_resolved_onnx_exporter_options</span><span class="o">.</span><span class="n">op_level_debug</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="c1"># Convert the exported result to ONNX ModelProto.</span>
            <span class="n">onnx_model</span> <span class="o">=</span> <span class="n">exported</span><span class="o">.</span><span class="n">to_model_proto</span><span class="p">(</span>
                <span class="n">opset_version</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_resolved_onnx_exporter_options</span><span class="o">.</span><span class="n">onnx_registry</span><span class="o">.</span><span class="n">opset_version</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1">####################################</span>
        <span class="c1"># TODO: end of the modification</span>
        <span class="c1">####################################</span>

        <span class="c1"># Modify ONNX model using pre-registered graph transforms.</span>
        <span class="c1"># They are in-place modifications for avoiding unnecessary</span>
        <span class="c1"># copy of ONNX initializers.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_options</span><span class="o">.</span><span class="n">pre_ort_model_transforms</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">transform</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_options</span><span class="o">.</span><span class="n">pre_ort_model_transforms</span><span class="p">:</span>
                <span class="n">transform</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">)</span>

        <span class="n">onnx_model_bytes</span> <span class="o">=</span> <span class="n">onnx_model</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;ONNXRT_DUMP_PATH&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">):</span>
            <span class="c1"># If not empty, environment variable ONNXRT_DUMP_PATH defined the path</span>
            <span class="c1"># where generated onnx files should be stored.</span>
            <span class="c1"># This module keeps a global variables keeping track of the</span>
            <span class="c1"># stored models.</span>
            <span class="c1"># If ONNXRT_DUMP_PATH=&quot;dumped/dumped_model_&quot;</span>
            <span class="c1"># The first file name will be &#39;dumped/dumped_model_0.onnx&#39;.</span>
            <span class="c1"># For every dumped model, a text file &#39;dumped/dumped_model_0.txt&#39;</span>
            <span class="c1"># is created as well to contain the string representing the graph_module.</span>
            <span class="n">_dump_onnx_model</span><span class="p">(</span><span class="n">onnx_model_bytes</span><span class="p">,</span> <span class="n">graph_module</span><span class="o">=</span><span class="n">graph_module</span><span class="p">)</span>

        <span class="c1"># Initialize a ORT session to execute this ONNX model.</span>
        <span class="c1"># Note that TorchDynamo assumes all inputs/outputs are on the</span>
        <span class="c1"># same device, but it&#39;s subject to change (very likely with</span>
        <span class="c1"># dynamic shape support), so we add execution providers</span>
        <span class="c1"># based on the logic in _select_eps: (explicitly preferred EPs,</span>
        <span class="c1"># EPs inferred from inputs or graph, and the fallback default EP)/</span>
        <span class="c1">#</span>
        <span class="c1"># TODO(wschin): enable external allocators.</span>
        <span class="c1"># See https://github.com/pytorch/pytorch/issues/106867</span>
        <span class="n">onnx_session</span> <span class="o">=</span> <span class="n">onnxruntime</span><span class="o">.</span><span class="n">InferenceSession</span><span class="p">(</span>
            <span class="n">path_or_bytes</span><span class="o">=</span><span class="n">onnx_model_bytes</span><span class="p">,</span>
            <span class="n">sess_options</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_options</span><span class="o">.</span><span class="n">ort_session_options</span><span class="p">,</span>
            <span class="n">providers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_select_eps</span><span class="p">(</span><span class="n">graph_module</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="c1"># Cache ORT session. It&#39;s reused for the same &quot;graph_module&quot;.</span>
        <span class="c1"># Generate ONNX model and extract its input and output names.</span>
        <span class="n">input_names</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">input</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="nb">input</span> <span class="ow">in</span> <span class="n">onnx_model</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">input</span><span class="p">)</span>
        <span class="n">output_names</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">onnx_model</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>
        <span class="n">input_devices</span> <span class="o">=</span> <span class="n">_get_onnx_devices</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
        <span class="c1"># Cache devices for inputs and outputs. They are used to invoke</span>
        <span class="c1"># ORT session. Output devices indicate where (e.g., GPU or CPU)</span>
        <span class="c1"># to store outputs</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prim_outputs</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">output_devices</span> <span class="o">=</span> <span class="n">_get_onnx_devices</span><span class="p">(</span><span class="n">prim_outputs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">output_devices</span> <span class="o">=</span> <span class="n">_get_onnx_devices</span><span class="p">((</span><span class="n">prim_outputs</span><span class="p">,))</span>

        <span class="n">input_value_infos</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">input</span> <span class="k">for</span> <span class="nb">input</span> <span class="ow">in</span> <span class="n">onnx_model</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">input</span><span class="p">)</span>
        <span class="n">output_value_infos</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">output</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">onnx_model</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>

        <span class="n">execution_info_per_session</span> <span class="o">=</span> <span class="n">OrtExecutionInfoPerSession</span><span class="p">(</span>
            <span class="n">session</span><span class="o">=</span><span class="n">onnx_session</span><span class="p">,</span>
            <span class="n">input_names</span><span class="o">=</span><span class="n">input_names</span><span class="p">,</span>
            <span class="n">input_value_infos</span><span class="o">=</span><span class="n">input_value_infos</span><span class="p">,</span>
            <span class="n">output_names</span><span class="o">=</span><span class="n">output_names</span><span class="p">,</span>
            <span class="n">output_value_infos</span><span class="o">=</span><span class="n">output_value_infos</span><span class="p">,</span>
            <span class="n">input_devices</span><span class="o">=</span><span class="n">input_devices</span><span class="p">,</span>
            <span class="n">output_devices</span><span class="o">=</span><span class="n">output_devices</span><span class="p">,</span>
            <span class="n">example_outputs</span><span class="o">=</span><span class="n">prim_outputs</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_all_ort_execution_info</span><span class="o">.</span><span class="n">cache_session_execution_info</span><span class="p">(</span>
            <span class="n">graph_module</span><span class="p">,</span> <span class="n">execution_info_per_session</span>
        <span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">execution_count</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="c1"># ORT always returns a tuple of outputs. If the original output is a tensor,</span>
    <span class="c1"># ORT output&#39;s first element must be extracted and returned. Otherwise, type</span>
    <span class="c1"># mismatch may happen in downstream computation.</span>
    <span class="n">is_single_tensor_output</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prim_outputs</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
    <span class="n">normalized_prim_outputs</span> <span class="o">=</span> <span class="p">(</span>
        <span class="p">(</span><span class="n">prim_outputs</span><span class="p">,)</span> <span class="k">if</span> <span class="n">is_single_tensor_output</span> <span class="k">else</span> <span class="n">prim_outputs</span>
    <span class="p">)</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">normalized_prim_outputs</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span>
        <span class="nb">isinstance</span><span class="p">(</span><span class="n">elem</span><span class="p">,</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">SymInt</span><span class="p">,</span> <span class="nb">int</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">normalized_prim_outputs</span>
    <span class="p">)</span>

    <span class="n">_nvtx_range_push</span><span class="p">(</span><span class="s2">&quot;run_onnx_session_with_ortvaluevector&quot;</span><span class="p">)</span>
    <span class="n">onnx_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
        <span class="n">onnx_session</span><span class="p">,</span>
        <span class="n">input_names</span><span class="p">,</span>
        <span class="n">args</span><span class="p">,</span>
        <span class="n">input_devices</span><span class="p">,</span>
        <span class="n">output_names</span><span class="p">,</span>
        <span class="n">normalized_prim_outputs</span><span class="p">,</span>
        <span class="n">output_devices</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_options</span><span class="o">.</span><span class="n">preallocate_output</span><span class="p">,</span>
        <span class="n">input_value_infos</span><span class="p">,</span>
        <span class="n">normalized_prim_outputs</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">_nvtx_range_pop</span><span class="p">()</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_assert_allclose_to_baseline</span><span class="p">:</span>
        <span class="c1"># Compute baseline.</span>
        <span class="n">baseline_outputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_prims</span><span class="o">.</span><span class="n">executor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span>
            <span class="n">graph_module</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">executor</span><span class="o">=</span><span class="s2">&quot;aten&quot;</span>
        <span class="p">)</span>
        <span class="n">normalized_baseline_ouptuts</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">(</span><span class="n">baseline_outputs</span><span class="p">,)</span> <span class="k">if</span> <span class="n">is_single_tensor_output</span> <span class="k">else</span> <span class="n">baseline_outputs</span>
        <span class="p">)</span>
        <span class="c1"># Ensure every output tensor is close to the corresponding baseline.</span>
        <span class="k">for</span> <span class="n">onnx_output</span><span class="p">,</span> <span class="n">baseline_output</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
            <span class="n">onnx_outputs</span><span class="p">,</span> <span class="n">normalized_baseline_ouptuts</span>
        <span class="p">):</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_close</span><span class="p">(</span><span class="n">onnx_output</span><span class="p">,</span> <span class="n">baseline_output</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">onnx_outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">is_single_tensor_output</span> <span class="k">else</span> <span class="n">onnx_outputs</span>
</pre></div>
</div>
</section>
<section id="examples">
<h2>Examples<a class="headerlink" href="#examples" title="Link to this heading">#</a></h2>
<section id="baseline">
<h3>Baseline<a class="headerlink" href="#baseline" title="Link to this heading">#</a></h3>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">onnx</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.onnx</span>
<span class="kn">from</span> <span class="nn">experimental_experiment.torch_helper.training_helper</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">make_aot_ort</span><span class="p">,</span>
    <span class="n">train_loop</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">experimental_experiment.torch_helper.dump_helper</span> <span class="kn">import</span> <span class="n">dump_onnx</span>

<span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
    <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">LlamaConfig</span>
    <span class="kn">from</span> <span class="nn">transformers.models.llama.modeling_llama</span> <span class="kn">import</span> <span class="n">LlamaModel</span>


<span class="k">def</span> <span class="nf">ids_tensor</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">):</span>
    <span class="n">total_dims</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="n">shape</span><span class="p">:</span>
        <span class="n">total_dims</span> <span class="o">*=</span> <span class="n">dim</span>

    <span class="n">values</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">total_dims</span><span class="p">):</span>
        <span class="n">values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">vocab_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>


<span class="n">config</span> <span class="o">=</span> <span class="n">LlamaConfig</span><span class="p">(</span>
    <span class="n">hidden_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">num_hidden_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">vocab_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
    <span class="n">intermediate_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">max_position_embeddings</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
    <span class="n">num_attention_heads</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">config</span><span class="o">.</span><span class="n">_attn_implementation</span> <span class="o">=</span> <span class="s2">&quot;eager&quot;</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">LlamaModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

<span class="n">batch</span><span class="p">,</span> <span class="n">seq</span><span class="p">,</span> <span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span>

<span class="n">input_ids</span> <span class="o">=</span> <span class="n">ids_tensor</span><span class="p">([</span><span class="n">batch</span><span class="p">,</span> <span class="n">seq</span><span class="p">],</span> <span class="n">vocab_size</span><span class="p">)</span>
<span class="n">input_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tril</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">seq</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

<span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">input_mask</span><span class="p">)</span>

<span class="n">local_aot_ort</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">make_aot_ort</span><span class="p">(</span>
    <span class="n">dynamic</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">rewrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>

<span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
    <span class="n">optimized_mod</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="n">local_aot_ort</span><span class="p">,</span> <span class="n">fullgraph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">dump_onnx</span><span class="p">(</span><span class="s2">&quot;dort-llama-ort&quot;</span><span class="p">,</span> <span class="n">folder</span><span class="o">=</span><span class="s2">&quot;dump_llama&quot;</span><span class="p">,</span> <span class="n">clean</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="n">train_loop</span><span class="p">(</span><span class="n">optimized_mod</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">input_mask</span><span class="p">)</span>

<span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="n">_</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s2">&quot;dump_llama&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">_</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.onnx&quot;</span><span class="p">)]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------------------------&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;exported model: </span><span class="si">{</span><span class="n">names</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">names</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;NODES in </span><span class="si">{name!r}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">onx</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">&quot;dump_llama&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">node</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">onx</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">onx</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="p">)</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">node</span><span class="o">.</span><span class="n">op_type</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="si">}</span><span class="s2"> -&gt; </span><span class="si">{</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    [make_aot_ort] enable rewriting
    [optimize_model_proto] starts optimize with 375 nodes and 25 local functions
    Applied 0 pattern rewrite rules.
    Applied 0 pattern rewrite rules.
    [optimize_model_proto] optimize done in 0.313549200000125 seconds.
    [optimize_model_proto] starts rewrite with 219 nodes and 8 local functions
    [optimize_model_proto] rewrite done in 1.7000002117129043e-06 seconds with 219 nodes and 8 local functions
    [optimize_model_proto] starts optimize with 394 nodes and 23 local functions
    Applied 0 pattern rewrite rules.
    Applied 0 pattern rewrite rules.
    [optimize_model_proto] optimize done in 0.5820715000008931 seconds.
    [optimize_model_proto] starts rewrite with 285 nodes and 18 local functions
    [optimize_model_proto] rewrite done in 2.0000006770715117e-06 seconds with 285 nodes and 18 local functions
    ------------------------------------------
    exported model: [&#39;dort-llama-ort_1.onnx&#39;, &#39;dort-llama-ort_0.onnx&#39;]
    
    NODES in {name!r}
    1/301: Mul [&#39;embedding&#39;, &#39;rsqrt&#39;] -&gt; [&#39;mul&#39;]
    2/301: Constant [] -&gt; [&#39;_val_40&#39;]
    3/301: Constant [] -&gt; [&#39;_val_44&#39;]
    4/301: Constant [] -&gt; [&#39;_val_48&#39;]
    5/301: Constant [] -&gt; [&#39;_val_52&#39;]
    6/301: Slice [&#39;primals_12&#39;, &#39;_val_40&#39;, &#39;_val_44&#39;, &#39;_val_48&#39;, &#39;_val_52&#39;] -&gt; [&#39;slice_7&#39;]
    7/301: Constant [] -&gt; [&#39;_val_57&#39;]
    8/301: Constant [] -&gt; [&#39;_val_61&#39;]
    9/301: Constant [] -&gt; [&#39;_val_65&#39;]
    10/301: Constant [] -&gt; [&#39;_val_69&#39;]
    11/301: Slice [&#39;primals_13&#39;, &#39;_val_57&#39;, &#39;_val_61&#39;, &#39;_val_65&#39;, &#39;_val_69&#39;] -&gt; [&#39;slice_8&#39;]
    12/301: Constant [] -&gt; [&#39;aten_view_142_size_0&#39;]
    13/301: Reshape [&#39;mm_3&#39;, &#39;aten_view_142_size_0&#39;] -&gt; [&#39;view_18&#39;]
    14/301: Constant [] -&gt; [&#39;aten_view_145_size_0&#39;]
    15/301: Reshape [&#39;mm_4&#39;, &#39;aten_view_145_size_0&#39;] -&gt; [&#39;view_20&#39;]
    16/301: Constant [] -&gt; [&#39;aten_view_147_size_0&#39;]
    17/301: Reshape [&#39;mm_5&#39;, &#39;aten_view_147_size_0&#39;] -&gt; [&#39;view_22&#39;]
    18/301: Constant [] -&gt; [&#39;aten_view_149_size_0&#39;]
    19/301: Reshape [&#39;mm_6&#39;, &#39;aten_view_149_size_0&#39;] -&gt; [&#39;view_24&#39;]
    20/301: Mul [&#39;tangents_1&#39;, &#39;primals_3&#39;] -&gt; [&#39;mul_12&#39;]
    21/301: Constant [] -&gt; [&#39;_val_85&#39;]
    22/301: Pow [&#39;embedding&#39;, &#39;_val_85&#39;] -&gt; [&#39;pow_9&#39;]
    23/301: Constant [] -&gt; [&#39;_val_87&#39;]
    24/301: Equal [&#39;primals_14&#39;, &#39;_val_87&#39;] -&gt; [&#39;eq&#39;]
    25/301: Transpose [&#39;slice_7&#39;] -&gt; [&#39;_val_90&#39;]
    26/301: Max [&#39;unsqueeze&#39;] -&gt; [&#39;_val_91&#39;]
    27/301: Shape [&#39;_val_91&#39;] -&gt; [&#39;_val_92&#39;]
    28/301: Expand [&#39;unsqueeze&#39;, &#39;_val_92&#39;] -&gt; [&#39;_val_93&#39;]
    29/301: Constant [] -&gt; [&#39;_val_94&#39;]
    30/301: Unsqueeze [&#39;_val_93&#39;, &#39;_val_94&#39;] -&gt; [&#39;_val_95&#39;]
    31/301: Concat [&#39;_val_95&#39;] -&gt; [&#39;_val_96&#39;]
    32/301: GatherND [&#39;_val_90&#39;, &#39;_val_96&#39;] -&gt; [&#39;_val_97&#39;]
    33/301: Transpose [&#39;_val_97&#39;] -&gt; [&#39;index&#39;]
    34/301: Transpose [&#39;slice_8&#39;] -&gt; [&#39;_val_99&#39;]
    35/301: Max [&#39;unsqueeze&#39;] -&gt; [&#39;_val_100&#39;]
    36/301: Shape [&#39;_val_100&#39;] -&gt; [&#39;_val_101&#39;]
    37/301: Expand [&#39;unsqueeze&#39;, &#39;_val_101&#39;] -&gt; [&#39;_val_102&#39;]
    38/301: Constant [] -&gt; [&#39;_val_103&#39;]
    39/301: Unsqueeze [&#39;_val_102&#39;, &#39;_val_103&#39;] -&gt; [&#39;_val_104&#39;]
    40/301: Concat [&#39;_val_104&#39;] -&gt; [&#39;_val_105&#39;]
    41/301: GatherND [&#39;_val_99&#39;, &#39;_val_105&#39;] -&gt; [&#39;_val_106&#39;]
    42/301: Transpose [&#39;_val_106&#39;] -&gt; [&#39;index_1&#39;]
    43/301: aten_add|folded_0 [&#39;embedding&#39;, &#39;view_18&#39;] -&gt; [&#39;add_5&#39;]
    44/301: Mul [&#39;view_20&#39;, &#39;sigmoid&#39;] -&gt; [&#39;mul_8&#39;]
    45/301: Mul [&#39;mul_12&#39;, &#39;rsqrt_2&#39;] -&gt; [&#39;mul_15&#39;]
    46/301: Constant [] -&gt; [&#39;fill&#39;]
    47/301: Constant [] -&gt; [&#39;_val_115&#39;]
    48/301: Mul [&#39;pow_9&#39;, &#39;_val_115&#39;] -&gt; [&#39;mul_45&#39;]
    49/301: Constant [] -&gt; [&#39;aten_unsqueeze_187_dim_0&#39;]
    50/301: Unsqueeze [&#39;eq&#39;, &#39;aten_unsqueeze_187_dim_0&#39;] -&gt; [&#39;unsqueeze_9&#39;]
    51/301: Constant [] -&gt; [&#39;aten_unsqueeze_189_dim_0&#39;]
    52/301: Unsqueeze [&#39;index&#39;, &#39;aten_unsqueeze_189_dim_0&#39;] -&gt; [&#39;unsqueeze_7&#39;]
    53/301: Constant [] -&gt; [&#39;aten_unsqueeze_190_dim_0&#39;]
    54/301: Unsqueeze [&#39;index_1&#39;, &#39;aten_unsqueeze_190_dim_0&#39;] -&gt; [&#39;unsqueeze_8&#39;]
    55/301: Mul [&#39;add_5&#39;, &#39;rsqrt_1&#39;] -&gt; [&#39;mul_6&#39;]
    56/301: aten_add|folded_1 [&#39;add_5&#39;, &#39;view_24&#39;] -&gt; [&#39;add_7&#39;]
    57/301: Constant [] -&gt; [&#39;_val_123&#39;]
    58/301: Pow [&#39;add_5&#39;, &#39;_val_123&#39;] -&gt; [&#39;pow_7&#39;]
    59/301: aten_sub|folded_0 [&#39;fill&#39;, &#39;sigmoid&#39;] -&gt; [&#39;sub&#39;]
    60/301: Mul [&#39;add_7&#39;, &#39;rsqrt_2&#39;] -&gt; [&#39;mul_10&#39;]
    61/301: Mul [&#39;mul_12&#39;, &#39;add_7&#39;] -&gt; [&#39;mul_14&#39;]
    62/301: Constant [] -&gt; [&#39;_val_131&#39;]
    63/301: Pow [&#39;add_7&#39;, &#39;_val_131&#39;] -&gt; [&#39;pow_5&#39;]
    64/301: Constant [] -&gt; [&#39;_val_133&#39;]
    65/301: Mul [&#39;pow_7&#39;, &#39;_val_133&#39;] -&gt; [&#39;mul_31&#39;]
    66/301: Mul [&#39;view_20&#39;, &#39;sub&#39;] -&gt; [&#39;mul_22&#39;]
    67/301: Constant [] -&gt; [&#39;scalar_tensor_default&#39;]
    68/301: Pow [&#39;rsqrt&#39;, &#39;scalar_tensor_default&#39;] -&gt; [&#39;pow_8&#39;]
    69/301: Mul [&#39;tangents_1&#39;, &#39;mul_10&#39;] -&gt; [&#39;mul_13&#39;]
    70/301: Constant [] -&gt; [&#39;_val_142&#39;]
    71/301: ReduceSum [&#39;mul_14&#39;, &#39;_val_142&#39;] -&gt; [&#39;sum_2&#39;]
    72/301: Constant [] -&gt; [&#39;_val_144&#39;]
    73/301: Mul [&#39;pow_5&#39;, &#39;_val_144&#39;] -&gt; [&#39;mul_18&#39;]
    74/301: Constant [] -&gt; [&#39;scalar_tensor_default_1&#39;]
    75/301: Pow [&#39;rsqrt_1&#39;, &#39;scalar_tensor_default_1&#39;] -&gt; [&#39;pow_6&#39;]
    76/301: Constant [] -&gt; [&#39;scalar_tensor_default_2&#39;]
    77/301: Pow [&#39;rsqrt_2&#39;, &#39;scalar_tensor_default_2&#39;] -&gt; [&#39;pow_4&#39;]
    78/301: Constant [] -&gt; [&#39;scalar_tensor_default_3&#39;]
    79/301: Constant [] -&gt; [&#39;aten_add_224_other_1&#39;]
    80/301: Add [&#39;mul_22&#39;, &#39;aten_add_224_other_1&#39;] -&gt; [&#39;add_10&#39;]
    81/301: Constant [] -&gt; [&#39;_val_155&#39;]
    82/301: ReduceSum [&#39;mul_13&#39;, &#39;_val_155&#39;] -&gt; [&#39;sum_1&#39;]
    83/301: Constant [] -&gt; [&#39;_val_157&#39;]
    84/301: Mul [&#39;sum_2&#39;, &#39;_val_157&#39;] -&gt; [&#39;mul_16&#39;]
    85/301: Mul [&#39;sigmoid&#39;, &#39;add_10&#39;] -&gt; [&#39;mul_23&#39;]
    86/301: Constant [] -&gt; [&#39;aten_view_231_size_0&#39;]
    87/301: Reshape [&#39;sum_1&#39;, &#39;aten_view_231_size_0&#39;] -&gt; [&#39;view_25&#39;]
    88/301: Mul [&#39;mul_16&#39;, &#39;pow_4&#39;] -&gt; [&#39;mul_17&#39;]
    89/301: Constant [] -&gt; [&#39;_val_163&#39;]
    90/301: Constant [] -&gt; [&#39;aten_expand_234_size_1&#39;]
    91/301: Expand [&#39;mul_17&#39;, &#39;aten_expand_234_size_1&#39;] -&gt; [&#39;expand_7&#39;]
    92/301: Constant [] -&gt; [&#39;scalar_tensor_default_4&#39;]
    93/301: Div [&#39;expand_7&#39;, &#39;scalar_tensor_default_4&#39;] -&gt; [&#39;div_1&#39;]
    94/301: Mul [&#39;div_1&#39;, &#39;mul_18&#39;] -&gt; [&#39;mul_19&#39;]
    95/301: aten_add|folded_3 [&#39;mul_15&#39;, &#39;mul_19&#39;] -&gt; [&#39;add_9&#39;]
    96/301: Constant [] -&gt; [&#39;aten_view_241_size_0&#39;]
    97/301: Reshape [&#39;add_9&#39;, &#39;aten_view_241_size_0&#39;] -&gt; [&#39;view_26&#39;]
    98/301: Transpose [&#39;view_26&#39;] -&gt; [&#39;t_7&#39;]
    99/301: MatMul [&#39;view_26&#39;, &#39;t_9&#39;] -&gt; [&#39;mm_8&#39;]
    100/301: MatMul [&#39;t_7&#39;, &#39;view_23&#39;] -&gt; [&#39;mm_7&#39;]
    101/301: Constant [] -&gt; [&#39;aten_view_246_size_0&#39;]
    102/301: Reshape [&#39;mm_8&#39;, &#39;aten_view_246_size_0&#39;] -&gt; [&#39;view_27&#39;]
    103/301: Transpose [&#39;mm_7&#39;] -&gt; [&#39;t_8&#39;]
    104/301: Mul [&#39;view_27&#39;, &#39;mul_8&#39;] -&gt; [&#39;mul_20&#39;]
    105/301: Mul [&#39;view_27&#39;, &#39;view_22&#39;] -&gt; [&#39;mul_21&#39;]
    106/301: Transpose [&#39;t_8&#39;] -&gt; [&#39;t_10&#39;]
    107/301: Constant [] -&gt; [&#39;aten_view_252_size_0&#39;]
    108/301: Reshape [&#39;mul_20&#39;, &#39;aten_view_252_size_0&#39;] -&gt; [&#39;view_28&#39;]
    109/301: Mul [&#39;mul_21&#39;, &#39;mul_23&#39;] -&gt; [&#39;mul_24&#39;]
    110/301: Transpose [&#39;view_28&#39;] -&gt; [&#39;t_11&#39;]
    111/301: MatMul [&#39;view_28&#39;, &#39;t_13&#39;] -&gt; [&#39;mm_10&#39;]
    112/301: Constant [] -&gt; [&#39;aten_view_257_size_0&#39;]
    113/301: Reshape [&#39;mul_24&#39;, &#39;aten_view_257_size_0&#39;] -&gt; [&#39;view_30&#39;]
    114/301: MatMul [&#39;t_11&#39;, &#39;view_19&#39;] -&gt; [&#39;mm_9&#39;]
    115/301: Constant [] -&gt; [&#39;aten_view_260_size_0&#39;]
    116/301: Reshape [&#39;mm_10&#39;, &#39;aten_view_260_size_0&#39;] -&gt; [&#39;view_29&#39;]
    117/301: Transpose [&#39;view_30&#39;] -&gt; [&#39;t_15&#39;]
    118/301: MatMul [&#39;view_30&#39;, &#39;t_17&#39;] -&gt; [&#39;mm_12&#39;]
    119/301: Transpose [&#39;mm_9&#39;] -&gt; [&#39;t_12&#39;]
    120/301: MatMul [&#39;t_15&#39;, &#39;view_19&#39;] -&gt; [&#39;mm_11&#39;]
    121/301: Constant [] -&gt; [&#39;aten_view_266_size_0&#39;]
    122/301: Reshape [&#39;mm_12&#39;, &#39;aten_view_266_size_0&#39;] -&gt; [&#39;view_31&#39;]
    123/301: Transpose [&#39;t_12&#39;] -&gt; [&#39;t_14&#39;]
    124/301: Transpose [&#39;mm_11&#39;] -&gt; [&#39;t_16&#39;]
    125/301: aten_add|folded_4 [&#39;view_29&#39;, &#39;view_31&#39;] -&gt; [&#39;add_11&#39;]
    126/301: Transpose [&#39;t_16&#39;] -&gt; [&#39;t_18&#39;]
    127/301: Mul [&#39;add_11&#39;, &#39;primals_2&#39;] -&gt; [&#39;mul_25&#39;]
    128/301: Mul [&#39;add_11&#39;, &#39;mul_6&#39;] -&gt; [&#39;mul_26&#39;]
    129/301: Mul [&#39;mul_25&#39;, &#39;add_5&#39;] -&gt; [&#39;mul_27&#39;]
    130/301: Mul [&#39;mul_25&#39;, &#39;rsqrt_1&#39;] -&gt; [&#39;mul_28&#39;]
    131/301: Constant [] -&gt; [&#39;_val_205&#39;]
    132/301: ReduceSum [&#39;mul_26&#39;, &#39;_val_205&#39;] -&gt; [&#39;sum_3&#39;]
    133/301: Constant [] -&gt; [&#39;_val_207&#39;]
    134/301: ReduceSum [&#39;mul_27&#39;, &#39;_val_207&#39;] -&gt; [&#39;sum_4&#39;]
    135/301: aten_add|folded_5 [&#39;add_9&#39;, &#39;mul_28&#39;] -&gt; [&#39;add_12&#39;]
    136/301: Constant [] -&gt; [&#39;aten_view_281_size_0&#39;]
    137/301: Reshape [&#39;sum_3&#39;, &#39;aten_view_281_size_0&#39;] -&gt; [&#39;view_32&#39;]
    138/301: Constant [] -&gt; [&#39;_val_212&#39;]
    139/301: Mul [&#39;sum_4&#39;, &#39;_val_212&#39;] -&gt; [&#39;mul_29&#39;]
    140/301: Mul [&#39;mul_29&#39;, &#39;pow_6&#39;] -&gt; [&#39;mul_30&#39;]
    141/301: Constant [] -&gt; [&#39;_val_215&#39;]
    142/301: Constant [] -&gt; [&#39;aten_expand_286_size_1&#39;]
    143/301: Expand [&#39;mul_30&#39;, &#39;aten_expand_286_size_1&#39;] -&gt; [&#39;expand_8&#39;]
    144/301: Constant [] -&gt; [&#39;scalar_tensor_default_5&#39;]
    145/301: Div [&#39;expand_8&#39;, &#39;scalar_tensor_default_5&#39;] -&gt; [&#39;div_2&#39;]
    146/301: Mul [&#39;div_2&#39;, &#39;mul_31&#39;] -&gt; [&#39;mul_32&#39;]
    147/301: aten_add|folded_6 [&#39;add_12&#39;, &#39;mul_32&#39;] -&gt; [&#39;add_13&#39;]
    148/301: Constant [] -&gt; [&#39;aten_view_293_size_0&#39;]
    149/301: Reshape [&#39;add_13&#39;, &#39;aten_view_293_size_0&#39;] -&gt; [&#39;view_33&#39;]
    150/301: Transpose [&#39;view_33&#39;] -&gt; [&#39;t_19&#39;]
    151/301: MatMul [&#39;view_33&#39;, &#39;t_21&#39;] -&gt; [&#39;mm_14&#39;]
    152/301: MatMul [&#39;t_19&#39;, &#39;view_17&#39;] -&gt; [&#39;mm_13&#39;]
    153/301: Constant [] -&gt; [&#39;aten_view_298_size_0&#39;]
    154/301: Reshape [&#39;mm_14&#39;, &#39;aten_view_298_size_0&#39;] -&gt; [&#39;view_34&#39;]
    155/301: Transpose [&#39;mm_13&#39;] -&gt; [&#39;t_20&#39;]
    156/301: Constant [] -&gt; [&#39;aten_view_301_size_0&#39;]
    157/301: Reshape [&#39;view_34&#39;, &#39;aten_view_301_size_0&#39;] -&gt; [&#39;view_35&#39;]
    158/301: Transpose [&#39;t_20&#39;] -&gt; [&#39;t_22&#39;]
    159/301: Transpose [&#39;view_35&#39;] -&gt; [&#39;transpose_5&#39;]
    160/301: Constant [] -&gt; [&#39;aten_view_306_size_0&#39;]
    161/301: Reshape [&#39;transpose_5&#39;, &#39;aten_view_306_size_0&#39;] -&gt; [&#39;view_36&#39;]
    162/301: MatMul [&#39;transpose_6&#39;, &#39;view_36&#39;] -&gt; [&#39;bmm_2&#39;]
    163/301: MatMul [&#39;view_36&#39;, &#39;transpose_7&#39;] -&gt; [&#39;bmm_3&#39;]
    164/301: Constant [] -&gt; [&#39;aten_view_310_size_0&#39;]
    165/301: Reshape [&#39;bmm_2&#39;, &#39;aten_view_310_size_0&#39;] -&gt; [&#39;view_37&#39;]
    166/301: Constant [] -&gt; [&#39;aten_view_312_size_0&#39;]
    167/301: Reshape [&#39;bmm_3&#39;, &#39;aten_view_312_size_0&#39;] -&gt; [&#39;view_38&#39;]
    168/301: aten_add|folded_7 [&#39;tangents_3&#39;, &#39;view_37&#39;] -&gt; [&#39;add_14&#39;]
    169/301: Mul [&#39;view_38&#39;, &#39;detach_13&#39;] -&gt; [&#39;mul_33&#39;]
    170/301: Transpose [&#39;add_14&#39;] -&gt; [&#39;transpose_11&#39;]
    171/301: Constant [] -&gt; [&#39;_val_246&#39;]
    172/301: ReduceSum [&#39;mul_33&#39;, &#39;_val_246&#39;] -&gt; [&#39;sum_5&#39;]
    173/301: Mul [&#39;detach_13&#39;, &#39;sum_5&#39;] -&gt; [&#39;mul_34&#39;]
    174/301: Constant [] -&gt; [&#39;aten_view_321_size_0&#39;]
    175/301: Reshape [&#39;transpose_11&#39;, &#39;aten_view_321_size_0&#39;] -&gt; [&#39;view_42&#39;]
    176/301: aten_sub|folded_1 [&#39;mul_33&#39;, &#39;mul_34&#39;] -&gt; [&#39;sub_1&#39;]
    177/301: Constant [] -&gt; [&#39;aten_view_324_size_0&#39;]
    178/301: Reshape [&#39;view_42&#39;, &#39;aten_view_324_size_0&#39;] -&gt; [&#39;view_45&#39;]
    179/301: Constant [] -&gt; [&#39;_val_255&#39;]
    180/301: Div [&#39;sub_1&#39;, &#39;_val_255&#39;] -&gt; [&#39;div_3&#39;]
    181/301: Transpose [&#39;view_45&#39;] -&gt; [&#39;t_23&#39;]
    182/301: MatMul [&#39;view_45&#39;, &#39;t_25&#39;] -&gt; [&#39;mm_16&#39;]
    183/301: Constant [] -&gt; [&#39;aten_view_330_size_0&#39;]
    184/301: Reshape [&#39;div_3&#39;, &#39;aten_view_330_size_0&#39;] -&gt; [&#39;view_39&#39;]
    185/301: MatMul [&#39;t_23&#39;, &#39;view_1&#39;] -&gt; [&#39;mm_15&#39;]
    186/301: Constant [] -&gt; [&#39;aten_view_333_size_0&#39;]
    187/301: Reshape [&#39;mm_16&#39;, &#39;aten_view_333_size_0&#39;] -&gt; [&#39;view_46&#39;]
    188/301: MatMul [&#39;transpose_8&#39;, &#39;view_39&#39;] -&gt; [&#39;bmm_4&#39;]
    189/301: MatMul [&#39;view_39&#39;, &#39;transpose_9&#39;] -&gt; [&#39;bmm_5&#39;]
    190/301: Transpose [&#39;mm_15&#39;] -&gt; [&#39;t_24&#39;]
    191/301: Constant [] -&gt; [&#39;aten_view_338_size_0&#39;]
    192/301: Reshape [&#39;bmm_4&#39;, &#39;aten_view_338_size_0&#39;] -&gt; [&#39;view_40&#39;]
    193/301: Constant [] -&gt; [&#39;aten_view_340_size_0&#39;]
    194/301: Reshape [&#39;bmm_5&#39;, &#39;aten_view_340_size_0&#39;] -&gt; [&#39;view_41&#39;]
    195/301: Transpose [&#39;t_24&#39;] -&gt; [&#39;t_26&#39;]
    196/301: Transpose [&#39;view_40&#39;] -&gt; [&#39;transpose_10&#39;]
    197/301: Mul [&#39;view_41&#39;, &#39;unsqueeze_8&#39;] -&gt; [&#39;mul_37&#39;]
    198/301: Mul [&#39;view_41&#39;, &#39;unsqueeze_7&#39;] -&gt; [&#39;mul_38&#39;]
    199/301: aten_add|folded_8 [&#39;tangents_2&#39;, &#39;transpose_10&#39;] -&gt; [&#39;add_15&#39;]
    200/301: Constant [] -&gt; [&#39;_val_279&#39;]
    201/301: Constant [] -&gt; [&#39;_val_283&#39;]
    202/301: Constant [] -&gt; [&#39;_val_287&#39;]
    203/301: Constant [] -&gt; [&#39;_val_291&#39;]
    204/301: Slice [&#39;mul_37&#39;, &#39;_val_279&#39;, &#39;_val_283&#39;, &#39;_val_287&#39;, &#39;_val_291&#39;] -&gt; [&#39;slice_15&#39;]
    205/301: Constant [] -&gt; [&#39;_val_296&#39;]
    206/301: Constant [] -&gt; [&#39;_val_300&#39;]
    207/301: Constant [] -&gt; [&#39;_val_304&#39;]
    208/301: Constant [] -&gt; [&#39;_val_308&#39;]
    209/301: Slice [&#39;mul_37&#39;, &#39;_val_296&#39;, &#39;_val_300&#39;, &#39;_val_304&#39;, &#39;_val_308&#39;] -&gt; [&#39;slice_16&#39;]
    210/301: Mul [&#39;add_15&#39;, &#39;unsqueeze_8&#39;] -&gt; [&#39;mul_35&#39;]
    211/301: Mul [&#39;add_15&#39;, &#39;unsqueeze_7&#39;] -&gt; [&#39;mul_36&#39;]
    212/301: Neg [&#39;slice_15&#39;] -&gt; [&#39;neg_3&#39;]
    213/301: Constant [] -&gt; [&#39;new_zeros_3&#39;]
    214/301: Constant [] -&gt; [&#39;_val_318&#39;]
    215/301: Constant [] -&gt; [&#39;_val_322&#39;]
    216/301: Constant [] -&gt; [&#39;_val_326&#39;]
    217/301: Constant [] -&gt; [&#39;_val_330&#39;]
    218/301: Slice [&#39;mul_35&#39;, &#39;_val_318&#39;, &#39;_val_322&#39;, &#39;_val_326&#39;, &#39;_val_330&#39;] -&gt; [&#39;slice_13&#39;]
    219/301: Constant [] -&gt; [&#39;_val_335&#39;]
    220/301: Constant [] -&gt; [&#39;_val_339&#39;]
    221/301: Constant [] -&gt; [&#39;_val_343&#39;]
    222/301: Constant [] -&gt; [&#39;_val_347&#39;]
    223/301: Slice [&#39;mul_35&#39;, &#39;_val_335&#39;, &#39;_val_339&#39;, &#39;_val_343&#39;, &#39;_val_347&#39;] -&gt; [&#39;slice_14&#39;]
    224/301: Constant [] -&gt; [&#39;new_zeros_2&#39;]
    225/301: Constant [] -&gt; [&#39;_val_351&#39;]
    226/301: Constant [] -&gt; [&#39;_val_352&#39;]
    227/301: Constant [] -&gt; [&#39;_val_353&#39;]
    228/301: Constant [] -&gt; [&#39;aten_slice_scatter_424_indices&#39;]
    229/301: ScatterElements [&#39;new_zeros_3&#39;, &#39;aten_slice_scatter_424_indices&#39;, &#39;slice_16&#39;] -&gt; [&#39;slice_scatter_3&#39;]
    230/301: Neg [&#39;slice_13&#39;] -&gt; [&#39;neg_2&#39;]
    231/301: Constant [] -&gt; [&#39;new_zeros_1&#39;]
    232/301: Constant [] -&gt; [&#39;_val_358&#39;]
    233/301: Constant [] -&gt; [&#39;_val_359&#39;]
    234/301: Constant [] -&gt; [&#39;_val_360&#39;]
    235/301: Constant [] -&gt; [&#39;aten_slice_scatter_431_indices&#39;]
    236/301: ScatterElements [&#39;new_zeros_2&#39;, &#39;aten_slice_scatter_431_indices&#39;, &#39;neg_3&#39;] -&gt; [&#39;slice_scatter_2&#39;]
    237/301: Constant [] -&gt; [&#39;new_zeros&#39;]
    238/301: Constant [] -&gt; [&#39;_val_364&#39;]
    239/301: Constant [] -&gt; [&#39;_val_365&#39;]
    240/301: Constant [] -&gt; [&#39;_val_366&#39;]
    241/301: Constant [] -&gt; [&#39;aten_slice_scatter_437_indices&#39;]
    242/301: ScatterElements [&#39;new_zeros_1&#39;, &#39;aten_slice_scatter_437_indices&#39;, &#39;slice_14&#39;] -&gt; [&#39;slice_scatter_1&#39;]
    243/301: aten_add|folded_9 [&#39;slice_scatter_2&#39;, &#39;slice_scatter_3&#39;] -&gt; [&#39;add_18&#39;]
    244/301: Constant [] -&gt; [&#39;_val_369&#39;]
    245/301: Constant [] -&gt; [&#39;_val_370&#39;]
    246/301: Constant [] -&gt; [&#39;_val_371&#39;]
    247/301: Constant [] -&gt; [&#39;aten_slice_scatter_442_indices&#39;]
    248/301: ScatterElements [&#39;new_zeros&#39;, &#39;aten_slice_scatter_442_indices&#39;, &#39;neg_2&#39;] -&gt; [&#39;slice_scatter&#39;]
    249/301: aten_add|folded_10 [&#39;add_18&#39;, &#39;mul_38&#39;] -&gt; [&#39;add_19&#39;]
    250/301: aten_add|folded_11 [&#39;slice_scatter&#39;, &#39;slice_scatter_1&#39;] -&gt; [&#39;add_16&#39;]
    251/301: Transpose [&#39;add_19&#39;] -&gt; [&#39;transpose_13&#39;]
    252/301: aten_add|folded_12 [&#39;add_16&#39;, &#39;mul_36&#39;] -&gt; [&#39;add_17&#39;]
    253/301: Transpose [&#39;add_17&#39;] -&gt; [&#39;transpose_12&#39;]
    254/301: Constant [] -&gt; [&#39;aten_view_450_size_0&#39;]
    255/301: Reshape [&#39;transpose_13&#39;, &#39;aten_view_450_size_0&#39;] -&gt; [&#39;view_44&#39;]
    256/301: Constant [] -&gt; [&#39;aten_view_453_size_0&#39;]
    257/301: Reshape [&#39;view_44&#39;, &#39;aten_view_453_size_0&#39;] -&gt; [&#39;view_49&#39;]
    258/301: Constant [] -&gt; [&#39;aten_view_455_size_0&#39;]
    259/301: Reshape [&#39;transpose_12&#39;, &#39;aten_view_455_size_0&#39;] -&gt; [&#39;view_43&#39;]
    260/301: Transpose [&#39;view_49&#39;] -&gt; [&#39;t_31&#39;]
    261/301: MatMul [&#39;view_49&#39;, &#39;t_33&#39;] -&gt; [&#39;mm_20&#39;]
    262/301: Constant [] -&gt; [&#39;aten_view_459_size_0&#39;]
    263/301: Reshape [&#39;view_43&#39;, &#39;aten_view_459_size_0&#39;] -&gt; [&#39;view_47&#39;]
    264/301: MatMul [&#39;t_31&#39;, &#39;view_1&#39;] -&gt; [&#39;mm_19&#39;]
    265/301: Constant [] -&gt; [&#39;aten_view_462_size_0&#39;]
    266/301: Reshape [&#39;mm_20&#39;, &#39;aten_view_462_size_0&#39;] -&gt; [&#39;view_50&#39;]
    267/301: Transpose [&#39;view_47&#39;] -&gt; [&#39;t_27&#39;]
    268/301: MatMul [&#39;view_47&#39;, &#39;t_29&#39;] -&gt; [&#39;mm_18&#39;]
    269/301: Transpose [&#39;mm_19&#39;] -&gt; [&#39;t_32&#39;]
    270/301: MatMul [&#39;t_27&#39;, &#39;view_1&#39;] -&gt; [&#39;mm_17&#39;]
    271/301: Constant [] -&gt; [&#39;aten_view_468_size_0&#39;]
    272/301: Reshape [&#39;mm_18&#39;, &#39;aten_view_468_size_0&#39;] -&gt; [&#39;view_48&#39;]
    273/301: Transpose [&#39;t_32&#39;] -&gt; [&#39;t_34&#39;]
    274/301: Transpose [&#39;mm_17&#39;] -&gt; [&#39;t_28&#39;]
    275/301: aten_add|folded_13 [&#39;view_46&#39;, &#39;view_48&#39;] -&gt; [&#39;add_20&#39;]
    276/301: Transpose [&#39;t_28&#39;] -&gt; [&#39;t_30&#39;]
    277/301: aten_add|folded_14 [&#39;add_20&#39;, &#39;view_50&#39;] -&gt; [&#39;add_21&#39;]
    278/301: Mul [&#39;add_21&#39;, &#39;primals_1&#39;] -&gt; [&#39;mul_39&#39;]
    279/301: Mul [&#39;add_21&#39;, &#39;mul&#39;] -&gt; [&#39;mul_40&#39;]
    280/301: Mul [&#39;mul_39&#39;, &#39;embedding&#39;] -&gt; [&#39;mul_41&#39;]
    281/301: Mul [&#39;mul_39&#39;, &#39;rsqrt&#39;] -&gt; [&#39;mul_42&#39;]
    282/301: Constant [] -&gt; [&#39;_val_408&#39;]
    283/301: ReduceSum [&#39;mul_40&#39;, &#39;_val_408&#39;] -&gt; [&#39;sum_6&#39;]
    284/301: Constant [] -&gt; [&#39;_val_410&#39;]
    285/301: ReduceSum [&#39;mul_41&#39;, &#39;_val_410&#39;] -&gt; [&#39;sum_7&#39;]
    286/301: aten_add|folded_15 [&#39;add_13&#39;, &#39;mul_42&#39;] -&gt; [&#39;add_22&#39;]
    287/301: Constant [] -&gt; [&#39;aten_view_484_size_0&#39;]
    288/301: Reshape [&#39;sum_6&#39;, &#39;aten_view_484_size_0&#39;] -&gt; [&#39;view_51&#39;]
    289/301: Constant [] -&gt; [&#39;_val_415&#39;]
    290/301: Mul [&#39;sum_7&#39;, &#39;_val_415&#39;] -&gt; [&#39;mul_43&#39;]
    291/301: Mul [&#39;mul_43&#39;, &#39;pow_8&#39;] -&gt; [&#39;mul_44&#39;]
    292/301: Constant [] -&gt; [&#39;_val_418&#39;]
    293/301: Constant [] -&gt; [&#39;aten_expand_489_size_1&#39;]
    294/301: Expand [&#39;mul_44&#39;, &#39;aten_expand_489_size_1&#39;] -&gt; [&#39;expand_9&#39;]
    295/301: Constant [] -&gt; [&#39;scalar_tensor_default_6&#39;]
    296/301: Div [&#39;expand_9&#39;, &#39;scalar_tensor_default_6&#39;] -&gt; [&#39;div_4&#39;]
    297/301: Mul [&#39;div_4&#39;, &#39;mul_45&#39;] -&gt; [&#39;mul_46&#39;]
    298/301: aten_add|folded_16 [&#39;add_22&#39;, &#39;mul_46&#39;] -&gt; [&#39;add_23&#39;]
    299/301: Constant [] -&gt; [&#39;aten_masked_fill_496_value_cast&#39;]
    300/301: Where [&#39;unsqueeze_9&#39;, &#39;aten_masked_fill_496_value_cast&#39;, &#39;add_23&#39;] -&gt; [&#39;masked_fill_3&#39;]
    301/301: Constant [] -&gt; [&#39;new_zeros_4&#39;]
    
    NODES in {name!r}
    1/228: Gather [&#39;primals_4&#39;, &#39;primals_14&#39;] -&gt; [&#39;embedding&#39;]
    2/228: Constant [] -&gt; [&#39;_val_23&#39;]
    3/228: Constant [] -&gt; [&#39;_val_24&#39;]
    4/228: aten_full [&#39;_val_23&#39;, &#39;_val_24&#39;] -&gt; [&#39;full&#39;]
    5/228: Constant [] -&gt; [&#39;_val_37&#39;]
    6/228: Constant [] -&gt; [&#39;_val_41&#39;]
    7/228: Constant [] -&gt; [&#39;_val_45&#39;]
    8/228: Constant [] -&gt; [&#39;_val_49&#39;]
    9/228: Slice [&#39;primals_15&#39;, &#39;_val_37&#39;, &#39;_val_41&#39;, &#39;_val_45&#39;, &#39;_val_49&#39;] -&gt; [&#39;slice_3&#39;]
    10/228: Transpose [&#39;primals_5&#39;] -&gt; [&#39;t&#39;]
    11/228: Transpose [&#39;primals_6&#39;] -&gt; [&#39;t_1&#39;]
    12/228: Transpose [&#39;primals_7&#39;] -&gt; [&#39;t_2&#39;]
    13/228: Constant [] -&gt; [&#39;_val_57&#39;]
    14/228: Constant [] -&gt; [&#39;_val_61&#39;]
    15/228: Constant [] -&gt; [&#39;_val_65&#39;]
    16/228: Constant [] -&gt; [&#39;_val_69&#39;]
    17/228: Slice [&#39;primals_12&#39;, &#39;_val_57&#39;, &#39;_val_61&#39;, &#39;_val_65&#39;, &#39;_val_69&#39;] -&gt; [&#39;slice_7&#39;]
    18/228: Constant [] -&gt; [&#39;_val_74&#39;]
    19/228: Constant [] -&gt; [&#39;_val_78&#39;]
    20/228: Constant [] -&gt; [&#39;_val_82&#39;]
    21/228: Constant [] -&gt; [&#39;_val_86&#39;]
    22/228: Slice [&#39;primals_13&#39;, &#39;_val_74&#39;, &#39;_val_78&#39;, &#39;_val_82&#39;, &#39;_val_86&#39;] -&gt; [&#39;slice_8&#39;]
    23/228: Transpose [&#39;primals_8&#39;] -&gt; [&#39;t_3&#39;]
    24/228: Transpose [&#39;primals_9&#39;] -&gt; [&#39;t_4&#39;]
    25/228: Transpose [&#39;primals_10&#39;] -&gt; [&#39;t_5&#39;]
    26/228: Transpose [&#39;primals_11&#39;] -&gt; [&#39;t_6&#39;]
    27/228: Constant [] -&gt; [&#39;unsqueeze&#39;]
    28/228: Constant [] -&gt; [&#39;scalar_tensor_default&#39;]
    29/228: Pow [&#39;embedding&#39;, &#39;scalar_tensor_default&#39;] -&gt; [&#39;pow_1&#39;]
    30/228: Constant [] -&gt; [&#39;aten_unsqueeze_178_dim_0&#39;]
    31/228: Unsqueeze [&#39;slice_3&#39;, &#39;aten_unsqueeze_178_dim_0&#39;] -&gt; [&#39;unsqueeze_3&#39;]
    32/228: Transpose [&#39;t&#39;] -&gt; [&#39;t_33&#39;]
    33/228: Transpose [&#39;t_1&#39;] -&gt; [&#39;t_29&#39;]
    34/228: Transpose [&#39;t_2&#39;] -&gt; [&#39;t_25&#39;]
    35/228: Transpose [&#39;t_3&#39;] -&gt; [&#39;t_21&#39;]
    36/228: Transpose [&#39;t_4&#39;] -&gt; [&#39;t_17&#39;]
    37/228: Transpose [&#39;t_5&#39;] -&gt; [&#39;t_13&#39;]
    38/228: Transpose [&#39;t_6&#39;] -&gt; [&#39;t_9&#39;]
    39/228: Transpose [&#39;slice_7&#39;] -&gt; [&#39;_val_106&#39;]
    40/228: Constant [] -&gt; [&#39;_val_112&#39;]
    41/228: GatherND [&#39;_val_106&#39;, &#39;_val_112&#39;] -&gt; [&#39;_val_113&#39;]
    42/228: Transpose [&#39;_val_113&#39;] -&gt; [&#39;index&#39;]
    43/228: Transpose [&#39;slice_8&#39;] -&gt; [&#39;_val_115&#39;]
    44/228: Constant [] -&gt; [&#39;_val_121&#39;]
    45/228: GatherND [&#39;_val_115&#39;, &#39;_val_121&#39;] -&gt; [&#39;_val_122&#39;]
    46/228: Transpose [&#39;_val_122&#39;] -&gt; [&#39;index_1&#39;]
    47/228: Constant [] -&gt; [&#39;_val_124&#39;]
    48/228: ReduceMean [&#39;pow_1&#39;, &#39;_val_124&#39;] -&gt; [&#39;mean&#39;]
    49/228: Constant [] -&gt; [&#39;aten_unsqueeze_208_dim_0&#39;]
    50/228: Unsqueeze [&#39;unsqueeze_3&#39;, &#39;aten_unsqueeze_208_dim_0&#39;] -&gt; [&#39;unsqueeze_4&#39;]
    51/228: Constant [] -&gt; [&#39;aten_unsqueeze_209_dim_0&#39;]
    52/228: Unsqueeze [&#39;index&#39;, &#39;aten_unsqueeze_209_dim_0&#39;] -&gt; [&#39;unsqueeze_7&#39;]
    53/228: Constant [] -&gt; [&#39;aten_unsqueeze_210_dim_0&#39;]
    54/228: Unsqueeze [&#39;index_1&#39;, &#39;aten_unsqueeze_210_dim_0&#39;] -&gt; [&#39;unsqueeze_8&#39;]
    55/228: Constant [] -&gt; [&#39;_val_131&#39;]
    56/228: Constant [] -&gt; [&#39;aten_add_212_other_1&#39;]
    57/228: Add [&#39;mean&#39;, &#39;aten_add_212_other_1&#39;] -&gt; [&#39;add_1&#39;]
    58/228: Constant [] -&gt; [&#39;lt&#39;]
    59/228: Constant [] -&gt; [&#39;_val_137&#39;]
    60/228: Constant [] -&gt; [&#39;_val_141&#39;]
    61/228: Constant [] -&gt; [&#39;_val_145&#39;]
    62/228: Constant [] -&gt; [&#39;_val_149&#39;]
    63/228: Slice [&#39;unsqueeze_4&#39;, &#39;_val_137&#39;, &#39;_val_141&#39;, &#39;_val_145&#39;, &#39;_val_149&#39;] -&gt; [&#39;slice_4&#39;]
    64/228: aten_rsqrt [&#39;add_1&#39;] -&gt; [&#39;rsqrt&#39;]
    65/228: Constant [] -&gt; [&#39;aten_masked_fill_233_value_cast&#39;]
    66/228: Where [&#39;lt&#39;, &#39;aten_masked_fill_233_value_cast&#39;, &#39;full&#39;] -&gt; [&#39;masked_fill&#39;]
    67/228: Constant [] -&gt; [&#39;_val_154&#39;]
    68/228: Constant [] -&gt; [&#39;aten_expand_235_size_1&#39;]
    69/228: Expand [&#39;slice_4&#39;, &#39;aten_expand_235_size_1&#39;] -&gt; [&#39;expand_1&#39;]
    70/228: Mul [&#39;embedding&#39;, &#39;rsqrt&#39;] -&gt; [&#39;mul&#39;]
    71/228: Constant [] -&gt; [&#39;aten_unsqueeze_237_dim_0&#39;]
    72/228: Unsqueeze [&#39;masked_fill&#39;, &#39;aten_unsqueeze_237_dim_0&#39;] -&gt; [&#39;unsqueeze_5&#39;]
    73/228: Constant [] -&gt; [&#39;_val_158&#39;]
    74/228: aten_rsub [&#39;expand_1&#39;, &#39;_val_158&#39;] -&gt; [&#39;rsub&#39;]
    75/228: Mul [&#39;primals_1&#39;, &#39;mul&#39;] -&gt; [&#39;mul_1&#39;]
    76/228: Constant [] -&gt; [&#39;aten_unsqueeze_241_dim_0&#39;]
    77/228: Unsqueeze [&#39;unsqueeze_5&#39;, &#39;aten_unsqueeze_241_dim_0&#39;] -&gt; [&#39;unsqueeze_6&#39;]
    78/228: Cast [&#39;rsub&#39;] -&gt; [&#39;_to_copy&#39;]
    79/228: Constant [] -&gt; [&#39;aten_view_244_size_0&#39;]
    80/228: Reshape [&#39;mul_1&#39;, &#39;aten_view_244_size_0&#39;] -&gt; [&#39;view_1&#39;]
    81/228: Constant [] -&gt; [&#39;_val_168&#39;]
    82/228: Constant [] -&gt; [&#39;_val_172&#39;]
    83/228: Constant [] -&gt; [&#39;_val_176&#39;]
    84/228: Constant [] -&gt; [&#39;_val_180&#39;]
    85/228: Slice [&#39;unsqueeze_6&#39;, &#39;_val_168&#39;, &#39;_val_172&#39;, &#39;_val_176&#39;, &#39;_val_180&#39;] -&gt; [&#39;slice_5&#39;]
    86/228: Constant [] -&gt; [&#39;aten_masked_fill_263_value_cast&#39;]
    87/228: Where [&#39;_to_copy&#39;, &#39;aten_masked_fill_263_value_cast&#39;, &#39;rsub&#39;] -&gt; [&#39;masked_fill_1&#39;]
    88/228: MatMul [&#39;view_1&#39;, &#39;t&#39;] -&gt; [&#39;mm&#39;]
    89/228: MatMul [&#39;view_1&#39;, &#39;t_1&#39;] -&gt; [&#39;mm_1&#39;]
    90/228: MatMul [&#39;view_1&#39;, &#39;t_2&#39;] -&gt; [&#39;mm_2&#39;]
    91/228: Constant [] -&gt; [&#39;_val_190&#39;]
    92/228: Constant [] -&gt; [&#39;_val_194&#39;]
    93/228: Constant [] -&gt; [&#39;_val_198&#39;]
    94/228: Constant [] -&gt; [&#39;_val_202&#39;]
    95/228: Slice [&#39;slice_5&#39;, &#39;_val_190&#39;, &#39;_val_194&#39;, &#39;_val_198&#39;, &#39;_val_202&#39;] -&gt; [&#39;slice_6&#39;]
    96/228: Cast [&#39;masked_fill_1&#39;] -&gt; [&#39;_to_copy_1&#39;]
    97/228: Constant [] -&gt; [&#39;aten_view_286_size_0&#39;]
    98/228: Reshape [&#39;mm&#39;, &#39;aten_view_286_size_0&#39;] -&gt; [&#39;view_2&#39;]
    99/228: Constant [] -&gt; [&#39;aten_view_288_size_0&#39;]
    100/228: Reshape [&#39;mm_1&#39;, &#39;aten_view_288_size_0&#39;] -&gt; [&#39;view_4&#39;]
    101/228: Constant [] -&gt; [&#39;aten_view_290_size_0&#39;]
    102/228: Reshape [&#39;mm_2&#39;, &#39;aten_view_290_size_0&#39;] -&gt; [&#39;view_6&#39;]
    103/228: Constant [] -&gt; [&#39;_val_211&#39;]
    104/228: Constant [] -&gt; [&#39;aten_expand_292_size_1&#39;]
    105/228: Expand [&#39;slice_6&#39;, &#39;aten_expand_292_size_1&#39;] -&gt; [&#39;expand_2&#39;]
    106/228: Constant [] -&gt; [&#39;aten_view_294_size_0&#39;]
    107/228: Reshape [&#39;view_2&#39;, &#39;aten_view_294_size_0&#39;] -&gt; [&#39;view_7&#39;]
    108/228: Constant [] -&gt; [&#39;aten_view_296_size_0&#39;]
    109/228: Reshape [&#39;view_4&#39;, &#39;aten_view_296_size_0&#39;] -&gt; [&#39;view_8&#39;]
    110/228: Constant [] -&gt; [&#39;aten_view_298_size_0&#39;]
    111/228: Reshape [&#39;view_6&#39;, &#39;aten_view_298_size_0&#39;] -&gt; [&#39;view_9&#39;]
    112/228: Constant [] -&gt; [&#39;aten_masked_fill_300_value_cast&#39;]
    113/228: Where [&#39;_to_copy_1&#39;, &#39;aten_masked_fill_300_value_cast&#39;, &#39;expand_2&#39;] -&gt; [&#39;masked_fill_2&#39;]
    114/228: Transpose [&#39;view_7&#39;] -&gt; [&#39;transpose&#39;]
    115/228: Transpose [&#39;view_8&#39;] -&gt; [&#39;transpose_1&#39;]
    116/228: Transpose [&#39;view_9&#39;] -&gt; [&#39;transpose_2&#39;]
    117/228: Mul [&#39;transpose&#39;, &#39;unsqueeze_7&#39;] -&gt; [&#39;mul_2&#39;]
    118/228: Constant [] -&gt; [&#39;_val_228&#39;]
    119/228: Constant [] -&gt; [&#39;_val_232&#39;]
    120/228: Constant [] -&gt; [&#39;_val_236&#39;]
    121/228: Constant [] -&gt; [&#39;_val_240&#39;]
    122/228: Slice [&#39;transpose&#39;, &#39;_val_228&#39;, &#39;_val_232&#39;, &#39;_val_236&#39;, &#39;_val_240&#39;] -&gt; [&#39;slice_9&#39;]
    123/228: Constant [] -&gt; [&#39;_val_245&#39;]
    124/228: Constant [] -&gt; [&#39;_val_249&#39;]
    125/228: Constant [] -&gt; [&#39;_val_253&#39;]
    126/228: Constant [] -&gt; [&#39;_val_257&#39;]
    127/228: Slice [&#39;transpose&#39;, &#39;_val_245&#39;, &#39;_val_249&#39;, &#39;_val_253&#39;, &#39;_val_257&#39;] -&gt; [&#39;slice_10&#39;]
    128/228: Mul [&#39;transpose_1&#39;, &#39;unsqueeze_7&#39;] -&gt; [&#39;mul_4&#39;]
    129/228: Constant [] -&gt; [&#39;_val_263&#39;]
    130/228: Constant [] -&gt; [&#39;_val_267&#39;]
    131/228: Constant [] -&gt; [&#39;_val_271&#39;]
    132/228: Constant [] -&gt; [&#39;_val_275&#39;]
    133/228: Slice [&#39;transpose_1&#39;, &#39;_val_263&#39;, &#39;_val_267&#39;, &#39;_val_271&#39;, &#39;_val_275&#39;] -&gt; [&#39;slice_11&#39;]
    134/228: Constant [] -&gt; [&#39;_val_280&#39;]
    135/228: Constant [] -&gt; [&#39;_val_284&#39;]
    136/228: Constant [] -&gt; [&#39;_val_288&#39;]
    137/228: Constant [] -&gt; [&#39;_val_292&#39;]
    138/228: Slice [&#39;transpose_1&#39;, &#39;_val_280&#39;, &#39;_val_284&#39;, &#39;_val_288&#39;, &#39;_val_292&#39;] -&gt; [&#39;slice_12&#39;]
    139/228: Constant [] -&gt; [&#39;_val_294&#39;]
    140/228: Constant [] -&gt; [&#39;aten_expand_375_size_1&#39;]
    141/228: Expand [&#39;transpose_2&#39;, &#39;aten_expand_375_size_1&#39;] -&gt; [&#39;expand_6&#39;]
    142/228: Neg [&#39;slice_10&#39;] -&gt; [&#39;neg&#39;]
    143/228: Neg [&#39;slice_12&#39;] -&gt; [&#39;neg_1&#39;]
    144/228: Concat [&#39;neg&#39;, &#39;slice_9&#39;] -&gt; [&#39;cat&#39;]
    145/228: Concat [&#39;neg_1&#39;, &#39;slice_11&#39;] -&gt; [&#39;cat_1&#39;]
    146/228: Constant [] -&gt; [&#39;aten_view_384_size_0&#39;]
    147/228: Reshape [&#39;expand_6&#39;, &#39;aten_view_384_size_0&#39;] -&gt; [&#39;view_14&#39;]
    148/228: Mul [&#39;cat&#39;, &#39;unsqueeze_8&#39;] -&gt; [&#39;mul_3&#39;]
    149/228: Mul [&#39;cat_1&#39;, &#39;unsqueeze_8&#39;] -&gt; [&#39;mul_5&#39;]
    150/228: Transpose [&#39;view_14&#39;] -&gt; [&#39;transpose_7&#39;]
    151/228: aten_add|folded_2 [&#39;mul_2&#39;, &#39;mul_3&#39;] -&gt; [&#39;add_2&#39;]
    152/228: aten_add|folded_3 [&#39;mul_4&#39;, &#39;mul_5&#39;] -&gt; [&#39;add_3&#39;]
    153/228: Constant [] -&gt; [&#39;_val_310&#39;]
    154/228: Constant [] -&gt; [&#39;aten_expand_391_size_1&#39;]
    155/228: Expand [&#39;add_2&#39;, &#39;aten_expand_391_size_1&#39;] -&gt; [&#39;expand_3&#39;]
    156/228: Transpose [&#39;add_3&#39;] -&gt; [&#39;transpose_3&#39;]
    157/228: Constant [] -&gt; [&#39;_val_314&#39;]
    158/228: Constant [] -&gt; [&#39;aten_expand_395_size_1&#39;]
    159/228: Expand [&#39;transpose_3&#39;, &#39;aten_expand_395_size_1&#39;] -&gt; [&#39;expand_4&#39;]
    160/228: Constant [] -&gt; [&#39;aten_view_397_size_0&#39;]
    161/228: Reshape [&#39;expand_3&#39;, &#39;aten_view_397_size_0&#39;] -&gt; [&#39;view_10&#39;]
    162/228: Transpose [&#39;view_10&#39;] -&gt; [&#39;transpose_8&#39;]
    163/228: Constant [] -&gt; [&#39;aten_view_401_size_0&#39;]
    164/228: Reshape [&#39;expand_4&#39;, &#39;aten_view_401_size_0&#39;] -&gt; [&#39;view_11&#39;]
    165/228: MatMul [&#39;view_10&#39;, &#39;view_11&#39;] -&gt; [&#39;bmm&#39;]
    166/228: Transpose [&#39;view_11&#39;] -&gt; [&#39;transpose_9&#39;]
    167/228: Constant [] -&gt; [&#39;aten_view_405_size_0&#39;]
    168/228: Reshape [&#39;bmm&#39;, &#39;aten_view_405_size_0&#39;] -&gt; [&#39;view_12&#39;]
    169/228: Constant [] -&gt; [&#39;_val_326&#39;]
    170/228: Div [&#39;view_12&#39;, &#39;_val_326&#39;] -&gt; [&#39;div&#39;]
    171/228: aten_add|folded_4 [&#39;div&#39;, &#39;masked_fill_2&#39;] -&gt; [&#39;add_4&#39;]
    172/228: Softmax [&#39;add_4&#39;] -&gt; [&#39;_softmax&#39;]
    173/228: Constant [] -&gt; [&#39;_val_333&#39;]
    174/228: Constant [] -&gt; [&#39;aten_expand_414_size_1&#39;]
    175/228: Expand [&#39;_softmax&#39;, &#39;aten_expand_414_size_1&#39;] -&gt; [&#39;expand_5&#39;]
    176/228: Constant [] -&gt; [&#39;aten_view_417_size_0&#39;]
    177/228: Reshape [&#39;expand_5&#39;, &#39;aten_view_417_size_0&#39;] -&gt; [&#39;view_13&#39;]
    178/228: Identity [&#39;_softmax&#39;] -&gt; [&#39;detach_13&#39;]
    179/228: MatMul [&#39;view_13&#39;, &#39;view_14&#39;] -&gt; [&#39;bmm_1&#39;]
    180/228: Transpose [&#39;view_13&#39;] -&gt; [&#39;transpose_6&#39;]
    181/228: Constant [] -&gt; [&#39;aten_view_422_size_0&#39;]
    182/228: Reshape [&#39;bmm_1&#39;, &#39;aten_view_422_size_0&#39;] -&gt; [&#39;view_15&#39;]
    183/228: Transpose [&#39;view_15&#39;] -&gt; [&#39;transpose_4&#39;]
    184/228: Constant [] -&gt; [&#39;aten_view_426_size_0&#39;]
    185/228: Reshape [&#39;transpose_4&#39;, &#39;aten_view_426_size_0&#39;] -&gt; [&#39;view_16&#39;]
    186/228: Constant [] -&gt; [&#39;aten_view_428_size_0&#39;]
    187/228: Reshape [&#39;view_16&#39;, &#39;aten_view_428_size_0&#39;] -&gt; [&#39;view_17&#39;]
    188/228: MatMul [&#39;view_17&#39;, &#39;t_3&#39;] -&gt; [&#39;mm_3&#39;]
    189/228: Constant [] -&gt; [&#39;aten_view_431_size_0&#39;]
    190/228: Reshape [&#39;mm_3&#39;, &#39;aten_view_431_size_0&#39;] -&gt; [&#39;view_18&#39;]
    191/228: aten_add|folded_5 [&#39;embedding&#39;, &#39;view_18&#39;] -&gt; [&#39;add_5&#39;]
    192/228: Constant [] -&gt; [&#39;scalar_tensor_default_1&#39;]
    193/228: Pow [&#39;add_5&#39;, &#39;scalar_tensor_default_1&#39;] -&gt; [&#39;pow_2&#39;]
    194/228: Constant [] -&gt; [&#39;_val_356&#39;]
    195/228: ReduceMean [&#39;pow_2&#39;, &#39;_val_356&#39;] -&gt; [&#39;mean_1&#39;]
    196/228: Constant [] -&gt; [&#39;_val_358&#39;]
    197/228: Constant [] -&gt; [&#39;aten_add_439_other_1&#39;]
    198/228: Add [&#39;mean_1&#39;, &#39;aten_add_439_other_1&#39;] -&gt; [&#39;add_6&#39;]
    199/228: aten_rsqrt [&#39;add_6&#39;] -&gt; [&#39;rsqrt_1&#39;]
    200/228: Mul [&#39;add_5&#39;, &#39;rsqrt_1&#39;] -&gt; [&#39;mul_6&#39;]
    201/228: Mul [&#39;primals_2&#39;, &#39;mul_6&#39;] -&gt; [&#39;mul_7&#39;]
    202/228: Constant [] -&gt; [&#39;aten_view_444_size_0&#39;]
    203/228: Reshape [&#39;mul_7&#39;, &#39;aten_view_444_size_0&#39;] -&gt; [&#39;view_19&#39;]
    204/228: MatMul [&#39;view_19&#39;, &#39;t_4&#39;] -&gt; [&#39;mm_4&#39;]
    205/228: MatMul [&#39;view_19&#39;, &#39;t_5&#39;] -&gt; [&#39;mm_5&#39;]
    206/228: Constant [] -&gt; [&#39;aten_view_448_size_0&#39;]
    207/228: Reshape [&#39;mm_4&#39;, &#39;aten_view_448_size_0&#39;] -&gt; [&#39;view_20&#39;]
    208/228: Constant [] -&gt; [&#39;aten_view_450_size_0&#39;]
    209/228: Reshape [&#39;mm_5&#39;, &#39;aten_view_450_size_0&#39;] -&gt; [&#39;view_22&#39;]
    210/228: Sigmoid [&#39;view_20&#39;] -&gt; [&#39;sigmoid&#39;]
    211/228: Mul [&#39;view_20&#39;, &#39;sigmoid&#39;] -&gt; [&#39;mul_8&#39;]
    212/228: Mul [&#39;mul_8&#39;, &#39;view_22&#39;] -&gt; [&#39;mul_9&#39;]
    213/228: Constant [] -&gt; [&#39;aten_view_455_size_0&#39;]
    214/228: Reshape [&#39;mul_9&#39;, &#39;aten_view_455_size_0&#39;] -&gt; [&#39;view_23&#39;]
    215/228: MatMul [&#39;view_23&#39;, &#39;t_6&#39;] -&gt; [&#39;mm_6&#39;]
    216/228: Constant [] -&gt; [&#39;aten_view_458_size_0&#39;]
    217/228: Reshape [&#39;mm_6&#39;, &#39;aten_view_458_size_0&#39;] -&gt; [&#39;view_24&#39;]
    218/228: aten_add|folded_7 [&#39;add_5&#39;, &#39;view_24&#39;] -&gt; [&#39;add_7&#39;]
    219/228: Constant [] -&gt; [&#39;scalar_tensor_default_2&#39;]
    220/228: Pow [&#39;add_7&#39;, &#39;scalar_tensor_default_2&#39;] -&gt; [&#39;pow_3&#39;]
    221/228: Constant [] -&gt; [&#39;_val_383&#39;]
    222/228: ReduceMean [&#39;pow_3&#39;, &#39;_val_383&#39;] -&gt; [&#39;mean_2&#39;]
    223/228: Constant [] -&gt; [&#39;_val_385&#39;]
    224/228: Constant [] -&gt; [&#39;aten_add_466_other_1&#39;]
    225/228: Add [&#39;mean_2&#39;, &#39;aten_add_466_other_1&#39;] -&gt; [&#39;add_8&#39;]
    226/228: aten_rsqrt [&#39;add_8&#39;] -&gt; [&#39;rsqrt_2&#39;]
    227/228: Mul [&#39;add_7&#39;, &#39;rsqrt_2&#39;] -&gt; [&#39;mul_10&#39;]
    228/228: Mul [&#39;primals_3&#39;, &#39;mul_10&#39;] -&gt; [&#39;mul_11&#39;]
    [runpythonerror]
    /home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/exporter.py:136: UserWarning: torch.onnx.dynamo_export only implements opset version 18 for now. If you need to use a different opset version, please register them with register_custom_op.
      warnings.warn(
    W0317 17:45:57.778000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.778000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.778000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.778000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.transpose.int (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.779000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.transpose.int (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.779000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.779000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.779000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.transpose.int (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.779000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.transpose.int (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.779000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.779000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.779000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.779000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.780000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.780000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.780000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.rsqrt.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.780000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.780000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.mean.dim (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.780000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.pow.Tensor_Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.780000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.780000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.781000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.781000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.781000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.781000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.781000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.781000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.781000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.781000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.782000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.sigmoid.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.782000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.782000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.782000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.782000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.782000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.782000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.783000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.rsqrt.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.783000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.783000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.mean.dim (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.783000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.pow.Tensor_Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.783000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.783000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.783000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.783000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.784000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.784000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.784000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.clone.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.784000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.transpose.int (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.784000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.784000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.bmm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.784000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.784000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.clone.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.785000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.expand.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.785000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.785000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.expand.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.785000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.clone.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.785000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.785000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.785000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten._softmax.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.785000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.786000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.div.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.786000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.786000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.bmm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.786000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.786000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.clone.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.786000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.expand.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.786000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.787000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.clone.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.787000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.expand.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.787000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.transpose.int (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.787000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.787000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.787000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.cat.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.787000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.neg.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.787000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.788000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.788000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.788000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.788000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.788000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.cat.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.788000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.neg.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.788000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.789000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.789000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.789000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.unsqueeze.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.789000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.index.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.789000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.unsqueeze.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.789000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.index.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.789000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.790000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.790000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.transpose.int (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.790000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.790000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.transpose.int (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.790000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.790000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.transpose.int (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.790000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.791000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.791000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.791000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.791000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.791000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.791000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.791000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.792000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.792000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.792000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.792000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.792000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.792000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.rsqrt.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.792000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.793000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.mean.dim (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.793000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.pow.Tensor_Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.793000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.masked_fill.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.793000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.expand.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.793000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.793000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.793000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.unsqueeze.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.793000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.unsqueeze.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.794000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten._to_copy.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.794000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.masked_fill.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.794000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten._to_copy.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.794000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.rsub.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.794000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.expand.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.794000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.794000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.unsqueeze.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.795000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.unsqueeze.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.795000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.795000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.masked_fill.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.795000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.lt.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.795000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.795000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.795000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.arange.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.796000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.full.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.796000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.embedding.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.796000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.unsqueeze.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:57.796000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.arange.start (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    2024-03-17 17:45:58,046 onnxrewriter.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue return_val due to large size 4194304.
    2024-03-17 17:45:58,046 onnxrewriter.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue full due to large size 4194304.
    2024-03-17 17:45:58,106 onnxrewriter.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue masked_fill due to large size 4194304.
    2024-03-17 17:45:58,107 onnxrewriter.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue return_val due to large size 4194304.
    2024-03-17 17:45:58,107 onnxrewriter.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue unsqueeze_5 due to large size 4194304.
    2024-03-17 17:45:58,109 onnxrewriter.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue return_val due to large size 4194304.
    2024-03-17 17:45:58,109 onnxrewriter.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue unsqueeze_6 due to large size 4194304.
    2024-03-17 17:45:58,113 onnxrewriter.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue slice_5 due to large size 4194304.
    2024-03-17 17:45:58,116 onnxrewriter.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue slice_6 due to large size 4194304.
    2024-03-17 17:45:58,131 onnxrewriter.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue return_val due to large size 8388608.
    2024-03-17 17:45:58,131 onnxrewriter.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue expand_2 due to large size 8388608.
    2024-03-17 17:45:58,240 onnxrewriter.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue return_val due to large size 4194304.
    2024-03-17 17:45:58,240 onnxrewriter.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue full due to large size 4194304.
    2024-03-17 17:45:58,248 onnxrewriter.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue masked_fill due to large size 4194304.
    2024-03-17 17:45:58,249 onnxrewriter.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue unsqueeze_5 due to large size 4194304.
    2024-03-17 17:45:58,249 onnxrewriter.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue unsqueeze_6 due to large size 4194304.
    2024-03-17 17:45:58,250 onnxrewriter.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue slice_5 due to large size 4194304.
    2024-03-17 17:45:58,251 onnxrewriter.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue slice_6 due to large size 4194304.
    2024-03-17 17:45:58,256 onnxrewriter.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue expand_2 due to large size 8388608.
    [0;93m2024-03-17 17:45:58.329330000 [W:onnxruntime:, graph.cc:3594 CleanUnusedInitializersAndNodeArgs] Removing initializer &#39;_val_333&#39;. It is not used by any node and should be removed from the model.[m
    [0;93m2024-03-17 17:45:58.329380400 [W:onnxruntime:, graph.cc:3594 CleanUnusedInitializersAndNodeArgs] Removing initializer &#39;_val_314&#39;. It is not used by any node and should be removed from the model.[m
    [0;93m2024-03-17 17:45:58.329387300 [W:onnxruntime:, graph.cc:3594 CleanUnusedInitializersAndNodeArgs] Removing initializer &#39;_val_310&#39;. It is not used by any node and should be removed from the model.[m
    [0;93m2024-03-17 17:45:58.329392000 [W:onnxruntime:, graph.cc:3594 CleanUnusedInitializersAndNodeArgs] Removing initializer &#39;_val_131&#39;. It is not used by any node and should be removed from the model.[m
    [0;93m2024-03-17 17:45:58.329395500 [W:onnxruntime:, graph.cc:3594 CleanUnusedInitializersAndNodeArgs] Removing initializer &#39;_val_294&#39;. It is not used by any node and should be removed from the model.[m
    [0;93m2024-03-17 17:45:58.329402100 [W:onnxruntime:, graph.cc:3594 CleanUnusedInitializersAndNodeArgs] Removing initializer &#39;_val_358&#39;. It is not used by any node and should be removed from the model.[m
    [0;93m2024-03-17 17:45:58.329405900 [W:onnxruntime:, graph.cc:3594 CleanUnusedInitializersAndNodeArgs] Removing initializer &#39;_val_211&#39;. It is not used by any node and should be removed from the model.[m
    [0;93m2024-03-17 17:45:58.329408800 [W:onnxruntime:, graph.cc:3594 CleanUnusedInitializersAndNodeArgs] Removing initializer &#39;_val_154&#39;. It is not used by any node and should be removed from the model.[m
    [0;93m2024-03-17 17:45:58.329412400 [W:onnxruntime:, graph.cc:3594 CleanUnusedInitializersAndNodeArgs] Removing initializer &#39;_val_385&#39;. It is not used by any node and should be removed from the model.[m
    W0317 17:45:58.463000 140489313312768 torch/onnx/_internal/onnxruntime.py:201] support_dict and extra_support_dict don&#39;t support node.target: aten._unsafe_index_put.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.464000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.new_zeros.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.464000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.masked_fill.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.464000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.unsqueeze.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.464000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.eq.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.464000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.464000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.464000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.464000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.pow.Tensor_Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.464000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.div.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.465000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.expand.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.465000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.465000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.465000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.pow.Tensor_Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.465000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.465000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.465000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.465000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.sum.dim_IntList (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.466000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.466000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.466000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.466000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.sum.dim_IntList (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.466000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.466000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.466000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.466000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.467000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.467000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.467000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.467000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.467000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.467000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.467000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.467000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.467000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.468000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.468000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.468000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.468000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.468000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.468000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.468000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.468000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.469000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.469000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.469000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.469000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.469000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.469000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.clone.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.469000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.transpose.int (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.469000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.470000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.clone.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.470000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.transpose.int (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.470000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.470000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.clone.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.470000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.transpose.int (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.470000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.470000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.470000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.471000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.slice_scatter.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.471000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.new_zeros.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.471000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.slice_scatter.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.471000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.new_zeros.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.471000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.neg.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.471000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.471000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.471000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.472000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.472000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.472000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.472000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.slice_scatter.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.472000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.new_zeros.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.472000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.slice_scatter.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.472000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.new_zeros.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.472000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.neg.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.473000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.473000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.473000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.473000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.473000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.transpose.int (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.473000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.473000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.474000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.bmm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.474000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.bmm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.474000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.474000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.div.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.474000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.sub.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.474000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.474000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.sum.dim_IntList (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.474000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.475000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.475000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.475000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.475000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.bmm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.475000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.bmm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.475000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.475000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.clone.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.475000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.transpose.int (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.476000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.476000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.476000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.476000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.476000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.476000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.476000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.476000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.477000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.477000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.477000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.477000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.pow.Tensor_Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.477000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.div.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.477000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.expand.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.477000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.478000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.478000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.pow.Tensor_Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.478000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.478000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.478000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.478000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.sum.dim_IntList (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.478000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.479000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.479000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.479000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.sum.dim_IntList (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.479000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.479000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.479000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.479000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.479000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.480000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.480000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.480000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.480000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.480000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.480000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.480000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.481000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.add.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.481000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.481000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.sub.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.481000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.fill.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.481000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.empty_like.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.481000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.481000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.482000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.482000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.482000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.482000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.482000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.482000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.482000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.483000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.483000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.483000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.483000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.483000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.483000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.483000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.484000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.484000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.484000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.484000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.pow.Tensor_Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.484000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.div.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.484000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.expand.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.484000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.485000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.485000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.pow.Tensor_Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.485000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.485000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.485000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.sum.dim_IntList (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.485000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.486000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.486000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.486000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.sum.dim_IntList (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.486000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.486000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.486000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.486000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.487000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.487000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.487000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.487000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.487000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.487000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.487000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.488000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.488000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.488000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.488000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.488000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.unsqueeze.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.488000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.index.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.489000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.unsqueeze.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.489000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.index.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.489000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.489000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.489000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.489000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:45:58.489000 140489313312768 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    [0;93m2024-03-17 17:45:59.283819100 [W:onnxruntime:, graph.cc:3594 CleanUnusedInitializersAndNodeArgs] Removing initializer &#39;_val_360&#39;. It is not used by any node and should be removed from the model.[m
    [0;93m2024-03-17 17:45:59.283876800 [W:onnxruntime:, graph.cc:3594 CleanUnusedInitializersAndNodeArgs] Removing initializer &#39;_val_359&#39;. It is not used by any node and should be removed from the model.[m
    [0;93m2024-03-17 17:45:59.283883900 [W:onnxruntime:, graph.cc:3594 CleanUnusedInitializersAndNodeArgs] Removing initializer &#39;_val_358&#39;. It is not used by any node and should be removed from the model.[m
    [0;93m2024-03-17 17:45:59.283888000 [W:onnxruntime:, graph.cc:3594 CleanUnusedInitializersAndNodeArgs] Removing initializer &#39;_val_352&#39;. It is not used by any node and should be removed from the model.[m
    [0;93m2024-03-17 17:45:59.283891800 [W:onnxruntime:, graph.cc:3594 CleanUnusedInitializersAndNodeArgs] Removing initializer &#39;_val_353&#39;. It is not used by any node and should be removed from the model.[m
    [0;93m2024-03-17 17:45:59.283895900 [W:onnxruntime:, graph.cc:3594 CleanUnusedInitializersAndNodeArgs] Removing initializer &#39;_val_366&#39;. It is not used by any node and should be removed from the model.[m
    [0;93m2024-03-17 17:45:59.283899300 [W:onnxruntime:, graph.cc:3594 CleanUnusedInitializersAndNodeArgs] Removing initializer &#39;_val_364&#39;. It is not used by any node and should be removed from the model.[m
    [0;93m2024-03-17 17:45:59.283904700 [W:onnxruntime:, graph.cc:3594 CleanUnusedInitializersAndNodeArgs] Removing initializer &#39;_val_163&#39;. It is not used by any node and should be removed from the model.[m
    [0;93m2024-03-17 17:45:59.283909700 [W:onnxruntime:, graph.cc:3594 CleanUnusedInitializersAndNodeArgs] Removing initializer &#39;_val_369&#39;. It is not used by any node and should be removed from the model.[m
    [0;93m2024-03-17 17:45:59.283914700 [W:onnxruntime:, graph.cc:3594 CleanUnusedInitializersAndNodeArgs] Removing initializer &#39;_val_370&#39;. It is not used by any node and should be removed from the model.[m
    [0;93m2024-03-17 17:45:59.283918900 [W:onnxruntime:, graph.cc:3594 CleanUnusedInitializersAndNodeArgs] Removing initializer &#39;_val_365&#39;. It is not used by any node and should be removed from the model.[m
    [0;93m2024-03-17 17:45:59.283923400 [W:onnxruntime:, graph.cc:3594 CleanUnusedInitializersAndNodeArgs] Removing initializer &#39;_val_351&#39;. It is not used by any node and should be removed from the model.[m
    [0;93m2024-03-17 17:45:59.283927100 [W:onnxruntime:, graph.cc:3594 CleanUnusedInitializersAndNodeArgs] Removing initializer &#39;_val_371&#39;. It is not used by any node and should be removed from the model.[m
    [0;93m2024-03-17 17:45:59.283930400 [W:onnxruntime:, graph.cc:3594 CleanUnusedInitializersAndNodeArgs] Removing initializer &#39;scalar_tensor_default_3&#39;. It is not used by any node and should be removed from the model.[m
    [0;93m2024-03-17 17:45:59.283935100 [W:onnxruntime:, graph.cc:3594 CleanUnusedInitializersAndNodeArgs] Removing initializer &#39;_val_215&#39;. It is not used by any node and should be removed from the model.[m
    [0;93m2024-03-17 17:45:59.283938600 [W:onnxruntime:, graph.cc:3594 CleanUnusedInitializersAndNodeArgs] Removing initializer &#39;_val_418&#39;. It is not used by any node and should be removed from the model.[m
</pre></div>
</div>
</section>
<section id="with-the-custom-exporter">
<h3>With the custom exporter<a class="headerlink" href="#with-the-custom-exporter" title="Link to this heading">#</a></h3>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">onnx</span>

<span class="c1"># from onnx_array_api.plotting.text_plot import onnx_simple_text_plot</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.onnx</span>
<span class="kn">from</span> <span class="nn">experimental_experiment.torch_helper.training_helper</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">make_aot_ort</span><span class="p">,</span>
    <span class="n">train_loop</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">experimental_experiment.torch_helper.dump_helper</span> <span class="kn">import</span> <span class="n">dump_onnx</span>

<span class="c1"># from experimental_experiment.torch_interpreter import to_onnx</span>

<span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
    <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">LlamaConfig</span>
    <span class="kn">from</span> <span class="nn">transformers.models.llama.modeling_llama</span> <span class="kn">import</span> <span class="n">LlamaModel</span>


<span class="k">def</span> <span class="nf">ids_tensor</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">):</span>
    <span class="n">total_dims</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="n">shape</span><span class="p">:</span>
        <span class="n">total_dims</span> <span class="o">*=</span> <span class="n">dim</span>

    <span class="n">values</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">total_dims</span><span class="p">):</span>
        <span class="n">values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">vocab_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>


<span class="n">config</span> <span class="o">=</span> <span class="n">LlamaConfig</span><span class="p">(</span>
    <span class="n">hidden_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">num_hidden_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">vocab_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
    <span class="n">intermediate_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">max_position_embeddings</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
    <span class="n">num_attention_heads</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">config</span><span class="o">.</span><span class="n">_attn_implementation</span> <span class="o">=</span> <span class="s2">&quot;eager&quot;</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">LlamaModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

<span class="n">batch</span><span class="p">,</span> <span class="n">seq</span><span class="p">,</span> <span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span>

<span class="n">input_ids</span> <span class="o">=</span> <span class="n">ids_tensor</span><span class="p">([</span><span class="n">batch</span><span class="p">,</span> <span class="n">seq</span><span class="p">],</span> <span class="n">vocab_size</span><span class="p">)</span>
<span class="n">input_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tril</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">seq</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

<span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">input_mask</span><span class="p">)</span>

<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;ONNXRT_CHANGE_REWRITER&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;1&quot;</span>

<span class="n">local_aot_ort</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">make_aot_ort</span><span class="p">(</span>
    <span class="n">dynamic</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">rewrite</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>

<span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
    <span class="n">optimized_mod</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="n">local_aot_ort</span><span class="p">,</span> <span class="n">fullgraph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">dump_onnx</span><span class="p">(</span><span class="s2">&quot;dort-llama-ort&quot;</span><span class="p">,</span> <span class="n">folder</span><span class="o">=</span><span class="s2">&quot;dump_llama&quot;</span><span class="p">,</span> <span class="n">clean</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="n">train_loop</span><span class="p">(</span><span class="n">optimized_mod</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">input_mask</span><span class="p">)</span>

<span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="n">_</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s2">&quot;dump_llama&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">_</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.onnx&quot;</span><span class="p">)]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------------------------&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;exported model: </span><span class="si">{</span><span class="n">names</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">names</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;NODES in </span><span class="si">{name!r}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">onx</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">&quot;dump_llama&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">node</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">onx</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">onx</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="p">)</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">node</span><span class="o">.</span><span class="n">op_type</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="si">}</span><span class="s2"> -&gt; </span><span class="si">{</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;ONNXRT_CHANGE_REWRITER&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;0&quot;</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    [to_onnx] build the graph module
    [_make_builder_interpreter] use existing &lt;class &#39;torch.fx.graph_module.GraphModule.__new__.&lt;locals&gt;.GraphModuleImpl&#39;&gt;
    [to_onnx] graph module done in 0.00224779999916791 s
    [to_onnx] start creating the onnx nodes
    [GraphBuilder-RXO.make_tensor_input] input0[1:(1024, 16)]
    [GraphBuilder-RXO.make_tensor_input] input1[7:(2, 1024)]
    [GraphBuilder-RXO.make_tensor_input] input2[1:(2, 1024)]
    [GraphBuilder-RXO.make_tensor_input] input3[1:(16, 16)]
    [GraphBuilder-RXO.make_tensor_input] input4[1:(16, 16)]
    [GraphBuilder-RXO.make_tensor_input] input5[1:(16, 16)]
    [GraphBuilder-RXO.make_tensor_input] input6[1:(1024, 8)]
    [GraphBuilder-RXO.make_tensor_input] input7[1:(1024, 8)]
    [GraphBuilder-RXO.make_tensor_input] input8[1:(16, 16)]
    [GraphBuilder-RXO.make_tensor_input] input9[1:(16, 16)]
    [GraphBuilder-RXO.make_tensor_input] input10[1:(16, 16)]
    [GraphBuilder-RXO.make_tensor_input] input11[1:(16, 16)]
    [GraphBuilder-RXO.make_tensor_input] input12[1:(16,)]
    [GraphBuilder-RXO.make_tensor_input] input13[1:(16,)]
    [GraphBuilder-RXO.make_tensor_input] input14[1:(16,)]
    [GraphBuilder-RXO.make_tensor_output] output_0[1:(2, 1024, 16)]
    [GraphBuilder-RXO.make_tensor_output] output_1[7:(1, 1024)]
    [GraphBuilder-RXO.make_tensor_output] output_2[1:(16, 16)]
    [GraphBuilder-RXO.make_tensor_output] output_3[1:(16, 16)]
    [GraphBuilder-RXO.make_tensor_output] output_4[1:(16, 16)]
    [GraphBuilder-RXO.make_tensor_output] output_5[1:(16, 16)]
    [GraphBuilder-RXO.make_tensor_output] output_6[1:(16, 16)]
    [GraphBuilder-RXO.make_tensor_output] output_7[1:(16, 16)]
    [GraphBuilder-RXO.make_tensor_output] output_8[1:(16, 16)]
    [GraphBuilder-RXO.make_tensor_output] output_9[1:(2, 1024, 1)]
    [GraphBuilder-RXO.make_tensor_output] output_10[1:(2048, 16)]
    [GraphBuilder-RXO.make_tensor_output] output_11[1:(2, 2, 1024, 8)]
    [GraphBuilder-RXO.make_tensor_output] output_12[1:(4, 8, 1024)]
    [GraphBuilder-RXO.make_tensor_output] output_13[1:(2, 2, 1024, 8)]
    [GraphBuilder-RXO.make_tensor_output] output_14[1:(4, 8, 1024)]
    [GraphBuilder-RXO.make_tensor_output] output_15[1:(4, 1024, 8)]
    [GraphBuilder-RXO.make_tensor_output] output_16[1:(2, 2, 1024, 1024)]
    [GraphBuilder-RXO.make_tensor_output] output_17[1:(4, 1024, 1024)]
    [GraphBuilder-RXO.make_tensor_output] output_18[1:(2048, 16)]
    [GraphBuilder-RXO.make_tensor_output] output_19[1:(2048, 16)]
    [GraphBuilder-RXO.make_tensor_output] output_20[1:(2, 1024, 1)]
    [GraphBuilder-RXO.make_tensor_output] output_21[1:(2048, 16)]
    [GraphBuilder-RXO.make_tensor_output] output_22[1:(2048, 16)]
    [GraphBuilder-RXO.make_tensor_output] output_23[1:(2048, 16)]
    [GraphBuilder-RXO.make_tensor_output] output_24[1:(2, 1024, 16)]
    [GraphBuilder-RXO.make_tensor_output] output_25[1:(2048, 16)]
    [GraphBuilder-RXO.make_tensor_output] output_26[1:(2048, 16)]
    [GraphBuilder-RXO.make_tensor_output] output_27[1:(2, 1024, 1)]
    [GraphBuilder-RXO.make_tensor_output] output_28[1:(2, 1024, 16)]
    [to_onnx] onnx nodes done in 0.0592940999995335 s
    [to_onnx] start conversion to onnx (before optimization)
    [GraphBuilderPatternOptimization.optimize] start with 127 nodes and 16 patterns
    [GraphBuilderPatternOptimization.optimize] use pattern 1/16 - CastPattern
    [GraphBuilderPatternOptimization.optimize] use pattern 2/16 - ExpandPattern
    [GraphBuilderPatternOptimization.optimize] use pattern 3/16 - ExpandBroadcastPattern
    [GraphBuilderPatternOptimization.optimize] use pattern 4/16 - ExpandSwapPattern
    [GraphBuilderPatternOptimization.optimize] use pattern 5/16 - MulMulMulScalarPattern
    [GraphBuilderPatternOptimization.optimize] use pattern 6/16 - ReduceReshapePattern
    [GraphBuilderPatternOptimization.optimize] use pattern 7/16 - ReshapeMatMulReshapePattern
    [GraphBuilderPatternOptimization.optimize] use pattern 8/16 - Reshape2Of3Pattern
    [GraphBuilderPatternOptimization.optimize] use pattern 9/16 - MatMulReshape2Of3Pattern
    [GraphBuilderPatternOptimization.optimize] use pattern 10/16 - ReshapeReshapePattern
    [GraphBuilderPatternOptimization.optimize] use pattern 11/16 - RotaryConcatPartPattern
    [GraphBuilderPatternOptimization.optimize] use pattern 12/16 - Sub1MulPattern
    [GraphBuilderPatternOptimization.optimize] use pattern 13/16 - TransposeMatMulPattern
    [GraphBuilderPatternOptimization.optimize] use pattern 14/16 - TransposeReshapeMatMulPattern
    [GraphBuilderPatternOptimization.optimize] use pattern 15/16 - TransposeTransposePattern
    [GraphBuilderPatternOptimization.optimize] use pattern 16/16 - UnsqueezeUnsqueezePattern
    [GraphBuilderPatternOptimization.optimize] iteration 0: 127 nodes
    [GraphBuilderPatternOptimization.optimize] applies 20 matches, [0]=MatchResult: ExpandPattern replaces [&#39;Expand&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 1: 113 nodes
    [GraphBuilderPatternOptimization.optimize] applies 1 matches, [0]=MatchResult: Reshape2Of3Pattern replaces [&#39;Reshape&#39;, &#39;Reshape&#39;, &#39;Mul&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 2: 113 nodes
    [GraphBuilderPatternOptimization.optimize] applies 1 matches, [0]=MatchResult: TransposeMatMulPattern replaces [&#39;Transpose&#39;, &#39;MatMul&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 3: 112 nodes
    [GraphBuilderPatternOptimization.optimize] applies 1 matches, [0]=MatchResult: TransposeMatMulPattern replaces [&#39;Transpose&#39;, &#39;MatMul&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 4: 111 nodes
    [GraphBuilderPatternOptimization.optimize] applies 1 matches, [0]=MatchResult: TransposeMatMulPattern replaces [&#39;Transpose&#39;, &#39;MatMul&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 5: 110 nodes
    [GraphBuilderPatternOptimization.optimize] applies 1 matches, [0]=MatchResult: TransposeMatMulPattern replaces [&#39;Transpose&#39;, &#39;MatMul&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 6: 109 nodes
    [GraphBuilderPatternOptimization.optimize] applies 1 matches, [0]=MatchResult: TransposeMatMulPattern replaces [&#39;Transpose&#39;, &#39;MatMul&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 7: 108 nodes
    [GraphBuilderPatternOptimization.optimize] applies 1 matches, [0]=MatchResult: TransposeMatMulPattern replaces [&#39;Transpose&#39;, &#39;MatMul&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 8: 107 nodes
    [GraphBuilderPatternOptimization.optimize] applies 1 matches, [0]=MatchResult: TransposeMatMulPattern replaces [&#39;Transpose&#39;, &#39;MatMul&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 9: 106 nodes
    [GraphBuilderPatternOptimization.optimize] done after 10 iterations with 106 nodes in 0.029
    [GraphBuilder-RXO.to_onnx] make_model
    [GraphBuilder-RXO._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s_0:int64[()]
    [GraphBuilder-RXO._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s_1024:int64[()]
    [GraphBuilder-RXO._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s_1:int64[()]
    [GraphBuilder-RXO._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s2_1024_1024:int64[(2,)]
    [GraphBuilder-RXO._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s1_0:int64[(1,)]
    [GraphBuilder-RXO._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s1_1024:int64[(1,)]
    [GraphBuilder-RXO._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s1_:float32[(1,)]
    [GraphBuilder-RXO._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s1_1:int64[(1,)]
    [GraphBuilder-RXO._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s1_-1:int64[(1,)]
    [GraphBuilder-RXO._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s2_1024_1:int64[(2,)]
    [GraphBuilder-RXO._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s_:float32[()]
    [GraphBuilder-RXO._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s1_2:float32[(1,)]
    [GraphBuilder-RXO._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s4_2_1_1024_1024:int64[(4,)]
    [GraphBuilder-RXO._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s_2:float32[()]
    [GraphBuilder-RXO._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s2_2048_16:int64[(2,)]
    [GraphBuilder-RXO._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s1_3:float32[(1,)]
    [GraphBuilder-RXO._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s3_2_1024_16:int64[(3,)]
    [GraphBuilder-RXO._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s4_2_1024_2_8:int64[(4,)]
    [GraphBuilder-RXO._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s1_4:float32[(1,)]
    [GraphBuilder-RXO._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s1_4:int64[(1,)]
    [GraphBuilder-RXO._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s1_3:int64[(1,)]
    [GraphBuilder-RXO._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s1_9223372036854775807:int64[(1,)]
    [GraphBuilder-RXO._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s3_4_1024_8:int64[(3,)]
    [GraphBuilder-RXO._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s3_4_8_1024:int64[(3,)]
    [GraphBuilder-RXO._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s_3:float32[()]
    [GraphBuilder-RXO._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s3_4_1024_1024:int64[(3,)]
    [GraphBuilder-RXO._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s1_5:float32[(1,)]
    [GraphBuilder-RXO._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s_4:float32[()]
    [GraphBuilder-RXO._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s1_6:float32[(1,)]
    [GraphBuilder-RXO._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s_5:float32[()]
    [GraphBuilder-RXO._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s2_1_2:int64[(2,)]
    [GraphBuilder-RXO._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s2_0_1:int64[(2,)]
    [to_onnx] to_onnx done in 0.03358300000036252 s
    [to_onnx] build the graph module
    [_make_builder_interpreter] use existing &lt;class &#39;torch.fx.graph_module.GraphModule.__new__.&lt;locals&gt;.GraphModuleImpl&#39;&gt;
    [to_onnx] graph module done in 6.439999924623407e-05 s
    [to_onnx] start creating the onnx nodes
    [GraphBuilder-LWI.make_tensor_input] input0[1:(2, 1024, 1)]
    [GraphBuilder-LWI.make_tensor_input] input1[1:(2, 1024, 16)]
    [GraphBuilder-LWI.make_tensor_input] input2[1:(1024, 8)]
    [GraphBuilder-LWI.make_tensor_input] input3[1:(1024, 8)]
    [GraphBuilder-LWI.make_tensor_input] input4[1:(2048, 16)]
    [GraphBuilder-LWI.make_tensor_input] input5[1:(2, 1024, 1)]
    [GraphBuilder-LWI.make_tensor_input] input6[1:(2048, 16)]
    [GraphBuilder-LWI.make_tensor_input] input7[1:(2048, 16)]
    [GraphBuilder-LWI.make_tensor_input] input8[1:(2048, 16)]
    [GraphBuilder-LWI.make_tensor_input] input9[1:(2, 1024, 1)]
    [GraphBuilder-LWI.make_tensor_input] input10[1:(2, 1024, 16)]
    [GraphBuilder-LWI.make_tensor_input] input11[1:(16,)]
    [GraphBuilder-LWI.make_tensor_input] input12[1:(2, 1024, 16)]
    [GraphBuilder-LWI.make_tensor_input] input13[7:(2, 1024)]
    [GraphBuilder-LWI.make_tensor_input] input14[7:(1, 1024)]
    [GraphBuilder-LWI.make_tensor_input] input15[1:(16, 16)]
    [GraphBuilder-LWI.make_tensor_input] input16[1:(2048, 16)]
    [GraphBuilder-LWI.make_tensor_input] input17[1:(16, 16)]
    [GraphBuilder-LWI.make_tensor_input] input18[1:(2048, 16)]
    [GraphBuilder-LWI.make_tensor_input] input19[1:(16, 16)]
    [GraphBuilder-LWI.make_tensor_input] input20[1:(16,)]
    [GraphBuilder-LWI.make_tensor_input] input21[1:(16, 16)]
    [GraphBuilder-LWI.make_tensor_input] input22[1:(2048, 16)]
    [GraphBuilder-LWI.make_tensor_input] input23[1:(4, 1024, 1024)]
    [GraphBuilder-LWI.make_tensor_input] input24[1:(4, 8, 1024)]
    [GraphBuilder-LWI.make_tensor_input] input25[1:(2, 2, 1024, 8)]
    [GraphBuilder-LWI.make_tensor_input] input26[1:(2, 2, 1024, 1024)]
    [GraphBuilder-LWI.make_tensor_input] input27[1:(16, 16)]
    [GraphBuilder-LWI.make_tensor_input] input28[1:(2048, 16)]
    [GraphBuilder-LWI.make_tensor_input] input29[1:(4, 8, 1024)]
    [GraphBuilder-LWI.make_tensor_input] input30[1:(4, 1024, 8)]
    [GraphBuilder-LWI.make_tensor_input] input31[1:(2, 2, 1024, 8)]
    [GraphBuilder-LWI.make_tensor_input] input32[1:(16, 16)]
    [GraphBuilder-LWI.make_tensor_input] input33[1:(16, 16)]
    [GraphBuilder-LWI.make_tensor_input] input34[1:(16,)]
    [GraphBuilder-LWI.make_tensor_output] output_0[1:(16,)]
    [GraphBuilder-LWI.make_tensor_output] output_1[1:(16, 16)]
    [GraphBuilder-LWI.make_tensor_output] output_2[1:(16, 16)]
    [GraphBuilder-LWI.make_tensor_output] output_3[1:(16, 16)]
    [GraphBuilder-LWI.make_tensor_output] output_4[1:(16,)]
    [GraphBuilder-LWI.make_tensor_output] output_5[1:(16, 16)]
    [GraphBuilder-LWI.make_tensor_output] output_6[1:(16, 16)]
    [GraphBuilder-LWI.make_tensor_output] output_7[1:(16, 16)]
    [GraphBuilder-LWI.make_tensor_output] output_8[1:(16, 16)]
    [GraphBuilder-LWI.make_tensor_output] output_9[1:(16,)]
    [GraphBuilder-LWI.make_tensor_output] output_10[1:(2, 1024, 16)]
    [GraphBuilder-LWI.make_tensor_output] output_11[1:(1024, 16)]
    [to_onnx] onnx nodes done in 0.032100500000524335 s
    [to_onnx] start conversion to onnx (before optimization)
    [GraphBuilderPatternOptimization.optimize] start with 190 nodes and 16 patterns
    [GraphBuilderPatternOptimization.optimize] use pattern 1/16 - CastPattern
    [GraphBuilderPatternOptimization.optimize] use pattern 2/16 - ExpandPattern
    [GraphBuilderPatternOptimization.optimize] use pattern 3/16 - ExpandBroadcastPattern
    [GraphBuilderPatternOptimization.optimize] use pattern 4/16 - ExpandSwapPattern
    [GraphBuilderPatternOptimization.optimize] use pattern 5/16 - MulMulMulScalarPattern
    [GraphBuilderPatternOptimization.optimize] use pattern 6/16 - ReduceReshapePattern
    [GraphBuilderPatternOptimization.optimize] use pattern 7/16 - ReshapeMatMulReshapePattern
    [GraphBuilderPatternOptimization.optimize] use pattern 8/16 - Reshape2Of3Pattern
    [GraphBuilderPatternOptimization.optimize] use pattern 9/16 - MatMulReshape2Of3Pattern
    [GraphBuilderPatternOptimization.optimize] use pattern 10/16 - ReshapeReshapePattern
    [GraphBuilderPatternOptimization.optimize] use pattern 11/16 - RotaryConcatPartPattern
    [GraphBuilderPatternOptimization.optimize] use pattern 12/16 - Sub1MulPattern
    [GraphBuilderPatternOptimization.optimize] use pattern 13/16 - TransposeMatMulPattern
    [GraphBuilderPatternOptimization.optimize] use pattern 14/16 - TransposeReshapeMatMulPattern
    [GraphBuilderPatternOptimization.optimize] use pattern 15/16 - TransposeTransposePattern
    [GraphBuilderPatternOptimization.optimize] use pattern 16/16 - UnsqueezeUnsqueezePattern
    [GraphBuilderPatternOptimization.optimize] iteration 0: 190 nodes
    [GraphBuilderPatternOptimization.optimize] applies 25 matches, [0]=MatchResult: CastPattern replaces [&#39;Cast&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 1: 159 nodes
    [GraphBuilderPatternOptimization.optimize] applies 4 matches, [0]=MatchResult: MulMulMulScalarPattern replaces [&#39;Mul&#39;, &#39;Div&#39;, &#39;Mul&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 2: 156 nodes
    [GraphBuilderPatternOptimization.optimize] applies 4 matches, [0]=MatchResult: ExpandBroadcastPattern replaces [&#39;Expand&#39;, &#39;Mul&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 3: 152 nodes
    [GraphBuilderPatternOptimization.optimize] applies 1 matches, [0]=MatchResult: Reshape2Of3Pattern replaces [&#39;Reshape&#39;, &#39;Reshape&#39;, &#39;Mul&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 4: 151 nodes
    [GraphBuilderPatternOptimization.optimize] applies 1 matches, [0]=MatchResult: Reshape2Of3Pattern replaces [&#39;Reshape&#39;, &#39;Reshape&#39;, &#39;Add&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 5: 150 nodes
    [GraphBuilderPatternOptimization.optimize] applies 1 matches, [0]=MatchResult: MatMulReshape2Of3Pattern replaces [&#39;Reshape&#39;, &#39;MatMul&#39;, &#39;Reshape&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 6: 150 nodes
    [GraphBuilderPatternOptimization.optimize] applies 1 matches, [0]=MatchResult: MatMulReshape2Of3Pattern replaces [&#39;Reshape&#39;, &#39;MatMul&#39;, &#39;Reshape&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 7: 149 nodes
    [GraphBuilderPatternOptimization.optimize] applies 1 matches, [0]=MatchResult: MatMulReshape2Of3Pattern replaces [&#39;Reshape&#39;, &#39;MatMul&#39;, &#39;Reshape&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 8: 149 nodes
    [GraphBuilderPatternOptimization.optimize] applies 1 matches, [0]=MatchResult: MatMulReshape2Of3Pattern replaces [&#39;Reshape&#39;, &#39;MatMul&#39;, &#39;Reshape&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 9: 148 nodes
    [GraphBuilderPatternOptimization.optimize] applies 1 matches, [0]=MatchResult: TransposeMatMulPattern replaces [&#39;Transpose&#39;, &#39;MatMul&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 10: 147 nodes
    [GraphBuilderPatternOptimization.optimize] applies 1 matches, [0]=MatchResult: TransposeMatMulPattern replaces [&#39;Transpose&#39;, &#39;MatMul&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 11: 146 nodes
    [GraphBuilderPatternOptimization.optimize] applies 1 matches, [0]=MatchResult: TransposeMatMulPattern replaces [&#39;Transpose&#39;, &#39;MatMul&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 12: 145 nodes
    [GraphBuilderPatternOptimization.optimize] applies 1 matches, [0]=MatchResult: TransposeMatMulPattern replaces [&#39;Transpose&#39;, &#39;MatMul&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 13: 144 nodes
    [GraphBuilderPatternOptimization.optimize] applies 1 matches, [0]=MatchResult: TransposeMatMulPattern replaces [&#39;Transpose&#39;, &#39;MatMul&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 14: 143 nodes
    [GraphBuilderPatternOptimization.optimize] applies 1 matches, [0]=MatchResult: TransposeMatMulPattern replaces [&#39;Transpose&#39;, &#39;MatMul&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 15: 142 nodes
    [GraphBuilderPatternOptimization.optimize] applies 1 matches, [0]=MatchResult: TransposeMatMulPattern replaces [&#39;Transpose&#39;, &#39;MatMul&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 16: 141 nodes
    [GraphBuilderPatternOptimization.optimize] done after 17 iterations with 141 nodes in 0.073
    [GraphBuilder-LWI.to_onnx] make_model
    [GraphBuilder-LWI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s1_0:int64[(1,)]
    [GraphBuilder-LWI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s1_1024:int64[(1,)]
    [GraphBuilder-LWI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s3_2_1024_16:int64[(3,)]
    [GraphBuilder-LWI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s_-1:int64[()]
    [GraphBuilder-LWI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s1_-1:int64[(1,)]
    [GraphBuilder-LWI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s1_1:int64[(1,)]
    [GraphBuilder-LWI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s1_:float32[(1,)]
    [GraphBuilder-LWI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s1_2:int64[(1,)]
    [GraphBuilder-LWI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s1_2:float32[(1,)]
    [GraphBuilder-LWI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s1_3:float32[(1,)]
    [GraphBuilder-LWI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s_4:float32[()]
    [GraphBuilder-LWI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s2_0_1:int64[(2,)]
    [GraphBuilder-LWI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s_5:float32[()]
    [GraphBuilder-LWI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s2_2048_16:int64[(2,)]
    [GraphBuilder-LWI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s_7:float32[()]
    [GraphBuilder-LWI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s4_2_1024_2_8:int64[(4,)]
    [GraphBuilder-LWI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s4_2_2_1024_8:int64[(4,)]
    [GraphBuilder-LWI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s4_2_2_1024_1024:int64[(4,)]
    [GraphBuilder-LWI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s_9:float32[()]
    [GraphBuilder-LWI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s4_2_2_8_1024:int64[(4,)]
    [GraphBuilder-LWI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s1_4:int64[(1,)]
    [GraphBuilder-LWI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s1_3:int64[(1,)]
    [GraphBuilder-LWI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s1_8:int64[(1,)]
    [GraphBuilder-LWI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s4_0_1_2_3:int64[(4,)]
    [GraphBuilder-LWI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s4_4_5_6_7:int64[(4,)]
    [GraphBuilder-LWI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s_10:float32[()]
    [GraphBuilder-LWI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s1_4:float32[(1,)]
    [GraphBuilder-LWI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s2_1024_16:int64[(2,)]
    [GraphBuilder-LWI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s_12:float32[()]
    [GraphBuilder-LWI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s_13:float32[()]
    [GraphBuilder-LWI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s_14:float32[()]
    [to_onnx] to_onnx done in 0.07785279999916384 s
    ------------------------------------------
    exported model: [&#39;dort-llama-ort_1.onnx&#39;, &#39;dort-llama-ort_0.onnx&#39;]
    
    NODES in {name!r}
    1/140: Reshape [&#39;input30&#39;, &#39;init7_s4_2_2_1024_8&#39;] -&gt; [&#39;typeL_view_39&#39;]
    2/140: Reshape [&#39;input29&#39;, &#39;init7_s4_2_2_8_1024&#39;] -&gt; [&#39;typeL_input29&#39;]
    3/140: Reshape [&#39;input24&#39;, &#39;init7_s4_2_2_8_1024&#39;] -&gt; [&#39;typeL_view_36&#39;]
    4/140: Reshape [&#39;input23&#39;, &#39;init7_s4_2_2_1024_1024&#39;] -&gt; [&#39;typeL_input23&#39;]
    5/140: Reshape [&#39;input6&#39;, &#39;init7_s3_2_1024_16&#39;] -&gt; [&#39;view_20&#39;]
    6/140: Reshape [&#39;input12&#39;, &#39;init7_s2_2048_16&#39;] -&gt; [&#39;typeR_input12&#39;]
    7/140: Mul [&#39;input6&#39;, &#39;typeR_input12&#39;] -&gt; [&#39;typeR_mul_8&#39;]
    8/140: Mul [&#39;view_20&#39;, &#39;input12&#39;] -&gt; [&#39;type--mul_22&#39;]
    9/140: Sub [&#39;view_20&#39;, &#39;type--mul_22&#39;] -&gt; [&#39;mul_22&#39;]
    10/140: Mul [&#39;input1&#39;, &#39;input0&#39;] -&gt; [&#39;mul&#39;]
    11/140: Slice [&#39;input2&#39;, &#39;init7_s1_0&#39;, &#39;init7_s1_1024&#39;, &#39;init7_s1_0&#39;] -&gt; [&#39;slice_7&#39;]
    12/140: Slice [&#39;input3&#39;, &#39;init7_s1_0&#39;, &#39;init7_s1_1024&#39;, &#39;init7_s1_0&#39;] -&gt; [&#39;slice_8&#39;]
    13/140: Reshape [&#39;input4&#39;, &#39;init7_s3_2_1024_16&#39;] -&gt; [&#39;view_18&#39;]
    14/140: Reshape [&#39;input8&#39;, &#39;init7_s3_2_1024_16&#39;] -&gt; [&#39;view_24&#39;]
    15/140: Mul [&#39;input10&#39;, &#39;input11&#39;] -&gt; [&#39;mul_12&#39;]
    16/140: Equal [&#39;input13&#39;, &#39;init7_s_-1&#39;] -&gt; [&#39;eq&#39;]
    17/140: Gather [&#39;slice_7&#39;, &#39;input14&#39;] -&gt; [&#39;index&#39;]
    18/140: Gather [&#39;slice_8&#39;, &#39;input14&#39;] -&gt; [&#39;index_1&#39;]
    19/140: Add [&#39;input1&#39;, &#39;view_18&#39;] -&gt; [&#39;add_5&#39;]
    20/140: Mul [&#39;mul_12&#39;, &#39;input9&#39;] -&gt; [&#39;mul_15&#39;]
    21/140: Unsqueeze [&#39;eq&#39;, &#39;init7_s1_-1&#39;] -&gt; [&#39;unsqueeze_9&#39;]
    22/140: Unsqueeze [&#39;index&#39;, &#39;init7_s1_1&#39;] -&gt; [&#39;unsqueeze_7&#39;]
    23/140: Unsqueeze [&#39;index_1&#39;, &#39;init7_s1_1&#39;] -&gt; [&#39;unsqueeze_8&#39;]
    24/140: Mul [&#39;add_5&#39;, &#39;input5&#39;] -&gt; [&#39;mul_6&#39;]
    25/140: Add [&#39;add_5&#39;, &#39;view_24&#39;] -&gt; [&#39;add_7&#39;]
    26/140: Mul [&#39;add_7&#39;, &#39;input9&#39;] -&gt; [&#39;mul_10&#39;]
    27/140: Mul [&#39;mul_12&#39;, &#39;add_7&#39;] -&gt; [&#39;mul_14&#39;]
    28/140: Pow [&#39;input0&#39;, &#39;init1_s1_&#39;] -&gt; [&#39;pow_8&#39;]
    29/140: Mul [&#39;input10&#39;, &#39;mul_10&#39;] -&gt; [&#39;mul_13&#39;]
    30/140: ReduceSum [&#39;mul_14&#39;, &#39;init7_s1_2&#39;] -&gt; [&#39;sum_2&#39;]
    31/140: Pow [&#39;input5&#39;, &#39;init1_s1_2&#39;] -&gt; [&#39;pow_6&#39;]
    32/140: Pow [&#39;input9&#39;, &#39;init1_s1_3&#39;] -&gt; [&#39;pow_4&#39;]
    33/140: Add [&#39;mul_22&#39;, &#39;init1_s_4&#39;] -&gt; [&#39;add_10&#39;]
    34/140: ReduceSum [&#39;mul_13&#39;, &#39;init7_s2_0_1&#39;] -&gt; [&#39;output_0&#39;]
    35/140: Mul [&#39;sum_2&#39;, &#39;init1_s_5&#39;] -&gt; [&#39;_onx_mul04&#39;]
    36/140: Mul [&#39;input12&#39;, &#39;add_10&#39;] -&gt; [&#39;mul_23&#39;]
    37/140: Reshape [&#39;mul_23&#39;, &#39;init7_s2_2048_16&#39;] -&gt; [&#39;typeR_mul_23&#39;]
    38/140: Mul [&#39;_onx_mul04&#39;, &#39;pow_4&#39;] -&gt; [&#39;mul_17&#39;]
    39/140: Mul [&#39;mul_17&#39;, &#39;add_7&#39;] -&gt; [&#39;type--mul_19&#39;]
    40/140: Mul [&#39;type--mul_19&#39;, &#39;init1_s_12&#39;] -&gt; [&#39;mul_19&#39;]
    41/140: Add [&#39;mul_15&#39;, &#39;mul_19&#39;] -&gt; [&#39;add_9&#39;]
    42/140: Reshape [&#39;add_9&#39;, &#39;init7_s2_2048_16&#39;] -&gt; [&#39;view_26&#39;]
    43/140: MatMul [&#39;view_26&#39;, &#39;input15&#39;] -&gt; [&#39;mm_8&#39;]
    44/140: Mul [&#39;mm_8&#39;, &#39;input7&#39;] -&gt; [&#39;typeL_mul_21&#39;]
    45/140: Mul [&#39;typeL_mul_21&#39;, &#39;typeR_mul_23&#39;] -&gt; [&#39;view_30&#39;]
    46/140: Mul [&#39;mm_8&#39;, &#39;typeR_mul_8&#39;] -&gt; [&#39;view_28&#39;]
    47/140: Gemm [&#39;view_26&#39;, &#39;input16&#39;] -&gt; [&#39;output_1&#39;]
    48/140: MatMul [&#39;view_28&#39;, &#39;input17&#39;] -&gt; [&#39;mm_10&#39;]
    49/140: Gemm [&#39;view_28&#39;, &#39;input18&#39;] -&gt; [&#39;output_2&#39;]
    50/140: Reshape [&#39;mm_10&#39;, &#39;init7_s3_2_1024_16&#39;] -&gt; [&#39;view_29&#39;]
    51/140: MatMul [&#39;view_30&#39;, &#39;input19&#39;] -&gt; [&#39;mm_12&#39;]
    52/140: Gemm [&#39;view_30&#39;, &#39;input18&#39;] -&gt; [&#39;output_3&#39;]
    53/140: Reshape [&#39;mm_12&#39;, &#39;init7_s3_2_1024_16&#39;] -&gt; [&#39;view_31&#39;]
    54/140: Add [&#39;view_29&#39;, &#39;view_31&#39;] -&gt; [&#39;add_11&#39;]
    55/140: Mul [&#39;add_11&#39;, &#39;input20&#39;] -&gt; [&#39;mul_25&#39;]
    56/140: Mul [&#39;add_11&#39;, &#39;mul_6&#39;] -&gt; [&#39;mul_26&#39;]
    57/140: Mul [&#39;mul_25&#39;, &#39;add_5&#39;] -&gt; [&#39;mul_27&#39;]
    58/140: Mul [&#39;mul_25&#39;, &#39;input5&#39;] -&gt; [&#39;mul_28&#39;]
    59/140: ReduceSum [&#39;mul_26&#39;, &#39;init7_s2_0_1&#39;] -&gt; [&#39;output_4&#39;]
    60/140: ReduceSum [&#39;mul_27&#39;, &#39;init7_s1_2&#39;] -&gt; [&#39;sum_4&#39;]
    61/140: Add [&#39;add_9&#39;, &#39;mul_28&#39;] -&gt; [&#39;add_12&#39;]
    62/140: Mul [&#39;sum_4&#39;, &#39;init1_s_7&#39;] -&gt; [&#39;_onx_mul05&#39;]
    63/140: Mul [&#39;_onx_mul05&#39;, &#39;pow_6&#39;] -&gt; [&#39;mul_30&#39;]
    64/140: Mul [&#39;mul_30&#39;, &#39;add_5&#39;] -&gt; [&#39;type--mul_32&#39;]
    65/140: Mul [&#39;type--mul_32&#39;, &#39;init1_s_13&#39;] -&gt; [&#39;mul_32&#39;]
    66/140: Add [&#39;add_12&#39;, &#39;mul_32&#39;] -&gt; [&#39;add_13&#39;]
    67/140: Reshape [&#39;add_13&#39;, &#39;init7_s2_2048_16&#39;] -&gt; [&#39;view_33&#39;]
    68/140: MatMul [&#39;view_33&#39;, &#39;input21&#39;] -&gt; [&#39;mm_14&#39;]
    69/140: Gemm [&#39;view_33&#39;, &#39;input22&#39;] -&gt; [&#39;output_5&#39;]
    70/140: Reshape [&#39;mm_14&#39;, &#39;init7_s4_2_1024_2_8&#39;] -&gt; [&#39;view_35&#39;]
    71/140: Transpose [&#39;view_35&#39;] -&gt; [&#39;transpose_5&#39;]
    72/140: MatMul [&#39;transpose_5&#39;, &#39;typeL_view_36&#39;] -&gt; [&#39;view_38&#39;]
    73/140: MatMul [&#39;typeL_input23&#39;, &#39;transpose_5&#39;] -&gt; [&#39;view_37&#39;]
    74/140: Add [&#39;input25&#39;, &#39;view_37&#39;] -&gt; [&#39;add_14&#39;]
    75/140: Mul [&#39;view_38&#39;, &#39;input26&#39;] -&gt; [&#39;mul_33&#39;]
    76/140: Transpose [&#39;add_14&#39;] -&gt; [&#39;transpose_11&#39;]
    77/140: ReduceSum [&#39;mul_33&#39;, &#39;init7_s1_-1&#39;] -&gt; [&#39;sum_5&#39;]
    78/140: Mul [&#39;input26&#39;, &#39;sum_5&#39;] -&gt; [&#39;mul_34&#39;]
    79/140: Sub [&#39;mul_33&#39;, &#39;mul_34&#39;] -&gt; [&#39;sub_1&#39;]
    80/140: Reshape [&#39;transpose_11&#39;, &#39;init7_s2_2048_16&#39;] -&gt; [&#39;view_45&#39;]
    81/140: Div [&#39;sub_1&#39;, &#39;init1_s_9&#39;] -&gt; [&#39;div_3&#39;]
    82/140: MatMul [&#39;div_3&#39;, &#39;typeL_view_39&#39;] -&gt; [&#39;view_41&#39;]
    83/140: MatMul [&#39;typeL_input29&#39;, &#39;div_3&#39;] -&gt; [&#39;view_40&#39;]
    84/140: MatMul [&#39;view_45&#39;, &#39;input27&#39;] -&gt; [&#39;mm_16&#39;]
    85/140: Gemm [&#39;view_45&#39;, &#39;input28&#39;] -&gt; [&#39;output_6&#39;]
    86/140: Transpose [&#39;view_40&#39;] -&gt; [&#39;transpose_10&#39;]
    87/140: Mul [&#39;view_41&#39;, &#39;unsqueeze_8&#39;] -&gt; [&#39;mul_37&#39;]
    88/140: Mul [&#39;view_41&#39;, &#39;unsqueeze_7&#39;] -&gt; [&#39;mul_38&#39;]
    89/140: Add [&#39;input31&#39;, &#39;transpose_10&#39;] -&gt; [&#39;add_15&#39;]
    90/140: Slice [&#39;mul_37&#39;, &#39;init7_s1_0&#39;, &#39;init7_s1_4&#39;, &#39;init7_s1_3&#39;] -&gt; [&#39;slice_15&#39;]
    91/140: Slice [&#39;mul_37&#39;, &#39;init7_s1_4&#39;, &#39;init7_s1_8&#39;, &#39;init7_s1_3&#39;] -&gt; [&#39;slice_16&#39;]
    92/140: Mul [&#39;add_15&#39;, &#39;unsqueeze_8&#39;] -&gt; [&#39;mul_35&#39;]
    93/140: Mul [&#39;add_15&#39;, &#39;unsqueeze_7&#39;] -&gt; [&#39;mul_36&#39;]
    94/140: Neg [&#39;slice_15&#39;] -&gt; [&#39;neg_3&#39;]
    95/140: ConstantOfShape [&#39;init7_s4_2_2_1024_8&#39;] -&gt; [&#39;new_zeros_3&#39;]
    96/140: Slice [&#39;mul_35&#39;, &#39;init7_s1_0&#39;, &#39;init7_s1_4&#39;, &#39;init7_s1_3&#39;] -&gt; [&#39;slice_13&#39;]
    97/140: Slice [&#39;mul_35&#39;, &#39;init7_s1_4&#39;, &#39;init7_s1_8&#39;, &#39;init7_s1_3&#39;] -&gt; [&#39;slice_14&#39;]
    98/140: ScatterElements [&#39;init7_s4_2_2_1024_8&#39;, &#39;init7_s1_3&#39;, &#39;init7_s1_1&#39;] -&gt; [&#39;_onx_scatterelements0&#39;]
    99/140: Expand [&#39;init7_s4_0_1_2_3&#39;, &#39;_onx_scatterelements0&#39;] -&gt; [&#39;_onx_expand0&#39;]
    100/140: ScatterElements [&#39;new_zeros_3&#39;, &#39;_onx_expand0&#39;, &#39;slice_16&#39;] -&gt; [&#39;_onx_scatterelements02&#39;]
    101/140: Neg [&#39;slice_13&#39;] -&gt; [&#39;neg_2&#39;]
    102/140: ScatterElements [&#39;init7_s4_2_2_1024_8&#39;, &#39;init7_s1_3&#39;, &#39;init7_s1_1&#39;] -&gt; [&#39;_onx_scatterelements03&#39;]
    103/140: Expand [&#39;init7_s4_4_5_6_7&#39;, &#39;_onx_scatterelements03&#39;] -&gt; [&#39;_onx_expand02&#39;]
    104/140: ScatterElements [&#39;new_zeros_3&#39;, &#39;_onx_expand02&#39;, &#39;neg_3&#39;] -&gt; [&#39;_onx_scatterelements04&#39;]
    105/140: ScatterElements [&#39;init7_s4_2_2_1024_8&#39;, &#39;init7_s1_3&#39;, &#39;init7_s1_1&#39;] -&gt; [&#39;_onx_scatterelements05&#39;]
    106/140: Expand [&#39;init7_s4_0_1_2_3&#39;, &#39;_onx_scatterelements05&#39;] -&gt; [&#39;_onx_expand03&#39;]
    107/140: ScatterElements [&#39;new_zeros_3&#39;, &#39;_onx_expand03&#39;, &#39;slice_14&#39;] -&gt; [&#39;_onx_scatterelements06&#39;]
    108/140: Add [&#39;_onx_scatterelements04&#39;, &#39;_onx_scatterelements02&#39;] -&gt; [&#39;add_18&#39;]
    109/140: ScatterElements [&#39;init7_s4_2_2_1024_8&#39;, &#39;init7_s1_3&#39;, &#39;init7_s1_1&#39;] -&gt; [&#39;_onx_scatterelements07&#39;]
    110/140: Expand [&#39;init7_s4_4_5_6_7&#39;, &#39;_onx_scatterelements07&#39;] -&gt; [&#39;_onx_expand04&#39;]
    111/140: ScatterElements [&#39;new_zeros_3&#39;, &#39;_onx_expand04&#39;, &#39;neg_2&#39;] -&gt; [&#39;_onx_scatterelements08&#39;]
    112/140: Add [&#39;add_18&#39;, &#39;mul_38&#39;] -&gt; [&#39;add_19&#39;]
    113/140: Add [&#39;_onx_scatterelements08&#39;, &#39;_onx_scatterelements06&#39;] -&gt; [&#39;add_16&#39;]
    114/140: Transpose [&#39;add_19&#39;] -&gt; [&#39;transpose_13&#39;]
    115/140: Add [&#39;add_16&#39;, &#39;mul_36&#39;] -&gt; [&#39;add_17&#39;]
    116/140: Transpose [&#39;add_17&#39;] -&gt; [&#39;transpose_12&#39;]
    117/140: Reshape [&#39;transpose_13&#39;, &#39;init7_s2_2048_16&#39;] -&gt; [&#39;view_49&#39;]
    118/140: MatMul [&#39;view_49&#39;, &#39;input32&#39;] -&gt; [&#39;mm_20&#39;]
    119/140: Reshape [&#39;transpose_12&#39;, &#39;init7_s2_2048_16&#39;] -&gt; [&#39;view_47&#39;]
    120/140: Gemm [&#39;view_49&#39;, &#39;input28&#39;] -&gt; [&#39;output_7&#39;]
    121/140: Reshape [&#39;mm_20&#39;, &#39;init7_s3_2_1024_16&#39;] -&gt; [&#39;view_50&#39;]
    122/140: MatMul [&#39;view_47&#39;, &#39;input33&#39;] -&gt; [&#39;mm_18&#39;]
    123/140: Add [&#39;mm_16&#39;, &#39;mm_18&#39;] -&gt; [&#39;typeL_add_20&#39;]
    124/140: Reshape [&#39;typeL_add_20&#39;, &#39;init7_s3_2_1024_16&#39;] -&gt; [&#39;add_20&#39;]
    125/140: Gemm [&#39;view_47&#39;, &#39;input28&#39;] -&gt; [&#39;output_8&#39;]
    126/140: Add [&#39;add_20&#39;, &#39;view_50&#39;] -&gt; [&#39;add_21&#39;]
    127/140: Mul [&#39;add_21&#39;, &#39;input34&#39;] -&gt; [&#39;mul_39&#39;]
    128/140: Mul [&#39;add_21&#39;, &#39;mul&#39;] -&gt; [&#39;mul_40&#39;]
    129/140: Mul [&#39;mul_39&#39;, &#39;input1&#39;] -&gt; [&#39;mul_41&#39;]
    130/140: Mul [&#39;mul_39&#39;, &#39;input0&#39;] -&gt; [&#39;mul_42&#39;]
    131/140: ReduceSum [&#39;mul_40&#39;, &#39;init7_s2_0_1&#39;] -&gt; [&#39;output_9&#39;]
    132/140: ReduceSum [&#39;mul_41&#39;, &#39;init7_s1_2&#39;] -&gt; [&#39;sum_7&#39;]
    133/140: Add [&#39;add_13&#39;, &#39;mul_42&#39;] -&gt; [&#39;add_22&#39;]
    134/140: Mul [&#39;sum_7&#39;, &#39;init1_s_10&#39;] -&gt; [&#39;_onx_mul06&#39;]
    135/140: Mul [&#39;_onx_mul06&#39;, &#39;pow_8&#39;] -&gt; [&#39;mul_44&#39;]
    136/140: Mul [&#39;mul_44&#39;, &#39;input1&#39;] -&gt; [&#39;type--mul_46&#39;]
    137/140: Mul [&#39;type--mul_46&#39;, &#39;init1_s_14&#39;] -&gt; [&#39;mul_46&#39;]
    138/140: Add [&#39;add_22&#39;, &#39;mul_46&#39;] -&gt; [&#39;add_23&#39;]
    139/140: Where [&#39;unsqueeze_9&#39;, &#39;init1_s1_4&#39;, &#39;add_23&#39;] -&gt; [&#39;output_10&#39;]
    140/140: ConstantOfShape [&#39;init7_s2_1024_16&#39;] -&gt; [&#39;output_11&#39;]
    
    NODES in {name!r}
    1/106: Identity [&#39;input11&#39;] -&gt; [&#39;output_8&#39;]
    2/106: Identity [&#39;input10&#39;] -&gt; [&#39;output_7&#39;]
    3/106: Identity [&#39;input9&#39;] -&gt; [&#39;output_6&#39;]
    4/106: Identity [&#39;input8&#39;] -&gt; [&#39;output_5&#39;]
    5/106: Identity [&#39;input5&#39;] -&gt; [&#39;output_4&#39;]
    6/106: Identity [&#39;input4&#39;] -&gt; [&#39;output_3&#39;]
    7/106: Identity [&#39;input3&#39;] -&gt; [&#39;output_2&#39;]
    8/106: Range [&#39;init7_s_0&#39;, &#39;init7_s_1024&#39;, &#39;init7_s_1&#39;] -&gt; [&#39;arange&#39;]
    9/106: Gather [&#39;input0&#39;, &#39;input1&#39;] -&gt; [&#39;output_0&#39;]
    10/106: ConstantOfShape [&#39;init7_s2_1024_1024&#39;] -&gt; [&#39;full&#39;]
    11/106: Range [&#39;init7_s_0&#39;, &#39;init7_s_1024&#39;, &#39;init7_s_1&#39;] -&gt; [&#39;arange_1&#39;]
    12/106: Slice [&#39;input6&#39;, &#39;init7_s1_0&#39;, &#39;init7_s1_1024&#39;, &#39;init7_s1_0&#39;] -&gt; [&#39;slice_7&#39;]
    13/106: Slice [&#39;input7&#39;, &#39;init7_s1_0&#39;, &#39;init7_s1_1024&#39;, &#39;init7_s1_0&#39;] -&gt; [&#39;slice_8&#39;]
    14/106: Unsqueeze [&#39;arange&#39;, &#39;init7_s1_0&#39;] -&gt; [&#39;output_1&#39;]
    15/106: Pow [&#39;output_0&#39;, &#39;init1_s1_&#39;] -&gt; [&#39;pow_1&#39;]
    16/106: Add [&#39;arange_1&#39;, &#39;init7_s_1&#39;] -&gt; [&#39;add&#39;]
    17/106: Unsqueeze [&#39;input2&#39;, &#39;init7_s2_1_2&#39;] -&gt; [&#39;unsqueeze_4&#39;]
    18/106: Gather [&#39;slice_7&#39;, &#39;output_1&#39;] -&gt; [&#39;index&#39;]
    19/106: Gather [&#39;slice_8&#39;, &#39;output_1&#39;] -&gt; [&#39;index_1&#39;]
    20/106: ReduceMean [&#39;pow_1&#39;, &#39;init7_s1_-1&#39;] -&gt; [&#39;mean&#39;]
    21/106: Reshape [&#39;add&#39;, &#39;init7_s2_1024_1&#39;] -&gt; [&#39;view&#39;]
    22/106: Unsqueeze [&#39;index&#39;, &#39;init7_s1_1&#39;] -&gt; [&#39;unsqueeze_7&#39;]
    23/106: Unsqueeze [&#39;index_1&#39;, &#39;init7_s1_1&#39;] -&gt; [&#39;unsqueeze_8&#39;]
    24/106: Add [&#39;mean&#39;, &#39;init1_s_&#39;] -&gt; [&#39;add_1&#39;]
    25/106: Less [&#39;arange_1&#39;, &#39;view&#39;] -&gt; [&#39;lt&#39;]
    26/106: Sqrt [&#39;add_1&#39;] -&gt; [&#39;_onx_sqrt0&#39;]
    27/106: Reciprocal [&#39;_onx_sqrt0&#39;] -&gt; [&#39;output_9&#39;]
    28/106: Where [&#39;lt&#39;, &#39;init1_s1_2&#39;, &#39;full&#39;] -&gt; [&#39;_onx_where0&#39;]
    29/106: Expand [&#39;unsqueeze_4&#39;, &#39;init7_s4_2_1_1024_1024&#39;] -&gt; [&#39;expand_1&#39;]
    30/106: Mul [&#39;output_0&#39;, &#39;output_9&#39;] -&gt; [&#39;mul&#39;]
    31/106: Unsqueeze [&#39;_onx_where0&#39;, &#39;init7_s2_0_1&#39;] -&gt; [&#39;unsqueeze_6&#39;]
    32/106: Sub [&#39;init1_s_2&#39;, &#39;expand_1&#39;] -&gt; [&#39;rsub&#39;]
    33/106: Mul [&#39;input12&#39;, &#39;mul&#39;] -&gt; [&#39;mul_1&#39;]
    34/106: Cast [&#39;rsub&#39;] -&gt; [&#39;_to_copy&#39;]
    35/106: Reshape [&#39;mul_1&#39;, &#39;init7_s2_2048_16&#39;] -&gt; [&#39;output_10&#39;]
    36/106: Where [&#39;_to_copy&#39;, &#39;init1_s1_3&#39;, &#39;rsub&#39;] -&gt; [&#39;_onx_where02&#39;]
    37/106: Gemm [&#39;output_10&#39;, &#39;input3&#39;] -&gt; [&#39;mm&#39;]
    38/106: Gemm [&#39;output_10&#39;, &#39;input4&#39;] -&gt; [&#39;mm_1&#39;]
    39/106: Gemm [&#39;output_10&#39;, &#39;input5&#39;] -&gt; [&#39;mm_2&#39;]
    40/106: Cast [&#39;_onx_where02&#39;] -&gt; [&#39;_to_copy_1&#39;]
    41/106: Expand [&#39;unsqueeze_6&#39;, &#39;init7_s4_2_1_1024_1024&#39;] -&gt; [&#39;expand_2&#39;]
    42/106: Reshape [&#39;mm&#39;, &#39;init7_s4_2_1024_2_8&#39;] -&gt; [&#39;view_7&#39;]
    43/106: Reshape [&#39;mm_1&#39;, &#39;init7_s4_2_1024_2_8&#39;] -&gt; [&#39;view_8&#39;]
    44/106: Reshape [&#39;mm_2&#39;, &#39;init7_s4_2_1024_2_8&#39;] -&gt; [&#39;view_9&#39;]
    45/106: Where [&#39;_to_copy_1&#39;, &#39;init1_s1_4&#39;, &#39;expand_2&#39;] -&gt; [&#39;_onx_where03&#39;]
    46/106: Transpose [&#39;view_7&#39;] -&gt; [&#39;transpose&#39;]
    47/106: Transpose [&#39;view_8&#39;] -&gt; [&#39;transpose_1&#39;]
    48/106: Transpose [&#39;view_9&#39;] -&gt; [&#39;output_11&#39;]
    49/106: Mul [&#39;transpose&#39;, &#39;unsqueeze_7&#39;] -&gt; [&#39;mul_2&#39;]
    50/106: Slice [&#39;transpose&#39;, &#39;init7_s1_0&#39;, &#39;init7_s1_4&#39;, &#39;init7_s1_3&#39;] -&gt; [&#39;slice_9&#39;]
    51/106: Slice [&#39;transpose&#39;, &#39;init7_s1_4&#39;, &#39;init7_s1_9223372036854775807&#39;, &#39;init7_s1_3&#39;] -&gt; [&#39;slice_10&#39;]
    52/106: Mul [&#39;transpose_1&#39;, &#39;unsqueeze_7&#39;] -&gt; [&#39;mul_4&#39;]
    53/106: Slice [&#39;transpose_1&#39;, &#39;init7_s1_0&#39;, &#39;init7_s1_4&#39;, &#39;init7_s1_3&#39;] -&gt; [&#39;slice_11&#39;]
    54/106: Slice [&#39;transpose_1&#39;, &#39;init7_s1_4&#39;, &#39;init7_s1_9223372036854775807&#39;, &#39;init7_s1_3&#39;] -&gt; [&#39;slice_12&#39;]
    55/106: Reshape [&#39;output_11&#39;, &#39;init7_s3_4_1024_8&#39;] -&gt; [&#39;view_14&#39;]
    56/106: Neg [&#39;slice_10&#39;] -&gt; [&#39;neg&#39;]
    57/106: Neg [&#39;slice_12&#39;] -&gt; [&#39;neg_1&#39;]
    58/106: Concat [&#39;neg&#39;, &#39;slice_9&#39;] -&gt; [&#39;cat&#39;]
    59/106: Concat [&#39;neg_1&#39;, &#39;slice_11&#39;] -&gt; [&#39;cat_1&#39;]
    60/106: Mul [&#39;cat&#39;, &#39;unsqueeze_8&#39;] -&gt; [&#39;mul_3&#39;]
    61/106: Mul [&#39;cat_1&#39;, &#39;unsqueeze_8&#39;] -&gt; [&#39;mul_5&#39;]
    62/106: Transpose [&#39;view_14&#39;] -&gt; [&#39;output_12&#39;]
    63/106: Add [&#39;mul_2&#39;, &#39;mul_3&#39;] -&gt; [&#39;add_2&#39;]
    64/106: Add [&#39;mul_4&#39;, &#39;mul_5&#39;] -&gt; [&#39;output_13&#39;]
    65/106: Reshape [&#39;add_2&#39;, &#39;init7_s3_4_1024_8&#39;] -&gt; [&#39;view_10&#39;]
    66/106: Transpose [&#39;output_13&#39;] -&gt; [&#39;transpose_3&#39;]
    67/106: Reshape [&#39;transpose_3&#39;, &#39;init7_s3_4_8_1024&#39;] -&gt; [&#39;view_11&#39;]
    68/106: MatMul [&#39;add_2&#39;, &#39;transpose_3&#39;] -&gt; [&#39;view_12&#39;]
    69/106: Transpose [&#39;view_10&#39;] -&gt; [&#39;output_14&#39;]
    70/106: Transpose [&#39;view_11&#39;] -&gt; [&#39;output_15&#39;]
    71/106: Div [&#39;view_12&#39;, &#39;init1_s_3&#39;] -&gt; [&#39;div&#39;]
    72/106: Add [&#39;div&#39;, &#39;_onx_where03&#39;] -&gt; [&#39;add_4&#39;]
    73/106: Softmax [&#39;add_4&#39;] -&gt; [&#39;output_16&#39;]
    74/106: Reshape [&#39;output_16&#39;, &#39;init7_s3_4_1024_1024&#39;] -&gt; [&#39;view_13&#39;]
    75/106: MatMul [&#39;output_16&#39;, &#39;output_11&#39;] -&gt; [&#39;view_15&#39;]
    76/106: Transpose [&#39;view_13&#39;] -&gt; [&#39;output_17&#39;]
    77/106: Transpose [&#39;view_15&#39;] -&gt; [&#39;transpose_4&#39;]
    78/106: Reshape [&#39;transpose_4&#39;, &#39;init7_s2_2048_16&#39;] -&gt; [&#39;output_18&#39;]
    79/106: Gemm [&#39;output_18&#39;, &#39;input8&#39;] -&gt; [&#39;output_19&#39;]
    80/106: Reshape [&#39;output_19&#39;, &#39;init7_s3_2_1024_16&#39;] -&gt; [&#39;view_18&#39;]
    81/106: Add [&#39;output_0&#39;, &#39;view_18&#39;] -&gt; [&#39;add_5&#39;]
    82/106: Pow [&#39;add_5&#39;, &#39;init1_s1_5&#39;] -&gt; [&#39;pow_2&#39;]
    83/106: ReduceMean [&#39;pow_2&#39;, &#39;init7_s1_-1&#39;] -&gt; [&#39;mean_1&#39;]
    84/106: Add [&#39;mean_1&#39;, &#39;init1_s_4&#39;] -&gt; [&#39;add_6&#39;]
    85/106: Sqrt [&#39;add_6&#39;] -&gt; [&#39;_onx_sqrt02&#39;]
    86/106: Reciprocal [&#39;_onx_sqrt02&#39;] -&gt; [&#39;output_20&#39;]
    87/106: Mul [&#39;add_5&#39;, &#39;output_20&#39;] -&gt; [&#39;mul_6&#39;]
    88/106: Mul [&#39;input13&#39;, &#39;mul_6&#39;] -&gt; [&#39;mul_7&#39;]
    89/106: Reshape [&#39;mul_7&#39;, &#39;init7_s2_2048_16&#39;] -&gt; [&#39;output_21&#39;]
    90/106: Gemm [&#39;output_21&#39;, &#39;input9&#39;] -&gt; [&#39;output_22&#39;]
    91/106: Reshape [&#39;output_22&#39;, &#39;init7_s3_2_1024_16&#39;] -&gt; [&#39;view_20&#39;]
    92/106: Gemm [&#39;output_21&#39;, &#39;input10&#39;] -&gt; [&#39;output_23&#39;]
    93/106: Sigmoid [&#39;view_20&#39;] -&gt; [&#39;output_24&#39;]
    94/106: Reshape [&#39;output_24&#39;, &#39;init7_s2_2048_16&#39;] -&gt; [&#39;typeR_output_24&#39;]
    95/106: Mul [&#39;output_22&#39;, &#39;typeR_output_24&#39;] -&gt; [&#39;typeL_mul_8&#39;]
    96/106: Mul [&#39;typeL_mul_8&#39;, &#39;output_23&#39;] -&gt; [&#39;output_25&#39;]
    97/106: Gemm [&#39;output_25&#39;, &#39;input11&#39;] -&gt; [&#39;output_26&#39;]
    98/106: Reshape [&#39;output_26&#39;, &#39;init7_s3_2_1024_16&#39;] -&gt; [&#39;view_24&#39;]
    99/106: Add [&#39;add_5&#39;, &#39;view_24&#39;] -&gt; [&#39;add_7&#39;]
    100/106: Pow [&#39;add_7&#39;, &#39;init1_s1_6&#39;] -&gt; [&#39;pow_3&#39;]
    101/106: ReduceMean [&#39;pow_3&#39;, &#39;init7_s1_-1&#39;] -&gt; [&#39;mean_2&#39;]
    102/106: Add [&#39;mean_2&#39;, &#39;init1_s_5&#39;] -&gt; [&#39;add_8&#39;]
    103/106: Sqrt [&#39;add_8&#39;] -&gt; [&#39;_onx_sqrt03&#39;]
    104/106: Reciprocal [&#39;_onx_sqrt03&#39;] -&gt; [&#39;output_27&#39;]
    105/106: Mul [&#39;add_7&#39;, &#39;output_27&#39;] -&gt; [&#39;mul_10&#39;]
    106/106: Mul [&#39;input14&#39;, &#39;mul_10&#39;] -&gt; [&#39;output_28&#39;]
    [runpythonerror]
    /home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/exporter.py:136: UserWarning: torch.onnx.dynamo_export only implements opset version 18 for now. If you need to use a different opset version, please register them with register_custom_op.
      warnings.warn(
    W0317 17:46:06.178000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.179000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.179000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.179000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.transpose.int (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.179000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.transpose.int (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.179000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.179000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.179000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.transpose.int (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.179000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.transpose.int (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.179000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.180000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.180000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.180000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.180000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.180000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.180000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.rsqrt.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.180000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.180000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.mean.dim (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.180000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.pow.Tensor_Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.181000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.181000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.181000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.181000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.181000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.181000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.181000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.181000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.182000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.182000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.182000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.sigmoid.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.182000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.182000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.182000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.182000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.182000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.183000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.183000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.rsqrt.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.183000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.183000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.mean.dim (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.183000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.pow.Tensor_Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.183000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.183000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.183000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.184000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.184000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.184000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.184000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.clone.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.184000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.transpose.int (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.184000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.184000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.bmm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.184000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.185000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.clone.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.185000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.expand.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.185000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.185000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.expand.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.185000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.clone.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.185000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.185000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.185000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten._softmax.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.186000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.186000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.div.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.186000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.186000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.bmm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.186000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.186000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.clone.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.186000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.expand.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.186000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.187000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.clone.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.187000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.expand.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.187000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.transpose.int (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.187000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.187000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.187000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.cat.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.187000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.neg.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.188000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.188000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.188000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.188000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.188000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.188000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.cat.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.188000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.neg.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.188000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.189000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.189000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.189000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.unsqueeze.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.189000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.index.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.189000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.unsqueeze.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.189000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.index.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.189000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.190000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.190000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.transpose.int (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.190000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.190000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.transpose.int (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.190000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.190000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.transpose.int (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.190000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.191000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.191000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.191000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.191000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.191000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.192000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.192000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.192000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.192000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.192000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.192000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.192000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.192000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.rsqrt.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.193000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.193000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.mean.dim (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.193000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.pow.Tensor_Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.193000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.masked_fill.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.193000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.expand.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.193000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.193000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.194000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.unsqueeze.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.194000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.unsqueeze.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.194000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten._to_copy.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.194000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.masked_fill.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.194000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten._to_copy.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.194000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.rsub.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.194000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.expand.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.195000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.195000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.unsqueeze.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.195000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.unsqueeze.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.195000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.195000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.masked_fill.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.195000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.lt.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.195000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.196000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.196000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.arange.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.196000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.full.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.196000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.embedding.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.196000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.unsqueeze.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.196000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] [0/0] support_dict supports node.target: aten.arange.start (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.501000 140689160114176 torch/onnx/_internal/onnxruntime.py:201] support_dict and extra_support_dict don&#39;t support node.target: aten._unsafe_index_put.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.501000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.new_zeros.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.501000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.masked_fill.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.501000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.unsqueeze.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.501000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.eq.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.501000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.502000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.502000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.502000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.pow.Tensor_Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.502000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.div.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.502000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.expand.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.502000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.502000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.503000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.pow.Tensor_Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.503000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.503000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.503000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.503000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.sum.dim_IntList (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.503000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.504000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.504000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.504000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.sum.dim_IntList (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.504000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.504000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.504000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.504000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.505000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.505000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.505000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.505000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.505000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.505000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.506000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.506000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.506000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.506000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.506000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.506000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.506000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.507000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.507000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.507000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.507000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.507000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.507000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.507000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.507000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.508000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.508000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.clone.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.508000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.transpose.int (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.508000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.508000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.clone.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.508000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.transpose.int (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.508000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.508000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.clone.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.508000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.transpose.int (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.509000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.509000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.509000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.509000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.slice_scatter.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.509000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.new_zeros.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.509000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.slice_scatter.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.509000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.new_zeros.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.509000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.neg.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.510000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.510000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.510000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.510000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.510000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.510000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.510000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.slice_scatter.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.511000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.new_zeros.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.511000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.slice_scatter.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.511000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.new_zeros.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.511000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.neg.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.511000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.511000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.511000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.511000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.512000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.transpose.int (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.512000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.512000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.512000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.bmm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.512000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.bmm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.512000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.512000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.div.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.512000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.sub.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.513000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.513000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.sum.dim_IntList (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.513000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.513000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.513000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.513000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.513000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.bmm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.513000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.bmm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.514000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.514000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.clone.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.514000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.transpose.int (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.514000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.514000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.514000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.514000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.515000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.515000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.515000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.515000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.515000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.515000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.515000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.515000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.pow.Tensor_Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.516000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.div.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.516000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.expand.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.516000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.516000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.516000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.pow.Tensor_Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.516000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.516000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.517000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.517000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.sum.dim_IntList (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.517000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.517000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.517000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.517000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.sum.dim_IntList (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.517000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.518000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.518000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.518000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.518000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.518000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.518000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.518000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.519000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.519000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.519000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.519000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.519000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.add.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.519000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.519000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.sub.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.520000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.fill.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.520000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.empty_like.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.520000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.520000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.520000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.520000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.520000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.521000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.521000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.521000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.521000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.521000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.521000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.521000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.522000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.522000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.522000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.522000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.522000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.522000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.522000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.523000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.pow.Tensor_Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.523000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.div.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.523000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.expand.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.523000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.523000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.523000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.pow.Tensor_Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.524000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.524000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.524000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.sum.dim_IntList (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.524000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.524000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.524000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.524000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.sum.dim_IntList (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.525000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.525000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.525000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.525000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.525000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.525000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.525000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.526000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.526000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.526000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.526000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.526000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.526000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.527000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.527000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.527000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.unsqueeze.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.527000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.index.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.527000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.unsqueeze.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.527000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.index.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.527000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.528000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.528000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.528000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0317 17:46:06.528000 140689160114176 torch/onnx/_internal/onnxruntime.py:185] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
</pre></div>
</div>
</section>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="llama.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">LLaMa</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="torchtry.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Tries with Undocumented</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2023-2024
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Use the custom exporter in torch</a><ul>
<li><a class="reference internal" href="#file-onnxruntime-py">File <cite>onnxruntime.py</cite></a></li>
<li><a class="reference internal" href="#examples">Examples</a><ul>
<li><a class="reference internal" href="#baseline">Baseline</a></li>
<li><a class="reference internal" href="#with-the-custom-exporter">With the custom exporter</a></li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../_static/documentation_options.js?v=a1637f0b"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/furo.js?v=32e29ea5"></script>
    </body>
</html>