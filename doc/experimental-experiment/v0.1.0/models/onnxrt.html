<!doctype html>
<html class="no-js" lang="en" data-content_root="../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="LLaMa" href="llama.html" /><link rel="prev" title="Tries with Undocumented" href="torchtry.html" />

    <!-- Generated with Sphinx 7.2.6 and Furo 2024.01.29 -->
        <title>Use the custom exporter in torch - experimental-experiment 0.1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=135e06be" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css?v=7f9a90b1" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css?v=eafc0fe6" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=61a4c737" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=36a5483c" />
    
    


<style>
  body {
    --color-code-background: #eeffcc;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">experimental-experiment 0.1.0 documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="../_static/logo.png" alt="Logo"/>
  </div>
  
  <span class="sidebar-brand-text">experimental-experiment 0.1.0 documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Contents</span></p>
<ul class="current">
<li class="toctree-l1 has-children"><a class="reference internal" href="../tutorial/index.html">Tutorial</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of Tutorial</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../tutorial/pytorch.html">pytorch and onnx</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of pytorch and onnx</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_linreg_101.html">101: Linear Regression and export to ONNX</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_custom_backend_101.html">101: A custom backend for torch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_optimize_101.html">101: Graph Optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_convolutation_matmul_102.html">102: Convolution and Matrix Multiplication</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_llama_bench_102.html">102: Measure LLAMA speed</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_export_201.html">201: Evaluate different ways to export a torch model to ONNX</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_dort_201.html">201: Evaluate DORT</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_aot_201.html">201: Evaluate DORT Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_llama_diff_export_301.html">301: Compares LLAMA exporters</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_llama_diff_dort_301.html">301: Compares LLAMA exporters for onnxrt backend</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../tutorial/onnx.html">onnx</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of onnx</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_profile_existing_onnx_101.html">101: Profile an existing model with onnxruntime</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../design/index.html">Design</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of Design</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../design/exporter.html">Custom Exporter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../design/optimizer.html">Pattern Optimizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../design/backends.html">Dynamo Backends</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api/index.html">API</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of API</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../api/gradient.html">gradient</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/reference.html">reference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/graph_builder.html">graph_builder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/graph_builder_pattern.html">graph_builder_optim</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/interpreter.html">interpreter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/onnx_export.html">onnx_export</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/aten_function.html">aten_functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/aten_method.html">aten_methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/prims_function.html">aten_prims</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/convert.html">convert</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/torch_helper.html">torch_helper</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/torch_dynamo.html">torch_dynamo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/misc.html">Others…</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/dimension.html">Dimension</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../auto_examples/index.html">Example gallery</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle navigation of Example gallery</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_optimize_101.html">101: Graph Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_profile_existing_onnx_101.html">101: Profile an existing model with onnxruntime</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_torch_linreg_101.html">101: Linear Regression and export to ONNX</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_torch_custom_backend_101.html">101: A custom backend for torch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_convolutation_matmul_102.html">102: Convolution and Matrix Multiplication</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_llama_bench_102.html">102: Measure LLAMA speed</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_llama_diff_export_301.html">301: Compares LLAMA exporters</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_llama_diff_dort_301.html">301: Compares LLAMA exporters for onnxrt backend</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_torch_aot_201.html">201: Evaluate DORT Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_torch_dort_201.html">201: Evaluate DORT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_torch_export_201.html">201: Evaluate different ways to export a torch model to ONNX</a></li>
</ul>
</li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="index.html">Supported Models</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle navigation of Supported Models</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="torchtry.html">Tries with Undocumented</a></li>
<li class="toctree-l2 current current-page"><a class="current reference internal" href="#">Use the custom exporter in torch</a></li>
<li class="toctree-l2"><a class="reference internal" href="llama.html">LLaMa</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../times.html">Times</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">More</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../CHANGELOGS.html">Change Logs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
<li class="toctree-l1"><a class="reference internal" href="../long_outputs.html">Long Outputs uneasy to read</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <section id="use-the-custom-exporter-in-torch">
<h1>Use the custom exporter in torch<a class="headerlink" href="#use-the-custom-exporter-in-torch" title="Link to this heading">#</a></h1>
<p><em>Subject to change</em></p>
<section id="file-onnxruntime-py">
<h2>File <cite>onnxruntime.py</cite><a class="headerlink" href="#file-onnxruntime-py" title="Link to this heading">#</a></h2>
<p>This change enables the custom rewriter is an environment variable is enabled.
Look for substring <code class="docutils literal notranslate"><span class="pre">TODO:</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">_ort_acclerated_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph_module</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">GraphModule</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;This function replaces GraphModule._wrapped_call in compiled model.</span>

<span class="sd">    The _wrapped_call is the underlying implementation of forward method. Replacing</span>
<span class="sd">    it means we delegate the computation to _ort_acclerated_call and therefore</span>
<span class="sd">    onnxruntime.InferenceSession.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">cached_execution_info_per_session</span> <span class="o">=</span> <span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_all_ort_execution_info</span><span class="o">.</span><span class="n">search_reusable_session_execution_info</span><span class="p">(</span>
            <span class="n">graph_module</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span>
        <span class="p">)</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">cached_execution_info_per_session</span><span class="p">:</span>
        <span class="n">onnx_session</span> <span class="o">=</span> <span class="n">cached_execution_info_per_session</span><span class="o">.</span><span class="n">session</span>
        <span class="n">input_names</span> <span class="o">=</span> <span class="n">cached_execution_info_per_session</span><span class="o">.</span><span class="n">input_names</span>
        <span class="n">output_names</span> <span class="o">=</span> <span class="n">cached_execution_info_per_session</span><span class="o">.</span><span class="n">output_names</span>
        <span class="n">input_value_infos</span> <span class="o">=</span> <span class="n">cached_execution_info_per_session</span><span class="o">.</span><span class="n">input_value_infos</span>
        <span class="n">output_value_infos</span> <span class="o">=</span> <span class="n">cached_execution_info_per_session</span><span class="o">.</span><span class="n">output_value_infos</span>
        <span class="n">input_devices</span> <span class="o">=</span> <span class="n">cached_execution_info_per_session</span><span class="o">.</span><span class="n">input_devices</span>
        <span class="n">output_devices</span> <span class="o">=</span> <span class="n">cached_execution_info_per_session</span><span class="o">.</span><span class="n">output_devices</span>
        <span class="n">prim_outputs</span> <span class="o">=</span> <span class="n">cached_execution_info_per_session</span><span class="o">.</span><span class="n">example_outputs</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># It&#39;s first time seeing such as graph. Let&#39;s make a new session</span>
        <span class="c1"># (type: onnxruntime.InferenceSession) for it.</span>

        <span class="c1">##########################</span>
        <span class="c1"># TODO: Insert these lines</span>
        <span class="c1">##########################</span>

        <span class="n">use_other_rewriter</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;ONNXRT_CHANGE_REWRITER&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;1&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">use_other_rewriter</span><span class="p">:</span>
            <span class="kn">from</span> <span class="nn">experimental_experiment.torch_interpreter</span> <span class="kn">import</span> <span class="n">to_onnx</span>
            <span class="kn">from</span> <span class="nn">experimental_experiment.torch_interpreter._torch_helper</span> <span class="kn">import</span> <span class="n">create_input_names</span>
            <span class="kn">from</span> <span class="nn">experimental_experiment.xbuilder</span> <span class="kn">import</span> <span class="n">OptimizationOptions</span>
            <span class="kn">from</span> <span class="nn">experimental_experiment.torch_interpreter.oxs_dispatcher</span> <span class="kn">import</span> <span class="n">OxsDispatcher</span>

            <span class="n">input_names</span> <span class="o">=</span> <span class="n">input_names</span> <span class="o">=</span> <span class="n">create_input_names</span><span class="p">(</span><span class="n">graph_module</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span>
            <span class="n">dispatcher</span> <span class="o">=</span> <span class="n">OxsDispatcher</span><span class="p">()</span>
            <span class="n">target_opset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_resolved_onnx_exporter_options</span><span class="o">.</span><span class="n">onnx_registry</span><span class="o">.</span><span class="n">opset_version</span>
            <span class="n">options</span> <span class="o">=</span> <span class="n">OptimizationOptions</span><span class="p">(</span>
                <span class="n">remove_unused</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">constant_folding</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">patterns</span><span class="o">=</span><span class="s2">&quot;default&quot;</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">onnx_model</span><span class="p">,</span> <span class="n">builder</span> <span class="o">=</span> <span class="n">to_onnx</span><span class="p">(</span>
                <span class="n">graph_module</span><span class="p">,</span>
                <span class="nb">tuple</span><span class="p">(</span><span class="n">args</span><span class="p">),</span>
                <span class="n">input_names</span><span class="o">=</span><span class="n">input_names</span><span class="p">,</span>
                <span class="n">options</span><span class="o">=</span><span class="n">options</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">target_opset</span><span class="o">=</span><span class="n">target_opset</span><span class="p">,</span>
                <span class="n">return_builder</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dispatcher</span><span class="o">=</span><span class="n">dispatcher</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="k">def</span> <span class="nf">maybe_map_to_meta_val</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="s2">&quot;meta&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="s2">&quot;val&quot;</span> <span class="ow">in</span> <span class="n">value</span><span class="o">.</span><span class="n">meta</span><span class="p">:</span>
                    <span class="c1"># Select outputs with &quot;val&quot; information. Without &quot;val&quot;,</span>
                    <span class="c1"># it&#39;s not possible access output_arg.meta[&quot;val&quot;].device.</span>
                    <span class="k">return</span> <span class="n">value</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s2">&quot;val&quot;</span><span class="p">]</span>
                <span class="k">return</span> <span class="n">value</span>

            <span class="n">extracted_outputs</span> <span class="o">=</span> <span class="n">_extract_graph_module_outputs</span><span class="p">(</span><span class="n">graph_module</span><span class="p">)</span>
            <span class="n">prim_outputs</span> <span class="o">=</span> <span class="n">_pytree</span><span class="o">.</span><span class="n">tree_map</span><span class="p">(</span><span class="n">maybe_map_to_meta_val</span><span class="p">,</span> <span class="n">extracted_outputs</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>

        <span class="c1">####################################</span>
        <span class="c1"># TODO: end of the insertion</span>
        <span class="c1"># TODO: indent what follows</span>
        <span class="c1">####################################</span>

            <span class="n">graph_module</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">_internal</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">passes</span><span class="o">.</span><span class="n">MovePlaceholderToFront</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_resolved_onnx_exporter_options</span><span class="o">.</span><span class="n">diagnostic_context</span><span class="p">,</span>
                <span class="n">graph_module</span><span class="p">,</span>
            <span class="p">)</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
            <span class="c1"># Generate reference outputs. They are used to indicate output</span>
            <span class="c1"># tensors&#39; types and devices when calling ORT.</span>
            <span class="c1">#</span>
            <span class="c1"># WARNING: The downstream code should not change prim_outputs and</span>
            <span class="c1"># this backend should always produces output with schema identical to prim_outputs&#39;.</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_resolved_onnx_exporter_options</span><span class="o">.</span><span class="n">dynamic_shapes</span><span class="p">:</span>
                <span class="c1"># No pre-allocation when dynamic shape is enabled.</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">preallocate_output</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="n">extracted_outputs</span> <span class="o">=</span> <span class="n">_extract_graph_module_outputs</span><span class="p">(</span><span class="n">graph_module</span><span class="p">)</span>

                <span class="k">def</span> <span class="nf">maybe_map_to_meta_val</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="s2">&quot;meta&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="s2">&quot;val&quot;</span> <span class="ow">in</span> <span class="n">value</span><span class="o">.</span><span class="n">meta</span><span class="p">:</span>
                        <span class="c1"># Select outputs with &quot;val&quot; information. Without &quot;val&quot;,</span>
                        <span class="c1"># it&#39;s not possible access output_arg.meta[&quot;val&quot;].device.</span>
                        <span class="k">return</span> <span class="n">value</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s2">&quot;val&quot;</span><span class="p">]</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">return</span> <span class="n">value</span>

                <span class="n">prim_outputs</span> <span class="o">=</span> <span class="n">_pytree</span><span class="o">.</span><span class="n">tree_map</span><span class="p">(</span>
                    <span class="n">maybe_map_to_meta_val</span><span class="p">,</span> <span class="n">extracted_outputs</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">prim_outputs</span> <span class="o">=</span> <span class="n">FakeTensorProp</span><span class="p">(</span><span class="n">graph_module</span><span class="p">)</span><span class="o">.</span><span class="n">propagate</span><span class="p">(</span>
                        <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
                    <span class="p">)</span>
                <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;FakeTensorProb failed for </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">graph_module</span><span class="p">)</span>
                    <span class="c1"># When FakeTensorProp fails, it is not possible to preallocate output buffers</span>
                    <span class="c1"># because the output shapes are not inferred.</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">preallocate_output</span> <span class="o">=</span> <span class="kc">False</span>

                    <span class="c1"># rethrow FakeTensorProb failure because it is not yet currently handled.</span>
                    <span class="k">raise</span>

            <span class="c1"># Create the object to iterate through the nodes in graph one-by-one</span>
            <span class="c1"># and calls the corresponding ONNX exporter for each node.</span>
            <span class="n">fx_interpreter</span> <span class="o">=</span> <span class="n">fx_onnx_interpreter</span><span class="o">.</span><span class="n">FxOnnxInterpreter</span><span class="p">(</span>
                <span class="n">diagnostic_context</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_resolved_onnx_exporter_options</span><span class="o">.</span><span class="n">diagnostic_context</span>
            <span class="p">)</span>
            <span class="c1"># Cast FX variables if they will result schema-mismatch when searching</span>
            <span class="c1"># for ONNX operator. E.g., add(double_tensor, int_tensor) is fine in PyTorch,</span>
            <span class="c1"># but ONNX expects add(double_tensor, double_tensor).</span>
            <span class="n">graph_module</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">_internal</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">passes</span><span class="o">.</span><span class="n">InsertTypePromotion</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_resolved_onnx_exporter_options</span><span class="o">.</span><span class="n">diagnostic_context</span><span class="p">,</span> <span class="n">graph_module</span>
            <span class="p">)</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
            <span class="c1"># Start the per-node exporting process. It&#39;s conceptually a for loop</span>
            <span class="c1"># scanning through the nodes in the graph.</span>
            <span class="n">exported</span> <span class="o">=</span> <span class="n">fx_interpreter</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                <span class="n">fx_graph_module</span><span class="o">=</span><span class="n">graph_module</span><span class="p">,</span>
                <span class="n">onnxfunction_dispatcher</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_resolved_onnx_exporter_options</span><span class="o">.</span><span class="n">onnxfunction_dispatcher</span><span class="p">,</span>
                <span class="n">op_level_debug</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_resolved_onnx_exporter_options</span><span class="o">.</span><span class="n">op_level_debug</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="c1"># Convert the exported result to ONNX ModelProto.</span>
            <span class="n">onnx_model</span> <span class="o">=</span> <span class="n">exported</span><span class="o">.</span><span class="n">to_model_proto</span><span class="p">(</span>
                <span class="n">opset_version</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_resolved_onnx_exporter_options</span><span class="o">.</span><span class="n">onnx_registry</span><span class="o">.</span><span class="n">opset_version</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1">####################################</span>
        <span class="c1"># TODO: end of the modification</span>
        <span class="c1">####################################</span>

        <span class="c1"># Modify ONNX model using pre-registered graph transforms.</span>
        <span class="c1"># They are in-place modifications for avoiding unnecessary</span>
        <span class="c1"># copy of ONNX initializers.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_options</span><span class="o">.</span><span class="n">pre_ort_model_transforms</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">transform</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_options</span><span class="o">.</span><span class="n">pre_ort_model_transforms</span><span class="p">:</span>
                <span class="n">transform</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">)</span>

        <span class="n">onnx_model_bytes</span> <span class="o">=</span> <span class="n">onnx_model</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;ONNXRT_DUMP_PATH&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">):</span>
            <span class="c1"># If not empty, environment variable ONNXRT_DUMP_PATH defined the path</span>
            <span class="c1"># where generated onnx files should be stored.</span>
            <span class="c1"># This module keeps a global variables keeping track of the</span>
            <span class="c1"># stored models.</span>
            <span class="c1"># If ONNXRT_DUMP_PATH=&quot;dumped/dumped_model_&quot;</span>
            <span class="c1"># The first file name will be &#39;dumped/dumped_model_0.onnx&#39;.</span>
            <span class="c1"># For every dumped model, a text file &#39;dumped/dumped_model_0.txt&#39;</span>
            <span class="c1"># is created as well to contain the string representing the graph_module.</span>
            <span class="n">_dump_onnx_model</span><span class="p">(</span><span class="n">onnx_model_bytes</span><span class="p">,</span> <span class="n">graph_module</span><span class="o">=</span><span class="n">graph_module</span><span class="p">)</span>

        <span class="c1"># Initialize a ORT session to execute this ONNX model.</span>
        <span class="c1"># Note that TorchDynamo assumes all inputs/outputs are on the</span>
        <span class="c1"># same device, but it&#39;s subject to change (very likely with</span>
        <span class="c1"># dynamic shape support), so we add execution providers</span>
        <span class="c1"># based on the logic in _select_eps: (explicitly preferred EPs,</span>
        <span class="c1"># EPs inferred from inputs or graph, and the fallback default EP)/</span>
        <span class="c1">#</span>
        <span class="c1"># TODO(wschin): enable external allocators.</span>
        <span class="c1"># See https://github.com/pytorch/pytorch/issues/106867</span>
        <span class="n">onnx_session</span> <span class="o">=</span> <span class="n">onnxruntime</span><span class="o">.</span><span class="n">InferenceSession</span><span class="p">(</span>
            <span class="n">path_or_bytes</span><span class="o">=</span><span class="n">onnx_model_bytes</span><span class="p">,</span>
            <span class="n">sess_options</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_options</span><span class="o">.</span><span class="n">ort_session_options</span><span class="p">,</span>
            <span class="n">providers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_select_eps</span><span class="p">(</span><span class="n">graph_module</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="c1"># Cache ORT session. It&#39;s reused for the same &quot;graph_module&quot;.</span>
        <span class="c1"># Generate ONNX model and extract its input and output names.</span>
        <span class="n">input_names</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">input</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="nb">input</span> <span class="ow">in</span> <span class="n">onnx_model</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">input</span><span class="p">)</span>
        <span class="n">output_names</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">onnx_model</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>
        <span class="n">input_devices</span> <span class="o">=</span> <span class="n">_get_onnx_devices</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
        <span class="c1"># Cache devices for inputs and outputs. They are used to invoke</span>
        <span class="c1"># ORT session. Output devices indicate where (e.g., GPU or CPU)</span>
        <span class="c1"># to store outputs</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prim_outputs</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">output_devices</span> <span class="o">=</span> <span class="n">_get_onnx_devices</span><span class="p">(</span><span class="n">prim_outputs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">output_devices</span> <span class="o">=</span> <span class="n">_get_onnx_devices</span><span class="p">((</span><span class="n">prim_outputs</span><span class="p">,))</span>

        <span class="n">input_value_infos</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">input</span> <span class="k">for</span> <span class="nb">input</span> <span class="ow">in</span> <span class="n">onnx_model</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">input</span><span class="p">)</span>
        <span class="n">output_value_infos</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">output</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">onnx_model</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>

        <span class="n">execution_info_per_session</span> <span class="o">=</span> <span class="n">OrtExecutionInfoPerSession</span><span class="p">(</span>
            <span class="n">session</span><span class="o">=</span><span class="n">onnx_session</span><span class="p">,</span>
            <span class="n">input_names</span><span class="o">=</span><span class="n">input_names</span><span class="p">,</span>
            <span class="n">input_value_infos</span><span class="o">=</span><span class="n">input_value_infos</span><span class="p">,</span>
            <span class="n">output_names</span><span class="o">=</span><span class="n">output_names</span><span class="p">,</span>
            <span class="n">output_value_infos</span><span class="o">=</span><span class="n">output_value_infos</span><span class="p">,</span>
            <span class="n">input_devices</span><span class="o">=</span><span class="n">input_devices</span><span class="p">,</span>
            <span class="n">output_devices</span><span class="o">=</span><span class="n">output_devices</span><span class="p">,</span>
            <span class="n">example_outputs</span><span class="o">=</span><span class="n">prim_outputs</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_all_ort_execution_info</span><span class="o">.</span><span class="n">cache_session_execution_info</span><span class="p">(</span>
            <span class="n">graph_module</span><span class="p">,</span> <span class="n">execution_info_per_session</span>
        <span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">execution_count</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="c1"># ORT always returns a tuple of outputs. If the original output is a tensor,</span>
    <span class="c1"># ORT output&#39;s first element must be extracted and returned. Otherwise, type</span>
    <span class="c1"># mismatch may happen in downstream computation.</span>
    <span class="n">is_single_tensor_output</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prim_outputs</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
    <span class="n">normalized_prim_outputs</span> <span class="o">=</span> <span class="p">(</span>
        <span class="p">(</span><span class="n">prim_outputs</span><span class="p">,)</span> <span class="k">if</span> <span class="n">is_single_tensor_output</span> <span class="k">else</span> <span class="n">prim_outputs</span>
    <span class="p">)</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">normalized_prim_outputs</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span>
        <span class="nb">isinstance</span><span class="p">(</span><span class="n">elem</span><span class="p">,</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">SymInt</span><span class="p">,</span> <span class="nb">int</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">normalized_prim_outputs</span>
    <span class="p">)</span>

    <span class="n">_nvtx_range_push</span><span class="p">(</span><span class="s2">&quot;run_onnx_session_with_ortvaluevector&quot;</span><span class="p">)</span>
    <span class="n">onnx_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
        <span class="n">onnx_session</span><span class="p">,</span>
        <span class="n">input_names</span><span class="p">,</span>
        <span class="n">args</span><span class="p">,</span>
        <span class="n">input_devices</span><span class="p">,</span>
        <span class="n">output_names</span><span class="p">,</span>
        <span class="n">normalized_prim_outputs</span><span class="p">,</span>
        <span class="n">output_devices</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_options</span><span class="o">.</span><span class="n">preallocate_output</span><span class="p">,</span>
        <span class="n">input_value_infos</span><span class="p">,</span>
        <span class="n">normalized_prim_outputs</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">_nvtx_range_pop</span><span class="p">()</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_assert_allclose_to_baseline</span><span class="p">:</span>
        <span class="c1"># Compute baseline.</span>
        <span class="n">baseline_outputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_prims</span><span class="o">.</span><span class="n">executor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span>
            <span class="n">graph_module</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">executor</span><span class="o">=</span><span class="s2">&quot;aten&quot;</span>
        <span class="p">)</span>
        <span class="n">normalized_baseline_ouptuts</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">(</span><span class="n">baseline_outputs</span><span class="p">,)</span> <span class="k">if</span> <span class="n">is_single_tensor_output</span> <span class="k">else</span> <span class="n">baseline_outputs</span>
        <span class="p">)</span>
        <span class="c1"># Ensure every output tensor is close to the corresponding baseline.</span>
        <span class="k">for</span> <span class="n">onnx_output</span><span class="p">,</span> <span class="n">baseline_output</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
            <span class="n">onnx_outputs</span><span class="p">,</span> <span class="n">normalized_baseline_ouptuts</span>
        <span class="p">):</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_close</span><span class="p">(</span><span class="n">onnx_output</span><span class="p">,</span> <span class="n">baseline_output</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">onnx_outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">is_single_tensor_output</span> <span class="k">else</span> <span class="n">onnx_outputs</span>
</pre></div>
</div>
</section>
<section id="examples">
<h2>Examples<a class="headerlink" href="#examples" title="Link to this heading">#</a></h2>
<section id="baseline">
<h3>Baseline<a class="headerlink" href="#baseline" title="Link to this heading">#</a></h3>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">onnx</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.onnx</span>
<span class="kn">from</span> <span class="nn">experimental_experiment.torch_helper.training_helper</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">make_aot_ort</span><span class="p">,</span>
    <span class="n">train_loop</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">experimental_experiment.torch_helper.dump_helper</span> <span class="kn">import</span> <span class="n">dump_onnx</span>

<span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
    <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">LlamaConfig</span>
    <span class="kn">from</span> <span class="nn">transformers.models.llama.modeling_llama</span> <span class="kn">import</span> <span class="n">LlamaModel</span>


<span class="k">def</span> <span class="nf">ids_tensor</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">):</span>
    <span class="n">total_dims</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="n">shape</span><span class="p">:</span>
        <span class="n">total_dims</span> <span class="o">*=</span> <span class="n">dim</span>

    <span class="n">values</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">total_dims</span><span class="p">):</span>
        <span class="n">values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">vocab_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>


<span class="n">config</span> <span class="o">=</span> <span class="n">LlamaConfig</span><span class="p">(</span>
    <span class="n">hidden_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">num_hidden_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">vocab_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
    <span class="n">intermediate_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">max_position_embeddings</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
    <span class="n">num_attention_heads</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">config</span><span class="o">.</span><span class="n">_attn_implementation</span> <span class="o">=</span> <span class="s2">&quot;eager&quot;</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">LlamaModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

<span class="n">batch</span><span class="p">,</span> <span class="n">seq</span><span class="p">,</span> <span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span>

<span class="n">input_ids</span> <span class="o">=</span> <span class="n">ids_tensor</span><span class="p">([</span><span class="n">batch</span><span class="p">,</span> <span class="n">seq</span><span class="p">],</span> <span class="n">vocab_size</span><span class="p">)</span>
<span class="n">input_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tril</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">seq</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

<span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">input_mask</span><span class="p">)</span>

<span class="n">local_aot_ort</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">make_aot_ort</span><span class="p">(</span>
    <span class="n">dynamic</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">rewrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>

<span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
    <span class="n">optimized_mod</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="n">local_aot_ort</span><span class="p">,</span> <span class="n">fullgraph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">dump_onnx</span><span class="p">(</span><span class="s2">&quot;dort-llama-ort&quot;</span><span class="p">,</span> <span class="n">folder</span><span class="o">=</span><span class="s2">&quot;dump_llama&quot;</span><span class="p">,</span> <span class="n">clean</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="n">train_loop</span><span class="p">(</span><span class="n">optimized_mod</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">input_mask</span><span class="p">)</span>

<span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="n">_</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s2">&quot;dump_llama&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">_</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.onnx&quot;</span><span class="p">)]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------------------------&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;exported model: </span><span class="si">{</span><span class="n">names</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">names</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;NODES in </span><span class="si">{name!r}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">onx</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">&quot;dump_llama&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">node</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">onx</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">onx</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="p">)</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">node</span><span class="o">.</span><span class="n">op_type</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="si">}</span><span class="s2"> -&gt; </span><span class="si">{</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    [make_aot_ort] enable rewriting
    [optimize_model_proto] starts inliner with 375 nodes and 25 local functions
    [optimize_model_proto] inliner done in 0.0032567999987804797 seconds.
    [optimize_model_proto] starts optimize with 549 nodes and 0 local functions
    Applied 0 pattern rewrite rules.
    Applied 0 pattern rewrite rules.
    [optimize_model_proto] optimize done in 0.21586830000160262 seconds.
    [optimize_model_proto] starts rewrite with 234 nodes and 0 local functions
    [optimize_model_proto] rewrite done in 1.2000018614344299e-06 seconds with 234 nodes and 0 local functions
    [optimize_model_proto] starts inliner with 394 nodes and 23 local functions
    [optimize_model_proto] inliner done in 0.0030493000012938865 seconds.
    [optimize_model_proto] starts optimize with 821 nodes and 0 local functions
    Applied 0 pattern rewrite rules.
    Applied 0 pattern rewrite rules.
    [optimize_model_proto] optimize done in 0.24330430000190972 seconds.
    [optimize_model_proto] starts rewrite with 321 nodes and 0 local functions
    [optimize_model_proto] rewrite done in 1.3000026228837669e-06 seconds with 321 nodes and 0 local functions
    ------------------------------------------
    exported model: [&#39;dort-llama-ort_1.onnx&#39;, &#39;dort-llama-ort_0.onnx&#39;]
    
    NODES in {name!r}
    1/394: Constant [] -&gt; [&#39;_val_35&#39;]
    2/394: Cast [&#39;_val_35&#39;] -&gt; [&#39;_val_36&#39;]
    3/394: Constant [] -&gt; [&#39;_val_37&#39;]
    4/394: Reshape [&#39;_val_36&#39;, &#39;_val_37&#39;] -&gt; [&#39;_val_38&#39;]
    5/394: Constant [] -&gt; [&#39;_val_39&#39;]
    6/394: Cast [&#39;_val_39&#39;] -&gt; [&#39;_val_40&#39;]
    7/394: Constant [] -&gt; [&#39;_val_41&#39;]
    8/394: Reshape [&#39;_val_40&#39;, &#39;_val_41&#39;] -&gt; [&#39;_val_42&#39;]
    9/394: Constant [] -&gt; [&#39;_val_43&#39;]
    10/394: Cast [&#39;_val_43&#39;] -&gt; [&#39;_val_44&#39;]
    11/394: Constant [] -&gt; [&#39;_val_45&#39;]
    12/394: Reshape [&#39;_val_44&#39;, &#39;_val_45&#39;] -&gt; [&#39;_val_46&#39;]
    13/394: Constant [] -&gt; [&#39;_val_47&#39;]
    14/394: Cast [&#39;_val_47&#39;] -&gt; [&#39;_val_48&#39;]
    15/394: Constant [] -&gt; [&#39;_val_49&#39;]
    16/394: Reshape [&#39;_val_48&#39;, &#39;_val_49&#39;] -&gt; [&#39;_val_50&#39;]
    17/394: Slice [&#39;primals_13&#39;, &#39;_val_38&#39;, &#39;_val_42&#39;, &#39;_val_46&#39;, &#39;_val_50&#39;] -&gt; [&#39;slice_8&#39;]
    18/394: Constant [] -&gt; [&#39;_val_52&#39;]
    19/394: aten_view [&#39;mm_3&#39;, &#39;_val_52&#39;] -&gt; [&#39;view_18&#39;]
    20/394: aten_detach [&#39;rsqrt_1&#39;] -&gt; [&#39;detach_4&#39;]
    21/394: Constant [] -&gt; [&#39;_val_55&#39;]
    22/394: aten_view [&#39;mm_4&#39;, &#39;_val_55&#39;] -&gt; [&#39;view_20&#39;]
    23/394: Constant [] -&gt; [&#39;_val_57&#39;]
    24/394: aten_view [&#39;mm_5&#39;, &#39;_val_57&#39;] -&gt; [&#39;view_22&#39;]
    25/394: Constant [] -&gt; [&#39;_val_59&#39;]
    26/394: aten_view [&#39;mm_6&#39;, &#39;_val_59&#39;] -&gt; [&#39;view_24&#39;]
    27/394: aten_detach [&#39;rsqrt_2&#39;] -&gt; [&#39;detach_6&#39;]
    28/394: aten_mul [&#39;tangents_1&#39;, &#39;primals_3&#39;] -&gt; [&#39;mul_12&#39;]
    29/394: Constant [] -&gt; [&#39;_val_63&#39;]
    30/394: CastLike [&#39;_val_63&#39;, &#39;sigmoid&#39;] -&gt; [&#39;_val_64&#39;]
    31/394: _aten_empty_like_onnx [&#39;sigmoid&#39;, &#39;_val_64&#39;] -&gt; [&#39;empty_like&#39;]
    32/394: Constant [] -&gt; [&#39;_val_66&#39;]
    33/394: aten_pow [&#39;embedding&#39;, &#39;_val_66&#39;] -&gt; [&#39;pow_9&#39;]
    34/394: Constant [] -&gt; [&#39;_val_68&#39;]
    35/394: aten_eq [&#39;primals_14&#39;, &#39;_val_68&#39;] -&gt; [&#39;eq&#39;]
    36/394: aten_detach [&#39;rsqrt&#39;] -&gt; [&#39;detach&#39;]
    37/394: aten_mul [&#39;embedding&#39;, &#39;rsqrt&#39;] -&gt; [&#39;mul&#39;]
    38/394: Constant [] -&gt; [&#39;_val_72&#39;]
    39/394: Cast [&#39;_val_72&#39;] -&gt; [&#39;_val_73&#39;]
    40/394: Constant [] -&gt; [&#39;_val_74&#39;]
    41/394: Reshape [&#39;_val_73&#39;, &#39;_val_74&#39;] -&gt; [&#39;_val_75&#39;]
    42/394: Constant [] -&gt; [&#39;_val_76&#39;]
    43/394: Cast [&#39;_val_76&#39;] -&gt; [&#39;_val_77&#39;]
    44/394: Constant [] -&gt; [&#39;_val_78&#39;]
    45/394: Reshape [&#39;_val_77&#39;, &#39;_val_78&#39;] -&gt; [&#39;_val_79&#39;]
    46/394: Constant [] -&gt; [&#39;_val_80&#39;]
    47/394: Cast [&#39;_val_80&#39;] -&gt; [&#39;_val_81&#39;]
    48/394: Constant [] -&gt; [&#39;_val_82&#39;]
    49/394: Reshape [&#39;_val_81&#39;, &#39;_val_82&#39;] -&gt; [&#39;_val_83&#39;]
    50/394: Constant [] -&gt; [&#39;_val_84&#39;]
    51/394: Cast [&#39;_val_84&#39;] -&gt; [&#39;_val_85&#39;]
    52/394: Constant [] -&gt; [&#39;_val_86&#39;]
    53/394: Reshape [&#39;_val_85&#39;, &#39;_val_86&#39;] -&gt; [&#39;_val_87&#39;]
    54/394: Slice [&#39;primals_12&#39;, &#39;_val_75&#39;, &#39;_val_79&#39;, &#39;_val_83&#39;, &#39;_val_87&#39;] -&gt; [&#39;slice_7&#39;]
    55/394: Transpose [&#39;slice_8&#39;] -&gt; [&#39;_val_89&#39;]
    56/394: Max [&#39;unsqueeze&#39;] -&gt; [&#39;_val_90&#39;]
    57/394: Shape [&#39;_val_90&#39;] -&gt; [&#39;_val_91&#39;]
    58/394: Expand [&#39;unsqueeze&#39;, &#39;_val_91&#39;] -&gt; [&#39;_val_92&#39;]
    59/394: Constant [] -&gt; [&#39;_val_93&#39;]
    60/394: Unsqueeze [&#39;_val_92&#39;, &#39;_val_93&#39;] -&gt; [&#39;_val_94&#39;]
    61/394: Concat [&#39;_val_94&#39;] -&gt; [&#39;_val_95&#39;]
    62/394: GatherND [&#39;_val_89&#39;, &#39;_val_95&#39;] -&gt; [&#39;_val_96&#39;]
    63/394: Transpose [&#39;_val_96&#39;] -&gt; [&#39;index_1&#39;]
    64/394: aten_add [&#39;embedding&#39;, &#39;view_18&#39;] -&gt; [&#39;add_5&#39;]
    65/394: aten_detach [&#39;detach_4&#39;] -&gt; [&#39;detach_5&#39;]
    66/394: aten_mul [&#39;view_20&#39;, &#39;sigmoid&#39;] -&gt; [&#39;mul_8&#39;]
    67/394: aten_detach [&#39;detach_6&#39;] -&gt; [&#39;detach_7&#39;]
    68/394: aten_mul [&#39;mul_12&#39;, &#39;rsqrt_2&#39;] -&gt; [&#39;mul_15&#39;]
    69/394: Constant [] -&gt; [&#39;_val_103&#39;]
    70/394: aten_fill [&#39;empty_like&#39;, &#39;_val_103&#39;] -&gt; [&#39;fill&#39;]
    71/394: Constant [] -&gt; [&#39;_val_105&#39;]
    72/394: aten_mul [&#39;pow_9&#39;, &#39;_val_105&#39;] -&gt; [&#39;mul_45&#39;]
    73/394: aten_unsqueeze [&#39;eq&#39;] -&gt; [&#39;unsqueeze_9&#39;]
    74/394: aten_detach [&#39;detach&#39;] -&gt; [&#39;detach_1&#39;]
    75/394: Transpose [&#39;slice_7&#39;] -&gt; [&#39;_val_109&#39;]
    76/394: Max [&#39;unsqueeze&#39;] -&gt; [&#39;_val_110&#39;]
    77/394: Shape [&#39;_val_110&#39;] -&gt; [&#39;_val_111&#39;]
    78/394: Expand [&#39;unsqueeze&#39;, &#39;_val_111&#39;] -&gt; [&#39;_val_112&#39;]
    79/394: Constant [] -&gt; [&#39;_val_113&#39;]
    80/394: Unsqueeze [&#39;_val_112&#39;, &#39;_val_113&#39;] -&gt; [&#39;_val_114&#39;]
    81/394: Concat [&#39;_val_114&#39;] -&gt; [&#39;_val_115&#39;]
    82/394: GatherND [&#39;_val_109&#39;, &#39;_val_115&#39;] -&gt; [&#39;_val_116&#39;]
    83/394: Transpose [&#39;_val_116&#39;] -&gt; [&#39;index&#39;]
    84/394: aten_unsqueeze [&#39;index_1&#39;] -&gt; [&#39;unsqueeze_8&#39;]
    85/394: aten_mul [&#39;add_5&#39;, &#39;rsqrt_1&#39;] -&gt; [&#39;mul_6&#39;]
    86/394: aten_add [&#39;add_5&#39;, &#39;view_24&#39;] -&gt; [&#39;add_7&#39;]
    87/394: Constant [] -&gt; [&#39;_val_121&#39;]
    88/394: aten_pow [&#39;add_5&#39;, &#39;_val_121&#39;] -&gt; [&#39;pow_7&#39;]
    89/394: aten_detach [&#39;detach_5&#39;] -&gt; [&#39;detach_10&#39;]
    90/394: aten_detach [&#39;detach_7&#39;] -&gt; [&#39;detach_8&#39;]
    91/394: aten_sub [&#39;fill&#39;, &#39;sigmoid&#39;] -&gt; [&#39;sub&#39;]
    92/394: aten_detach [&#39;detach_1&#39;] -&gt; [&#39;detach_14&#39;]
    93/394: aten_unsqueeze [&#39;index&#39;] -&gt; [&#39;unsqueeze_7&#39;]
    94/394: aten_mul [&#39;add_7&#39;, &#39;rsqrt_2&#39;] -&gt; [&#39;mul_10&#39;]
    95/394: aten_mul [&#39;mul_12&#39;, &#39;add_7&#39;] -&gt; [&#39;mul_14&#39;]
    96/394: Constant [] -&gt; [&#39;_val_130&#39;]
    97/394: aten_pow [&#39;add_7&#39;, &#39;_val_130&#39;] -&gt; [&#39;pow_5&#39;]
    98/394: Constant [] -&gt; [&#39;_val_132&#39;]
    99/394: aten_mul [&#39;pow_7&#39;, &#39;_val_132&#39;] -&gt; [&#39;mul_31&#39;]
    100/394: aten_detach [&#39;detach_10&#39;] -&gt; [&#39;detach_11&#39;]
    101/394: aten_detach [&#39;detach_8&#39;] -&gt; [&#39;detach_9&#39;]
    102/394: aten_mul [&#39;view_20&#39;, &#39;sub&#39;] -&gt; [&#39;mul_22&#39;]
    103/394: aten_detach [&#39;detach_14&#39;] -&gt; [&#39;detach_15&#39;]
    104/394: aten_mul [&#39;tangents_1&#39;, &#39;mul_10&#39;] -&gt; [&#39;mul_13&#39;]
    105/394: Constant [] -&gt; [&#39;_val_139&#39;]
    106/394: _aten_sum_dim_onnx [&#39;mul_14&#39;, &#39;_val_139&#39;] -&gt; [&#39;sum_2&#39;]
    107/394: Constant [] -&gt; [&#39;_val_141&#39;]
    108/394: aten_mul [&#39;pow_5&#39;, &#39;_val_141&#39;] -&gt; [&#39;mul_18&#39;]
    109/394: Constant [] -&gt; [&#39;_val_143&#39;]
    110/394: Cast [&#39;_val_143&#39;] -&gt; [&#39;scalar_tensor_default&#39;]
    111/394: aten_pow [&#39;detach_11&#39;, &#39;scalar_tensor_default&#39;] -&gt; [&#39;pow_6&#39;]
    112/394: Constant [] -&gt; [&#39;_val_146&#39;]
    113/394: Cast [&#39;_val_146&#39;] -&gt; [&#39;scalar_tensor_default_1&#39;]
    114/394: aten_pow [&#39;detach_9&#39;, &#39;scalar_tensor_default_1&#39;] -&gt; [&#39;pow_4&#39;]
    115/394: Constant [] -&gt; [&#39;_val_149&#39;]
    116/394: Cast [&#39;_val_149&#39;] -&gt; [&#39;scalar_tensor_default_2&#39;]
    117/394: aten_add [&#39;mul_22&#39;, &#39;scalar_tensor_default_2&#39;] -&gt; [&#39;add_10&#39;]
    118/394: Constant [] -&gt; [&#39;_val_152&#39;]
    119/394: Cast [&#39;_val_152&#39;] -&gt; [&#39;scalar_tensor_default_3&#39;]
    120/394: aten_pow [&#39;detach_15&#39;, &#39;scalar_tensor_default_3&#39;] -&gt; [&#39;pow_8&#39;]
    121/394: Constant [] -&gt; [&#39;_val_155&#39;]
    122/394: _aten_sum_dim_onnx [&#39;mul_13&#39;, &#39;_val_155&#39;] -&gt; [&#39;sum_1&#39;]
    123/394: Constant [] -&gt; [&#39;_val_157&#39;]
    124/394: aten_mul [&#39;sum_2&#39;, &#39;_val_157&#39;] -&gt; [&#39;mul_16&#39;]
    125/394: aten_mul [&#39;sigmoid&#39;, &#39;add_10&#39;] -&gt; [&#39;mul_23&#39;]
    126/394: Constant [] -&gt; [&#39;_val_160&#39;]
    127/394: aten_view [&#39;sum_1&#39;, &#39;_val_160&#39;] -&gt; [&#39;view_25&#39;]
    128/394: aten_mul [&#39;mul_16&#39;, &#39;pow_4&#39;] -&gt; [&#39;mul_17&#39;]
    129/394: Constant [] -&gt; [&#39;_val_163&#39;]
    130/394: aten_expand [&#39;mul_17&#39;, &#39;_val_163&#39;] -&gt; [&#39;expand_7&#39;]
    131/394: Constant [] -&gt; [&#39;_val_165&#39;]
    132/394: Cast [&#39;_val_165&#39;] -&gt; [&#39;scalar_tensor_default_4&#39;]
    133/394: aten_div [&#39;expand_7&#39;, &#39;scalar_tensor_default_4&#39;] -&gt; [&#39;div_1&#39;]
    134/394: aten_mul [&#39;div_1&#39;, &#39;mul_18&#39;] -&gt; [&#39;mul_19&#39;]
    135/394: aten_add [&#39;mul_15&#39;, &#39;mul_19&#39;] -&gt; [&#39;add_9&#39;]
    136/394: Constant [] -&gt; [&#39;_val_170&#39;]
    137/394: aten_view [&#39;add_9&#39;, &#39;_val_170&#39;] -&gt; [&#39;view_26&#39;]
    138/394: aten_t [&#39;view_26&#39;] -&gt; [&#39;t_7&#39;]
    139/394: aten_mm [&#39;view_26&#39;, &#39;t_9&#39;] -&gt; [&#39;mm_8&#39;]
    140/394: aten_mm [&#39;t_7&#39;, &#39;view_23&#39;] -&gt; [&#39;mm_7&#39;]
    141/394: Constant [] -&gt; [&#39;_val_175&#39;]
    142/394: aten_view [&#39;mm_8&#39;, &#39;_val_175&#39;] -&gt; [&#39;view_27&#39;]
    143/394: aten_t [&#39;mm_7&#39;] -&gt; [&#39;t_8&#39;]
    144/394: aten_mul [&#39;view_27&#39;, &#39;mul_8&#39;] -&gt; [&#39;mul_20&#39;]
    145/394: aten_mul [&#39;view_27&#39;, &#39;view_22&#39;] -&gt; [&#39;mul_21&#39;]
    146/394: aten_t [&#39;t_8&#39;] -&gt; [&#39;t_10&#39;]
    147/394: Constant [] -&gt; [&#39;_val_181&#39;]
    148/394: aten_view [&#39;mul_20&#39;, &#39;_val_181&#39;] -&gt; [&#39;view_28&#39;]
    149/394: aten_mul [&#39;mul_21&#39;, &#39;mul_23&#39;] -&gt; [&#39;mul_24&#39;]
    150/394: aten_t [&#39;view_28&#39;] -&gt; [&#39;t_11&#39;]
    151/394: aten_mm [&#39;view_28&#39;, &#39;t_13&#39;] -&gt; [&#39;mm_10&#39;]
    152/394: Constant [] -&gt; [&#39;_val_186&#39;]
    153/394: aten_view [&#39;mul_24&#39;, &#39;_val_186&#39;] -&gt; [&#39;view_30&#39;]
    154/394: aten_mm [&#39;t_11&#39;, &#39;view_19&#39;] -&gt; [&#39;mm_9&#39;]
    155/394: Constant [] -&gt; [&#39;_val_189&#39;]
    156/394: aten_view [&#39;mm_10&#39;, &#39;_val_189&#39;] -&gt; [&#39;view_29&#39;]
    157/394: aten_t [&#39;view_30&#39;] -&gt; [&#39;t_15&#39;]
    158/394: aten_mm [&#39;view_30&#39;, &#39;t_17&#39;] -&gt; [&#39;mm_12&#39;]
    159/394: aten_t [&#39;mm_9&#39;] -&gt; [&#39;t_12&#39;]
    160/394: aten_mm [&#39;t_15&#39;, &#39;view_19&#39;] -&gt; [&#39;mm_11&#39;]
    161/394: Constant [] -&gt; [&#39;_val_195&#39;]
    162/394: aten_view [&#39;mm_12&#39;, &#39;_val_195&#39;] -&gt; [&#39;view_31&#39;]
    163/394: aten_t [&#39;t_12&#39;] -&gt; [&#39;t_14&#39;]
    164/394: aten_t [&#39;mm_11&#39;] -&gt; [&#39;t_16&#39;]
    165/394: aten_add [&#39;view_29&#39;, &#39;view_31&#39;] -&gt; [&#39;add_11&#39;]
    166/394: aten_t [&#39;t_16&#39;] -&gt; [&#39;t_18&#39;]
    167/394: aten_mul [&#39;add_11&#39;, &#39;primals_2&#39;] -&gt; [&#39;mul_25&#39;]
    168/394: aten_mul [&#39;add_11&#39;, &#39;mul_6&#39;] -&gt; [&#39;mul_26&#39;]
    169/394: aten_mul [&#39;mul_25&#39;, &#39;add_5&#39;] -&gt; [&#39;mul_27&#39;]
    170/394: aten_mul [&#39;mul_25&#39;, &#39;rsqrt_1&#39;] -&gt; [&#39;mul_28&#39;]
    171/394: Constant [] -&gt; [&#39;_val_205&#39;]
    172/394: _aten_sum_dim_onnx [&#39;mul_26&#39;, &#39;_val_205&#39;] -&gt; [&#39;sum_3&#39;]
    173/394: Constant [] -&gt; [&#39;_val_207&#39;]
    174/394: _aten_sum_dim_onnx [&#39;mul_27&#39;, &#39;_val_207&#39;] -&gt; [&#39;sum_4&#39;]
    175/394: aten_add [&#39;add_9&#39;, &#39;mul_28&#39;] -&gt; [&#39;add_12&#39;]
    176/394: Constant [] -&gt; [&#39;_val_210&#39;]
    177/394: aten_view [&#39;sum_3&#39;, &#39;_val_210&#39;] -&gt; [&#39;view_32&#39;]
    178/394: Constant [] -&gt; [&#39;_val_212&#39;]
    179/394: aten_mul [&#39;sum_4&#39;, &#39;_val_212&#39;] -&gt; [&#39;mul_29&#39;]
    180/394: aten_mul [&#39;mul_29&#39;, &#39;pow_6&#39;] -&gt; [&#39;mul_30&#39;]
    181/394: Constant [] -&gt; [&#39;_val_215&#39;]
    182/394: aten_expand [&#39;mul_30&#39;, &#39;_val_215&#39;] -&gt; [&#39;expand_8&#39;]
    183/394: Constant [] -&gt; [&#39;_val_217&#39;]
    184/394: Cast [&#39;_val_217&#39;] -&gt; [&#39;scalar_tensor_default_5&#39;]
    185/394: aten_div [&#39;expand_8&#39;, &#39;scalar_tensor_default_5&#39;] -&gt; [&#39;div_2&#39;]
    186/394: aten_mul [&#39;div_2&#39;, &#39;mul_31&#39;] -&gt; [&#39;mul_32&#39;]
    187/394: aten_add [&#39;add_12&#39;, &#39;mul_32&#39;] -&gt; [&#39;add_13&#39;]
    188/394: Constant [] -&gt; [&#39;_val_222&#39;]
    189/394: aten_view [&#39;add_13&#39;, &#39;_val_222&#39;] -&gt; [&#39;view_33&#39;]
    190/394: aten_t [&#39;view_33&#39;] -&gt; [&#39;t_19&#39;]
    191/394: aten_mm [&#39;view_33&#39;, &#39;t_21&#39;] -&gt; [&#39;mm_14&#39;]
    192/394: aten_mm [&#39;t_19&#39;, &#39;view_17&#39;] -&gt; [&#39;mm_13&#39;]
    193/394: Constant [] -&gt; [&#39;_val_227&#39;]
    194/394: aten_view [&#39;mm_14&#39;, &#39;_val_227&#39;] -&gt; [&#39;view_34&#39;]
    195/394: aten_t [&#39;mm_13&#39;] -&gt; [&#39;t_20&#39;]
    196/394: Constant [] -&gt; [&#39;_val_230&#39;]
    197/394: aten_view [&#39;view_34&#39;, &#39;_val_230&#39;] -&gt; [&#39;view_35&#39;]
    198/394: aten_t [&#39;t_20&#39;] -&gt; [&#39;t_22&#39;]
    199/394: Transpose [&#39;view_35&#39;] -&gt; [&#39;transpose_5&#39;]
    200/394: aten_clone [&#39;transpose_5&#39;] -&gt; [&#39;clone_5&#39;]
    201/394: Constant [] -&gt; [&#39;_val_235&#39;]
    202/394: aten_view [&#39;clone_5&#39;, &#39;_val_235&#39;] -&gt; [&#39;view_36&#39;]
    203/394: aten_bmm [&#39;transpose_6&#39;, &#39;view_36&#39;] -&gt; [&#39;bmm_2&#39;]
    204/394: aten_bmm [&#39;view_36&#39;, &#39;transpose_7&#39;] -&gt; [&#39;bmm_3&#39;]
    205/394: Constant [] -&gt; [&#39;_val_239&#39;]
    206/394: aten_view [&#39;bmm_2&#39;, &#39;_val_239&#39;] -&gt; [&#39;view_37&#39;]
    207/394: Constant [] -&gt; [&#39;_val_241&#39;]
    208/394: aten_view [&#39;bmm_3&#39;, &#39;_val_241&#39;] -&gt; [&#39;view_38&#39;]
    209/394: aten_add [&#39;tangents_3&#39;, &#39;view_37&#39;] -&gt; [&#39;add_14&#39;]
    210/394: aten_mul [&#39;view_38&#39;, &#39;detach_13&#39;] -&gt; [&#39;mul_33&#39;]
    211/394: Transpose [&#39;add_14&#39;] -&gt; [&#39;transpose_11&#39;]
    212/394: Constant [] -&gt; [&#39;_val_246&#39;]
    213/394: _aten_sum_dim_onnx [&#39;mul_33&#39;, &#39;_val_246&#39;] -&gt; [&#39;sum_5&#39;]
    214/394: aten_clone [&#39;transpose_11&#39;] -&gt; [&#39;clone_6&#39;]
    215/394: aten_mul [&#39;detach_13&#39;, &#39;sum_5&#39;] -&gt; [&#39;mul_34&#39;]
    216/394: Constant [] -&gt; [&#39;_val_250&#39;]
    217/394: aten_view [&#39;clone_6&#39;, &#39;_val_250&#39;] -&gt; [&#39;view_42&#39;]
    218/394: aten_sub [&#39;mul_33&#39;, &#39;mul_34&#39;] -&gt; [&#39;sub_1&#39;]
    219/394: Constant [] -&gt; [&#39;_val_253&#39;]
    220/394: aten_view [&#39;view_42&#39;, &#39;_val_253&#39;] -&gt; [&#39;view_45&#39;]
    221/394: Constant [] -&gt; [&#39;_val_255&#39;]
    222/394: aten_div [&#39;sub_1&#39;, &#39;_val_255&#39;] -&gt; [&#39;div_3&#39;]
    223/394: aten_t [&#39;view_45&#39;] -&gt; [&#39;t_23&#39;]
    224/394: aten_mm [&#39;view_45&#39;, &#39;t_25&#39;] -&gt; [&#39;mm_16&#39;]
    225/394: Constant [] -&gt; [&#39;_val_259&#39;]
    226/394: aten_view [&#39;div_3&#39;, &#39;_val_259&#39;] -&gt; [&#39;view_39&#39;]
    227/394: aten_mm [&#39;t_23&#39;, &#39;view_1&#39;] -&gt; [&#39;mm_15&#39;]
    228/394: Constant [] -&gt; [&#39;_val_262&#39;]
    229/394: aten_view [&#39;mm_16&#39;, &#39;_val_262&#39;] -&gt; [&#39;view_46&#39;]
    230/394: aten_bmm [&#39;transpose_8&#39;, &#39;view_39&#39;] -&gt; [&#39;bmm_4&#39;]
    231/394: aten_bmm [&#39;view_39&#39;, &#39;transpose_9&#39;] -&gt; [&#39;bmm_5&#39;]
    232/394: aten_t [&#39;mm_15&#39;] -&gt; [&#39;t_24&#39;]
    233/394: Constant [] -&gt; [&#39;_val_267&#39;]
    234/394: aten_view [&#39;bmm_4&#39;, &#39;_val_267&#39;] -&gt; [&#39;view_40&#39;]
    235/394: Constant [] -&gt; [&#39;_val_269&#39;]
    236/394: aten_view [&#39;bmm_5&#39;, &#39;_val_269&#39;] -&gt; [&#39;view_41&#39;]
    237/394: aten_t [&#39;t_24&#39;] -&gt; [&#39;t_26&#39;]
    238/394: Transpose [&#39;view_40&#39;] -&gt; [&#39;transpose_10&#39;]
    239/394: aten_mul [&#39;view_41&#39;, &#39;unsqueeze_8&#39;] -&gt; [&#39;mul_37&#39;]
    240/394: aten_mul [&#39;view_41&#39;, &#39;unsqueeze_7&#39;] -&gt; [&#39;mul_38&#39;]
    241/394: aten_add [&#39;tangents_2&#39;, &#39;transpose_10&#39;] -&gt; [&#39;add_15&#39;]
    242/394: Constant [] -&gt; [&#39;_val_276&#39;]
    243/394: Cast [&#39;_val_276&#39;] -&gt; [&#39;_val_277&#39;]
    244/394: Constant [] -&gt; [&#39;_val_278&#39;]
    245/394: Reshape [&#39;_val_277&#39;, &#39;_val_278&#39;] -&gt; [&#39;_val_279&#39;]
    246/394: Constant [] -&gt; [&#39;_val_280&#39;]
    247/394: Cast [&#39;_val_280&#39;] -&gt; [&#39;_val_281&#39;]
    248/394: Constant [] -&gt; [&#39;_val_282&#39;]
    249/394: Reshape [&#39;_val_281&#39;, &#39;_val_282&#39;] -&gt; [&#39;_val_283&#39;]
    250/394: Constant [] -&gt; [&#39;_val_284&#39;]
    251/394: Cast [&#39;_val_284&#39;] -&gt; [&#39;_val_285&#39;]
    252/394: Constant [] -&gt; [&#39;_val_286&#39;]
    253/394: Reshape [&#39;_val_285&#39;, &#39;_val_286&#39;] -&gt; [&#39;_val_287&#39;]
    254/394: Constant [] -&gt; [&#39;_val_288&#39;]
    255/394: Cast [&#39;_val_288&#39;] -&gt; [&#39;_val_289&#39;]
    256/394: Constant [] -&gt; [&#39;_val_290&#39;]
    257/394: Reshape [&#39;_val_289&#39;, &#39;_val_290&#39;] -&gt; [&#39;_val_291&#39;]
    258/394: Slice [&#39;mul_37&#39;, &#39;_val_279&#39;, &#39;_val_283&#39;, &#39;_val_287&#39;, &#39;_val_291&#39;] -&gt; [&#39;slice_15&#39;]
    259/394: Constant [] -&gt; [&#39;_val_293&#39;]
    260/394: Cast [&#39;_val_293&#39;] -&gt; [&#39;_val_294&#39;]
    261/394: Constant [] -&gt; [&#39;_val_295&#39;]
    262/394: Reshape [&#39;_val_294&#39;, &#39;_val_295&#39;] -&gt; [&#39;_val_296&#39;]
    263/394: Constant [] -&gt; [&#39;_val_297&#39;]
    264/394: Cast [&#39;_val_297&#39;] -&gt; [&#39;_val_298&#39;]
    265/394: Constant [] -&gt; [&#39;_val_299&#39;]
    266/394: Reshape [&#39;_val_298&#39;, &#39;_val_299&#39;] -&gt; [&#39;_val_300&#39;]
    267/394: Constant [] -&gt; [&#39;_val_301&#39;]
    268/394: Cast [&#39;_val_301&#39;] -&gt; [&#39;_val_302&#39;]
    269/394: Constant [] -&gt; [&#39;_val_303&#39;]
    270/394: Reshape [&#39;_val_302&#39;, &#39;_val_303&#39;] -&gt; [&#39;_val_304&#39;]
    271/394: Constant [] -&gt; [&#39;_val_305&#39;]
    272/394: Cast [&#39;_val_305&#39;] -&gt; [&#39;_val_306&#39;]
    273/394: Constant [] -&gt; [&#39;_val_307&#39;]
    274/394: Reshape [&#39;_val_306&#39;, &#39;_val_307&#39;] -&gt; [&#39;_val_308&#39;]
    275/394: Slice [&#39;mul_37&#39;, &#39;_val_296&#39;, &#39;_val_300&#39;, &#39;_val_304&#39;, &#39;_val_308&#39;] -&gt; [&#39;slice_16&#39;]
    276/394: aten_mul [&#39;add_15&#39;, &#39;unsqueeze_8&#39;] -&gt; [&#39;mul_35&#39;]
    277/394: aten_mul [&#39;add_15&#39;, &#39;unsqueeze_7&#39;] -&gt; [&#39;mul_36&#39;]
    278/394: aten_neg [&#39;slice_15&#39;] -&gt; [&#39;neg_3&#39;]
    279/394: Constant [] -&gt; [&#39;_val_313&#39;]
    280/394: aten_new_zeros [&#39;slice_16&#39;, &#39;_val_313&#39;] -&gt; [&#39;new_zeros_3&#39;]
    281/394: Constant [] -&gt; [&#39;_val_315&#39;]
    282/394: Cast [&#39;_val_315&#39;] -&gt; [&#39;_val_316&#39;]
    283/394: Constant [] -&gt; [&#39;_val_317&#39;]
    284/394: Reshape [&#39;_val_316&#39;, &#39;_val_317&#39;] -&gt; [&#39;_val_318&#39;]
    285/394: Constant [] -&gt; [&#39;_val_319&#39;]
    286/394: Cast [&#39;_val_319&#39;] -&gt; [&#39;_val_320&#39;]
    287/394: Constant [] -&gt; [&#39;_val_321&#39;]
    288/394: Reshape [&#39;_val_320&#39;, &#39;_val_321&#39;] -&gt; [&#39;_val_322&#39;]
    289/394: Constant [] -&gt; [&#39;_val_323&#39;]
    290/394: Cast [&#39;_val_323&#39;] -&gt; [&#39;_val_324&#39;]
    291/394: Constant [] -&gt; [&#39;_val_325&#39;]
    292/394: Reshape [&#39;_val_324&#39;, &#39;_val_325&#39;] -&gt; [&#39;_val_326&#39;]
    293/394: Constant [] -&gt; [&#39;_val_327&#39;]
    294/394: Cast [&#39;_val_327&#39;] -&gt; [&#39;_val_328&#39;]
    295/394: Constant [] -&gt; [&#39;_val_329&#39;]
    296/394: Reshape [&#39;_val_328&#39;, &#39;_val_329&#39;] -&gt; [&#39;_val_330&#39;]
    297/394: Slice [&#39;mul_35&#39;, &#39;_val_318&#39;, &#39;_val_322&#39;, &#39;_val_326&#39;, &#39;_val_330&#39;] -&gt; [&#39;slice_13&#39;]
    298/394: Constant [] -&gt; [&#39;_val_332&#39;]
    299/394: Cast [&#39;_val_332&#39;] -&gt; [&#39;_val_333&#39;]
    300/394: Constant [] -&gt; [&#39;_val_334&#39;]
    301/394: Reshape [&#39;_val_333&#39;, &#39;_val_334&#39;] -&gt; [&#39;_val_335&#39;]
    302/394: Constant [] -&gt; [&#39;_val_336&#39;]
    303/394: Cast [&#39;_val_336&#39;] -&gt; [&#39;_val_337&#39;]
    304/394: Constant [] -&gt; [&#39;_val_338&#39;]
    305/394: Reshape [&#39;_val_337&#39;, &#39;_val_338&#39;] -&gt; [&#39;_val_339&#39;]
    306/394: Constant [] -&gt; [&#39;_val_340&#39;]
    307/394: Cast [&#39;_val_340&#39;] -&gt; [&#39;_val_341&#39;]
    308/394: Constant [] -&gt; [&#39;_val_342&#39;]
    309/394: Reshape [&#39;_val_341&#39;, &#39;_val_342&#39;] -&gt; [&#39;_val_343&#39;]
    310/394: Constant [] -&gt; [&#39;_val_344&#39;]
    311/394: Cast [&#39;_val_344&#39;] -&gt; [&#39;_val_345&#39;]
    312/394: Constant [] -&gt; [&#39;_val_346&#39;]
    313/394: Reshape [&#39;_val_345&#39;, &#39;_val_346&#39;] -&gt; [&#39;_val_347&#39;]
    314/394: Slice [&#39;mul_35&#39;, &#39;_val_335&#39;, &#39;_val_339&#39;, &#39;_val_343&#39;, &#39;_val_347&#39;] -&gt; [&#39;slice_14&#39;]
    315/394: Constant [] -&gt; [&#39;_val_349&#39;]
    316/394: aten_new_zeros [&#39;neg_3&#39;, &#39;_val_349&#39;] -&gt; [&#39;new_zeros_2&#39;]
    317/394: Constant [] -&gt; [&#39;_val_351&#39;]
    318/394: Constant [] -&gt; [&#39;_val_352&#39;]
    319/394: Constant [] -&gt; [&#39;_val_353&#39;]
    320/394: aten_slice_scatter [&#39;new_zeros_3&#39;, &#39;slice_16&#39;, &#39;_val_351&#39;, &#39;_val_352&#39;, &#39;_val_353&#39;] -&gt; [&#39;slice_scatter_3&#39;]
    321/394: aten_neg [&#39;slice_13&#39;] -&gt; [&#39;neg_2&#39;]
    322/394: Constant [] -&gt; [&#39;_val_356&#39;]
    323/394: aten_new_zeros [&#39;slice_14&#39;, &#39;_val_356&#39;] -&gt; [&#39;new_zeros_1&#39;]
    324/394: Constant [] -&gt; [&#39;_val_358&#39;]
    325/394: Constant [] -&gt; [&#39;_val_359&#39;]
    326/394: Constant [] -&gt; [&#39;_val_360&#39;]
    327/394: aten_slice_scatter [&#39;new_zeros_2&#39;, &#39;neg_3&#39;, &#39;_val_358&#39;, &#39;_val_359&#39;, &#39;_val_360&#39;] -&gt; [&#39;slice_scatter_2&#39;]
    328/394: Constant [] -&gt; [&#39;_val_362&#39;]
    329/394: aten_new_zeros [&#39;neg_2&#39;, &#39;_val_362&#39;] -&gt; [&#39;new_zeros&#39;]
    330/394: Constant [] -&gt; [&#39;_val_364&#39;]
    331/394: Constant [] -&gt; [&#39;_val_365&#39;]
    332/394: Constant [] -&gt; [&#39;_val_366&#39;]
    333/394: aten_slice_scatter [&#39;new_zeros_1&#39;, &#39;slice_14&#39;, &#39;_val_364&#39;, &#39;_val_365&#39;, &#39;_val_366&#39;] -&gt; [&#39;slice_scatter_1&#39;]
    334/394: aten_add [&#39;slice_scatter_2&#39;, &#39;slice_scatter_3&#39;] -&gt; [&#39;add_18&#39;]
    335/394: Constant [] -&gt; [&#39;_val_369&#39;]
    336/394: Constant [] -&gt; [&#39;_val_370&#39;]
    337/394: Constant [] -&gt; [&#39;_val_371&#39;]
    338/394: aten_slice_scatter [&#39;new_zeros&#39;, &#39;neg_2&#39;, &#39;_val_369&#39;, &#39;_val_370&#39;, &#39;_val_371&#39;] -&gt; [&#39;slice_scatter&#39;]
    339/394: aten_add [&#39;add_18&#39;, &#39;mul_38&#39;] -&gt; [&#39;add_19&#39;]
    340/394: aten_add [&#39;slice_scatter&#39;, &#39;slice_scatter_1&#39;] -&gt; [&#39;add_16&#39;]
    341/394: Transpose [&#39;add_19&#39;] -&gt; [&#39;transpose_13&#39;]
    342/394: aten_add [&#39;add_16&#39;, &#39;mul_36&#39;] -&gt; [&#39;add_17&#39;]
    343/394: aten_clone [&#39;transpose_13&#39;] -&gt; [&#39;clone_8&#39;]
    344/394: Transpose [&#39;add_17&#39;] -&gt; [&#39;transpose_12&#39;]
    345/394: Constant [] -&gt; [&#39;_val_379&#39;]
    346/394: aten_view [&#39;clone_8&#39;, &#39;_val_379&#39;] -&gt; [&#39;view_44&#39;]
    347/394: aten_clone [&#39;transpose_12&#39;] -&gt; [&#39;clone_7&#39;]
    348/394: Constant [] -&gt; [&#39;_val_382&#39;]
    349/394: aten_view [&#39;view_44&#39;, &#39;_val_382&#39;] -&gt; [&#39;view_49&#39;]
    350/394: Constant [] -&gt; [&#39;_val_384&#39;]
    351/394: aten_view [&#39;clone_7&#39;, &#39;_val_384&#39;] -&gt; [&#39;view_43&#39;]
    352/394: aten_t [&#39;view_49&#39;] -&gt; [&#39;t_31&#39;]
    353/394: aten_mm [&#39;view_49&#39;, &#39;t_33&#39;] -&gt; [&#39;mm_20&#39;]
    354/394: Constant [] -&gt; [&#39;_val_388&#39;]
    355/394: aten_view [&#39;view_43&#39;, &#39;_val_388&#39;] -&gt; [&#39;view_47&#39;]
    356/394: aten_mm [&#39;t_31&#39;, &#39;view_1&#39;] -&gt; [&#39;mm_19&#39;]
    357/394: Constant [] -&gt; [&#39;_val_391&#39;]
    358/394: aten_view [&#39;mm_20&#39;, &#39;_val_391&#39;] -&gt; [&#39;view_50&#39;]
    359/394: aten_t [&#39;view_47&#39;] -&gt; [&#39;t_27&#39;]
    360/394: aten_mm [&#39;view_47&#39;, &#39;t_29&#39;] -&gt; [&#39;mm_18&#39;]
    361/394: aten_t [&#39;mm_19&#39;] -&gt; [&#39;t_32&#39;]
    362/394: aten_mm [&#39;t_27&#39;, &#39;view_1&#39;] -&gt; [&#39;mm_17&#39;]
    363/394: Constant [] -&gt; [&#39;_val_397&#39;]
    364/394: aten_view [&#39;mm_18&#39;, &#39;_val_397&#39;] -&gt; [&#39;view_48&#39;]
    365/394: aten_t [&#39;t_32&#39;] -&gt; [&#39;t_34&#39;]
    366/394: aten_t [&#39;mm_17&#39;] -&gt; [&#39;t_28&#39;]
    367/394: aten_add [&#39;view_46&#39;, &#39;view_48&#39;] -&gt; [&#39;add_20&#39;]
    368/394: aten_t [&#39;t_28&#39;] -&gt; [&#39;t_30&#39;]
    369/394: aten_add [&#39;add_20&#39;, &#39;view_50&#39;] -&gt; [&#39;add_21&#39;]
    370/394: aten_mul [&#39;add_21&#39;, &#39;primals_1&#39;] -&gt; [&#39;mul_39&#39;]
    371/394: aten_mul [&#39;add_21&#39;, &#39;mul&#39;] -&gt; [&#39;mul_40&#39;]
    372/394: aten_mul [&#39;mul_39&#39;, &#39;embedding&#39;] -&gt; [&#39;mul_41&#39;]
    373/394: aten_mul [&#39;mul_39&#39;, &#39;rsqrt&#39;] -&gt; [&#39;mul_42&#39;]
    374/394: Constant [] -&gt; [&#39;_val_408&#39;]
    375/394: _aten_sum_dim_onnx [&#39;mul_40&#39;, &#39;_val_408&#39;] -&gt; [&#39;sum_6&#39;]
    376/394: Constant [] -&gt; [&#39;_val_410&#39;]
    377/394: _aten_sum_dim_onnx [&#39;mul_41&#39;, &#39;_val_410&#39;] -&gt; [&#39;sum_7&#39;]
    378/394: aten_add [&#39;add_13&#39;, &#39;mul_42&#39;] -&gt; [&#39;add_22&#39;]
    379/394: Constant [] -&gt; [&#39;_val_413&#39;]
    380/394: aten_view [&#39;sum_6&#39;, &#39;_val_413&#39;] -&gt; [&#39;view_51&#39;]
    381/394: Constant [] -&gt; [&#39;_val_415&#39;]
    382/394: aten_mul [&#39;sum_7&#39;, &#39;_val_415&#39;] -&gt; [&#39;mul_43&#39;]
    383/394: aten_mul [&#39;mul_43&#39;, &#39;pow_8&#39;] -&gt; [&#39;mul_44&#39;]
    384/394: Constant [] -&gt; [&#39;_val_418&#39;]
    385/394: aten_expand [&#39;mul_44&#39;, &#39;_val_418&#39;] -&gt; [&#39;expand_9&#39;]
    386/394: Constant [] -&gt; [&#39;_val_420&#39;]
    387/394: Cast [&#39;_val_420&#39;] -&gt; [&#39;scalar_tensor_default_6&#39;]
    388/394: aten_div [&#39;expand_9&#39;, &#39;scalar_tensor_default_6&#39;] -&gt; [&#39;div_4&#39;]
    389/394: aten_mul [&#39;div_4&#39;, &#39;mul_45&#39;] -&gt; [&#39;mul_46&#39;]
    390/394: aten_add [&#39;add_22&#39;, &#39;mul_46&#39;] -&gt; [&#39;add_23&#39;]
    391/394: Constant [] -&gt; [&#39;_val_425&#39;]
    392/394: aten_masked_fill [&#39;add_23&#39;, &#39;unsqueeze_9&#39;, &#39;_val_425&#39;] -&gt; [&#39;masked_fill_3&#39;]
    393/394: Constant [] -&gt; [&#39;_val_427&#39;]
    394/394: aten_new_zeros [&#39;add_23&#39;, &#39;_val_427&#39;] -&gt; [&#39;new_zeros_4&#39;]
    
    NODES in {name!r}
    1/375: aten_t [&#39;primals_5&#39;] -&gt; [&#39;t&#39;]
    2/375: aten_t [&#39;primals_6&#39;] -&gt; [&#39;t_1&#39;]
    3/375: aten_t [&#39;primals_7&#39;] -&gt; [&#39;t_2&#39;]
    4/375: Constant [] -&gt; [&#39;_val_18&#39;]
    5/375: Cast [&#39;_val_18&#39;] -&gt; [&#39;_val_19&#39;]
    6/375: Constant [] -&gt; [&#39;_val_20&#39;]
    7/375: Reshape [&#39;_val_19&#39;, &#39;_val_20&#39;] -&gt; [&#39;_val_21&#39;]
    8/375: Constant [] -&gt; [&#39;_val_22&#39;]
    9/375: Cast [&#39;_val_22&#39;] -&gt; [&#39;_val_23&#39;]
    10/375: Constant [] -&gt; [&#39;_val_24&#39;]
    11/375: Reshape [&#39;_val_23&#39;, &#39;_val_24&#39;] -&gt; [&#39;_val_25&#39;]
    12/375: Constant [] -&gt; [&#39;_val_26&#39;]
    13/375: Cast [&#39;_val_26&#39;] -&gt; [&#39;_val_27&#39;]
    14/375: Constant [] -&gt; [&#39;_val_28&#39;]
    15/375: Reshape [&#39;_val_27&#39;, &#39;_val_28&#39;] -&gt; [&#39;_val_29&#39;]
    16/375: Constant [] -&gt; [&#39;_val_30&#39;]
    17/375: Cast [&#39;_val_30&#39;] -&gt; [&#39;_val_31&#39;]
    18/375: Constant [] -&gt; [&#39;_val_32&#39;]
    19/375: Reshape [&#39;_val_31&#39;, &#39;_val_32&#39;] -&gt; [&#39;_val_33&#39;]
    20/375: Slice [&#39;primals_12&#39;, &#39;_val_21&#39;, &#39;_val_25&#39;, &#39;_val_29&#39;, &#39;_val_33&#39;] -&gt; [&#39;slice_7&#39;]
    21/375: Constant [] -&gt; [&#39;_val_35&#39;]
    22/375: Cast [&#39;_val_35&#39;] -&gt; [&#39;_val_36&#39;]
    23/375: Constant [] -&gt; [&#39;_val_37&#39;]
    24/375: Reshape [&#39;_val_36&#39;, &#39;_val_37&#39;] -&gt; [&#39;_val_38&#39;]
    25/375: Constant [] -&gt; [&#39;_val_39&#39;]
    26/375: Cast [&#39;_val_39&#39;] -&gt; [&#39;_val_40&#39;]
    27/375: Constant [] -&gt; [&#39;_val_41&#39;]
    28/375: Reshape [&#39;_val_40&#39;, &#39;_val_41&#39;] -&gt; [&#39;_val_42&#39;]
    29/375: Constant [] -&gt; [&#39;_val_43&#39;]
    30/375: Cast [&#39;_val_43&#39;] -&gt; [&#39;_val_44&#39;]
    31/375: Constant [] -&gt; [&#39;_val_45&#39;]
    32/375: Reshape [&#39;_val_44&#39;, &#39;_val_45&#39;] -&gt; [&#39;_val_46&#39;]
    33/375: Constant [] -&gt; [&#39;_val_47&#39;]
    34/375: Cast [&#39;_val_47&#39;] -&gt; [&#39;_val_48&#39;]
    35/375: Constant [] -&gt; [&#39;_val_49&#39;]
    36/375: Reshape [&#39;_val_48&#39;, &#39;_val_49&#39;] -&gt; [&#39;_val_50&#39;]
    37/375: Slice [&#39;primals_13&#39;, &#39;_val_38&#39;, &#39;_val_42&#39;, &#39;_val_46&#39;, &#39;_val_50&#39;] -&gt; [&#39;slice_8&#39;]
    38/375: Constant [] -&gt; [&#39;_val_52&#39;]
    39/375: Cast [&#39;_val_52&#39;] -&gt; [&#39;_val_53&#39;]
    40/375: Constant [] -&gt; [&#39;_val_54&#39;]
    41/375: Cast [&#39;_val_54&#39;] -&gt; [&#39;_val_55&#39;]
    42/375: Constant [] -&gt; [&#39;_val_56&#39;]
    43/375: Cast [&#39;_val_56&#39;] -&gt; [&#39;_val_57&#39;]
    44/375: Range [&#39;_val_55&#39;, &#39;_val_53&#39;, &#39;_val_57&#39;] -&gt; [&#39;arange&#39;]
    45/375: aten_t [&#39;primals_8&#39;] -&gt; [&#39;t_3&#39;]
    46/375: aten_embedding [&#39;primals_4&#39;, &#39;primals_14&#39;] -&gt; [&#39;embedding&#39;]
    47/375: aten_t [&#39;primals_9&#39;] -&gt; [&#39;t_4&#39;]
    48/375: Constant [] -&gt; [&#39;_val_62&#39;]
    49/375: Constant [] -&gt; [&#39;_val_63&#39;]
    50/375: aten_full [&#39;_val_62&#39;, &#39;_val_63&#39;] -&gt; [&#39;full&#39;]
    51/375: Constant [] -&gt; [&#39;_val_65&#39;]
    52/375: Constant [] -&gt; [&#39;_val_66&#39;]
    53/375: CastLike [&#39;_val_65&#39;, &#39;_val_66&#39;] -&gt; [&#39;_val_67&#39;]
    54/375: Constant [] -&gt; [&#39;_val_68&#39;]
    55/375: Constant [] -&gt; [&#39;_val_69&#39;]
    56/375: CastLike [&#39;_val_68&#39;, &#39;_val_69&#39;] -&gt; [&#39;_val_70&#39;]
    57/375: Constant [] -&gt; [&#39;_val_71&#39;]
    58/375: Range [&#39;_val_67&#39;, &#39;_val_71&#39;, &#39;_val_70&#39;] -&gt; [&#39;arange_1&#39;]
    59/375: Constant [] -&gt; [&#39;_val_73&#39;]
    60/375: Cast [&#39;_val_73&#39;] -&gt; [&#39;_val_74&#39;]
    61/375: Constant [] -&gt; [&#39;_val_75&#39;]
    62/375: Reshape [&#39;_val_74&#39;, &#39;_val_75&#39;] -&gt; [&#39;_val_76&#39;]
    63/375: Constant [] -&gt; [&#39;_val_77&#39;]
    64/375: Cast [&#39;_val_77&#39;] -&gt; [&#39;_val_78&#39;]
    65/375: Constant [] -&gt; [&#39;_val_79&#39;]
    66/375: Reshape [&#39;_val_78&#39;, &#39;_val_79&#39;] -&gt; [&#39;_val_80&#39;]
    67/375: Constant [] -&gt; [&#39;_val_81&#39;]
    68/375: Cast [&#39;_val_81&#39;] -&gt; [&#39;_val_82&#39;]
    69/375: Constant [] -&gt; [&#39;_val_83&#39;]
    70/375: Reshape [&#39;_val_82&#39;, &#39;_val_83&#39;] -&gt; [&#39;_val_84&#39;]
    71/375: Constant [] -&gt; [&#39;_val_85&#39;]
    72/375: Cast [&#39;_val_85&#39;] -&gt; [&#39;_val_86&#39;]
    73/375: Constant [] -&gt; [&#39;_val_87&#39;]
    74/375: Reshape [&#39;_val_86&#39;, &#39;_val_87&#39;] -&gt; [&#39;_val_88&#39;]
    75/375: Slice [&#39;primals_15&#39;, &#39;_val_76&#39;, &#39;_val_80&#39;, &#39;_val_84&#39;, &#39;_val_88&#39;] -&gt; [&#39;slice_3&#39;]
    76/375: aten_t [&#39;primals_10&#39;] -&gt; [&#39;t_5&#39;]
    77/375: aten_t [&#39;primals_11&#39;] -&gt; [&#39;t_6&#39;]
    78/375: aten_t [&#39;t&#39;] -&gt; [&#39;t_33&#39;]
    79/375: aten_t [&#39;t_1&#39;] -&gt; [&#39;t_29&#39;]
    80/375: aten_t [&#39;t_2&#39;] -&gt; [&#39;t_25&#39;]
    81/375: aten_unsqueeze [&#39;arange&#39;] -&gt; [&#39;unsqueeze&#39;]
    82/375: aten_t [&#39;t_3&#39;] -&gt; [&#39;t_21&#39;]
    83/375: Constant [] -&gt; [&#39;_val_97&#39;]
    84/375: Cast [&#39;_val_97&#39;] -&gt; [&#39;scalar_tensor_default&#39;]
    85/375: aten_pow [&#39;embedding&#39;, &#39;scalar_tensor_default&#39;] -&gt; [&#39;pow_1&#39;]
    86/375: aten_t [&#39;t_4&#39;] -&gt; [&#39;t_17&#39;]
    87/375: Constant [] -&gt; [&#39;_val_101&#39;]
    88/375: aten_add [&#39;arange_1&#39;, &#39;_val_101&#39;] -&gt; [&#39;add&#39;]
    89/375: aten_unsqueeze [&#39;slice_3&#39;] -&gt; [&#39;unsqueeze_3&#39;]
    90/375: aten_t [&#39;t_5&#39;] -&gt; [&#39;t_13&#39;]
    91/375: aten_t [&#39;t_6&#39;] -&gt; [&#39;t_9&#39;]
    92/375: Transpose [&#39;slice_7&#39;] -&gt; [&#39;_val_106&#39;]
    93/375: Max [&#39;unsqueeze&#39;] -&gt; [&#39;_val_107&#39;]
    94/375: Shape [&#39;_val_107&#39;] -&gt; [&#39;_val_108&#39;]
    95/375: Expand [&#39;unsqueeze&#39;, &#39;_val_108&#39;] -&gt; [&#39;_val_109&#39;]
    96/375: Constant [] -&gt; [&#39;_val_110&#39;]
    97/375: Unsqueeze [&#39;_val_109&#39;, &#39;_val_110&#39;] -&gt; [&#39;_val_111&#39;]
    98/375: Concat [&#39;_val_111&#39;] -&gt; [&#39;_val_112&#39;]
    99/375: GatherND [&#39;_val_106&#39;, &#39;_val_112&#39;] -&gt; [&#39;_val_113&#39;]
    100/375: Transpose [&#39;_val_113&#39;] -&gt; [&#39;index&#39;]
    101/375: Transpose [&#39;slice_8&#39;] -&gt; [&#39;_val_115&#39;]
    102/375: Max [&#39;unsqueeze&#39;] -&gt; [&#39;_val_116&#39;]
    103/375: Shape [&#39;_val_116&#39;] -&gt; [&#39;_val_117&#39;]
    104/375: Expand [&#39;unsqueeze&#39;, &#39;_val_117&#39;] -&gt; [&#39;_val_118&#39;]
    105/375: Constant [] -&gt; [&#39;_val_119&#39;]
    106/375: Unsqueeze [&#39;_val_118&#39;, &#39;_val_119&#39;] -&gt; [&#39;_val_120&#39;]
    107/375: Concat [&#39;_val_120&#39;] -&gt; [&#39;_val_121&#39;]
    108/375: GatherND [&#39;_val_115&#39;, &#39;_val_121&#39;] -&gt; [&#39;_val_122&#39;]
    109/375: Transpose [&#39;_val_122&#39;] -&gt; [&#39;index_1&#39;]
    110/375: Constant [] -&gt; [&#39;_val_124&#39;]
    111/375: aten_mean_dim [&#39;pow_1&#39;, &#39;_val_124&#39;] -&gt; [&#39;mean&#39;]
    112/375: Constant [] -&gt; [&#39;_val_126&#39;]
    113/375: aten_view [&#39;add&#39;, &#39;_val_126&#39;] -&gt; [&#39;view&#39;]
    114/375: aten_unsqueeze [&#39;unsqueeze_3&#39;] -&gt; [&#39;unsqueeze_4&#39;]
    115/375: aten_unsqueeze [&#39;index&#39;] -&gt; [&#39;unsqueeze_7&#39;]
    116/375: aten_unsqueeze [&#39;index_1&#39;] -&gt; [&#39;unsqueeze_8&#39;]
    117/375: Constant [] -&gt; [&#39;_val_131&#39;]
    118/375: aten_add [&#39;mean&#39;, &#39;_val_131&#39;] -&gt; [&#39;add_1&#39;]
    119/375: aten_lt [&#39;arange_1&#39;, &#39;view&#39;] -&gt; [&#39;lt&#39;]
    120/375: Constant [] -&gt; [&#39;_val_134&#39;]
    121/375: Cast [&#39;_val_134&#39;] -&gt; [&#39;_val_135&#39;]
    122/375: Constant [] -&gt; [&#39;_val_136&#39;]
    123/375: Reshape [&#39;_val_135&#39;, &#39;_val_136&#39;] -&gt; [&#39;_val_137&#39;]
    124/375: Constant [] -&gt; [&#39;_val_138&#39;]
    125/375: Cast [&#39;_val_138&#39;] -&gt; [&#39;_val_139&#39;]
    126/375: Constant [] -&gt; [&#39;_val_140&#39;]
    127/375: Reshape [&#39;_val_139&#39;, &#39;_val_140&#39;] -&gt; [&#39;_val_141&#39;]
    128/375: Constant [] -&gt; [&#39;_val_142&#39;]
    129/375: Cast [&#39;_val_142&#39;] -&gt; [&#39;_val_143&#39;]
    130/375: Constant [] -&gt; [&#39;_val_144&#39;]
    131/375: Reshape [&#39;_val_143&#39;, &#39;_val_144&#39;] -&gt; [&#39;_val_145&#39;]
    132/375: Constant [] -&gt; [&#39;_val_146&#39;]
    133/375: Cast [&#39;_val_146&#39;] -&gt; [&#39;_val_147&#39;]
    134/375: Constant [] -&gt; [&#39;_val_148&#39;]
    135/375: Reshape [&#39;_val_147&#39;, &#39;_val_148&#39;] -&gt; [&#39;_val_149&#39;]
    136/375: Slice [&#39;unsqueeze_4&#39;, &#39;_val_137&#39;, &#39;_val_141&#39;, &#39;_val_145&#39;, &#39;_val_149&#39;] -&gt; [&#39;slice_4&#39;]
    137/375: aten_rsqrt [&#39;add_1&#39;] -&gt; [&#39;rsqrt&#39;]
    138/375: Constant [] -&gt; [&#39;_val_152&#39;]
    139/375: aten_masked_fill [&#39;full&#39;, &#39;lt&#39;, &#39;_val_152&#39;] -&gt; [&#39;masked_fill&#39;]
    140/375: Constant [] -&gt; [&#39;_val_154&#39;]
    141/375: aten_expand [&#39;slice_4&#39;, &#39;_val_154&#39;] -&gt; [&#39;expand_1&#39;]
    142/375: aten_mul [&#39;embedding&#39;, &#39;rsqrt&#39;] -&gt; [&#39;mul&#39;]
    143/375: aten_unsqueeze [&#39;masked_fill&#39;] -&gt; [&#39;unsqueeze_5&#39;]
    144/375: Constant [] -&gt; [&#39;_val_158&#39;]
    145/375: aten_rsub [&#39;expand_1&#39;, &#39;_val_158&#39;] -&gt; [&#39;rsub&#39;]
    146/375: aten_mul [&#39;primals_1&#39;, &#39;mul&#39;] -&gt; [&#39;mul_1&#39;]
    147/375: aten_unsqueeze [&#39;unsqueeze_5&#39;] -&gt; [&#39;unsqueeze_6&#39;]
    148/375: Cast [&#39;rsub&#39;] -&gt; [&#39;_to_copy&#39;]
    149/375: Constant [] -&gt; [&#39;_val_163&#39;]
    150/375: aten_view [&#39;mul_1&#39;, &#39;_val_163&#39;] -&gt; [&#39;view_1&#39;]
    151/375: Constant [] -&gt; [&#39;_val_165&#39;]
    152/375: Cast [&#39;_val_165&#39;] -&gt; [&#39;_val_166&#39;]
    153/375: Constant [] -&gt; [&#39;_val_167&#39;]
    154/375: Reshape [&#39;_val_166&#39;, &#39;_val_167&#39;] -&gt; [&#39;_val_168&#39;]
    155/375: Constant [] -&gt; [&#39;_val_169&#39;]
    156/375: Cast [&#39;_val_169&#39;] -&gt; [&#39;_val_170&#39;]
    157/375: Constant [] -&gt; [&#39;_val_171&#39;]
    158/375: Reshape [&#39;_val_170&#39;, &#39;_val_171&#39;] -&gt; [&#39;_val_172&#39;]
    159/375: Constant [] -&gt; [&#39;_val_173&#39;]
    160/375: Cast [&#39;_val_173&#39;] -&gt; [&#39;_val_174&#39;]
    161/375: Constant [] -&gt; [&#39;_val_175&#39;]
    162/375: Reshape [&#39;_val_174&#39;, &#39;_val_175&#39;] -&gt; [&#39;_val_176&#39;]
    163/375: Constant [] -&gt; [&#39;_val_177&#39;]
    164/375: Cast [&#39;_val_177&#39;] -&gt; [&#39;_val_178&#39;]
    165/375: Constant [] -&gt; [&#39;_val_179&#39;]
    166/375: Reshape [&#39;_val_178&#39;, &#39;_val_179&#39;] -&gt; [&#39;_val_180&#39;]
    167/375: Slice [&#39;unsqueeze_6&#39;, &#39;_val_168&#39;, &#39;_val_172&#39;, &#39;_val_176&#39;, &#39;_val_180&#39;] -&gt; [&#39;slice_5&#39;]
    168/375: Constant [] -&gt; [&#39;_val_182&#39;]
    169/375: aten_masked_fill [&#39;rsub&#39;, &#39;_to_copy&#39;, &#39;_val_182&#39;] -&gt; [&#39;masked_fill_1&#39;]
    170/375: aten_mm [&#39;view_1&#39;, &#39;t&#39;] -&gt; [&#39;mm&#39;]
    171/375: aten_mm [&#39;view_1&#39;, &#39;t_1&#39;] -&gt; [&#39;mm_1&#39;]
    172/375: aten_mm [&#39;view_1&#39;, &#39;t_2&#39;] -&gt; [&#39;mm_2&#39;]
    173/375: Constant [] -&gt; [&#39;_val_187&#39;]
    174/375: Cast [&#39;_val_187&#39;] -&gt; [&#39;_val_188&#39;]
    175/375: Constant [] -&gt; [&#39;_val_189&#39;]
    176/375: Reshape [&#39;_val_188&#39;, &#39;_val_189&#39;] -&gt; [&#39;_val_190&#39;]
    177/375: Constant [] -&gt; [&#39;_val_191&#39;]
    178/375: Cast [&#39;_val_191&#39;] -&gt; [&#39;_val_192&#39;]
    179/375: Constant [] -&gt; [&#39;_val_193&#39;]
    180/375: Reshape [&#39;_val_192&#39;, &#39;_val_193&#39;] -&gt; [&#39;_val_194&#39;]
    181/375: Constant [] -&gt; [&#39;_val_195&#39;]
    182/375: Cast [&#39;_val_195&#39;] -&gt; [&#39;_val_196&#39;]
    183/375: Constant [] -&gt; [&#39;_val_197&#39;]
    184/375: Reshape [&#39;_val_196&#39;, &#39;_val_197&#39;] -&gt; [&#39;_val_198&#39;]
    185/375: Constant [] -&gt; [&#39;_val_199&#39;]
    186/375: Cast [&#39;_val_199&#39;] -&gt; [&#39;_val_200&#39;]
    187/375: Constant [] -&gt; [&#39;_val_201&#39;]
    188/375: Reshape [&#39;_val_200&#39;, &#39;_val_201&#39;] -&gt; [&#39;_val_202&#39;]
    189/375: Slice [&#39;slice_5&#39;, &#39;_val_190&#39;, &#39;_val_194&#39;, &#39;_val_198&#39;, &#39;_val_202&#39;] -&gt; [&#39;slice_6&#39;]
    190/375: Cast [&#39;masked_fill_1&#39;] -&gt; [&#39;_to_copy_1&#39;]
    191/375: Constant [] -&gt; [&#39;_val_205&#39;]
    192/375: aten_view [&#39;mm&#39;, &#39;_val_205&#39;] -&gt; [&#39;view_2&#39;]
    193/375: Constant [] -&gt; [&#39;_val_207&#39;]
    194/375: aten_view [&#39;mm_1&#39;, &#39;_val_207&#39;] -&gt; [&#39;view_4&#39;]
    195/375: Constant [] -&gt; [&#39;_val_209&#39;]
    196/375: aten_view [&#39;mm_2&#39;, &#39;_val_209&#39;] -&gt; [&#39;view_6&#39;]
    197/375: Constant [] -&gt; [&#39;_val_211&#39;]
    198/375: aten_expand [&#39;slice_6&#39;, &#39;_val_211&#39;] -&gt; [&#39;expand_2&#39;]
    199/375: Constant [] -&gt; [&#39;_val_213&#39;]
    200/375: aten_view [&#39;view_2&#39;, &#39;_val_213&#39;] -&gt; [&#39;view_7&#39;]
    201/375: Constant [] -&gt; [&#39;_val_215&#39;]
    202/375: aten_view [&#39;view_4&#39;, &#39;_val_215&#39;] -&gt; [&#39;view_8&#39;]
    203/375: Constant [] -&gt; [&#39;_val_217&#39;]
    204/375: aten_view [&#39;view_6&#39;, &#39;_val_217&#39;] -&gt; [&#39;view_9&#39;]
    205/375: Constant [] -&gt; [&#39;_val_219&#39;]
    206/375: aten_masked_fill [&#39;expand_2&#39;, &#39;_to_copy_1&#39;, &#39;_val_219&#39;] -&gt; [&#39;masked_fill_2&#39;]
    207/375: Transpose [&#39;view_7&#39;] -&gt; [&#39;transpose&#39;]
    208/375: Transpose [&#39;view_8&#39;] -&gt; [&#39;transpose_1&#39;]
    209/375: Transpose [&#39;view_9&#39;] -&gt; [&#39;transpose_2&#39;]
    210/375: aten_mul [&#39;transpose&#39;, &#39;unsqueeze_7&#39;] -&gt; [&#39;mul_2&#39;]
    211/375: Constant [] -&gt; [&#39;_val_225&#39;]
    212/375: Cast [&#39;_val_225&#39;] -&gt; [&#39;_val_226&#39;]
    213/375: Constant [] -&gt; [&#39;_val_227&#39;]
    214/375: Reshape [&#39;_val_226&#39;, &#39;_val_227&#39;] -&gt; [&#39;_val_228&#39;]
    215/375: Constant [] -&gt; [&#39;_val_229&#39;]
    216/375: Cast [&#39;_val_229&#39;] -&gt; [&#39;_val_230&#39;]
    217/375: Constant [] -&gt; [&#39;_val_231&#39;]
    218/375: Reshape [&#39;_val_230&#39;, &#39;_val_231&#39;] -&gt; [&#39;_val_232&#39;]
    219/375: Constant [] -&gt; [&#39;_val_233&#39;]
    220/375: Cast [&#39;_val_233&#39;] -&gt; [&#39;_val_234&#39;]
    221/375: Constant [] -&gt; [&#39;_val_235&#39;]
    222/375: Reshape [&#39;_val_234&#39;, &#39;_val_235&#39;] -&gt; [&#39;_val_236&#39;]
    223/375: Constant [] -&gt; [&#39;_val_237&#39;]
    224/375: Cast [&#39;_val_237&#39;] -&gt; [&#39;_val_238&#39;]
    225/375: Constant [] -&gt; [&#39;_val_239&#39;]
    226/375: Reshape [&#39;_val_238&#39;, &#39;_val_239&#39;] -&gt; [&#39;_val_240&#39;]
    227/375: Slice [&#39;transpose&#39;, &#39;_val_228&#39;, &#39;_val_232&#39;, &#39;_val_236&#39;, &#39;_val_240&#39;] -&gt; [&#39;slice_9&#39;]
    228/375: Constant [] -&gt; [&#39;_val_242&#39;]
    229/375: Cast [&#39;_val_242&#39;] -&gt; [&#39;_val_243&#39;]
    230/375: Constant [] -&gt; [&#39;_val_244&#39;]
    231/375: Reshape [&#39;_val_243&#39;, &#39;_val_244&#39;] -&gt; [&#39;_val_245&#39;]
    232/375: Constant [] -&gt; [&#39;_val_246&#39;]
    233/375: Cast [&#39;_val_246&#39;] -&gt; [&#39;_val_247&#39;]
    234/375: Constant [] -&gt; [&#39;_val_248&#39;]
    235/375: Reshape [&#39;_val_247&#39;, &#39;_val_248&#39;] -&gt; [&#39;_val_249&#39;]
    236/375: Constant [] -&gt; [&#39;_val_250&#39;]
    237/375: Cast [&#39;_val_250&#39;] -&gt; [&#39;_val_251&#39;]
    238/375: Constant [] -&gt; [&#39;_val_252&#39;]
    239/375: Reshape [&#39;_val_251&#39;, &#39;_val_252&#39;] -&gt; [&#39;_val_253&#39;]
    240/375: Constant [] -&gt; [&#39;_val_254&#39;]
    241/375: Cast [&#39;_val_254&#39;] -&gt; [&#39;_val_255&#39;]
    242/375: Constant [] -&gt; [&#39;_val_256&#39;]
    243/375: Reshape [&#39;_val_255&#39;, &#39;_val_256&#39;] -&gt; [&#39;_val_257&#39;]
    244/375: Slice [&#39;transpose&#39;, &#39;_val_245&#39;, &#39;_val_249&#39;, &#39;_val_253&#39;, &#39;_val_257&#39;] -&gt; [&#39;slice_10&#39;]
    245/375: aten_mul [&#39;transpose_1&#39;, &#39;unsqueeze_7&#39;] -&gt; [&#39;mul_4&#39;]
    246/375: Constant [] -&gt; [&#39;_val_260&#39;]
    247/375: Cast [&#39;_val_260&#39;] -&gt; [&#39;_val_261&#39;]
    248/375: Constant [] -&gt; [&#39;_val_262&#39;]
    249/375: Reshape [&#39;_val_261&#39;, &#39;_val_262&#39;] -&gt; [&#39;_val_263&#39;]
    250/375: Constant [] -&gt; [&#39;_val_264&#39;]
    251/375: Cast [&#39;_val_264&#39;] -&gt; [&#39;_val_265&#39;]
    252/375: Constant [] -&gt; [&#39;_val_266&#39;]
    253/375: Reshape [&#39;_val_265&#39;, &#39;_val_266&#39;] -&gt; [&#39;_val_267&#39;]
    254/375: Constant [] -&gt; [&#39;_val_268&#39;]
    255/375: Cast [&#39;_val_268&#39;] -&gt; [&#39;_val_269&#39;]
    256/375: Constant [] -&gt; [&#39;_val_270&#39;]
    257/375: Reshape [&#39;_val_269&#39;, &#39;_val_270&#39;] -&gt; [&#39;_val_271&#39;]
    258/375: Constant [] -&gt; [&#39;_val_272&#39;]
    259/375: Cast [&#39;_val_272&#39;] -&gt; [&#39;_val_273&#39;]
    260/375: Constant [] -&gt; [&#39;_val_274&#39;]
    261/375: Reshape [&#39;_val_273&#39;, &#39;_val_274&#39;] -&gt; [&#39;_val_275&#39;]
    262/375: Slice [&#39;transpose_1&#39;, &#39;_val_263&#39;, &#39;_val_267&#39;, &#39;_val_271&#39;, &#39;_val_275&#39;] -&gt; [&#39;slice_11&#39;]
    263/375: Constant [] -&gt; [&#39;_val_277&#39;]
    264/375: Cast [&#39;_val_277&#39;] -&gt; [&#39;_val_278&#39;]
    265/375: Constant [] -&gt; [&#39;_val_279&#39;]
    266/375: Reshape [&#39;_val_278&#39;, &#39;_val_279&#39;] -&gt; [&#39;_val_280&#39;]
    267/375: Constant [] -&gt; [&#39;_val_281&#39;]
    268/375: Cast [&#39;_val_281&#39;] -&gt; [&#39;_val_282&#39;]
    269/375: Constant [] -&gt; [&#39;_val_283&#39;]
    270/375: Reshape [&#39;_val_282&#39;, &#39;_val_283&#39;] -&gt; [&#39;_val_284&#39;]
    271/375: Constant [] -&gt; [&#39;_val_285&#39;]
    272/375: Cast [&#39;_val_285&#39;] -&gt; [&#39;_val_286&#39;]
    273/375: Constant [] -&gt; [&#39;_val_287&#39;]
    274/375: Reshape [&#39;_val_286&#39;, &#39;_val_287&#39;] -&gt; [&#39;_val_288&#39;]
    275/375: Constant [] -&gt; [&#39;_val_289&#39;]
    276/375: Cast [&#39;_val_289&#39;] -&gt; [&#39;_val_290&#39;]
    277/375: Constant [] -&gt; [&#39;_val_291&#39;]
    278/375: Reshape [&#39;_val_290&#39;, &#39;_val_291&#39;] -&gt; [&#39;_val_292&#39;]
    279/375: Slice [&#39;transpose_1&#39;, &#39;_val_280&#39;, &#39;_val_284&#39;, &#39;_val_288&#39;, &#39;_val_292&#39;] -&gt; [&#39;slice_12&#39;]
    280/375: Constant [] -&gt; [&#39;_val_294&#39;]
    281/375: aten_expand [&#39;transpose_2&#39;, &#39;_val_294&#39;] -&gt; [&#39;expand_6&#39;]
    282/375: aten_neg [&#39;slice_10&#39;] -&gt; [&#39;neg&#39;]
    283/375: aten_neg [&#39;slice_12&#39;] -&gt; [&#39;neg_1&#39;]
    284/375: aten_clone [&#39;expand_6&#39;] -&gt; [&#39;clone_3&#39;]
    285/375: SequenceConstruct [&#39;neg&#39;, &#39;slice_9&#39;] -&gt; [&#39;299&#39;]
    286/375: aten_cat [&#39;299&#39;] -&gt; [&#39;cat&#39;]
    287/375: SequenceConstruct [&#39;neg_1&#39;, &#39;slice_11&#39;] -&gt; [&#39;301&#39;]
    288/375: aten_cat [&#39;301&#39;] -&gt; [&#39;cat_1&#39;]
    289/375: Constant [] -&gt; [&#39;_val_303&#39;]
    290/375: aten_view [&#39;clone_3&#39;, &#39;_val_303&#39;] -&gt; [&#39;view_14&#39;]
    291/375: aten_mul [&#39;cat&#39;, &#39;unsqueeze_8&#39;] -&gt; [&#39;mul_3&#39;]
    292/375: aten_mul [&#39;cat_1&#39;, &#39;unsqueeze_8&#39;] -&gt; [&#39;mul_5&#39;]
    293/375: Transpose [&#39;view_14&#39;] -&gt; [&#39;transpose_7&#39;]
    294/375: aten_add [&#39;mul_2&#39;, &#39;mul_3&#39;] -&gt; [&#39;add_2&#39;]
    295/375: aten_add [&#39;mul_4&#39;, &#39;mul_5&#39;] -&gt; [&#39;add_3&#39;]
    296/375: Constant [] -&gt; [&#39;_val_310&#39;]
    297/375: aten_expand [&#39;add_2&#39;, &#39;_val_310&#39;] -&gt; [&#39;expand_3&#39;]
    298/375: Transpose [&#39;add_3&#39;] -&gt; [&#39;transpose_3&#39;]
    299/375: aten_clone [&#39;expand_3&#39;] -&gt; [&#39;clone&#39;]
    300/375: Constant [] -&gt; [&#39;_val_314&#39;]
    301/375: aten_expand [&#39;transpose_3&#39;, &#39;_val_314&#39;] -&gt; [&#39;expand_4&#39;]
    302/375: Constant [] -&gt; [&#39;_val_316&#39;]
    303/375: aten_view [&#39;clone&#39;, &#39;_val_316&#39;] -&gt; [&#39;view_10&#39;]
    304/375: aten_clone [&#39;expand_4&#39;] -&gt; [&#39;clone_1&#39;]
    305/375: Transpose [&#39;view_10&#39;] -&gt; [&#39;transpose_8&#39;]
    306/375: Constant [] -&gt; [&#39;_val_320&#39;]
    307/375: aten_view [&#39;clone_1&#39;, &#39;_val_320&#39;] -&gt; [&#39;view_11&#39;]
    308/375: aten_bmm [&#39;view_10&#39;, &#39;view_11&#39;] -&gt; [&#39;bmm&#39;]
    309/375: Transpose [&#39;view_11&#39;] -&gt; [&#39;transpose_9&#39;]
    310/375: Constant [] -&gt; [&#39;_val_324&#39;]
    311/375: aten_view [&#39;bmm&#39;, &#39;_val_324&#39;] -&gt; [&#39;view_12&#39;]
    312/375: Constant [] -&gt; [&#39;_val_326&#39;]
    313/375: aten_div [&#39;view_12&#39;, &#39;_val_326&#39;] -&gt; [&#39;div&#39;]
    314/375: aten_add [&#39;div&#39;, &#39;masked_fill_2&#39;] -&gt; [&#39;add_4&#39;]
    315/375: aten_softmax_no_dtype [&#39;add_4&#39;] -&gt; [&#39;_softmax&#39;]
    316/375: aten_detach [&#39;_softmax&#39;] -&gt; [&#39;detach_2&#39;]
    317/375: aten_clone [&#39;_softmax&#39;] -&gt; [&#39;clone_2&#39;]
    318/375: aten_detach [&#39;detach_2&#39;] -&gt; [&#39;detach_3&#39;]
    319/375: Constant [] -&gt; [&#39;_val_333&#39;]
    320/375: aten_expand [&#39;clone_2&#39;, &#39;_val_333&#39;] -&gt; [&#39;expand_5&#39;]
    321/375: aten_detach [&#39;detach_3&#39;] -&gt; [&#39;detach_12&#39;]
    322/375: Constant [] -&gt; [&#39;_val_336&#39;]
    323/375: aten_view [&#39;expand_5&#39;, &#39;_val_336&#39;] -&gt; [&#39;view_13&#39;]
    324/375: aten_detach [&#39;detach_12&#39;] -&gt; [&#39;detach_13&#39;]
    325/375: aten_bmm [&#39;view_13&#39;, &#39;view_14&#39;] -&gt; [&#39;bmm_1&#39;]
    326/375: Transpose [&#39;view_13&#39;] -&gt; [&#39;transpose_6&#39;]
    327/375: Constant [] -&gt; [&#39;_val_341&#39;]
    328/375: aten_view [&#39;bmm_1&#39;, &#39;_val_341&#39;] -&gt; [&#39;view_15&#39;]
    329/375: Transpose [&#39;view_15&#39;] -&gt; [&#39;transpose_4&#39;]
    330/375: aten_clone [&#39;transpose_4&#39;] -&gt; [&#39;clone_4&#39;]
    331/375: Constant [] -&gt; [&#39;_val_345&#39;]
    332/375: aten_view [&#39;clone_4&#39;, &#39;_val_345&#39;] -&gt; [&#39;view_16&#39;]
    333/375: Constant [] -&gt; [&#39;_val_347&#39;]
    334/375: aten_view [&#39;view_16&#39;, &#39;_val_347&#39;] -&gt; [&#39;view_17&#39;]
    335/375: aten_mm [&#39;view_17&#39;, &#39;t_3&#39;] -&gt; [&#39;mm_3&#39;]
    336/375: Constant [] -&gt; [&#39;_val_350&#39;]
    337/375: aten_view [&#39;mm_3&#39;, &#39;_val_350&#39;] -&gt; [&#39;view_18&#39;]
    338/375: aten_add [&#39;embedding&#39;, &#39;view_18&#39;] -&gt; [&#39;add_5&#39;]
    339/375: Constant [] -&gt; [&#39;_val_353&#39;]
    340/375: Cast [&#39;_val_353&#39;] -&gt; [&#39;scalar_tensor_default_1&#39;]
    341/375: aten_pow [&#39;add_5&#39;, &#39;scalar_tensor_default_1&#39;] -&gt; [&#39;pow_2&#39;]
    342/375: Constant [] -&gt; [&#39;_val_356&#39;]
    343/375: aten_mean_dim [&#39;pow_2&#39;, &#39;_val_356&#39;] -&gt; [&#39;mean_1&#39;]
    344/375: Constant [] -&gt; [&#39;_val_358&#39;]
    345/375: aten_add [&#39;mean_1&#39;, &#39;_val_358&#39;] -&gt; [&#39;add_6&#39;]
    346/375: aten_rsqrt [&#39;add_6&#39;] -&gt; [&#39;rsqrt_1&#39;]
    347/375: aten_mul [&#39;add_5&#39;, &#39;rsqrt_1&#39;] -&gt; [&#39;mul_6&#39;]
    348/375: aten_mul [&#39;primals_2&#39;, &#39;mul_6&#39;] -&gt; [&#39;mul_7&#39;]
    349/375: Constant [] -&gt; [&#39;_val_363&#39;]
    350/375: aten_view [&#39;mul_7&#39;, &#39;_val_363&#39;] -&gt; [&#39;view_19&#39;]
    351/375: aten_mm [&#39;view_19&#39;, &#39;t_4&#39;] -&gt; [&#39;mm_4&#39;]
    352/375: aten_mm [&#39;view_19&#39;, &#39;t_5&#39;] -&gt; [&#39;mm_5&#39;]
    353/375: Constant [] -&gt; [&#39;_val_367&#39;]
    354/375: aten_view [&#39;mm_4&#39;, &#39;_val_367&#39;] -&gt; [&#39;view_20&#39;]
    355/375: Constant [] -&gt; [&#39;_val_369&#39;]
    356/375: aten_view [&#39;mm_5&#39;, &#39;_val_369&#39;] -&gt; [&#39;view_22&#39;]
    357/375: aten_sigmoid [&#39;view_20&#39;] -&gt; [&#39;sigmoid&#39;]
    358/375: aten_mul [&#39;view_20&#39;, &#39;sigmoid&#39;] -&gt; [&#39;mul_8&#39;]
    359/375: aten_mul [&#39;mul_8&#39;, &#39;view_22&#39;] -&gt; [&#39;mul_9&#39;]
    360/375: Constant [] -&gt; [&#39;_val_374&#39;]
    361/375: aten_view [&#39;mul_9&#39;, &#39;_val_374&#39;] -&gt; [&#39;view_23&#39;]
    362/375: aten_mm [&#39;view_23&#39;, &#39;t_6&#39;] -&gt; [&#39;mm_6&#39;]
    363/375: Constant [] -&gt; [&#39;_val_377&#39;]
    364/375: aten_view [&#39;mm_6&#39;, &#39;_val_377&#39;] -&gt; [&#39;view_24&#39;]
    365/375: aten_add [&#39;add_5&#39;, &#39;view_24&#39;] -&gt; [&#39;add_7&#39;]
    366/375: Constant [] -&gt; [&#39;_val_380&#39;]
    367/375: Cast [&#39;_val_380&#39;] -&gt; [&#39;scalar_tensor_default_2&#39;]
    368/375: aten_pow [&#39;add_7&#39;, &#39;scalar_tensor_default_2&#39;] -&gt; [&#39;pow_3&#39;]
    369/375: Constant [] -&gt; [&#39;_val_383&#39;]
    370/375: aten_mean_dim [&#39;pow_3&#39;, &#39;_val_383&#39;] -&gt; [&#39;mean_2&#39;]
    371/375: Constant [] -&gt; [&#39;_val_385&#39;]
    372/375: aten_add [&#39;mean_2&#39;, &#39;_val_385&#39;] -&gt; [&#39;add_8&#39;]
    373/375: aten_rsqrt [&#39;add_8&#39;] -&gt; [&#39;rsqrt_2&#39;]
    374/375: aten_mul [&#39;add_7&#39;, &#39;rsqrt_2&#39;] -&gt; [&#39;mul_10&#39;]
    375/375: aten_mul [&#39;primals_3&#39;, &#39;mul_10&#39;] -&gt; [&#39;mul_11&#39;]
    [runpythonerror]
    /home/xadupre/.local/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
      _torch_pytree._register_pytree_node(
    /home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/exporter.py:137: UserWarning: torch.onnx.dynamo_export only implements opset version 18 for now. If you need to use a different opset version, please register them with register_custom_op.
      warnings.warn(
    W0312 14:18:17.241000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.242000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.242000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.242000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.transpose.int (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.242000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.transpose.int (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.242000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.242000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.242000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.transpose.int (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.242000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.transpose.int (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.243000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.243000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.243000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.243000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.243000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.243000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.243000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.rsqrt.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.243000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.243000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.mean.dim (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.244000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.pow.Tensor_Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.244000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.244000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.244000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.245000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.245000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.245000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.245000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.245000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.245000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.245000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.245000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.sigmoid.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.246000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.246000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.246000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.246000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.246000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.246000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.246000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.rsqrt.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.246000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.247000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.mean.dim (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.247000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.pow.Tensor_Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.247000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.247000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.247000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.247000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.247000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.247000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.248000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.clone.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.248000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.transpose.int (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.248000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.248000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.bmm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.248000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.248000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.clone.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.248000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.expand.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.248000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.249000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.expand.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.249000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.clone.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.249000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.249000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.249000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten._softmax.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.249000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.249000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.div.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.250000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.250000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.bmm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.250000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.250000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.clone.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.250000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.expand.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.250000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.250000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.clone.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.250000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.expand.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.251000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.transpose.int (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.251000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.251000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.251000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.cat.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.251000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.neg.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.251000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.251000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.252000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.252000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.252000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.252000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.cat.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.252000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.neg.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.252000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.252000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.252000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.253000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.unsqueeze.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.253000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.index.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.253000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.unsqueeze.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.253000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.index.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.253000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.253000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.253000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.transpose.int (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.254000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.254000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.transpose.int (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.254000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.254000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.transpose.int (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.254000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.254000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.254000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.255000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.255000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.255000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.255000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.255000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.255000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.255000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.256000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.256000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.256000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.256000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.rsqrt.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.256000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.256000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.mean.dim (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.256000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.pow.Tensor_Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.257000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.masked_fill.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.257000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.expand.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.257000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.257000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.257000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.unsqueeze.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.257000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.unsqueeze.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.257000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten._to_copy.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.258000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.masked_fill.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.258000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten._to_copy.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.258000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.rsub.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.258000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.expand.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.258000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.258000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.unsqueeze.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.258000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.unsqueeze.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.259000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.259000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.masked_fill.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.259000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.lt.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.259000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.259000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.259000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.arange.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.260000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.full.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.260000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.embedding.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.260000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.unsqueeze.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.260000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] [0/0] support_dict supports node.target: aten.arange.start (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    2024-03-12 14:18:17,509 onnxrewriter.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue full due to large size 4194304.
    2024-03-12 14:18:17,556 onnxrewriter.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue masked_fill due to large size 4194304.
    2024-03-12 14:18:17,558 onnxrewriter.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue unsqueeze_5 due to large size 4194304.
    2024-03-12 14:18:17,560 onnxrewriter.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue unsqueeze_6 due to large size 4194304.
    2024-03-12 14:18:17,564 onnxrewriter.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue slice_5 due to large size 4194304.
    2024-03-12 14:18:17,568 onnxrewriter.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue slice_6 due to large size 4194304.
    2024-03-12 14:18:17,582 onnxrewriter.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue expand_2 due to large size 8388608.
    2024-03-12 14:18:17,648 onnxrewriter.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue full due to large size 4194304.
    2024-03-12 14:18:17,654 onnxrewriter.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue masked_fill due to large size 4194304.
    2024-03-12 14:18:17,655 onnxrewriter.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue unsqueeze_5 due to large size 4194304.
    2024-03-12 14:18:17,655 onnxrewriter.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue unsqueeze_6 due to large size 4194304.
    2024-03-12 14:18:17,656 onnxrewriter.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue slice_5 due to large size 4194304.
    2024-03-12 14:18:17,658 onnxrewriter.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue slice_6 due to large size 4194304.
    2024-03-12 14:18:17,662 onnxrewriter.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue expand_2 due to large size 8388608.
    [0;93m2024-03-12 14:18:17.712342700 [W:onnxruntime:, unsqueeze_elimination.cc:20 Apply] UnsqueezeElimination cannot remove node _inlfunc_aten_mean_dim_n1[m
    [0;93m2024-03-12 14:18:17.712479100 [W:onnxruntime:, unsqueeze_elimination.cc:20 Apply] UnsqueezeElimination cannot remove node _inlfunc_aten_mean_dim_token_67_n1[m
    [0;93m2024-03-12 14:18:17.712504100 [W:onnxruntime:, unsqueeze_elimination.cc:20 Apply] UnsqueezeElimination cannot remove node _inlfunc_aten_mean_dim_token_84_n1[m
    W0312 14:18:17.841000 140276405477376 torch/onnx/_internal/onnxruntime.py:202] support_dict and extra_support_dict don&#39;t support node.target: aten._unsafe_index_put.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.841000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.new_zeros.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.842000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.masked_fill.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.842000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.unsqueeze.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.842000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.eq.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.842000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.842000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.843000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mul.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.843000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.pow.Tensor_Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.843000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.div.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.843000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.expand.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.843000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.843000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mul.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.844000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.pow.Tensor_Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.844000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.844000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.844000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.844000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.sum.dim_IntList (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.844000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.844000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.845000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.845000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.sum.dim_IntList (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.845000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.845000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.845000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.845000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.846000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.846000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.846000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.846000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.846000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.846000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.846000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.847000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.847000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.847000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.847000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.847000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.847000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.847000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.848000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.848000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.848000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.848000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.848000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.848000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.848000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.849000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.849000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.clone.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.849000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.transpose.int (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.849000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.849000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.clone.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.849000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.transpose.int (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.850000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.850000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.clone.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.850000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.transpose.int (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.850000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.850000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.850000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.850000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.slice_scatter.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.851000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.new_zeros.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.851000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.slice_scatter.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.851000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.new_zeros.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.851000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.neg.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.851000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.851000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.851000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.852000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.852000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.852000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.852000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.slice_scatter.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.852000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.new_zeros.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.852000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.slice_scatter.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.852000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.new_zeros.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.853000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.neg.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.853000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.853000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.853000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.853000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.853000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.transpose.int (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.854000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.854000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.854000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.bmm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.854000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.bmm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.854000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.854000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.div.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.854000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.sub.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.855000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.855000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.sum.dim_IntList (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.855000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.855000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.855000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.855000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.856000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.bmm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.856000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.bmm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.856000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.856000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.clone.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.857000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.transpose.int (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.857000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.858000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.858000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.858000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.859000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.859000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.859000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.859000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.860000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.860000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.860000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mul.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.860000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.pow.Tensor_Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.860000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.div.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.860000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.expand.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.861000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.861000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mul.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.861000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.pow.Tensor_Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.861000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.861000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.862000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.862000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.sum.dim_IntList (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.862000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.862000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.862000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.863000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.sum.dim_IntList (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.863000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.863000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.863000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.863000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.863000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.864000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.864000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.864000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.864000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.864000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.864000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.865000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.865000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.add.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.865000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.865000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.sub.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.865000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.fill.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.866000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.empty_like.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.866000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.866000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.866000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.866000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.866000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.867000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.867000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.867000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.867000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.867000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.867000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.868000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.868000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.868000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mm.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.868000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.t.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.868000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.868000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.869000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.869000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mul.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.869000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.pow.Tensor_Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.869000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.div.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.869000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.expand.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.869000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.870000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mul.Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.870000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.pow.Tensor_Scalar (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.870000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.870000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.870000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.sum.dim_IntList (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.870000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.871000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.871000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.871000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.sum.dim_IntList (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.871000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.871000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.871000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.872000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.872000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.872000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.872000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.872000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.872000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.873000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.873000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.873000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.873000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.873000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.add.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.874000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.view.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.874000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.unsqueeze.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.874000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.index.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.874000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.unsqueeze.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.874000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.index.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.874000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.875000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.slice.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.875000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.mul.Tensor (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.875000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
    W0312 14:18:17.875000 140276405477376 torch/onnx/_internal/onnxruntime.py:186] support_dict supports node.target: aten.detach.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
</pre></div>
</div>
</section>
<section id="with-the-custom-exporter">
<h3>With the custom exporter<a class="headerlink" href="#with-the-custom-exporter" title="Link to this heading">#</a></h3>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">onnx</span>

<span class="c1"># from onnx_array_api.plotting.text_plot import onnx_simple_text_plot</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.onnx</span>
<span class="kn">from</span> <span class="nn">experimental_experiment.torch_helper.training_helper</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">make_aot_ort</span><span class="p">,</span>
    <span class="n">train_loop</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">experimental_experiment.torch_helper.dump_helper</span> <span class="kn">import</span> <span class="n">dump_onnx</span>

<span class="c1"># from experimental_experiment.torch_interpreter import to_onnx</span>

<span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
    <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">LlamaConfig</span>
    <span class="kn">from</span> <span class="nn">transformers.models.llama.modeling_llama</span> <span class="kn">import</span> <span class="n">LlamaModel</span>


<span class="k">def</span> <span class="nf">ids_tensor</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">):</span>
    <span class="n">total_dims</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="n">shape</span><span class="p">:</span>
        <span class="n">total_dims</span> <span class="o">*=</span> <span class="n">dim</span>

    <span class="n">values</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">total_dims</span><span class="p">):</span>
        <span class="n">values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">vocab_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>


<span class="n">config</span> <span class="o">=</span> <span class="n">LlamaConfig</span><span class="p">(</span>
    <span class="n">hidden_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">num_hidden_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">vocab_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
    <span class="n">intermediate_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">max_position_embeddings</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
    <span class="n">num_attention_heads</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">config</span><span class="o">.</span><span class="n">_attn_implementation</span> <span class="o">=</span> <span class="s2">&quot;eager&quot;</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">LlamaModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

<span class="n">batch</span><span class="p">,</span> <span class="n">seq</span><span class="p">,</span> <span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span>

<span class="n">input_ids</span> <span class="o">=</span> <span class="n">ids_tensor</span><span class="p">([</span><span class="n">batch</span><span class="p">,</span> <span class="n">seq</span><span class="p">],</span> <span class="n">vocab_size</span><span class="p">)</span>
<span class="n">input_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tril</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">seq</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

<span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">input_mask</span><span class="p">)</span>

<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;ONNXRT_CHANGE_REWRITER&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;1&quot;</span>

<span class="n">local_aot_ort</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">make_aot_ort</span><span class="p">(</span>
    <span class="n">dynamic</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">rewrite</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>

<span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
    <span class="n">optimized_mod</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="n">local_aot_ort</span><span class="p">,</span> <span class="n">fullgraph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">dump_onnx</span><span class="p">(</span><span class="s2">&quot;dort-llama-ort&quot;</span><span class="p">,</span> <span class="n">folder</span><span class="o">=</span><span class="s2">&quot;dump_llama&quot;</span><span class="p">,</span> <span class="n">clean</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="n">train_loop</span><span class="p">(</span><span class="n">optimized_mod</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">input_mask</span><span class="p">)</span>

<span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="n">_</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s2">&quot;dump_llama&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">_</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.onnx&quot;</span><span class="p">)]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------------------------&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;exported model: </span><span class="si">{</span><span class="n">names</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">names</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;NODES in </span><span class="si">{name!r}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">onx</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">&quot;dump_llama&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">node</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">onx</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">onx</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="p">)</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">node</span><span class="o">.</span><span class="n">op_type</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="si">}</span><span class="s2"> -&gt; </span><span class="si">{</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;ONNXRT_CHANGE_REWRITER&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;0&quot;</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    [to_onnx] build the graph module
    [_make_builder_interpreter] use existing &lt;class &#39;torch.fx.graph_module.GraphModule.__new__.&lt;locals&gt;.GraphModuleImpl&#39;&gt;
    [to_onnx] graph module done in 0.0028594000032171607 s
    [to_onnx] start creating the onnx nodes
    [GraphBuilder-PSI.make_tensor_input] input0[1:(16, 16)]
    [GraphBuilder-PSI.make_tensor_input] input1[1:(16, 16)]
    [GraphBuilder-PSI.make_tensor_input] input2[1:(1024, 8)]
    [GraphBuilder-PSI.make_tensor_input] input3[1:(1024, 8)]
    [GraphBuilder-PSI.make_tensor_input] input4[1:(16, 16)]
    [GraphBuilder-PSI.make_tensor_input] input5[1:(1024, 16)]
    [GraphBuilder-PSI.make_tensor_input] input6[7:(2, 1024)]
    [GraphBuilder-PSI.make_tensor_input] input7[1:(16, 16)]
    [GraphBuilder-PSI.make_tensor_input] input8[1:(2, 1024)]
    [GraphBuilder-PSI.make_tensor_input] input9[1:(16, 16)]
    [GraphBuilder-PSI.make_tensor_input] input10[1:(16, 16)]
    [GraphBuilder-PSI.make_tensor_input] input11[1:(16, 16)]
    [GraphBuilder-PSI.make_tensor_input] input12[1:(16,)]
    [GraphBuilder-PSI.make_tensor_input] input13[1:(16,)]
    [GraphBuilder-PSI.make_tensor_input] input14[1:(16,)]
    [GraphBuilder-PSI.make_tensor_output] output_0[1:(2, 1024, 16)]
    [GraphBuilder-PSI.make_tensor_output] output_1[1:(16, 16)]
    [GraphBuilder-PSI.make_tensor_output] output_2[1:(16, 16)]
    [GraphBuilder-PSI.make_tensor_output] output_3[7:(1, 1024)]
    [GraphBuilder-PSI.make_tensor_output] output_4[1:(16, 16)]
    [GraphBuilder-PSI.make_tensor_output] output_5[1:(16, 16)]
    [GraphBuilder-PSI.make_tensor_output] output_6[1:(16, 16)]
    [GraphBuilder-PSI.make_tensor_output] output_7[1:(16, 16)]
    [GraphBuilder-PSI.make_tensor_output] output_8[1:(16, 16)]
    [GraphBuilder-PSI.make_tensor_output] output_9[1:(2, 1024, 1)]
    [GraphBuilder-PSI.make_tensor_output] output_10[1:(2048, 16)]
    [GraphBuilder-PSI.make_tensor_output] output_11[1:(2, 2, 1024, 8)]
    [GraphBuilder-PSI.make_tensor_output] output_12[1:(4, 8, 1024)]
    [GraphBuilder-PSI.make_tensor_output] output_13[1:(2, 2, 1024, 8)]
    [GraphBuilder-PSI.make_tensor_output] output_14[1:(4, 8, 1024)]
    [GraphBuilder-PSI.make_tensor_output] output_15[1:(4, 1024, 8)]
    [GraphBuilder-PSI.make_tensor_output] output_16[1:(2, 2, 1024, 1024)]
    [GraphBuilder-PSI.make_tensor_output] output_17[1:(4, 1024, 1024)]
    [GraphBuilder-PSI.make_tensor_output] output_18[1:(2048, 16)]
    [GraphBuilder-PSI.make_tensor_output] output_19[1:(2048, 16)]
    [GraphBuilder-PSI.make_tensor_output] output_20[1:(2, 1024, 1)]
    [GraphBuilder-PSI.make_tensor_output] output_21[1:(2048, 16)]
    [GraphBuilder-PSI.make_tensor_output] output_22[1:(2048, 16)]
    [GraphBuilder-PSI.make_tensor_output] output_23[1:(2048, 16)]
    [GraphBuilder-PSI.make_tensor_output] output_24[1:(2, 1024, 16)]
    [GraphBuilder-PSI.make_tensor_output] output_25[1:(2048, 16)]
    [GraphBuilder-PSI.make_tensor_output] output_26[1:(2048, 16)]
    [GraphBuilder-PSI.make_tensor_output] output_27[1:(2, 1024, 1)]
    [GraphBuilder-PSI.make_tensor_output] output_28[1:(2, 1024, 16)]
    [to_onnx] onnx nodes done in 0.06085449999955017 s
    [to_onnx] start conversion to onnx (before optimization)
    [GraphBuilderPatternOptimization.optimize] start with 127 nodes and 16 patterns
    [GraphBuilderPatternOptimization.optimize] use pattern 1/16 - CastPattern
    [GraphBuilderPatternOptimization.optimize] use pattern 2/16 - ExpandPattern
    [GraphBuilderPatternOptimization.optimize] use pattern 3/16 - ExpandBroadcastPattern
    [GraphBuilderPatternOptimization.optimize] use pattern 4/16 - ExpandSwapPattern
    [GraphBuilderPatternOptimization.optimize] use pattern 5/16 - MulMulMulScalarPattern
    [GraphBuilderPatternOptimization.optimize] use pattern 6/16 - ReduceReshapePattern
    [GraphBuilderPatternOptimization.optimize] use pattern 7/16 - ReshapeMatMulReshapePattern
    [GraphBuilderPatternOptimization.optimize] use pattern 8/16 - Reshape2Of3Pattern
    [GraphBuilderPatternOptimization.optimize] use pattern 9/16 - MatMulReshape2Of3Pattern
    [GraphBuilderPatternOptimization.optimize] use pattern 10/16 - ReshapeReshapePattern
    [GraphBuilderPatternOptimization.optimize] use pattern 11/16 - RotaryConcatPartPattern
    [GraphBuilderPatternOptimization.optimize] use pattern 12/16 - Sub1MulPattern
    [GraphBuilderPatternOptimization.optimize] use pattern 13/16 - TransposeMatMulPattern
    [GraphBuilderPatternOptimization.optimize] use pattern 14/16 - TransposeReshapeMatMulPattern
    [GraphBuilderPatternOptimization.optimize] use pattern 15/16 - TransposeTransposePattern
    [GraphBuilderPatternOptimization.optimize] use pattern 16/16 - UnsqueezeUnsqueezePattern
    [GraphBuilderPatternOptimization.optimize] iteration 0: 127 nodes
    [GraphBuilderPatternOptimization.optimize] applies 20 matches, [0]=MatchResult: ExpandPattern replaces [&#39;Expand&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 1: 113 nodes
    [GraphBuilderPatternOptimization.optimize] applies 1 matches, [0]=MatchResult: Reshape2Of3Pattern replaces [&#39;Reshape&#39;, &#39;Reshape&#39;, &#39;Mul&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 2: 113 nodes
    [GraphBuilderPatternOptimization.optimize] applies 1 matches, [0]=MatchResult: TransposeMatMulPattern replaces [&#39;Transpose&#39;, &#39;MatMul&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 3: 112 nodes
    [GraphBuilderPatternOptimization.optimize] applies 1 matches, [0]=MatchResult: TransposeMatMulPattern replaces [&#39;Transpose&#39;, &#39;MatMul&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 4: 111 nodes
    [GraphBuilderPatternOptimization.optimize] applies 1 matches, [0]=MatchResult: TransposeMatMulPattern replaces [&#39;Transpose&#39;, &#39;MatMul&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 5: 110 nodes
    [GraphBuilderPatternOptimization.optimize] applies 1 matches, [0]=MatchResult: TransposeMatMulPattern replaces [&#39;Transpose&#39;, &#39;MatMul&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 6: 109 nodes
    [GraphBuilderPatternOptimization.optimize] applies 1 matches, [0]=MatchResult: TransposeMatMulPattern replaces [&#39;Transpose&#39;, &#39;MatMul&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 7: 108 nodes
    [GraphBuilderPatternOptimization.optimize] applies 1 matches, [0]=MatchResult: TransposeMatMulPattern replaces [&#39;Transpose&#39;, &#39;MatMul&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 8: 107 nodes
    [GraphBuilderPatternOptimization.optimize] applies 1 matches, [0]=MatchResult: TransposeMatMulPattern replaces [&#39;Transpose&#39;, &#39;MatMul&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 9: 106 nodes
    [GraphBuilderPatternOptimization.optimize] done after 10 iterations with 106 nodes in 0.028
    [GraphBuilder-PSI.to_onnx] make_model
    [GraphBuilder-PSI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s1_0:int64[(1,)]
    [GraphBuilder-PSI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s1_1024:int64[(1,)]
    [GraphBuilder-PSI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s_0:int64[()]
    [GraphBuilder-PSI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s_1024:int64[()]
    [GraphBuilder-PSI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s_1:int64[()]
    [GraphBuilder-PSI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s2_1024_1024:int64[(2,)]
    [GraphBuilder-PSI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s1_:float32[(1,)]
    [GraphBuilder-PSI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s1_1:int64[(1,)]
    [GraphBuilder-PSI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s1_-1:int64[(1,)]
    [GraphBuilder-PSI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s2_1024_1:int64[(2,)]
    [GraphBuilder-PSI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s_:float32[()]
    [GraphBuilder-PSI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s1_2:float32[(1,)]
    [GraphBuilder-PSI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s4_2_1_1024_1024:int64[(4,)]
    [GraphBuilder-PSI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s_2:float32[()]
    [GraphBuilder-PSI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s2_2048_16:int64[(2,)]
    [GraphBuilder-PSI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s1_3:float32[(1,)]
    [GraphBuilder-PSI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s3_2_1024_16:int64[(3,)]
    [GraphBuilder-PSI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s4_2_1024_2_8:int64[(4,)]
    [GraphBuilder-PSI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s1_4:float32[(1,)]
    [GraphBuilder-PSI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s1_4:int64[(1,)]
    [GraphBuilder-PSI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s1_3:int64[(1,)]
    [GraphBuilder-PSI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s1_9223372036854775807:int64[(1,)]
    [GraphBuilder-PSI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s3_4_1024_8:int64[(3,)]
    [GraphBuilder-PSI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s3_4_8_1024:int64[(3,)]
    [GraphBuilder-PSI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s_3:float32[()]
    [GraphBuilder-PSI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s3_4_1024_1024:int64[(3,)]
    [GraphBuilder-PSI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s1_5:float32[(1,)]
    [GraphBuilder-PSI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s_4:float32[()]
    [GraphBuilder-PSI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s1_6:float32[(1,)]
    [GraphBuilder-PSI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s_5:float32[()]
    [GraphBuilder-PSI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s2_1_2:int64[(2,)]
    [GraphBuilder-PSI._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s2_0_1:int64[(2,)]
    [to_onnx] to_onnx done in 0.032235599999694386 s
    [to_onnx] build the graph module
    [_make_builder_interpreter] use existing &lt;class &#39;torch.fx.graph_module.GraphModule.__new__.&lt;locals&gt;.GraphModuleImpl&#39;&gt;
    [to_onnx] graph module done in 6.450000000768341e-05 s
    [to_onnx] start creating the onnx nodes
    [GraphBuilder-ENG.make_tensor_input] input0[1:(2048, 16)]
    [GraphBuilder-ENG.make_tensor_input] input1[1:(2, 1024, 1)]
    [GraphBuilder-ENG.make_tensor_input] input2[1:(2, 1024, 16)]
    [GraphBuilder-ENG.make_tensor_input] input3[1:(16,)]
    [GraphBuilder-ENG.make_tensor_input] input4[1:(2, 1024, 16)]
    [GraphBuilder-ENG.make_tensor_input] input5[1:(2, 1024, 16)]
    [GraphBuilder-ENG.make_tensor_input] input6[7:(2, 1024)]
    [GraphBuilder-ENG.make_tensor_input] input7[1:(2, 1024, 1)]
    [GraphBuilder-ENG.make_tensor_input] input8[1:(1024, 8)]
    [GraphBuilder-ENG.make_tensor_input] input9[1:(1024, 8)]
    [GraphBuilder-ENG.make_tensor_input] input10[1:(2048, 16)]
    [GraphBuilder-ENG.make_tensor_input] input11[1:(2, 1024, 1)]
    [GraphBuilder-ENG.make_tensor_input] input12[1:(2048, 16)]
    [GraphBuilder-ENG.make_tensor_input] input13[1:(2048, 16)]
    [GraphBuilder-ENG.make_tensor_input] input14[7:(1, 1024)]
    [GraphBuilder-ENG.make_tensor_input] input15[1:(16, 16)]
    [GraphBuilder-ENG.make_tensor_input] input16[1:(2048, 16)]
    [GraphBuilder-ENG.make_tensor_input] input17[1:(16, 16)]
    [GraphBuilder-ENG.make_tensor_input] input18[1:(2048, 16)]
    [GraphBuilder-ENG.make_tensor_input] input19[1:(16, 16)]
    [GraphBuilder-ENG.make_tensor_input] input20[1:(16,)]
    [GraphBuilder-ENG.make_tensor_input] input21[1:(16, 16)]
    [GraphBuilder-ENG.make_tensor_input] input22[1:(2048, 16)]
    [GraphBuilder-ENG.make_tensor_input] input23[1:(4, 1024, 1024)]
    [GraphBuilder-ENG.make_tensor_input] input24[1:(4, 8, 1024)]
    [GraphBuilder-ENG.make_tensor_input] input25[1:(2, 2, 1024, 8)]
    [GraphBuilder-ENG.make_tensor_input] input26[1:(2, 2, 1024, 1024)]
    [GraphBuilder-ENG.make_tensor_input] input27[1:(16, 16)]
    [GraphBuilder-ENG.make_tensor_input] input28[1:(2048, 16)]
    [GraphBuilder-ENG.make_tensor_input] input29[1:(4, 8, 1024)]
    [GraphBuilder-ENG.make_tensor_input] input30[1:(4, 1024, 8)]
    [GraphBuilder-ENG.make_tensor_input] input31[1:(2, 2, 1024, 8)]
    [GraphBuilder-ENG.make_tensor_input] input32[1:(16, 16)]
    [GraphBuilder-ENG.make_tensor_input] input33[1:(16, 16)]
    [GraphBuilder-ENG.make_tensor_input] input34[1:(16,)]
    [GraphBuilder-ENG.make_tensor_output] output_0[1:(16,)]
    [GraphBuilder-ENG.make_tensor_output] output_1[1:(16, 16)]
    [GraphBuilder-ENG.make_tensor_output] output_2[1:(16, 16)]
    [GraphBuilder-ENG.make_tensor_output] output_3[1:(16, 16)]
    [GraphBuilder-ENG.make_tensor_output] output_4[1:(16,)]
    [GraphBuilder-ENG.make_tensor_output] output_5[1:(16, 16)]
    [GraphBuilder-ENG.make_tensor_output] output_6[1:(16, 16)]
    [GraphBuilder-ENG.make_tensor_output] output_7[1:(16, 16)]
    [GraphBuilder-ENG.make_tensor_output] output_8[1:(16, 16)]
    [GraphBuilder-ENG.make_tensor_output] output_9[1:(16,)]
    [GraphBuilder-ENG.make_tensor_output] output_10[1:(2, 1024, 16)]
    [GraphBuilder-ENG.make_tensor_output] output_11[1:(1024, 16)]
    [to_onnx] onnx nodes done in 0.038236000000324566 s
    [to_onnx] start conversion to onnx (before optimization)
    [GraphBuilderPatternOptimization.optimize] start with 193 nodes and 16 patterns
    [GraphBuilderPatternOptimization.optimize] use pattern 1/16 - CastPattern
    [GraphBuilderPatternOptimization.optimize] use pattern 2/16 - ExpandPattern
    [GraphBuilderPatternOptimization.optimize] use pattern 3/16 - ExpandBroadcastPattern
    [GraphBuilderPatternOptimization.optimize] use pattern 4/16 - ExpandSwapPattern
    [GraphBuilderPatternOptimization.optimize] use pattern 5/16 - MulMulMulScalarPattern
    [GraphBuilderPatternOptimization.optimize] use pattern 6/16 - ReduceReshapePattern
    [GraphBuilderPatternOptimization.optimize] use pattern 7/16 - ReshapeMatMulReshapePattern
    [GraphBuilderPatternOptimization.optimize] use pattern 8/16 - Reshape2Of3Pattern
    [GraphBuilderPatternOptimization.optimize] use pattern 9/16 - MatMulReshape2Of3Pattern
    [GraphBuilderPatternOptimization.optimize] use pattern 10/16 - ReshapeReshapePattern
    [GraphBuilderPatternOptimization.optimize] use pattern 11/16 - RotaryConcatPartPattern
    [GraphBuilderPatternOptimization.optimize] use pattern 12/16 - Sub1MulPattern
    [GraphBuilderPatternOptimization.optimize] use pattern 13/16 - TransposeMatMulPattern
    [GraphBuilderPatternOptimization.optimize] use pattern 14/16 - TransposeReshapeMatMulPattern
    [GraphBuilderPatternOptimization.optimize] use pattern 15/16 - TransposeTransposePattern
    [GraphBuilderPatternOptimization.optimize] use pattern 16/16 - UnsqueezeUnsqueezePattern
    [GraphBuilderPatternOptimization.optimize] iteration 0: 193 nodes
    [GraphBuilderPatternOptimization.optimize] applies 25 matches, [0]=MatchResult: CastPattern replaces [&#39;Cast&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 1: 162 nodes
    [GraphBuilderPatternOptimization.optimize] applies 4 matches, [0]=MatchResult: MulMulMulScalarPattern replaces [&#39;Mul&#39;, &#39;Div&#39;, &#39;Mul&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 2: 159 nodes
    [GraphBuilderPatternOptimization.optimize] applies 4 matches, [0]=MatchResult: ExpandBroadcastPattern replaces [&#39;Expand&#39;, &#39;Mul&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 3: 155 nodes
    [GraphBuilderPatternOptimization.optimize] applies 1 matches, [0]=MatchResult: Reshape2Of3Pattern replaces [&#39;Reshape&#39;, &#39;Reshape&#39;, &#39;Mul&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 4: 154 nodes
    [GraphBuilderPatternOptimization.optimize] applies 1 matches, [0]=MatchResult: Reshape2Of3Pattern replaces [&#39;Reshape&#39;, &#39;Reshape&#39;, &#39;Add&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 5: 153 nodes
    [GraphBuilderPatternOptimization.optimize] applies 1 matches, [0]=MatchResult: MatMulReshape2Of3Pattern replaces [&#39;Reshape&#39;, &#39;MatMul&#39;, &#39;Reshape&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 6: 153 nodes
    [GraphBuilderPatternOptimization.optimize] applies 1 matches, [0]=MatchResult: MatMulReshape2Of3Pattern replaces [&#39;Reshape&#39;, &#39;MatMul&#39;, &#39;Reshape&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 7: 152 nodes
    [GraphBuilderPatternOptimization.optimize] applies 1 matches, [0]=MatchResult: MatMulReshape2Of3Pattern replaces [&#39;Reshape&#39;, &#39;MatMul&#39;, &#39;Reshape&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 8: 152 nodes
    [GraphBuilderPatternOptimization.optimize] applies 1 matches, [0]=MatchResult: MatMulReshape2Of3Pattern replaces [&#39;Reshape&#39;, &#39;MatMul&#39;, &#39;Reshape&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 9: 151 nodes
    [GraphBuilderPatternOptimization.optimize] applies 1 matches, [0]=MatchResult: TransposeMatMulPattern replaces [&#39;Transpose&#39;, &#39;MatMul&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 10: 150 nodes
    [GraphBuilderPatternOptimization.optimize] applies 1 matches, [0]=MatchResult: TransposeMatMulPattern replaces [&#39;Transpose&#39;, &#39;MatMul&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 11: 149 nodes
    [GraphBuilderPatternOptimization.optimize] applies 1 matches, [0]=MatchResult: TransposeMatMulPattern replaces [&#39;Transpose&#39;, &#39;MatMul&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 12: 148 nodes
    [GraphBuilderPatternOptimization.optimize] applies 1 matches, [0]=MatchResult: TransposeMatMulPattern replaces [&#39;Transpose&#39;, &#39;MatMul&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 13: 147 nodes
    [GraphBuilderPatternOptimization.optimize] applies 1 matches, [0]=MatchResult: TransposeMatMulPattern replaces [&#39;Transpose&#39;, &#39;MatMul&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 14: 146 nodes
    [GraphBuilderPatternOptimization.optimize] applies 1 matches, [0]=MatchResult: TransposeMatMulPattern replaces [&#39;Transpose&#39;, &#39;MatMul&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 15: 145 nodes
    [GraphBuilderPatternOptimization.optimize] applies 1 matches, [0]=MatchResult: TransposeMatMulPattern replaces [&#39;Transpose&#39;, &#39;MatMul&#39;]
    [GraphBuilderPatternOptimization.optimize] iteration 16: 144 nodes
    [GraphBuilderPatternOptimization.optimize] done after 17 iterations with 144 nodes in 0.071
    [GraphBuilder-ENG.to_onnx] make_model
    [GraphBuilder-ENG._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s3_2_1024_16:int64[(3,)]
    [GraphBuilder-ENG._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s_-1:int64[()]
    [GraphBuilder-ENG._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s1_0:int64[(1,)]
    [GraphBuilder-ENG._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s1_1024:int64[(1,)]
    [GraphBuilder-ENG._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s1_-1:int64[(1,)]
    [GraphBuilder-ENG._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s1_1:int64[(1,)]
    [GraphBuilder-ENG._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s1_:float32[(1,)]
    [GraphBuilder-ENG._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s_3:float32[()]
    [GraphBuilder-ENG._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s1_2:float32[(1,)]
    [GraphBuilder-ENG._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s1_2:int64[(1,)]
    [GraphBuilder-ENG._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s1_3:float32[(1,)]
    [GraphBuilder-ENG._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s2_0_1:int64[(2,)]
    [GraphBuilder-ENG._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s_5:float32[()]
    [GraphBuilder-ENG._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s2_2048_16:int64[(2,)]
    [GraphBuilder-ENG._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s_7:float32[()]
    [GraphBuilder-ENG._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s4_2_1024_2_8:int64[(4,)]
    [GraphBuilder-ENG._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s4_2_2_1024_8:int64[(4,)]
    [GraphBuilder-ENG._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s4_2_2_1024_1024:int64[(4,)]
    [GraphBuilder-ENG._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s_9:float32[()]
    [GraphBuilder-ENG._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s4_2_2_8_1024:int64[(4,)]
    [GraphBuilder-ENG._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s1_4:int64[(1,)]
    [GraphBuilder-ENG._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s1_3:int64[(1,)]
    [GraphBuilder-ENG._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s1_8:int64[(1,)]
    [GraphBuilder-ENG._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s4_0_1_2_3:int64[(4,)]
    [GraphBuilder-ENG._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s4_4_5_6_7:int64[(4,)]
    [GraphBuilder-ENG._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s_10:float32[()]
    [GraphBuilder-ENG._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s1_4:float32[(1,)]
    [GraphBuilder-ENG._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init7_s2_1024_16:int64[(2,)]
    [GraphBuilder-ENG._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s_12:float32[()]
    [GraphBuilder-ENG._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s_13:float32[()]
    [GraphBuilder-ENG._build_initializers] &lt;class &#39;numpy.ndarray&#39;&gt;-init1_s_14:float32[()]
    [to_onnx] to_onnx done in 0.07534119999763789 s
    ------------------------------------------
    exported model: [&#39;dort-llama-ort_1.onnx&#39;, &#39;dort-llama-ort_0.onnx&#39;]
    
    NODES in {name!r}
    1/143: Reshape [&#39;input30&#39;, &#39;init7_s4_2_2_1024_8&#39;] -&gt; [&#39;typeL_view_39&#39;]
    2/143: Reshape [&#39;input29&#39;, &#39;init7_s4_2_2_8_1024&#39;] -&gt; [&#39;typeL_input29&#39;]
    3/143: Reshape [&#39;input24&#39;, &#39;init7_s4_2_2_8_1024&#39;] -&gt; [&#39;typeL_view_36&#39;]
    4/143: Reshape [&#39;input23&#39;, &#39;init7_s4_2_2_1024_1024&#39;] -&gt; [&#39;typeL_input23&#39;]
    5/143: Reshape [&#39;input12&#39;, &#39;init7_s3_2_1024_16&#39;] -&gt; [&#39;view_20&#39;]
    6/143: Reshape [&#39;input4&#39;, &#39;init7_s2_2048_16&#39;] -&gt; [&#39;typeR_input4&#39;]
    7/143: Mul [&#39;input12&#39;, &#39;typeR_input4&#39;] -&gt; [&#39;typeR_mul_8&#39;]
    8/143: Mul [&#39;view_20&#39;, &#39;input4&#39;] -&gt; [&#39;type--mul_22&#39;]
    9/143: Sub [&#39;view_20&#39;, &#39;type--mul_22&#39;] -&gt; [&#39;mul_22&#39;]
    10/143: Reshape [&#39;input0&#39;, &#39;init7_s3_2_1024_16&#39;] -&gt; [&#39;view_24&#39;]
    11/143: Mul [&#39;input2&#39;, &#39;input3&#39;] -&gt; [&#39;mul_12&#39;]
    12/143: Equal [&#39;input6&#39;, &#39;init7_s_-1&#39;] -&gt; [&#39;eq&#39;]
    13/143: Mul [&#39;input5&#39;, &#39;input7&#39;] -&gt; [&#39;mul&#39;]
    14/143: Slice [&#39;input8&#39;, &#39;init7_s1_0&#39;, &#39;init7_s1_1024&#39;, &#39;init7_s1_0&#39;] -&gt; [&#39;slice_7&#39;]
    15/143: Slice [&#39;input9&#39;, &#39;init7_s1_0&#39;, &#39;init7_s1_1024&#39;, &#39;init7_s1_0&#39;] -&gt; [&#39;slice_8&#39;]
    16/143: Reshape [&#39;input10&#39;, &#39;init7_s3_2_1024_16&#39;] -&gt; [&#39;view_18&#39;]
    17/143: Mul [&#39;mul_12&#39;, &#39;input1&#39;] -&gt; [&#39;mul_15&#39;]
    18/143: Unsqueeze [&#39;eq&#39;, &#39;init7_s1_-1&#39;] -&gt; [&#39;unsqueeze_9&#39;]
    19/143: Gather [&#39;slice_7&#39;, &#39;input14&#39;] -&gt; [&#39;index&#39;]
    20/143: Gather [&#39;slice_8&#39;, &#39;input14&#39;] -&gt; [&#39;index_1&#39;]
    21/143: Add [&#39;input5&#39;, &#39;view_18&#39;] -&gt; [&#39;add_5&#39;]
    22/143: Unsqueeze [&#39;index&#39;, &#39;init7_s1_1&#39;] -&gt; [&#39;unsqueeze_7&#39;]
    23/143: Unsqueeze [&#39;index_1&#39;, &#39;init7_s1_1&#39;] -&gt; [&#39;unsqueeze_8&#39;]
    24/143: Mul [&#39;add_5&#39;, &#39;input11&#39;] -&gt; [&#39;mul_6&#39;]
    25/143: Add [&#39;add_5&#39;, &#39;view_24&#39;] -&gt; [&#39;add_7&#39;]
    26/143: Mul [&#39;add_7&#39;, &#39;input1&#39;] -&gt; [&#39;mul_10&#39;]
    27/143: Mul [&#39;mul_12&#39;, &#39;add_7&#39;] -&gt; [&#39;mul_14&#39;]
    28/143: Pow [&#39;input1&#39;, &#39;init1_s1_&#39;] -&gt; [&#39;pow_4&#39;]
    29/143: Add [&#39;mul_22&#39;, &#39;init1_s_3&#39;] -&gt; [&#39;add_10&#39;]
    30/143: Pow [&#39;input7&#39;, &#39;init1_s1_2&#39;] -&gt; [&#39;pow_8&#39;]
    31/143: Mul [&#39;input2&#39;, &#39;mul_10&#39;] -&gt; [&#39;mul_13&#39;]
    32/143: ReduceSum [&#39;mul_14&#39;, &#39;init7_s1_2&#39;] -&gt; [&#39;sum_2&#39;]
    33/143: Pow [&#39;input11&#39;, &#39;init1_s1_3&#39;] -&gt; [&#39;pow_6&#39;]
    34/143: Mul [&#39;input4&#39;, &#39;add_10&#39;] -&gt; [&#39;mul_23&#39;]
    35/143: Reshape [&#39;mul_23&#39;, &#39;init7_s2_2048_16&#39;] -&gt; [&#39;typeR_mul_23&#39;]
    36/143: ReduceSum [&#39;mul_13&#39;, &#39;init7_s2_0_1&#39;] -&gt; [&#39;output_0&#39;]
    37/143: Mul [&#39;sum_2&#39;, &#39;init1_s_5&#39;] -&gt; [&#39;_onx_mul04&#39;]
    38/143: Mul [&#39;_onx_mul04&#39;, &#39;pow_4&#39;] -&gt; [&#39;mul_17&#39;]
    39/143: Mul [&#39;mul_17&#39;, &#39;add_7&#39;] -&gt; [&#39;type--mul_19&#39;]
    40/143: Mul [&#39;type--mul_19&#39;, &#39;init1_s_12&#39;] -&gt; [&#39;mul_19&#39;]
    41/143: Add [&#39;mul_15&#39;, &#39;mul_19&#39;] -&gt; [&#39;add_9&#39;]
    42/143: Reshape [&#39;add_9&#39;, &#39;init7_s2_2048_16&#39;] -&gt; [&#39;view_26&#39;]
    43/143: MatMul [&#39;view_26&#39;, &#39;input15&#39;] -&gt; [&#39;mm_8&#39;]
    44/143: Mul [&#39;mm_8&#39;, &#39;input13&#39;] -&gt; [&#39;typeL_mul_21&#39;]
    45/143: Mul [&#39;typeL_mul_21&#39;, &#39;typeR_mul_23&#39;] -&gt; [&#39;view_30&#39;]
    46/143: Mul [&#39;mm_8&#39;, &#39;typeR_mul_8&#39;] -&gt; [&#39;view_28&#39;]
    47/143: Gemm [&#39;view_26&#39;, &#39;input16&#39;] -&gt; [&#39;output_1&#39;]
    48/143: MatMul [&#39;view_28&#39;, &#39;input17&#39;] -&gt; [&#39;mm_10&#39;]
    49/143: Gemm [&#39;view_28&#39;, &#39;input18&#39;] -&gt; [&#39;output_2&#39;]
    50/143: Reshape [&#39;mm_10&#39;, &#39;init7_s3_2_1024_16&#39;] -&gt; [&#39;view_29&#39;]
    51/143: MatMul [&#39;view_30&#39;, &#39;input19&#39;] -&gt; [&#39;mm_12&#39;]
    52/143: Gemm [&#39;view_30&#39;, &#39;input18&#39;] -&gt; [&#39;output_3&#39;]
    53/143: Reshape [&#39;mm_12&#39;, &#39;init7_s3_2_1024_16&#39;] -&gt; [&#39;view_31&#39;]
    54/143: Add [&#39;view_29&#39;, &#39;view_31&#39;] -&gt; [&#39;add_11&#39;]
    55/143: Mul [&#39;add_11&#39;, &#39;input20&#39;] -&gt; [&#39;mul_25&#39;]
    56/143: Mul [&#39;add_11&#39;, &#39;mul_6&#39;] -&gt; [&#39;mul_26&#39;]
    57/143: Mul [&#39;mul_25&#39;, &#39;add_5&#39;] -&gt; [&#39;mul_27&#39;]
    58/143: Mul [&#39;mul_25&#39;, &#39;input11&#39;] -&gt; [&#39;mul_28&#39;]
    59/143: ReduceSum [&#39;mul_26&#39;, &#39;init7_s2_0_1&#39;] -&gt; [&#39;output_4&#39;]
    60/143: ReduceSum [&#39;mul_27&#39;, &#39;init7_s1_2&#39;] -&gt; [&#39;sum_4&#39;]
    61/143: Add [&#39;add_9&#39;, &#39;mul_28&#39;] -&gt; [&#39;add_12&#39;]
    62/143: Mul [&#39;sum_4&#39;, &#39;init1_s_7&#39;] -&gt; [&#39;_onx_mul05&#39;]
    63/143: Mul [&#39;_onx_mul05&#39;, &#39;pow_6&#39;] -&gt; [&#39;mul_30&#39;]
    64/143: Mul [&#39;mul_30&#39;, &#39;add_5&#39;] -&gt; [&#39;type--mul_32&#39;]
    65/143: Mul [&#39;type--mul_32&#39;, &#39;init1_s_13&#39;] -&gt; [&#39;mul_32&#39;]
    66/143: Add [&#39;add_12&#39;, &#39;mul_32&#39;] -&gt; [&#39;add_13&#39;]
    67/143: Reshape [&#39;add_13&#39;, &#39;init7_s2_2048_16&#39;] -&gt; [&#39;view_33&#39;]
    68/143: MatMul [&#39;view_33&#39;, &#39;input21&#39;] -&gt; [&#39;mm_14&#39;]
    69/143: Gemm [&#39;view_33&#39;, &#39;input22&#39;] -&gt; [&#39;output_5&#39;]
    70/143: Reshape [&#39;mm_14&#39;, &#39;init7_s4_2_1024_2_8&#39;] -&gt; [&#39;view_35&#39;]
    71/143: Transpose [&#39;view_35&#39;] -&gt; [&#39;transpose_5&#39;]
    72/143: MatMul [&#39;transpose_5&#39;, &#39;typeL_view_36&#39;] -&gt; [&#39;view_38&#39;]
    73/143: MatMul [&#39;typeL_input23&#39;, &#39;transpose_5&#39;] -&gt; [&#39;view_37&#39;]
    74/143: Add [&#39;input25&#39;, &#39;view_37&#39;] -&gt; [&#39;add_14&#39;]
    75/143: Mul [&#39;view_38&#39;, &#39;input26&#39;] -&gt; [&#39;mul_33&#39;]
    76/143: Transpose [&#39;add_14&#39;] -&gt; [&#39;transpose_11&#39;]
    77/143: ReduceSum [&#39;mul_33&#39;, &#39;init7_s1_-1&#39;] -&gt; [&#39;sum_5&#39;]
    78/143: Mul [&#39;input26&#39;, &#39;sum_5&#39;] -&gt; [&#39;mul_34&#39;]
    79/143: Sub [&#39;mul_33&#39;, &#39;mul_34&#39;] -&gt; [&#39;sub_1&#39;]
    80/143: Reshape [&#39;transpose_11&#39;, &#39;init7_s2_2048_16&#39;] -&gt; [&#39;view_45&#39;]
    81/143: Div [&#39;sub_1&#39;, &#39;init1_s_9&#39;] -&gt; [&#39;div_3&#39;]
    82/143: MatMul [&#39;div_3&#39;, &#39;typeL_view_39&#39;] -&gt; [&#39;view_41&#39;]
    83/143: MatMul [&#39;typeL_input29&#39;, &#39;div_3&#39;] -&gt; [&#39;view_40&#39;]
    84/143: MatMul [&#39;view_45&#39;, &#39;input27&#39;] -&gt; [&#39;mm_16&#39;]
    85/143: Gemm [&#39;view_45&#39;, &#39;input28&#39;] -&gt; [&#39;output_6&#39;]
    86/143: Transpose [&#39;view_40&#39;] -&gt; [&#39;transpose_10&#39;]
    87/143: Mul [&#39;view_41&#39;, &#39;unsqueeze_8&#39;] -&gt; [&#39;mul_37&#39;]
    88/143: Mul [&#39;view_41&#39;, &#39;unsqueeze_7&#39;] -&gt; [&#39;mul_38&#39;]
    89/143: Add [&#39;input31&#39;, &#39;transpose_10&#39;] -&gt; [&#39;add_15&#39;]
    90/143: Slice [&#39;mul_37&#39;, &#39;init7_s1_0&#39;, &#39;init7_s1_4&#39;, &#39;init7_s1_3&#39;] -&gt; [&#39;slice_15&#39;]
    91/143: Slice [&#39;mul_37&#39;, &#39;init7_s1_4&#39;, &#39;init7_s1_8&#39;, &#39;init7_s1_3&#39;] -&gt; [&#39;slice_16&#39;]
    92/143: Mul [&#39;add_15&#39;, &#39;unsqueeze_8&#39;] -&gt; [&#39;mul_35&#39;]
    93/143: Mul [&#39;add_15&#39;, &#39;unsqueeze_7&#39;] -&gt; [&#39;mul_36&#39;]
    94/143: Neg [&#39;slice_15&#39;] -&gt; [&#39;neg_3&#39;]
    95/143: ConstantOfShape [&#39;init7_s4_2_2_1024_8&#39;] -&gt; [&#39;new_zeros_3&#39;]
    96/143: Slice [&#39;mul_35&#39;, &#39;init7_s1_0&#39;, &#39;init7_s1_4&#39;, &#39;init7_s1_3&#39;] -&gt; [&#39;slice_13&#39;]
    97/143: Slice [&#39;mul_35&#39;, &#39;init7_s1_4&#39;, &#39;init7_s1_8&#39;, &#39;init7_s1_3&#39;] -&gt; [&#39;slice_14&#39;]
    98/143: ConstantOfShape [&#39;init7_s4_2_2_1024_8&#39;] -&gt; [&#39;new_zeros_2&#39;]
    99/143: ScatterElements [&#39;init7_s4_2_2_1024_8&#39;, &#39;init7_s1_3&#39;, &#39;init7_s1_1&#39;] -&gt; [&#39;_onx_scatterelements0&#39;]
    100/143: Expand [&#39;init7_s4_0_1_2_3&#39;, &#39;_onx_scatterelements0&#39;] -&gt; [&#39;_onx_expand0&#39;]
    101/143: ScatterElements [&#39;new_zeros_3&#39;, &#39;_onx_expand0&#39;, &#39;slice_16&#39;] -&gt; [&#39;_onx_scatterelements02&#39;]
    102/143: Neg [&#39;slice_13&#39;] -&gt; [&#39;neg_2&#39;]
    103/143: ConstantOfShape [&#39;init7_s4_2_2_1024_8&#39;] -&gt; [&#39;new_zeros_1&#39;]
    104/143: ScatterElements [&#39;init7_s4_2_2_1024_8&#39;, &#39;init7_s1_3&#39;, &#39;init7_s1_1&#39;] -&gt; [&#39;_onx_scatterelements03&#39;]
    105/143: Expand [&#39;init7_s4_4_5_6_7&#39;, &#39;_onx_scatterelements03&#39;] -&gt; [&#39;_onx_expand02&#39;]
    106/143: ScatterElements [&#39;new_zeros_2&#39;, &#39;_onx_expand02&#39;, &#39;neg_3&#39;] -&gt; [&#39;_onx_scatterelements04&#39;]
    107/143: ConstantOfShape [&#39;init7_s4_2_2_1024_8&#39;] -&gt; [&#39;new_zeros&#39;]
    108/143: ScatterElements [&#39;init7_s4_2_2_1024_8&#39;, &#39;init7_s1_3&#39;, &#39;init7_s1_1&#39;] -&gt; [&#39;_onx_scatterelements05&#39;]
    109/143: Expand [&#39;init7_s4_0_1_2_3&#39;, &#39;_onx_scatterelements05&#39;] -&gt; [&#39;_onx_expand03&#39;]
    110/143: ScatterElements [&#39;new_zeros_1&#39;, &#39;_onx_expand03&#39;, &#39;slice_14&#39;] -&gt; [&#39;_onx_scatterelements06&#39;]
    111/143: Add [&#39;_onx_scatterelements04&#39;, &#39;_onx_scatterelements02&#39;] -&gt; [&#39;add_18&#39;]
    112/143: ScatterElements [&#39;init7_s4_2_2_1024_8&#39;, &#39;init7_s1_3&#39;, &#39;init7_s1_1&#39;] -&gt; [&#39;_onx_scatterelements07&#39;]
    113/143: Expand [&#39;init7_s4_4_5_6_7&#39;, &#39;_onx_scatterelements07&#39;] -&gt; [&#39;_onx_expand04&#39;]
    114/143: ScatterElements [&#39;new_zeros&#39;, &#39;_onx_expand04&#39;, &#39;neg_2&#39;] -&gt; [&#39;_onx_scatterelements08&#39;]
    115/143: Add [&#39;add_18&#39;, &#39;mul_38&#39;] -&gt; [&#39;add_19&#39;]
    116/143: Add [&#39;_onx_scatterelements08&#39;, &#39;_onx_scatterelements06&#39;] -&gt; [&#39;add_16&#39;]
    117/143: Transpose [&#39;add_19&#39;] -&gt; [&#39;transpose_13&#39;]
    118/143: Add [&#39;add_16&#39;, &#39;mul_36&#39;] -&gt; [&#39;add_17&#39;]
    119/143: Transpose [&#39;add_17&#39;] -&gt; [&#39;transpose_12&#39;]
    120/143: Reshape [&#39;transpose_13&#39;, &#39;init7_s2_2048_16&#39;] -&gt; [&#39;view_49&#39;]
    121/143: MatMul [&#39;view_49&#39;, &#39;input32&#39;] -&gt; [&#39;mm_20&#39;]
    122/143: Reshape [&#39;transpose_12&#39;, &#39;init7_s2_2048_16&#39;] -&gt; [&#39;view_47&#39;]
    123/143: Gemm [&#39;view_49&#39;, &#39;input28&#39;] -&gt; [&#39;output_7&#39;]
    124/143: Reshape [&#39;mm_20&#39;, &#39;init7_s3_2_1024_16&#39;] -&gt; [&#39;view_50&#39;]
    125/143: MatMul [&#39;view_47&#39;, &#39;input33&#39;] -&gt; [&#39;mm_18&#39;]
    126/143: Add [&#39;mm_16&#39;, &#39;mm_18&#39;] -&gt; [&#39;typeL_add_20&#39;]
    127/143: Reshape [&#39;typeL_add_20&#39;, &#39;init7_s3_2_1024_16&#39;] -&gt; [&#39;add_20&#39;]
    128/143: Gemm [&#39;view_47&#39;, &#39;input28&#39;] -&gt; [&#39;output_8&#39;]
    129/143: Add [&#39;add_20&#39;, &#39;view_50&#39;] -&gt; [&#39;add_21&#39;]
    130/143: Mul [&#39;add_21&#39;, &#39;input34&#39;] -&gt; [&#39;mul_39&#39;]
    131/143: Mul [&#39;add_21&#39;, &#39;mul&#39;] -&gt; [&#39;mul_40&#39;]
    132/143: Mul [&#39;mul_39&#39;, &#39;input5&#39;] -&gt; [&#39;mul_41&#39;]
    133/143: Mul [&#39;mul_39&#39;, &#39;input7&#39;] -&gt; [&#39;mul_42&#39;]
    134/143: ReduceSum [&#39;mul_40&#39;, &#39;init7_s2_0_1&#39;] -&gt; [&#39;output_9&#39;]
    135/143: ReduceSum [&#39;mul_41&#39;, &#39;init7_s1_2&#39;] -&gt; [&#39;sum_7&#39;]
    136/143: Add [&#39;add_13&#39;, &#39;mul_42&#39;] -&gt; [&#39;add_22&#39;]
    137/143: Mul [&#39;sum_7&#39;, &#39;init1_s_10&#39;] -&gt; [&#39;_onx_mul06&#39;]
    138/143: Mul [&#39;_onx_mul06&#39;, &#39;pow_8&#39;] -&gt; [&#39;mul_44&#39;]
    139/143: Mul [&#39;mul_44&#39;, &#39;input5&#39;] -&gt; [&#39;type--mul_46&#39;]
    140/143: Mul [&#39;type--mul_46&#39;, &#39;init1_s_14&#39;] -&gt; [&#39;mul_46&#39;]
    141/143: Add [&#39;add_22&#39;, &#39;mul_46&#39;] -&gt; [&#39;add_23&#39;]
    142/143: Where [&#39;unsqueeze_9&#39;, &#39;init1_s1_4&#39;, &#39;add_23&#39;] -&gt; [&#39;output_10&#39;]
    143/143: ConstantOfShape [&#39;init7_s2_1024_16&#39;] -&gt; [&#39;output_11&#39;]
    
    NODES in {name!r}
    1/106: Identity [&#39;input11&#39;] -&gt; [&#39;output_8&#39;]
    2/106: Identity [&#39;input10&#39;] -&gt; [&#39;output_7&#39;]
    3/106: Identity [&#39;input9&#39;] -&gt; [&#39;output_6&#39;]
    4/106: Identity [&#39;input7&#39;] -&gt; [&#39;output_5&#39;]
    5/106: Identity [&#39;input4&#39;] -&gt; [&#39;output_4&#39;]
    6/106: Identity [&#39;input1&#39;] -&gt; [&#39;output_2&#39;]
    7/106: Identity [&#39;input0&#39;] -&gt; [&#39;output_1&#39;]
    8/106: Slice [&#39;input2&#39;, &#39;init7_s1_0&#39;, &#39;init7_s1_1024&#39;, &#39;init7_s1_0&#39;] -&gt; [&#39;slice_7&#39;]
    9/106: Slice [&#39;input3&#39;, &#39;init7_s1_0&#39;, &#39;init7_s1_1024&#39;, &#39;init7_s1_0&#39;] -&gt; [&#39;slice_8&#39;]
    10/106: Range [&#39;init7_s_0&#39;, &#39;init7_s_1024&#39;, &#39;init7_s_1&#39;] -&gt; [&#39;arange&#39;]
    11/106: Gather [&#39;input5&#39;, &#39;input6&#39;] -&gt; [&#39;output_0&#39;]
    12/106: ConstantOfShape [&#39;init7_s2_1024_1024&#39;] -&gt; [&#39;full&#39;]
    13/106: Range [&#39;init7_s_0&#39;, &#39;init7_s_1024&#39;, &#39;init7_s_1&#39;] -&gt; [&#39;arange_1&#39;]
    14/106: Unsqueeze [&#39;arange&#39;, &#39;init7_s1_0&#39;] -&gt; [&#39;output_3&#39;]
    15/106: Pow [&#39;output_0&#39;, &#39;init1_s1_&#39;] -&gt; [&#39;pow_1&#39;]
    16/106: Add [&#39;arange_1&#39;, &#39;init7_s_1&#39;] -&gt; [&#39;add&#39;]
    17/106: Unsqueeze [&#39;input8&#39;, &#39;init7_s2_1_2&#39;] -&gt; [&#39;unsqueeze_4&#39;]
    18/106: Gather [&#39;slice_7&#39;, &#39;output_3&#39;] -&gt; [&#39;index&#39;]
    19/106: Gather [&#39;slice_8&#39;, &#39;output_3&#39;] -&gt; [&#39;index_1&#39;]
    20/106: ReduceMean [&#39;pow_1&#39;, &#39;init7_s1_-1&#39;] -&gt; [&#39;mean&#39;]
    21/106: Reshape [&#39;add&#39;, &#39;init7_s2_1024_1&#39;] -&gt; [&#39;view&#39;]
    22/106: Unsqueeze [&#39;index&#39;, &#39;init7_s1_1&#39;] -&gt; [&#39;unsqueeze_7&#39;]
    23/106: Unsqueeze [&#39;index_1&#39;, &#39;init7_s1_1&#39;] -&gt; [&#39;unsqueeze_8&#39;]
    24/106: Add [&#39;mean&#39;, &#39;init1_s_&#39;] -&gt; [&#39;add_1&#39;]
    25/106: Less [&#39;arange_1&#39;, &#39;view&#39;] -&gt; [&#39;lt&#39;]
    26/106: Sqrt [&#39;add_1&#39;] -&gt; [&#39;_onx_sqrt0&#39;]
    27/106: Reciprocal [&#39;_onx_sqrt0&#39;] -&gt; [&#39;output_9&#39;]
    28/106: Where [&#39;lt&#39;, &#39;init1_s1_2&#39;, &#39;full&#39;] -&gt; [&#39;_onx_where0&#39;]
    29/106: Expand [&#39;unsqueeze_4&#39;, &#39;init7_s4_2_1_1024_1024&#39;] -&gt; [&#39;expand_1&#39;]
    30/106: Mul [&#39;output_0&#39;, &#39;output_9&#39;] -&gt; [&#39;mul&#39;]
    31/106: Unsqueeze [&#39;_onx_where0&#39;, &#39;init7_s2_0_1&#39;] -&gt; [&#39;unsqueeze_6&#39;]
    32/106: Sub [&#39;init1_s_2&#39;, &#39;expand_1&#39;] -&gt; [&#39;rsub&#39;]
    33/106: Mul [&#39;input12&#39;, &#39;mul&#39;] -&gt; [&#39;mul_1&#39;]
    34/106: Cast [&#39;rsub&#39;] -&gt; [&#39;_to_copy&#39;]
    35/106: Reshape [&#39;mul_1&#39;, &#39;init7_s2_2048_16&#39;] -&gt; [&#39;output_10&#39;]
    36/106: Where [&#39;_to_copy&#39;, &#39;init1_s1_3&#39;, &#39;rsub&#39;] -&gt; [&#39;_onx_where02&#39;]
    37/106: Gemm [&#39;output_10&#39;, &#39;input11&#39;] -&gt; [&#39;mm&#39;]
    38/106: Gemm [&#39;output_10&#39;, &#39;input0&#39;] -&gt; [&#39;mm_1&#39;]
    39/106: Gemm [&#39;output_10&#39;, &#39;input1&#39;] -&gt; [&#39;mm_2&#39;]
    40/106: Cast [&#39;_onx_where02&#39;] -&gt; [&#39;_to_copy_1&#39;]
    41/106: Expand [&#39;unsqueeze_6&#39;, &#39;init7_s4_2_1_1024_1024&#39;] -&gt; [&#39;expand_2&#39;]
    42/106: Reshape [&#39;mm&#39;, &#39;init7_s4_2_1024_2_8&#39;] -&gt; [&#39;view_7&#39;]
    43/106: Reshape [&#39;mm_1&#39;, &#39;init7_s4_2_1024_2_8&#39;] -&gt; [&#39;view_8&#39;]
    44/106: Reshape [&#39;mm_2&#39;, &#39;init7_s4_2_1024_2_8&#39;] -&gt; [&#39;view_9&#39;]
    45/106: Where [&#39;_to_copy_1&#39;, &#39;init1_s1_4&#39;, &#39;expand_2&#39;] -&gt; [&#39;_onx_where03&#39;]
    46/106: Transpose [&#39;view_7&#39;] -&gt; [&#39;transpose&#39;]
    47/106: Transpose [&#39;view_8&#39;] -&gt; [&#39;transpose_1&#39;]
    48/106: Transpose [&#39;view_9&#39;] -&gt; [&#39;output_11&#39;]
    49/106: Mul [&#39;transpose&#39;, &#39;unsqueeze_7&#39;] -&gt; [&#39;mul_2&#39;]
    50/106: Slice [&#39;transpose&#39;, &#39;init7_s1_0&#39;, &#39;init7_s1_4&#39;, &#39;init7_s1_3&#39;] -&gt; [&#39;slice_9&#39;]
    51/106: Slice [&#39;transpose&#39;, &#39;init7_s1_4&#39;, &#39;init7_s1_9223372036854775807&#39;, &#39;init7_s1_3&#39;] -&gt; [&#39;slice_10&#39;]
    52/106: Mul [&#39;transpose_1&#39;, &#39;unsqueeze_7&#39;] -&gt; [&#39;mul_4&#39;]
    53/106: Slice [&#39;transpose_1&#39;, &#39;init7_s1_0&#39;, &#39;init7_s1_4&#39;, &#39;init7_s1_3&#39;] -&gt; [&#39;slice_11&#39;]
    54/106: Slice [&#39;transpose_1&#39;, &#39;init7_s1_4&#39;, &#39;init7_s1_9223372036854775807&#39;, &#39;init7_s1_3&#39;] -&gt; [&#39;slice_12&#39;]
    55/106: Reshape [&#39;output_11&#39;, &#39;init7_s3_4_1024_8&#39;] -&gt; [&#39;view_14&#39;]
    56/106: Neg [&#39;slice_10&#39;] -&gt; [&#39;neg&#39;]
    57/106: Neg [&#39;slice_12&#39;] -&gt; [&#39;neg_1&#39;]
    58/106: Concat [&#39;neg&#39;, &#39;slice_9&#39;] -&gt; [&#39;cat&#39;]
    59/106: Concat [&#39;neg_1&#39;, &#39;slice_11&#39;] -&gt; [&#39;cat_1&#39;]
    60/106: Mul [&#39;cat&#39;, &#39;unsqueeze_8&#39;] -&gt; [&#39;mul_3&#39;]
    61/106: Mul [&#39;cat_1&#39;, &#39;unsqueeze_8&#39;] -&gt; [&#39;mul_5&#39;]
    62/106: Transpose [&#39;view_14&#39;] -&gt; [&#39;output_12&#39;]
    63/106: Add [&#39;mul_2&#39;, &#39;mul_3&#39;] -&gt; [&#39;add_2&#39;]
    64/106: Add [&#39;mul_4&#39;, &#39;mul_5&#39;] -&gt; [&#39;output_13&#39;]
    65/106: Reshape [&#39;add_2&#39;, &#39;init7_s3_4_1024_8&#39;] -&gt; [&#39;view_10&#39;]
    66/106: Transpose [&#39;output_13&#39;] -&gt; [&#39;transpose_3&#39;]
    67/106: Reshape [&#39;transpose_3&#39;, &#39;init7_s3_4_8_1024&#39;] -&gt; [&#39;view_11&#39;]
    68/106: MatMul [&#39;add_2&#39;, &#39;transpose_3&#39;] -&gt; [&#39;view_12&#39;]
    69/106: Transpose [&#39;view_10&#39;] -&gt; [&#39;output_14&#39;]
    70/106: Transpose [&#39;view_11&#39;] -&gt; [&#39;output_15&#39;]
    71/106: Div [&#39;view_12&#39;, &#39;init1_s_3&#39;] -&gt; [&#39;div&#39;]
    72/106: Add [&#39;div&#39;, &#39;_onx_where03&#39;] -&gt; [&#39;add_4&#39;]
    73/106: Softmax [&#39;add_4&#39;] -&gt; [&#39;output_16&#39;]
    74/106: Reshape [&#39;output_16&#39;, &#39;init7_s3_4_1024_1024&#39;] -&gt; [&#39;view_13&#39;]
    75/106: MatMul [&#39;output_16&#39;, &#39;output_11&#39;] -&gt; [&#39;view_15&#39;]
    76/106: Transpose [&#39;view_13&#39;] -&gt; [&#39;output_17&#39;]
    77/106: Transpose [&#39;view_15&#39;] -&gt; [&#39;transpose_4&#39;]
    78/106: Reshape [&#39;transpose_4&#39;, &#39;init7_s2_2048_16&#39;] -&gt; [&#39;output_18&#39;]
    79/106: Gemm [&#39;output_18&#39;, &#39;input4&#39;] -&gt; [&#39;output_19&#39;]
    80/106: Reshape [&#39;output_19&#39;, &#39;init7_s3_2_1024_16&#39;] -&gt; [&#39;view_18&#39;]
    81/106: Add [&#39;output_0&#39;, &#39;view_18&#39;] -&gt; [&#39;add_5&#39;]
    82/106: Pow [&#39;add_5&#39;, &#39;init1_s1_5&#39;] -&gt; [&#39;pow_2&#39;]
    83/106: ReduceMean [&#39;pow_2&#39;, &#39;init7_s1_-1&#39;] -&gt; [&#39;mean_1&#39;]
    84/106: Add [&#39;mean_1&#39;, &#39;init1_s_4&#39;] -&gt; [&#39;add_6&#39;]
    85/106: Sqrt [&#39;add_6&#39;] -&gt; [&#39;_onx_sqrt02&#39;]
    86/106: Reciprocal [&#39;_onx_sqrt02&#39;] -&gt; [&#39;output_20&#39;]
    87/106: Mul [&#39;add_5&#39;, &#39;output_20&#39;] -&gt; [&#39;mul_6&#39;]
    88/106: Mul [&#39;input13&#39;, &#39;mul_6&#39;] -&gt; [&#39;mul_7&#39;]
    89/106: Reshape [&#39;mul_7&#39;, &#39;init7_s2_2048_16&#39;] -&gt; [&#39;output_21&#39;]
    90/106: Gemm [&#39;output_21&#39;, &#39;input7&#39;] -&gt; [&#39;output_22&#39;]
    91/106: Reshape [&#39;output_22&#39;, &#39;init7_s3_2_1024_16&#39;] -&gt; [&#39;view_20&#39;]
    92/106: Gemm [&#39;output_21&#39;, &#39;input9&#39;] -&gt; [&#39;output_23&#39;]
    93/106: Sigmoid [&#39;view_20&#39;] -&gt; [&#39;output_24&#39;]
    94/106: Reshape [&#39;output_24&#39;, &#39;init7_s2_2048_16&#39;] -&gt; [&#39;typeR_output_24&#39;]
    95/106: Mul [&#39;output_22&#39;, &#39;typeR_output_24&#39;] -&gt; [&#39;typeL_mul_8&#39;]
    96/106: Mul [&#39;typeL_mul_8&#39;, &#39;output_23&#39;] -&gt; [&#39;output_25&#39;]
    97/106: Gemm [&#39;output_25&#39;, &#39;input10&#39;] -&gt; [&#39;output_26&#39;]
    98/106: Reshape [&#39;output_26&#39;, &#39;init7_s3_2_1024_16&#39;] -&gt; [&#39;view_24&#39;]
    99/106: Add [&#39;add_5&#39;, &#39;view_24&#39;] -&gt; [&#39;add_7&#39;]
    100/106: Pow [&#39;add_7&#39;, &#39;init1_s1_6&#39;] -&gt; [&#39;pow_3&#39;]
    101/106: ReduceMean [&#39;pow_3&#39;, &#39;init7_s1_-1&#39;] -&gt; [&#39;mean_2&#39;]
    102/106: Add [&#39;mean_2&#39;, &#39;init1_s_5&#39;] -&gt; [&#39;add_8&#39;]
    103/106: Sqrt [&#39;add_8&#39;] -&gt; [&#39;_onx_sqrt03&#39;]
    104/106: Reciprocal [&#39;_onx_sqrt03&#39;] -&gt; [&#39;output_27&#39;]
    105/106: Mul [&#39;add_7&#39;, &#39;output_27&#39;] -&gt; [&#39;mul_10&#39;]
    106/106: Mul [&#39;input14&#39;, &#39;mul_10&#39;] -&gt; [&#39;output_28&#39;]
    [runpythonerror]
    /home/xadupre/.local/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
      _torch_pytree._register_pytree_node(
    W0312 14:18:26.792000 139995022979072 torch/onnx/_internal/onnxruntime.py:202] support_dict and extra_support_dict don&#39;t support node.target: aten._unsafe_index_put.default (type: &lt;class &#39;torch._ops.OpOverload&#39;&gt;)
</pre></div>
</div>
</section>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="llama.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">LLaMa</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="torchtry.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Tries with Undocumented</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2023-2024
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Use the custom exporter in torch</a><ul>
<li><a class="reference internal" href="#file-onnxruntime-py">File <cite>onnxruntime.py</cite></a></li>
<li><a class="reference internal" href="#examples">Examples</a><ul>
<li><a class="reference internal" href="#baseline">Baseline</a></li>
<li><a class="reference internal" href="#with-the-custom-exporter">With the custom exporter</a></li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../_static/documentation_options.js?v=a1637f0b"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/furo.js?v=32e29ea5"></script>
    </body>
</html>