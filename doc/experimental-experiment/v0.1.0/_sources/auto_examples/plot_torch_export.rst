
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_torch_export.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_plot_torch_export.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_torch_export.py:


Evaluate different ways to export a torch model to ONNX
=======================================================

The example evaluates the performance of onnxruntime of a simple
torch model after it was converted into ONNX through different processes:

* `TorchScript-based ONNX Exporter
  <https://pytorch.org/docs/stable/onnx.html#torchscript-based-onnx-exporter>`_,
  let's call it **script**
* `TorchDynamo-based ONNX Exporter
  <https://pytorch.org/docs/stable/onnx.html#torchdynamo-based-onnx-exporter>`_,
  let's call it **dynamo**
* if available, the previous model but optimized, **dynopt**
* a custom exporter **cus_p0**, this exporter supports a very limited
  set of models, as **dynamo**, it relies on
  `torch.fx <https://pytorch.org/docs/stable/fx.html>`_ but the design is closer to
  what tensorflow-onnx does.
* the same exporter but unused nodes were removed and constants were folded, **cus_p2**

To run the script:

::

    python _doc/examples/plot_torch_export --help

The script takes around 12 minutes with a larger models.

Some helpers
++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 32-100

.. code-block:: Python


    import contextlib
    import itertools
    import os
    import platform
    import pprint
    import multiprocessing
    import time
    import cProfile
    import pstats
    import io
    import warnings
    import logging
    from pstats import SortKey

    try:
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            import onnxruntime

            has_cuda = "CUDAExecutionProvider" in onnxruntime.get_available_providers()
    except ImportError:
        print("onnxruntime not available.")
        import sys

        sys.exit(0)

    import numpy as np
    import matplotlib.pyplot as plt
    import pandas
    import onnx
    from onnx_array_api.plotting.text_plot import onnx_simple_text_plot
    from onnx_array_api.profiling import profile2graph
    import torch
    from torch import nn
    import torch.nn.functional as F
    import experimental_experiment
    from experimental_experiment.torch_exp.onnx_export import to_onnx
    from experimental_experiment.plotting.memory import memory_peak_plot
    from experimental_experiment.ext_test_case import (
        get_parsed_args,
        measure_time,
        get_figure,
    )
    from experimental_experiment.memory_peak import start_spying_on
    from tqdm import tqdm

    has_cuda = has_cuda and torch.cuda.is_available()
    logging.disable(logging.ERROR)


    def system_info():
        obs = {}
        obs["processor"] = platform.processor()
        obs["cores"] = multiprocessing.cpu_count()
        try:
            obs["cuda"] = 1 if torch.cuda.is_available() else 0
            obs["cuda_count"] = torch.cuda.device_count()
            obs["cuda_name"] = torch.cuda.get_device_name()
            obs["cuda_capa"] = torch.cuda.get_device_capability()
        except (RuntimeError, AssertionError):
            # no cuda
            pass
        return obs


    pprint.pprint(system_info())





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [2024-02-11 17:37:26,856] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
    {'cores': 8,
     'cuda': 1,
     'cuda_capa': (6, 1),
     'cuda_count': 1,
     'cuda_name': 'NVIDIA GeForce GTX 1060',
     'processor': 'x86_64'}




.. GENERATED FROM PYTHON SOURCE LINES 101-102

Scripts arguments

.. GENERATED FROM PYTHON SOURCE LINES 102-129

.. code-block:: Python



    script_args = get_parsed_args(
        "plot_torch_export",
        description=__doc__,
        scenarios={
            "small": "small model to test",
            "middle": "55Mb model",
            "large": "1Gb model",
        },
        warmup=5,
        repeat=5,
        maxtime=(
            2,
            "maximum time to run a model to measure the computation time, "
            "it is 0.1 when scenario is small",
        ),
        expose="scenarios,repeat,warmup",
    )

    if script_args.scenario in (None, "small"):
        script_args.maxtime = 0.1
    print(f"scenario={script_args.scenario or 'small'}")
    print(f"warmup={script_args.warmup}")
    print(f"repeat={script_args.repeat}")
    print(f"maxtime={script_args.maxtime}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    scenario=small
    warmup=5
    repeat=5
    maxtime=0.1




.. GENERATED FROM PYTHON SOURCE LINES 130-134

The model
+++++++++

A simple model to convert.

.. GENERATED FROM PYTHON SOURCE LINES 134-233

.. code-block:: Python



    class MyModelClass(nn.Module):
        def __init__(self, scenario=script_args.scenario):
            super(MyModelClass, self).__init__()
            if scenario == "middle":
                self.large = False
                self.conv1 = nn.Conv2d(1, 128, 5)
                self.conv2 = nn.Conv2d(128, 16, 5)
                self.fc1 = nn.Linear(13456, 1024)
                self.fcs = []
                self.fc2 = nn.Linear(1024, 128)
                self.fc3 = nn.Linear(128, 10)
            elif scenario in (None, "small"):
                self.large = False
                self.conv1 = nn.Conv2d(1, 16, 5)
                self.conv2 = nn.Conv2d(16, 16, 5)
                self.fc1 = nn.Linear(16, 512)
                self.fcs = []
                self.fc2 = nn.Linear(512, 128)
                self.fc3 = nn.Linear(128, 10)
            elif scenario in (None, "large"):
                self.large = True
                self.conv1 = nn.Conv2d(1, 128, 5)
                self.conv2 = nn.Conv2d(128, 16, 5)
                self.fc1 = nn.Linear(13456, 4096)
                # torch script does not support loops.
                self.fca = nn.Linear(4096, 4096)
                self.fcb = nn.Linear(4096, 4096)
                self.fcc = nn.Linear(4096, 4096)
                self.fcd = nn.Linear(4096, 4096)
                self.fce = nn.Linear(4096, 4096)
                self.fcf = nn.Linear(4096, 4096)
                self.fcg = nn.Linear(4096, 4096)
                self.fch = nn.Linear(4096, 4096)
                self.fci = nn.Linear(4096, 4096)
                self.fck = nn.Linear(4096, 4096)
                self.fcl = nn.Linear(4096, 4096)
                self.fcm = nn.Linear(4096, 4096)
                self.fcn = nn.Linear(4096, 4096)
                # end of the unfolded loop.
                self.fc2 = nn.Linear(4096, 128)
                self.fc3 = nn.Linear(128, 10)
            else:
                raise ValueError(f"Unsupported scenario={scenario!r}.")

        def forward(self, x):
            x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))
            x = F.max_pool2d(F.relu(self.conv2(x)), 2)
            x = torch.flatten(x, 1)
            x = F.relu(self.fc1(x))
            if self.large:
                # loop
                x = F.relu(self.fca(x))
                x = F.relu(self.fcb(x))
                x = F.relu(self.fcc(x))
                x = F.relu(self.fcd(x))
                x = F.relu(self.fce(x))
                x = F.relu(self.fcf(x))
                x = F.relu(self.fcg(x))
                x = F.relu(self.fch(x))
                x = F.relu(self.fci(x))
                x = F.relu(self.fck(x))
                x = F.relu(self.fcl(x))
                x = F.relu(self.fcm(x))
                x = F.relu(self.fcn(x))
                # end of the loop
            x = F.relu(self.fc2(x))
            x = self.fc3(x)
            return x


    def create_model_and_input(scenario=script_args.scenario):
        if scenario == "middle":
            shape = [1, 1, 128, 128]
        elif scenario in (None, "small"):
            shape = [1, 1, 16, 16]
        elif scenario == "large":
            shape = [1, 1, 128, 128]
        else:
            raise ValueError(f"Unsupported scenario={scenario!r}.")
        input_tensor = torch.rand(*shape).to(torch.float32)
        model = MyModelClass(scenario=scenario)
        assert model(input_tensor) is not None
        return model, input_tensor


    def torch_model_size(model):
        size_model = 0
        for param in model.parameters():
            size = param.numel() * torch.finfo(param.data.dtype).bits / 8
            size_model += size
        return size_model


    model, input_tensor = create_model_and_input()
    model_size = torch_model_size(model)
    print(f"model size={model_size / 2 ** 20} Mb")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    model size=0.31467437744140625 Mb




.. GENERATED FROM PYTHON SOURCE LINES 234-236

The exporters
+++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 236-285

.. code-block:: Python



    def export_script(filename, model, *args):
        with contextlib.redirect_stdout(io.StringIO()):
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                torch.onnx.export(model, *args, filename, input_names=["input"])


    def export_dynamo(filename, model, *args):
        with contextlib.redirect_stdout(io.StringIO()):
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                export_output = torch.onnx.dynamo_export(model, *args)
                export_output.save(filename)


    def export_dynopt(filename, model, *args):
        with contextlib.redirect_stdout(io.StringIO()):
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                export_output = torch.onnx.dynamo_export(model, *args)
                model_onnx = export_output.model_proto

                from onnxrewriter.optimizer import optimize

                optimized_model = optimize(model_onnx)
                with open(filename, "wb") as f:
                    f.write(optimized_model.SerializeToString())


    def export_cus_p0(filename, model, *args):
        onx = to_onnx(model, tuple(args), input_names=["input"])
        with open(filename, "wb") as f:
            f.write(onx.SerializeToString())


    def export_cus_p2(filename, model, *args):
        onx = to_onnx(
            model,
            tuple(args),
            input_names=["input"],
            remove_unused=True,
            constant_folding=True,
        )
        with open(filename, "wb") as f:
            f.write(onx.SerializeToString())









.. GENERATED FROM PYTHON SOURCE LINES 286-287

Let's check they are working.

.. GENERATED FROM PYTHON SOURCE LINES 287-311

.. code-block:: Python


    export_functions = [
        export_script,
        export_dynamo,
        export_dynopt,
        export_cus_p0,
        export_cus_p2,
    ]

    exporters = {f.__name__.replace("export_", ""): f for f in export_functions}

    supported_exporters = {}
    for k, v in exporters.items():
        print(f"run exporter {k}")
        filename = f"plot_torch_export_{k}.onnx"
        try:
            v(filename, model, input_tensor)
        except Exception as e:
            print(f"skipped due to {str(e)[:1000]}")
            continue
        supported_exporters[k] = v
        print(f"done. size={os.stat(filename).st_size / 2 ** 20:1.0f} Mb")






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    run exporter script
    done. size=0 Mb
    run exporter dynamo
    done. size=0 Mb
    run exporter dynopt
    done. size=0 Mb
    run exporter cus_p0
    done. size=0 Mb
    run exporter cus_p2
    done. size=0 Mb




.. GENERATED FROM PYTHON SOURCE LINES 312-314

Exporter memory
+++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 314-346

.. code-block:: Python



    def flatten(ps):
        obs = ps["cpu"].to_dict(unit=2**20)
        if "gpus" in ps:
            for i, g in enumerate(ps["gpus"]):
                for k, v in g.to_dict(unit=2**20).items():
                    obs[f"gpu{i}_{k}"] = v
        return obs


    data = []

    for k, v in supported_exporters.items():
        print(f"run exporter for memory {k}")
        filename = f"plot_torch_export_{k}.onnx"
        if has_cuda:
            torch.cuda.set_device(0)
        stat = start_spying_on(cuda=1 if has_cuda else 0)
        v(filename, model, input_tensor)
        obs = flatten(stat.stop())
        print("done.")
        onx = onnx.load(filename)
        obs.update(dict(nodes=len(onx.graph.node), export=k))
        data.append(obs)

    stat = start_spying_on(cuda=1 if has_cuda else 0)
    exported_mod = torch.export.export(model, (input_tensor,))
    obs = flatten(stat.stop())
    obs.update(dict(export="torch.fx"))
    data.append(obs)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    run exporter for memory script
    done.
    run exporter for memory dynamo
    done.
    run exporter for memory dynopt
    done.
    run exporter for memory cus_p0
    done.
    run exporter for memory cus_p2
    done.




.. GENERATED FROM PYTHON SOURCE LINES 347-348

The result.

.. GENERATED FROM PYTHON SOURCE LINES 348-361

.. code-block:: Python

    df1 = pandas.DataFrame(data)
    df1.to_csv("plot_torch_export_memory.csv", index=False)
    df1.to_excel("plot_torch_export_memory.xlsx", index=False)
    print(df1)

    ax = memory_peak_plot(
        data,
        bars=[model_size * i / 2**20 for i in range(1, 5)],
        suptitle=f"Memory Consumption of the Export\n"
        f"model size={model_size / 2**20:1.0f} Mb",
    )
    get_figure(ax).savefig("plot_torch_export_memory.png")




.. image-sg:: /auto_examples/images/sphx_glr_plot_torch_export_001.png
   :alt: Memory Consumption of the Export model size=0 Mb, Memory peak (Mb), Memory peak - memory begin (Mb), Memory average - memory begin (Mb), GPU Memory peak (Mb), GPU Memory peak - memory begin (Mb), GPU Memory average - memory begin (Mb)
   :srcset: /auto_examples/images/sphx_glr_plot_torch_export_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

             peak        mean         n       begin         end  gpu0_peak  gpu0_mean    gpu0_n  gpu0_begin  gpu0_end  nodes    export
    0  829.261719  829.259766  0.000004  829.257812  829.261719       98.0       98.0  0.000004        98.0      98.0   12.0    script
    1  830.058594  829.721726  0.000020  829.265625  830.058594       98.0       98.0  0.000020        98.0      98.0   13.0    dynamo
    2  832.484375  830.461250  0.000024  830.058594  832.484375       98.0       98.0  0.000024        98.0      98.0   18.0    dynopt
    3  832.785156  832.744715  0.000016  832.699219  832.785156       98.0       98.0  0.000016        98.0      98.0   27.0    cus_p0
    4  832.835938  832.816189  0.000017  832.785156  832.835938       98.0       98.0  0.000017        98.0      98.0   12.0    cus_p2
    5  832.972656  832.895313  0.000014  832.835938  832.972656       98.0       98.0  0.000014        98.0      98.0    NaN  torch.fx




.. GENERATED FROM PYTHON SOURCE LINES 362-364

Exporter speed
++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 364-392

.. code-block:: Python


    data = []

    for k, v in supported_exporters.items():
        print(f"run exporter {k}")
        filename = f"plot_torch_export_{k}.onnx"
        times = []
        for i in range(script_args.repeat):
            begin = time.perf_counter()
            v(filename, model, input_tensor)
            duration = time.perf_counter() - begin
            times.append(duration)
        onx = onnx.load(filename)
        print("done.")
        data.append(
            dict(
                export=k,
                time=np.mean(times),
                min=min(times),
                max=max(times),
                first=times[0],
                last=times[-1],
                std=np.std(times),
                nodes=len(onx.graph.node),
            )
        )






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    run exporter script
    done.
    run exporter dynamo
    done.
    run exporter dynopt
    done.
    run exporter cus_p0
    done.
    run exporter cus_p2
    done.




.. GENERATED FROM PYTHON SOURCE LINES 393-396

The last export to measure time torch spends in export the model
before any other export can begin the translation
except the first one.

.. GENERATED FROM PYTHON SOURCE LINES 396-416

.. code-block:: Python


    times = []
    for i in range(script_args.repeat):
        begin = time.perf_counter()
        exported_mod = torch.export.export(model, (input_tensor,))
        duration = time.perf_counter() - begin
        times.append(duration)
    data.append(
        dict(
            export="torch.fx",
            time=np.mean(times),
            min=min(times),
            max=max(times),
            first=times[0],
            last=times[-1],
            std=np.std(times),
            nodes=len(onx.graph.node),
        )
    )








.. GENERATED FROM PYTHON SOURCE LINES 417-418

The result.

.. GENERATED FROM PYTHON SOURCE LINES 418-429

.. code-block:: Python

    df1 = pandas.DataFrame(data)
    df1.to_csv("plot_torch_export_time.csv", index=False)
    df1.to_excel("plot_torch_export_time.xlsx", index=False)
    print(df1)

    fig, ax = plt.subplots(1, 1)
    dfi = df1[["export", "time", "std"]].set_index("export")
    dfi["time"].plot.bar(ax=ax, title="Export time", yerr=dfi["std"], rot=30)
    fig.tight_layout()
    fig.savefig("plot_torch_export_time.png")




.. image-sg:: /auto_examples/images/sphx_glr_plot_torch_export_002.png
   :alt: Export time
   :srcset: /auto_examples/images/sphx_glr_plot_torch_export_002.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

         export      time       min       max     first      last       std  nodes
    0    script  0.018704  0.017504  0.019603  0.018702  0.019603  0.000677     12
    1    dynamo  0.187403  0.158446  0.222378  0.158446  0.170694  0.022527     13
    2    dynopt  0.259688  0.199234  0.474025  0.201543  0.199234  0.107321     18
    3    cus_p0  0.111760  0.105736  0.117943  0.115983  0.113022  0.005016     27
    4    cus_p2  0.112837  0.103636  0.124302  0.107003  0.124302  0.008125     12
    5  torch.fx  0.119069  0.115464  0.122147  0.117054  0.115464  0.002440     12




.. GENERATED FROM PYTHON SOURCE LINES 430-432

Exporter Profiling
++++++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 432-484

.. code-block:: Python



    def clean_text(text):
        pathes = [
            os.path.abspath(
                os.path.normpath(os.path.join(os.path.dirname(torch.__file__), ".."))
            ),
            os.path.abspath(
                os.path.normpath(os.path.join(os.path.dirname(onnx.__file__), ".."))
            ),
            os.path.abspath(
                os.path.normpath(
                    os.path.join(os.path.dirname(experimental_experiment.__file__), "..")
                )
            ),
        ]
        for p in pathes:
            text = text.replace(p, "")
        text = text.replace("experimental_experiment", "experimental_experiment".upper())
        return text


    def profile_function(name, export_function, verbose=False):
        print(f"profile {name}: {export_function}")
        pr = cProfile.Profile()
        pr.enable()
        for i in range(script_args.repeat):
            export_function("dummyc.onnx", model, input_tensor)
        pr.disable()
        s = io.StringIO()
        sortby = SortKey.CUMULATIVE
        ps = pstats.Stats(pr, stream=s).sort_stats(sortby)
        ps.print_stats()

        raw = s.getvalue()
        text = "\n".join(raw.split("\n")[:200])
        if verbose:
            print(text)
        with open(f"plot_torch_export_profile_{name}.txt", "w") as f:
            f.write(raw)

        root, nodes = profile2graph(ps, clean_text=clean_text)
        text = root.to_text()
        with open(f"plot_torch_export_profile_{name}_h.txt", "w") as f:
            f.write(text)
        print("done.")


    profile_function("custom0", export_cus_p0, True)
    profile_function("custom2", export_cus_p2)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    profile custom0: <function export_cus_p0 at 0x7f087268dbd0>
             1037253 function calls (984458 primitive calls) in 2.036 seconds

       Ordered by: cumulative time

       ncalls  tottime  percall  cumtime  percall filename:lineno(function)
            5    0.000    0.000    2.087    0.417 /home/xadupre/github/experimental-experiment/_doc/examples/plot_torch_export.py:267(export_cus_p0)
            5    0.000    0.000    2.080    0.416 /home/xadupre/github/experimental-experiment/experimental_experiment/torch_exp/onnx_export.py:153(to_onnx)
            5    0.000    0.000    2.026    0.405 /home/xadupre/github/experimental-experiment/experimental_experiment/torch_exp/onnx_export.py:83(_make_builder_interpreter)
            5    0.000    0.000    2.025    0.405 /home/xadupre/.local/lib/python3.10/site-packages/torch/export/__init__.py:75(export)
            5    0.000    0.000    2.025    0.405 /home/xadupre/.local/lib/python3.10/site-packages/torch/export/exported_program.py:80(wrapper)
            5    0.001    0.000    2.025    0.405 /home/xadupre/.local/lib/python3.10/site-packages/torch/export/_trace.py:497(_export)
        15/10    0.000    0.000    1.734    0.173 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/utils.py:242(time_wrapper)
        20/10    0.000    0.000    1.452    0.145 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:431(_fn)
       120/55    0.000    0.000    1.056    0.019 /home/xadupre/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1549(_wrapped_call_impl)
       120/55    0.001    0.000    1.056    0.019 /home/xadupre/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1555(_call_impl)
            5    0.001    0.000    1.036    0.207 /home/xadupre/.local/lib/python3.10/site-packages/torch/export/_trace.py:335(_export_non_strict)
            5    0.000    0.000    1.024    0.205 /home/xadupre/.local/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py:903(aot_export_module)
            5    0.000    0.000    1.021    0.204 /home/xadupre/.local/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py:1158(_aot_export_function)
            5    0.001    0.000    1.018    0.204 /home/xadupre/.local/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py:387(create_aot_dispatcher_function)
            5    0.000    0.000    0.915    0.183 /home/xadupre/.local/lib/python3.10/site-packages/torch/export/_trace.py:273(_export_to_torch_ir)
            5    0.001    0.000    0.913    0.183 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:1186(inner)
            5    0.000    0.000    0.727    0.145 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:854(catch_errors)
            5    0.000    0.000    0.726    0.145 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:286(_convert_frame_assert)
        15/10    0.000    0.000    0.725    0.072 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/external_utils.py:23(inner)
         10/5    0.000    0.000    0.725    0.145 /usr/lib/python3.10/contextlib.py:76(inner)
            5    0.001    0.000    0.724    0.145 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:448(_compile)
            5    0.000    0.000    0.714    0.143 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:531(compile_inner)
          970    0.042    0.000    0.709    0.001 /home/xadupre/.local/lib/python3.10/site-packages/torch/_subclasses/functional_tensor.py:247(__torch_dispatch__)
            5    0.000    0.000    0.678    0.136 /home/xadupre/.local/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:401(aot_wrapper_dedupe)
         2565    0.009    0.000    0.678    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/export/_safeguard.py:17(__torch_function__)
            5    0.000    0.000    0.678    0.136 /home/xadupre/.local/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:620(aot_wrapper_synthetic_base)
            5    0.000    0.000    0.676    0.135 /home/xadupre/.local/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:50(aot_dispatch_base_graph)
            5    0.000    0.000    0.638    0.128 /home/xadupre/.local/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:34(_create_graph)
            5    0.000    0.000    0.637    0.127 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:996(wrapped)
            5    0.000    0.000    0.631    0.126 /home/xadupre/.local/lib/python3.10/site-packages/torch/_compile.py:20(inner)
            5    0.000    0.000    0.629    0.126 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:544(dispatch_trace)
            5    0.000    0.000    0.602    0.120 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:906(trace)
            5    0.000    0.000    0.601    0.120 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/_symbolic_trace.py:663(trace)
            5    0.000    0.000    0.572    0.114 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:569(wrapped)
    2830/1980    0.008    0.000    0.534    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/utils/_stats.py:15(wrapper)
           15    0.002    0.000    0.495    0.033 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/interpreter.py:106(run)
          210    0.002    0.000    0.486    0.002 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/interpreter.py:184(run_node)
           10    0.000    0.000    0.482    0.048 /home/xadupre/.local/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py:155(flat_fn)
           10    0.000    0.000    0.480    0.048 /home/xadupre/.local/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py:608(functional_call)
          140    0.001    0.000    0.461    0.003 /home/xadupre/.local/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py:590(run_node)
            5    0.000    0.000    0.456    0.091 /home/xadupre/.local/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py:347(_functionalized_f_helper)
            5    0.000    0.000    0.452    0.090 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py:1025(transform_code_object)
            5    0.000    0.000    0.434    0.087 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:148(_fn)
            5    0.000    0.000    0.433    0.087 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:484(transform)
    2395/1335    0.011    0.000    0.413    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/utils/_pytree.py:857(tree_map)
            5    0.000    0.000    0.392    0.078 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:2129(run)
            5    0.001    0.000    0.392    0.078 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:786(run)
          280    0.004    0.000    0.391    0.001 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:684(step)
         2135    0.008    0.000    0.340    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:864(__torch_dispatch__)
            5    0.000    0.000    0.338    0.068 /home/xadupre/.local/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py:66(inner_fn)
         2135    0.014    0.000    0.329    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:1185(dispatch)
    8860/1470    0.046    0.000    0.314    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/utils/_pytree.py:732(unflatten)
         2250    0.009    0.000    0.304    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/utils/_pytree.py:1032(tree_map_only)
          905    0.008    0.000    0.295    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:918(_cached_dispatch_impl)
            5    0.002    0.000    0.269    0.054 /home/xadupre/.local/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/collect_metadata_analysis.py:92(inner)
           60    0.000    0.000    0.266    0.004 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:460(wrapper)
           60    0.000    0.000    0.264    0.004 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:1198(CALL_FUNCTION)
           60    0.001    0.000    0.263    0.004 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:637(call_function)
            5    0.001    0.000    0.261    0.052 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/guards.py:944(__init__)
           50    0.000    0.000    0.240    0.005 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/interpreter.py:298(call_module)
          545    0.004    0.000    0.238    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:653(__torch_dispatch__)
           65    0.000    0.000    0.232    0.004 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/variables/builder.py:1263(wrap_fx_proxy)
           65    0.003    0.000    0.232    0.004 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/variables/builder.py:1323(wrap_fx_proxy_cls)
            5    0.001    0.000    0.230    0.046 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/guards.py:1018(compile_check_fn)
          545    0.002    0.000    0.220    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:684(inner_torch_dispatch)
          110    0.000    0.000    0.212    0.002 /home/xadupre/.local/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/functional_utils.py:23(to_fun)
          110    0.001    0.000    0.211    0.002 /home/xadupre/.local/lib/python3.10/site-packages/torch/_subclasses/functional_tensor.py:172(to_functional)
           70    0.000    0.000    0.206    0.003 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/interpreter.py:256(call_function)
           75    0.004    0.000    0.201    0.003 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:303(proxy_call)
           60    0.002    0.000    0.189    0.003 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/utils.py:1575(get_fake_value)
           50    0.001    0.000    0.179    0.004 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/_symbolic_trace.py:455(call_module)
      430/325    0.008    0.000    0.177    0.001 {method 'detach' of 'torch._C.TensorBase' objects}
         2585    0.004    0.000    0.177    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/utils/_pytree.py:797(tree_flatten)
           25    0.001    0.000    0.175    0.007 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/variables/nn_module.py:244(call_function)
           90    0.000    0.000    0.174    0.002 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/utils.py:1160(wrap_fake_exception)
    9140/2585    0.035    0.000    0.172    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/utils/_pytree.py:776(_tree_flatten_helper)
           25    0.000    0.000    0.171    0.007 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/_symbolic_trace.py:761(module_call_wrapper)
           25    0.000    0.000    0.170    0.007 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:955(call_module)
           25    0.000    0.000    0.168    0.007 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/_symbolic_trace.py:763(forward)
           60    0.000    0.000    0.166    0.003 /home/xadupre/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py:115(forward)
        90/60    0.009    0.000    0.165    0.003 {built-in method torch._C._nn.linear}
           60    0.001    0.000    0.158    0.003 /home/xadupre/.local/lib/python3.10/site-packages/torch/overrides.py:1571(handle_torch_function)
           80    0.000    0.000    0.158    0.002 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:202(track_tensor_tree)
       155/80    0.001    0.000    0.158    0.002 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:203(wrap_with_proxy)
    2180/1450    0.004    0.000    0.147    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/_ops.py:568(__call__)
            5    0.001    0.000    0.146    0.029 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/guards.py:1237(build_guard_function)
          150    0.001    0.000    0.140    0.001 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:166(set_meta)
      170/150    0.001    0.000    0.133    0.001 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:135(extract_val)
          160    0.000    0.000    0.132    0.001 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:132(snapshot_fake)
           40    0.000    0.000    0.128    0.003 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/graph.py:1281(python_code)
           35    0.001    0.000    0.124    0.004 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/graph_module.py:707(recompile)
           25    0.000    0.000    0.119    0.005 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/utils.py:1171(deepcopy_to_fake_tensor)
           40    0.000    0.000    0.119    0.003 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/graph.py:1343(_python_code)
      545/170    0.002    0.000    0.118    0.001 /usr/lib/python3.10/copy.py:259(_reconstruct)
           40    0.011    0.000    0.118    0.003 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/graph.py:372(_gen_python_code)
           25    0.000    0.000    0.118    0.005 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/utils.py:1173(<lambda>)
      1475/30    0.008    0.000    0.118    0.004 /usr/lib/python3.10/copy.py:128(deepcopy)
    4825/1695    0.010    0.000    0.116    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/utils/_pytree.py:790(<listcomp>)
     5200/300    0.013    0.000    0.116    0.000 /usr/lib/python3.10/ast.py:414(visit)
           25    0.001    0.000    0.115    0.005 /usr/lib/python3.10/copy.py:227(_deepcopy_dict)
        60/40    0.000    0.000    0.113    0.003 /home/xadupre/.local/lib/python3.10/site-packages/torch/_jit_internal.py:487(fn)
        60/40    0.001    0.000    0.113    0.003 /home/xadupre/.local/lib/python3.10/site-packages/torch/nn/functional.py:774(_max_pool2d)
           40    0.003    0.000    0.111    0.003 {built-in method torch.max_pool2d}
          905    0.020    0.000    0.110    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:953(_cache_key)
    153120/150810    0.091    0.000    0.106    0.000 {built-in method builtins.isinstance}
          225    0.001    0.000    0.103    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:318(__call__)
           40    0.000    0.000    0.103    0.003 /home/xadupre/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:459(forward)
          225    0.002    0.000    0.103    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:240(from_real_tensor)
           40    0.000    0.000    0.102    0.003 /home/xadupre/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:451(_conv_forward)
        60/40    0.006    0.000    0.102    0.003 {built-in method torch.conv2d}
           50    0.002    0.000    0.099    0.002 /home/xadupre/.local/lib/python3.10/site-packages/torch/nn/parameter.py:55(__deepcopy__)
       120/80    0.001    0.000    0.098    0.001 /home/xadupre/.local/lib/python3.10/site-packages/torch/nn/functional.py:1489(relu)
          135    0.005    0.000    0.098    0.001 /home/xadupre/.local/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:1211(_dispatch_impl)
           55    0.000    0.000    0.097    0.002 /home/xadupre/.local/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/collect_metadata_analysis.py:82(_to_fun)
            5    0.000    0.000    0.096    0.019 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:1244(result_capturing_wrapper)
          275    0.002    0.000    0.096    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/proxy.py:173(create_proxy)
           80    0.004    0.000    0.095    0.001 {built-in method torch.relu}
          250    0.002    0.000    0.095    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:1726(__torch_function__)
          165    0.004    0.000    0.095    0.001 /home/xadupre/.local/lib/python3.10/site-packages/torch/_subclasses/meta_utils.py:627(__call__)
          165    0.012    0.000    0.089    0.001 /home/xadupre/.local/lib/python3.10/site-packages/torch/_subclasses/meta_utils.py:186(meta_tensor)
           35    0.003    0.000    0.086    0.002 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/variables/torch.py:255(call_function)
         4410    0.009    0.000    0.082    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/node.py:698(map_arg)
          110    0.003    0.000    0.081    0.001 {built-in method torch._to_functional_tensor}
          135    0.002    0.000    0.079    0.001 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/guards.py:1029(add_code_part)
          220    0.004    0.000    0.077    0.000 {built-in method torch._mirror_autograd_meta_to}
          110    0.001    0.000    0.073    0.001 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/variables/builder.py:240(__call__)
    8435/7735    0.012    0.000    0.072    0.000 {built-in method builtins.next}
          110    0.006    0.000    0.072    0.001 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/variables/builder.py:362(_wrap)
          640    0.002    0.000    0.071    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/guards.py:136(_ast_unparse)
    8590/4415    0.033    0.000    0.070    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/node.py:706(map_aggregate)
           65    0.001    0.000    0.070    0.001 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:1292(LOAD_ATTR)
          770    0.009    0.000    0.070    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:1114(_output_from_cache_entry)
          135    0.001    0.000    0.069    0.001 /home/xadupre/.local/lib/python3.10/site-packages/torch/utils/_traceback.py:170(summary)
          640    0.002    0.000    0.068    0.000 /usr/lib/python3.10/ast.py:1679(unparse)
          165    0.001    0.000    0.068    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:1607(from_tensor)
           20    0.001    0.000    0.068    0.003 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/graph_module.py:353(__init__)
      435/385    0.003    0.000    0.068    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1732(__setattr__)
          100    0.000    0.000    0.066    0.001 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/guards.py:1244(replace)
          100    0.001    0.000    0.066    0.001 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/guards.py:914(replace)
          640    0.002    0.000    0.066    0.000 /usr/lib/python3.10/ast.py:811(visit)
           20    0.002    0.000    0.064    0.003 {built-in method }
            5    0.000    0.000    0.064    0.013 /home/xadupre/.local/lib/python3.10/site-packages/torch/_functorch/functional_call.py:10(functional_call)
            5    0.000    0.000    0.064    0.013 /home/xadupre/.local/lib/python3.10/site-packages/torch/nn/utils/stateless.py:229(_functional_call)
            5    0.000    0.000    0.064    0.013 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:922(rewrite_signature)
           10    0.000    0.000    0.064    0.006 /home/xadupre/.local/lib/python3.10/site-packages/torch/_decomp/decompositions_for_rng.py:129(reset)
     3125/640    0.007    0.000    0.063    0.000 /usr/lib/python3.10/ast.py:801(traverse)
           65    0.002    0.000    0.063    0.001 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/variables/builtin.py:527(call_function)
          280    0.008    0.000    0.063    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/_subclasses/functional_tensor.py:78(__new__)
          285    0.003    0.000    0.063    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/proxy.py:117(create_node)
           20    0.000    0.000    0.062    0.003 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/graph_module.py:462(graph)
          135    0.009    0.000    0.062    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/utils/_traceback.py:246(_extract_symbolized_tb)
           30    0.000    0.000    0.062    0.002 /home/xadupre/.local/lib/python3.10/site-packages/torch/_decomp/decompositions_for_rng.py:71(__init__)
           30    0.000    0.000    0.062    0.002 /home/xadupre/.local/lib/python3.10/site-packages/torch/_decomp/decompositions_for_rng.py:74(reset)
            5    0.000    0.000    0.061    0.012 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/_lazy_graph_module.py:112(_lazy_forward)
       120/60    0.005    0.000    0.061    0.001 {built-in method torch.tensor}
          150    0.002    0.000    0.060    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:507(__torch_dispatch__)
        18900    0.023    0.000    0.060    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/utils/_pytree.py:599(_get_node_type)
        12900    0.018    0.000    0.060    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/utils/_pytree.py:606(_is_leaf)
            5    0.001    0.000    0.059    0.012 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/guards.py:905(count)
     1115/895    0.011    0.000    0.058    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:1010(_prep_args_for_hash)
     1320/100    0.004    0.000    0.056    0.001 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/guards.py:852(visit)
          295    0.003    0.000    0.055    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/graph.py:878(create_node)
     1320/100    0.009    0.000    0.055    0.001 /usr/lib/python3.10/ast.py:420(generic_visit)
      295/240    0.007    0.000    0.055    0.000 {method 'clone' of 'torch._C.TensorBase' objects}
         6895    0.009    0.000    0.053    0.000 /usr/lib/python3.10/traceback.py:259(__init__)
         4830    0.015    0.000    0.052    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/utils/_pytree.py:627(__post_init__)
        30/20    0.003    0.000    0.052    0.003 {built-in method torch.flatten}
           60    0.000    0.000    0.050    0.001 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/utils.py:1622(<lambda>)
           60    0.000    0.000    0.050    0.001 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/utils.py:1701(run_node)
         7695    0.014    0.000    0.049    0.000 /usr/lib/python3.10/traceback.py:301(line)
    3760/3480    0.006    0.000    0.048    0.000 /usr/lib/python3.10/contextlib.py:130(__enter__)
            5    0.000    0.000    0.047    0.009 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/graph_module.py:736(call_wrapped)
            5    0.000    0.000    0.047    0.009 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/graph_module.py:299(__call__)
      930/100    0.003    0.000    0.046    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/guards.py:868(visit)
          795    0.007    0.000    0.046    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/graph.py:528(emit_node)
           50    0.000    0.000    0.046    0.001 /home/xadupre/.local/lib/python3.10/site-packages/torch/nn/parameter.py:34(__new__)
      855/100    0.006    0.000    0.045    0.000 /usr/lib/python3.10/ast.py:488(generic_visit)
            5    0.000    0.000    0.044    0.009 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:864(transform)
            5    0.000    0.000    0.044    0.009 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/interpreter.py:500(transform)
            5    0.001    0.000    0.044    0.009 /home/xadupre/github/experimental-experiment/experimental_experiment/torch_exp/graph_builder.py:1130(process)
    5795/5290    0.006    0.000    0.044    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/node.py:712(<genexpr>)
           15    0.000    0.000    0.043    0.003 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/_lazy_graph_module.py:54(_make_graph_module)
           65    0.002    0.000    0.042    0.001 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/variables/builtin.py:1203(call_getattr)
     1220/685    0.016    0.000    0.042    0.000 {built-in method torch._ops.prim.}
          145    0.001    0.000    0.042    0.000 /home/xadupre/github/experimental-experiment/experimental_experiment/torch_exp/interpreter.py:27(run_node)
         1010    0.017    0.000    0.040    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:673(extract_tensor_metadata)
            5    0.000    0.000    0.040    0.008 /home/xadupre/.local/lib/python3.10/site-packages/torch/export/exported_program.py:129(__init__)
            5    0.000    0.000    0.040    0.008 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:2022(__init__)
         2250    0.007    0.000    0.037    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/utils/_pytree.py:970(map_only)
    3760/3480    0.008    0.000    0.037    0.000 /usr/lib/python3.10/contextlib.py:139(__exit__)
        18900    0.027    0.000    0.037    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/utils/_pytree.py:588(_is_namedtuple_instance)
           85    0.001    0.000    0.036    0.000 /home/xadupre/github/experimental-experiment/experimental_experiment/torch_exp/interpreter.py:534(call_function)
      610/530    0.005    0.000    0.036    0.000 /usr/lib/python3.10/ast.py:1463(visit_Subscript)
    63850/63685    0.035    0.000    0.036    0.000 {built-in method builtins.len}
    3760/1755    0.011    0.000    0.035    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/utils/_pytree.py:821(_tree_leaves_helper)
    done.
    profile custom2: <function export_cus_p2 at 0x7f087268dc60>
    done.




.. GENERATED FROM PYTHON SOURCE LINES 485-486

Same with dynamo-exporter.

.. GENERATED FROM PYTHON SOURCE LINES 486-492

.. code-block:: Python


    profile_function("dynamo", export_dynamo, verbose=True)
    if "dynopt" in supported_exporters:
        profile_function("dynopt", export_dynopt)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    profile dynamo: <function export_dynamo at 0x7f087268dab0>
             1731574 function calls (1665764 primitive calls) in 13.351 seconds

       Ordered by: cumulative time

       ncalls  tottime  percall  cumtime  percall filename:lineno(function)
            5    0.004    0.001   14.130    2.826 /home/xadupre/github/experimental-experiment/_doc/examples/plot_torch_export.py:245(export_dynamo)
            5    0.000    0.000   14.077    2.815 /home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/exporter.py:1336(dynamo_export)
            5    0.001    0.000   11.501    2.300 /home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/exporter.py:1162(export)
            5    0.001    0.000   10.502    2.100 /home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/fx/dynamo_graph_extractor.py:187(generate_fx)
        30/15    0.002    0.000    8.068    0.538 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:431(_fn)
       605/35    0.080    0.000    6.822    0.195 /home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py:71(wrapper)
            5    0.000    0.000    6.158    1.232 /home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/fx/dynamo_graph_extractor.py:234(pre_export_passes)
            5    0.002    0.000    6.158    1.232 /home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/exporter.py:1444(common_pre_export_passes)
           30    0.002    0.000    6.054    0.202 /home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/fx/_pass.py:240(run)
    3165/1440    0.059    0.000    4.547    0.003 /home/xadupre/.local/lib/python3.10/site-packages/torch/utils/_stats.py:15(wrapper)
        25/15    0.001    0.000    4.518    0.301 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/external_utils.py:23(inner)
            5    0.008    0.002    4.325    0.865 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:1186(inner)
           20    0.015    0.001    4.289    0.214 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/interpreter.py:106(run)
           10    0.003    0.000    4.135    0.414 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:996(wrapped)
          490    0.026    0.000    4.121    0.008 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/interpreter.py:184(run_node)
           10    0.001    0.000    4.109    0.411 /home/xadupre/.local/lib/python3.10/site-packages/torch/_compile.py:20(inner)
           10    0.001    0.000    4.090    0.409 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:544(dispatch_trace)
            5    0.000    0.000    3.965    0.793 /home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/fx/dynamo_graph_extractor.py:166(wrapped)
           10    0.014    0.001    3.747    0.375 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/_symbolic_trace.py:663(trace)
           10    0.002    0.000    3.617    0.362 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:569(wrapped)
           10    0.001    0.000    3.548    0.355 /home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/fx/passes/_utils.py:28(wrapped)
           10    0.000    0.000    3.547    0.355 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:854(catch_errors)
            5    0.001    0.000    3.534    0.707 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:286(_convert_frame_assert)
         10/5    0.000    0.000    3.532    0.706 /usr/lib/python3.10/contextlib.py:76(inner)
            5    0.001    0.000    3.532    0.706 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:448(_compile)
         10/5    0.001    0.000    3.507    0.701 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/utils.py:242(time_wrapper)
            5    0.001    0.000    3.493    0.699 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:531(compile_inner)
          575    0.023    0.000    3.300    0.006 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:653(__torch_dispatch__)
          575    0.021    0.000    3.200    0.006 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:684(inner_torch_dispatch)
          190    0.073    0.000    3.103    0.016 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:303(proxy_call)
     1065/555    0.021    0.000    3.031    0.005 /home/xadupre/.local/lib/python3.10/site-packages/torch/_ops.py:568(__call__)
          265    0.003    0.000    2.857    0.011 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/interpreter.py:256(call_function)
            5    0.001    0.000    2.573    0.515 /home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/exporter.py:356(__init__)
    2440/1780    0.044    0.000    2.537    0.001 /home/xadupre/.local/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:864(__torch_dispatch__)
    2440/1780    0.096    0.000    2.488    0.001 /home/xadupre/.local/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:1185(dispatch)
            5    0.005    0.001    2.429    0.486 /home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/fx/decomposition_table.py:78(create_onnx_friendly_decomposition_table)
            5    0.000    0.000    2.420    0.484 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py:1025(transform_code_object)
            5    0.474    0.095    2.416    0.483 /home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/fx/decomposition_table.py:18(_create_onnx_supports_op_overload_table)
            5    0.001    0.000    2.350    0.470 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:148(_fn)
            5    0.001    0.000    2.344    0.469 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:484(transform)
    1385/1025    0.070    0.000    2.338    0.002 /home/xadupre/.local/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:918(_cached_dispatch_impl)
            5    0.001    0.000    2.314    0.463 /home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/fx/passes/decomp.py:32(_run)
            5    0.000    0.000    2.151    0.430 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:2129(run)
            5    0.002    0.000    2.151    0.430 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:786(run)
          280    0.014    0.000    2.148    0.008 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:684(step)
            5    0.001    0.000    2.048    0.410 /home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/fx/passes/functionalization.py:101(_run)
            5    0.000    0.000    1.703    0.341 /home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/fx/passes/functionalization.py:80(wrapped)
           60    0.001    0.000    1.475    0.025 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:460(wrapper)
           60    0.001    0.000    1.470    0.024 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:1198(CALL_FUNCTION)
           60    0.002    0.000    1.466    0.024 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:637(call_function)
        85/55    0.001    0.000    1.390    0.025 /home/xadupre/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1549(_wrapped_call_impl)
        85/55    0.002    0.000    1.389    0.025 /home/xadupre/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1555(_call_impl)
           65    0.001    0.000    1.309    0.020 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/variables/builder.py:1263(wrap_fx_proxy)
           65    0.031    0.000    1.308    0.020 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/variables/builder.py:1323(wrap_fx_proxy_cls)
      350/170    0.083    0.000    1.202    0.007 /home/xadupre/.local/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:1211(_dispatch_impl)
         1580    0.054    0.000    1.197    0.001 /home/xadupre/.local/lib/python3.10/site-packages/torch/utils/_pytree.py:857(tree_map)
        36010    0.170    0.000    1.098    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/exporter.py:250(is_registered_op)
            5    0.003    0.001    1.069    0.214 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/guards.py:944(__init__)
           60    0.012    0.000    1.033    0.017 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/utils.py:1575(get_fake_value)
           25    0.001    0.000    1.019    0.041 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/interpreter.py:298(call_module)
           25    0.000    0.000    1.016    0.041 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/_symbolic_trace.py:761(module_call_wrapper)
           70    0.007    0.000    1.015    0.014 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/graph_module.py:707(recompile)
           25    0.000    0.000    1.006    0.040 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:502(call_module)
           25    0.000    0.000    1.005    0.040 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/_symbolic_trace.py:763(forward)
           75    0.004    0.000    0.962    0.013 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/graph.py:1281(python_code)
           90    0.001    0.000    0.955    0.011 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/utils.py:1160(wrap_fake_exception)
            5    0.002    0.000    0.933    0.187 /home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/fx/passes/modularization.py:821(_run)
        36085    0.212    0.000    0.932    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/exporter.py:227(get_op_functions)
            5    0.003    0.001    0.919    0.184 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/guards.py:1018(compile_check_fn)
           25    0.002    0.000    0.906    0.036 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/variables/nn_module.py:244(call_function)
           75    0.003    0.000    0.894    0.012 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/graph.py:1343(_python_code)
           75    0.081    0.001    0.890    0.012 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/graph.py:372(_gen_python_code)
           55    0.010    0.000    0.807    0.015 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/graph_module.py:353(__init__)
           45    0.011    0.000    0.794    0.018 /home/xadupre/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py:115(forward)
     1020/865    0.025    0.000    0.790    0.001 /home/xadupre/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1732(__setattr__)
           45    0.051    0.001    0.782    0.017 {built-in method torch._C._nn.linear}
          365    0.013    0.000    0.779    0.002 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/proxy.py:173(create_proxy)
         30/5    0.019    0.001    0.750    0.150 /home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:495(run)
    8330/1760    0.187    0.000    0.745    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/utils/_pytree.py:732(unflatten)
         1385    0.191    0.000    0.744    0.001 /home/xadupre/.local/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:953(_cache_key)
           55    0.011    0.000    0.719    0.013 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/graph_module.py:462(graph)
       220/80    0.011    0.000    0.713    0.009 /home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:413(run_node)
         30/5    0.024    0.001    0.702    0.140 /home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/fx/passes/modularization.py:591(build_module)
      360/310    0.036    0.000    0.663    0.002 {method 'detach' of 'torch._C.TensorBase' objects}
            5    0.000    0.000    0.657    0.131 /home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py:1716(_run)
    215900/211225    0.445    0.000    0.637    0.000 {built-in method builtins.isinstance}
          200    0.007    0.000    0.627    0.003 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:202(track_tensor_tree)
      250/200    0.016    0.000    0.620    0.003 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:203(wrap_with_proxy)
      780/405    0.011    0.000    0.612    0.002 /usr/lib/python3.10/copy.py:259(_reconstruct)
         9470    0.065    0.000    0.606    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/node.py:698(map_arg)
         2180    0.014    0.000    0.597    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/utils/_pytree.py:797(tree_flatten)
          655    0.015    0.000    0.595    0.001 /home/xadupre/.local/lib/python3.10/site-packages/torch/utils/_pytree.py:1032(tree_map_only)
        56435    0.239    0.000    0.595    0.000 {method 'get' of 'dict' objects}
      1595/50    0.031    0.000    0.586    0.012 /usr/lib/python3.10/copy.py:128(deepcopy)
    8660/2180    0.119    0.000    0.583    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/utils/_pytree.py:776(_tree_flatten_helper)
           25    0.001    0.000    0.581    0.023 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/utils.py:1171(deepcopy_to_fake_tensor)
           25    0.000    0.000    0.579    0.023 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/utils.py:1173(<lambda>)
          175    0.005    0.000    0.576    0.003 /home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py:1618(run_node)
           50    0.004    0.000    0.574    0.011 /usr/lib/python3.10/copy.py:227(_deepcopy_dict)
           75    0.001    0.000    0.567    0.008 /home/xadupre/.local/lib/python3.10/site-packages/torch/_prims_common/wrappers.py:242(_fn)
           45    0.003    0.000    0.563    0.013 /home/xadupre/.local/lib/python3.10/site-packages/torch/_decomp/decompositions.py:50(inner)
            5    0.004    0.001    0.560    0.112 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/guards.py:1237(build_guard_function)
           60    0.001    0.000    0.546    0.009 /home/xadupre/.local/lib/python3.10/site-packages/torch/nn/functional.py:1489(relu)
           60    0.032    0.001    0.544    0.009 {built-in method torch.relu}
           35    0.011    0.000    0.540    0.015 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/variables/torch.py:255(call_function)
    18595/9475    0.254    0.000    0.528    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/node.py:706(map_aggregate)
           50    0.005    0.000    0.523    0.010 /home/xadupre/.local/lib/python3.10/site-packages/torch/nn/parameter.py:55(__deepcopy__)
          760    0.036    0.000    0.523    0.001 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/graph.py:878(create_node)
          250    0.006    0.000    0.511    0.002 /home/xadupre/.local/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:1726(__torch_function__)
           25    0.003    0.000    0.510    0.020 /home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:764(call_module)
          480    0.035    0.000    0.503    0.001 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/proxy.py:117(create_node)
     5200/300    0.049    0.000    0.467    0.002 /usr/lib/python3.10/ast.py:414(visit)
    16645/15055    0.100    0.000    0.467    0.000 {built-in method builtins.next}
           30    0.000    0.000    0.462    0.015 /home/xadupre/.local/lib/python3.10/site-packages/torch/_jit_internal.py:487(fn)
          240    0.008    0.000    0.462    0.002 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:166(set_meta)
           30    0.001    0.000    0.462    0.015 /home/xadupre/.local/lib/python3.10/site-packages/torch/nn/functional.py:774(_max_pool2d)
           30    0.026    0.001    0.460    0.015 {built-in method torch.max_pool2d}
        22240    0.240    0.000    0.437    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/fx/registration.py:55(from_qualified_name)
         1035    0.071    0.000    0.436    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:1114(_output_from_cache_entry)
           85    0.007    0.000    0.432    0.005 /home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:647(call_function)
      280/240    0.003    0.000    0.431    0.002 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:135(extract_val)
            5    0.001    0.000    0.428    0.086 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:1244(result_capturing_wrapper)
          260    0.002    0.000    0.426    0.002 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:132(snapshot_fake)
           20    0.001    0.000    0.425    0.021 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/_lazy_graph_module.py:54(_make_graph_module)
        90/50    0.018    0.000    0.413    0.008 {built-in method torch._ops.aten.}
           30    0.001    0.000    0.412    0.014 /home/xadupre/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:459(forward)
           30    0.000    0.000    0.411    0.014 /home/xadupre/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:451(_conv_forward)
           30    0.020    0.001    0.410    0.014 {built-in method torch.conv2d}
          110    0.004    0.000    0.399    0.004 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/variables/builder.py:240(__call__)
          110    0.048    0.000    0.391    0.004 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/variables/builder.py:362(_wrap)
    4525/1900    0.038    0.000    0.390    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/utils/_pytree.py:790(<listcomp>)
         1345    0.052    0.000    0.383    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/graph.py:528(emit_node)
          150    0.022    0.000    0.362    0.002 /home/xadupre/.local/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:507(__torch_dispatch__)
     1570/745    0.031    0.000    0.352    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/_symbolic_trace.py:311(create_arg)
          135    0.009    0.000    0.347    0.003 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/guards.py:1029(add_code_part)
          275    0.010    0.000    0.343    0.001 /home/xadupre/.local/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:318(__call__)
     1240/490    0.039    0.000    0.340    0.001 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:511(create_arg)
    7290/6560    0.042    0.000    0.335    0.000 /usr/lib/python3.10/contextlib.py:130(__enter__)
           60    0.001    0.000    0.335    0.006 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/utils.py:1622(<lambda>)
           60    0.002    0.000    0.334    0.006 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/utils.py:1701(run_node)
          275    0.004    0.000    0.334    0.001 /home/xadupre/.local/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:240(from_real_tensor)
          240    0.032    0.000    0.333    0.001 {method 'to' of 'torch._C.TensorBase' objects}
           65    0.003    0.000    0.331    0.005 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:1292(LOAD_ATTR)
    1410/1255    0.066    0.000    0.328    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:1010(_prep_args_for_hash)
          125    0.002    0.000    0.320    0.003 /home/xadupre/.local/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:1607(from_tensor)
     1570/745    0.063    0.000    0.320    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/proxy.py:240(create_arg)
    11615/11225    0.032    0.000    0.312    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/node.py:712(<genexpr>)
          135    0.019    0.000    0.309    0.002 /home/xadupre/.local/lib/python3.10/site-packages/torch/utils/_traceback.py:170(summary)
          640    0.006    0.000    0.308    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/guards.py:136(_ast_unparse)
          640    0.008    0.000    0.301    0.000 /usr/lib/python3.10/ast.py:1679(unparse)
          105    0.009    0.000    0.298    0.003 /home/xadupre/.local/lib/python3.10/site-packages/torch/_subclasses/meta_utils.py:627(__call__)
    1425/1065    0.006    0.000    0.291    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/proxy.py:258(<genexpr>)
          640    0.005    0.000    0.290    0.000 /usr/lib/python3.10/ast.py:811(visit)
          105    0.051    0.000    0.286    0.003 /home/xadupre/.local/lib/python3.10/site-packages/torch/_subclasses/meta_utils.py:186(meta_tensor)
     3125/640    0.023    0.000    0.283    0.000 /usr/lib/python3.10/ast.py:801(traverse)
          810    0.038    0.000    0.282    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/node.py:165(__init__)
           65    0.009    0.000    0.278    0.004 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/variables/builtin.py:527(call_function)
            5    0.000    0.000    0.275    0.055 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:922(rewrite_signature)
      175/125    0.013    0.000    0.274    0.002 {method 'clone' of 'torch._C.TensorBase' objects}
            5    0.000    0.000    0.267    0.053 /home/xadupre/.local/lib/python3.10/site-packages/torch/_functorch/functional_call.py:10(functional_call)
        74290    0.260    0.000    0.267    0.000 {built-in method builtins.getattr}
            5    0.000    0.000    0.267    0.053 /home/xadupre/.local/lib/python3.10/site-packages/torch/nn/utils/stateless.py:229(_functional_call)
          135    0.002    0.000    0.266    0.002 /home/xadupre/.local/lib/python3.10/site-packages/torch/_decomp/decompositions.py:60(increase_prec)
            5    0.000    0.000    0.261    0.052 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/_lazy_graph_module.py:112(_lazy_forward)
           75    0.001    0.000    0.258    0.003 /home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/fx/onnxfunction_dispatcher.py:111(dispatch)
          100    0.001    0.000    0.256    0.003 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/guards.py:1244(replace)
            5    0.008    0.002    0.255    0.051 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/guards.py:905(count)
          100    0.003    0.000    0.255    0.003 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/guards.py:914(replace)
        14065    0.075    0.000    0.251    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/utils/_pytree.py:606(_is_leaf)
        36110    0.119    0.000    0.245    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/fx/registration.py:44(from_name_parts)
           50    0.001    0.000    0.244    0.005 /home/xadupre/.local/lib/python3.10/site-packages/torch/nn/parameter.py:34(__new__)
         1305    0.093    0.000    0.239    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:673(extract_tensor_metadata)
     1320/100    0.015    0.000    0.236    0.002 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/guards.py:852(visit)
          135    0.036    0.000    0.236    0.002 /home/xadupre/.local/lib/python3.10/site-packages/torch/utils/_traceback.py:246(_extract_symbolized_tb)
        20855    0.098    0.000    0.233    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/utils/_pytree.py:599(_get_node_type)
     1320/100    0.031    0.000    0.232    0.002 /usr/lib/python3.10/ast.py:420(generic_visit)
    7290/6560    0.066    0.000    0.225    0.000 /usr/lib/python3.10/contextlib.py:139(__exit__)
         5005    0.126    0.000    0.224    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/graph.py:131(create_name)
            5    0.014    0.003    0.217    0.043 /home/xadupre/github/onnx-script/onnxscript/function_libs/torch_lib/graph_building.py:943(to_model_proto)
    5405/1085    0.064    0.000    0.211    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/utils/_pytree.py:821(_tree_leaves_helper)
           10    0.002    0.000    0.208    0.021 /home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/fx/passes/_utils.py:83(replace_placeholder_name_and_target)
         6025    0.028    0.000    0.208    0.000 /usr/lib/python3.10/traceback.py:259(__init__)
            5    0.000    0.000    0.207    0.041 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/graph_module.py:736(call_wrapped)
            5    0.000    0.000    0.207    0.041 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/graph_module.py:299(__call__)
           55    0.011    0.000    0.206    0.004 /home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/fx/passes/modularization.py:538(module_inputs)
    70955/67370    0.184    0.000    0.205    0.000 {built-in method builtins.hash}
          675    0.004    0.000    0.203    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/utils/_pytree.py:839(tree_leaves)
         6705    0.052    0.000    0.202    0.000 /usr/lib/python3.10/traceback.py:301(line)
            5    0.000    0.000    0.199    0.040 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:864(transform)
            5    0.000    0.000    0.199    0.040 /home/xadupre/.local/lib/python3.10/site-packages/torch/fx/interpreter.py:500(transform)
            5    0.001    0.000    0.190    0.038 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:2022(__init__)
           45    0.014    0.000    0.181    0.004 /home/xadupre/.local/lib/python3.10/site-packages/torch/_decomp/decompositions.py:1321(addmm)
      525/340    0.013    0.000    0.178    0.001 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/variables/base.py:168(apply)
         4525    0.060    0.000    0.176    0.000 /home/xadupre/.local/lib/python3.10/site-packages/torch/utils/_pytree.py:627(__post_init__)
      930/100    0.014    0.000    0.172    0.002 /home/xadupre/.local/lib/python3.10/site-packages/torch/_dynamo/guards.py:868(visit)
    done.
    profile dynopt: <function export_dynopt at 0x7f087268db40>
    done.




.. GENERATED FROM PYTHON SOURCE LINES 493-495

Benchmark exported models with ORT
++++++++++++++++++++++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 495-640

.. code-block:: Python



    def benchmark(shape):
        from onnxruntime import InferenceSession, SessionOptions, GraphOptimizationLevel

        data = []
        data1 = []
        data_mem_load = []
        data_mem_first_run = []
        data_mem_run = []
        confs = list(
            itertools.product(
                [_ for _ in os.listdir(".") if ".onnx" in _ and _.startswith("plot_torch")],
                [
                    ["CPUExecutionProvider"],
                    ["CUDAExecutionProvider", "CPUExecutionProvider"],
                ],
                ["0", "1"],
            )
        )
        loop = tqdm(confs)
        print(f"number of experiments: {len(loop)}")
        for name, ps, aot in loop:
            root = os.path.split(name)[-1]
            _, ext = os.path.splitext(root)
            if ext != ".onnx":
                continue

            obs = {}  # system_info()
            obs["name"] = name
            obs["providers"] = ",".join(ps)
            p = "CUDA" if "CUDA" in obs["providers"] else "CPU"
            obs["compute"] = p
            obs["aot"] = 1 if aot == "0" else 0
            obs["export"] = name.replace("plot_torch_export_", "").replace(".onnx", "")

            if not has_cuda and p == "CUDA":
                continue

            onx = onnx.load(name)
            obs["n_nodes"] = len(onx.graph.node)
            obs["n_function"] = len(onx.functions or [])
            obs["n_sub"] = len([n for n in onx.graph.node if n.op_type == "Sub"])
            obs1 = obs.copy()
            short_obs = dict(
                name=obs["name"],
                aot=obs["aot"],
                providers=obs["providers"],
                export=obs["export"],
                compute=obs["compute"],
            )

            opts = SessionOptions()
            opts.add_session_config_entry("session.disable_aot_function_inlining", aot)
            opts.graph_optimization_level = GraphOptimizationLevel.ORT_ENABLE_ALL
            opts.optimized_model_filepath = (
                f"ort-{name.replace('.onnx', '')}-{p.lower()}-"
                f"aot{1 if aot == '0' else 0}.onnx"
            )

            try:
                InferenceSession(name, opts, providers=ps)
            except Exception as e:
                loop.set_description(f"ERROR-load: {name} {e}")
                obs.update({"error": e, "step": "run"})
                data.append(obs)
                continue

            opts = SessionOptions()
            opts.add_session_config_entry("session.disable_aot_function_inlining", aot)
            opts.graph_optimization_level = GraphOptimizationLevel.ORT_ENABLE_ALL
            stat = start_spying_on(cuda=1 if has_cuda else 0)
            sess = InferenceSession(name, opts, providers=ps)
            memobs = flatten(stat.stop())
            memobs.update(short_obs)
            data_mem_load.append(memobs)

            input_name = sess.get_inputs()[0].name
            feeds = {input_name: np.random.rand(*shape).astype(np.float32)}

            stat = start_spying_on(cuda=1 if has_cuda else 0)
            try:
                sess.run(None, feeds)
            except Exception as e:
                loop.set_description(f"ERROR-run: {name} {e}")
                obs.update({"error": e, "step": "load"})
                data.append(obs)
                stat.stop()
                continue
            memobs = flatten(stat.stop())
            memobs.update(short_obs)
            data_mem_first_run.append(memobs)

            # memory consumption
            stat = start_spying_on(cuda=1 if has_cuda else 0)
            for i in range(0, script_args.warmup):
                sess.run(None, feeds)
            memobs = flatten(stat.stop())
            memobs.update(short_obs)
            data_mem_run.append(memobs)

            obs.update(
                measure_time(
                    lambda: sess.run(None, feeds),
                    max_time=script_args.maxtime,
                    repeat=script_args.repeat,
                    number=1,
                )
            )

            loop.set_description(f"{obs['average']} {name} {ps}")
            data.append(obs)

            # check first run
            obs1.update(
                measure_time(
                    lambda: InferenceSession(name, opts, providers=ps).run(None, feeds),
                    max_time=script_args.maxtime,
                    repeat=max(1, script_args.repeat // 2),
                    number=1,
                )
            )
            data1.append(obs1)

        df = pandas.DataFrame(data)
        df.to_csv("plot_torch_export_ort_time.csv", index=False)
        df.to_excel("plot_torch_export_ort_time.xlsx", index=False)
        df1 = pandas.DataFrame(data1)
        df1.to_csv("plot_torch_export_ort_time1_init.csv", index=False)
        df1.to_excel("plot_torch_export_ort_time1_init.xlsx", index=False)
        dfmem = pandas.DataFrame(data_mem_load)
        dfmem.to_csv("plot_torch_export_ort_load_mem.csv", index=False)
        dfmem.to_excel("plot_torch_export_ort_load_mem.xlsx", index=False)
        dfmemr = pandas.DataFrame(data_mem_run)
        dfmemr.to_csv("plot_torch_export_ort_run_mem.csv", index=False)
        dfmemr.to_excel("plot_torch_export_ort_run_mem.xlsx", index=False)
        dfmemfr = pandas.DataFrame(data_mem_first_run)
        dfmemfr.to_csv("plot_torch_export_ort_first_run_mem.csv", index=False)
        dfmemfr.to_excel("plot_torch_export_ort_first_run_mem.xlsx", index=False)
        return df, df1, dfmem, dfmemfr, dfmemr


    df, df_init, dfmem, dfmemfr, dfmemr = benchmark(list(input_tensor.shape))
    print(df)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

      0%|          | 0/20 [00:00<?, ?it/s]number of experiments: 20
    8.560786136436462e-05 plot_torch_export_cus_p2.onnx ['CPUExecutionProvider']:   0%|          | 0/20 [00:01<?, ?it/s]    8.560786136436462e-05 plot_torch_export_cus_p2.onnx ['CPUExecutionProvider']:   5%|▌         | 1/20 [00:01<00:35,  1.85s/it]    0.0002595144097199409 plot_torch_export_cus_p2.onnx ['CPUExecutionProvider']:   5%|▌         | 1/20 [00:02<00:35,  1.85s/it]    0.0002595144097199409 plot_torch_export_cus_p2.onnx ['CPUExecutionProvider']:  10%|█         | 2/20 [00:02<00:23,  1.30s/it]    0.001011537735840253 plot_torch_export_cus_p2.onnx ['CUDAExecutionProvider', 'CPUExecutionProvider']:  10%|█         | 2/20 [00:16<00:23,  1.30s/it]    0.001011537735840253 plot_torch_export_cus_p2.onnx ['CUDAExecutionProvider', 'CPUExecutionProvider']:  15%|█▌        | 3/20 [00:16<01:59,  7.01s/it]    0.0011035314960245732 plot_torch_export_cus_p2.onnx ['CUDAExecutionProvider', 'CPUExecutionProvider']:  15%|█▌        | 3/20 [00:17<01:59,  7.01s/it]    0.0011035314960245732 plot_torch_export_cus_p2.onnx ['CUDAExecutionProvider', 'CPUExecutionProvider']:  20%|██        | 4/20 [00:17<01:13,  4.62s/it]    0.00022546918367805454 plot_torch_export_script.onnx ['CPUExecutionProvider']:  20%|██        | 4/20 [00:18<01:13,  4.62s/it]                            0.00022546918367805454 plot_torch_export_script.onnx ['CPUExecutionProvider']:  25%|██▌       | 5/20 [00:18<00:49,  3.32s/it]    0.00017236805555824897 plot_torch_export_script.onnx ['CPUExecutionProvider']:  25%|██▌       | 5/20 [00:19<00:49,  3.32s/it]    0.00017236805555824897 plot_torch_export_script.onnx ['CPUExecutionProvider']:  30%|███       | 6/20 [00:19<00:35,  2.57s/it]    0.001966687037094272 plot_torch_export_script.onnx ['CUDAExecutionProvider', 'CPUExecutionProvider']:  30%|███       | 6/20 [00:20<00:35,  2.57s/it]    0.001966687037094272 plot_torch_export_script.onnx ['CUDAExecutionProvider', 'CPUExecutionProvider']:  35%|███▌      | 7/20 [00:20<00:26,  2.03s/it]    0.0038270138887431435 plot_torch_export_script.onnx ['CUDAExecutionProvider', 'CPUExecutionProvider']:  35%|███▌      | 7/20 [00:21<00:26,  2.03s/it]    0.0038270138887431435 plot_torch_export_script.onnx ['CUDAExecutionProvider', 'CPUExecutionProvider']:  40%|████      | 8/20 [00:21<00:20,  1.71s/it]    0.0005795436868584607 plot_torch_export_cus_p0.onnx ['CPUExecutionProvider']:  40%|████      | 8/20 [00:22<00:20,  1.71s/it]                             0.0005795436868584607 plot_torch_export_cus_p0.onnx ['CPUExecutionProvider']:  45%|████▌     | 9/20 [00:22<00:17,  1.58s/it]    0.0002186840277747453 plot_torch_export_cus_p0.onnx ['CPUExecutionProvider']:  45%|████▌     | 9/20 [00:23<00:17,  1.58s/it]    0.0002186840277747453 plot_torch_export_cus_p0.onnx ['CPUExecutionProvider']:  50%|█████     | 10/20 [00:23<00:14,  1.41s/it]    0.0021747705882886543 plot_torch_export_cus_p0.onnx ['CUDAExecutionProvider', 'CPUExecutionProvider']:  50%|█████     | 10/20 [00:24<00:14,  1.41s/it]    0.0021747705882886543 plot_torch_export_cus_p0.onnx ['CUDAExecutionProvider', 'CPUExecutionProvider']:  55%|█████▌    | 11/20 [00:25<00:11,  1.32s/it]    0.0032555266665844507 plot_torch_export_cus_p0.onnx ['CUDAExecutionProvider', 'CPUExecutionProvider']:  55%|█████▌    | 11/20 [00:26<00:11,  1.32s/it]    0.0032555266665844507 plot_torch_export_cus_p0.onnx ['CUDAExecutionProvider', 'CPUExecutionProvider']:  60%|██████    | 12/20 [00:26<00:11,  1.38s/it]    0.0002162754458074815 plot_torch_export_dynopt.onnx ['CPUExecutionProvider']:  60%|██████    | 12/20 [00:27<00:11,  1.38s/it]                             0.0002162754458074815 plot_torch_export_dynopt.onnx ['CPUExecutionProvider']:  65%|██████▌   | 13/20 [00:27<00:08,  1.24s/it]    7.662876132626672e-05 plot_torch_export_dynopt.onnx ['CPUExecutionProvider']:  65%|██████▌   | 13/20 [00:28<00:08,  1.24s/it]    7.662876132626672e-05 plot_torch_export_dynopt.onnx ['CPUExecutionProvider']:  70%|███████   | 14/20 [00:28<00:06,  1.09s/it]    0.0018600317461176827 plot_torch_export_dynopt.onnx ['CUDAExecutionProvider', 'CPUExecutionProvider']:  70%|███████   | 14/20 [00:28<00:06,  1.09s/it]    0.0018600317461176827 plot_torch_export_dynopt.onnx ['CUDAExecutionProvider', 'CPUExecutionProvider']:  75%|███████▌  | 15/20 [00:29<00:05,  1.02s/it]    0.001534912345735471 plot_torch_export_dynopt.onnx ['CUDAExecutionProvider', 'CPUExecutionProvider']:  75%|███████▌  | 15/20 [00:29<00:05,  1.02s/it]     0.001534912345735471 plot_torch_export_dynopt.onnx ['CUDAExecutionProvider', 'CPUExecutionProvider']:  80%|████████  | 16/20 [00:30<00:04,  1.00s/it]    0.00031196151685639707 plot_torch_export_dynamo.onnx ['CPUExecutionProvider']:  80%|████████  | 16/20 [00:30<00:04,  1.00s/it]                           0.00031196151685639707 plot_torch_export_dynamo.onnx ['CPUExecutionProvider']:  85%|████████▌ | 17/20 [00:30<00:02,  1.03it/s]    0.00018786616915598308 plot_torch_export_dynamo.onnx ['CPUExecutionProvider']:  85%|████████▌ | 17/20 [00:31<00:02,  1.03it/s]    0.00018786616915598308 plot_torch_export_dynamo.onnx ['CPUExecutionProvider']:  90%|█████████ | 18/20 [00:31<00:01,  1.01it/s]    0.00358581190483251 plot_torch_export_dynamo.onnx ['CUDAExecutionProvider', 'CPUExecutionProvider']:  90%|█████████ | 18/20 [00:32<00:01,  1.01it/s]    0.00358581190483251 plot_torch_export_dynamo.onnx ['CUDAExecutionProvider', 'CPUExecutionProvider']:  95%|█████████▌| 19/20 [00:32<00:00,  1.00it/s]    0.00450016666649457 plot_torch_export_dynamo.onnx ['CUDAExecutionProvider', 'CPUExecutionProvider']:  95%|█████████▌| 19/20 [00:33<00:00,  1.00it/s]    0.00450016666649457 plot_torch_export_dynamo.onnx ['CUDAExecutionProvider', 'CPUExecutionProvider']: 100%|██████████| 20/20 [00:34<00:00,  1.09s/it]    0.00450016666649457 plot_torch_export_dynamo.onnx ['CUDAExecutionProvider', 'CPUExecutionProvider']: 100%|██████████| 20/20 [00:34<00:00,  1.71s/it]
                                 name                                   providers compute  aot  export  n_nodes  n_function  n_sub   average  deviation  min_exec  max_exec  repeat  number     ttime  context_size  warmup_time
    0   plot_torch_export_cus_p2.onnx                        CPUExecutionProvider     CPU    1  cus_p2       12           0      0  0.000086   0.000007  0.000080  0.000158       1  1183.0  0.101274            64     0.000377
    1   plot_torch_export_cus_p2.onnx                        CPUExecutionProvider     CPU    0  cus_p2       12           0      0  0.000260   0.000009  0.000163  0.000264       1   576.0  0.149480            64     0.000406
    2   plot_torch_export_cus_p2.onnx  CUDAExecutionProvider,CPUExecutionProvider    CUDA    1  cus_p2       12           0      0  0.001012   0.000162  0.000626  0.001237       1   159.0  0.160834            64     0.001094
    3   plot_torch_export_cus_p2.onnx  CUDAExecutionProvider,CPUExecutionProvider    CUDA    0  cus_p2       12           0      0  0.001104   0.000244  0.000799  0.001489       1   127.0  0.140148            64     0.001155
    4   plot_torch_export_script.onnx                        CPUExecutionProvider     CPU    1  script       12           0      0  0.000225   0.000122  0.000092  0.000939       1   490.0  0.110480            64     0.001700
    5   plot_torch_export_script.onnx                        CPUExecutionProvider     CPU    0  script       12           0      0  0.000172   0.000011  0.000109  0.000180       1   792.0  0.136516            64     0.000611
    6   plot_torch_export_script.onnx  CUDAExecutionProvider,CPUExecutionProvider    CUDA    1  script       12           0      0  0.001967   0.000687  0.001480  0.002975       1    54.0  0.106201            64     0.002664
    7   plot_torch_export_script.onnx  CUDAExecutionProvider,CPUExecutionProvider    CUDA    0  script       12           0      0  0.003827   0.000392  0.002180  0.004020       1    36.0  0.137772            64     0.001958
    8   plot_torch_export_cus_p0.onnx                        CPUExecutionProvider     CPU    1  cus_p0       27           0      2  0.000580   0.000083  0.000231  0.000693       1   396.0  0.229499            64     0.000641
    9   plot_torch_export_cus_p0.onnx                        CPUExecutionProvider     CPU    0  cus_p0       27           0      2  0.000219   0.000020  0.000154  0.000247       1   576.0  0.125962            64     0.000495
    10  plot_torch_export_cus_p0.onnx  CUDAExecutionProvider,CPUExecutionProvider    CUDA    1  cus_p0       27           0      2  0.002175   0.000178  0.002049  0.002504       1    51.0  0.110913            64     0.004019
    11  plot_torch_export_cus_p0.onnx  CUDAExecutionProvider,CPUExecutionProvider    CUDA    0  cus_p0       27           0      2  0.003256   0.000439  0.002623  0.004127       1    45.0  0.146499            64     0.002513
    12  plot_torch_export_dynopt.onnx                        CPUExecutionProvider     CPU    1  dynopt       18           0      0  0.000216   0.000052  0.000119  0.000290       1   729.0  0.157665            64     0.000447
    13  plot_torch_export_dynopt.onnx                        CPUExecutionProvider     CPU    0  dynopt       18           0      0  0.000077   0.000009  0.000068  0.000104       1  1655.0  0.126821            64     0.000348
    14  plot_torch_export_dynopt.onnx  CUDAExecutionProvider,CPUExecutionProvider    CUDA    1  dynopt       18           0      0  0.001860   0.000153  0.001594  0.002099       1    63.0  0.117182            64     0.002654
    15  plot_torch_export_dynopt.onnx  CUDAExecutionProvider,CPUExecutionProvider    CUDA    0  dynopt       18           0      0  0.001535   0.000170  0.001467  0.002418       1    81.0  0.124328            64     0.002888
    16  plot_torch_export_dynamo.onnx                        CPUExecutionProvider     CPU    1  dynamo       13          13      0  0.000312   0.000070  0.000211  0.000863       1   356.0  0.111058            64     0.001176
    17  plot_torch_export_dynamo.onnx                        CPUExecutionProvider     CPU    0  dynamo       13          13      0  0.000188   0.000007  0.000179  0.000245       1   603.0  0.113283            64     0.000475
    18  plot_torch_export_dynamo.onnx  CUDAExecutionProvider,CPUExecutionProvider    CUDA    1  dynamo       13          13      0  0.003586   0.001238  0.002168  0.005421       1    42.0  0.150604            64     0.003954
    19  plot_torch_export_dynamo.onnx  CUDAExecutionProvider,CPUExecutionProvider    CUDA    0  dynamo       13          13      0  0.004500   0.000413  0.004219  0.005258       1    27.0  0.121504            64     0.005392




.. GENERATED FROM PYTHON SOURCE LINES 641-642

Other view

.. GENERATED FROM PYTHON SOURCE LINES 642-679

.. code-block:: Python



    def view_time(df, title, suffix="time"):
        piv = pandas.pivot_table(
            df, index="export", columns=["compute", "aot"], values="average"
        )
        print(piv)
        piv.to_csv(f"plot_torch_export_ort_{suffix}_compute.csv")
        piv.to_excel(f"plot_torch_export_ort_{suffix}_compute.xlsx")

        piv_cpu = pandas.pivot_table(
            df[df.compute == "CPU"],
            index="export",
            columns=["compute", "aot"],
            values="average",
        )

        fig, ax = plt.subplots(1, 2, figsize=(12, 4))
        fig.suptitle(title)
        piv_cpu.plot.barh(ax=ax[0], title="CPU")

        if has_cuda:
            piv_gpu = pandas.pivot_table(
                df[df.compute == "CUDA"],
                index="export",
                columns=["compute", "aot"],
                values="average",
            )
            piv_gpu.plot.barh(ax=ax[1], title="CUDA")

        fig.tight_layout()
        fig.savefig(f"plot_torch_export_ort_{suffix}.png")
        return ax


    view_time(df, "Compares onnxruntime time on exported models")




.. image-sg:: /auto_examples/images/sphx_glr_plot_torch_export_003.png
   :alt: Compares onnxruntime time on exported models, CPU, CUDA
   :srcset: /auto_examples/images/sphx_glr_plot_torch_export_003.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    compute       CPU                CUDA          
    aot             0         1         0         1
    export                                         
    cus_p0   0.000219  0.000580  0.003256  0.002175
    cus_p2   0.000260  0.000086  0.001104  0.001012
    dynamo   0.000188  0.000312  0.004500  0.003586
    dynopt   0.000077  0.000216  0.001535  0.001860
    script   0.000172  0.000225  0.003827  0.001967

    array([<Axes: title={'center': 'CPU'}, ylabel='export'>,
           <Axes: title={'center': 'CUDA'}, ylabel='export'>], dtype=object)



.. GENERATED FROM PYTHON SOURCE LINES 680-681

New graph without the very long times.

.. GENERATED FROM PYTHON SOURCE LINES 681-709

.. code-block:: Python


    piv_cpu = pandas.pivot_table(
        df[
            (df.compute == "CPU")
            & ((df.aot == 1) | ((df.export != "dynamo") & (df.export != "dynopt")))
        ],
        index="export",
        columns=["compute", "aot"],
        values="average",
    )

    fig, ax = plt.subplots(1, 2, figsize=(12, 4))
    fig.suptitle("Compares onnxruntime time on exported models\nHide dynamo without AOT")
    piv_cpu.plot.barh(ax=ax[0], title="CPU")

    if has_cuda:
        piv_gpu = pandas.pivot_table(
            df[df.compute == "CUDA"],
            index="export",
            columns=["compute", "aot"],
            values="average",
        )
        piv_gpu.plot.barh(ax=ax[1], title="CUDA")

    fig.tight_layout()
    fig.savefig("plot_torch_export_ort_time_2.png")





.. image-sg:: /auto_examples/images/sphx_glr_plot_torch_export_004.png
   :alt: Compares onnxruntime time on exported models Hide dynamo without AOT, CPU, CUDA
   :srcset: /auto_examples/images/sphx_glr_plot_torch_export_004.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 710-711

Let's do the same with the loading time + the first run.

.. GENERATED FROM PYTHON SOURCE LINES 711-719

.. code-block:: Python


    view_time(
        df_init,
        "Compares onnxruntime loading time and first run on exported models",
        suffix="time1_init",
    )





.. image-sg:: /auto_examples/images/sphx_glr_plot_torch_export_005.png
   :alt: Compares onnxruntime loading time and first run on exported models, CPU, CUDA
   :srcset: /auto_examples/images/sphx_glr_plot_torch_export_005.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    compute       CPU                CUDA          
    aot             0         1         0         1
    export                                         
    cus_p0   0.022111  0.067302  0.152128  0.051576
    cus_p2   0.018234  0.006767  0.044191  0.027138
    dynamo   0.071992  0.020337  0.205793  0.082254
    dynopt   0.009902  0.019579  0.025880  0.030232
    script   0.012983  0.008208  0.041099  0.021895

    array([<Axes: title={'center': 'CPU'}, ylabel='export'>,
           <Axes: title={'center': 'CUDA'}, ylabel='export'>], dtype=object)



.. GENERATED FROM PYTHON SOURCE LINES 720-722

Memory Loading Time (ORT)
+++++++++++++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 722-736

.. code-block:: Python


    for compute in ["CPU", "CUDA"]:
        if not has_cuda and compute == "CUDA":
            continue
        ax = memory_peak_plot(
            dfmem[dfmem.compute == compute],
            ("export", "aot"),
            suptitle=f"Memory Consumption of onnxruntime loading time"
            f"\nrunning on {compute}",
            bars=[model_size * i / 2**20 for i in range(1, 3)],
            figsize=(18, 6),
        )
        get_figure(ax).savefig(f"plot_torch_export_ort_load_mem_{compute}.png")




.. rst-class:: sphx-glr-horizontal


    *

      .. image-sg:: /auto_examples/images/sphx_glr_plot_torch_export_006.png
         :alt: Memory Consumption of onnxruntime loading time running on CPU, Memory peak (Mb), Memory peak - memory begin (Mb), Memory average - memory begin (Mb), GPU Memory peak (Mb), GPU Memory peak - memory begin (Mb), GPU Memory average - memory begin (Mb)
         :srcset: /auto_examples/images/sphx_glr_plot_torch_export_006.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/images/sphx_glr_plot_torch_export_007.png
         :alt: Memory Consumption of onnxruntime loading time running on CUDA, Memory peak (Mb), Memory peak - memory begin (Mb), Memory average - memory begin (Mb), GPU Memory peak (Mb), GPU Memory peak - memory begin (Mb), GPU Memory average - memory begin (Mb)
         :srcset: /auto_examples/images/sphx_glr_plot_torch_export_007.png
         :class: sphx-glr-multi-img





.. GENERATED FROM PYTHON SOURCE LINES 737-739

Memory First Running Time (ORT)
+++++++++++++++++++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 739-753

.. code-block:: Python


    for compute in ["CPU", "CUDA"]:
        if not has_cuda and compute == "CUDA":
            continue
        ax = memory_peak_plot(
            dfmemfr[dfmemfr.compute == compute],
            ("export", "aot"),
            suptitle=f"Memory Consumption of onnxruntime first running time"
            f"\nrunning on {compute}",
            bars=[model_size * i / 2**20 for i in range(1, 3)],
            figsize=(18, 6),
        )
        get_figure(ax).savefig(f"plot_torch_export_ort_first_run_mem_{compute}.png")




.. rst-class:: sphx-glr-horizontal


    *

      .. image-sg:: /auto_examples/images/sphx_glr_plot_torch_export_008.png
         :alt: Memory Consumption of onnxruntime first running time running on CPU, Memory peak (Mb), Memory peak - memory begin (Mb), Memory average - memory begin (Mb), GPU Memory peak (Mb), GPU Memory peak - memory begin (Mb), GPU Memory average - memory begin (Mb)
         :srcset: /auto_examples/images/sphx_glr_plot_torch_export_008.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/images/sphx_glr_plot_torch_export_009.png
         :alt: Memory Consumption of onnxruntime first running time running on CUDA, Memory peak (Mb), Memory peak - memory begin (Mb), Memory average - memory begin (Mb), GPU Memory peak (Mb), GPU Memory peak - memory begin (Mb), GPU Memory average - memory begin (Mb)
         :srcset: /auto_examples/images/sphx_glr_plot_torch_export_009.png
         :class: sphx-glr-multi-img





.. GENERATED FROM PYTHON SOURCE LINES 754-756

Memory Running Time (ORT)
+++++++++++++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 756-771

.. code-block:: Python


    for compute in ["CPU", "CUDA"]:
        if not has_cuda and compute == "CUDA":
            continue
        ax = memory_peak_plot(
            dfmemr[dfmemr.compute == compute],
            ("export", "aot"),
            suptitle=f"Memory Consumption of onnxruntime running time"
            f"\nrunning on {compute}",
            bars=[model_size * i / 2**20 for i in range(1, 3)],
            figsize=(18, 6),
        )
        get_figure(ax).savefig(f"plot_torch_export_ort_run_mem_{compute}.png")





.. rst-class:: sphx-glr-horizontal


    *

      .. image-sg:: /auto_examples/images/sphx_glr_plot_torch_export_010.png
         :alt: Memory Consumption of onnxruntime running time running on CPU, Memory peak (Mb), Memory peak - memory begin (Mb), Memory average - memory begin (Mb), GPU Memory peak (Mb), GPU Memory peak - memory begin (Mb), GPU Memory average - memory begin (Mb)
         :srcset: /auto_examples/images/sphx_glr_plot_torch_export_010.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/images/sphx_glr_plot_torch_export_011.png
         :alt: Memory Consumption of onnxruntime running time running on CUDA, Memory peak (Mb), Memory peak - memory begin (Mb), Memory average - memory begin (Mb), GPU Memory peak (Mb), GPU Memory peak - memory begin (Mb), GPU Memory average - memory begin (Mb)
         :srcset: /auto_examples/images/sphx_glr_plot_torch_export_011.png
         :class: sphx-glr-multi-img





.. GENERATED FROM PYTHON SOURCE LINES 772-777

Show the interesting models for CPU
+++++++++++++++++++++++++++++++++++

script
~~~~~~

.. GENERATED FROM PYTHON SOURCE LINES 777-782

.. code-block:: Python


    model = "ort-plot_torch_export_cus_p2-cpu-aot0.onnx"
    if os.path.exists(model):
        print(onnx_simple_text_plot(onnx.load(model)))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    opset: domain='' version=18
    opset: domain='ai.onnx.ml' version=4
    opset: domain='ai.onnx.training' version=1
    opset: domain='ai.onnx.preview.training' version=1
    opset: domain='com.microsoft' version=1
    opset: domain='com.microsoft.experimental' version=1
    opset: domain='com.microsoft.nchwc' version=1
    opset: domain='org.pytorch.aten' version=1
    input: name='input' type=dtype('float32') shape=[1, 1, 16, 16]
    init: name='reorder' type=dtype('float32') shape=(16, 1, 5, 5)
    init: name='arg1_1' type=dtype('float32') shape=(16,)
    init: name='reorder_token_10' type=dtype('float32') shape=(16, 16, 5, 5)
    init: name='arg3_1' type=dtype('float32') shape=(16,)
    init: name='arg5_1' type=dtype('float32') shape=(512,)
    init: name='arg7_1' type=dtype('float32') shape=(128,)
    init: name='arg9_1' type=dtype('float32') shape=(10,)
    init: name='ortshared_7_1_2_0_token_8' type=dtype('int64') shape=(2,) -- array([ 1, 16])
    init: name='t' type=dtype('float32') shape=(16, 512)
    init: name='t_1' type=dtype('float32') shape=(512, 128)
    init: name='t_2' type=dtype('float32') shape=(128, 10)
    Conv[com.microsoft.nchwc](input, reorder, arg1_1, activation=b'Relu', dilations=[1,1], group=1, strides=[1,1], pads=[0,0,0,0], auto_pad=b'NOTSET') -> reorder_token_9
      ReorderOutput[com.microsoft.nchwc](reorder_token_9, channels_last=0, channels=16) -> relu
        MaxPool(relu, storage_order=0, auto_pad=b'NOTSET', ceil_mode=0, dilations=[1,1], kernel_shape=[2,2], pads=[0,0,0,0], strides=[2,2]) -> _onx_maxpool0, _onx_maxpool1
          ReorderInput[com.microsoft.nchwc](_onx_maxpool0, channels_last=0) -> reorder_token_11
            Conv[com.microsoft.nchwc](reorder_token_11, reorder_token_10, arg3_1, activation=b'Relu', dilations=[1,1], group=1, strides=[1,1], pads=[0,0,0,0], auto_pad=b'NOTSET') -> reorder_token_12
              ReorderOutput[com.microsoft.nchwc](reorder_token_12, channels_last=0, channels=16) -> relu_1
                MaxPool(relu_1, storage_order=0, auto_pad=b'NOTSET', ceil_mode=0, dilations=[1,1], kernel_shape=[2,2], pads=[0,0,0,0], strides=[2,2]) -> _onx_maxpool03, _onx_maxpool13
                  Reshape(_onx_maxpool03, ortshared_7_1_2_0_token_8, allowzero=0) -> view
                    FusedGemm[com.microsoft](view, t, arg5_1, activation=b'Relu', transB=0, transA=0, alpha=1.00, beta=1.00) -> relu_2
                      FusedGemm[com.microsoft](relu_2, t_1, arg7_1, activation=b'Relu', transB=0, transA=0, alpha=1.00, beta=1.00) -> relu_3
                        Gemm(relu_3, t_2, arg9_1, transB=0, transA=0, alpha=1.00, beta=1.00) -> output_0
    output: name='output_0' type=dtype('float32') shape=[1, 10]




.. GENERATED FROM PYTHON SOURCE LINES 783-785

cus_p2
~~~~~~

.. GENERATED FROM PYTHON SOURCE LINES 785-790

.. code-block:: Python


    model = "ort-plot_torch_export_cus_p2-cpu-aot0.onnx"
    if os.path.exists(model):
        print(onnx_simple_text_plot(onnx.load(model)))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    opset: domain='' version=18
    opset: domain='ai.onnx.ml' version=4
    opset: domain='ai.onnx.training' version=1
    opset: domain='ai.onnx.preview.training' version=1
    opset: domain='com.microsoft' version=1
    opset: domain='com.microsoft.experimental' version=1
    opset: domain='com.microsoft.nchwc' version=1
    opset: domain='org.pytorch.aten' version=1
    input: name='input' type=dtype('float32') shape=[1, 1, 16, 16]
    init: name='reorder' type=dtype('float32') shape=(16, 1, 5, 5)
    init: name='arg1_1' type=dtype('float32') shape=(16,)
    init: name='reorder_token_10' type=dtype('float32') shape=(16, 16, 5, 5)
    init: name='arg3_1' type=dtype('float32') shape=(16,)
    init: name='arg5_1' type=dtype('float32') shape=(512,)
    init: name='arg7_1' type=dtype('float32') shape=(128,)
    init: name='arg9_1' type=dtype('float32') shape=(10,)
    init: name='ortshared_7_1_2_0_token_8' type=dtype('int64') shape=(2,) -- array([ 1, 16])
    init: name='t' type=dtype('float32') shape=(16, 512)
    init: name='t_1' type=dtype('float32') shape=(512, 128)
    init: name='t_2' type=dtype('float32') shape=(128, 10)
    Conv[com.microsoft.nchwc](input, reorder, arg1_1, activation=b'Relu', dilations=[1,1], group=1, strides=[1,1], pads=[0,0,0,0], auto_pad=b'NOTSET') -> reorder_token_9
      ReorderOutput[com.microsoft.nchwc](reorder_token_9, channels_last=0, channels=16) -> relu
        MaxPool(relu, storage_order=0, auto_pad=b'NOTSET', ceil_mode=0, dilations=[1,1], kernel_shape=[2,2], pads=[0,0,0,0], strides=[2,2]) -> _onx_maxpool0, _onx_maxpool1
          ReorderInput[com.microsoft.nchwc](_onx_maxpool0, channels_last=0) -> reorder_token_11
            Conv[com.microsoft.nchwc](reorder_token_11, reorder_token_10, arg3_1, activation=b'Relu', dilations=[1,1], group=1, strides=[1,1], pads=[0,0,0,0], auto_pad=b'NOTSET') -> reorder_token_12
              ReorderOutput[com.microsoft.nchwc](reorder_token_12, channels_last=0, channels=16) -> relu_1
                MaxPool(relu_1, storage_order=0, auto_pad=b'NOTSET', ceil_mode=0, dilations=[1,1], kernel_shape=[2,2], pads=[0,0,0,0], strides=[2,2]) -> _onx_maxpool03, _onx_maxpool13
                  Reshape(_onx_maxpool03, ortshared_7_1_2_0_token_8, allowzero=0) -> view
                    FusedGemm[com.microsoft](view, t, arg5_1, activation=b'Relu', transB=0, transA=0, alpha=1.00, beta=1.00) -> relu_2
                      FusedGemm[com.microsoft](relu_2, t_1, arg7_1, activation=b'Relu', transB=0, transA=0, alpha=1.00, beta=1.00) -> relu_3
                        Gemm(relu_3, t_2, arg9_1, transB=0, transA=0, alpha=1.00, beta=1.00) -> output_0
    output: name='output_0' type=dtype('float32') shape=[1, 10]




.. GENERATED FROM PYTHON SOURCE LINES 791-793

dynopt
~~~~~~

.. GENERATED FROM PYTHON SOURCE LINES 793-798

.. code-block:: Python


    model = "ort-plot_torch_export_dynopt-cpu-aot1.onnx"
    if os.path.exists(model):
        print(onnx_simple_text_plot(onnx.load(model)))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    opset: domain='pkg.onnxscript.torch_lib' version=1
    opset: domain='pkg.torch.2.3.0.dev20240209+cu118' version=1
    opset: domain='' version=18
    opset: domain='pkg.onnxscript.torch_lib.common' version=1
    opset: domain='ai.onnx.ml' version=4
    opset: domain='ai.onnx.training' version=1
    opset: domain='ai.onnx.preview.training' version=1
    opset: domain='com.microsoft' version=1
    opset: domain='com.microsoft.experimental' version=1
    opset: domain='com.microsoft.nchwc' version=1
    opset: domain='org.pytorch.aten' version=1
    input: name='l_x_' type=dtype('float32') shape=[1, 1, 16, 16]
    init: name='reorder' type=dtype('float32') shape=(16, 1, 5, 5)
    init: name='conv1.bias' type=dtype('float32') shape=(16,)
    init: name='reorder_token_10' type=dtype('float32') shape=(16, 16, 5, 5)
    init: name='conv2.bias' type=dtype('float32') shape=(16,)
    init: name='fc1.bias' type=dtype('float32') shape=(512,)
    init: name='fc2.bias' type=dtype('float32') shape=(128,)
    init: name='fc3.bias' type=dtype('float32') shape=(10,)
    init: name='torch_nn_modules_linear_Linear_fc3_1_13_t_2' type=dtype('float32') shape=(128, 10)
    init: name='ortshared_7_1_2_0_token_8' type=dtype('int64') shape=(2,) -- array([ 1, 16])
    init: name='torch_nn_modules_linear_Linear_fc1_1_9_t' type=dtype('float32') shape=(16, 512)
    init: name='torch_nn_modules_linear_Linear_fc2_1_11_t_1' type=dtype('float32') shape=(512, 128)
    Conv[com.microsoft.nchwc](l_x_, reorder, conv1.bias, activation=b'Relu', dilations=[1,1], group=1, strides=[1,1], pads=[0,0,0,0], auto_pad=b'NOTSET') -> reorder_token_9
      ReorderOutput[com.microsoft.nchwc](reorder_token_9, channels_last=0, channels=16) -> relu
        MaxPool(relu, storage_order=0, auto_pad=b'NOTSET', ceil_mode=0, dilations=[1,1], kernel_shape=[2,2], pads=[0,0,0,0], strides=[2,2]) -> _aten_max_pool_with_indices_onnx_3_pool_result, _aten_max_pool_with_indices_onnx_3_indices
          ReorderInput[com.microsoft.nchwc](_aten_max_pool_with_indices_onnx_3_pool_result, channels_last=0) -> reorder_token_11
            Conv[com.microsoft.nchwc](reorder_token_11, reorder_token_10, conv2.bias, activation=b'Relu', dilations=[1,1], group=1, strides=[1,1], pads=[0,0,0,0], auto_pad=b'NOTSET') -> reorder_token_12
              ReorderOutput[com.microsoft.nchwc](reorder_token_12, channels_last=0, channels=16) -> relu_1
                MaxPool(relu_1, storage_order=0, auto_pad=b'NOTSET', ceil_mode=0, dilations=[1,1], kernel_shape=[2,2], pads=[0,0,0,0], strides=[2,2]) -> _aten_max_pool_with_indices_onnx_6_pool_result, _aten_max_pool_with_indices_onnx_6_indices
                  Reshape(_aten_max_pool_with_indices_onnx_6_pool_result, ortshared_7_1_2_0_token_8, allowzero=0) -> view
                    FusedGemm[com.microsoft](view, torch_nn_modules_linear_Linear_fc1_1_9_t, fc1.bias, activation=b'Relu', transB=0, transA=0, alpha=1.00, beta=1.00) -> relu_2
                      FusedGemm[com.microsoft](relu_2, torch_nn_modules_linear_Linear_fc2_1_11_t_1, fc2.bias, activation=b'Relu', transB=0, transA=0, alpha=1.00, beta=1.00) -> relu_3
                        Gemm(relu_3, torch_nn_modules_linear_Linear_fc3_1_13_t_2, fc3.bias, transB=0, transA=0, alpha=1.00, beta=1.00) -> fc3_1
    output: name='fc3_1' type=dtype('float32') shape=[1, 10]




.. GENERATED FROM PYTHON SOURCE LINES 799-801

dynamo
~~~~~~

.. GENERATED FROM PYTHON SOURCE LINES 801-807

.. code-block:: Python


    model = "ort-plot_torch_export_dynamo-cpu-aot1.onnx"
    if os.path.exists(model):
        print(onnx_simple_text_plot(onnx.load(model)))






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    opset: domain='pkg.onnxscript.torch_lib' version=1
    opset: domain='pkg.torch.2.3.0.dev20240209+cu118' version=1
    opset: domain='' version=18
    opset: domain='pkg.onnxscript.torch_lib.common' version=1
    opset: domain='ai.onnx.ml' version=4
    opset: domain='ai.onnx.training' version=1
    opset: domain='ai.onnx.preview.training' version=1
    opset: domain='com.microsoft' version=1
    opset: domain='com.microsoft.experimental' version=1
    opset: domain='com.microsoft.nchwc' version=1
    opset: domain='org.pytorch.aten' version=1
    input: name='l_x_' type=dtype('float32') shape=[1, 1, 16, 16]
    init: name='reorder' type=dtype('float32') shape=(16, 1, 5, 5)
    init: name='conv1.bias' type=dtype('float32') shape=(16,)
    init: name='reorder_token_71' type=dtype('float32') shape=(16, 16, 5, 5)
    init: name='conv2.bias' type=dtype('float32') shape=(16,)
    init: name='ortshared_7_1_2_3_token_69' type=dtype('int64') shape=(2,) -- array([0, 0])
    init: name='fc1.bias' type=dtype('float32') shape=(512,)
    init: name='_inlfunc_torch_nn_modules_linear_Linear_fc1_1_t' type=dtype('float32') shape=(16, 512)
    init: name='fc2.bias' type=dtype('float32') shape=(128,)
    init: name='ortshared_7_1_2_1_token_67' type=dtype('int64') shape=(2,) -- array([2, 3])
    init: name='fc3.bias' type=dtype('float32') shape=(10,)
    init: name='ortshared_7_1_2_2_token_68' type=dtype('int64') shape=(2,) -- array([ 1, 16])
    init: name='_inlfunc_torch_nn_modules_linear_Linear_fc3_1_t_2' type=dtype('float32') shape=(128, 10)
    init: name='ortshared_7_1_2_0_token_66' type=dtype('int64') shape=(2,) -- array([1, 1])
    init: name='_inlfunc_torch_nn_modules_linear_Linear_fc2_1_t_1' type=dtype('float32') shape=(512, 128)
    Conv[com.microsoft.nchwc](l_x_, reorder, conv1.bias, activation=b'Relu', dilations=[1,1], group=1, strides=[1,1], pads=[0,0,0,0], auto_pad=b'NOTSET') -> reorder_token_70
      ReorderOutput[com.microsoft.nchwc](reorder_token_70, channels_last=0, channels=16) -> relu
        MaxPool(relu, storage_order=0, auto_pad=b'NOTSET', ceil_mode=0, dilations=[1,1], kernel_shape=[2,2], pads=[0,0,0,0], strides=[2,2]) -> _inlfunc__aten_max_pool_with_indices_onnx_pool_result, _inlfunc__aten_max_pool_with_indices_onnx_indices
          ReorderInput[com.microsoft.nchwc](_inlfunc__aten_max_pool_with_indices_onnx_pool_result, channels_last=0) -> reorder_token_72
            Conv[com.microsoft.nchwc](reorder_token_72, reorder_token_71, conv2.bias, activation=b'Relu', dilations=[1,1], group=1, strides=[1,1], pads=[0,0,0,0], auto_pad=b'NOTSET') -> reorder_token_73
              ReorderOutput[com.microsoft.nchwc](reorder_token_73, channels_last=0, channels=16) -> relu_1
                MaxPool(relu_1, storage_order=0, auto_pad=b'NOTSET', ceil_mode=0, dilations=[1,1], kernel_shape=[2,2], pads=[0,0,0,0], strides=[2,2]) -> _inlfunc__aten_max_pool_with_indices_onnx_token_1_pool_result, _inlfunc__aten_max_pool_with_indices_onnx_token_1_indices
                  Reshape(_inlfunc__aten_max_pool_with_indices_onnx_token_1_pool_result, ortshared_7_1_2_2_token_68, allowzero=0) -> view
                    FusedGemm[com.microsoft](view, _inlfunc_torch_nn_modules_linear_Linear_fc1_1_t, fc1.bias, activation=b'Relu', transB=0, transA=0, alpha=1.00, beta=1.00) -> relu_2
                      FusedGemm[com.microsoft](relu_2, _inlfunc_torch_nn_modules_linear_Linear_fc2_1_t_1, fc2.bias, activation=b'Relu', transB=0, transA=0, alpha=1.00, beta=1.00) -> relu_3
                        Gemm(relu_3, _inlfunc_torch_nn_modules_linear_Linear_fc3_1_t_2, fc3.bias, transB=0, transA=0, alpha=1.00, beta=1.00) -> fc3_1
                MaxPool(relu_1, auto_pad=b'NOTSET', dilations=[1,1], ceil_mode=0, kernel_shape=[1,1], storage_order=0, strides=[1,1]) -> _inlfunc__aten_max_pool_with_indices_onnx_token_1__, _inlfunc__aten_max_pool_with_indices_onnx_token_1_flatten_indices
                  Slice(_inlfunc__aten_max_pool_with_indices_onnx_token_1_flatten_indices, ortshared_7_1_2_3_token_69, ortshared_7_1_2_0_token_66, ortshared_7_1_2_1_token_67) -> _inlfunc__aten_max_pool_with_indices_onnx_token_1_delta
                  Sub(_inlfunc__aten_max_pool_with_indices_onnx_token_1_indices, _inlfunc__aten_max_pool_with_indices_onnx_token_1_delta) -> _inlfunc__aten_max_pool_with_indices_onnx_token_1_indices_3
        MaxPool(relu, auto_pad=b'NOTSET', dilations=[1,1], ceil_mode=0, kernel_shape=[1,1], storage_order=0, strides=[1,1]) -> _inlfunc__aten_max_pool_with_indices_onnx__, _inlfunc__aten_max_pool_with_indices_onnx_flatten_indices
          Slice(_inlfunc__aten_max_pool_with_indices_onnx_flatten_indices, ortshared_7_1_2_3_token_69, ortshared_7_1_2_0_token_66, ortshared_7_1_2_1_token_67) -> _inlfunc__aten_max_pool_with_indices_onnx_delta
          Sub(_inlfunc__aten_max_pool_with_indices_onnx_indices, _inlfunc__aten_max_pool_with_indices_onnx_delta) -> _inlfunc__aten_max_pool_with_indices_onnx_indices_3
    output: name='fc3_1' type=dtype('float32') shape=[1, 10]




.. GENERATED FROM PYTHON SOURCE LINES 808-813

Show the interesting models for CUDA
++++++++++++++++++++++++++++++++++++

script
~~~~~~

.. GENERATED FROM PYTHON SOURCE LINES 813-818

.. code-block:: Python


    model = "ort-plot_torch_export_cus_p2-cuda-aot0.onnx"
    if os.path.exists(model):
        print(onnx_simple_text_plot(onnx.load(model)))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    opset: domain='' version=18
    opset: domain='ai.onnx.ml' version=4
    opset: domain='ai.onnx.training' version=1
    opset: domain='ai.onnx.preview.training' version=1
    opset: domain='com.microsoft' version=1
    opset: domain='com.microsoft.experimental' version=1
    opset: domain='com.microsoft.nchwc' version=1
    opset: domain='org.pytorch.aten' version=1
    input: name='input' type=dtype('float32') shape=[1, 1, 16, 16]
    init: name='arg0_1' type=dtype('float32') shape=(16, 1, 5, 5)
    init: name='arg1_1' type=dtype('float32') shape=(16,)
    init: name='arg2_1' type=dtype('float32') shape=(16, 16, 5, 5)
    init: name='arg3_1' type=dtype('float32') shape=(16,)
    init: name='arg5_1' type=dtype('float32') shape=(512,)
    init: name='arg7_1' type=dtype('float32') shape=(128,)
    init: name='arg9_1' type=dtype('float32') shape=(10,)
    init: name='ortshared_7_1_2_0_token_8' type=dtype('int64') shape=(2,) -- array([ 1, 16])
    init: name='t' type=dtype('float32') shape=(16, 512)
    init: name='t_1' type=dtype('float32') shape=(512, 128)
    init: name='t_2' type=dtype('float32') shape=(128, 10)
    FusedConv[com.microsoft](input, arg0_1, arg1_1, activation=b'Relu', dilations=[1,1], group=1, strides=[1,1], pads=[0,0,0,0], auto_pad=b'NOTSET') -> relu
      MaxPool(relu, storage_order=0, auto_pad=b'NOTSET', ceil_mode=0, dilations=[1,1], kernel_shape=[2,2], pads=[0,0,0,0], strides=[2,2]) -> _onx_maxpool0, _onx_maxpool1
        FusedConv[com.microsoft](_onx_maxpool0, arg2_1, arg3_1, activation=b'Relu', dilations=[1,1], group=1, strides=[1,1], pads=[0,0,0,0], auto_pad=b'NOTSET') -> relu_1
          MaxPool(relu_1, storage_order=0, auto_pad=b'NOTSET', ceil_mode=0, dilations=[1,1], kernel_shape=[2,2], pads=[0,0,0,0], strides=[2,2]) -> _onx_maxpool03, _onx_maxpool13
            Reshape(_onx_maxpool03, ortshared_7_1_2_0_token_8, allowzero=0) -> view
              Gemm(view, t, arg5_1, transB=0, transA=0, alpha=1.00, beta=1.00) -> addmm
                Relu(addmm) -> relu_2
                  Gemm(relu_2, t_1, arg7_1, transB=0, transA=0, alpha=1.00, beta=1.00) -> addmm_1
                    Relu(addmm_1) -> relu_3
                      Gemm(relu_3, t_2, arg9_1, transB=0, transA=0, alpha=1.00, beta=1.00) -> output_0
    output: name='output_0' type=dtype('float32') shape=[1, 10]




.. GENERATED FROM PYTHON SOURCE LINES 819-821

cus_p2
~~~~~~

.. GENERATED FROM PYTHON SOURCE LINES 821-826

.. code-block:: Python


    model = "ort-plot_torch_export_cus_p2-cuda-aot0.onnx"
    if os.path.exists(model):
        print(onnx_simple_text_plot(onnx.load(model)))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    opset: domain='' version=18
    opset: domain='ai.onnx.ml' version=4
    opset: domain='ai.onnx.training' version=1
    opset: domain='ai.onnx.preview.training' version=1
    opset: domain='com.microsoft' version=1
    opset: domain='com.microsoft.experimental' version=1
    opset: domain='com.microsoft.nchwc' version=1
    opset: domain='org.pytorch.aten' version=1
    input: name='input' type=dtype('float32') shape=[1, 1, 16, 16]
    init: name='arg0_1' type=dtype('float32') shape=(16, 1, 5, 5)
    init: name='arg1_1' type=dtype('float32') shape=(16,)
    init: name='arg2_1' type=dtype('float32') shape=(16, 16, 5, 5)
    init: name='arg3_1' type=dtype('float32') shape=(16,)
    init: name='arg5_1' type=dtype('float32') shape=(512,)
    init: name='arg7_1' type=dtype('float32') shape=(128,)
    init: name='arg9_1' type=dtype('float32') shape=(10,)
    init: name='ortshared_7_1_2_0_token_8' type=dtype('int64') shape=(2,) -- array([ 1, 16])
    init: name='t' type=dtype('float32') shape=(16, 512)
    init: name='t_1' type=dtype('float32') shape=(512, 128)
    init: name='t_2' type=dtype('float32') shape=(128, 10)
    FusedConv[com.microsoft](input, arg0_1, arg1_1, activation=b'Relu', dilations=[1,1], group=1, strides=[1,1], pads=[0,0,0,0], auto_pad=b'NOTSET') -> relu
      MaxPool(relu, storage_order=0, auto_pad=b'NOTSET', ceil_mode=0, dilations=[1,1], kernel_shape=[2,2], pads=[0,0,0,0], strides=[2,2]) -> _onx_maxpool0, _onx_maxpool1
        FusedConv[com.microsoft](_onx_maxpool0, arg2_1, arg3_1, activation=b'Relu', dilations=[1,1], group=1, strides=[1,1], pads=[0,0,0,0], auto_pad=b'NOTSET') -> relu_1
          MaxPool(relu_1, storage_order=0, auto_pad=b'NOTSET', ceil_mode=0, dilations=[1,1], kernel_shape=[2,2], pads=[0,0,0,0], strides=[2,2]) -> _onx_maxpool03, _onx_maxpool13
            Reshape(_onx_maxpool03, ortshared_7_1_2_0_token_8, allowzero=0) -> view
              Gemm(view, t, arg5_1, transB=0, transA=0, alpha=1.00, beta=1.00) -> addmm
                Relu(addmm) -> relu_2
                  Gemm(relu_2, t_1, arg7_1, transB=0, transA=0, alpha=1.00, beta=1.00) -> addmm_1
                    Relu(addmm_1) -> relu_3
                      Gemm(relu_3, t_2, arg9_1, transB=0, transA=0, alpha=1.00, beta=1.00) -> output_0
    output: name='output_0' type=dtype('float32') shape=[1, 10]




.. GENERATED FROM PYTHON SOURCE LINES 827-829

dynopt
~~~~~~

.. GENERATED FROM PYTHON SOURCE LINES 829-834

.. code-block:: Python


    model = "ort-plot_torch_export_dynopt-cuda-aot1.onnx"
    if os.path.exists(model):
        print(onnx_simple_text_plot(onnx.load(model)))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    opset: domain='pkg.onnxscript.torch_lib' version=1
    opset: domain='pkg.torch.2.3.0.dev20240209+cu118' version=1
    opset: domain='' version=18
    opset: domain='pkg.onnxscript.torch_lib.common' version=1
    opset: domain='ai.onnx.ml' version=4
    opset: domain='ai.onnx.training' version=1
    opset: domain='ai.onnx.preview.training' version=1
    opset: domain='com.microsoft' version=1
    opset: domain='com.microsoft.experimental' version=1
    opset: domain='com.microsoft.nchwc' version=1
    opset: domain='org.pytorch.aten' version=1
    input: name='l_x_' type=dtype('float32') shape=[1, 1, 16, 16]
    init: name='conv1.weight' type=dtype('float32') shape=(16, 1, 5, 5)
    init: name='conv1.bias' type=dtype('float32') shape=(16,)
    init: name='conv2.weight' type=dtype('float32') shape=(16, 16, 5, 5)
    init: name='conv2.bias' type=dtype('float32') shape=(16,)
    init: name='fc1.bias' type=dtype('float32') shape=(512,)
    init: name='fc2.bias' type=dtype('float32') shape=(128,)
    init: name='fc3.bias' type=dtype('float32') shape=(10,)
    init: name='torch_nn_modules_linear_Linear_fc3_1_13_t_2' type=dtype('float32') shape=(128, 10)
    init: name='ortshared_7_1_2_0_token_8' type=dtype('int64') shape=(2,) -- array([ 1, 16])
    init: name='torch_nn_modules_linear_Linear_fc1_1_9_t' type=dtype('float32') shape=(16, 512)
    init: name='torch_nn_modules_linear_Linear_fc2_1_11_t_1' type=dtype('float32') shape=(512, 128)
    FusedConv[com.microsoft](l_x_, conv1.weight, conv1.bias, activation=b'Relu', dilations=[1,1], group=1, strides=[1,1], pads=[0,0,0,0], auto_pad=b'NOTSET') -> relu
      MaxPool(relu, storage_order=0, auto_pad=b'NOTSET', ceil_mode=0, dilations=[1,1], kernel_shape=[2,2], pads=[0,0,0,0], strides=[2,2]) -> _aten_max_pool_with_indices_onnx_3_pool_result, _aten_max_pool_with_indices_onnx_3_indices
        FusedConv[com.microsoft](_aten_max_pool_with_indices_onnx_3_pool_result, conv2.weight, conv2.bias, activation=b'Relu', dilations=[1,1], group=1, strides=[1,1], pads=[0,0,0,0], auto_pad=b'NOTSET') -> relu_1
          MaxPool(relu_1, storage_order=0, auto_pad=b'NOTSET', ceil_mode=0, dilations=[1,1], kernel_shape=[2,2], pads=[0,0,0,0], strides=[2,2]) -> _aten_max_pool_with_indices_onnx_6_pool_result, _aten_max_pool_with_indices_onnx_6_indices
            Reshape(_aten_max_pool_with_indices_onnx_6_pool_result, ortshared_7_1_2_0_token_8, allowzero=0) -> view
              Gemm(view, torch_nn_modules_linear_Linear_fc1_1_9_t, fc1.bias, transB=0, transA=0, alpha=1.00, beta=1.00) -> fc1_1
                Relu(fc1_1) -> relu_2
                  Gemm(relu_2, torch_nn_modules_linear_Linear_fc2_1_11_t_1, fc2.bias, transB=0, transA=0, alpha=1.00, beta=1.00) -> fc2_1
                    Relu(fc2_1) -> relu_3
                      Gemm(relu_3, torch_nn_modules_linear_Linear_fc3_1_13_t_2, fc3.bias, transB=0, transA=0, alpha=1.00, beta=1.00) -> fc3_1
    output: name='fc3_1' type=dtype('float32') shape=[1, 10]




.. GENERATED FROM PYTHON SOURCE LINES 835-837

dynamo
~~~~~~

.. GENERATED FROM PYTHON SOURCE LINES 837-841

.. code-block:: Python


    model = "ort-plot_torch_export_dynamo-cuda-aot1.onnx"
    if os.path.exists(model):
        print(onnx_simple_text_plot(onnx.load(model)))




.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    opset: domain='pkg.onnxscript.torch_lib' version=1
    opset: domain='pkg.torch.2.3.0.dev20240209+cu118' version=1
    opset: domain='' version=18
    opset: domain='pkg.onnxscript.torch_lib.common' version=1
    opset: domain='ai.onnx.ml' version=4
    opset: domain='ai.onnx.training' version=1
    opset: domain='ai.onnx.preview.training' version=1
    opset: domain='com.microsoft' version=1
    opset: domain='com.microsoft.experimental' version=1
    opset: domain='com.microsoft.nchwc' version=1
    opset: domain='org.pytorch.aten' version=1
    input: name='l_x_' type=dtype('float32') shape=[1, 1, 16, 16]
    init: name='conv1.weight' type=dtype('float32') shape=(16, 1, 5, 5)
    init: name='conv1.bias' type=dtype('float32') shape=(16,)
    init: name='conv2.weight' type=dtype('float32') shape=(16, 16, 5, 5)
    init: name='conv2.bias' type=dtype('float32') shape=(16,)
    init: name='ortshared_7_1_2_3_token_69' type=dtype('int64') shape=(2,) -- array([0, 0])
    init: name='fc1.bias' type=dtype('float32') shape=(512,)
    init: name='_inlfunc_torch_nn_modules_linear_Linear_fc1_1_t' type=dtype('float32') shape=(16, 512)
    init: name='fc2.bias' type=dtype('float32') shape=(128,)
    init: name='ortshared_7_1_2_1_token_67' type=dtype('int64') shape=(2,) -- array([2, 3])
    init: name='fc3.bias' type=dtype('float32') shape=(10,)
    init: name='ortshared_7_1_2_2_token_68' type=dtype('int64') shape=(2,) -- array([ 1, 16])
    init: name='_inlfunc_torch_nn_modules_linear_Linear_fc3_1_t_2' type=dtype('float32') shape=(128, 10)
    init: name='ortshared_7_1_2_0_token_66' type=dtype('int64') shape=(2,) -- array([1, 1])
    init: name='_inlfunc_torch_nn_modules_linear_Linear_fc2_1_t_1' type=dtype('float32') shape=(512, 128)
    FusedConv[com.microsoft](l_x_, conv1.weight, conv1.bias, activation=b'Relu', dilations=[1,1], group=1, strides=[1,1], pads=[0,0,0,0], auto_pad=b'NOTSET') -> relu
      MaxPool(relu, storage_order=0, auto_pad=b'NOTSET', ceil_mode=0, dilations=[1,1], kernel_shape=[2,2], pads=[0,0,0,0], strides=[2,2]) -> _inlfunc__aten_max_pool_with_indices_onnx_pool_result, _inlfunc__aten_max_pool_with_indices_onnx_indices
        FusedConv[com.microsoft](_inlfunc__aten_max_pool_with_indices_onnx_pool_result, conv2.weight, conv2.bias, activation=b'Relu', dilations=[1,1], group=1, strides=[1,1], pads=[0,0,0,0], auto_pad=b'NOTSET') -> relu_1
          MaxPool(relu_1, storage_order=0, auto_pad=b'NOTSET', ceil_mode=0, dilations=[1,1], kernel_shape=[2,2], pads=[0,0,0,0], strides=[2,2]) -> _inlfunc__aten_max_pool_with_indices_onnx_token_1_pool_result, _inlfunc__aten_max_pool_with_indices_onnx_token_1_indices
            Reshape(_inlfunc__aten_max_pool_with_indices_onnx_token_1_pool_result, ortshared_7_1_2_2_token_68, allowzero=0) -> view
              Gemm(view, _inlfunc_torch_nn_modules_linear_Linear_fc1_1_t, fc1.bias, transB=0, transA=0, alpha=1.00, beta=1.00) -> fc1_1
                Relu(fc1_1) -> relu_2
                  Gemm(relu_2, _inlfunc_torch_nn_modules_linear_Linear_fc2_1_t_1, fc2.bias, transB=0, transA=0, alpha=1.00, beta=1.00) -> fc2_1
                    Relu(fc2_1) -> relu_3
                      Gemm(relu_3, _inlfunc_torch_nn_modules_linear_Linear_fc3_1_t_2, fc3.bias, transB=0, transA=0, alpha=1.00, beta=1.00) -> fc3_1
          MaxPool(relu_1, auto_pad=b'NOTSET', dilations=[1,1], ceil_mode=0, kernel_shape=[1,1], storage_order=0, strides=[1,1]) -> _inlfunc__aten_max_pool_with_indices_onnx_token_1__, _inlfunc__aten_max_pool_with_indices_onnx_token_1_flatten_indices
            Slice(_inlfunc__aten_max_pool_with_indices_onnx_token_1_flatten_indices, ortshared_7_1_2_3_token_69, ortshared_7_1_2_0_token_66, ortshared_7_1_2_1_token_67) -> _inlfunc__aten_max_pool_with_indices_onnx_token_1_delta
            Sub(_inlfunc__aten_max_pool_with_indices_onnx_token_1_indices, _inlfunc__aten_max_pool_with_indices_onnx_token_1_delta) -> _inlfunc__aten_max_pool_with_indices_onnx_token_1_indices_3
      MaxPool(relu, auto_pad=b'NOTSET', dilations=[1,1], ceil_mode=0, kernel_shape=[1,1], storage_order=0, strides=[1,1]) -> _inlfunc__aten_max_pool_with_indices_onnx__, _inlfunc__aten_max_pool_with_indices_onnx_flatten_indices
        Slice(_inlfunc__aten_max_pool_with_indices_onnx_flatten_indices, ortshared_7_1_2_3_token_69, ortshared_7_1_2_0_token_66, ortshared_7_1_2_1_token_67) -> _inlfunc__aten_max_pool_with_indices_onnx_delta
        Sub(_inlfunc__aten_max_pool_with_indices_onnx_indices, _inlfunc__aten_max_pool_with_indices_onnx_delta) -> _inlfunc__aten_max_pool_with_indices_onnx_indices_3
    output: name='fc3_1' type=dtype('float32') shape=[1, 10]





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (1 minutes 54.892 seconds)


.. _sphx_glr_download_auto_examples_plot_torch_export.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_torch_export.ipynb <plot_torch_export.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_torch_export.py <plot_torch_export.py>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
