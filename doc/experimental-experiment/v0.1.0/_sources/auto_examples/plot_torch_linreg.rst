
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_torch_linreg.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_plot_torch_linreg.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_torch_linreg.py:


=================
Linear Regression
=================

:epkg:`scikit-learn` and :epkg:`torch` to train a linear regression.

data
====

.. GENERATED FROM PYTHON SOURCE LINES 11-23

.. code-block:: Python


    from sklearn.datasets import make_regression
    from sklearn.linear_model import LinearRegression, SGDRegressor
    from sklearn.metrics import mean_squared_error, r2_score
    from sklearn.model_selection import train_test_split
    import torch

    X, y = make_regression(1000, n_features=5, noise=10.0, n_informative=2)
    print(X.shape, y.shape)

    X_train, X_test, y_train, y_test = train_test_split(X, y)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    (1000, 5) (1000,)




.. GENERATED FROM PYTHON SOURCE LINES 24-30

scikit-learn: the simple regression
===================================

.. math::

      A^* = (X'X)^{-1}X'Y

.. GENERATED FROM PYTHON SOURCE LINES 30-37

.. code-block:: Python



    clr = LinearRegression()
    clr.fit(X_train, y_train)

    print(f"coefficients: {clr.coef_}, {clr.intercept_}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    coefficients: [ 0.16862047  0.27719019  0.25621964  8.81117422 52.49860566], -0.31509127574197215




.. GENERATED FROM PYTHON SOURCE LINES 38-40

Evaluation
==========

.. GENERATED FROM PYTHON SOURCE LINES 40-46

.. code-block:: Python


    y_pred = clr.predict(X_test)
    l2 = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    print(f"LinearRegression: l2={l2}, r2={r2}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    LinearRegression: l2=110.26346117873129, r2=0.9634330427887183




.. GENERATED FROM PYTHON SOURCE LINES 47-51

scikit-learn: SGD algorithm
===================================

SGD = Stochastic Gradient Descent

.. GENERATED FROM PYTHON SOURCE LINES 51-57

.. code-block:: Python


    clr = SGDRegressor(max_iter=5, verbose=1)
    clr.fit(X_train, y_train)

    print(f"coefficients: {clr.coef_}, {clr.intercept_}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    -- Epoch 1
    Norm: 44.95, NNZs: 5, Bias: -0.358127, T: 750, Avg. loss: 320.771073
    Total training time: 0.00 seconds.
    -- Epoch 2
    Norm: 50.73, NNZs: 5, Bias: -0.435342, T: 1500, Avg. loss: 64.636716
    Total training time: 0.00 seconds.
    -- Epoch 3
    Norm: 52.36, NNZs: 5, Bias: -0.423154, T: 2250, Avg. loss: 53.754539
    Total training time: 0.00 seconds.
    -- Epoch 4
    Norm: 52.86, NNZs: 5, Bias: -0.363326, T: 3000, Avg. loss: 52.624321
    Total training time: 0.00 seconds.
    -- Epoch 5
    Norm: 53.09, NNZs: 5, Bias: -0.358911, T: 3750, Avg. loss: 52.454007
    Total training time: 0.00 seconds.
    /home/xadupre/install/scikit-learn/sklearn/linear_model/_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
      warnings.warn(
    coefficients: [ 0.15517763  0.3750597   0.31082611  8.85499387 52.33987051], [-0.35891068]




.. GENERATED FROM PYTHON SOURCE LINES 58-59

Evaluation

.. GENERATED FROM PYTHON SOURCE LINES 59-67

.. code-block:: Python


    y_pred = clr.predict(X_test)
    sl2 = mean_squared_error(y_test, y_pred)
    sr2 = r2_score(y_test, y_pred)
    print(f"SGDRegressor: sl2={sl2}, sr2={sr2}")







.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    SGDRegressor: sl2=110.68165371581833, sr2=0.9632943565145322




.. GENERATED FROM PYTHON SOURCE LINES 68-70

torch
=====

.. GENERATED FROM PYTHON SOURCE LINES 70-119

.. code-block:: Python



    class TorchLinearRegression(torch.nn.Module):
        def __init__(self, n_dims: int, n_targets: int):
            super(TorchLinearRegression, self).__init__()
            self.linear = torch.nn.Linear(n_dims, n_targets)

        def forward(self, x):
            return self.linear(x)


    def train_loop(dataloader, model, loss_fn, optimizer):
        total_loss = 0.0

        # Set the model to training mode - important for batch normalization and dropout layers
        # Unnecessary in this situation but added for best practices
        model.train()
        for batch, (X, y) in enumerate(dataloader):
            # Compute prediction and loss
            pred = model(X)
            loss = loss_fn(pred.ravel(), y)

            # Backpropagation
            loss.backward()
            optimizer.step()
            optimizer.zero_grad()

            # training loss
            total_loss += loss

        return total_loss


    model = TorchLinearRegression(X_train.shape[1], 1)
    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)
    loss_fn = torch.nn.MSELoss()

    device = "cpu"
    model = model.to(device)
    dataset = torch.utils.data.TensorDataset(
        torch.Tensor(X_train).to(device), torch.Tensor(y_train).to(device)
    )
    dataloader = torch.utils.data.DataLoader(dataset, batch_size=1)


    for i in range(5):
        loss = train_loop(dataloader, model, loss_fn, optimizer)
        print(f"iteration {i}, loss={loss}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /home/xadupre/.local/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
      _torch_pytree._register_pytree_node(
    [2024-01-26 00:12:27,274] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
    /home/xadupre/.local/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
      _torch_pytree._register_pytree_node(
    iteration 0, loss=742280.4375
    iteration 1, loss=116097.8203125
    iteration 2, loss=80855.5625
    iteration 3, loss=78952.6484375
    iteration 4, loss=78879.921875




.. GENERATED FROM PYTHON SOURCE LINES 120-121

Let's check the error

.. GENERATED FROM PYTHON SOURCE LINES 121-127

.. code-block:: Python


    y_pred = model(torch.Tensor(X_test)).detach().numpy()
    tl2 = mean_squared_error(y_test, y_pred)
    tr2 = r2_score(y_test, y_pred)
    print(f"TorchLinearRegression: tl2={tl2}, tr2={tr2}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    TorchLinearRegression: tl2=110.64094822810304, tr2=0.9633078557808498




.. GENERATED FROM PYTHON SOURCE LINES 128-129

And the coefficients.

.. GENERATED FROM PYTHON SOURCE LINES 129-133

.. code-block:: Python


    print("coefficients:")
    for p in model.parameters():
        print(p)




.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    coefficients:
    Parameter containing:
    tensor([[ 0.3342,  0.3307,  0.4485,  8.7304, 52.6217]], requires_grad=True)
    Parameter containing:
    tensor([-0.2749], requires_grad=True)





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 13.611 seconds)


.. _sphx_glr_download_auto_examples_plot_torch_linreg.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_torch_linreg.ipynb <plot_torch_linreg.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_torch_linreg.py <plot_torch_linreg.py>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
