
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_recipes/plot_exporter_recipes_oe_cond.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_recipes_plot_exporter_recipes_oe_cond.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_recipes_plot_exporter_recipes_oe_cond.py:


.. _l-plot-exporter-recipes-onnx-exporter-cond:

torch.onnx.export and a model with a test
=========================================

Tests cannot be exported into ONNX unless they refactored
to use :func:`torch.cond`.

A model with a test
+++++++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 13-18

.. code-block:: Python


    from onnx.printer import to_text
    import torch









.. GENERATED FROM PYTHON SOURCE LINES 19-20

We define a model with a control flow (-> graph break)

.. GENERATED FROM PYTHON SOURCE LINES 20-45

.. code-block:: Python



    class ForwardWithControlFlowTest(torch.nn.Module):
        def forward(self, x):
            if x.sum():
                return x * 2
            return -x


    class ModelWithControlFlowTest(torch.nn.Module):
        def __init__(self):
            super().__init__()
            self.mlp = torch.nn.Sequential(
                torch.nn.Linear(3, 2),
                torch.nn.Linear(2, 1),
                ForwardWithControlFlowTest(),
            )

        def forward(self, x):
            out = self.mlp(x)
            return out


    model = ModelWithControlFlowTest()








.. GENERATED FROM PYTHON SOURCE LINES 46-47

Let's check it runs.

.. GENERATED FROM PYTHON SOURCE LINES 47-50

.. code-block:: Python

    x = torch.randn(3)
    model(x)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    tensor([0.3413], grad_fn=<MulBackward0>)



.. GENERATED FROM PYTHON SOURCE LINES 51-52

As expected, it does not export.

.. GENERATED FROM PYTHON SOURCE LINES 52-58

.. code-block:: Python

    try:
        torch.export.export(model, (x,))
        raise AssertionError("This export should failed unless pytorch now supports this model.")
    except Exception as e:
        print(e)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Dynamic control flow is not supported at the moment. Please use torch.cond to explicitly capture the control flow. For more information about this error, see: https://pytorch.org/docs/main/generated/exportdb/index.html#cond-operands

    from user code:
       File "/home/xadupre/github/experimental-experiment/_doc/recipes/plot_exporter_recipes_oe_cond.py", line 39, in forward
        out = self.mlp(x)
      File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1760, in _call_impl
        return forward_call(*args, **kwargs)
      File "/home/xadupre/github/experimental-experiment/_doc/recipes/plot_exporter_recipes_oe_cond.py", line 24, in forward
        if x.sum():

    Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information





.. GENERATED FROM PYTHON SOURCE LINES 59-62

It does export with :func:`torch.onnx.export` because
it uses JIT to trace the execution.
But the model is not exactly the same as the initial model.

.. GENERATED FROM PYTHON SOURCE LINES 62-66

.. code-block:: Python

    ep = torch.onnx.export(model, (x,), dynamo=True)
    print(to_text(ep.model_proto))






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [torch.onnx] Obtain model graph for `ModelWithControlFlowTest([...]` with `torch.export.export(..., strict=False)`...
    [torch.onnx] Obtain model graph for `ModelWithControlFlowTest([...]` with `torch.export.export(..., strict=False)`... ❌
    [torch.onnx] Obtain model graph for `ModelWithControlFlowTest([...]` with `torch.export.export`...
    [torch.onnx] Obtain model graph for `ModelWithControlFlowTest([...]` with `torch.export.export`... ❌
    [torch.onnx] Obtain model graph for `ModelWithControlFlowTest([...]` with Torch Script...
    /home/xadupre/github/experimental-experiment/_doc/recipes/plot_exporter_recipes_oe_cond.py:24: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
      if x.sum():
    [torch.onnx] Obtain model graph for `ModelWithControlFlowTest([...]` with Torch Script... ✅
    [torch.onnx] Run decomposition...
    /home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_unlift.py:81: UserWarning: Attempted to insert a get_attr Node with no underlying reference in the owning GraphModule! Call GraphModule.add_submodule to add the necessary submodule, GraphModule.add_parameter to add the necessary Parameter, or nn.Module.register_buffer to add the necessary buffer
      getattr_node = gm.graph.get_attr(lifted_node)
    /home/xadupre/vv/this312/lib/python3.12/site-packages/torch/fx/graph.py:1790: UserWarning: Node lifted_tensor_6 target lifted_tensor_6 lifted_tensor_6 of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target
      warnings.warn(
    [torch.onnx] Run decomposition... ✅
    [torch.onnx] Translate the graph into ONNX...
    [torch.onnx] Translate the graph into ONNX... ✅
    <
       ir_version: 10,
       opset_import: ["pkg.onnxscript.torch_lib.common" : 1, "" : 18],
       producer_name: "pytorch",
       producer_version: "2.7.0.dev20250130+cu126"
    >
    main_graph (float[3] input_1) => (float[1] mul) 
       <float[2] "model.mlp.0.bias" =  {-0.221143,-0.247102}, float[2,3] "model.mlp.0.weight" =  {0.231354,-0.255796,0.0359441,0.298362,-0.0870362,0.161169}, float[1] "model.mlp.1.bias" =  {0.214936}, float[1,2] "model.mlp.1.weight" =  {-0.452569,0.453443}, float[2] linear, float[1] linear_1, float scalar_tensor_default>
    {
       [node_Transpose_0] val_0 = Transpose <perm: ints = [1, 0]> ("model.mlp.0.weight")
       [node_MatMul_1] val_1 = MatMul (input_1, val_0)
       [node_Add_2] linear = Add (val_1, "model.mlp.0.bias")
       [node_Transpose_3] val_2 = Transpose <perm: ints = [1, 0]> ("model.mlp.1.weight")
       [node_MatMul_4] val_3 = MatMul (linear, val_2)
       [node_Add_5] linear_1 = Add (val_3, "model.mlp.1.bias")
       [node_Constant_6] val_4 = Constant <value: tensor = int64 {2}> ()
       [node_Cast_7] scalar_tensor_default = Cast <to: int = 1> (val_4)
       [node_Mul_8] mul = Mul (linear_1, scalar_tensor_default)
    }
    <
      domain: "pkg.onnxscript.torch_lib.common",
      opset_import: ["" : 18]
    >
    Rank (input) => (return_val)
    {
       [n0] tmp = Shape (input)
       [n1] return_val = Size (tmp)
    }
    <
      domain: "pkg.onnxscript.torch_lib.common",
      opset_import: ["" : 18]
    >
    IsScalar (input) => (return_val)
    {
       [n0] tmp = Shape (input)
       [n1] tmp_0 = Size (tmp)
       [n2] tmp_1 = Constant <value_int: int = 0> ()
       [n3] return_val = Equal (tmp_0, tmp_1)
    }




.. GENERATED FROM PYTHON SOURCE LINES 67-71

Suggested Patch
+++++++++++++++

Let's avoid the graph break by replacing the forward.

.. GENERATED FROM PYTHON SOURCE LINES 71-89

.. code-block:: Python



    def new_forward(x):
        def identity2(x):
            return x * 2

        def neg(x):
            return -x

        return torch.cond(x.sum() > 0, identity2, neg, (x,))


    print("the list of submodules")
    for name, mod in model.named_modules():
        print(name, type(mod))
        if isinstance(mod, ForwardWithControlFlowTest):
            mod.forward = new_forward





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    the list of submodules
     <class '__main__.ModelWithControlFlowTest'>
    mlp <class 'torch.nn.modules.container.Sequential'>
    mlp.0 <class 'torch.nn.modules.linear.Linear'>
    mlp.1 <class 'torch.nn.modules.linear.Linear'>
    mlp.2 <class '__main__.ForwardWithControlFlowTest'>




.. GENERATED FROM PYTHON SOURCE LINES 90-91

Let's see what the fx graph looks like.

.. GENERATED FROM PYTHON SOURCE LINES 91-94

.. code-block:: Python


    print(torch.export.export(model, (x,)).graph)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    graph():
        %p_mlp_0_weight : [num_users=1] = placeholder[target=p_mlp_0_weight]
        %p_mlp_0_bias : [num_users=1] = placeholder[target=p_mlp_0_bias]
        %p_mlp_1_weight : [num_users=1] = placeholder[target=p_mlp_1_weight]
        %p_mlp_1_bias : [num_users=1] = placeholder[target=p_mlp_1_bias]
        %x : [num_users=1] = placeholder[target=x]
        %linear : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%x, %p_mlp_0_weight, %p_mlp_0_bias), kwargs = {})
        %linear_1 : [num_users=2] = call_function[target=torch.ops.aten.linear.default](args = (%linear, %p_mlp_1_weight, %p_mlp_1_bias), kwargs = {})
        %sum_1 : [num_users=1] = call_function[target=torch.ops.aten.sum.default](args = (%linear_1,), kwargs = {})
        %gt : [num_users=1] = call_function[target=torch.ops.aten.gt.Scalar](args = (%sum_1, 0), kwargs = {})
        %true_graph_0 : [num_users=1] = get_attr[target=true_graph_0]
        %false_graph_0 : [num_users=1] = get_attr[target=false_graph_0]
        %cond : [num_users=1] = call_function[target=torch.ops.higher_order.cond](args = (%gt, %true_graph_0, %false_graph_0, [%linear_1]), kwargs = {})
        %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%cond, 0), kwargs = {})
        return (getitem,)




.. GENERATED FROM PYTHON SOURCE LINES 95-96

Let's export again.

.. GENERATED FROM PYTHON SOURCE LINES 96-101

.. code-block:: Python


    ep = torch.onnx.export(model, (x,), dynamo=True)
    print(to_text(ep.model_proto))






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [torch.onnx] Obtain model graph for `ModelWithControlFlowTest([...]` with `torch.export.export(..., strict=False)`...
    [torch.onnx] Obtain model graph for `ModelWithControlFlowTest([...]` with `torch.export.export(..., strict=False)`... ✅
    [torch.onnx] Run decomposition...
    [torch.onnx] Run decomposition... ✅
    [torch.onnx] Translate the graph into ONNX...
    [torch.onnx] Translate the graph into ONNX... ✅
    <
       ir_version: 10,
       opset_import: ["pkg.onnxscript.torch_lib.common" : 1, "" : 18, "pkg.torch.__subgraph__" : 1],
       producer_name: "pytorch",
       producer_version: "2.7.0.dev20250130+cu126"
    >
    main_graph (float[3] x) => (float[1] getitem) 
       <float[2,3] "mlp.0.weight" =  {0.231354,-0.255796,0.0359441,0.298362,-0.0870362,0.161169}, float[2] "mlp.0.bias" =  {-0.221143,-0.247102}, float[1,2] "mlp.1.weight" =  {-0.452569,0.453443}, float[1] "mlp.1.bias" =  {0.214936}, float[2] linear, float[1] linear_1, float sum_1, float scalar_tensor_default, bool gt>
    {
       [node_Transpose_0] val_0 = Transpose <perm: ints = [1, 0]> ("mlp.0.weight")
       [node_MatMul_1] val_1 = MatMul (x, val_0)
       [node_Add_2] linear = Add (val_1, "mlp.0.bias")
       [node_Transpose_3] val_2 = Transpose <perm: ints = [1, 0]> ("mlp.1.weight")
       [node_MatMul_4] val_3 = MatMul (linear, val_2)
       [node_Add_5] linear_1 = Add (val_3, "mlp.1.bias")
       [node_ReduceSum_6] sum_1 = ReduceSum <noop_with_empty_axes: int = 0, keepdims: int = 0> (linear_1)
       [node_Constant_7] val_4 = Constant <value: tensor = int64 {0}> ()
       [node_Cast_8] scalar_tensor_default = Cast <to: int = 1> (val_4)
       [node_Greater_9] gt = Greater (sum_1, scalar_tensor_default)
       [node_If_10] getitem = If (gt) <then_branch: graph = true_graph_0 () => ( mul_true_graph_0) {
          [node_true_graph_0_0] mul_true_graph_0 = pkg.torch.__subgraph__.true_graph_0 (linear_1)
       }, else_branch: graph = false_graph_0 () => ( neg_false_graph_0) {
          [node_false_graph_0_0] neg_false_graph_0 = pkg.torch.__subgraph__.false_graph_0 (linear_1)
       }>
    }
    <
      domain: "pkg.torch.__subgraph__",
      opset_import: ["" : 18]
    >
    false_graph_0 (linear_1) => (neg)
    {
       [node_Neg_0] neg = Neg (linear_1)
    }
    <
      domain: "pkg.torch.__subgraph__",
      opset_import: ["" : 18]
    >
    true_graph_0 (linear_1) => (mul)
    {
       [node_Constant_0] val_0 = Constant <value: tensor = int64 {2}> ()
       [node_Cast_1] scalar_tensor_default = Cast <to: int = 1> (val_0)
       [node_Mul_2] mul = Mul (linear_1, scalar_tensor_default)
    }
    <
      domain: "pkg.onnxscript.torch_lib.common",
      opset_import: ["" : 18]
    >
    Rank (input) => (return_val)
    {
       [n0] tmp = Shape (input)
       [n1] return_val = Size (tmp)
    }
    <
      domain: "pkg.onnxscript.torch_lib.common",
      opset_import: ["" : 18]
    >
    IsScalar (input) => (return_val)
    {
       [n0] tmp = Shape (input)
       [n1] tmp_0 = Size (tmp)
       [n2] tmp_1 = Constant <value_int: int = 0> ()
       [n3] return_val = Equal (tmp_0, tmp_1)
    }




.. GENERATED FROM PYTHON SOURCE LINES 102-103

Let's optimize to see a small model.

.. GENERATED FROM PYTHON SOURCE LINES 103-107

.. code-block:: Python


    ep = torch.onnx.export(model, (x,), dynamo=True)
    ep.optimize()
    print(to_text(ep.model_proto))




.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [torch.onnx] Obtain model graph for `ModelWithControlFlowTest([...]` with `torch.export.export(..., strict=False)`...
    [torch.onnx] Obtain model graph for `ModelWithControlFlowTest([...]` with `torch.export.export(..., strict=False)`... ✅
    [torch.onnx] Run decomposition...
    [torch.onnx] Run decomposition... ✅
    [torch.onnx] Translate the graph into ONNX...
    [torch.onnx] Translate the graph into ONNX... ✅
    <
       ir_version: 10,
       opset_import: ["pkg.onnxscript.torch_lib.common" : 1, "" : 18, "pkg.torch.__subgraph__" : 1],
       producer_name: "pytorch",
       producer_version: "2.7.0.dev20250130+cu126"
    >
    main_graph (float[3] x) => (float[1] getitem) 
       <float[2] "mlp.0.bias" =  {-0.221143,-0.247102}, float[1] "mlp.1.bias" =  {0.214936}, float[3,2] val_0, float[2] val_1, float[2] linear, float[2,1] val_2, float[1] val_3, float[1] linear_1, float sum_1, float scalar_tensor_default, bool gt>
    {
       [node_Constant_11] val_0 = Constant <value: tensor = float[3,2] val_0 {0.231354,0.298362,-0.255796,-0.0870362,0.0359441,0.161169}> ()
       [node_MatMul_1] val_1 = MatMul (x, val_0)
       [node_Add_2] linear = Add (val_1, "mlp.0.bias")
       [node_Constant_12] val_2 = Constant <value: tensor = float[2,1] val_2 {-0.452569,0.453443}> ()
       [node_MatMul_4] val_3 = MatMul (linear, val_2)
       [node_Add_5] linear_1 = Add (val_3, "mlp.1.bias")
       [node_ReduceSum_6] sum_1 = ReduceSum <noop_with_empty_axes: int = 0, keepdims: int = 0> (linear_1)
       [node_Constant_13] scalar_tensor_default = Constant <value: tensor = float scalar_tensor_default {0}> ()
       [node_Greater_9] gt = Greater (sum_1, scalar_tensor_default)
       [node_If_10] getitem = If (gt) <then_branch: graph = true_graph_0 () => (float[1] mul_true_graph_0) 
          <float scalar_tensor_default_2>
    {
          [node_Constant_1] scalar_tensor_default_2 = Constant <value: tensor = float scalar_tensor_default_2 {2}> ()
          [node_Mul_2] mul_true_graph_0 = Mul (linear_1, scalar_tensor_default_2)
       }, else_branch: graph = false_graph_0 () => (float[1] neg_false_graph_0) {
          [node_Neg_0] neg_false_graph_0 = Neg (linear_1)
       }>
    }





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 1.730 seconds)


.. _sphx_glr_download_auto_recipes_plot_exporter_recipes_oe_cond.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_exporter_recipes_oe_cond.ipynb <plot_exporter_recipes_oe_cond.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_exporter_recipes_oe_cond.py <plot_exporter_recipes_oe_cond.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_exporter_recipes_oe_cond.zip <plot_exporter_recipes_oe_cond.zip>`


.. include:: plot_exporter_recipes_oe_cond.recommendations


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
