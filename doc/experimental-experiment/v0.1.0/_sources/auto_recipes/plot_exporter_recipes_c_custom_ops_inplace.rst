
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_recipes/plot_exporter_recipes_c_custom_ops_inplace.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_recipes_plot_exporter_recipes_c_custom_ops_inplace.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_recipes_plot_exporter_recipes_c_custom_ops_inplace.py:


.. _l-plot-exporter-recipes-custom-custom-ops-inplace:

to_onnx and a custom operator inplace
=====================================

This example shows how to convert a custom operator as defined
in the tutorial `Python Custom Operators
<https://pytorch.org/tutorials/advanced/python_custom_ops.html#python-custom-ops-tutorial>`_.

Inplace modification are not supported by onnx.

A model with a custom ops
+++++++++++++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 16-26

.. code-block:: Python


    from typing import Any, Dict, List, Optional
    import numpy as np
    import torch
    from onnx_array_api.plotting.graphviz_helper import plot_dot
    from experimental_experiment.xbuilder import GraphBuilder
    from experimental_experiment.helpers import pretty_onnx
    from experimental_experiment.torch_interpreter import to_onnx, Dispatcher









.. GENERATED FROM PYTHON SOURCE LINES 27-28

We define a model with a custom operator.

.. GENERATED FROM PYTHON SOURCE LINES 28-48

.. code-block:: Python



    @torch.library.custom_op("mylib::numpy_sin", mutates_args={"output"}, device_types="cpu")
    def numpy_sin(x: torch.Tensor, output: torch.Tensor) -> None:
        assert x.device == output.device
        assert x.device.type == "cpu"
        x_np = x.numpy()
        output_np = output.numpy()
        np.sin(x_np, out=output_np)


    class ModuleWithACustomOperator(torch.nn.Module):
        def forward(self, x):
            out = torch.zeros(x.shape)
            numpy_sin(x, out)
            return out


    model = ModuleWithACustomOperator()








.. GENERATED FROM PYTHON SOURCE LINES 49-50

Let's check it runs.

.. GENERATED FROM PYTHON SOURCE LINES 50-53

.. code-block:: Python

    x = torch.randn(1, 3)
    model(x)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    tensor([[0.2777, 0.5496, 0.7560]])



.. GENERATED FROM PYTHON SOURCE LINES 54-55

As expected, it does not export.

.. GENERATED FROM PYTHON SOURCE LINES 55-61

.. code-block:: Python

    try:
        torch.export.export(model, (x,))
        raise AssertionError("This export should failed unless pytorch now supports this model.")
    except Exception as e:
        print(e)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    This export should failed unless pytorch now supports this model.




.. GENERATED FROM PYTHON SOURCE LINES 62-63

The exporter fails with the same eror as it expects torch.export.export to work.

.. GENERATED FROM PYTHON SOURCE LINES 63-70

.. code-block:: Python


    try:
        to_onnx(model, (x,))
    except Exception as e:
        print(e)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Unable to interpret function <class 'torch._ops.OpOverload'>: <OpOverload(op='mylib.numpy_sin', overload='default')>, searched for ['mylib::numpy_sin', 'numpy_sin_default'] and attributes ['__qualname__', '__name__'], args=(<OpOverload(op='mylib.numpy_sin', overload='default')>,), kwargs={'x': x, 'output': zeros}
    --DEBUG--
    [GraphBuilder-WKU] Message starts, there are 1 initializers, 1 nodes, 1 inputs, 1 outputs.
    --LOCAL FUNCTIONS--
    --PARAMETERS--
    dynamic_examples=
    --SHAPE--
    dynamic_examples=
    dynamic_objects=
    dynamic_objects_rev=
    dynamic_dimensions_source={}
    dynamic_alias={}
    dynamic_shapes=None
    _known_value_shape={}
    _known_types={'init7_s2_1_3': 7, 'x': 1, 'zeros': 1}
    _known_shapes={'init7_s2_1_3': (2,), 'x': (1, 3), 'zeros': (1, 3)}
    _known_constants=['init7_s2_1_3', 'zeros']
    _known_ranks={}
    --TORCH-USERS--
    auto_functionalized -> {getitem_1}
    x -> {auto_functionalized}
    zeros -> {auto_functionalized}
    --TORCH-SHAPES--
    x: ('run_node', ('', ('val', torch.float32, torch.Size([1, 3])))) --- 1:2:(1, 3):
    zeros: ('run_node', ('', ('val', torch.float32, torch.Size([1, 3])))) --- 1:2:(1, 3):
    auto_functionalized: ('run_node', ('', '')) --- :::
    --ONNX--
    -- process.graph_module --
    graph():
        %x : [num_users=1] = placeholder[target=x]
        %zeros : [num_users=1] = call_function[target=torch.ops.aten.zeros.default](args = ([1, 3],), kwargs = {device: cpu, pin_memory: False})
        %auto_functionalized : [num_users=1] = call_function[target=torch.ops.higher_order.auto_functionalized](args = (mylib.numpy_sin.default,), kwargs = {x: %x, output: %zeros})
        %getitem_1 : [num_users=1] = call_function[target=operator.getitem](args = (%auto_functionalized, 1), kwargs = {})
        return (getitem_1,)
    -- process.progress --
    node 2/5 target=auto_functionalized
    --
    [GraphBuilder-WKU.make_tensor_input] x[1:1x3]
    [GraphBuilder-WKU.make_initializer] init7_s2_1_3[int64:int64:[1, 3]]
    [GraphBuilder-WKU.make_node] zeros           [#:#   ] ConstantOfShape:['init7_s2_1_3']->['zeros']
    [GraphBuilder-WKU] Message completed, there are 1 initializers, 1 nodes, 1 inputs, 1 outputs.




.. GENERATED FROM PYTHON SOURCE LINES 71-78

Registration
++++++++++++

The exporter how to convert the new exporter into ONNX.
This must be defined. The first piece is to tell the exporter
that the shape of the output is the same as x.
input names must be the same.

.. GENERATED FROM PYTHON SOURCE LINES 78-85

.. code-block:: Python



    @numpy_sin.register_fake
    def numpy_sin_shape(x, output):
        pass









.. GENERATED FROM PYTHON SOURCE LINES 86-87

Let's see what the fx graph looks like.

.. GENERATED FROM PYTHON SOURCE LINES 87-90

.. code-block:: Python


    print(torch.export.export(model, (x,)).graph)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    graph():
        %x : [num_users=1] = placeholder[target=x]
        %zeros : [num_users=1] = call_function[target=torch.ops.aten.zeros.default](args = ([1, 3],), kwargs = {device: cpu, pin_memory: False})
        %auto_functionalized : [num_users=1] = call_function[target=torch.ops.higher_order.auto_functionalized](args = (mylib.numpy_sin.default,), kwargs = {x: %x, output: %zeros})
        %getitem_1 : [num_users=1] = call_function[target=operator.getitem](args = (%auto_functionalized, 1), kwargs = {})
        return (getitem_1,)




.. GENERATED FROM PYTHON SOURCE LINES 91-92

Next is the conversion to onnx.

.. GENERATED FROM PYTHON SOURCE LINES 92-110

.. code-block:: Python

    T = str  # a tensor name


    def numpy_sin_to_onnx(
        g: GraphBuilder,
        sts: Dict[str, Any],
        outputs: List[str],
        x: T,
        output: Optional[T] = None,
        name: str = "mylib.numpy_sin",
    ) -> T:
        # name= ... lets the user know when the node comes from
        # o is not used, we could check the shape are equal.
        # outputs contains unexpectedly two outputs
        g.op.Sin(x, name=name, outputs=outputs[1:])
        return outputs









.. GENERATED FROM PYTHON SOURCE LINES 111-112

We create a :class:`Dispatcher <experimental_experiment.torch_interpreter.Dispatcher>`.

.. GENERATED FROM PYTHON SOURCE LINES 112-115

.. code-block:: Python


    dispatcher = Dispatcher({"mylib::numpy_sin": numpy_sin_to_onnx})








.. GENERATED FROM PYTHON SOURCE LINES 116-117

And we convert again.

.. GENERATED FROM PYTHON SOURCE LINES 117-121

.. code-block:: Python


    onx = to_onnx(model, (x,), dispatcher=dispatcher, optimize=False)
    print(pretty_onnx(onx))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    opset: domain='' version=18
    doc_string: large_model=False, inline=False, external_threshold=102...
    input: name='x' type=dtype('float32') shape=[1, 3]
    init: name='init7_s2_1_3' type=dtype('int64') shape=(2,) -- array([1, 3])
    ConstantOfShape(init7_s2_1_3, value=[nan]) -> zeros
    Sin(x) -> auto_functionalized#1
      Identity(auto_functionalized#1) -> getitem_1
        Identity(getitem_1) -> output_0
    output: name='output_0' type=dtype('float32') shape=[1, 3]




.. GENERATED FROM PYTHON SOURCE LINES 122-123

And we convert again with optimization this time.

.. GENERATED FROM PYTHON SOURCE LINES 123-127

.. code-block:: Python


    onx = to_onnx(model, (x,), dispatcher=dispatcher, optimize=True)
    print(pretty_onnx(onx))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    opset: domain='' version=18
    doc_string: large_model=False, inline=False, external_threshold=102...
    input: name='x' type=dtype('float32') shape=[1, 3]
    Sin(x) -> output_0
    output: name='output_0' type=dtype('float32') shape=[1, 3]




.. GENERATED FROM PYTHON SOURCE LINES 128-129

And visually.

.. GENERATED FROM PYTHON SOURCE LINES 129-131

.. code-block:: Python


    plot_dot(onx)



.. image-sg:: /auto_recipes/images/sphx_glr_plot_exporter_recipes_c_custom_ops_inplace_001.png
   :alt: plot exporter recipes c custom ops inplace
   :srcset: /auto_recipes/images/sphx_glr_plot_exporter_recipes_c_custom_ops_inplace_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <Axes: >




.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 0.623 seconds)


.. _sphx_glr_download_auto_recipes_plot_exporter_recipes_c_custom_ops_inplace.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_exporter_recipes_c_custom_ops_inplace.ipynb <plot_exporter_recipes_c_custom_ops_inplace.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_exporter_recipes_c_custom_ops_inplace.py <plot_exporter_recipes_c_custom_ops_inplace.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_exporter_recipes_c_custom_ops_inplace.zip <plot_exporter_recipes_c_custom_ops_inplace.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
