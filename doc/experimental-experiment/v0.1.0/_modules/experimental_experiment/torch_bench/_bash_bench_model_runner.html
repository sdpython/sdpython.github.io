<!doctype html>
<html class="no-js" lang="en" data-content_root="../../../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><link rel="index" title="Index" href="../../../genindex.html" /><link rel="search" title="Search" href="../../../search.html" />

    <!-- Generated with Sphinx 8.1.3 and Furo 2024.08.06 -->
        <title>experimental_experiment.torch_bench._bash_bench_model_runner - experimental-experiment 0.1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/furo.css?v=354aac6f" />
    <link rel="stylesheet" type="text/css" href="../../../_static/plot_directive.css?v=7f9a90b1" />
    <link rel="stylesheet" type="text/css" href="../../../_static/graphviz.css?v=4ae1632d" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/furo-extensions.css?v=302659d7" />
    
    


<style>
  body {
    --color-code-background: #eeffcc;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../../../index.html"><div class="brand">experimental-experiment 0.1.0 documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon no-toc" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../../../index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="../../../_static/logo.png" alt="Logo"/>
  </div>
  
  <span class="sidebar-brand-text">experimental-experiment 0.1.0 documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../../../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Contents</span></p>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../design/index.html">Design</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of Design</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../design/exporter.html">Custom Exporter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../design/optimizer.html">Pattern Optimizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../design/backends.html">Dynamo Backends</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../tutorial/index.html">Tutorial</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of Tutorial</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorial/pytorch.html">pytorch and onnx</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorial/onnx.html">onnx</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorial/errors.html">Frequent Exceptions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorial/docker.html">Start from a docker</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../api/index.html">experimental_experiment</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of experimental_experiment</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../api/gradient/index.html">experimental_experiment.gradient</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of experimental_experiment.gradient</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../api/gradient/ops/index.html">experimental_experiment.gradient.ops</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of experimental_experiment.gradient.ops</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gradient/ops/op_broadcast_gradient_args.html">experimental_experiment.gradient.ops.op_broadcast_gradient_args</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gradient/grad_helper.html">experimental_experiment.gradient.grad_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gradient/loss_helper.html">experimental_experiment.gradient.loss_helper</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../api/reference/index.html">experimental_experiment.reference</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle navigation of experimental_experiment.reference</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../api/reference/ops/index.html">experimental_experiment.reference.ops</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle navigation of experimental_experiment.reference.ops</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/reference/ops/op_add_add_mul_mul.html">experimental_experiment.reference.ops.op_add_add_mul_mul</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/reference/ops/op_average_pool_grad.html">experimental_experiment.reference.ops.op_average_pool_grad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/reference/ops/op_cast_like.html">experimental_experiment.reference.ops.op_cast_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/reference/ops/op_concat.html">experimental_experiment.reference.ops.op_concat</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/reference/ops/op_constant_of_shape.html">experimental_experiment.reference.ops.op_constant_of_shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/reference/ops/op_fused_matmul.html">experimental_experiment.reference.ops.op_fused_matmul</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/reference/ops/op_gather_grad.html">experimental_experiment.reference.ops.op_gather_grad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/reference/ops/op_memcpy_host.html">experimental_experiment.reference.ops.op_memcpy_host</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/reference/ops/op_mul_sigmoid.html">experimental_experiment.reference.ops.op_mul_sigmoid</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/reference/ops/op_negxplus1.html">experimental_experiment.reference.ops.op_negxplus1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/reference/ops/op_quick_gelu.html">experimental_experiment.reference.ops.op_quick_gelu</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/reference/ops/op_replace_zero.html">experimental_experiment.reference.ops.op_replace_zero</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/reference/ops/op_rotary.html">experimental_experiment.reference.ops.op_rotary</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/reference/ops/op_scatter_elements.html">experimental_experiment.reference.ops.op_scatter_elements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/reference/ops/op_scatternd_of_shape.html">experimental_experiment.reference.ops.op_scatternd_of_shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/reference/ops/op_simplified_layer_normalization.html">experimental_experiment.reference.ops.op_simplified_layer_normalization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/reference/ops/op_slice.html">experimental_experiment.reference.ops.op_slice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/reference/ops/op_transpose_cast.html">experimental_experiment.reference.ops.op_transpose_cast</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/reference/ops/op_tri_matrix.html">experimental_experiment.reference.ops.op_tri_matrix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/reference/evaluator.html">experimental_experiment.reference.evaluator</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/reference/ort_evaluator.html">experimental_experiment.reference.ort_evaluator</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../api/convert/index.html">experimental_experiment.convert</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle navigation of experimental_experiment.convert</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api/convert/convert_helper.html">experimental_experiment.convert.convert_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/convert/ort_helper.html">experimental_experiment.convert.ort_helper</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../api/plotting/index.html">experimental_experiment.plotting</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle navigation of experimental_experiment.plotting</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api/plotting/data.html">experimental_experiment.plotting.data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/plotting/memory.html">experimental_experiment.plotting.memory</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../api/torch_interpreter/index.html">experimental_experiment.torch_interpreter</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle navigation of experimental_experiment.torch_interpreter</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_interpreter/_aten_functions.html">experimental_experiment.torch_interpreter._aten_functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_interpreter/_aten_functions_attention.html">experimental_experiment.torch_interpreter._aten_functions_attention</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_interpreter/_aten_methods.html">experimental_experiment.torch_interpreter._aten_methods</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_interpreter/_doc_.html">experimental_experiment.torch_interpreter._doc_</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_interpreter/_exceptions.html">experimental_experiment.torch_interpreter._exceptions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_interpreter/_prims_functions.html">experimental_experiment.torch_interpreter._prims_functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_interpreter/_torch_helper.html">experimental_experiment.torch_interpreter._torch_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_interpreter/aten_functions.html">experimental_experiment.torch_interpreter.aten_functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_interpreter/aten_methods.html">experimental_experiment.torch_interpreter.aten_methods</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_interpreter/dispatcher.html">experimental_experiment.torch_interpreter.dispatcher</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_interpreter/export_options.html">experimental_experiment.torch_interpreter.export_options</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_interpreter/interpreter.html">experimental_experiment.torch_interpreter.interpreter</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_interpreter/onnx_export.html">experimental_experiment.torch_interpreter.onnx_export</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_interpreter/onnx_export_errors.html">experimental_experiment.torch_interpreter.onnx_export_errors</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_interpreter/oxs_dispatcher.html">experimental_experiment.torch_interpreter.oxs_dispatcher</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_interpreter/oxs_opset.html">experimental_experiment.torch_interpreter.oxs_opset</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../api/torch_models/index.html">experimental_experiment.torch_models</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><div class="visually-hidden">Toggle navigation of experimental_experiment.torch_models</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_models/diffusion_model_helper.html">experimental_experiment.torch_models.diffusion_model_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_models/dump_helper.html">experimental_experiment.torch_models.dump_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_models/llama_helper.html">experimental_experiment.torch_models.llama_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_models/llm_model_helper.html">experimental_experiment.torch_models.llm_model_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_models/mistral_helper.html">experimental_experiment.torch_models.mistral_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_models/phi3_helper.html">experimental_experiment.torch_models.phi3_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_models/phi_helper.html">experimental_experiment.torch_models.phi_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_models/training_helper.html">experimental_experiment.torch_models.training_helper</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../api/xbuilder/index.html">experimental_experiment.xbuilder</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><div class="visually-hidden">Toggle navigation of experimental_experiment.xbuilder</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api/xbuilder/_dtype_helper.html">experimental_experiment.xbuilder._dtype_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/xbuilder/_graph_builder_runtime.html">experimental_experiment.xbuilder._graph_builder_runtime</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/xbuilder/_onnx_helper.html">experimental_experiment.xbuilder._onnx_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/xbuilder/_shape_helper.html">experimental_experiment.xbuilder._shape_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/xbuilder/expression_dimension.html">experimental_experiment.xbuilder.expression_dimension</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/xbuilder/graph_builder.html">experimental_experiment.xbuilder.graph_builder</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/xbuilder/graph_builder_opset.html">experimental_experiment.xbuilder.graph_builder_opset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/xbuilder/model_container.html">experimental_experiment.xbuilder.model_container</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/xbuilder/optimization_options.html">experimental_experiment.xbuilder.optimization_options</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/xbuilder/shape_type_compute.html">experimental_experiment.xbuilder.shape_type_compute</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/xbuilder/type_inference.html">experimental_experiment.xbuilder.type_inference</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../api/xoptim/index.html">experimental_experiment.xoptim</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" role="switch" type="checkbox"/><label for="toctree-checkbox-13"><div class="visually-hidden">Toggle navigation of experimental_experiment.xoptim</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../api/xoptim/patterns_investigation/index.html">experimental_experiment.xoptim.patterns_investigation</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" role="switch" type="checkbox"/><label for="toctree-checkbox-14"><div class="visually-hidden">Toggle navigation of experimental_experiment.xoptim.patterns_investigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/xoptim/patterns_investigation/element_wise.html">experimental_experiment.xoptim.patterns_investigation.element_wise</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../api/xoptim/patterns_ml/index.html">experimental_experiment.xoptim.patterns_ml</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" role="switch" type="checkbox"/><label for="toctree-checkbox-15"><div class="visually-hidden">Toggle navigation of experimental_experiment.xoptim.patterns_ml</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/xoptim/patterns_ml/tree_ensemble.html">experimental_experiment.xoptim.patterns_ml.tree_ensemble</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../api/xoptim/patterns_exp/index.html">experimental_experiment.xoptim.patterns_exp</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" role="switch" type="checkbox"/><label for="toctree-checkbox-16"><div class="visually-hidden">Toggle navigation of experimental_experiment.xoptim.patterns_exp</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/xoptim/patterns_exp/binary_operators.html">experimental_experiment.xoptim.patterns_exp.binary_operators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/xoptim/patterns_exp/constant_of_shape_scatter_nd.html">experimental_experiment.xoptim.patterns_exp.constant_of_shape_scatter_nd</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/xoptim/patterns_exp/constants.html">experimental_experiment.xoptim.patterns_exp.constants</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/xoptim/patterns_exp/simple_rotary.html">experimental_experiment.xoptim.patterns_exp.simple_rotary</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/xoptim/patterns_exp/unary_operators.html">experimental_experiment.xoptim.patterns_exp.unary_operators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/xoptim/patterns_exp/where_replace.html">experimental_experiment.xoptim.patterns_exp.where_replace</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../api/xoptim/patterns/index.html">experimental_experiment.xoptim.patterns</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" role="switch" type="checkbox"/><label for="toctree-checkbox-17"><div class="visually-hidden">Toggle navigation of experimental_experiment.xoptim.patterns</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/xoptim/patterns/onnx_any.html">experimental_experiment.xoptim.patterns.onnx_any</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/xoptim/patterns/onnx_cast.html">experimental_experiment.xoptim.patterns.onnx_cast</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/xoptim/patterns/onnx_conv.html">experimental_experiment.xoptim.patterns.onnx_conv</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/xoptim/patterns/onnx_dropout.html">experimental_experiment.xoptim.patterns.onnx_dropout</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/xoptim/patterns/onnx_equal.html">experimental_experiment.xoptim.patterns.onnx_equal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/xoptim/patterns/onnx_expand.html">experimental_experiment.xoptim.patterns.onnx_expand</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/xoptim/patterns/onnx_functions.html">experimental_experiment.xoptim.patterns.onnx_functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/xoptim/patterns/onnx_layer_normalization.html">experimental_experiment.xoptim.patterns.onnx_layer_normalization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/xoptim/patterns/onnx_matmul.html">experimental_experiment.xoptim.patterns.onnx_matmul</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/xoptim/patterns/onnx_mul.html">experimental_experiment.xoptim.patterns.onnx_mul</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/xoptim/patterns/onnx_reduce.html">experimental_experiment.xoptim.patterns.onnx_reduce</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/xoptim/patterns/onnx_reshape.html">experimental_experiment.xoptim.patterns.onnx_reshape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/xoptim/patterns/onnx_rotary.html">experimental_experiment.xoptim.patterns.onnx_rotary</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/xoptim/patterns/onnx_split.html">experimental_experiment.xoptim.patterns.onnx_split</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/xoptim/patterns/onnx_sub.html">experimental_experiment.xoptim.patterns.onnx_sub</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/xoptim/patterns/onnx_transpose.html">experimental_experiment.xoptim.patterns.onnx_transpose</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/xoptim/patterns/onnx_unsqueeze.html">experimental_experiment.xoptim.patterns.onnx_unsqueeze</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../api/xoptim/patterns_ort/index.html">experimental_experiment.xoptim.patterns_ort</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" role="switch" type="checkbox"/><label for="toctree-checkbox-18"><div class="visually-hidden">Toggle navigation of experimental_experiment.xoptim.patterns_ort</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/xoptim/patterns_ort/activation.html">experimental_experiment.xoptim.patterns_ort.activation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/xoptim/patterns_ort/activation_grad.html">experimental_experiment.xoptim.patterns_ort.activation_grad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/xoptim/patterns_ort/fused_matmul.html">experimental_experiment.xoptim.patterns_ort.fused_matmul</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/xoptim/patterns_ort/gather_grad.html">experimental_experiment.xoptim.patterns_ort.gather_grad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/xoptim/patterns_ort/simplified_layer_normalization.html">experimental_experiment.xoptim.patterns_ort.simplified_layer_normalization</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../api/xoptim/patterns_fix/index.html">experimental_experiment.xoptim.patterns_fix</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" role="switch" type="checkbox"/><label for="toctree-checkbox-19"><div class="visually-hidden">Toggle navigation of experimental_experiment.xoptim.patterns_fix</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/xoptim/patterns_fix/add_reduction_scatter_nd.html">experimental_experiment.xoptim.patterns_fix.add_reduction_scatter_nd</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/xoptim/graph_builder_optim.html">experimental_experiment.xoptim.graph_builder_optim</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/xoptim/order_optim.html">experimental_experiment.xoptim.order_optim</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/xoptim/patterns_api.html">experimental_experiment.xoptim.patterns_api</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../api/torch_dynamo/index.html">experimental_experiment.torch_dynamo</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" role="switch" type="checkbox"/><label for="toctree-checkbox-20"><div class="visually-hidden">Toggle navigation of experimental_experiment.torch_dynamo</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_dynamo/_dynamo_exporter.html">experimental_experiment.torch_dynamo._dynamo_exporter</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_dynamo/backend_helper.html">experimental_experiment.torch_dynamo.backend_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_dynamo/debug_backend.html">experimental_experiment.torch_dynamo.debug_backend</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_dynamo/dynger_backend.html">experimental_experiment.torch_dynamo.dynger_backend</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_dynamo/fast_backend.html">experimental_experiment.torch_dynamo.fast_backend</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_dynamo/partition.html">experimental_experiment.torch_dynamo.partition</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../api/torch_bench/index.html">experimental_experiment.torch_bench</a><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" role="switch" type="checkbox"/><label for="toctree-checkbox-21"><div class="visually-hidden">Toggle navigation of experimental_experiment.torch_bench</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../api/torch_bench/big_models/index.html">experimental_experiment.torch_bench.big_models</a><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" role="switch" type="checkbox"/><label for="toctree-checkbox-22"><div class="visually-hidden">Toggle navigation of experimental_experiment.torch_bench.big_models</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/torch_bench/big_models/try_codellama.html">experimental_experiment.torch_bench.big_models.try_codellama</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/torch_bench/big_models/try_codellama_test.html">experimental_experiment.torch_bench.big_models.try_codellama_test</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/torch_bench/big_models/try_falcon_mamba.html">experimental_experiment.torch_bench.big_models.try_falcon_mamba</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/torch_bench/big_models/try_falcon_mamba_test.html">experimental_experiment.torch_bench.big_models.try_falcon_mamba_test</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/torch_bench/big_models/try_flux_t5.html">experimental_experiment.torch_bench.big_models.try_flux_t5</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/torch_bench/big_models/try_flux_t5_test.html">experimental_experiment.torch_bench.big_models.try_flux_t5_test</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/torch_bench/big_models/try_flux_transformer.html">experimental_experiment.torch_bench.big_models.try_flux_transformer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/torch_bench/big_models/try_flux_transformer_test.html">experimental_experiment.torch_bench.big_models.try_flux_transformer_test</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/torch_bench/big_models/try_minilm.html">experimental_experiment.torch_bench.big_models.try_minilm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/torch_bench/big_models/try_minilm_test.html">experimental_experiment.torch_bench.big_models.try_minilm_test</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/torch_bench/big_models/try_phi_35_mini_instruct.html">experimental_experiment.torch_bench.big_models.try_phi_35_mini_instruct</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/torch_bench/big_models/try_phi_35_mini_instruct_test.html">experimental_experiment.torch_bench.big_models.try_phi_35_mini_instruct_test</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/torch_bench/big_models/try_smollm.html">experimental_experiment.torch_bench.big_models.try_smollm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/torch_bench/big_models/try_smollm_test.html">experimental_experiment.torch_bench.big_models.try_smollm_test</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/torch_bench/big_models/try_stable_diffusion_3.html">experimental_experiment.torch_bench.big_models.try_stable_diffusion_3</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/torch_bench/big_models/try_stable_diffusion_3_test.html">experimental_experiment.torch_bench.big_models.try_stable_diffusion_3_test</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_bench/_bash_bench_benchmark_runner.html">experimental_experiment.torch_bench._bash_bench_benchmark_runner</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_bench/_bash_bench_benchmark_runner_agg.html">experimental_experiment.torch_bench._bash_bench_benchmark_runner_agg</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_bench/_bash_bench_benchmark_runner_agg_helper.html">experimental_experiment.torch_bench._bash_bench_benchmark_runner_agg_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_bench/_bash_bench_cmd.html">experimental_experiment.torch_bench._bash_bench_cmd</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_bench/_bash_bench_model_runner.html">experimental_experiment.torch_bench._bash_bench_model_runner</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_bench/_bash_bench_models_helper.html">experimental_experiment.torch_bench._bash_bench_models_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_bench/_bash_bench_set_dummies.html">experimental_experiment.torch_bench._bash_bench_set_dummies</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_bench/_bash_bench_set_explicit.html">experimental_experiment.torch_bench._bash_bench_set_explicit</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_bench/_bash_bench_set_huggingface.html">experimental_experiment.torch_bench._bash_bench_set_huggingface</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_bench/_bash_bench_set_huggingface_big.html">experimental_experiment.torch_bench._bash_bench_set_huggingface_big</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_bench/_bash_bench_set_issues.html">experimental_experiment.torch_bench._bash_bench_set_issues</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_bench/_bash_bench_set_timm.html">experimental_experiment.torch_bench._bash_bench_set_timm</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_bench/_bash_bench_set_torchbench.html">experimental_experiment.torch_bench._bash_bench_set_torchbench</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_bench/_bash_bench_set_torchbench_ado.html">experimental_experiment.torch_bench._bash_bench_set_torchbench_ado</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_bench/_bash_bench_suites.html">experimental_experiment.torch_bench._bash_bench_suites</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_bench/_dort_cmd_common.html">experimental_experiment.torch_bench._dort_cmd_common</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_bench/_dort_cmd_common_models.html">experimental_experiment.torch_bench._dort_cmd_common_models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_bench/bash_bench_agg.html">experimental_experiment.torch_bench.bash_bench_agg</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_bench/bash_bench_explicit.html">experimental_experiment.torch_bench.bash_bench_explicit</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_bench/bash_bench_huggingface.html">experimental_experiment.torch_bench.bash_bench_huggingface</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_bench/bash_bench_huggingface_big.html">experimental_experiment.torch_bench.bash_bench_huggingface_big</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_bench/bash_bench_issues.html">experimental_experiment.torch_bench.bash_bench_issues</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_bench/bash_bench_timm.html">experimental_experiment.torch_bench.bash_bench_timm</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_bench/bash_bench_torchbench.html">experimental_experiment.torch_bench.bash_bench_torchbench</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_bench/bash_bench_torchbench_ado.html">experimental_experiment.torch_bench.bash_bench_torchbench_ado</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_bench/bash_bench_untrained.html">experimental_experiment.torch_bench.bash_bench_untrained</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_bench/check_model.html">experimental_experiment.torch_bench.check_model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_bench/dort_bench.html">experimental_experiment.torch_bench.dort_bench</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_bench/dort_bench_profile.html">experimental_experiment.torch_bench.dort_bench_profile</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_bench/dort_profile.html">experimental_experiment.torch_bench.dort_profile</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_bench/export_model.html">experimental_experiment.torch_bench.export_model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/torch_bench/export_model_helper.html">experimental_experiment.torch_bench.export_model_helper</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/_bench_test.html">experimental_experiment._bench_test</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/_command_lines_parser.html">experimental_experiment._command_lines_parser</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/args.html">experimental_experiment.args</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/bench_run.html">experimental_experiment.bench_run</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/checks.html">experimental_experiment.checks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/ext_test_case.html">experimental_experiment.ext_test_case</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/helpers.html">experimental_experiment.helpers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/memory_peak.html">experimental_experiment.memory_peak</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/model_run.html">experimental_experiment.model_run</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/onnx_tools.html">experimental_experiment.onnx_tools</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/torch_test_helper.html">experimental_experiment.torch_test_helper</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../auto_examples/index.html">Example gallery</a><input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" role="switch" type="checkbox"/><label for="toctree-checkbox-23"><div class="visually-hidden">Toggle navigation of Example gallery</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_onnxscript_102.html">102: Examples with onnxscript</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_optimize_101.html">101: Graph Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_executorch_102.html">102: First test with ExecuTorch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_torch_export_compile_102.html">102: Tweak onnx export</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_profile_existing_onnx_101.html">101: Profile an existing model with onnxruntime</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_rewrite_101.html">101: Onnx Model Rewriting</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_torch_linreg_101.html">101: Linear Regression and export to ONNX</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_torch_custom_backend_101.html">101: A custom backend for torch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_torch_export_101.html">101: Some dummy examples with torch.export.export</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_convolutation_matmul_102.html">102: Convolution and Matrix Multiplication</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_custom_backend_llama_102.html">102: Fuse kernels in a small Llama Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_llama_diff_export_301.html">301: Compares LLAMA exporters</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_llama_diff_dort_301.html">301: Compares LLAMA exporters for onnxrt backend</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_llama_bench_102.html">102: Measure LLAMA speed</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_torch_aot_201.html">201: Evaluate DORT Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_torch_dort_201.html">201: Evaluate DORT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_torch_export_201.html">201: Evaluate different ways to export a torch model to ONNX</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../models/index.html">Supported Models By the Custom Backend</a><input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" role="switch" type="checkbox"/><label for="toctree-checkbox-24"><div class="visually-hidden">Toggle navigation of Supported Models By the Custom Backend</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../models/llama.html">LLaMa</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../models/mistral.html">Mistral</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../models/phi.html">Phi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../models/phi3.html">Phi3</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../models/diffusion_helper.html">experimental_experiment.torch_models.llm_model_helper</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../models/llm_helper.html">experimental_experiment.torch_models.diffusion_model_helper</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../command_lines.html">Command Lines</a><input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" role="switch" type="checkbox"/><label for="toctree-checkbox-25"><div class="visually-hidden">Toggle navigation of Command Lines</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../bench/index.html">Benchmarks from the command line</a><input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" role="switch" type="checkbox"/><label for="toctree-checkbox-26"><div class="visually-hidden">Toggle navigation of Benchmarks from the command line</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../bench/dort_bench.html">experimental_experiment.torch_bench.dort_bench</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../bench/dort_profile.html">experimental_experiment.torch_bench.dort_profile</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../bench/scripts.html">Interesting scripts or command lines</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../bench/bash_bench.html">Measuring the exporters on a short list of sets of models</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../tools/index.html">Tools from the command line</a><input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" role="switch" type="checkbox"/><label for="toctree-checkbox-27"><div class="visually-hidden">Toggle navigation of Tools from the command line</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../tools/lighten.html">python -m experimental_experiment lighten and unlighten</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tools/optimize.html">python -m experimental_experiment optimize</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tools/run.html">python -m experimental_experiment run</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../miscellaneous/index.html">Miscellaneous</a><input class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" role="switch" type="checkbox"/><label for="toctree-checkbox-28"><div class="visually-hidden">Toggle navigation of Miscellaneous</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../miscellaneous/export_times.html">Export Times</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../miscellaneous/long_outputs.html">Long Outputs uneasy to read</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">More</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../CHANGELOGS.html">Change Logs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../license.html">License</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon no-toc" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <h1>Source code for experimental_experiment.torch_bench._bash_bench_model_runner</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">collections</span>
<span class="kn">import</span> <span class="nn">enum</span>
<span class="kn">import</span> <span class="nn">inspect</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pprint</span>
<span class="kn">import</span> <span class="nn">shutil</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>
<span class="kn">import</span> <span class="nn">onnx</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">..helpers</span> <span class="kn">import</span> <span class="n">string_type</span>
<span class="kn">from</span> <span class="nn">..torch_interpreter.onnx_export_errors</span> <span class="kn">import</span> <span class="n">bypass_export_some_errors</span>
<span class="kn">from</span> <span class="nn">.export_model_helper</span> <span class="kn">import</span> <span class="n">compute_weight_size</span>


<div class="viewcode-block" id="UseDefaultValue">
<a class="viewcode-back" href="../../../api/torch_bench/_bash_bench_model_runner.html#experimental_experiment.torch_bench._bash_bench_model_runner.UseDefaultValue">[docs]</a>
<span class="k">class</span> <span class="nc">UseDefaultValue</span><span class="p">(</span><span class="n">enum</span><span class="o">.</span><span class="n">IntEnum</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Defines if the exporter may use the default value.</span>

<span class="sd">    * FALSE: no default value</span>
<span class="sd">    * TRUE: there is a default value and the input is not specified</span>
<span class="sd">    * BOTH: there is a default and one input</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">FALSE</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">TRUE</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">BOTH</span> <span class="o">=</span> <span class="mi">3</span></div>



<div class="viewcode-block" id="MakeConfig">
<a class="viewcode-back" href="../../../api/torch_bench/_bash_bench_model_runner.html#experimental_experiment.torch_bench._bash_bench_model_runner.MakeConfig">[docs]</a>
<span class="k">class</span> <span class="nc">MakeConfig</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Creates a dictionary where keys are attributes.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span></div>



<span class="k">def</span> <span class="nf">_rand_int_tensor</span><span class="p">(</span><span class="n">device</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">low</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">high</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">shape</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Creates a random input integer tensor.</span>

<span class="sd">    :param device: device</span>
<span class="sd">    :param low: lower value</span>
<span class="sd">    :param high: high value</span>
<span class="sd">    :param shape: shape</span>
<span class="sd">    :return: tensor</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span>
        <span class="n">low</span><span class="p">,</span>
        <span class="n">high</span><span class="p">,</span>
        <span class="n">shape</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span>
        <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span>


<div class="viewcode-block" id="download_retry_decorator">
<a class="viewcode-back" href="../../../api/torch_bench/_bash_bench_model_runner.html#experimental_experiment.torch_bench._bash_bench_model_runner.download_retry_decorator">[docs]</a>
<span class="k">def</span> <span class="nf">download_retry_decorator</span><span class="p">(</span><span class="n">retry</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Callable</span><span class="p">:</span>  <span class="c1"># type: ignore[arg-type]</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Decorator function for applying retry logic to a download function.</span>

<span class="sd">    The wrapped function will be called up to 5 times</span>
<span class="sd">    and raises an exception if the function fails each time.</span>
<span class="sd">    After each unsuccessful attempt, there is a delay before</span>
<span class="sd">    the next attempt, which is increased linearly with the number of tries.</span>

<span class="sd">    :param retry: number of times to retry</span>

<span class="sd">    Usage:</span>

<span class="sd">    ::</span>

<span class="sd">        @download_retry_decorator(retry=5)</span>
<span class="sd">        def download_function(model_name: str):</span>
<span class="sd">            # download logic goes here</span>
<span class="sd">            # ...</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">decorator</span><span class="p">(</span><span class="n">download_fn</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">wrapper</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
            <span class="n">tries</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">total_allowed_tries</span> <span class="o">=</span> <span class="n">retry</span>
            <span class="k">while</span> <span class="n">tries</span> <span class="o">&lt;=</span> <span class="n">total_allowed_tries</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">model</span> <span class="o">=</span> <span class="n">download_fn</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
                    <span class="k">return</span> <span class="n">model</span>
                <span class="k">except</span> <span class="ne">RuntimeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="k">if</span> <span class="s2">&quot;Unknown model&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">):</span>
                        <span class="k">raise</span>
                    <span class="n">tries</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="k">if</span> <span class="n">tries</span> <span class="o">&lt;=</span> <span class="n">total_allowed_tries</span><span class="p">:</span>
                        <span class="n">wait</span> <span class="o">=</span> <span class="n">tries</span> <span class="o">*</span> <span class="mi">30</span>
                        <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="n">wait</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>  <span class="c1"># noqa: B904</span>
                            <span class="sa">f</span><span class="s2">&quot;Failed to load model </span><span class="si">{</span><span class="n">args</span><span class="si">!r}</span><span class="s2"> &quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;with following error(s): </span><span class="si">{</span><span class="n">e</span><span class="si">!r}</span><span class="s2">.&quot;</span>
                        <span class="p">)</span>

        <span class="k">return</span> <span class="n">wrapper</span>

    <span class="k">return</span> <span class="n">decorator</span></div>



<div class="viewcode-block" id="get_dynamo_stats">
<a class="viewcode-back" href="../../../api/torch_bench/_bash_bench_model_runner.html#experimental_experiment.torch_bench._bash_bench_model_runner.get_dynamo_stats">[docs]</a>
<span class="k">def</span> <span class="nf">get_dynamo_stats</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Returns statistics on memory as a dictionary.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">collections</span><span class="o">.</span><span class="n">Counter</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="s2">&quot;calls_captured&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">_dynamo</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">counters</span><span class="p">[</span><span class="s2">&quot;stats&quot;</span><span class="p">][</span><span class="s2">&quot;calls_captured&quot;</span><span class="p">],</span>
            <span class="s2">&quot;unique_graphs&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">_dynamo</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">counters</span><span class="p">[</span><span class="s2">&quot;stats&quot;</span><span class="p">][</span><span class="s2">&quot;unique_graphs&quot;</span><span class="p">],</span>
            <span class="s2">&quot;graph_breaks&quot;</span><span class="p">:</span> <span class="nb">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">_dynamo</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">counters</span><span class="p">[</span><span class="s2">&quot;graph_break&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span>
            <span class="c1"># NB: The plus removes zero counts</span>
            <span class="s2">&quot;unique_graph_breaks&quot;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="o">+</span><span class="n">torch</span><span class="o">.</span><span class="n">_dynamo</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">counters</span><span class="p">[</span><span class="s2">&quot;graph_break&quot;</span><span class="p">]),</span>
            <span class="s2">&quot;autograd_captures&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">_dynamo</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">counters</span><span class="p">[</span><span class="s2">&quot;compiled_autograd&quot;</span><span class="p">][</span><span class="s2">&quot;captures&quot;</span><span class="p">],</span>
            <span class="s2">&quot;autograd_compiles&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">_dynamo</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">counters</span><span class="p">[</span><span class="s2">&quot;compiled_autograd&quot;</span><span class="p">][</span><span class="s2">&quot;compiles&quot;</span><span class="p">],</span>
            <span class="s2">&quot;cudagraph_skips&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">_dynamo</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">counters</span><span class="p">[</span><span class="s2">&quot;inductor&quot;</span><span class="p">][</span><span class="s2">&quot;cudagraph_skips&quot;</span><span class="p">],</span>
        <span class="p">}</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="get_peak_memory">
<a class="viewcode-back" href="../../../api/torch_bench/_bash_bench_model_runner.html#experimental_experiment.torch_bench._bash_bench_model_runner.get_peak_memory">[docs]</a>
<span class="k">def</span> <span class="nf">get_peak_memory</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Retuns the memory peak.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">max_memory_allocated</span><span class="p">()</span> <span class="o">/</span> <span class="mi">10</span><span class="o">**</span><span class="mi">9</span></div>



<div class="viewcode-block" id="WrappedModelBase">
<a class="viewcode-back" href="../../../api/torch_bench/_bash_bench_model_runner.html#experimental_experiment.torch_bench._bash_bench_model_runner.WrappedModelBase">[docs]</a>
<span class="k">class</span> <span class="nc">WrappedModelBase</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="WrappedModelBase.forward">
<a class="viewcode-back" href="../../../api/torch_bench/_bash_bench_model_runner.html#experimental_experiment.torch_bench._bash_bench_model_runner.WrappedModelBase.forward">[docs]</a>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>


<div class="viewcode-block" id="WrappedModelBase.parameters">
<a class="viewcode-back" href="../../../api/torch_bench/_bash_bench_model_runner.html#experimental_experiment.torch_bench._bash_bench_model_runner.WrappedModelBase.parameters">[docs]</a>
    <span class="k">def</span> <span class="nf">parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">yield from</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span></div>
</div>



<div class="viewcode-block" id="WrappedModelToTuple">
<a class="viewcode-back" href="../../../api/torch_bench/_bash_bench_model_runner.html#experimental_experiment.torch_bench._bash_bench_model_runner.WrappedModelToTuple">[docs]</a>
<span class="k">class</span> <span class="nc">WrappedModelToTuple</span><span class="p">(</span><span class="n">WrappedModelBase</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">res</span><span class="o">.</span><span class="n">to_tuple</span><span class="p">()</span>

<div class="viewcode-block" id="WrappedModelToTuple.forward">
<a class="viewcode-back" href="../../../api/torch_bench/_bash_bench_model_runner.html#experimental_experiment.torch_bench._bash_bench_model_runner.WrappedModelToTuple.forward">[docs]</a>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">res</span><span class="o">.</span><span class="n">to_tuple</span><span class="p">()</span></div>
</div>



<div class="viewcode-block" id="ModelRunner">
<a class="viewcode-back" href="../../../api/torch_bench/_bash_bench_model_runner.html#experimental_experiment.torch_bench._bash_bench_model_runner.ModelRunner">[docs]</a>
<span class="k">class</span> <span class="nc">ModelRunner</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Wrappers around a model.</span>
<span class="sd">    Makes it easier to load, run inference.</span>

<span class="sd">    :param model: torch model</span>
<span class="sd">    :param inputs: example of inputs</span>
<span class="sd">    :param kw_inputs: example of keyword inputs</span>
<span class="sd">    :param device: device</span>
<span class="sd">    :param dtype: if the model needs to be converted</span>
<span class="sd">    :param warmup: number of iteration to warmup the model</span>
<span class="sd">    :param repeat: number of iteration to repeat the model</span>
<span class="sd">    :param suite: model suite</span>
<span class="sd">    :param wrap_kind: to wrap the model and tuple as much as possible,</span>
<span class="sd">        None is default behavior,</span>
<span class="sd">        &#39;nowrap&#39; to explicit avoid wrapping</span>
<span class="sd">    :param nvtx: enable nvtx events</span>
<span class="sd">    :param model_name: model name</span>
<span class="sd">    :param export_options: additional options when exporting if the default options never work</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_patched</span> <span class="o">=</span> <span class="kc">None</span>

<div class="viewcode-block" id="ModelRunner.allowed_configuration">
<a class="viewcode-back" href="../../../api/torch_bench/_bash_bench_model_runner.html#experimental_experiment.torch_bench._bash_bench_model_runner.ModelRunner.allowed_configuration">[docs]</a>
    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">allowed_configuration</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">exporter</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">optimization</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Defines the allowed configurations.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">optimization</span> <span class="ow">or</span> <span class="n">optimization</span> <span class="o">==</span> <span class="s2">&quot;none&quot;</span><span class="p">:</span>
            <span class="c1"># always possible</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="n">exporter</span> <span class="ow">in</span> <span class="p">{</span><span class="s2">&quot;custom&quot;</span><span class="p">,</span> <span class="s2">&quot;custom-fallback&quot;</span><span class="p">}:</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="n">exporter</span> <span class="ow">in</span> <span class="p">{</span><span class="s2">&quot;torch_script&quot;</span><span class="p">,</span> <span class="s2">&quot;dynamo_export&quot;</span><span class="p">}:</span>
            <span class="k">return</span> <span class="n">optimization</span> <span class="ow">in</span> <span class="p">{</span><span class="s2">&quot;default&quot;</span><span class="p">}</span>
        <span class="k">if</span> <span class="n">exporter</span> <span class="ow">in</span> <span class="p">{</span><span class="s2">&quot;onnx_dynamo&quot;</span><span class="p">,</span> <span class="s2">&quot;onnx_dynamo-fallback&quot;</span><span class="p">,</span> <span class="s2">&quot;onnx_dynamo-detailed&quot;</span><span class="p">}:</span>
            <span class="k">return</span> <span class="n">optimization</span> <span class="ow">in</span> <span class="p">{</span><span class="s2">&quot;default&quot;</span><span class="p">,</span> <span class="s2">&quot;ir&quot;</span><span class="p">}</span>
        <span class="k">return</span> <span class="kc">False</span></div>


    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">isinstance_namedtuple</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s2">&quot;_fields&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">_to_type_or_device</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">o</span><span class="p">,</span> <span class="n">dtype_or_device</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">dtype_or_device</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">o</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">o</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">o</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">o</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">[</span><span class="bp">cls</span><span class="o">.</span><span class="n">_to_type_or_device</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">dtype_or_device</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">o</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">o</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="bp">cls</span><span class="o">.</span><span class="n">_to_type_or_device</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">dtype_or_device</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">o</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">o</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dtype_or_device</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">or</span> <span class="n">o</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">in</span> <span class="p">{</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">,</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span>
            <span class="p">}:</span>
                <span class="k">return</span> <span class="n">o</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype_or_device</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">o</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">o</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="c1"># int gets ignored by torch.export.export</span>
            <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="n">o</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dtype_or_device</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="n">t</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype_or_device</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">t</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">o</span><span class="p">,</span> <span class="nb">bool</span><span class="p">):</span>
            <span class="c1"># int gets ignored by torch.export.export</span>
            <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="n">o</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dtype_or_device</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="n">t</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype_or_device</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">t</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">o</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
            <span class="c1"># int gets ignored by torch.export.export</span>
            <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="n">o</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dtype_or_device</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="n">t</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype_or_device</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">t</span>

        <span class="k">if</span> <span class="bp">cls</span><span class="o">.</span><span class="n">isinstance_namedtuple</span><span class="p">(</span><span class="n">o</span><span class="p">):</span>
            <span class="n">new_vals</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">o</span><span class="o">.</span><span class="n">_fields</span><span class="p">:</span>
                <span class="n">new_vals</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_to_type_or_device</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">o</span><span class="p">,</span> <span class="n">k</span><span class="p">),</span> <span class="n">dtype_or_device</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">o</span><span class="o">.</span><span class="vm">__class__</span><span class="p">(</span><span class="o">**</span><span class="n">new_vals</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">o</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;KeyedJaggedTensor&quot;</span><span class="p">):</span>
            <span class="n">ext</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
                <span class="n">weights</span><span class="o">=</span><span class="n">o</span><span class="o">.</span><span class="n">weights_or_none</span><span class="p">(),</span>
                <span class="n">values</span><span class="o">=</span><span class="n">o</span><span class="o">.</span><span class="n">values</span><span class="p">(),</span>
                <span class="n">offsets</span><span class="o">=</span><span class="n">o</span><span class="o">.</span><span class="n">offsets_or_none</span><span class="p">(),</span>
                <span class="n">keys</span><span class="o">=</span><span class="n">o</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span>
                <span class="c1"># index_per_key=o.index_per_key(),</span>
                <span class="n">length_per_key</span><span class="o">=</span><span class="n">o</span><span class="o">.</span><span class="n">length_per_key_or_none</span><span class="p">(),</span>
                <span class="n">lengths</span><span class="o">=</span><span class="n">o</span><span class="o">.</span><span class="n">lengths_or_none</span><span class="p">(),</span>
                <span class="c1"># stride_per_key=o.stride_per_key(),</span>
                <span class="n">stride_per_key_per_rank</span><span class="o">=</span><span class="n">o</span><span class="o">.</span><span class="n">stride_per_key_per_rank</span><span class="p">(),</span>
                <span class="c1"># variable_stride_per_key=o.variable_stride_per_key(),</span>
                <span class="n">offset_per_key</span><span class="o">=</span><span class="n">o</span><span class="o">.</span><span class="n">offset_per_key_or_none</span><span class="p">(),</span>
                <span class="n">inverse_indices</span><span class="o">=</span><span class="n">o</span><span class="o">.</span><span class="n">inverse_indices_or_none</span><span class="p">(),</span>
            <span class="p">)</span>
            <span class="n">ext</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_to_type_or_device</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">dtype_or_device</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">ext</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
            <span class="k">return</span> <span class="n">o</span><span class="o">.</span><span class="vm">__class__</span><span class="p">(</span><span class="o">**</span><span class="n">ext</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">o</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">res</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">o</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">res</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_to_type_or_device</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">dtype_or_device</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">res</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">o</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype_or_device</span><span class="p">)</span>
        <span class="k">except</span> <span class="p">(</span><span class="ne">AttributeError</span><span class="p">,</span> <span class="ne">AssertionError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AssertionError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Unable to convert class </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">o</span><span class="p">)</span><span class="si">}</span><span class="s2"> to </span><span class="si">{</span><span class="n">dtype_or_device</span><span class="si">}</span><span class="s2"> &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;(namedtuple=</span><span class="si">{</span><span class="bp">cls</span><span class="o">.</span><span class="n">isinstance_namedtuple</span><span class="p">(</span><span class="n">o</span><span class="p">)</span><span class="si">}</span><span class="s2">), o=</span><span class="si">{</span><span class="n">o</span><span class="si">}</span><span class="s2">)&quot;</span>
            <span class="p">)</span> <span class="kn">from</span> <span class="nn">e</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
        <span class="n">kw_inputs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
        <span class="n">device</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">dtype</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">warmup</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">repeat</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">suite</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">autocast</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">wrap_kind</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">nvtx</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">model_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">export_options</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">cvt</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">o</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_to_type_or_device</span><span class="p">(</span><span class="n">o</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>  <span class="c1"># noqa: E731</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">cvt</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">o</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_to_type_or_device</span><span class="p">(</span>  <span class="c1"># noqa: E731</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_to_type_or_device</span><span class="p">(</span><span class="n">o</span><span class="p">,</span> <span class="n">dtype</span><span class="p">),</span> <span class="n">device</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">cvt</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">inputs</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">cvt</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AssertionError</span> <span class="o">-</span> <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Input type is </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">kw_inputs</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">kw_inputs</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">cvt</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">kw_inputs</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="k">elif</span> <span class="n">kw_inputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AssertionError</span> <span class="o">-</span> <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Input type is </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">assert</span> <span class="ow">not</span> <span class="n">kw_inputs</span><span class="p">,</span> <span class="s2">&quot;Keyword inputs are not yet implemented.&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kw_inputs</span> <span class="o">=</span> <span class="n">kw_inputs</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="c1"># torch.export.export does not allow that.</span>
            <span class="n">sig</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">)</span>
            <span class="n">added</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">new_inputs</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">new_names</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">use_default</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">sig</span><span class="o">.</span><span class="n">parameters</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">:</span>
                    <span class="n">new_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="n">n</span><span class="p">])</span>
                    <span class="n">added</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="n">use_default</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                        <span class="n">UseDefaultValue</span><span class="o">.</span><span class="n">FALSE</span>
                        <span class="k">if</span> <span class="n">sig</span><span class="o">.</span><span class="n">parameters</span><span class="p">[</span><span class="n">n</span><span class="p">]</span><span class="o">.</span><span class="n">default</span> <span class="ow">is</span> <span class="n">inspect</span><span class="o">.</span><span class="n">_empty</span>
                        <span class="k">else</span> <span class="n">UseDefaultValue</span><span class="o">.</span><span class="n">BOTH</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">sig</span><span class="o">.</span><span class="n">parameters</span><span class="p">[</span><span class="n">n</span><span class="p">]</span><span class="o">.</span><span class="n">default</span> <span class="ow">is</span> <span class="n">inspect</span><span class="o">.</span><span class="n">_empty</span><span class="p">:</span>
                        <span class="c1"># probably one optional input</span>
                        <span class="k">continue</span>
                    <span class="n">new_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sig</span><span class="o">.</span><span class="n">parameters</span><span class="p">[</span><span class="n">n</span><span class="p">]</span><span class="o">.</span><span class="n">default</span><span class="p">)</span>
                    <span class="n">use_default</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">UseDefaultValue</span><span class="o">.</span><span class="n">TRUE</span><span class="p">)</span>
                <span class="n">new_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
            <span class="k">assert</span> <span class="n">added</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">),</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Unexpected input name in </span><span class="si">{</span><span class="nb">sorted</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span><span class="si">}</span><span class="s2"> and &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;parameters=</span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">sig</span><span class="o">.</span><span class="n">parameters</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">new_inputs</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">raw_input_names</span> <span class="o">=</span> <span class="n">new_names</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">raw_use_defaults</span> <span class="o">=</span> <span class="n">use_default</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">raw_input_names</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;input</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">))]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">raw_use_defaults</span> <span class="o">=</span> <span class="p">[</span>
                <span class="p">(</span><span class="n">UseDefaultValue</span><span class="o">.</span><span class="n">TRUE</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">UseDefaultValue</span><span class="o">.</span><span class="n">FALSE</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">inputs</span>
            <span class="p">]</span>

        <span class="n">config</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;config&quot;</span><span class="p">,</span> <span class="p">{})</span>
        <span class="n">to_tuple</span> <span class="o">=</span> <span class="ow">not</span> <span class="p">(</span><span class="nb">hasattr</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;to_tuple&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">config</span><span class="o">.</span><span class="n">to_tuple</span><span class="p">)</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="s2">&quot;AlexNet&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
            <span class="ow">and</span> <span class="s2">&quot;Mixer&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
        <span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">to_tuple</span><span class="p">,</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Model </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">model</span><span class="p">)</span><span class="si">}</span><span class="s2"> does not need to call &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;to_tuple, has config=</span><span class="si">{</span><span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;config&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="p">)</span>

        <span class="n">model_cvt</span> <span class="o">=</span> <span class="n">cvt</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
        <span class="k">del</span> <span class="n">model</span>
        <span class="k">if</span> <span class="n">wrap_kind</span> <span class="o">==</span> <span class="s2">&quot;nowrap&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model_cvt</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">wrap_kind</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Not implemented for wrap_kind=</span><span class="si">{</span><span class="n">wrap_kind</span><span class="si">!r}</span><span class="s2">&quot;</span>
            <span class="k">if</span> <span class="n">to_tuple</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">WrappedModelToTuple</span><span class="p">(</span><span class="n">model_cvt</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">WrappedModelBase</span><span class="p">(</span><span class="n">model_cvt</span><span class="p">)</span>

        <span class="k">assert</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span>
            <span class="ow">or</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
            <span class="ow">or</span> <span class="s2">&quot;cuda&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">device</span>
            <span class="ow">or</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_device</span><span class="p">()</span> <span class="o">&gt;=</span> <span class="mi">0</span>
        <span class="p">),</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;device=</span><span class="si">{</span><span class="n">device</span><span class="si">!r}</span><span class="s2"> but input device is </span><span class="si">{</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_device</span><span class="p">()</span><span class="si">}</span><span class="s2"> &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;(check </span><span class="si">{</span><span class="n">cvt</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">get_device</span><span class="p">()</span><span class="si">}</span><span class="s2">)&quot;</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">repeat</span> <span class="o">=</span> <span class="n">repeat</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">warmup</span> <span class="o">=</span> <span class="n">warmup</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">suite</span> <span class="o">=</span> <span class="n">suite</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">autocast</span> <span class="o">=</span> <span class="n">autocast</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span> <span class="o">=</span> <span class="n">model_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nvtx</span> <span class="o">=</span> <span class="n">nvtx</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">export_options</span> <span class="o">=</span> <span class="n">export_options</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">autocast</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">std_to_dump</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">input_names</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">raw_input_names</span>

<div class="viewcode-block" id="ModelRunner.is_lm">
<a class="viewcode-back" href="../../../api/torch_bench/_bash_bench_model_runner.html#experimental_experiment.torch_bench._bash_bench_model_runner.ModelRunner.is_lm">[docs]</a>
    <span class="k">def</span> <span class="nf">is_lm</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns True if the model is a language model.</span>
<span class="sd">        In that case, the dynamic dimensions with the two first ones.</span>
<span class="sd">        This test relies on the model name.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">return</span> <span class="s2">&quot;LM&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span></div>


<div class="viewcode-block" id="ModelRunner.get_dynamic_shapes">
<a class="viewcode-back" href="../../../api/torch_bench/_bash_bench_model_runner.html#experimental_experiment.torch_bench._bash_bench_model_runner.ModelRunner.get_dynamic_shapes">[docs]</a>
    <span class="k">def</span> <span class="nf">get_dynamic_shapes</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">dynamic</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">wrapped</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">input_names</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">]]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns dynamic shapes specifying the first dimension as dynamic.</span>

<span class="sd">        :param dynamic: make it dynamic or not</span>
<span class="sd">        :param wrapped: the model is wrapped into a class defining forward method</span>
<span class="sd">            as ``forward(self, *args, **kargs)``</span>
<span class="sd">        :param input_names: to overwrite the input names,</span>
<span class="sd">            (not used)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">dynamic</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">input_names</span> <span class="ow">is</span> <span class="kc">None</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;This method is not implemented if input_names=</span><span class="si">{</span><span class="n">input_names</span><span class="si">!r}</span><span class="s2">&quot;</span>
        <span class="k">assert</span> <span class="n">input_names</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_names</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">),</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Unexpected number of input_names </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">input_names</span><span class="p">)</span><span class="si">}</span><span class="s2"> != &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">)</span><span class="si">}</span><span class="s2"> (expected), input_names=</span><span class="si">{</span><span class="n">input_names</span><span class="si">!r}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

        <span class="n">batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">export</span><span class="o">.</span><span class="n">Dim</span><span class="p">(</span><span class="s2">&quot;batch&quot;</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">1024</span><span class="p">)</span>
        <span class="n">seq_length</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">export</span><span class="o">.</span><span class="n">Dim</span><span class="p">(</span><span class="s2">&quot;seql&quot;</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">131072</span><span class="p">)</span> <span class="o">*</span> <span class="mi">8</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_lm</span><span class="p">()</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="p">)</span>
        <span class="n">res</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">)):</span>
                <span class="n">res</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
                <span class="k">continue</span>

            <span class="n">dyn_dims</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="n">batch</span><span class="p">}</span>
            <span class="k">if</span> <span class="n">seq_length</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">dyn_dims</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="mi">1</span><span class="p">:</span> <span class="n">seq_length</span><span class="p">})</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span>
                    <span class="n">_</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">x</span>
                <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Unsupported types in a list </span><span class="si">{</span><span class="p">[</span><span class="nb">type</span><span class="p">(</span><span class="n">_</span><span class="p">)</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">_</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">x</span><span class="p">]</span><span class="si">}</span><span class="s2"> at position </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="n">tries</span> <span class="o">=</span> <span class="p">[</span><span class="n">dyn_dims</span> <span class="k">if</span> <span class="n">_</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">_</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">x</span><span class="p">]</span>
                <span class="n">res</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tries</span><span class="p">)</span>
                <span class="k">continue</span>
            <span class="k">assert</span> <span class="nb">hasattr</span><span class="p">(</span>
                <span class="n">x</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span>
            <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Unexpected type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="si">}</span><span class="s2"> for input </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="n">res</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dyn_dims</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>

        <span class="n">final</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">wrapped</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">final</span><span class="p">,)</span>
        <span class="k">return</span> <span class="n">final</span></div>


<div class="viewcode-block" id="ModelRunner.dump_std">
<a class="viewcode-back" href="../../../api/torch_bench/_bash_bench_model_runner.html#experimental_experiment.torch_bench._bash_bench_model_runner.ModelRunner.dump_std">[docs]</a>
    <span class="k">def</span> <span class="nf">dump_std</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Dumps some information in the given filename.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">std_to_dump</span><span class="p">:</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">std_to_dump</span><span class="p">)))</span></div>


    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">autocast</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">nvtx</span><span class="p">:</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">nvtx</span><span class="o">.</span><span class="n">range_push</span><span class="p">(</span><span class="s2">&quot;ModelRunner.Eager.AutoCast&quot;</span><span class="p">)</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span><span class="n">device_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">):</span>
                <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">nvtx</span><span class="p">:</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">nvtx</span><span class="o">.</span><span class="n">range_pop</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">res</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">nvtx</span><span class="p">:</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">nvtx</span><span class="o">.</span><span class="n">range_push</span><span class="p">(</span><span class="s2">&quot;ModelRunner.Eager&quot;</span><span class="p">)</span>
        <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">nvtx</span><span class="p">:</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">nvtx</span><span class="o">.</span><span class="n">range_pop</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">res</span>

    <span class="k">def</span> <span class="nf">run_dynamic</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">wrapped</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="n">dynamic_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_dynamic_inputs</span><span class="p">(</span><span class="n">wrapped</span><span class="o">=</span><span class="n">wrapped</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">autocast</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">nvtx</span><span class="p">:</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">nvtx</span><span class="o">.</span><span class="n">range_push</span><span class="p">(</span><span class="s2">&quot;ModelRunner.Eager.AutoCast.dynamic&quot;</span><span class="p">)</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span><span class="n">device_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">):</span>
                <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="o">*</span><span class="n">dynamic_inputs</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">nvtx</span><span class="p">:</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">nvtx</span><span class="o">.</span><span class="n">range_pop</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">res</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">nvtx</span><span class="p">:</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">nvtx</span><span class="o">.</span><span class="n">range_push</span><span class="p">(</span><span class="s2">&quot;ModelRunner.Eager.Dynamic&quot;</span><span class="p">)</span>
        <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="o">*</span><span class="n">dynamic_inputs</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">nvtx</span><span class="p">:</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">nvtx</span><span class="o">.</span><span class="n">range_pop</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">res</span>

<div class="viewcode-block" id="ModelRunner.compute_weight_size">
<a class="viewcode-back" href="../../../api/torch_bench/_bash_bench_model_runner.html#experimental_experiment.torch_bench._bash_bench_model_runner.ModelRunner.compute_weight_size">[docs]</a>
    <span class="k">def</span> <span class="nf">compute_weight_size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the weight size.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">compute_weight_size</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span></div>


<div class="viewcode-block" id="ModelRunner.parameters_dtype">
<a class="viewcode-back" href="../../../api/torch_bench/_bash_bench_model_runner.html#experimental_experiment.torch_bench._bash_bench_model_runner.ModelRunner.parameters_dtype">[docs]</a>
    <span class="k">def</span> <span class="nf">parameters_dtype</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the unique dtypes of all parameters.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;parameters&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="s2">&quot;&quot;</span>
        <span class="k">return</span> <span class="s2">&quot;,&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
            <span class="nb">sorted</span><span class="p">({</span><span class="nb">str</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;torch.&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()})</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="ModelRunner.export_as">
<a class="viewcode-back" href="../../../api/torch_bench/_bash_bench_model_runner.html#experimental_experiment.torch_bench._bash_bench_model_runner.ModelRunner.export_as">[docs]</a>
    <span class="k">def</span> <span class="nf">export_as</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">exporter</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">dynamic</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">fake_tensor</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">no_grad</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">optimization</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">target_opset</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">onnx</span><span class="o">.</span><span class="n">ModelProto</span><span class="p">,</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Converts a model into onnx.</span>

<span class="sd">        :param exporter: exporter</span>
<span class="sd">        :param name: filename</span>
<span class="sd">        :param dynamic: use dynamic shape</span>
<span class="sd">        :param fake_tensor: use fake_tensor</span>
<span class="sd">        :param no_grad: use no_grad</span>
<span class="sd">        :param optimization: defines the optimizations</span>
<span class="sd">        :param verbose: verbosity</span>
<span class="sd">        :param target_opset: target opset</span>
<span class="sd">        :return: the model proto with or without weights, statistics</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="ow">not</span> <span class="n">fake_tensor</span><span class="p">,</span> <span class="s2">&quot;fake_tensor not implemented.&quot;</span>

        <span class="k">if</span> <span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;1001Fail&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model </span><span class="si">{</span><span class="n">name</span><span class="si">!r}</span><span class="s2"> is meant to fail for unit test purpose.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="s2">&quot;-&quot;</span> <span class="ow">in</span> <span class="n">exporter</span><span class="p">:</span>
            <span class="n">spl</span> <span class="o">=</span> <span class="n">exporter</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="p">,</span> <span class="n">maxsplit</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">spl</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Unexpected name=</span><span class="si">{</span><span class="n">exporter</span><span class="si">!r}</span><span class="s2"> for the exporter&quot;</span>
            <span class="n">exporter</span><span class="p">,</span> <span class="n">strategy</span> <span class="o">=</span> <span class="n">spl</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">strategy</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;[ModelRunner.export_as] exporter=</span><span class="si">{</span><span class="n">exporter</span><span class="si">!r}</span><span class="s2"> &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;strategy=</span><span class="si">{</span><span class="n">strategy</span><span class="si">!r}</span><span class="s2"> optimization=</span><span class="si">{</span><span class="n">optimization</span><span class="si">!r}</span><span class="s2"> &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;n_inputs=</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;[ModelRunner.export_as] fake_tensor=</span><span class="si">{</span><span class="n">fake_tensor</span><span class="si">}</span><span class="s2"> dynamic=</span><span class="si">{</span><span class="n">dynamic</span><span class="si">}</span><span class="s2"> &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;target_opset=</span><span class="si">{</span><span class="n">target_opset</span><span class="si">}</span><span class="s2"> no_grad=</span><span class="si">{</span><span class="n">no_grad</span><span class="si">}</span><span class="s2"> name=</span><span class="si">{</span><span class="n">name</span><span class="si">!r}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[ModelRunner.export_as] use_raw_default=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_use_defaults</span><span class="si">!r}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">exporter</span> <span class="o">==</span> <span class="s2">&quot;custom&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_to_onnx_custom</span><span class="p">(</span>
                <span class="n">name</span><span class="p">,</span>
                <span class="n">dynamic</span><span class="o">=</span><span class="n">dynamic</span><span class="p">,</span>
                <span class="n">fake_tensor</span><span class="o">=</span><span class="n">fake_tensor</span><span class="p">,</span>
                <span class="n">no_grad</span><span class="o">=</span><span class="n">no_grad</span><span class="p">,</span>
                <span class="n">optimization</span><span class="o">=</span><span class="n">optimization</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
                <span class="n">target_opset</span><span class="o">=</span><span class="n">target_opset</span><span class="p">,</span>
                <span class="n">strategy</span><span class="o">=</span><span class="n">strategy</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">exporter</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;cort&quot;</span><span class="p">,</span> <span class="s2">&quot;cortgrad&quot;</span><span class="p">):</span>
            <span class="k">assert</span> <span class="n">strategy</span> <span class="ow">in</span> <span class="p">(</span>
                <span class="kc">None</span><span class="p">,</span>
                <span class="s2">&quot;none&quot;</span><span class="p">,</span>
            <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;strategy=</span><span class="si">{</span><span class="n">strategy</span><span class="si">!r}</span><span class="s2"> not implemented for </span><span class="si">{</span><span class="n">exporter</span><span class="si">!r}</span><span class="s2">&quot;</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_to_cort</span><span class="p">(</span>
                <span class="n">name</span><span class="p">,</span>
                <span class="n">dynamic</span><span class="o">=</span><span class="n">dynamic</span><span class="p">,</span>
                <span class="n">fake_tensor</span><span class="o">=</span><span class="n">fake_tensor</span><span class="p">,</span>
                <span class="n">no_grad</span><span class="o">=</span><span class="n">no_grad</span><span class="p">,</span>
                <span class="n">optimization</span><span class="o">=</span><span class="n">optimization</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
                <span class="n">target_opset</span><span class="o">=</span><span class="n">target_opset</span><span class="p">,</span>
                <span class="n">autograd</span><span class="o">=</span><span class="n">exporter</span> <span class="o">==</span> <span class="s2">&quot;cortgrad&quot;</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">exporter</span> <span class="o">==</span> <span class="s2">&quot;torch_script&quot;</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">strategy</span> <span class="ow">in</span> <span class="p">(</span>
                <span class="kc">None</span><span class="p">,</span>
                <span class="s2">&quot;none&quot;</span><span class="p">,</span>
            <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;strategy=</span><span class="si">{</span><span class="n">strategy</span><span class="si">!r}</span><span class="s2"> not implemented for </span><span class="si">{</span><span class="n">exporter</span><span class="si">!r}</span><span class="s2">&quot;</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_to_torchscript</span><span class="p">(</span>
                <span class="n">name</span><span class="p">,</span>
                <span class="n">dynamic</span><span class="o">=</span><span class="n">dynamic</span><span class="p">,</span>
                <span class="n">fake_tensor</span><span class="o">=</span><span class="n">fake_tensor</span><span class="p">,</span>
                <span class="n">no_grad</span><span class="o">=</span><span class="n">no_grad</span><span class="p">,</span>
                <span class="n">optimization</span><span class="o">=</span><span class="n">optimization</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
                <span class="n">target_opset</span><span class="o">=</span><span class="n">target_opset</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">exporter</span> <span class="o">==</span> <span class="s2">&quot;onnx_dynamo&quot;</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">strategy</span> <span class="ow">in</span> <span class="p">(</span>
                <span class="kc">None</span><span class="p">,</span>
                <span class="s2">&quot;none&quot;</span><span class="p">,</span>
                <span class="s2">&quot;fallback&quot;</span><span class="p">,</span>
                <span class="s2">&quot;detailed&quot;</span><span class="p">,</span>
            <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;strategy=</span><span class="si">{</span><span class="n">strategy</span><span class="si">!r}</span><span class="s2"> not implemented for </span><span class="si">{</span><span class="n">exporter</span><span class="si">!r}</span><span class="s2">&quot;</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_to_onnx_dynamo</span><span class="p">(</span>
                <span class="n">name</span><span class="p">,</span>
                <span class="n">dynamic</span><span class="o">=</span><span class="n">dynamic</span><span class="p">,</span>
                <span class="n">fake_tensor</span><span class="o">=</span><span class="n">fake_tensor</span><span class="p">,</span>
                <span class="n">no_grad</span><span class="o">=</span><span class="n">no_grad</span><span class="p">,</span>
                <span class="n">optimization</span><span class="o">=</span><span class="n">optimization</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
                <span class="n">target_opset</span><span class="o">=</span><span class="n">target_opset</span><span class="p">,</span>
                <span class="n">detailed</span><span class="o">=</span><span class="n">strategy</span> <span class="o">==</span> <span class="s2">&quot;detailed&quot;</span><span class="p">,</span>
                <span class="n">fallback</span><span class="o">=</span><span class="n">strategy</span> <span class="o">==</span> <span class="s2">&quot;fallback&quot;</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">exporter</span> <span class="o">==</span> <span class="s2">&quot;dynamo_export&quot;</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">strategy</span> <span class="ow">in</span> <span class="p">(</span>
                <span class="kc">None</span><span class="p">,</span>
                <span class="s2">&quot;none&quot;</span><span class="p">,</span>
            <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;strategy=</span><span class="si">{</span><span class="n">strategy</span><span class="si">!r}</span><span class="s2"> not implemented for </span><span class="si">{</span><span class="n">exporter</span><span class="si">!r}</span><span class="s2">&quot;</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_to_dynamo_export</span><span class="p">(</span>
                <span class="n">name</span><span class="p">,</span>
                <span class="n">dynamic</span><span class="o">=</span><span class="n">dynamic</span><span class="p">,</span>
                <span class="n">fake_tensor</span><span class="o">=</span><span class="n">fake_tensor</span><span class="p">,</span>
                <span class="n">no_grad</span><span class="o">=</span><span class="n">no_grad</span><span class="p">,</span>
                <span class="n">optimization</span><span class="o">=</span><span class="n">optimization</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
                <span class="n">target_opset</span><span class="o">=</span><span class="n">target_opset</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">exporter</span> <span class="o">==</span> <span class="s2">&quot;eager&quot;</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">strategy</span> <span class="ow">in</span> <span class="p">(</span>
                <span class="kc">None</span><span class="p">,</span>
                <span class="s2">&quot;none&quot;</span><span class="p">,</span>
            <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;strategy=</span><span class="si">{</span><span class="n">strategy</span><span class="si">!r}</span><span class="s2"> not implemented for </span><span class="si">{</span><span class="n">exporter</span><span class="si">!r}</span><span class="s2">&quot;</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_to_eager</span><span class="p">(</span>
                <span class="n">name</span><span class="p">,</span>
                <span class="n">dynamic</span><span class="o">=</span><span class="n">dynamic</span><span class="p">,</span>
                <span class="n">fake_tensor</span><span class="o">=</span><span class="n">fake_tensor</span><span class="p">,</span>
                <span class="n">no_grad</span><span class="o">=</span><span class="n">no_grad</span><span class="p">,</span>
                <span class="n">optimization</span><span class="o">=</span><span class="n">optimization</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">exporter</span> <span class="o">==</span> <span class="s2">&quot;compile&quot;</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">strategy</span> <span class="ow">in</span> <span class="p">(</span>
                <span class="kc">None</span><span class="p">,</span>
                <span class="s2">&quot;none&quot;</span><span class="p">,</span>
            <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;strategy=</span><span class="si">{</span><span class="n">strategy</span><span class="si">!r}</span><span class="s2"> not implemented for </span><span class="si">{</span><span class="n">exporter</span><span class="si">!r}</span><span class="s2">&quot;</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_to_compile</span><span class="p">(</span>
                <span class="n">name</span><span class="p">,</span>
                <span class="n">dynamic</span><span class="o">=</span><span class="n">dynamic</span><span class="p">,</span>
                <span class="n">fake_tensor</span><span class="o">=</span><span class="n">fake_tensor</span><span class="p">,</span>
                <span class="n">no_grad</span><span class="o">=</span><span class="n">no_grad</span><span class="p">,</span>
                <span class="n">optimization</span><span class="o">=</span><span class="n">optimization</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">exporter</span> <span class="o">==</span> <span class="s2">&quot;export&quot;</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">strategy</span> <span class="ow">in</span> <span class="p">{</span>
                <span class="kc">None</span><span class="p">,</span>
                <span class="s2">&quot;default&quot;</span><span class="p">,</span>
                <span class="s2">&quot;nostrict&quot;</span><span class="p">,</span>
                <span class="s2">&quot;none&quot;</span><span class="p">,</span>
                <span class="s2">&quot;fallback&quot;</span><span class="p">,</span>
                <span class="s2">&quot;fallback-default&quot;</span><span class="p">,</span>
                <span class="s2">&quot;jit&quot;</span><span class="p">,</span>
            <span class="p">},</span> <span class="sa">f</span><span class="s2">&quot;strategy=</span><span class="si">{</span><span class="n">strategy</span><span class="si">!r}</span><span class="s2"> not implemented for </span><span class="si">{</span><span class="n">exporter</span><span class="si">!r}</span><span class="s2">&quot;</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_to_export</span><span class="p">(</span>
                <span class="n">name</span><span class="p">,</span>
                <span class="n">dynamic</span><span class="o">=</span><span class="n">dynamic</span><span class="p">,</span>
                <span class="n">fake_tensor</span><span class="o">=</span><span class="n">fake_tensor</span><span class="p">,</span>
                <span class="n">no_grad</span><span class="o">=</span><span class="n">no_grad</span><span class="p">,</span>
                <span class="n">optimization</span><span class="o">=</span><span class="n">optimization</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
                <span class="n">strategy</span><span class="o">=</span><span class="n">strategy</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">exporter</span> <span class="o">==</span> <span class="s2">&quot;executorch&quot;</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">strategy</span> <span class="ow">in</span> <span class="p">{</span>
                <span class="kc">None</span><span class="p">,</span>
                <span class="s2">&quot;default&quot;</span><span class="p">,</span>
                <span class="s2">&quot;nostrict&quot;</span><span class="p">,</span>
                <span class="s2">&quot;none&quot;</span><span class="p">,</span>
                <span class="s2">&quot;fallback&quot;</span><span class="p">,</span>
                <span class="s2">&quot;fallback-default&quot;</span><span class="p">,</span>
                <span class="s2">&quot;jit&quot;</span><span class="p">,</span>
            <span class="p">},</span> <span class="sa">f</span><span class="s2">&quot;strategy=</span><span class="si">{</span><span class="n">strategy</span><span class="si">!r}</span><span class="s2"> not implemented for </span><span class="si">{</span><span class="n">exporter</span><span class="si">!r}</span><span class="s2">&quot;</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_to_executorch</span><span class="p">(</span>
                <span class="n">name</span><span class="p">,</span>
                <span class="n">dynamic</span><span class="o">=</span><span class="n">dynamic</span><span class="p">,</span>
                <span class="n">fake_tensor</span><span class="o">=</span><span class="n">fake_tensor</span><span class="p">,</span>
                <span class="n">no_grad</span><span class="o">=</span><span class="n">no_grad</span><span class="p">,</span>
                <span class="n">optimization</span><span class="o">=</span><span class="n">optimization</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
                <span class="n">strategy</span><span class="o">=</span><span class="n">strategy</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">exporter</span> <span class="o">==</span> <span class="s2">&quot;inductor&quot;</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">strategy</span> <span class="ow">in</span> <span class="p">(</span>
                <span class="kc">None</span><span class="p">,</span>
                <span class="s2">&quot;partial&quot;</span><span class="p">,</span>
                <span class="s2">&quot;none&quot;</span><span class="p">,</span>
            <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;strategy=</span><span class="si">{</span><span class="n">strategy</span><span class="si">!r}</span><span class="s2"> not implemented for </span><span class="si">{</span><span class="n">exporter</span><span class="si">!r}</span><span class="s2">&quot;</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_to_inductor</span><span class="p">(</span>
                <span class="n">name</span><span class="p">,</span>
                <span class="n">dynamic</span><span class="o">=</span><span class="n">dynamic</span><span class="p">,</span>
                <span class="n">fake_tensor</span><span class="o">=</span><span class="n">fake_tensor</span><span class="p">,</span>
                <span class="n">no_grad</span><span class="o">=</span><span class="n">no_grad</span><span class="p">,</span>
                <span class="n">optimization</span><span class="o">=</span><span class="n">optimization</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
                <span class="n">fullgraph</span><span class="o">=</span><span class="n">strategy</span> <span class="o">!=</span> <span class="s2">&quot;partial&quot;</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">exporter</span> <span class="o">==</span> <span class="s2">&quot;dort&quot;</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">strategy</span> <span class="ow">in</span> <span class="p">(</span>
                <span class="kc">None</span><span class="p">,</span>
                <span class="s2">&quot;none&quot;</span><span class="p">,</span>
            <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;strategy=</span><span class="si">{</span><span class="n">strategy</span><span class="si">!r}</span><span class="s2"> not implemented for </span><span class="si">{</span><span class="n">exporter</span><span class="si">!r}</span><span class="s2">&quot;</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_to_dort</span><span class="p">(</span>
                <span class="n">name</span><span class="p">,</span>
                <span class="n">dynamic</span><span class="o">=</span><span class="n">dynamic</span><span class="p">,</span>
                <span class="n">fake_tensor</span><span class="o">=</span><span class="n">fake_tensor</span><span class="p">,</span>
                <span class="n">no_grad</span><span class="o">=</span><span class="n">no_grad</span><span class="p">,</span>
                <span class="n">optimization</span><span class="o">=</span><span class="n">optimization</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
                <span class="n">target_opset</span><span class="o">=</span><span class="n">target_opset</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">exporter</span> <span class="o">==</span> <span class="s2">&quot;ORTModule&quot;</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">strategy</span> <span class="ow">in</span> <span class="p">(</span>
                <span class="kc">None</span><span class="p">,</span>
                <span class="s2">&quot;none&quot;</span><span class="p">,</span>
            <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;strategy=</span><span class="si">{</span><span class="n">strategy</span><span class="si">!r}</span><span class="s2"> not implemented for </span><span class="si">{</span><span class="n">exporter</span><span class="si">!r}</span><span class="s2">&quot;</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_to_ortmodule</span><span class="p">(</span>
                <span class="n">name</span><span class="p">,</span>
                <span class="n">dynamic</span><span class="o">=</span><span class="n">dynamic</span><span class="p">,</span>
                <span class="n">fake_tensor</span><span class="o">=</span><span class="n">fake_tensor</span><span class="p">,</span>
                <span class="n">no_grad</span><span class="o">=</span><span class="n">no_grad</span><span class="p">,</span>
                <span class="n">optimization</span><span class="o">=</span><span class="n">optimization</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
                <span class="n">target_opset</span><span class="o">=</span><span class="n">target_opset</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">raise</span> <span class="ne">AssertionError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Exporter </span><span class="si">{</span><span class="n">exporter</span><span class="si">!r}</span><span class="s2"> is not implemented.&quot;</span><span class="p">)</span></div>


    <span class="k">def</span> <span class="nf">_to_onnx_custom</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">dynamic</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">fake_tensor</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">no_grad</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">optimization</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">target_opset</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">strategy</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">assert</span> <span class="ow">not</span> <span class="n">fake_tensor</span><span class="p">,</span> <span class="s2">&quot;fake_tensor not implemented.&quot;</span>
        <span class="k">assert</span> <span class="n">no_grad</span><span class="p">,</span> <span class="s2">&quot;no_grad false not implemented yet&quot;</span>
        <span class="kn">from</span> <span class="nn">..torch_interpreter</span> <span class="kn">import</span> <span class="n">to_onnx</span><span class="p">,</span> <span class="n">ExportOptions</span>
        <span class="kn">from</span> <span class="nn">..xbuilder</span> <span class="kn">import</span> <span class="n">OptimizationOptions</span>

        <span class="k">if</span> <span class="n">optimization</span> <span class="ow">and</span> <span class="n">optimization</span> <span class="o">!=</span> <span class="s2">&quot;none&quot;</span><span class="p">:</span>
            <span class="c1"># cuda = any(m.is_cuda for m in self.model.parameters())</span>
            <span class="n">options</span> <span class="o">=</span> <span class="n">OptimizationOptions</span><span class="p">(</span>
                <span class="n">constant_folding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">patterns</span><span class="o">=</span><span class="n">optimization</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="mi">10</span> <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;=</span> <span class="mi">100</span> <span class="k">else</span> <span class="p">(</span><span class="mi">1</span> <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="mi">0</span><span class="p">),</span>
                <span class="n">processor</span><span class="o">=</span><span class="s2">&quot;CUDA&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="s2">&quot;CPU&quot;</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">options</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="n">export_options</span> <span class="o">=</span> <span class="n">ExportOptions</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="n">strategy</span><span class="p">,</span> <span class="o">**</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">export_options</span> <span class="ow">or</span> <span class="p">{}))</span>
        <span class="n">export_inputs</span><span class="p">,</span> <span class="n">export_kw_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_export_inputs</span><span class="p">(</span><span class="n">dynamic</span><span class="p">)</span>
        <span class="n">dyn_shapes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_dynamic_shapes</span><span class="p">(</span><span class="n">dynamic</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[ModelRunner._to_onnx_custom] dynamic_shapes=</span><span class="si">{</span><span class="n">dyn_shapes</span><span class="si">!r}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[ModelRunner._to_onnx_custom] type(model)=</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span><span class="si">!r}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;[ModelRunner._to_onnx_custom] export_inputs=</span><span class="si">{</span><span class="n">string_type</span><span class="p">(</span><span class="n">export_inputs</span><span class="p">)</span><span class="si">!r}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;[ModelRunner._to_onnx_custom] export_kw_inputs=&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">string_type</span><span class="p">(</span><span class="n">export_kw_inputs</span><span class="p">)</span><span class="si">!r}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[ModelRunner._to_onnx_custom] self.export_options=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">export_options</span><span class="si">!r}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[ModelRunner._to_onnx_custom] export_options=</span><span class="si">{</span><span class="n">export_options</span><span class="si">!r}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">autocast</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span>
                <span class="n">device_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span>
            <span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">(),</span> <span class="n">bypass_export_some_errors</span><span class="p">():</span>
                <span class="n">onx</span><span class="p">,</span> <span class="n">builder</span><span class="p">,</span> <span class="n">stats</span> <span class="o">=</span> <span class="n">to_onnx</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                    <span class="n">export_inputs</span><span class="p">,</span>
                    <span class="n">export_kw_inputs</span><span class="p">,</span>
                    <span class="n">optimize</span><span class="o">=</span><span class="nb">bool</span><span class="p">(</span><span class="n">optimization</span><span class="p">),</span>
                    <span class="n">large_model</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">verbose</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">verbose</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
                    <span class="n">target_opset</span><span class="o">=</span><span class="n">target_opset</span><span class="p">,</span>
                    <span class="n">return_optimize_report</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">options</span><span class="o">=</span><span class="n">options</span><span class="p">,</span>
                    <span class="n">return_builder</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">dynamic_shapes</span><span class="o">=</span><span class="n">dyn_shapes</span><span class="p">,</span>
                    <span class="n">export_options</span><span class="o">=</span><span class="n">export_options</span><span class="p">,</span>
                    <span class="n">inline</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">(),</span> <span class="n">bypass_export_some_errors</span><span class="p">():</span>
                <span class="n">onx</span><span class="p">,</span> <span class="n">builder</span><span class="p">,</span> <span class="n">stats</span> <span class="o">=</span> <span class="n">to_onnx</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                    <span class="n">export_inputs</span><span class="p">,</span>
                    <span class="n">export_kw_inputs</span><span class="p">,</span>
                    <span class="n">optimize</span><span class="o">=</span><span class="nb">bool</span><span class="p">(</span><span class="n">optimization</span><span class="p">),</span>
                    <span class="n">large_model</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">verbose</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">verbose</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
                    <span class="n">target_opset</span><span class="o">=</span><span class="n">target_opset</span><span class="p">,</span>
                    <span class="n">return_optimize_report</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">options</span><span class="o">=</span><span class="n">options</span><span class="p">,</span>
                    <span class="n">return_builder</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">dynamic_shapes</span><span class="o">=</span><span class="n">dyn_shapes</span><span class="p">,</span>
                    <span class="n">export_options</span><span class="o">=</span><span class="n">export_options</span><span class="p">,</span>
                    <span class="n">inline</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="p">)</span>
        <span class="n">begin</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">std_to_dump</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pprint</span><span class="o">.</span><span class="n">pformat</span><span class="p">(</span><span class="n">stats</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">std_to_dump</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;----------------------------&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">std_to_dump</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">builder</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="mi">24</span><span class="p">))</span>
        <span class="n">stats</span><span class="p">[</span><span class="s2">&quot;time_export_debuginfo&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">begin</span>
        <span class="n">begin</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
        <span class="n">onx</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">all_tensors_to_one_file</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">stats</span><span class="p">[</span><span class="s2">&quot;time_export_save&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">begin</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">onx</span><span class="o">.</span><span class="n">_stats</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">v</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">stats</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
        <span class="k">return</span> <span class="n">onx</span><span class="o">.</span><span class="n">model_proto</span><span class="p">,</span> <span class="n">stats</span>

    <span class="k">def</span> <span class="nf">_to_cort</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">dynamic</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">fake_tensor</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">no_grad</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">optimization</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">target_opset</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">autograd</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">assert</span> <span class="ow">not</span> <span class="n">fake_tensor</span><span class="p">,</span> <span class="s2">&quot;fake_tensor not implemented.&quot;</span>
        <span class="k">assert</span> <span class="ow">not</span> <span class="n">dynamic</span><span class="p">,</span> <span class="s2">&quot;dynamic true not implemented yet&quot;</span>
        <span class="k">assert</span> <span class="n">no_grad</span><span class="p">,</span> <span class="s2">&quot;no_grad true not implemented yet&quot;</span>
        <span class="kn">from</span> <span class="nn">..xbuilder</span> <span class="kn">import</span> <span class="n">OptimizationOptions</span>
        <span class="kn">from</span> <span class="nn">..torch_dynamo</span> <span class="kn">import</span> <span class="n">onnx_custom_backend</span><span class="p">,</span> <span class="n">get_decomposition_table</span>

        <span class="k">if</span> <span class="n">optimization</span><span class="p">:</span>
            <span class="c1"># cuda = any(m.is_cuda for m in self.model.parameters())</span>
            <span class="n">options</span> <span class="o">=</span> <span class="n">OptimizationOptions</span><span class="p">(</span>
                <span class="n">constant_folding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">patterns</span><span class="o">=</span><span class="n">optimization</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="mi">10</span> <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;=</span> <span class="mi">100</span> <span class="k">else</span> <span class="p">(</span><span class="mi">1</span> <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="mi">0</span><span class="p">),</span>
                <span class="n">processor</span><span class="o">=</span><span class="s2">&quot;CUDA&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="s2">&quot;CPU&quot;</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">options</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="n">cbff</span> <span class="o">=</span> <span class="k">lambda</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">onnx_custom_backend</span><span class="p">(</span>  <span class="c1"># noqa: E731</span>
            <span class="o">*</span><span class="n">args</span><span class="p">,</span>
            <span class="n">target_opset</span><span class="o">=</span><span class="n">target_opset</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">options</span><span class="o">=</span><span class="n">options</span><span class="p">,</span>
            <span class="n">optimize</span><span class="o">=</span><span class="nb">bool</span><span class="p">(</span><span class="n">optimization</span><span class="p">),</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">autograd</span><span class="p">:</span>
            <span class="kn">from</span> <span class="nn">torch._dynamo.backends.common</span> <span class="kn">import</span> <span class="n">aot_autograd</span>

            <span class="n">cbf</span> <span class="o">=</span> <span class="n">aot_autograd</span><span class="p">(</span><span class="n">fw_compiler</span><span class="o">=</span><span class="n">cbff</span><span class="p">,</span> <span class="n">decompositions</span><span class="o">=</span><span class="n">get_decomposition_table</span><span class="p">())</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">autocast</span><span class="p">:</span>
                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span><span class="n">device_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">):</span>
                    <span class="n">res</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="n">cbf</span><span class="p">,</span> <span class="n">fullgraph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">res</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="n">cbf</span><span class="p">,</span> <span class="n">fullgraph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">autocast</span><span class="p">:</span>
                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span>
                    <span class="n">device_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span>
                <span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                    <span class="n">res</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="n">cbff</span><span class="p">,</span> <span class="n">fullgraph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                    <span class="n">res</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="n">cbff</span><span class="p">,</span> <span class="n">fullgraph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">res</span><span class="p">,</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">_optimize_rewrite</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">optimization</span><span class="p">:</span> <span class="nb">str</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">onnx</span><span class="o">.</span><span class="n">ModelProto</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
        <span class="n">stats</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">begin</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
        <span class="n">shutil</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;.raw.onnx&quot;</span><span class="p">)</span>
        <span class="n">model_proto</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">load_external_data</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">rule_sets</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">opts</span> <span class="o">=</span> <span class="n">optimization</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;+&quot;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">opt</span> <span class="ow">in</span> <span class="n">opts</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">opt</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="s2">&quot;-&quot;</span><span class="p">,</span> <span class="s2">&quot;none&quot;</span><span class="p">):</span>
                <span class="k">continue</span>
            <span class="k">if</span> <span class="n">opt</span> <span class="o">==</span> <span class="s2">&quot;default&quot;</span><span class="p">:</span>
                <span class="c1"># from onnx.inliner import inline_local_functions</span>
                <span class="kn">from</span> <span class="nn">onnxscript.optimizer</span> <span class="kn">import</span> <span class="n">optimize</span>
                <span class="kn">from</span> <span class="nn">onnxscript.rewriter</span> <span class="kn">import</span> <span class="n">rewrite</span>

                <span class="n">first_model_proto</span> <span class="o">=</span> <span class="n">model_proto</span>
                <span class="n">model_proto</span> <span class="o">=</span> <span class="n">optimize</span><span class="p">(</span>
                    <span class="n">model_proto</span><span class="p">,</span>
                    <span class="n">num_iterations</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                    <span class="n">onnx_shape_inference</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">model_proto</span> <span class="o">=</span> <span class="n">rewrite</span><span class="p">(</span><span class="n">model_proto</span><span class="p">)</span>
                <span class="c1"># On MegatronBertForQuestionAnswering, this step hurts the latency by 10%.</span>
                <span class="c1"># model_proto = inline_local_functions(model_proto)</span>
                <span class="k">del</span> <span class="n">first_model_proto</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="p">[:]</span>
                <span class="k">del</span> <span class="n">first_model_proto</span><span class="o">.</span><span class="n">functions</span><span class="p">[:]</span>
                <span class="n">first_model_proto</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">model_proto</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="p">)</span>
                <span class="n">first_model_proto</span><span class="o">.</span><span class="n">functions</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">model_proto</span><span class="o">.</span><span class="n">functions</span><span class="p">)</span>
                <span class="k">continue</span>

            <span class="k">if</span> <span class="n">opt</span> <span class="o">==</span> <span class="s2">&quot;llm&quot;</span><span class="p">:</span>
                <span class="kn">from</span> <span class="nn">onnxscript.rewriter.llama_rule_sets</span> <span class="kn">import</span> <span class="n">llama_p0_rule_set</span>

                <span class="n">rule_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">llama_p0_rule_set</span><span class="p">)</span>
                <span class="k">continue</span>

            <span class="k">raise</span> <span class="ne">AssertionError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unexpected value for optimization=</span><span class="si">{</span><span class="n">optimization</span><span class="si">!r}</span><span class="s2">.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">rule_sets</span><span class="p">:</span>
            <span class="kn">from</span> <span class="nn">onnxscript</span> <span class="kn">import</span> <span class="n">ir</span>

            <span class="n">begin_pat</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
            <span class="n">ir_model</span> <span class="o">=</span> <span class="n">ir</span><span class="o">.</span><span class="n">serde</span><span class="o">.</span><span class="n">deserialize_model</span><span class="p">(</span><span class="n">model_proto</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">rs</span> <span class="ow">in</span> <span class="n">rule_sets</span><span class="p">:</span>
                <span class="n">rs</span><span class="p">()</span><span class="o">.</span><span class="n">apply_to_model</span><span class="p">(</span><span class="n">ir_model</span><span class="p">)</span>
            <span class="n">model_proto</span> <span class="o">=</span> <span class="n">ir</span><span class="o">.</span><span class="n">serde</span><span class="o">.</span><span class="n">serialize_model</span><span class="p">(</span><span class="n">ir_model</span><span class="p">)</span>
            <span class="n">stats</span><span class="p">[</span><span class="s2">&quot;time_export_optimization_pattern&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">begin_pat</span>

        <span class="n">onnx</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model_proto</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">save_as_external_data</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">model_proto</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">load_external_data</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">stats</span><span class="p">[</span><span class="s2">&quot;time_export_optimization&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">begin</span>
        <span class="k">return</span> <span class="n">model_proto</span><span class="p">,</span> <span class="n">stats</span>

    <span class="k">def</span> <span class="nf">_to_torchscript</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">dynamic</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">fake_tensor</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">no_grad</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">optimization</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">target_opset</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">assert</span> <span class="ow">not</span> <span class="n">fake_tensor</span><span class="p">,</span> <span class="s2">&quot;fake_tensor not implemented.&quot;</span>
        <span class="k">assert</span> <span class="n">no_grad</span><span class="p">,</span> <span class="s2">&quot;no_grad false not implemented yet&quot;</span>

        <span class="k">if</span> <span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span>
            <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
            <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">list</span><span class="p">)</span>
            <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">==</span> <span class="mi">1</span>
            <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="nb">dict</span><span class="p">)</span>
            <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span> <span class="o">&amp;</span> <span class="p">{</span><span class="s2">&quot;file_name&quot;</span><span class="p">,</span> <span class="s2">&quot;image&quot;</span><span class="p">})</span> <span class="o">==</span> <span class="mi">2</span>
        <span class="p">):</span>
            <span class="c1"># detectron2 take inputs such as</span>
            <span class="c1"># ([{&#39;file_name&#39;: ..., &#39;height&#39;: ..., &#39;image&#39;: torch.Tensor(...)}])</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;image&quot;</span><span class="p">],)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span>

        <span class="n">dynamic_shapes_for_export</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_dynamic_shapes</span><span class="p">(</span><span class="n">dynamic</span><span class="p">)</span>
        <span class="n">inputs</span><span class="p">,</span> <span class="n">kw_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_export_inputs</span><span class="p">(</span><span class="n">dynamic</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">)</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="n">kw_inputs</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;kwargs is not implemented yet but kw_inputs=</span><span class="si">{</span><span class="n">string_type</span><span class="p">(</span><span class="n">kw_inputs</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="n">kwargs_export</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="n">dynamic_shapes_for_export</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># torch_script only supports a dictionary</span>
            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
                <span class="n">dynamic_shapes_for_export</span><span class="p">,</span> <span class="nb">tuple</span>
            <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;dynamic_axes not supported when it is </span><span class="si">{</span><span class="n">dynamic_shapes_for_export</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="n">input_names</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">dynamic_axes</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">dyn</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dynamic_shapes_for_export</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">dyn</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">continue</span>
                <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dyn</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">),</span> <span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Model is wrapped, unexpected type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">dyn</span><span class="p">)</span><span class="si">}</span><span class="s2"> for input </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">, &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;dynamic_shapes_for_export=</span><span class="si">{</span><span class="n">dynamic_shapes_for_export</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">inp</span> <span class="ow">in</span> <span class="n">dyn</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">inp</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="k">continue</span>
                    <span class="n">dname</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;input</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">input_names</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                        <span class="k">for</span> <span class="n">di</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">inp</span><span class="p">):</span>
                            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="nb">dict</span><span class="p">),</span> <span class="p">(</span>
                                <span class="sa">f</span><span class="s2">&quot;Unexpected for input </span><span class="si">{</span><span class="n">dname</span><span class="si">!r}</span><span class="s2">, </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">d</span><span class="p">)</span><span class="si">}</span><span class="s2">, i=</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">, &quot;</span>
                                <span class="sa">f</span><span class="s2">&quot;inp=</span><span class="si">{</span><span class="n">inp</span><span class="si">}</span><span class="s2">, dyn=</span><span class="si">{</span><span class="n">dyn</span><span class="si">}</span><span class="s2">, &quot;</span>
                                <span class="sa">f</span><span class="s2">&quot;dynamic_shapes_for_export=</span><span class="si">{</span><span class="n">dynamic_shapes_for_export</span><span class="si">}</span><span class="s2">&quot;</span>
                            <span class="p">)</span>
                            <span class="n">dn</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">dname</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">di</span><span class="si">}</span><span class="s2">&quot;</span>
                            <span class="n">daxes</span> <span class="o">=</span> <span class="p">{}</span>
                            <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">d</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                                <span class="n">daxes</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="vm">__name__</span>
                            <span class="n">dynamic_axes</span><span class="p">[</span><span class="n">dn</span><span class="p">]</span> <span class="o">=</span> <span class="n">daxes</span>
                            <span class="n">input_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dn</span><span class="p">)</span>
                        <span class="k">continue</span>

                    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="nb">dict</span><span class="p">),</span> <span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Unexpected for input </span><span class="si">{</span><span class="n">dname</span><span class="si">!r}</span><span class="s2">, </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span><span class="si">}</span><span class="s2">, i=</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">, dyn=</span><span class="si">{</span><span class="n">dyn</span><span class="si">}</span><span class="s2">, &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;dynamic_shapes_for_export=</span><span class="si">{</span><span class="n">dynamic_shapes_for_export</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>
                    <span class="n">daxes</span> <span class="o">=</span> <span class="p">{}</span>
                    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">inp</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                        <span class="n">daxes</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="vm">__name__</span>
                    <span class="n">dynamic_axes</span><span class="p">[</span><span class="n">dname</span><span class="p">]</span> <span class="o">=</span> <span class="n">daxes</span>
                    <span class="n">input_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dname</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[ModelRunner._to_torchscript] dynamic_axes=</span><span class="si">{</span><span class="n">dynamic_axes</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[ModelRunner._to_torchscript] input_names=</span><span class="si">{</span><span class="n">input_names</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;[ModelRunner._to_torchscript] n_inputs=</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span><span class="si">}</span><span class="s2">, &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;n_kw_inputs=</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">kw_inputs</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
            <span class="n">kwargs_export</span><span class="p">[</span><span class="s2">&quot;dynamic_axes&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dynamic_axes</span>
            <span class="n">kwargs_export</span><span class="p">[</span><span class="s2">&quot;input_names&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">input_names</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">autocast</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span><span class="n">device_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">export</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                    <span class="n">inputs</span><span class="p">,</span>
                    <span class="n">name</span><span class="p">,</span>
                    <span class="n">do_constant_folding</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">opset_version</span><span class="o">=</span><span class="n">target_opset</span><span class="p">,</span>
                    <span class="n">verbose</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">verbose</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
                    <span class="n">external_data</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="o">**</span><span class="n">kwargs_export</span><span class="p">,</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">export</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                    <span class="n">inputs</span><span class="p">,</span>
                    <span class="n">name</span><span class="p">,</span>
                    <span class="n">do_constant_folding</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">opset_version</span><span class="o">=</span><span class="n">target_opset</span><span class="p">,</span>
                    <span class="n">verbose</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">verbose</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
                    <span class="n">external_data</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="o">**</span><span class="n">kwargs_export</span><span class="p">,</span>
                <span class="p">)</span>

        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[ModelRunner._to_torchscript] done saved into </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">optimization</span> <span class="ow">and</span> <span class="n">optimization</span> <span class="o">!=</span> <span class="s2">&quot;none&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimize_rewrite</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">optimization</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">onnx</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">load_external_data</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">_to_onnx_dynamo</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">dynamic</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">fake_tensor</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">no_grad</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">optimization</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">target_opset</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">detailed</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">fallback</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">assert</span> <span class="ow">not</span> <span class="n">fake_tensor</span><span class="p">,</span> <span class="s2">&quot;fake_tensor not implemented.&quot;</span>
        <span class="k">assert</span> <span class="n">no_grad</span><span class="p">,</span> <span class="s2">&quot;no_grad false not implemented yet&quot;</span>

        <span class="n">additional_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="n">detailed</span><span class="p">:</span>
            <span class="n">additional_kwargs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                <span class="nb">dict</span><span class="p">(</span>
                    <span class="n">profile</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">report</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">verify</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">dump_exported_program</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">artifacts_dir</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">name</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="p">)</span>

        <span class="n">export_inputs</span><span class="p">,</span> <span class="n">export_kw_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_export_inputs</span><span class="p">(</span><span class="n">dynamic</span><span class="p">)</span>
        <span class="n">dyn_shapes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_dynamic_shapes</span><span class="p">(</span><span class="n">dynamic</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">dyn_shapes</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">WrappedModelBase</span><span class="p">):</span>
            <span class="n">dyn_shapes</span> <span class="o">=</span> <span class="p">(</span><span class="n">dyn_shapes</span><span class="p">,)</span>

        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[ModelRunner._to_onnx_dynamo] detailed=</span><span class="si">{</span><span class="n">detailed</span><span class="si">}</span><span class="s2">, fallback=</span><span class="si">{</span><span class="n">fallback</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[ModelRunner._to_onnx_dynamo] additional_kwargs=</span><span class="si">{</span><span class="n">additional_kwargs</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[ModelRunner._to_onnx_dynamo] dynamic_shapes=</span><span class="si">{</span><span class="n">dyn_shapes</span><span class="si">!r}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;[ModelRunner._to_onnx_dynamo] export_inputs=</span><span class="si">{</span><span class="n">string_type</span><span class="p">(</span><span class="n">export_inputs</span><span class="p">)</span><span class="si">!r}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;[ModelRunner._to_onnx_dynamo] export_kw_inputs=&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">string_type</span><span class="p">(</span><span class="n">export_kw_inputs</span><span class="p">)</span><span class="si">!r}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[ModelRunner._to_onnx_dynamo] type(model)=</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span><span class="si">!r}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">autocast</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span><span class="n">device_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">onnx_program</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">export</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                    <span class="n">export_inputs</span><span class="p">,</span>
                    <span class="n">name</span> <span class="k">if</span> <span class="n">fallback</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                    <span class="n">kwargs</span><span class="o">=</span><span class="n">export_kw_inputs</span><span class="p">,</span>
                    <span class="n">opset_version</span><span class="o">=</span><span class="n">target_opset</span><span class="p">,</span>
                    <span class="n">dynamo</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">external_data</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">dynamic_shapes</span><span class="o">=</span><span class="n">dyn_shapes</span><span class="p">,</span>
                    <span class="n">fallback</span><span class="o">=</span><span class="n">fallback</span><span class="p">,</span>
                    <span class="o">**</span><span class="n">additional_kwargs</span><span class="p">,</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">onnx_program</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">export</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                    <span class="n">export_inputs</span><span class="p">,</span>
                    <span class="n">name</span> <span class="k">if</span> <span class="n">fallback</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                    <span class="n">kwargs</span><span class="o">=</span><span class="n">export_kw_inputs</span><span class="p">,</span>
                    <span class="n">opset_version</span><span class="o">=</span><span class="n">target_opset</span><span class="p">,</span>
                    <span class="n">dynamo</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">external_data</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">dynamic_shapes</span><span class="o">=</span><span class="n">dyn_shapes</span><span class="p">,</span>
                    <span class="n">fallback</span><span class="o">=</span><span class="n">fallback</span><span class="p">,</span>
                    <span class="o">**</span><span class="n">additional_kwargs</span><span class="p">,</span>
                <span class="p">)</span>

        <span class="n">stats</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">optimization</span><span class="p">:</span>
            <span class="n">opts</span> <span class="o">=</span> <span class="n">optimization</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;+&quot;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">opt</span> <span class="ow">in</span> <span class="n">opts</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">opt</span> <span class="o">==</span> <span class="s2">&quot;ir&quot;</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">stats</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">stats</span> <span class="o">=</span> <span class="p">{}</span>
                    <span class="n">begin</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
                    <span class="n">onnx_program</span><span class="o">.</span><span class="n">optimize</span><span class="p">()</span>
                    <span class="n">stats</span><span class="p">[</span><span class="s2">&quot;time_export_optimization&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">begin</span>
                    <span class="k">continue</span>
                <span class="k">assert</span> <span class="n">opt</span> <span class="ow">in</span> <span class="p">(</span>
                    <span class="s2">&quot;&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;none&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;-&quot;</span><span class="p">,</span>
                <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Unexpected optimization scenario </span><span class="si">{</span><span class="n">opt</span><span class="si">!r}</span><span class="s2"> in </span><span class="si">{</span><span class="n">opts</span><span class="si">!r}</span><span class="s2">&quot;</span>
            <span class="n">onnx_program</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">external_data</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="n">fallback</span><span class="p">:</span>
            <span class="c1"># The model was not save in that case.</span>
            <span class="n">onnx_program</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">external_data</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">onnx</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">load_external_data</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span> <span class="n">stats</span>

    <span class="k">def</span> <span class="nf">_to_dynamo_export</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">dynamic</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">fake_tensor</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">no_grad</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">optimization</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">target_opset</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">assert</span> <span class="ow">not</span> <span class="n">fake_tensor</span><span class="p">,</span> <span class="s2">&quot;fake_tensor not implemented.&quot;</span>
        <span class="k">assert</span> <span class="n">no_grad</span><span class="p">,</span> <span class="s2">&quot;no_grad false not implemented yet&quot;</span>
        <span class="n">stats</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">autocast</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span><span class="n">device_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">exported</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">dynamo_export</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                    <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span>
                    <span class="n">export_options</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">ExportOptions</span><span class="p">(</span>
                        <span class="n">dynamic_shapes</span><span class="o">=</span><span class="n">dynamic</span><span class="p">,</span>
                        <span class="c1"># registry=torch.onnx.OnnxRegistry()</span>
                    <span class="p">),</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">exported</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">dynamo_export</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                    <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span>
                    <span class="n">export_options</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">ExportOptions</span><span class="p">(</span>
                        <span class="n">dynamic_shapes</span><span class="o">=</span><span class="n">dynamic</span><span class="p">,</span>
                        <span class="c1"># registry=torch.onnx.OnnxRegistry()</span>
                    <span class="p">),</span>
                <span class="p">)</span>

        <span class="n">begin</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
        <span class="n">exported</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
        <span class="n">stats</span><span class="p">[</span><span class="s2">&quot;time_export_save&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">begin</span>

        <span class="n">onx</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">load_external_data</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">onnx</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">onx</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">save_as_external_data</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">optimization</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimize_rewrite</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">optimization</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">onnx</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">load_external_data</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span> <span class="n">stats</span>

    <span class="k">def</span> <span class="nf">_to_export</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">dynamic</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">fake_tensor</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">no_grad</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">optimization</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">strategy</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">assert</span> <span class="ow">not</span> <span class="n">fake_tensor</span><span class="p">,</span> <span class="s2">&quot;fake_tensor not implemented.&quot;</span>
        <span class="k">assert</span> <span class="n">no_grad</span><span class="p">,</span> <span class="s2">&quot;no_grad false not implemented yet&quot;</span>
        <span class="k">assert</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">autocast</span><span class="p">,</span> <span class="s2">&quot;not implemented for autocast&quot;</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="n">optimization</span> <span class="ow">or</span> <span class="n">optimization</span> <span class="o">==</span> <span class="s2">&quot;none&quot;</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;optimization </span><span class="si">{</span><span class="n">optimization</span><span class="si">!r}</span><span class="s2"> not compatible with export&quot;</span>
        <span class="kn">from</span> <span class="nn">..torch_interpreter</span> <span class="kn">import</span> <span class="n">ExportOptions</span>

        <span class="n">export_inputs</span><span class="p">,</span> <span class="n">export_kw_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_export_inputs</span><span class="p">(</span><span class="n">dynamic</span><span class="p">)</span>
        <span class="n">dynamic_shapes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_dynamic_shapes</span><span class="p">(</span><span class="n">dynamic</span><span class="p">)</span>
        <span class="n">export_options</span> <span class="o">=</span> <span class="n">ExportOptions</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="n">strategy</span><span class="p">,</span> <span class="o">**</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">export_options</span> <span class="ow">or</span> <span class="p">{}))</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[ModelRunner._to_export] dynamic_shapes=</span><span class="si">{</span><span class="n">dynamic_shapes</span><span class="si">!r}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[ModelRunner._to_export] export_inputs=</span><span class="si">{</span><span class="n">string_type</span><span class="p">(</span><span class="n">export_inputs</span><span class="p">)</span><span class="si">!r}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;[ModelRunner._to_export] export_kw_inputs=</span><span class="si">{</span><span class="n">string_type</span><span class="p">(</span><span class="n">export_kw_inputs</span><span class="p">)</span><span class="si">!r}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[ModelRunner._to_export] strategy=</span><span class="si">{</span><span class="n">strategy</span><span class="si">!r}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[ModelRunner._to_export] self.export_options=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">export_options</span><span class="si">!r}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[ModelRunner._to_export] export_options=</span><span class="si">{</span><span class="n">export_options</span><span class="si">!r}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[ModelRunner._to_export] type(model)=</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span><span class="si">!r}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">with</span> <span class="n">bypass_export_some_errors</span><span class="p">():</span>
            <span class="n">exported_mod</span> <span class="o">=</span> <span class="n">export_options</span><span class="o">.</span><span class="n">export</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                <span class="n">export_inputs</span><span class="p">,</span>
                <span class="n">export_kw_inputs</span><span class="p">,</span>
                <span class="n">dynamic_shapes</span><span class="o">=</span><span class="n">dynamic_shapes</span><span class="p">,</span>
                <span class="n">tracing_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">same_signature</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">root_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">splitext</span><span class="p">(</span><span class="n">name</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[ModelRunner._to_export] write fx graph intp </span><span class="si">{</span><span class="n">root_name</span><span class="si">!r}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">root_name</span><span class="si">}</span><span class="s2">.txt&quot;</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">exported_mod</span><span class="p">))</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">root_name</span><span class="si">}</span><span class="s2">.graph.txt&quot;</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">exported_mod</span><span class="o">.</span><span class="n">graph</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">exported_mod</span><span class="o">.</span><span class="n">module</span><span class="p">(),</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">_to_executorch</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">dynamic</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">fake_tensor</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">no_grad</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">optimization</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">strategy</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;executorch only works with CPU not </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="si">!r}</span><span class="s2">&quot;</span>
        <span class="k">assert</span> <span class="ow">not</span> <span class="n">fake_tensor</span><span class="p">,</span> <span class="s2">&quot;fake_tensor not implemented.&quot;</span>
        <span class="k">assert</span> <span class="n">no_grad</span><span class="p">,</span> <span class="s2">&quot;no_grad false not implemented yet&quot;</span>
        <span class="k">assert</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">autocast</span><span class="p">,</span> <span class="s2">&quot;not implemented for autocast&quot;</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="n">optimization</span> <span class="ow">or</span> <span class="n">optimization</span> <span class="o">==</span> <span class="s2">&quot;none&quot;</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;optimization </span><span class="si">{</span><span class="n">optimization</span><span class="si">!r}</span><span class="s2"> not compatible with export&quot;</span>
        <span class="kn">from</span> <span class="nn">..torch_interpreter</span> <span class="kn">import</span> <span class="n">ExportOptions</span>
        <span class="kn">from</span> <span class="nn">executorch.exir</span> <span class="kn">import</span> <span class="n">to_edge</span><span class="p">,</span> <span class="n">ExecutorchBackendConfig</span>

        <span class="n">export_inputs</span><span class="p">,</span> <span class="n">export_kw_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_export_inputs</span><span class="p">(</span><span class="n">dynamic</span><span class="p">)</span>
        <span class="n">dynamic_shapes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_dynamic_shapes</span><span class="p">(</span><span class="n">dynamic</span><span class="p">)</span>
        <span class="n">export_options</span> <span class="o">=</span> <span class="n">ExportOptions</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="n">strategy</span><span class="p">,</span> <span class="o">**</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">export_options</span> <span class="ow">or</span> <span class="p">{}))</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[ModelRunner._to_executorch] dynamic_shapes=</span><span class="si">{</span><span class="n">dynamic_shapes</span><span class="si">!r}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[ModelRunner._to_executorch] export_inputs=</span><span class="si">{</span><span class="n">string_type</span><span class="p">(</span><span class="n">export_inputs</span><span class="p">)</span><span class="si">!r}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;[ModelRunner._to_executorch] export_kw_inputs=&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">string_type</span><span class="p">(</span><span class="n">export_kw_inputs</span><span class="p">)</span><span class="si">!r}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[ModelRunner._to_executorch] strategy=</span><span class="si">{</span><span class="n">strategy</span><span class="si">!r}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[ModelRunner._to_executorch] self.export_options=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">export_options</span><span class="si">!r}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[ModelRunner._to_executorch] export_options=</span><span class="si">{</span><span class="n">export_options</span><span class="si">!r}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[ModelRunner._to_executorch] type(model)=</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span><span class="si">!r}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[ModelRunner._to_executorch] run torch.export.export&quot;</span><span class="p">)</span>

        <span class="k">with</span> <span class="n">bypass_export_some_errors</span><span class="p">():</span>
            <span class="n">exported_mod</span> <span class="o">=</span> <span class="n">export_options</span><span class="o">.</span><span class="n">export</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                <span class="n">export_inputs</span><span class="p">,</span>
                <span class="n">export_kw_inputs</span><span class="p">,</span>
                <span class="n">dynamic_shapes</span><span class="o">=</span><span class="n">dynamic_shapes</span><span class="p">,</span>
                <span class="n">tracing_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">same_signature</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">root_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">splitext</span><span class="p">(</span><span class="n">name</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[ModelRunner._to_executorch] write fx graph intp </span><span class="si">{</span><span class="n">root_name</span><span class="si">!r}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">root_name</span><span class="si">}</span><span class="s2">.txt&quot;</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">exported_mod</span><span class="p">))</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">root_name</span><span class="si">}</span><span class="s2">.graph.txt&quot;</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">exported_mod</span><span class="o">.</span><span class="n">graph</span><span class="p">))</span>

        <span class="k">assert</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">splitext</span><span class="p">(</span><span class="n">name</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;.pte&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Unexpected extension for </span><span class="si">{</span><span class="n">name</span><span class="si">!r}</span><span class="s2">&quot;</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[ModelRunner._to_executorch] export to EdgeProgramManager&quot;</span><span class="p">)</span>
        <span class="n">edge_program</span> <span class="o">=</span> <span class="n">to_edge</span><span class="p">(</span><span class="n">exported_mod</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;[ModelRunner._to_executorch] export </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">edge_program</span><span class="p">)</span><span class="si">}</span><span class="s2"> &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;to ExecutorchProgramManager&quot;</span>
            <span class="p">)</span>

        <span class="n">executorch_program</span> <span class="o">=</span> <span class="n">edge_program</span><span class="o">.</span><span class="n">to_executorch</span><span class="p">(</span><span class="n">ExecutorchBackendConfig</span><span class="p">(</span><span class="n">passes</span><span class="o">=</span><span class="p">[]))</span>

        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;[ModelRunner._to_executorch] saved </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">executorch_program</span><span class="p">)</span><span class="si">}</span><span class="s2"> into </span><span class="si">{</span><span class="n">name</span><span class="si">!r}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
            <span class="n">file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">executorch_program</span><span class="o">.</span><span class="n">buffer</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">executorch_program</span><span class="p">,</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">_to_eager</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">dynamic</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">fake_tensor</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">no_grad</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">optimization</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">assert</span> <span class="ow">not</span> <span class="n">fake_tensor</span><span class="p">,</span> <span class="s2">&quot;fake_tensor not implemented.&quot;</span>
        <span class="k">assert</span> <span class="n">no_grad</span><span class="p">,</span> <span class="s2">&quot;no_grad false not implemented yet&quot;</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="n">optimization</span> <span class="ow">or</span> <span class="n">optimization</span> <span class="o">==</span> <span class="s2">&quot;none&quot;</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;optimization </span><span class="si">{</span><span class="n">optimization</span><span class="si">!r}</span><span class="s2"> not compatible with eager&quot;</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">_to_ortmodule</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">dynamic</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">fake_tensor</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">no_grad</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">optimization</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">target_opset</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">assert</span> <span class="ow">not</span> <span class="n">fake_tensor</span><span class="p">,</span> <span class="s2">&quot;fake_tensor not implemented.&quot;</span>
        <span class="k">assert</span> <span class="ow">not</span> <span class="n">dynamic</span><span class="p">,</span> <span class="s2">&quot;dynamic true not implemented yet&quot;</span>
        <span class="k">assert</span> <span class="n">no_grad</span><span class="p">,</span> <span class="s2">&quot;no_grad false not implemented yet&quot;</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="n">optimization</span> <span class="ow">or</span> <span class="n">optimization</span> <span class="o">==</span> <span class="s2">&quot;none&quot;</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;optimization </span><span class="si">{</span><span class="n">optimization</span><span class="si">!r}</span><span class="s2"> not compatible with eager&quot;</span>
        <span class="kn">from</span> <span class="nn">onnxruntime.training.ortmodule</span> <span class="kn">import</span> <span class="n">ORTModule</span>

        <span class="k">return</span> <span class="n">ORTModule</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">),</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">_to_compile</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">dynamic</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">fake_tensor</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">no_grad</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">optimization</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">assert</span> <span class="ow">not</span> <span class="n">fake_tensor</span><span class="p">,</span> <span class="s2">&quot;fake_tensor not implemented.&quot;</span>
        <span class="k">assert</span> <span class="n">no_grad</span><span class="p">,</span> <span class="s2">&quot;no_grad true not implemented yet&quot;</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="n">optimization</span> <span class="ow">or</span> <span class="n">optimization</span> <span class="o">==</span> <span class="s2">&quot;none&quot;</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;optimization </span><span class="si">{</span><span class="n">optimization</span><span class="si">!r}</span><span class="s2"> not compatible with compile&quot;</span>

        <span class="k">def</span> <span class="nf">custom_backend</span><span class="p">(</span><span class="n">gm</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">GraphModule</span><span class="p">,</span> <span class="n">example_inputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]):</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[_to_compile] fx_graph]&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">gm</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">std_to_dump</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">gm</span><span class="p">))</span>

            <span class="k">return</span> <span class="n">gm</span><span class="o">.</span><span class="n">forward</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">autocast</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span><span class="n">device_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">res</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                    <span class="n">fullgraph</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">backend</span><span class="o">=</span><span class="n">custom_backend</span><span class="p">,</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">res</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">fullgraph</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="n">custom_backend</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">res</span><span class="p">,</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">_to_inductor</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">dynamic</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">fake_tensor</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">no_grad</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">optimization</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">fullgraph</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">assert</span> <span class="ow">not</span> <span class="n">fake_tensor</span><span class="p">,</span> <span class="s2">&quot;fake_tensor not implemented.&quot;</span>
        <span class="k">assert</span> <span class="n">no_grad</span><span class="p">,</span> <span class="s2">&quot;no_grad true not implemented yet&quot;</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="n">optimization</span> <span class="ow">or</span> <span class="n">optimization</span> <span class="o">==</span> <span class="s2">&quot;none&quot;</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;optimization </span><span class="si">{</span><span class="n">optimization</span><span class="si">!r}</span><span class="s2"> not compatible with inductor&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">autocast</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span><span class="n">device_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">res</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="s2">&quot;inductor&quot;</span><span class="p">,</span> <span class="n">fullgraph</span><span class="o">=</span><span class="n">fullgraph</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">res</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="s2">&quot;inductor&quot;</span><span class="p">,</span> <span class="n">fullgraph</span><span class="o">=</span><span class="n">fullgraph</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">res</span><span class="p">,</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">_to_dort</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">dynamic</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">fake_tensor</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">no_grad</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">optimization</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">target_opset</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">assert</span> <span class="ow">not</span> <span class="n">fake_tensor</span><span class="p">,</span> <span class="s2">&quot;fake_tensor not implemented.&quot;</span>
        <span class="k">assert</span> <span class="ow">not</span> <span class="n">dynamic</span><span class="p">,</span> <span class="s2">&quot;dynamic true not implemented yet&quot;</span>
        <span class="k">assert</span> <span class="n">no_grad</span><span class="p">,</span> <span class="s2">&quot;no_grad true not implemented yet&quot;</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="n">optimization</span> <span class="ow">or</span> <span class="n">optimization</span> <span class="o">==</span> <span class="s2">&quot;none&quot;</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;optimization </span><span class="si">{</span><span class="n">optimization</span><span class="si">!r}</span><span class="s2"> not compatible with dort&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">autocast</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span><span class="n">device_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">res</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="s2">&quot;onnxrt&quot;</span><span class="p">,</span> <span class="n">fullgraph</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dynamic</span><span class="o">=</span><span class="n">dynamic</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">res</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="s2">&quot;onnxrt&quot;</span><span class="p">,</span> <span class="n">fullgraph</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dynamic</span><span class="o">=</span><span class="n">dynamic</span>
                <span class="p">)</span>
        <span class="k">return</span> <span class="n">res</span><span class="p">,</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">_make_export_new_dynamic_shape</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_shape</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
        <span class="n">dyn_shape</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
        <span class="n">dyn_values</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span>
        <span class="n">i</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">]:</span>
        <span class="n">new_shape</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">assert</span> <span class="n">dyn_shape</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dyn_shape</span><span class="p">,</span> <span class="nb">dict</span><span class="p">),</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Unexpected type for input </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">, dyn_shape=</span><span class="si">{</span><span class="n">dyn_shape</span><span class="si">}</span><span class="s2">, &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;input_shape=</span><span class="si">{</span><span class="n">input_shape</span><span class="si">}</span><span class="s2">, dyn_values=</span><span class="si">{</span><span class="n">string_type</span><span class="p">(</span><span class="n">dyn_values</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">dyn_shape</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">input_shape</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">j</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">dyn_shape</span><span class="p">:</span>
                <span class="n">new_shape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">input_shape</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
                <span class="k">continue</span>
            <span class="n">name</span> <span class="o">=</span> <span class="n">dyn_shape</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">dyn_values</span><span class="p">:</span>
                <span class="n">new_shape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dyn_values</span><span class="p">[</span><span class="n">name</span><span class="p">])</span>
                <span class="k">continue</span>
            <span class="n">d</span> <span class="o">=</span> <span class="n">input_shape</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
            <span class="n">d</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">dyn_values</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">d</span>
            <span class="n">new_shape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>

        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">new_shape</span><span class="p">)</span>

<div class="viewcode-block" id="ModelRunner.make_export_inputs">
<a class="viewcode-back" href="../../../api/torch_bench/_bash_bench_model_runner.html#experimental_experiment.torch_bench._bash_bench_model_runner.ModelRunner.make_export_inputs">[docs]</a>
    <span class="k">def</span> <span class="nf">make_export_inputs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">dynamic</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">wrapped</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="o">...</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">kw_inputs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">int_to_tensor</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Creates the new inputs for the benchmarks.</span>
<span class="sd">        :func:`torch.export.export` fails when a dimension is dynamic</span>
<span class="sd">        and the value for this dimension is 1. This function</span>
<span class="sd">        expands the input on that dimension to make it 2</span>
<span class="sd">        if it is 1. These inputs should only be used at export time.</span>

<span class="sd">        :param dynamic: dynamic, yes or no?</span>
<span class="sd">        :param wrapped: wrapped model</span>
<span class="sd">        :param inputs: existing inputs or None to use `self.inputs`</span>
<span class="sd">        :param int_to_tensor: converts integers or float to tensors</span>
<span class="sd">        :return: new inputs</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">dynamic</span><span class="p">:</span>
            <span class="c1"># easy case</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">int_to_tensor</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span> <span class="k">if</span> <span class="n">inputs</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">inputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">kw_inputs</span>

            <span class="k">if</span> <span class="n">inputs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span>
            <span class="k">if</span> <span class="n">kw_inputs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">kw_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kw_inputs</span>

            <span class="n">new_inputs</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)):</span>
                <span class="n">inp</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">inp</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">new_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
                    <span class="k">continue</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                    <span class="n">new_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="n">inp</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
                    <span class="k">continue</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
                    <span class="n">new_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="n">inp</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
                    <span class="k">continue</span>
                <span class="n">new_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>

            <span class="n">new_kw_inputs</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">inp</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">kw_inputs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">inp</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">new_kw_inputs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
                    <span class="k">continue</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                    <span class="n">new_kw_inputs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="n">inp</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
                    <span class="k">continue</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
                    <span class="n">new_kw_inputs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="n">inp</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
                    <span class="k">continue</span>
                <span class="n">new_kw_inputs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">inp</span>

            <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">new_inputs</span><span class="p">),</span> <span class="n">new_kw_inputs</span>

        <span class="k">if</span> <span class="n">inputs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span>
        <span class="k">if</span> <span class="n">kw_inputs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">kw_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kw_inputs</span>

        <span class="k">assert</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="n">kw_inputs</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Keyword attribute are not implemented yet but kw_inputs=</span><span class="si">{</span><span class="n">string_type</span><span class="p">(</span><span class="n">kw_inputs</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>

        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="nb">tuple</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Not implemented for type(self.inputs)=</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="n">dynamic_shapes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_dynamic_shapes</span><span class="p">(</span><span class="n">dynamic</span><span class="p">,</span> <span class="n">wrapped</span><span class="o">=</span><span class="n">wrapped</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">wrapped</span><span class="p">:</span>
            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dynamic_shapes</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">),</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Unexpected type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">dynamic_shapes</span><span class="p">)</span><span class="si">}</span><span class="s2"> for dynamic_shapes, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;wrapped=</span><span class="si">{</span><span class="n">wrapped</span><span class="si">}</span><span class="s2">, input type is </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">dynamic_shapes</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Unexpected number of dynamic_shapes </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">dynamic_shapes</span><span class="p">)</span><span class="si">}</span><span class="s2">, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;input type is </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
            <span class="n">dynamic_shapes</span> <span class="o">=</span> <span class="n">dynamic_shapes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">dyn_inputs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">dyn_values</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)):</span>
            <span class="n">inp</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">inp</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">dyn_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
                <span class="k">continue</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                <span class="n">dyn_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="n">inp</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span> <span class="k">if</span> <span class="n">int_to_tensor</span> <span class="k">else</span> <span class="n">inp</span>
                <span class="p">)</span>
                <span class="k">continue</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
                <span class="n">dyn_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="n">inp</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="k">if</span> <span class="n">int_to_tensor</span> <span class="k">else</span> <span class="n">inp</span>
                <span class="p">)</span>
                <span class="k">continue</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dynamic_shapes</span><span class="p">):</span>
                <span class="n">dyn_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
                <span class="k">continue</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dynamic_shapes</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="nb">list</span><span class="p">),</span> <span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Unexpected type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">dynamic_shapes</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="si">}</span><span class="s2"> for input(list) </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">, &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;dynamic_shapes[i]=</span><span class="si">{</span><span class="n">dynamic_shapes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
                <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span>
                    <span class="n">x</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">inp</span>
                <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Unexpected type in input(list) </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="p">[</span><span class="nb">type</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">inp</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">dynamic_shapes</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">inp</span><span class="p">),</span> <span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Length mismatch len(dynamic_shapes[i])=</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">dynamic_shapes</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="si">}</span><span class="s2"> &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;len(inp)=</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
                <span class="n">new_inputs</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">ds</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">dynamic_shapes</span><span class="p">[</span><span class="n">i</span><span class="p">]):</span>
                    <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">new_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                        <span class="k">continue</span>
                    <span class="n">nds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_export_new_dynamic_shape</span><span class="p">(</span>
                        <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">ds</span><span class="p">,</span> <span class="n">dyn_values</span><span class="o">=</span><span class="n">dyn_values</span><span class="p">,</span> <span class="n">i</span><span class="o">=</span><span class="n">i</span>
                    <span class="p">)</span>
                    <span class="n">new_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span> <span class="k">if</span> <span class="n">nds</span> <span class="o">==</span> <span class="n">ds</span> <span class="k">else</span> <span class="n">x</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">nds</span><span class="p">))</span>
                <span class="n">dyn_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_inputs</span><span class="p">)</span>
                <span class="k">continue</span>
            <span class="n">new_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_export_new_dynamic_shape</span><span class="p">(</span>
                <span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dynamic_shapes</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">dyn_values</span><span class="o">=</span><span class="n">dyn_values</span><span class="p">,</span> <span class="n">i</span><span class="o">=</span><span class="n">i</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">new_shape</span> <span class="o">==</span> <span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
                <span class="n">dyn_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
                <span class="k">continue</span>
            <span class="n">dyn_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">inp</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">new_shape</span><span class="p">))</span>

        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">dyn_inputs</span><span class="p">),</span> <span class="kc">None</span></div>


    <span class="k">def</span> <span class="nf">_get_input_shape_tensor</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">export</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">input_shape</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
        <span class="n">dyn_shape</span><span class="p">,</span>
        <span class="n">dyn_values</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
        <span class="n">i</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">dyn_shape</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">input_shape</span>
        <span class="n">new_shape</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dyn_shape</span><span class="p">,</span> <span class="nb">dict</span><span class="p">),</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Unexpected type for input </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">, &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;dyn_shape</span><span class="si">{</span><span class="n">dyn_shape</span><span class="si">}</span><span class="s2">, shape of input[</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">]=</span><span class="si">{</span><span class="n">input_shape</span><span class="si">}</span><span class="s2">, &quot;</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">export</span> <span class="ow">or</span> <span class="n">j</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">dyn_shape</span> <span class="ow">or</span> <span class="n">input_shape</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">new_shape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">input_shape</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
                <span class="k">continue</span>
            <span class="n">name</span> <span class="o">=</span> <span class="n">dyn_shape</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">dyn_values</span><span class="p">:</span>
                <span class="n">new_shape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dyn_values</span><span class="p">[</span><span class="n">name</span><span class="p">])</span>
                <span class="k">continue</span>
            <span class="n">d</span> <span class="o">=</span> <span class="n">input_shape</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
            <span class="n">d</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">dyn_values</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">d</span>
            <span class="n">new_shape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>

        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">new_shape</span><span class="p">)</span>

<div class="viewcode-block" id="ModelRunner.get_input_shapes">
<a class="viewcode-back" href="../../../api/torch_bench/_bash_bench_model_runner.html#experimental_experiment.torch_bench._bash_bench_model_runner.ModelRunner.get_input_shapes">[docs]</a>
    <span class="k">def</span> <span class="nf">get_input_shapes</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">dynamic</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">wrapped</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">export</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the input shapes.</span>

<span class="sd">        :param dynamic: dynamic, yes or no?</span>
<span class="sd">        :param wrapped: wrapped model</span>
<span class="sd">        :param inputs: existing inputs or None to use `self.inputs`</span>
<span class="sd">        :param export: returns the shapes for the inputs used for export</span>
<span class="sd">        :return: new inputs</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">inputs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_input_shapes</span><span class="p">(</span>
                <span class="n">dynamic</span><span class="o">=</span><span class="n">dynamic</span><span class="p">,</span> <span class="n">export</span><span class="o">=</span><span class="n">export</span><span class="p">,</span> <span class="n">wrapped</span><span class="o">=</span><span class="n">wrapped</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span>
            <span class="p">)</span>

        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="nb">tuple</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Not implemented for type(self.inputs)=</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="n">dynamic_shapes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_dynamic_shapes</span><span class="p">(</span><span class="n">dynamic</span><span class="p">,</span> <span class="n">wrapped</span><span class="o">=</span><span class="n">wrapped</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">dynamic_shapes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">wrapped</span><span class="p">:</span>
            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dynamic_shapes</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">),</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Unexpected type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">dynamic_shapes</span><span class="p">)</span><span class="si">}</span><span class="s2"> for dynamic_shapes, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;wrapped=</span><span class="si">{</span><span class="n">wrapped</span><span class="si">}</span><span class="s2">, input type is </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">dynamic_shapes</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Unexpected number of dynamic_shapes </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">dynamic_shapes</span><span class="p">)</span><span class="si">}</span><span class="s2">, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;input type is </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
            <span class="n">dynamic_shapes</span> <span class="o">=</span> <span class="n">dynamic_shapes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">dyn_input_shapes</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">dyn_values</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">)):</span>
            <span class="n">inp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">inp</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">dyn_input_shapes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
                <span class="k">continue</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">)):</span>
                <span class="n">dyn_input_shapes</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="mi">1</span><span class="p">,))</span>
                <span class="k">continue</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                <span class="c1"># List of inputs.</span>
                <span class="n">dyn_shape</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="kc">None</span>
                    <span class="k">if</span> <span class="n">dynamic_shapes</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dynamic_shapes</span><span class="p">)</span>
                    <span class="k">else</span> <span class="n">dynamic_shapes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="n">dyn_shape</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">dyn_input_shapes</span><span class="o">.</span><span class="n">append</span><span class="p">([{}</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">inp</span><span class="p">])</span>
                    <span class="k">continue</span>

                <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">dyn_shape</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span>
                    <span class="n">inp</span>
                <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Length mismatch len(dyn_shape)=</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">dyn_shape</span><span class="p">)</span><span class="si">}</span><span class="s2">, len(inp)=</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="n">new_shapes</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">t</span><span class="p">,</span> <span class="n">ds</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">dyn_shape</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">t</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">new_shapes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
                        <span class="k">continue</span>
                    <span class="n">new_shapes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_shape_tensor</span><span class="p">(</span>
                            <span class="n">export</span><span class="o">=</span><span class="n">export</span><span class="p">,</span>
                            <span class="n">input_shape</span><span class="o">=</span><span class="n">t</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
                            <span class="n">dyn_shape</span><span class="o">=</span><span class="n">ds</span><span class="p">,</span>
                            <span class="n">dyn_values</span><span class="o">=</span><span class="n">dyn_values</span><span class="p">,</span>
                            <span class="n">i</span><span class="o">=</span><span class="n">i</span><span class="p">,</span>
                        <span class="p">)</span>
                    <span class="p">)</span>
                <span class="n">dyn_input_shapes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_shapes</span><span class="p">)</span>
                <span class="k">continue</span>

            <span class="n">new_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_shape_tensor</span><span class="p">(</span>
                <span class="n">export</span><span class="o">=</span><span class="n">export</span><span class="p">,</span>
                <span class="n">input_shape</span><span class="o">=</span><span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
                <span class="n">dyn_shape</span><span class="o">=</span><span class="p">(</span>
                    <span class="kc">None</span>
                    <span class="k">if</span> <span class="n">dynamic_shapes</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dynamic_shapes</span><span class="p">)</span>
                    <span class="k">else</span> <span class="n">dynamic_shapes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="p">),</span>
                <span class="n">dyn_values</span><span class="o">=</span><span class="n">dyn_values</span><span class="p">,</span>
                <span class="n">i</span><span class="o">=</span><span class="n">i</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">dyn_input_shapes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_shape</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">dyn_input_shapes</span><span class="p">)</span></div>


    <span class="k">def</span> <span class="nf">_make_dynamic_inputs_tensor</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">,</span> <span class="n">dyn_shape</span><span class="p">,</span> <span class="n">dyn_values</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">i</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">):</span>
        <span class="n">new_shape</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">assert</span> <span class="n">dyn_shape</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dyn_shape</span><span class="p">,</span> <span class="nb">dict</span><span class="p">),</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Unexpected type for input </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">, dyn_shape</span><span class="si">{</span><span class="n">dyn_shape</span><span class="si">}</span><span class="s2">, &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;shape of input[</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">]=</span><span class="si">{</span><span class="n">input_shape</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">dyn_shape</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">j</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">dyn_shape</span><span class="p">:</span>
                <span class="n">new_shape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">input_shape</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
                <span class="k">continue</span>
            <span class="n">name</span> <span class="o">=</span> <span class="n">dyn_shape</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">dyn_values</span><span class="p">:</span>
                <span class="n">new_shape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dyn_values</span><span class="p">[</span><span class="n">name</span><span class="p">])</span>
                <span class="k">continue</span>
            <span class="n">d</span> <span class="o">=</span> <span class="n">input_shape</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
            <span class="n">d</span> <span class="o">+=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">j</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">8</span>
            <span class="n">dyn_values</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">d</span>
            <span class="n">new_shape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>

        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">new_shape</span><span class="p">)</span>

<div class="viewcode-block" id="ModelRunner.make_dynamic_inputs">
<a class="viewcode-back" href="../../../api/torch_bench/_bash_bench_model_runner.html#experimental_experiment.torch_bench._bash_bench_model_runner.ModelRunner.make_dynamic_inputs">[docs]</a>
    <span class="k">def</span> <span class="nf">make_dynamic_inputs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">wrapped</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Creates dynamic inputs based on the static ones by changing the dynamic</span>
<span class="sd">        according to the definition of the dynamic_shapes.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">tuple</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Not implemented for type(self.inputs)=</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="n">dynamic_shapes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_dynamic_shapes</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">wrapped</span><span class="o">=</span><span class="n">wrapped</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">wrapped</span><span class="p">:</span>
            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dynamic_shapes</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">),</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Unexpected type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">dynamic_shapes</span><span class="p">)</span><span class="si">}</span><span class="s2"> for dynamic_shapes, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;wrapped=</span><span class="si">{</span><span class="n">wrapped</span><span class="si">}</span><span class="s2">, input type is </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">dynamic_shapes</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Unexpected number of dynamic_shapes </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">dynamic_shapes</span><span class="p">)</span><span class="si">}</span><span class="s2">, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;input type is </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
            <span class="n">dynamic_shapes</span> <span class="o">=</span> <span class="n">dynamic_shapes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">dyn_inputs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">dyn_values</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">)):</span>
            <span class="n">inp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dynamic_shapes</span><span class="p">):</span>
                <span class="n">dyn_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
                <span class="k">continue</span>
            <span class="n">dyn_shape</span> <span class="o">=</span> <span class="n">dynamic_shapes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">inp</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">)):</span>
                <span class="n">dyn_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
                <span class="k">continue</span>

            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dyn_shape</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="nb">list</span><span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Unexpected type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span><span class="si">}</span><span class="s2"> for input </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">dyn_shape</span><span class="p">),</span> <span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Length mismatch len(self.inputs[i])=</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span><span class="si">}</span><span class="s2"> == &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;len(dynamic_shapes[i])=</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">dyn_shape</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
                <span class="n">new_input</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">ds</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">dyn_shape</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">new_input</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
                        <span class="k">continue</span>
                    <span class="n">ns</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_dynamic_inputs_tensor</span><span class="p">(</span>
                        <span class="n">input_shape</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">i</span><span class="o">=</span><span class="n">i</span><span class="p">,</span> <span class="n">dyn_shape</span><span class="o">=</span><span class="n">ds</span><span class="p">,</span> <span class="n">dyn_values</span><span class="o">=</span><span class="n">dyn_values</span>
                    <span class="p">)</span>
                    <span class="n">zeros</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">ns</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                    <span class="n">slices</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
                    <span class="n">zeros</span><span class="p">[</span><span class="n">slices</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">slices</span><span class="p">]</span>
                    <span class="n">new_input</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">zeros</span><span class="p">)</span>
                <span class="n">dyn_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_input</span><span class="p">)</span>
                <span class="k">continue</span>

            <span class="n">new_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_dynamic_inputs_tensor</span><span class="p">(</span>
                <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">))</span> <span class="k">else</span> <span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
                <span class="n">i</span><span class="o">=</span><span class="n">i</span><span class="p">,</span>
                <span class="n">dyn_shape</span><span class="o">=</span><span class="n">dyn_shape</span><span class="p">,</span>
                <span class="n">dyn_values</span><span class="o">=</span><span class="n">dyn_values</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">zeros</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">new_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">inp</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">inp</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">slices</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="n">zeros</span><span class="p">[</span><span class="n">slices</span><span class="p">]</span> <span class="o">=</span> <span class="n">inp</span><span class="p">[</span><span class="n">slices</span><span class="p">]</span>
            <span class="n">dyn_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">zeros</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">dyn_inputs</span><span class="p">)</span></div>


<div class="viewcode-block" id="ModelRunner.make_feeds">
<a class="viewcode-back" href="../../../api/torch_bench/_bash_bench_model_runner.html#experimental_experiment.torch_bench._bash_bench_model_runner.ModelRunner.make_feeds">[docs]</a>
    <span class="k">def</span> <span class="nf">make_feeds</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">exporter</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">filename</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">dynamic</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Creates feed inputs.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">exporter</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="p">,</span> <span class="n">maxsplit</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">in</span> <span class="p">{</span>
            <span class="s2">&quot;eager&quot;</span><span class="p">,</span>
            <span class="s2">&quot;export&quot;</span><span class="p">,</span>
            <span class="s2">&quot;compile&quot;</span><span class="p">,</span>
            <span class="s2">&quot;inductor&quot;</span><span class="p">,</span>
            <span class="s2">&quot;dort&quot;</span><span class="p">,</span>
            <span class="s2">&quot;cort&quot;</span><span class="p">,</span>
            <span class="s2">&quot;cortgrad&quot;</span><span class="p">,</span>
            <span class="s2">&quot;executorch&quot;</span><span class="p">,</span>
        <span class="p">}:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span>

        <span class="n">use_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">dynamic</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_dynamic_inputs</span><span class="p">()</span>

        <span class="c1"># for onnx</span>
        <span class="n">onx</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">load_external_data</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">initializer_names</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">onx</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">initializer</span><span class="p">}</span>
        <span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="n">_</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">onx</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">input</span> <span class="k">if</span> <span class="n">_</span><span class="o">.</span><span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">initializer_names</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">use_inputs</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="k">assert</span> <span class="nb">set</span><span class="p">(</span><span class="n">names</span><span class="p">)</span> <span class="o">==</span> <span class="nb">set</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span>
            <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Input names mismatch, got </span><span class="si">{</span><span class="nb">set</span><span class="p">(</span><span class="n">use_inputs</span><span class="p">)</span><span class="si">}</span><span class="s2">, expecting </span><span class="si">{</span><span class="nb">set</span><span class="p">(</span><span class="n">names</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">use_inputs</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_use_defaults</span><span class="p">),</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Mismatch len(use_inputs)=</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">use_inputs</span><span class="p">)</span><span class="si">}</span><span class="s2">, &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;len(self.raw_use_defaults)=</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_use_defaults</span><span class="p">)</span><span class="si">}</span><span class="s2">, &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;self.raw_use_defaults=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_use_defaults</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">i</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">use_inputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">raw_use_defaults</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">d</span> <span class="o">!=</span> <span class="n">UseDefaultValue</span><span class="o">.</span><span class="n">TRUE</span> <span class="ow">or</span> <span class="n">i</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="p">]</span>

        <span class="c1"># We need to flatten list, wrap scalar</span>
        <span class="n">new_inputs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="n">new_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
                <span class="k">continue</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="n">i</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">exporter</span> <span class="o">==</span> <span class="s2">&quot;torch_script&quot;</span><span class="p">:</span>
                    <span class="n">t</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">new_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
                <span class="k">continue</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
                <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="n">i</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">exporter</span> <span class="o">==</span> <span class="s2">&quot;torch_script&quot;</span><span class="p">:</span>
                    <span class="n">t</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">new_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
                <span class="k">continue</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">u</span> <span class="ow">in</span> <span class="n">i</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">u</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="k">continue</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                        <span class="n">new_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
                        <span class="k">continue</span>
                    <span class="k">raise</span> <span class="ne">AssertionError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Unable to process input type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">u</span><span class="p">)</span><span class="si">}</span><span class="s2"> in input list&quot;</span>
                    <span class="p">)</span>
                <span class="k">continue</span>
            <span class="k">raise</span> <span class="ne">AssertionError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unable to process input type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">names</span><span class="p">)</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">new_inputs</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">(</span>
            <span class="p">(</span>
                <span class="n">r</span> <span class="o">==</span> <span class="n">UseDefaultValue</span><span class="o">.</span><span class="n">TRUE</span>
                <span class="c1"># onnx_dynamo does not seem to consider int or float as inputs</span>
                <span class="ow">or</span> <span class="p">(</span><span class="n">exporter</span> <span class="o">==</span> <span class="s2">&quot;onnx_dynamo&quot;</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">)))</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">use_inputs</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">names</span><span class="p">)</span> <span class="p">:],</span> <span class="bp">self</span><span class="o">.</span><span class="n">raw_use_defaults</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">names</span><span class="p">)</span> <span class="p">:])</span>
        <span class="p">):</span>
            <span class="n">new_inputs</span> <span class="o">=</span> <span class="n">new_inputs</span><span class="p">[:</span> <span class="nb">len</span><span class="p">(</span><span class="n">names</span><span class="p">)]</span>

        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">names</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">new_inputs</span><span class="p">),</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Mismatch number of inputs, </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">new_inputs</span><span class="p">)</span><span class="si">}</span><span class="s2">) &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;inputs, there are </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">new_inputs</span><span class="p">)</span><span class="si">}</span><span class="s2"> flattened inputs.</span><span class="se">\n</span><span class="s2">----</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;names=</span><span class="si">{</span><span class="n">names</span><span class="si">}</span><span class="se">\n</span><span class="s2">----</span><span class="se">\n</span><span class="s2">input types=</span><span class="si">{</span><span class="n">string_type</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span><span class="si">}</span><span class="se">\n</span><span class="s2">----</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;new input types=</span><span class="si">{</span><span class="n">string_type</span><span class="p">(</span><span class="n">new_inputs</span><span class="p">)</span><span class="si">}</span><span class="se">\n</span><span class="s2">----</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;named parameters=</span><span class="si">{</span><span class="nb">sorted</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">----</span><span class="se">\n</span><span class="s2">named buffers=</span><span class="si">{</span><span class="nb">sorted</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">named_buffers</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">----</span><span class="se">\n</span><span class="s2">self.raw_input_names=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_input_names</span><span class="si">}</span><span class="se">\n</span><span class="s2">----</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;self.raw_use_defaults=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_use_defaults</span><span class="si">}</span><span class="se">\n</span><span class="s2">----</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;initializer_names=</span><span class="si">{</span><span class="nb">sorted</span><span class="p">(</span><span class="n">initializer_names</span><span class="p">)</span><span class="si">}</span><span class="se">\n</span><span class="s2">----</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">names</span><span class="p">,</span> <span class="n">new_inputs</span><span class="p">))</span></div>
</div>

</pre></div>
        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          
          
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2023-2024
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer no-toc">
      
      
      
    </aside>
  </div>
</div><script src="../../../_static/documentation_options.js?v=a1637f0b"></script>
    <script src="../../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/scripts/furo.js?v=5fa4622c"></script>
    </body>
</html>