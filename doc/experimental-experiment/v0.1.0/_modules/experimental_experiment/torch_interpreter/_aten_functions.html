<!doctype html>
<html class="no-js" lang="en" data-content_root="../../../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><link rel="index" title="Index" href="../../../genindex.html" /><link rel="search" title="Search" href="../../../search.html" />

    <!-- Generated with Sphinx 7.2.6 and Furo 2024.05.06 -->
        <title>experimental_experiment.torch_interpreter._aten_functions - experimental-experiment 0.1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/furo.css?v=387cc868" />
    <link rel="stylesheet" type="text/css" href="../../../_static/plot_directive.css?v=7f9a90b1" />
    <link rel="stylesheet" type="text/css" href="../../../_static/graphviz.css?v=eafc0fe6" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery.css?v=61a4c737" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/furo-extensions.css?v=36a5483c" />
    
    


<style>
  body {
    --color-code-background: #eeffcc;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" /
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../../../index.html"><div class="brand">experimental-experiment 0.1.0 documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon no-toc" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../../../index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="../../../_static/logo.png" alt="Logo"/>
  </div>
  
  <span class="sidebar-brand-text">experimental-experiment 0.1.0 documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../../../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Contents</span></p>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../tutorial/index.html">Tutorial</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of Tutorial</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../tutorial/pytorch.html">pytorch and onnx</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of pytorch and onnx</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plot_torch_linreg_101.html">101: Linear Regression and export to ONNX</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plot_torch_custom_backend_101.html">101: A custom backend for torch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plot_optimize_101.html">101: Graph Optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plot_convolutation_matmul_102.html">102: Convolution and Matrix Multiplication</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plot_llama_bench_102.html">102: Measure LLAMA speed</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plot_torch_export_201.html">201: Evaluate different ways to export a torch model to ONNX</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plot_torch_dort_201.html">201: Evaluate DORT</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plot_torch_aot_201.html">201: Evaluate DORT Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plot_llama_diff_export_301.html">301: Compares LLAMA exporters</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plot_llama_diff_dort_301.html">301: Compares LLAMA exporters for onnxrt backend</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../tutorial/onnx.html">onnx</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of onnx</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../auto_examples/plot_profile_existing_onnx_101.html">101: Profile an existing model with onnxruntime</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorial/errors.html">Frequent Exceptions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorial/docker.html">Start from a docker</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../design/index.html">Design</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of Design</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../design/exporter.html">Custom Exporter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../design/optimizer.html">Pattern Optimizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../design/backends.html">Dynamo Backends</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../api/index.html">API</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of API</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gradient.html">gradient</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/reference.html">reference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/graph_builder.html">graph_builder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/torch_model_container.html">TorchModelContainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/graph_builder_pattern.html">graph_builder_optim</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/graph_builder_patterns.html">Optimization Patterns</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/order_optimization.html">order_optim</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/interpreter.html">interpreter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/onnx_export.html">onnx_export</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/aten_function.html">aten_functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/aten_method.html">aten_methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/prims_function.html">aten_prims</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/convert.html">convert_tools</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/torch_dynamo.html">torch_dynamo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/misc.html">Othersâ€¦</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/torch_helper.html">torch_models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/dimension.html">Dimension</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/torch_test.html">Testing</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../auto_examples/index.html">Example gallery</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle navigation of Example gallery</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_optimize_101.html">101: Graph Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_profile_existing_onnx_101.html">101: Profile an existing model with onnxruntime</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_torch_linreg_101.html">101: Linear Regression and export to ONNX</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_torch_custom_backend_101.html">101: A custom backend for torch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_convolutation_matmul_102.html">102: Convolution and Matrix Multiplication</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_llama_diff_export_301.html">301: Compares LLAMA exporters</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_llama_diff_dort_301.html">301: Compares LLAMA exporters for onnxrt backend</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_llama_bench_102.html">102: Measure LLAMA speed</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_torch_aot_201.html">201: Evaluate DORT Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_torch_dort_201.html">201: Evaluate DORT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../auto_examples/plot_torch_export_201.html">201: Evaluate different ways to export a torch model to ONNX</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../models/index.html">Supported Models</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle navigation of Supported Models</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../models/torchtry.html">Tries with Undocumented</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../models/onnxrt.html">Use the custom exporter in torch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../models/example_bug.html">A script to report a bug</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../models/llama.html">LLaMa</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../models/mistral.html">Mistral</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../models/phi.html">Phi</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../bench/index.html">Benchmark from the command line</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle navigation of Benchmark from the command line</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../bench/dort_bench.html">experimental_experiment.torch_bench.dort_bench</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../bench/dort_profile.html">experimental_experiment.torch_bench.dort_profile</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../bench/scripts.html">Interesting scripts or command lines</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../times.html">Times</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">More</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../CHANGELOGS.html">Change Logs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../license.html">License</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../long_outputs.html">Long Outputs uneasy to read</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon no-toc" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <h1>Source code for experimental_experiment.torch_interpreter._aten_functions</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">onnx</span> <span class="kn">import</span> <span class="n">TensorProto</span>
<span class="kn">from</span> <span class="nn">onnx.helper</span> <span class="kn">import</span> <span class="n">tensor_dtype_to_np_dtype</span><span class="p">,</span> <span class="n">make_tensor</span>
<span class="kn">from</span> <span class="nn">onnx.numpy_helper</span> <span class="kn">import</span> <span class="n">from_array</span>
<span class="kn">from</span> <span class="nn">..xbuilder.shape_helper</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">all_float</span><span class="p">,</span>
    <span class="n">all_int</span><span class="p">,</span>
    <span class="n">all_int_or_float</span><span class="p">,</span>
    <span class="n">is_static_dimension</span><span class="p">,</span>
    <span class="n">is_static_shape</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">..xbuilder._dtype_helper</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">onnx_dtype_to_torch_dtype</span><span class="p">,</span>
    <span class="n">torch_dtype_to_onnx_dtype</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">..xbuilder.graph_builder</span> <span class="kn">import</span> <span class="n">GraphBuilder</span>
<span class="kn">from</span> <span class="nn">..xbuilder.shape_type_compute</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">_adjust_attributes_of_max_pool</span><span class="p">,</span>
    <span class="n">set_type_shape_unary_op</span><span class="p">,</span>
    <span class="n">set_type_shape_binary_op</span><span class="p">,</span>
    <span class="n">set_type_shape_reduce_op</span><span class="p">,</span>
    <span class="n">set_type_shape_reshape</span><span class="p">,</span>
    <span class="n">set_type_shape_matmul</span><span class="p">,</span>
    <span class="n">prepare_inputs_homogeneous_operator</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">._exceptions</span> <span class="kn">import</span> <span class="n">FunctionNotFoundError</span>


<span class="n">T</span> <span class="o">=</span> <span class="nb">str</span>


<div class="viewcode-block" id="aten_abs">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_abs">[docs]</a>
<span class="k">def</span> <span class="nf">aten_abs</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span> <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">x</span><span class="p">:</span> <span class="n">T</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;abs&quot;</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Abs&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;abs&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_acos">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_acos">[docs]</a>
<span class="k">def</span> <span class="nf">aten_acos</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span> <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">x</span><span class="p">:</span> <span class="n">T</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;acos&quot;</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Acos&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;acos&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_acosh">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_acosh">[docs]</a>
<span class="k">def</span> <span class="nf">aten_acosh</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span> <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">x</span><span class="p">:</span> <span class="n">T</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;acosh&quot;</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Acosh&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;acosh&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_add">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_add">[docs]</a>
<span class="k">def</span> <span class="nf">aten_add</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;add&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;add&quot;</span>
    <span class="n">res</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">prepare_inputs_homogeneous_operator</span><span class="p">(</span>
        <span class="n">g</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">f</span><span class="o">=</span><span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Add</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">sts</span><span class="o">=</span><span class="n">sts</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_binary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_add_Scalar">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_add_Scalar">[docs]</a>
<span class="k">def</span> <span class="nf">aten_add_Scalar</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">alpha</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;add&quot;</span>
    <span class="k">assert</span> <span class="n">alpha</span> <span class="ow">in</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;alpha=</span><span class="si">{</span><span class="n">alpha</span><span class="si">}</span><span class="s2">, not implemented&quot;</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">prepare_inputs_homogeneous_operator</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;add_Scalar&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_binary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_add_Tensor">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_add_Tensor">[docs]</a>
<span class="k">def</span> <span class="nf">aten_add_Tensor</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">alpha</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;add&quot;</span>
    <span class="k">assert</span> <span class="n">alpha</span> <span class="ow">in</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;alpha=</span><span class="si">{</span><span class="n">alpha</span><span class="si">}</span><span class="s2">, not implemented&quot;</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">prepare_inputs_homogeneous_operator</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;add_Tensor&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_binary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_and">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_and">[docs]</a>
<span class="k">def</span> <span class="nf">aten_and</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;and&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;and&quot;</span>
    <span class="n">res</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">prepare_inputs_homogeneous_operator</span><span class="p">(</span>
        <span class="n">g</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">f</span><span class="o">=</span><span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">And</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">sts</span><span class="o">=</span><span class="n">sts</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_binary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_and_">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_and_">[docs]</a>
<span class="k">def</span> <span class="nf">aten_and_</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;and&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;and&quot;</span>
    <span class="k">return</span> <span class="n">aten_and</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">sts</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;and_&quot;</span><span class="p">)</span></div>



<div class="viewcode-block" id="aten_addmm">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_addmm">[docs]</a>
<span class="k">def</span> <span class="nf">aten_addmm</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">a</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">b</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">c</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">beta</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;gemm&quot;</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Gemm</span><span class="p">(</span>
        <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="n">alpha</span><span class="p">),</span> <span class="n">beta</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="n">beta</span><span class="p">),</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;addmm&quot;</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_type</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">b</span><span class="p">))</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_rank</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_alias">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_alias">[docs]</a>
<span class="k">def</span> <span class="nf">aten_alias</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span> <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">x</span><span class="p">:</span> <span class="n">T</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;identity&quot;</span>
    <span class="k">return</span> <span class="n">g</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Identity&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;alias&quot;</span><span class="p">)</span></div>



<div class="viewcode-block" id="aten_all">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_all">[docs]</a>
<span class="k">def</span> <span class="nf">aten_all</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span> <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">x</span><span class="p">:</span> <span class="n">T</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;cast&quot;</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Cast</span><span class="p">(</span>
        <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">ReduceMin</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Cast</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">to</span><span class="o">=</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">INT32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;all&quot;</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;all&quot;</span><span class="p">),</span>
        <span class="n">to</span><span class="o">=</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">BOOL</span><span class="p">,</span>
        <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;all&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_type</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">BOOL</span><span class="p">)</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_amax">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_amax">[docs]</a>
<span class="k">def</span> <span class="nf">aten_amax</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">dim</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">keepdim</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">output_dtype</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;torch.dtype&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># noqa: F821</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;aten_amax&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;reducemax&quot;</span>
    <span class="kn">from</span> <span class="nn">._prims_functions</span> <span class="kn">import</span> <span class="n">prims_amax</span>

    <span class="k">return</span> <span class="n">prims_amax</span><span class="p">(</span>
        <span class="n">g</span><span class="p">,</span> <span class="n">sts</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">output_dtype</span><span class="o">=</span><span class="n">output_dtype</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="aten_arange">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_arange">[docs]</a>
<span class="k">def</span> <span class="nf">aten_arange</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">start</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">end</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">step</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">dtype</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;torch.dtype&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># noqa: F821</span>
    <span class="n">layout</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;torch.device&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># noqa: F821</span>
    <span class="n">pin_memory</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;arange&quot;</span><span class="p">,</span>
    <span class="n">requires_grad</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;arange&quot;</span>
    <span class="k">assert</span> <span class="p">(</span>
        <span class="n">layout</span> <span class="ow">is</span> <span class="kc">None</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;arange not implemented for layout=</span><span class="si">{</span><span class="n">layout</span><span class="si">!r}</span><span class="s2"> is not None</span><span class="si">{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">assert</span> <span class="p">(</span>
        <span class="ow">not</span> <span class="n">pin_memory</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;arange not implemented for pin_memory=True</span><span class="si">{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">assert</span> <span class="p">(</span>
        <span class="ow">not</span> <span class="n">requires_grad</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;arange not implemented when requires_grad is True</span><span class="si">{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">if</span> <span class="n">start</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">end</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">end</span> <span class="o">=</span> <span class="n">start</span>
        <span class="n">start</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="kn">import</span> <span class="nn">torch</span>
        <span class="kn">from</span> <span class="nn">torch._prims_common</span> <span class="kn">import</span> <span class="n">IntLike</span>

        <span class="c1"># coming from function arange in torch/_refs.__init__.py</span>
        <span class="n">args</span> <span class="o">=</span> <span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
        <span class="n">dt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">int64</span>
        <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">args</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">IntLike</span><span class="p">):</span>
                <span class="k">continue</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="n">it</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">it</span> <span class="o">!=</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">INT64</span><span class="p">:</span>
                    <span class="n">dt</span> <span class="o">=</span> <span class="n">onnx_dtype_to_torch_dtype</span><span class="p">(</span><span class="n">it</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">dt</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">dt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">get_default_dtype</span><span class="p">(</span><span class="n">dt</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">dt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch_dtype_to_onnx_dtype</span><span class="p">(</span><span class="n">dt</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">end</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">itype</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">end</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">end</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">itype</span> <span class="o">=</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">INT64</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">end</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
            <span class="n">itype</span> <span class="o">=</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">itype</span> <span class="o">=</span> <span class="n">torch_dtype_to_onnx_dtype</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">end</span><span class="p">))</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">itype</span> <span class="o">=</span> <span class="n">dtype</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">itype</span> <span class="o">=</span> <span class="n">torch_dtype_to_onnx_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_may_cast</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">it</span><span class="p">):</span>
        <span class="n">gi</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">gi</span> <span class="o">==</span> <span class="n">it</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">a</span>
        <span class="k">return</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Cast</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">to</span><span class="o">=</span><span class="n">it</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>

    <span class="n">dtype</span> <span class="o">=</span> <span class="n">onnx_dtype_to_torch_dtype</span><span class="p">(</span><span class="n">itype</span><span class="p">)</span>
    <span class="n">npdtype</span> <span class="o">=</span> <span class="n">tensor_dtype_to_np_dtype</span><span class="p">(</span><span class="n">itype</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">step</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">step</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">assert</span> <span class="n">start</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;start cannot be None&quot;</span>
    <span class="k">assert</span> <span class="n">end</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;end cannot be None&quot;</span>
    <span class="k">assert</span> <span class="n">step</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;step cannot be None&quot;</span>
    <span class="n">i_start</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">_may_cast</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">itype</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
        <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">npdtype</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">i_end</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">_may_cast</span><span class="p">(</span><span class="n">end</span><span class="p">,</span> <span class="n">itype</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">end</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">end</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">npdtype</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">i_step</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">_may_cast</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="n">itype</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
        <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">npdtype</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Range</span><span class="p">(</span><span class="n">i_start</span><span class="p">,</span> <span class="n">i_end</span><span class="p">,</span> <span class="n">i_step</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_type</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">itype</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">end</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">g</span><span class="o">.</span><span class="n">set_rank</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">g</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="p">((</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span> <span class="o">//</span> <span class="n">step</span><span class="p">,))</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_arange_start">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_arange_start">[docs]</a>
<span class="k">def</span> <span class="nf">aten_arange_start</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">start</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">end</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">dtype</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;torch.dtype&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># noqa: F821</span>
    <span class="n">layout</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;torch.device&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># noqa: F821</span>
    <span class="n">pin_memory</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;arange&quot;</span>
    <span class="kn">import</span> <span class="nn">torch</span>

    <span class="k">assert</span> <span class="n">layout</span> <span class="ow">in</span> <span class="p">(</span>
        <span class="kc">None</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">strided</span><span class="p">,</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;arange not implemented for layout=</span><span class="si">{</span><span class="n">layout</span><span class="si">!r}</span><span class="s2">&quot;</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="n">pin_memory</span><span class="p">,</span> <span class="s2">&quot;arange not implemented for pin_memory=True&quot;</span>
    <span class="k">return</span> <span class="n">aten_arange</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">sts</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span></div>



<div class="viewcode-block" id="aten_arange_start_step">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_arange_start_step">[docs]</a>
<span class="k">def</span> <span class="nf">aten_arange_start_step</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">start</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">end</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">step</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">dtype</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;torch.dtype&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># noqa: F821</span>
    <span class="n">layout</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;torch.device&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># noqa: F821</span>
    <span class="n">pin_memory</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;arange&quot;</span>
    <span class="kn">import</span> <span class="nn">torch</span>

    <span class="k">assert</span> <span class="n">layout</span> <span class="ow">in</span> <span class="p">(</span>
        <span class="kc">None</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">strided</span><span class="p">,</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;arange not implemented for layout=</span><span class="si">{</span><span class="n">layout</span><span class="si">!r}</span><span class="s2"> is not None&quot;</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="n">pin_memory</span><span class="p">,</span> <span class="s2">&quot;arange not implemented for pin_memory=True&quot;</span>
    <span class="k">return</span> <span class="n">aten_arange</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">sts</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span></div>



<div class="viewcode-block" id="aten_argmax">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_argmax">[docs]</a>
<span class="k">def</span> <span class="nf">aten_argmax</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">dim</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">keepdim</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;argmax&quot;</span>
    <span class="k">if</span> <span class="n">dim</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">xf</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">SqueezeAnyOpset</span><span class="p">(</span>
            <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">ArgMax</span><span class="p">(</span><span class="n">xf</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span> <span class="k">if</span> <span class="n">keepdim</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)),</span>
            <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;argmax&quot;</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">ArgMax</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="mi">1</span> <span class="k">if</span> <span class="n">keepdim</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;argmax&quot;</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unexpected type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span><span class="si">}</span><span class="s2"> for dim&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_type</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">INT64</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">dim</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">g</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,))</span>
        <span class="k">elif</span> <span class="n">g</span><span class="o">.</span><span class="n">has_shape</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
            <span class="n">sh</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">g</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="p">(</span><span class="n">sh</span><span class="p">[</span><span class="n">dim</span><span class="p">],))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">g</span><span class="o">.</span><span class="n">set_rank</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_as_strided">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_as_strided">[docs]</a>
<span class="k">def</span> <span class="nf">aten_as_strided</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">size</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">stride</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">storage_offset</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;as_strided&quot;</span>
    <span class="k">assert</span> <span class="kc">False</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;The implementation is still incorrect</span><span class="si">{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>

    <span class="kn">import</span> <span class="nn">torch</span>
    <span class="kn">from</span> <span class="nn">torch.fx.experimental.proxy_tensor</span> <span class="kn">import</span> <span class="n">maybe_disable_fake_tensor_mode</span>

    <span class="k">assert</span> <span class="n">g</span><span class="o">.</span><span class="n">has_shape</span><span class="p">(</span>
        <span class="n">x</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;not implemented when shape of x is not known</span><span class="si">{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">maybe_disable_fake_tensor_mode</span><span class="p">():</span>
        <span class="n">tindices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">strided</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_strided</span><span class="p">(</span><span class="n">tindices</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">storage_offset</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">RuntimeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;error with as_strided, x=</span><span class="si">{</span><span class="n">x</span><span class="si">!r}</span><span class="s2">, shape=</span><span class="si">{</span><span class="n">shape</span><span class="si">!r}</span><span class="s2">, n=</span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2">, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;storage_offset=</span><span class="si">{</span><span class="n">storage_offset</span><span class="si">}</span><span class="s2">, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;size=</span><span class="si">{</span><span class="n">size</span><span class="si">}</span><span class="s2">, stride=</span><span class="si">{</span><span class="n">stride</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">e</span><span class="si">}{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span> <span class="kn">from</span> <span class="nn">e</span>
        <span class="n">np_strided</span> <span class="o">=</span> <span class="n">strided</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

    <span class="n">flat</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span>
    <span class="n">xflat</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Gather</span><span class="p">(</span><span class="n">flat</span><span class="p">,</span> <span class="n">np_strided</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Reshape</span><span class="p">(</span><span class="n">xflat</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_type</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">size</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_asin">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_asin">[docs]</a>
<span class="k">def</span> <span class="nf">aten_asin</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span> <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">x</span><span class="p">:</span> <span class="n">T</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;asin&quot;</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Asin&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;asin&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_asinh">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_asinh">[docs]</a>
<span class="k">def</span> <span class="nf">aten_asinh</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span> <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">x</span><span class="p">:</span> <span class="n">T</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;asinh&quot;</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Asinh&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;asinh&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_atan">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_atan">[docs]</a>
<span class="k">def</span> <span class="nf">aten_atan</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span> <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">x</span><span class="p">:</span> <span class="n">T</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;atan&quot;</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Atan&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;atan&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_atanh">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_atanh">[docs]</a>
<span class="k">def</span> <span class="nf">aten_atanh</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span> <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">x</span><span class="p">:</span> <span class="n">T</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;atanh&quot;</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Atanh&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;atanh&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_bmm">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_bmm">[docs]</a>
<span class="k">def</span> <span class="nf">aten_bmm</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span> <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">T</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;bmm&quot;</span>
    <span class="k">assert</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">==</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;type mismatch between </span><span class="si">{</span><span class="n">x</span><span class="si">!r}</span><span class="s2">:</span><span class="si">{</span><span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="si">}</span><span class="s2"> and &quot;</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">y</span><span class="si">!r}</span><span class="s2">:</span><span class="si">{</span><span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="si">}{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">MatMul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;bmm&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_matmul</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_cat">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_cat">[docs]</a>
<span class="k">def</span> <span class="nf">aten_cat</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">tensors</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">T</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
    <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;cat&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;concat&quot;</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">tensors</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;No tensor to concat</span><span class="si">{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">tensors</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Not enough tensors to concat</span><span class="si">{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Concat</span><span class="p">(</span><span class="o">*</span><span class="n">tensors</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;cat&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">dt0</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="o">==</span> <span class="n">dt0</span><span class="p">,</span> <span class="n">tensors</span><span class="p">))</span>
        <span class="n">r0</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_rank</span><span class="p">(</span><span class="n">tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">g</span><span class="o">.</span><span class="n">get_rank</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="o">==</span> <span class="n">r0</span><span class="p">,</span> <span class="n">tensors</span><span class="p">))</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_type</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dt0</span><span class="p">)</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_rank</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">r0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_clone">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_clone">[docs]</a>
<span class="k">def</span> <span class="nf">aten_clone</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">memory_format</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;clone&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;identity&quot;</span>
    <span class="kn">import</span> <span class="nn">torch</span>

    <span class="k">assert</span> <span class="p">(</span>
        <span class="n">memory_format</span> <span class="ow">is</span> <span class="kc">None</span>
        <span class="ow">or</span> <span class="n">memory_format</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">contiguous_format</span>
        <span class="ow">or</span> <span class="n">memory_format</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Unexpected value for memory_format=</span><span class="si">{</span><span class="n">memory_format</span><span class="si">!r}{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">return</span> <span class="n">g</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Identity&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span></div>



<div class="viewcode-block" id="aten_convolution">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_convolution">[docs]</a>
<span class="k">def</span> <span class="nf">aten_convolution</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="nb">input</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">weight</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">bias</span><span class="p">:</span> <span class="n">T</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">stride</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,),</span>
    <span class="n">padding</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,),</span>
    <span class="n">dilation</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,),</span>
    <span class="n">transposed</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">output_padding</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,),</span>
    <span class="n">groups</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;conv&quot;</span>
    <span class="k">if</span> <span class="n">transposed</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">FunctionNotFoundError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;aten_convolution does not support transposed=</span><span class="si">{</span><span class="n">transposed</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">output_padding</span> <span class="ow">and</span> <span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">output_padding</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="nb">max</span><span class="p">(</span><span class="n">output_padding</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">):</span>
        <span class="k">raise</span> <span class="n">FunctionNotFoundError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;aten_convolution does not support output_padding=</span><span class="si">{</span><span class="n">output_padding</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">padding</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">):</span>
        <span class="n">padding</span> <span class="o">=</span> <span class="p">(</span><span class="n">padding</span><span class="p">,</span> <span class="n">padding</span><span class="p">)</span>
    <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="o">*</span><span class="n">padding</span><span class="p">,</span> <span class="o">*</span><span class="n">padding</span><span class="p">]</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dilation</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">):</span>
        <span class="n">dilation</span> <span class="o">=</span> <span class="p">(</span><span class="n">dilation</span><span class="p">,</span> <span class="n">dilation</span><span class="p">)</span>
    <span class="n">dilations</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">dilation</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">stride</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">):</span>
        <span class="n">stride</span> <span class="o">=</span> <span class="p">(</span><span class="n">stride</span><span class="p">,</span> <span class="n">stride</span><span class="p">)</span>
    <span class="n">strides</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">stride</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">bias</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">g</span><span class="o">.</span><span class="n">main_opset</span> <span class="o">&gt;=</span> <span class="mi">13</span><span class="p">:</span>
            <span class="n">weight_dim_0</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Shape&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">weight</span><span class="p">],</span> <span class="n">start</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;conv&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">g</span><span class="o">.</span><span class="n">main_opset</span> <span class="o">&gt;=</span> <span class="mi">13</span><span class="p">:</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Shape</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;conv&quot;</span><span class="p">)</span>
            <span class="n">weight_dim_0</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Slice</span><span class="p">(</span>
                <span class="n">shape</span><span class="p">,</span>
                <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
                <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
                <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
                <span class="n">name</span><span class="o">=</span><span class="s2">&quot;conv&quot;</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Shape</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;conv&quot;</span><span class="p">)</span>
            <span class="n">weight_dim_0</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Slice</span><span class="p">(</span>
                <span class="n">shape</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">starts</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ends</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;conv&quot;</span>
            <span class="p">)</span>
        <span class="n">cst1</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">make_initializer</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span>
        <span class="n">bias_shape</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Expand&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">weight_dim_0</span><span class="p">,</span> <span class="n">cst1</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;conv&quot;</span><span class="p">)</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">tensor_dtype_to_np_dtype</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="nb">input</span><span class="p">))</span>
        <span class="n">bias</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Expand</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">),</span> <span class="n">bias_shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;conv&quot;</span><span class="p">)</span>

    <span class="c1"># if Rank(input) != Rank(weight):</span>
    <span class="c1">#    input = op.UnsqueezeAnyOpset(input, op.Constant(value_ints=[0]))</span>

    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
        <span class="s2">&quot;Conv&quot;</span><span class="p">,</span>
        <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">],</span>
        <span class="n">outputs</span><span class="p">,</span>
        <span class="n">strides</span><span class="o">=</span><span class="n">strides</span><span class="p">,</span>
        <span class="n">pads</span><span class="o">=</span><span class="n">pads</span><span class="p">,</span>
        <span class="n">group</span><span class="o">=</span><span class="n">groups</span><span class="p">,</span>
        <span class="n">dilations</span><span class="o">=</span><span class="n">dilations</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;conv&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_type</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="nb">input</span><span class="p">))</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_rank</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">get_rank</span><span class="p">(</span><span class="nb">input</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_conv2d">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_conv2d">[docs]</a>
<span class="k">def</span> <span class="nf">aten_conv2d</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="nb">input</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">weight</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">bias</span><span class="p">:</span> <span class="n">T</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">stride</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="n">padding</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
    <span class="n">dilation</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="n">groups</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;conv&quot;</span>
    <span class="k">return</span> <span class="n">aten_convolution</span><span class="p">(</span>
        <span class="n">g</span><span class="p">,</span>
        <span class="n">sts</span><span class="p">,</span>
        <span class="n">outputs</span><span class="p">,</span>
        <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span>
        <span class="n">weight</span><span class="o">=</span><span class="n">weight</span><span class="p">,</span>
        <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
        <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
        <span class="n">dilation</span><span class="o">=</span><span class="n">dilation</span><span class="p">,</span>
        <span class="n">groups</span><span class="o">=</span><span class="n">groups</span><span class="p">,</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="aten_copy">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_copy">[docs]</a>
<span class="k">def</span> <span class="nf">aten_copy</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">src</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">non_blocking</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;copy&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;identity&quot;</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="n">non_blocking</span><span class="p">,</span> <span class="s2">&quot;copy implemented when non_blocking is True&quot;</span>
    <span class="k">if</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">==</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">src</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Identity</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">CastLike</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span></div>



<div class="viewcode-block" id="aten_copy_">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_copy_">[docs]</a>
<span class="k">def</span> <span class="nf">aten_copy_</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">src</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">non_blocking</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;identity&quot;</span>
    <span class="k">return</span> <span class="n">aten_copy</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">sts</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">non_blocking</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;copy_&quot;</span><span class="p">)</span></div>



<div class="viewcode-block" id="aten_cos">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_cos">[docs]</a>
<span class="k">def</span> <span class="nf">aten_cos</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;cos&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;cos&quot;</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Cos&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_cosh">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_cosh">[docs]</a>
<span class="k">def</span> <span class="nf">aten_cosh</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span> <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">x</span><span class="p">:</span> <span class="n">T</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;cosh&quot;</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Cosh&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;cosh&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_detach">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_detach">[docs]</a>
<span class="k">def</span> <span class="nf">aten_detach</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span> <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">x</span><span class="p">:</span> <span class="n">T</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;identity&quot;</span>
    <span class="k">return</span> <span class="n">g</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Identity&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;detach&quot;</span><span class="p">)</span></div>



<div class="viewcode-block" id="aten_div">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_div">[docs]</a>
<span class="k">def</span> <span class="nf">aten_div</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;div&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;div&quot;</span>
    <span class="n">res</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">prepare_inputs_homogeneous_operator</span><span class="p">(</span>
        <span class="n">g</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">f</span><span class="o">=</span><span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Div</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">sts</span><span class="o">=</span><span class="n">sts</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_binary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_div_Scalar">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_div_Scalar">[docs]</a>
<span class="k">def</span> <span class="nf">aten_div_Scalar</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span> <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">T</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;div&quot;</span>
    <span class="k">return</span> <span class="n">aten_div</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">sts</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;div_Scalar&quot;</span><span class="p">)</span></div>



<div class="viewcode-block" id="aten_div_Tensor">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_div_Tensor">[docs]</a>
<span class="k">def</span> <span class="nf">aten_div_Tensor</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">alpha</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;div&quot;</span>
    <span class="k">assert</span> <span class="n">alpha</span> <span class="ow">in</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;alpha=</span><span class="si">{</span><span class="n">alpha</span><span class="si">}</span><span class="s2">, not implemented&quot;</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">prepare_inputs_homogeneous_operator</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Div</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;div_Tensor&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_binary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_dropout">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_dropout">[docs]</a>
<span class="k">def</span> <span class="nf">aten_dropout</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">p</span><span class="p">:</span> <span class="n">T</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>  <span class="c1"># float</span>
    <span class="n">training</span><span class="p">:</span> <span class="n">T</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>  <span class="c1"># bool</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;dropout&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">training</span><span class="p">,</span> <span class="nb">bool</span><span class="p">):</span>
        <span class="n">training</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">training</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">bool_</span><span class="p">)</span>
    <span class="n">result</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span></div>



<div class="viewcode-block" id="aten_elu">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_elu">[docs]</a>
<span class="k">def</span> <span class="nf">aten_elu</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="n">scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="n">input_scale</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">inplace</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;elu&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;elu&quot;</span>
    <span class="k">assert</span> <span class="p">(</span>
        <span class="n">input_scale</span> <span class="o">==</span> <span class="mi">1</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;not implemented when input_scale=</span><span class="si">{</span><span class="n">input_scale</span><span class="si">}{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">assert</span> <span class="p">(</span>
        <span class="ow">not</span> <span class="n">inplace</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;inplace computation is not allowed with onnx</span><span class="si">{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">if</span> <span class="n">scale</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Elu</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="n">alpha</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">nptype</span> <span class="o">=</span> <span class="n">tensor_dtype_to_np_dtype</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">elu</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Elu</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="n">alpha</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Mul</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">scale</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nptype</span><span class="p">),</span> <span class="n">elu</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">elu</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_embedding">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_embedding">[docs]</a>
<span class="k">def</span> <span class="nf">aten_embedding</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">weight</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">indices</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">padding_idx</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">max_norm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">norm_type</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">2.0</span><span class="p">,</span>
    <span class="n">scale_grad_by_freq</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">sparse</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;embedding&quot;</span>
    <span class="k">if</span> <span class="p">(</span>
        <span class="p">(</span><span class="n">padding_idx</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">padding_idx</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span>
        <span class="ow">or</span> <span class="n">scale_grad_by_freq</span>
        <span class="ow">or</span> <span class="n">sparse</span>
        <span class="ow">or</span> <span class="n">max_norm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Not implemented when padding_idx=</span><span class="si">{</span><span class="n">padding_idx</span><span class="si">}</span><span class="s2">, or &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;scale_grad_by_freq=</span><span class="si">{</span><span class="n">scale_grad_by_freq</span><span class="si">}</span><span class="s2"> or sparse=</span><span class="si">{</span><span class="n">sparse</span><span class="si">}</span><span class="s2"> &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;or max_norm=</span><span class="si">{</span><span class="n">max_norm</span><span class="si">}</span><span class="s2"> or norm_type=</span><span class="si">{</span><span class="n">norm_type</span><span class="si">}</span><span class="s2"> &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;are different from the default values.&quot;</span>
        <span class="p">)</span>
    <span class="k">assert</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span> <span class="o">==</span> <span class="mi">7</span><span class="p">,</span> <span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;indices be integer not </span><span class="si">{</span><span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span><span class="si">}</span><span class="s2">, &quot;</span>
        <span class="sa">f</span><span class="s2">&quot;weight is </span><span class="si">{</span><span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="p">)</span>

    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Gather</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;embedding&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_type</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">weight</span><span class="p">))</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_rank</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">get_rank</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span> <span class="o">+</span> <span class="n">g</span><span class="o">.</span><span class="n">get_rank</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_empty_like">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_empty_like">[docs]</a>
<span class="k">def</span> <span class="nf">aten_empty_like</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">dtype</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;torch.dtype&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># noqa: F821</span>
    <span class="n">layout</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;torch.device&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># noqa: F821</span>
    <span class="n">pin_memory</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">memory_format</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;constantofshape&quot;</span>
    <span class="k">return</span> <span class="n">aten_full</span><span class="p">(</span>
        <span class="n">g</span><span class="p">,</span>
        <span class="n">sts</span><span class="p">,</span>
        <span class="n">outputs</span><span class="p">,</span>
        <span class="n">x</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span> <span class="ow">or</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;empty_like&quot;</span><span class="p">,</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="aten_empty_permuted">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_empty_permuted">[docs]</a>
<span class="k">def</span> <span class="nf">aten_empty_permuted</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">size</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">physical_layout</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">dtype</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;torch.dtype&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># noqa: F821</span>
    <span class="n">layout</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;torch.device&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># noqa: F821</span>
    <span class="n">requires_grad</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">pin_memory</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;empty_permuted&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;constantofshape&quot;</span>
    <span class="c1"># strided is unused.</span>
    <span class="k">assert</span> <span class="nb">list</span><span class="p">(</span><span class="n">physical_layout</span><span class="p">)</span> <span class="o">==</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">physical_layout</span><span class="p">))),</span> <span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;empty_permuted not implemented when physical_layout=</span><span class="si">{</span><span class="n">physical_layout</span><span class="si">}</span><span class="s2">, &quot;</span>
        <span class="sa">f</span><span class="s2">&quot;size=</span><span class="si">{</span><span class="n">size</span><span class="si">}{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">aten_zeros</span><span class="p">(</span>
        <span class="n">g</span><span class="p">,</span>
        <span class="n">sts</span><span class="p">,</span>
        <span class="n">outputs</span><span class="p">,</span>
        <span class="n">size</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">layout</span><span class="o">=</span><span class="n">layout</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
        <span class="n">pin_memory</span><span class="o">=</span><span class="n">pin_memory</span><span class="p">,</span>
        <span class="n">requires_grad</span><span class="o">=</span><span class="n">requires_grad</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="aten_empty_strided">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_empty_strided">[docs]</a>
<span class="k">def</span> <span class="nf">aten_empty_strided</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">size</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">stride</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">dtype</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;torch.dtype&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># noqa: F821</span>
    <span class="n">layout</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;torch.device&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># noqa: F821</span>
    <span class="n">requires_grad</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">pin_memory</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;empty_strided&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;constantofshape&quot;</span>
    <span class="c1"># strided is unused.</span>
    <span class="k">return</span> <span class="n">aten_zeros</span><span class="p">(</span>
        <span class="n">g</span><span class="p">,</span>
        <span class="n">sts</span><span class="p">,</span>
        <span class="n">outputs</span><span class="p">,</span>
        <span class="n">size</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">layout</span><span class="o">=</span><span class="n">layout</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
        <span class="n">pin_memory</span><span class="o">=</span><span class="n">pin_memory</span><span class="p">,</span>
        <span class="n">requires_grad</span><span class="o">=</span><span class="n">requires_grad</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="aten__enter_autocast">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten__enter_autocast">[docs]</a>
<span class="k">def</span> <span class="nf">aten__enter_autocast</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span> <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">]</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the function returns a dummy which will be removed</span>
<span class="sd">    after the graph is created.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">or</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">{</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span> <span class="s2">&quot;cuda&quot;</span><span class="p">},</span> <span class="n">args</span><span class="p">)),</span> <span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;The function should not take any tensors as input but types are &quot;</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="p">[</span><span class="nb">type</span><span class="p">(</span><span class="n">_</span><span class="p">)</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">_</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">args</span><span class="p">]</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">args</span><span class="si">}{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">g</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Constant&quot;</span><span class="p">,</span> <span class="p">[],</span> <span class="n">value_floats</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;_enter_autocast&quot;</span><span class="p">)</span></div>



<div class="viewcode-block" id="aten_eq">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_eq">[docs]</a>
<span class="k">def</span> <span class="nf">aten_eq</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;eq&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;equal&quot;</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">prepare_inputs_homogeneous_operator</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Equal</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_binary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cmp_op</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_eq_Tensor">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_eq_Tensor">[docs]</a>
<span class="k">def</span> <span class="nf">aten_eq_Tensor</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;eq_Tensor&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;equal&quot;</span>
    <span class="k">return</span> <span class="n">aten_eq</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">sts</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span></div>



<div class="viewcode-block" id="aten_eq_Scalar">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_eq_Scalar">[docs]</a>
<span class="k">def</span> <span class="nf">aten_eq_Scalar</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span> <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">T</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;equal&quot;</span>
    <span class="k">return</span> <span class="n">aten_eq</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">sts</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span></div>



<div class="viewcode-block" id="aten_exp">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_exp">[docs]</a>
<span class="k">def</span> <span class="nf">aten_exp</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;exp&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;exp&quot;</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Exp&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten__exit_autocast">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten__exit_autocast">[docs]</a>
<span class="k">def</span> <span class="nf">aten__exit_autocast</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">output_of_enter_auto_cast</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the function returns a dummy which will be removed</span>
<span class="sd">    after the graph is created.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">g</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Identity&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">output_of_enter_auto_cast</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;_exit_autocast&quot;</span><span class="p">)</span></div>



<div class="viewcode-block" id="aten_expand">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_expand">[docs]</a>
<span class="k">def</span> <span class="nf">aten_expand</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">sizes</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">T</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]],</span>
    <span class="n">implicit</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;expand&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;expand&quot;</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="n">implicit</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Unexpected value for implicit=</span><span class="si">{</span><span class="n">implicit</span><span class="si">!r}</span><span class="s2">&quot;</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sizes</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="n">all_int</span><span class="p">(</span><span class="n">sizes</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">min</span><span class="p">(</span><span class="n">sizes</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># static sizes</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Expand</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">sizes</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
            <span class="n">g</span><span class="o">.</span><span class="n">set_type</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
            <span class="n">g</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">sizes</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">res</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sizes</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="n">g</span><span class="o">.</span><span class="n">has_shape</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span>
            <span class="n">sizes</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Unexpected shape=</span><span class="si">{</span><span class="n">shape</span><span class="si">}</span><span class="s2"> for x as sizes=</span><span class="si">{</span><span class="n">sizes</span><span class="si">}{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="n">new_shape</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">is_static</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">for</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">sizes</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">b</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
                <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="nb">int</span><span class="p">),</span> <span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Not implemented when the shape is not fully known, &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;shape=</span><span class="si">{</span><span class="n">shape</span><span class="si">}</span><span class="s2"> for x as sizes=</span><span class="si">{</span><span class="n">sizes</span><span class="si">}{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
                <span class="n">new_shape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">new_shape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
                <span class="n">is_static</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">i_new_shape</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">new_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">is_static</span>
            <span class="k">else</span> <span class="n">g</span><span class="o">.</span><span class="n">make_shape_from_results</span><span class="p">(</span><span class="n">new_shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">_neg&quot;</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Expand</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">i_new_shape</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">_neg&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
            <span class="n">g</span><span class="o">.</span><span class="n">set_type</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
            <span class="n">g</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">new_shape</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">res</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sizes</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
        <span class="c1"># A combination of static and dynamic dimensions.</span>
        <span class="n">new_shape</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">make_shape_from_results</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">sizes</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">_dyn&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">new_shape</span> <span class="o">=</span> <span class="n">sizes</span>

    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Expand</span><span class="p">(</span>
        <span class="n">x</span><span class="p">,</span>
        <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Abs</span><span class="p">(</span><span class="n">new_shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">_dyn&quot;</span><span class="p">),</span>
        <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">_dyn&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_type</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_rank</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">sizes</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_fill_Scalar">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_fill_Scalar">[docs]</a>
<span class="k">def</span> <span class="nf">aten_fill_Scalar</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span> <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span> <span class="n">v</span><span class="p">:</span> <span class="n">T</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;constantofshape&quot;</span>
    <span class="k">if</span> <span class="n">g</span><span class="o">.</span><span class="n">has_shape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="ow">and</span> <span class="n">is_static_shape</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(</span><span class="n">x</span><span class="p">)):</span>
        <span class="k">return</span> <span class="n">aten_full</span><span class="p">(</span>
            <span class="n">g</span><span class="p">,</span>
            <span class="n">sts</span><span class="p">,</span>
            <span class="n">outputs</span><span class="p">,</span>
            <span class="n">g</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
            <span class="n">v</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;fill_Scalar&quot;</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;fill is not implemented when shape is not fully known</span><span class="si">{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="aten_flatten">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_flatten">[docs]</a>
<span class="k">def</span> <span class="nf">aten_flatten</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">start_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">end_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;flatten&quot;</span>
    <span class="k">if</span> <span class="n">start_dim</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">start_dim</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">end_dim</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Shape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;flatten&quot;</span><span class="p">)</span>
            <span class="n">take</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">GatherElements</span><span class="p">(</span>
                <span class="n">shape</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;flatten&quot;</span>
            <span class="p">)</span>
            <span class="n">resh</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Concat</span><span class="p">(</span>
                <span class="n">take</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;flatten&quot;</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">resh</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;flatten&quot;</span><span class="p">)</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;start_dim=</span><span class="si">{</span><span class="n">start_dim</span><span class="si">}</span><span class="s2">, end_dim=</span><span class="si">{</span><span class="n">end_dim</span><span class="si">}</span><span class="s2"> not supported.&quot;</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">end_dim</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">g</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Flatten&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;flatten&quot;</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Flatten&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">to</span><span class="o">=</span><span class="n">end_dim</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_type</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">g</span><span class="o">.</span><span class="n">has_shape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">full</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
            <span class="n">g</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(</span><span class="n">x</span><span class="p">)))))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">g</span><span class="o">.</span><span class="n">set_rank</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_full">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_full">[docs]</a>
<span class="k">def</span> <span class="nf">aten_full</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">size</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">fill_value</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">dtype</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;torch.dtype&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># noqa: F821</span>
    <span class="n">layout</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;torch.device&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># noqa: F821</span>
    <span class="n">pin_memory</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">requires_grad</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;full&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;constantofshape&quot;</span>
    <span class="kn">import</span> <span class="nn">torch</span>

    <span class="k">assert</span> <span class="n">layout</span> <span class="ow">in</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">strided</span><span class="p">),</span> <span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;full not implemented for layout=</span><span class="si">{</span><span class="n">layout</span><span class="si">!r}</span><span class="s2"> is not None, &quot;</span>
        <span class="sa">f</span><span class="s2">&quot;size=</span><span class="si">{</span><span class="n">size</span><span class="si">!r}</span><span class="s2">, dtype=</span><span class="si">{</span><span class="n">dtype</span><span class="si">}{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="p">)</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="n">requires_grad</span><span class="p">,</span> <span class="s2">&quot;aten_full does not implement requires_grad&quot;</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="n">pin_memory</span><span class="p">,</span> <span class="s2">&quot;full not implemented for pin_memory=True&quot;</span>
    <span class="k">assert</span> <span class="n">fill_value</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span>
        <span class="n">fill_value</span><span class="p">,</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Unexpected type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">fill_value</span><span class="p">)</span><span class="si">}</span><span class="s2"> for fill_value.&quot;</span>

    <span class="n">new_shape</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="n">all_int</span><span class="p">(</span><span class="n">size</span><span class="p">):</span>
        <span class="n">tsize</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
        <span class="n">new_shape</span> <span class="o">=</span> <span class="n">size</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">all_int</span><span class="p">(</span><span class="n">size</span><span class="p">):</span>
            <span class="n">tsize</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
            <span class="n">new_shape</span> <span class="o">=</span> <span class="n">size</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tsize</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">make_shape_from_results</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">g</span><span class="o">.</span><span class="n">has_shape</span><span class="p">(</span><span class="n">size</span><span class="p">)</span> <span class="ow">and</span> <span class="n">is_static_shape</span><span class="p">(</span><span class="n">size</span><span class="p">):</span>
            <span class="n">tsize</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(</span><span class="n">size</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tsize</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Shape</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unexpected type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">size</span><span class="p">)</span><span class="si">}</span><span class="s2"> for size.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">fill_value</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">fill_value</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">fill_value</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,))</span>
            <span class="n">itype</span> <span class="o">=</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">fill_value</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">fill_value</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,))</span>
            <span class="n">itype</span> <span class="o">=</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">INT64</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">itype</span> <span class="o">=</span> <span class="n">torch_dtype_to_onnx_dtype</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">fill_value</span><span class="p">))</span>
            <span class="n">ntype</span> <span class="o">=</span> <span class="n">tensor_dtype_to_np_dtype</span><span class="p">(</span><span class="n">itype</span><span class="p">)</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">fill_value</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ntype</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">itype</span> <span class="o">=</span> <span class="n">dtype</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="k">else</span> <span class="n">torch_dtype_to_onnx_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">ntype</span> <span class="o">=</span> <span class="n">tensor_dtype_to_np_dtype</span><span class="p">(</span><span class="n">itype</span><span class="p">)</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">fill_value</span> <span class="ow">or</span> <span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ntype</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,))</span>

    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">ConstantOfShape</span><span class="p">(</span>
        <span class="n">tsize</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">from_array</span><span class="p">(</span><span class="n">value</span><span class="p">),</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;name&quot;</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_type</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">itype</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">new_shape</span><span class="p">:</span>
            <span class="n">g</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">new_shape</span><span class="p">)</span>

    <span class="c1"># size = op.Cast(size, to=INT64.dtype)</span>
    <span class="c1"># fill_value = op.Cast(fill_value, to=dtype)</span>
    <span class="c1"># return op.Expand(fill_value, size)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_full_like">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_full_like">[docs]</a>
<span class="k">def</span> <span class="nf">aten_full_like</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">fill_value</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">dtype</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;torch.dtype&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># noqa: F821</span>
    <span class="n">layout</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;torch.device&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># noqa: F821</span>
    <span class="n">pin_memory</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">memory_format</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;full_like&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;constantofshape&quot;</span>
    <span class="kn">import</span> <span class="nn">torch</span>

    <span class="k">assert</span> <span class="p">(</span>
        <span class="n">layout</span> <span class="ow">is</span> <span class="kc">None</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;empty_like not implemented for layout=</span><span class="si">{</span><span class="n">layout</span><span class="si">!r}</span><span class="s2"> is not None&quot;</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="n">pin_memory</span><span class="p">,</span> <span class="s2">&quot;empty_like not implemented for pin_memory=True&quot;</span>
    <span class="k">assert</span> <span class="p">(</span>
        <span class="n">memory_format</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">memory_format</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;empty_like not implemented for memory_format=</span><span class="si">{</span><span class="n">memory_format</span><span class="si">}</span><span class="s2">&quot;</span>

    <span class="k">if</span> <span class="n">g</span><span class="o">.</span><span class="n">has_shape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="ow">and</span> <span class="n">is_static_shape</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(</span><span class="n">x</span><span class="p">)):</span>
        <span class="c1"># simple case</span>
        <span class="k">return</span> <span class="n">aten_full</span><span class="p">(</span>
            <span class="n">g</span><span class="p">,</span>
            <span class="n">sts</span><span class="p">,</span>
            <span class="n">outputs</span><span class="p">,</span>
            <span class="n">g</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
            <span class="n">fill_value</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span> <span class="ow">or</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
            <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">aten_full</span><span class="p">(</span>
        <span class="n">g</span><span class="p">,</span>
        <span class="n">sts</span><span class="p">,</span>
        <span class="n">outputs</span><span class="p">,</span>
        <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Shape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;full_like&quot;</span><span class="p">),</span>
        <span class="n">fill_value</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span> <span class="ow">or</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
        <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="aten_FunctionCtx">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_FunctionCtx">[docs]</a>
<span class="k">def</span> <span class="nf">aten_FunctionCtx</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span> <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
<span class="p">):</span>
    <span class="s2">&quot;not implemented&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;args=</span><span class="si">{</span><span class="n">args</span><span class="si">}</span><span class="s2">, kwargs=</span><span class="si">{</span><span class="n">kwargs</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span></div>



<div class="viewcode-block" id="aten_ge">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_ge">[docs]</a>
<span class="k">def</span> <span class="nf">aten_ge</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;ge&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;greater or equal&quot;</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">prepare_inputs_homogeneous_operator</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">GreaterOrEqual</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_binary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cmp_op</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_ge_Tensor">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_ge_Tensor">[docs]</a>
<span class="k">def</span> <span class="nf">aten_ge_Tensor</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span> <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">T</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;greater or equal&quot;</span>
    <span class="k">return</span> <span class="n">aten_ge</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">sts</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;ge_Tensor&quot;</span><span class="p">)</span></div>



<div class="viewcode-block" id="aten_gt">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_gt">[docs]</a>
<span class="k">def</span> <span class="nf">aten_gt</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;gt&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;greater&quot;</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">prepare_inputs_homogeneous_operator</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Greater</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_binary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cmp_op</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_gt_Tensor">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_gt_Tensor">[docs]</a>
<span class="k">def</span> <span class="nf">aten_gt_Tensor</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span> <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">T</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;greater&quot;</span>
    <span class="k">return</span> <span class="n">aten_gt</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">sts</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;gt_Tensor&quot;</span><span class="p">)</span></div>



<div class="viewcode-block" id="aten_index_Tensor">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_index_Tensor">[docs]</a>
<span class="k">def</span> <span class="nf">aten_index_Tensor</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">indices</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;[...,:, ...]&quot;</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
        <span class="n">indices</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Unexpected type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span><span class="si">}</span><span class="s2"> for indices&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">indices</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">aten_index_select</span><span class="p">(</span>
            <span class="n">g</span><span class="p">,</span> <span class="n">sts</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">indices</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;index1_Tensor&quot;</span>
        <span class="p">)</span>
    <span class="n">n_none</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">indices</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">n_none</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># only one dimension is not None, the other must be added</span>
        <span class="n">position</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span> <span class="k">if</span> <span class="n">v</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">index</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[</span><span class="n">position</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">res</span> <span class="o">=</span> <span class="n">aten_index_select</span><span class="p">(</span>
                <span class="n">g</span><span class="p">,</span>
                <span class="n">sts</span><span class="p">,</span>
                <span class="kc">None</span><span class="p">,</span>
                <span class="n">x</span><span class="p">,</span>
                <span class="n">dim</span><span class="o">=</span><span class="n">position</span><span class="p">,</span>
                <span class="n">index</span><span class="o">=</span><span class="n">index</span><span class="p">,</span>
                <span class="n">name</span><span class="o">=</span><span class="s2">&quot;index2_Tensor&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">to_add</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">))</span> <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">position</span><span class="p">)</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="nb">len</span><span class="p">(</span><span class="n">to_add</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>
            <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Unexpected value for to_add=</span><span class="si">{</span><span class="n">to_add</span><span class="si">}</span><span class="s2">, position=</span><span class="si">{</span><span class="n">position</span><span class="si">}</span><span class="s2">, indices=</span><span class="si">{</span><span class="n">indices</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="c1"># res = g.op.UnsqueezeAnyOpset(</span>
            <span class="c1">#     temp, np.array(to_add, dtype=np.int64), outputs=outputs</span>
            <span class="c1"># )</span>
            <span class="c1"># if not sts:</span>
            <span class="c1">#     g.set_type(res, g.get_type(x))</span>
            <span class="c1">#     if g.has_shape(temp):</span>
            <span class="c1">#         shape = list(g.get_shape(temp))</span>
            <span class="c1">#         for i in to_add:</span>
            <span class="c1">#            shape.insert(i, 1)</span>
            <span class="c1">#         g.set_shape(res, tuple(shape))</span>
            <span class="c1">#     else:</span>
            <span class="c1">#         g.set_rank(res, g.get_rank(temp) + 2)</span>
            <span class="k">return</span> <span class="n">res</span>

    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;aten_index_Tensor not implemented yet for indices=</span><span class="si">{</span><span class="n">indices</span><span class="si">}</span><span class="s2">, &quot;</span>
        <span class="sa">f</span><span class="s2">&quot;n_none=</span><span class="si">{</span><span class="n">n_none</span><span class="si">}{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="aten_index_put">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_index_put">[docs]</a>
<span class="k">def</span> <span class="nf">aten_index_put</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">indices</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">T</span><span class="p">],</span>
    <span class="n">values</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">accumulate</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;aten_index_put&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;[...,:, ...]&quot;</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
        <span class="n">indices</span><span class="p">,</span> <span class="nb">list</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Unexpected type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span><span class="si">}{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">assert</span> <span class="p">(</span>
        <span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Not implementeded for indices=</span><span class="si">{</span><span class="n">indices</span><span class="si">}{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">assert</span> <span class="n">g</span><span class="o">.</span><span class="n">has_shape</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Missing shape for </span><span class="si">{</span><span class="n">x</span><span class="si">!r}{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>

    <span class="n">index</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># tensor</span>
    <span class="n">index_dtype</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">index_dtype</span> <span class="o">==</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">BOOL</span><span class="p">:</span>
        <span class="k">assert</span> <span class="ow">not</span> <span class="n">accumulate</span><span class="p">,</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;accumulate is True but it does not make sense in that case&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Where</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">sts</span><span class="p">:</span>
            <span class="n">g</span><span class="o">.</span><span class="n">set_type</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
            <span class="n">g</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">res</span>

    <span class="n">new_index</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">UnsqueezeAnyOpset</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="n">g</span><span class="o">.</span><span class="n">set_type</span><span class="p">(</span><span class="n">new_index</span><span class="p">,</span> <span class="n">index_dtype</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">g</span><span class="o">.</span><span class="n">has_shape</span><span class="p">(</span><span class="n">index</span><span class="p">):</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">new_index</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(</span><span class="n">index</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="p">,))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_rank</span><span class="p">(</span><span class="n">new_index</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">get_rank</span><span class="p">(</span><span class="n">index</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">accumulate</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">g</span><span class="o">.</span><span class="n">main_opset</span> <span class="o">&gt;=</span> <span class="mi">13</span><span class="p">,</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;index_put cannot be implemented for opset &lt; 13 &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;because ScatterND does not support reduction&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">ScatterND</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">new_index</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;add&quot;</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">ScatterND</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">new_index</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_type</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten__unsafe_index_put">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten__unsafe_index_put">[docs]</a>
<span class="k">def</span> <span class="nf">aten__unsafe_index_put</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="bp">self</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">indices</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">T</span><span class="p">],</span>
    <span class="n">values</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">accumulate</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;[...,:, ...]&quot;</span>
    <span class="k">return</span> <span class="n">aten_index_put</span><span class="p">(</span>
        <span class="n">g</span><span class="p">,</span>
        <span class="n">sts</span><span class="p">,</span>
        <span class="n">outputs</span><span class="p">,</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">indices</span><span class="p">,</span>
        <span class="n">values</span><span class="p">,</span>
        <span class="n">accumulate</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;aten__unsafe_index_put&quot;</span><span class="p">,</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="aten_index_select">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_index_select">[docs]</a>
<span class="k">def</span> <span class="nf">aten_index_select</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">index</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;index_select&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;[...,:, ...]&quot;</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Gather</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_type</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">g</span><span class="o">.</span><span class="n">has_shape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="ow">and</span> <span class="n">g</span><span class="o">.</span><span class="n">has_shape</span><span class="p">(</span><span class="n">index</span><span class="p">):</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
            <span class="n">index_shape</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
            <span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">=</span> <span class="n">index_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">g</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">g</span><span class="o">.</span><span class="n">set_rank</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">get_rank</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_layer_norm">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_layer_norm">[docs]</a>
<span class="k">def</span> <span class="nf">aten_layer_norm</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">normalized_shape</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">weight</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">T</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">bias</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">T</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-05</span><span class="p">,</span>
    <span class="n">cudnn_enable</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>  <span class="c1"># not used</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;layer_norm&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;layer_norm&quot;</span>
    <span class="n">axes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">normalized_shape</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
    <span class="n">itype</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">tensor_dtype_to_np_dtype</span><span class="p">(</span><span class="n">itype</span><span class="p">)</span>

    <span class="n">two_cst</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">2.0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">eps_cst</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">eps</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>

    <span class="n">mean</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">ReduceMeanAnyOpset</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">numerator</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Sub</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="n">variance</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">ReduceMeanAnyOpset</span><span class="p">(</span>
        <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Pow</span><span class="p">(</span><span class="n">numerator</span><span class="p">,</span> <span class="n">two_cst</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">),</span> <span class="n">axes</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span>
    <span class="p">)</span>
    <span class="n">denominator</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Sqrt</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Add</span><span class="p">(</span><span class="n">variance</span><span class="p">,</span> <span class="n">eps_cst</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="n">normalized</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Div</span><span class="p">(</span><span class="n">numerator</span><span class="p">,</span> <span class="n">denominator</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">normalized</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Mul</span><span class="p">(</span><span class="n">normalized</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">normalized</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Add</span><span class="p">(</span><span class="n">normalized</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>

    <span class="c1"># rdenominator = g.op.Reciprocal(denominator)</span>
    <span class="k">return</span> <span class="n">normalized</span>  <span class="c1"># , mean, rdenominator</span></div>



<div class="viewcode-block" id="aten_leaky_relu">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_leaky_relu">[docs]</a>
<span class="k">def</span> <span class="nf">aten_leaky_relu</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">a</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">negative_slope</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">,</span>
    <span class="n">inplace</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;leaky_relu&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;leaky relu&quot;</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="n">inplace</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;inplace not implemented for leaky_relu</span><span class="si">{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>

    <span class="n">dtype</span> <span class="o">=</span> <span class="n">tensor_dtype_to_np_dtype</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">a</span><span class="p">))</span>
    <span class="n">slope</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">negative_slope</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Where</span><span class="p">(</span>
        <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Greater</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">),</span>
        <span class="n">a</span><span class="p">,</span>
        <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Mul</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">slope</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">),</span>
        <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_leaky_relu_backward">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_leaky_relu_backward">[docs]</a>
<span class="k">def</span> <span class="nf">aten_leaky_relu_backward</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">grad_output</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">negative_slope</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">self_is_result</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;leaky_relu_backward&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;leaky relu&quot;</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">tensor_dtype_to_np_dtype</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">grad_output</span><span class="p">))</span>
    <span class="n">slope</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">negative_slope</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Where</span><span class="p">(</span>
        <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Greater</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">),</span>
        <span class="n">grad_output</span><span class="p">,</span>
        <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Mul</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">slope</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">),</span>
        <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_lift_fresh_copy">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_lift_fresh_copy">[docs]</a>
<span class="k">def</span> <span class="nf">aten_lift_fresh_copy</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span> <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">x</span><span class="p">:</span> <span class="n">T</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;identity&quot;</span>
    <span class="k">return</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Identity</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;lift_fresh_copy&quot;</span><span class="p">)</span></div>



<div class="viewcode-block" id="aten_linear">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_linear">[docs]</a>
<span class="k">def</span> <span class="nf">aten_linear</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">weight</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">bias</span><span class="p">:</span> <span class="n">T</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;linear&quot;</span>
    <span class="n">weight_transposed</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Transpose</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">bias</span><span class="p">:</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">MatMul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">weight_transposed</span><span class="p">)</span>
        <span class="n">set_type_shape_matmul</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">weight_transposed</span><span class="p">)</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Add</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">MatMul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">weight_transposed</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_type</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">g</span><span class="o">.</span><span class="n">has_shape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="ow">and</span> <span class="n">g</span><span class="o">.</span><span class="n">has_shape</span><span class="p">(</span><span class="n">weight</span><span class="p">):</span>
            <span class="n">shape_x</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">shape_w</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span>
            <span class="n">new_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">shape_x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">shape_w</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">g</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">new_shape</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">g</span><span class="o">.</span><span class="n">set_rank</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten__log_softmax">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten__log_softmax">[docs]</a>
<span class="k">def</span> <span class="nf">aten__log_softmax</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">unnamed</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">dtype</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;torch.dtype&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># noqa: F821</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;logsoftmax&quot;</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="n">unnamed</span><span class="p">,</span> <span class="s2">&quot;Not implemented when the third parameter is False&quot;</span>
    <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">itype</span> <span class="o">=</span> <span class="n">torch_dtype_to_onnx_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">xc</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Cast</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">to</span><span class="o">=</span><span class="n">itype</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;log_softmax&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">itype</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">xc</span> <span class="o">=</span> <span class="n">x</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">LogSoftmax</span><span class="p">(</span><span class="n">xc</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="n">xc</span><span class="p">,</span> <span class="n">itype</span><span class="o">=</span><span class="n">itype</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten__log_softmax_backward_data">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten__log_softmax_backward_data">[docs]</a>
<span class="k">def</span> <span class="nf">aten__log_softmax_backward_data</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">grad_output</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">output</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">input_dtype</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;torch.dtype&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># noqa: F821</span>
<span class="p">):</span>
    <span class="s2">&quot;logsoftmax backward&quot;</span>
    <span class="k">if</span> <span class="n">input_dtype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">itype</span> <span class="o">=</span> <span class="n">torch_dtype_to_onnx_dtype</span><span class="p">(</span><span class="n">input_dtype</span><span class="p">)</span>
        <span class="n">grad_outputc</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Cast</span><span class="p">(</span>
            <span class="n">grad_output</span><span class="p">,</span> <span class="n">to</span><span class="o">=</span><span class="n">itype</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;log_softmax_backward_data&quot;</span>
        <span class="p">)</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">grad_outputc</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">itype</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">itype</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">grad_outputc</span> <span class="o">=</span> <span class="n">grad_output</span>

    <span class="n">vexp</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Exp</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;log_softmax_backward_data&quot;</span><span class="p">)</span>
    <span class="n">red</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">ReduceSum</span><span class="p">(</span>
        <span class="n">grad_outputc</span><span class="p">,</span>
        <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">dim</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
        <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;log_softmax_backward_data&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">vmul</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Mul</span><span class="p">(</span><span class="n">vexp</span><span class="p">,</span> <span class="n">red</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;log_softmax_backward_data&quot;</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Sub</span><span class="p">(</span>
        <span class="n">grad_outputc</span><span class="p">,</span> <span class="n">vmul</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;log_softmax_backward_data&quot;</span>
    <span class="p">)</span>

    <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">vexp</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
    <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">vmul</span><span class="p">,</span> <span class="n">vexp</span><span class="p">)</span>
    <span class="n">set_type_shape_reduce_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">red</span><span class="p">,</span> <span class="n">grad_outputc</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="p">(</span><span class="n">dim</span><span class="p">,))</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="n">grad_outputc</span><span class="p">,</span> <span class="n">itype</span><span class="o">=</span><span class="n">itype</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_lt">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_lt">[docs]</a>
<span class="k">def</span> <span class="nf">aten_lt</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;lt&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;less&quot;</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">prepare_inputs_homogeneous_operator</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Less</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_binary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cmp_op</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_lt_Tensor">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_lt_Tensor">[docs]</a>
<span class="k">def</span> <span class="nf">aten_lt_Tensor</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span> <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">T</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;less&quot;</span>
    <span class="k">return</span> <span class="n">aten_lt</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">sts</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;lt_Tensor&quot;</span><span class="p">)</span></div>



<div class="viewcode-block" id="aten_matmul">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_matmul">[docs]</a>
<span class="k">def</span> <span class="nf">aten_matmul</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span> <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">T</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;matmul&quot;</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">MatMul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_binary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_masked_fill_Scalar">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_masked_fill_Scalar">[docs]</a>
<span class="k">def</span> <span class="nf">aten_masked_fill_Scalar</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">mask</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">value</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;masked_fill_Scalar&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;masked&quot;</span>
    <span class="n">dt</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">dt</span> <span class="o">!=</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">BOOL</span><span class="p">:</span>
        <span class="n">cmask</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Cast</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">to</span><span class="o">=</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">BOOL</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">cmask</span> <span class="o">=</span> <span class="n">mask</span>
    <span class="n">dtx</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">avalue</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">value</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tensor_dtype_to_np_dtype</span><span class="p">(</span><span class="n">dtx</span><span class="p">))</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Where</span><span class="p">(</span><span class="n">cmask</span><span class="p">,</span> <span class="n">avalue</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_type</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">dtx</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">g</span><span class="o">.</span><span class="n">has_shape</span><span class="p">(</span><span class="n">mask</span><span class="p">):</span>
            <span class="n">g</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(</span><span class="n">mask</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">g</span><span class="o">.</span><span class="n">set_rank</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">get_rank</span><span class="p">(</span><span class="n">mask</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">res</span></div>



<span class="k">def</span> <span class="nf">_aten_max_pool_onnx</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">kernel_shape</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">strides</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">pads</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">dilations</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">ceil_mode</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">unbatched_rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;maxpool&quot;</span>
    <span class="c1"># self_rank_is_unbatched_rank = Rank(self) == unbatched_rank</span>
    <span class="c1"># if self_rank_is_unbatched_rank:  # C,H,W -&gt; N,C,H,W and N=1</span>
    <span class="c1">#     self = op.UnsqueezeAnyOpset(self, op.Constant(value_ints=[0]))</span>

    <span class="n">pool_result</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">MaxPool</span><span class="p">(</span>
        <span class="n">x</span><span class="p">,</span>
        <span class="n">ceil_mode</span><span class="o">=</span><span class="n">ceil_mode</span><span class="p">,</span>
        <span class="n">dilations</span><span class="o">=</span><span class="n">dilations</span><span class="p">,</span>
        <span class="n">kernel_shape</span><span class="o">=</span><span class="n">kernel_shape</span><span class="p">,</span>
        <span class="n">pads</span><span class="o">=</span><span class="n">pads</span><span class="p">,</span>
        <span class="n">strides</span><span class="o">=</span><span class="n">strides</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># if self_rank_is_unbatched_rank:</span>
    <span class="c1">#    pool_result = op.SqueezeAnyOpset(pool_result, op.Constant(value_ints=[0]))</span>

    <span class="k">return</span> <span class="n">pool_result</span>


<div class="viewcode-block" id="aten_max_pool2d">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_max_pool2d">[docs]</a>
<span class="k">def</span> <span class="nf">aten_max_pool2d</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">kernel_size</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">stride</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(),</span>
    <span class="n">padding</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
    <span class="n">dilation</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="n">ceil_mode</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;maxpool&quot;</span>
    <span class="n">expand_size</span> <span class="o">=</span> <span class="mi">2</span>

    <span class="n">kernel_shape</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">pads</span><span class="p">,</span> <span class="n">dilations</span> <span class="o">=</span> <span class="n">_adjust_attributes_of_max_pool</span><span class="p">(</span>
        <span class="n">expand_size</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">_aten_max_pool_onnx</span><span class="p">(</span>
        <span class="n">g</span><span class="p">,</span>
        <span class="n">sts</span><span class="p">,</span>
        <span class="n">outputs</span><span class="p">,</span>
        <span class="n">x</span><span class="p">,</span>
        <span class="n">kernel_shape</span><span class="p">,</span>
        <span class="n">strides</span><span class="p">,</span>
        <span class="n">pads</span><span class="p">,</span>
        <span class="n">dilations</span><span class="p">,</span>
        <span class="n">ceil_mode</span><span class="p">,</span>
        <span class="mi">3</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;max_pool2d&quot;</span><span class="p">,</span>
    <span class="p">)</span></div>



<span class="k">def</span> <span class="nf">_aten_max_pool_with_indices_onnx</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">kernel_size</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">stride</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">padding</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">dilation</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">ceil_mode</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">unbatched_rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">n_dims_one</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">n_dims_zero</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">n_dims_axes</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">T</span><span class="p">,</span> <span class="n">T</span><span class="p">]:</span>
    <span class="s2">&quot;maxpool&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ceil_mode</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unexpected ceil_mode=</span><span class="si">{</span><span class="n">ceil_mode</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">is_unbatched_rank</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">rank</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">==</span> <span class="n">unbatched_rank</span>
    <span class="k">if</span> <span class="n">is_unbatched_rank</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">UnsqueezeAnyOpset</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">pool_result</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">MaxPool</span><span class="p">(</span>
        <span class="n">x</span><span class="p">,</span>
        <span class="n">ceil_mode</span><span class="o">=</span><span class="n">ceil_mode</span><span class="p">,</span>
        <span class="n">dilations</span><span class="o">=</span><span class="n">dilation</span><span class="p">,</span>
        <span class="n">kernel_shape</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span>
        <span class="n">pads</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
        <span class="n">strides</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">flatten_indices</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">MaxPool</span><span class="p">(</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">dilations</span><span class="o">=</span><span class="n">dilation</span><span class="p">,</span> <span class="n">kernel_shape</span><span class="o">=</span><span class="n">n_dims_one</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="n">n_dims_one</span>
    <span class="p">)</span>

    <span class="n">ends</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">make_initializer</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">n_dims_one</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span>
    <span class="n">starts</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">make_initializer</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">n_dims_zero</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span>
    <span class="n">axes</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">make_initializer</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">n_dims_axes</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span>

    <span class="n">delta</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Slice</span><span class="p">(</span><span class="n">flatten_indices</span><span class="p">,</span> <span class="n">starts</span><span class="p">,</span> <span class="n">ends</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Sub</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">delta</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">is_unbatched_rank</span><span class="p">:</span>
        <span class="n">pool_result</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">SqueezeAnyOpset</span><span class="p">(</span>
            <span class="n">pool_result</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span>
        <span class="p">)</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">SqueezeAnyOpset</span><span class="p">(</span>
            <span class="n">indices</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span>
        <span class="p">)</span>

    <span class="n">g</span><span class="o">.</span><span class="n">set_type</span><span class="p">(</span><span class="n">delta</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">flatten_indices</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">outputs</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Multiple outputs are expeted but type(outputs) is </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Multiple outputs are expeted but outputs is </span><span class="si">{</span><span class="n">outputs</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Identity</span><span class="p">(</span><span class="n">pool_result</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">),</span>
            <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Identity</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">),</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">pool_result</span><span class="p">,</span> <span class="n">indices</span>


<div class="viewcode-block" id="aten_max_pool2d_with_indices">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_max_pool2d_with_indices">[docs]</a>
<span class="k">def</span> <span class="nf">aten_max_pool2d_with_indices</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">kernel_size</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">stride</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(),</span>
    <span class="n">padding</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
    <span class="n">dilation</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="n">ceil_mode</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">T</span><span class="p">,</span> <span class="n">T</span><span class="p">]:</span>
    <span class="s2">&quot;maxpool&quot;</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">padding</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">))</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ceil_mode</span><span class="p">,</span> <span class="p">(</span><span class="nb">bool</span><span class="p">,</span> <span class="nb">int</span><span class="p">))</span>
    <span class="n">expand_size</span> <span class="o">=</span> <span class="mi">2</span>

    <span class="n">kernel_shape</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">pads</span><span class="p">,</span> <span class="n">dilations</span> <span class="o">=</span> <span class="n">_adjust_attributes_of_max_pool</span><span class="p">(</span>
        <span class="n">expand_size</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">_aten_max_pool_with_indices_onnx</span><span class="p">(</span>
        <span class="n">g</span><span class="p">,</span>
        <span class="n">sts</span><span class="p">,</span>
        <span class="n">outputs</span><span class="p">,</span>
        <span class="n">x</span><span class="p">,</span>
        <span class="n">kernel_shape</span><span class="p">,</span>
        <span class="n">strides</span><span class="p">,</span>
        <span class="n">pads</span><span class="p">,</span>
        <span class="n">dilations</span><span class="p">,</span>
        <span class="n">ceil_mode</span><span class="p">,</span>
        <span class="mi">3</span><span class="p">,</span>
        <span class="p">([</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">expand_size</span><span class="p">),</span>
        <span class="p">([</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">expand_size</span><span class="p">),</span>
        <span class="p">([</span><span class="mi">2</span> <span class="o">+</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">expand_size</span><span class="p">)]),</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;max_pool2d_with_indices&quot;</span><span class="p">,</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="aten_mean_dim">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_mean_dim">[docs]</a>
<span class="k">def</span> <span class="nf">aten_mean_dim</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">dim</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">keepdim</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">dtype</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;torch.dtype&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># noqa: F821</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;reducemean&quot;</span>
    <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">itype</span> <span class="o">=</span> <span class="n">torch_dtype_to_onnx_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">xc</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Cast</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">to</span><span class="o">=</span><span class="n">itype</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">xc</span> <span class="o">=</span> <span class="n">x</span>
    <span class="k">if</span> <span class="n">dim</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">ReduceMeanAnyOpset</span><span class="p">(</span>
            <span class="n">xc</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="n">keepdim</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;mean_dim&quot;</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">adim</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">dim</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">adim</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">ReduceMeanAnyOpset</span><span class="p">(</span>
            <span class="n">xc</span><span class="p">,</span> <span class="n">adim</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="n">keepdim</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;mean_dim&quot;</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_reduce_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="n">keepdim</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span></div>



<div class="viewcode-block" id="aten_mm">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_mm">[docs]</a>
<span class="k">def</span> <span class="nf">aten_mm</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span> <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">T</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;matmul&quot;</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">MatMul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;mm&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_matmul</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_mul">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_mul">[docs]</a>
<span class="k">def</span> <span class="nf">aten_mul</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;mul&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;mul&quot;</span>
    <span class="k">if</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">==</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">BOOL</span> <span class="ow">and</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">==</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">BOOL</span><span class="p">:</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">And</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;mul_and&quot;</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">res</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">prepare_inputs_homogeneous_operator</span><span class="p">(</span>
            <span class="n">g</span><span class="p">,</span>
            <span class="n">x</span><span class="p">,</span>
            <span class="n">y</span><span class="p">,</span>
            <span class="n">f</span><span class="o">=</span><span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Mul</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;mul&quot;</span><span class="p">,</span>
            <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span>
            <span class="n">sts</span><span class="o">=</span><span class="n">sts</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_binary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_mul_Scalar">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_mul_Scalar">[docs]</a>
<span class="k">def</span> <span class="nf">aten_mul_Scalar</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span> <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">T</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;mul&quot;</span>
    <span class="k">return</span> <span class="n">aten_mul</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">sts</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;mul_Scalar&quot;</span><span class="p">)</span></div>



<div class="viewcode-block" id="aten_mul_Tensor">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_mul_Tensor">[docs]</a>
<span class="k">def</span> <span class="nf">aten_mul_Tensor</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span> <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">T</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;mul&quot;</span>
    <span class="k">return</span> <span class="n">aten_mul</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">sts</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;mul_Tensor&quot;</span><span class="p">)</span></div>



<div class="viewcode-block" id="aten_native_dropout">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_native_dropout">[docs]</a>
<span class="k">def</span> <span class="nf">aten_native_dropout</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">p</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">train</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;native_dropout&quot;</span><span class="p">,</span>
<span class="p">):</span>
    <span class="s2">&quot;dropout&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">train</span><span class="p">:</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;train is False and outputs is </span><span class="si">{</span><span class="n">outputs</span><span class="si">}{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">return</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Identity</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">assert</span> <span class="p">(</span>
        <span class="nb">len</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;train is True and outputs is </span><span class="si">{</span><span class="n">outputs</span><span class="si">}{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="n">tp</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">make_initializer</span><span class="p">(</span>
        <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tensor_dtype_to_np_dtype</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
    <span class="p">)</span>
    <span class="n">tt</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">make_initializer</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">bool_</span><span class="p">))</span>
    <span class="n">g</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Dropout&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">tp</span><span class="p">,</span> <span class="n">tt</span><span class="p">],</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">)</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_type</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">BOOL</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">g</span><span class="o">.</span><span class="n">has_shape</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
            <span class="n">g</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">g</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">g</span><span class="o">.</span><span class="n">set_rank</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">g</span><span class="o">.</span><span class="n">get_rank</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span></div>



<div class="viewcode-block" id="aten_native_layer_norm">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_native_layer_norm">[docs]</a>
<span class="k">def</span> <span class="nf">aten_native_layer_norm</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">normalized_shape</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>  <span class="c1"># int64</span>
    <span class="n">weight</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">T</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">bias</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">T</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-05</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;aten_native_layer_norm&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">T</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">T</span><span class="p">]:</span>
    <span class="s2">&quot;native_layer_norm&quot;</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">normalized_shape</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="n">all_int</span><span class="p">(</span><span class="n">normalized_shape</span><span class="p">),</span> <span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;aten_native_layer_norm not implemented for normalized_shape=</span><span class="si">{</span><span class="n">normalized_shape</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="p">)</span>
    <span class="n">start_axis</span> <span class="o">=</span> <span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">normalized_shape</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">weight</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">tensor_dtype_to_np_dtype</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">ConstantOfShape</span><span class="p">(</span>
            <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Shape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="n">start_axis</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">),</span>
            <span class="n">value</span><span class="o">=</span><span class="n">from_array</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">),</span>
            <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="n">g</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
        <span class="s2">&quot;LayerNormalization&quot;</span><span class="p">,</span>
        <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span> <span class="ow">or</span> <span class="s2">&quot;&quot;</span><span class="p">],</span>
        <span class="n">outputs</span><span class="p">,</span>
        <span class="n">axis</span><span class="o">=</span><span class="n">start_axis</span><span class="p">,</span>
        <span class="n">epsilon</span><span class="o">=</span><span class="n">eps</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_type</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">)</span>
        <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">g</span><span class="o">.</span><span class="n">has_shape</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
            <span class="n">g</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">g</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">g</span><span class="o">.</span><span class="n">set_rank</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">g</span><span class="o">.</span><span class="n">get_rank</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">(</span><span class="mi">1</span><span class="p">,))</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">(</span><span class="mi">1</span><span class="p">,))</span>

    <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span></div>



<div class="viewcode-block" id="aten_ne">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_ne">[docs]</a>
<span class="k">def</span> <span class="nf">aten_ne</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;ne&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;not equal&quot;</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">prepare_inputs_homogeneous_operator</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">eq</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Equal</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Not</span><span class="p">(</span><span class="n">eq</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_binary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">eq</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cmp_op</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="n">eq</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_ne_Tensor">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_ne_Tensor">[docs]</a>
<span class="k">def</span> <span class="nf">aten_ne_Tensor</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;ne_Tensor&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;not equal&quot;</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">aten_ne</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">sts</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_binary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cmp_op</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_neg">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_neg">[docs]</a>
<span class="k">def</span> <span class="nf">aten_neg</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span> <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;neg&quot;</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;neg&quot;</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Neg&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_new_zeros">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_new_zeros">[docs]</a>
<span class="k">def</span> <span class="nf">aten_new_zeros</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">size</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">dtype</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;torch.dtype&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># noqa: F821</span>
    <span class="n">layout</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;torch.device&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># noqa: F821</span>
    <span class="n">pin_memory</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;seros&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;constantofshape&quot;</span>
    <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">onnx_dtype_to_torch_dtype</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">aten_full</span><span class="p">(</span>
        <span class="n">g</span><span class="p">,</span>
        <span class="n">sts</span><span class="p">,</span>
        <span class="n">outputs</span><span class="p">,</span>
        <span class="n">size</span><span class="p">,</span>
        <span class="n">fill_value</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">layout</span><span class="o">=</span><span class="n">layout</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
        <span class="n">pin_memory</span><span class="o">=</span><span class="n">pin_memory</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="aten_not">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_not">[docs]</a>
<span class="k">def</span> <span class="nf">aten_not</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;not&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;not&quot;</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Not&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_not_">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_not_">[docs]</a>
<span class="k">def</span> <span class="nf">aten_not_</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;not&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;not&quot;</span>
    <span class="k">return</span> <span class="n">aten_not</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">sts</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;not_&quot;</span><span class="p">)</span></div>



<div class="viewcode-block" id="aten_ones">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_ones">[docs]</a>
<span class="k">def</span> <span class="nf">aten_ones</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">size</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">dtype</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">layout</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;torch.device&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># noqa: F821</span>
    <span class="n">pin_memory</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;ones&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;constantofshape&quot;</span>
    <span class="kn">import</span> <span class="nn">torch</span>

    <span class="k">assert</span> <span class="n">layout</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;ones not implemented for layout=</span><span class="si">{</span><span class="n">layout</span><span class="si">!r}</span><span class="s2"> is not None&quot;</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="n">pin_memory</span><span class="p">,</span> <span class="s2">&quot;ones not implemented for pin_memory=True&quot;</span>
    <span class="n">new_shape</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="n">isize</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
        <span class="n">new_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">isize</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">size</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
        <span class="n">new_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">size</span><span class="p">,)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="n">isize</span> <span class="o">=</span> <span class="n">size</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
        <span class="n">new_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">isize</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">isize</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Cast</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">to</span><span class="o">=</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">INT64</span><span class="p">)</span>
        <span class="n">new_shape</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">ConstantOfShape</span><span class="p">(</span>
        <span class="n">isize</span><span class="p">,</span>
        <span class="n">value</span><span class="o">=</span><span class="n">from_array</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
                <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tensor_dtype_to_np_dtype</span><span class="p">(</span><span class="n">torch_dtype_to_onnx_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">))</span>
            <span class="p">)</span>
        <span class="p">),</span>
        <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_type</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">new_shape</span><span class="p">:</span>
            <span class="n">g</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">new_shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_ones_like">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_ones_like">[docs]</a>
<span class="k">def</span> <span class="nf">aten_ones_like</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">dtype</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;torch.dtype&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># noqa: F821</span>
    <span class="n">layout</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;torch.device&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># noqa: F821</span>
    <span class="n">pin_memory</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">memory_format</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;constantofshape&quot;</span>
    <span class="k">return</span> <span class="n">aten_full_like</span><span class="p">(</span>
        <span class="n">g</span><span class="p">,</span>
        <span class="n">sts</span><span class="p">,</span>
        <span class="n">outputs</span><span class="p">,</span>
        <span class="n">x</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span> <span class="ow">or</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;ones_like&quot;</span><span class="p">,</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="aten_permute">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_permute">[docs]</a>
<span class="k">def</span> <span class="nf">aten_permute</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">dims</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;transpose&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">dims</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;permute&quot;</span><span class="p">)</span>

    <span class="n">dims</span> <span class="o">=</span> <span class="p">[</span><span class="n">axis</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">dims</span><span class="p">)</span> <span class="k">if</span> <span class="n">axis</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">axis</span> <span class="k">for</span> <span class="n">axis</span> <span class="ow">in</span> <span class="n">dims</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="n">dims</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;permute&quot;</span><span class="p">)</span></div>



<div class="viewcode-block" id="aten_pow_Tensor_Scalar">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_pow_Tensor_Scalar">[docs]</a>
<span class="k">def</span> <span class="nf">aten_pow_Tensor_Scalar</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">exponent</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;pow_Tensor_Scalar&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;pow&quot;</span>
    <span class="k">return</span> <span class="n">aten_pow_Tensor_Tensor</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">sts</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">exponent</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span></div>



<div class="viewcode-block" id="aten_pow_Tensor_Tensor">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_pow_Tensor_Tensor">[docs]</a>
<span class="k">def</span> <span class="nf">aten_pow_Tensor_Tensor</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">exponent</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;pow_Tensor_Tensor&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;pow&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">exponent</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">exponent</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># The node is removed.</span>
            <span class="k">return</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Identity</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>
        <span class="n">exponent</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">exponent</span><span class="p">])</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">exponent</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">g</span><span class="o">.</span><span class="n">has_type</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
            <span class="n">exponent</span> <span class="o">=</span> <span class="n">exponent</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">tensor_dtype_to_np_dtype</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">exponent</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">CastLike</span><span class="p">(</span><span class="n">exponent</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">exponent</span><span class="p">,</span> <span class="nb">str</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;unexpected type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">exponent</span><span class="p">)</span><span class="si">}</span><span class="s2"> for exponent</span><span class="si">{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">assert</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">==</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">exponent</span><span class="p">),</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;type mismatch between </span><span class="si">{</span><span class="n">x</span><span class="si">!r}</span><span class="s2"> and </span><span class="si">{</span><span class="n">exponent</span><span class="si">!r}</span><span class="s2">, &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="si">}</span><span class="s2"> != </span><span class="si">{</span><span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">exponent</span><span class="p">)</span><span class="si">}{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Pow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">exponent</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten__prelu_kernel">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten__prelu_kernel">[docs]</a>
<span class="k">def</span> <span class="nf">aten__prelu_kernel</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span> <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span> <span class="n">weight</span><span class="p">:</span> <span class="n">T</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;prelu&quot;</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">tensor_dtype_to_np_dtype</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="n">ge</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Greater</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;_prelu_kernel&quot;</span><span class="p">)</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Mul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;_prelu_kernel&quot;</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Where</span><span class="p">(</span><span class="n">ge</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;_prelu_kernel&quot;</span><span class="p">)</span>
    <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">ge</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">BOOL</span><span class="p">)</span>
    <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten__prelu_kernel_backward">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten__prelu_kernel_backward">[docs]</a>
<span class="k">def</span> <span class="nf">aten__prelu_kernel_backward</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">grad_output</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">weight</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">T</span><span class="p">,</span> <span class="n">T</span><span class="p">]:</span>
    <span class="s2">&quot;prelu backward&quot;</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">tensor_dtype_to_np_dtype</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="n">zero</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">make_initializer</span><span class="p">(</span><span class="s2">&quot;zero&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">))</span>
    <span class="n">xg0</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Greater</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">zero</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;_prelu_kernel_backward&quot;</span><span class="p">)</span>
    <span class="n">mu1</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Mul</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;_prelu_kernel_backward&quot;</span><span class="p">)</span>
    <span class="n">input_grad</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Where</span><span class="p">(</span>
        <span class="n">xg0</span><span class="p">,</span>
        <span class="n">grad_output</span><span class="p">,</span>
        <span class="n">mu1</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;_prelu_kernel_backward&quot;</span><span class="p">,</span>
        <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">[:</span><span class="mi">1</span><span class="p">],</span>
    <span class="p">)</span>
    <span class="n">mu2</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Mul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;_prelu_kernel_backward&quot;</span><span class="p">)</span>
    <span class="n">weight_grad</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Where</span><span class="p">(</span>
        <span class="n">xg0</span><span class="p">,</span> <span class="n">zero</span><span class="p">,</span> <span class="n">mu2</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;_prelu_kernel_backward&quot;</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
    <span class="p">)</span>
    <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">xg0</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">BOOL</span><span class="p">)</span>
    <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">mu1</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span>
    <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">mu2</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">input_grad</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">weight_grad</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">input_grad</span><span class="p">,</span> <span class="n">weight_grad</span></div>



<div class="viewcode-block" id="aten_relu">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_relu">[docs]</a>
<span class="k">def</span> <span class="nf">aten_relu</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">inplace</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;relu&quot;</span>
    <span class="k">assert</span> <span class="p">(</span>
        <span class="ow">not</span> <span class="n">inplace</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;inplace computation is not allowed with onnx</span><span class="si">{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Relu</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_rrelu_with_noise_backward">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_rrelu_with_noise_backward">[docs]</a>
<span class="k">def</span> <span class="nf">aten_rrelu_with_noise_backward</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">grad_output</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">noise</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">lower</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">upper</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">training</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">self_is_result</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;rrelu_with_noise_backward&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;rrelu&quot;</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="n">training</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Not implemented if training is True</span><span class="si">{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>

    <span class="c1"># if training and upper - lower &gt; 1e-6:</span>
    <span class="c1">#     return grad_output.mul(noise)</span>
    <span class="n">negative_slope</span> <span class="o">=</span> <span class="p">(</span><span class="n">lower</span> <span class="o">+</span> <span class="n">upper</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
    <span class="k">return</span> <span class="n">aten_leaky_relu_backward</span><span class="p">(</span>
        <span class="n">g</span><span class="p">,</span> <span class="n">sts</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">negative_slope</span><span class="p">,</span> <span class="n">self_is_result</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="aten_repeat">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_repeat">[docs]</a>
<span class="k">def</span> <span class="nf">aten_repeat</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">repeats</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;repeat&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;repeat&quot;</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">repeats</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">all_int</span><span class="p">(</span><span class="n">repeats</span><span class="p">):</span>
        <span class="n">irep</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">repeats</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">g</span><span class="o">.</span><span class="n">is_dynamic_shape</span><span class="p">(</span><span class="n">repeats</span><span class="p">):</span>
        <span class="c1"># repeats is like a shape</span>
        <span class="n">irep</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">make_shape_from_results</span><span class="p">(</span><span class="n">repeats</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;repeat not implemented for repeats=</span><span class="si">{</span><span class="n">repeats</span><span class="si">}{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">g</span><span class="o">.</span><span class="n">get_rank</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">repeats</span><span class="p">):</span>
        <span class="n">expanded</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Expand</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">((</span><span class="mi">1</span><span class="p">,)</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">repeats</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">expanded</span> <span class="o">=</span> <span class="n">x</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Tile</span><span class="p">(</span><span class="n">expanded</span><span class="p">,</span> <span class="n">irep</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_type</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">g</span><span class="o">.</span><span class="n">has_shape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="ow">and</span> <span class="n">all_int</span><span class="p">(</span><span class="n">repeats</span><span class="p">):</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">repeats</span><span class="p">):</span>
                <span class="n">new_shape</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">irep</span>
                <span class="n">g</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">new_shape</span><span class="p">)))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">g</span><span class="o">.</span><span class="n">set_rank</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">repeats</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">g</span><span class="o">.</span><span class="n">set_rank</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">repeats</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_rsqrt">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_rsqrt">[docs]</a>
<span class="k">def</span> <span class="nf">aten_rsqrt</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span> <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">x</span><span class="p">:</span> <span class="n">T</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;rqsrt&quot;</span>
    <span class="n">ext</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Sqrt&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;rsqrt&quot;</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Reciprocal</span><span class="p">(</span><span class="n">ext</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;rsqrt&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_round">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_round">[docs]</a>
<span class="k">def</span> <span class="nf">aten_round</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span> <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">x</span><span class="p">:</span> <span class="n">T</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;round&quot;</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Round&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;round&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_rsub">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_rsub">[docs]</a>
<span class="k">def</span> <span class="nf">aten_rsub</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;rsub&quot;</span>
    <span class="k">assert</span> <span class="n">alpha</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Not implemented with alpha=</span><span class="si">{</span><span class="n">alpha</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">return</span> <span class="n">aten_sub</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">sts</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;rsub&quot;</span><span class="p">)</span></div>



<div class="viewcode-block" id="aten_rsub_Scalar">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_rsub_Scalar">[docs]</a>
<span class="k">def</span> <span class="nf">aten_rsub_Scalar</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;rsub&quot;</span>
    <span class="k">assert</span> <span class="n">alpha</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Not implemented with alpha=</span><span class="si">{</span><span class="n">alpha</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">return</span> <span class="n">aten_sub</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">sts</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;rsub_Scalar&quot;</span><span class="p">)</span></div>



<span class="k">def</span> <span class="nf">_attention_scale</span><span class="p">(</span><span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span> <span class="n">query</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;_attention_scale&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">g</span><span class="o">.</span><span class="n">has_shape</span><span class="p">(</span><span class="n">query</span><span class="p">):</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
        <span class="n">last</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">last</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">last</span><span class="p">)</span> <span class="o">**</span> <span class="mf">0.5</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">scale</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tensor_dtype_to_np_dtype</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">query</span><span class="p">)))</span>

    <span class="n">shape</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Shape</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="n">last</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Gather</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="n">itype</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
    <span class="n">clast</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Cast</span><span class="p">(</span><span class="n">itype</span><span class="p">,</span> <span class="n">to</span><span class="o">=</span><span class="n">itype</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Reciprocal</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Sqrt</span><span class="p">(</span><span class="n">clast</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_causal_attention_mask</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span> <span class="n">query</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;_causal_attention_mask&quot;</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="n">itype</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">tensor_dtype_to_np_dtype</span><span class="p">(</span><span class="n">itype</span><span class="p">)</span>
    <span class="n">attn_mask</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">g</span><span class="o">.</span><span class="n">has_shape</span><span class="p">(</span><span class="n">query</span><span class="p">)</span> <span class="ow">and</span> <span class="n">g</span><span class="o">.</span><span class="n">has_shape</span><span class="p">(</span><span class="n">key</span><span class="p">):</span>
        <span class="n">shape_query</span><span class="p">,</span> <span class="n">shape_key</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(</span><span class="n">query</span><span class="p">),</span> <span class="n">g</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape_query</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape_key</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">shape_query</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">shape_key</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span>
            <span class="n">attn_mask</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">ConstantOfShape</span><span class="p">(</span>
                <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
                <span class="n">value</span><span class="o">=</span><span class="n">from_array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)),</span>
                <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
            <span class="p">)</span>

    <span class="k">if</span> <span class="n">attn_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># dynamic path</span>
        <span class="n">shape_query</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Shape</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="n">shape_key</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Shape</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="n">dquery</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Gather</span><span class="p">(</span><span class="n">shape_query</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="n">dkey</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Gather</span><span class="p">(</span><span class="n">shape_key</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="n">size</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Concat</span><span class="p">(</span><span class="n">dquery</span><span class="p">,</span> <span class="n">dkey</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">attn_mask</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">ConstantOfShape</span><span class="p">(</span>
            <span class="n">size</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">from_array</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span>
        <span class="p">)</span>

    <span class="n">tri_attn_mask</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Trilu</span><span class="p">(</span><span class="n">attn_mask</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>

    <span class="n">new_attn_mask</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Where</span><span class="p">(</span>
        <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Equal</span><span class="p">(</span><span class="n">tri_attn_mask</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">),</span>
        <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">),</span>
        <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">),</span>
        <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">new_attn_mask</span>


<div class="viewcode-block" id="aten_scaled_dot_product_attention">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_scaled_dot_product_attention">[docs]</a>
<span class="k">def</span> <span class="nf">aten_scaled_dot_product_attention</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">query</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">key</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">value</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">attn_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">T</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">dropout_p</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
    <span class="n">is_causal</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">scale</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">T</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;aten_scaled_dot_product_attention&quot;</span><span class="p">,</span>
<span class="p">):</span>
    <span class="s2">&quot;scaled_dot_product_attention&quot;</span>
    <span class="k">assert</span> <span class="p">(</span><span class="ow">not</span> <span class="n">is_causal</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span>
        <span class="p">(</span><span class="n">is_causal</span> <span class="ow">and</span> <span class="n">attn_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;is_causal and attn_mask cannot be set at the same time</span><span class="si">{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>

    <span class="k">if</span> <span class="n">scale</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="n">_attention_scale</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">query</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">is_causal</span><span class="p">:</span>
        <span class="n">attn_mask</span> <span class="o">=</span> <span class="n">_causal_attention_mask</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span>

    <span class="n">key_transposed_axes</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">get_rank</span><span class="p">(</span><span class="n">key</span><span class="p">)))</span>
    <span class="n">key_transposed_axes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">key_transposed_axes</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">key_transposed_axes</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span>
        <span class="n">key_transposed_axes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
    <span class="p">)</span>
    <span class="n">key_transposed</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Transpose</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="n">key_transposed_axes</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>

    <span class="n">sc</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Sqrt</span><span class="p">(</span><span class="n">scale</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="n">query_scaled</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Mul</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">sc</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="n">key_transposed_scaled</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Mul</span><span class="p">(</span><span class="n">key_transposed</span><span class="p">,</span> <span class="n">sc</span><span class="p">)</span>
    <span class="n">mul_qk</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">MatMul</span><span class="p">(</span><span class="n">query_scaled</span><span class="p">,</span> <span class="n">key_transposed_scaled</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>

    <span class="n">itype</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">tensor_dtype_to_np_dtype</span><span class="p">(</span><span class="n">itype</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">attn_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">mul_qk_add</span> <span class="o">=</span> <span class="n">mul_qk</span>
    <span class="k">elif</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">attn_mask</span><span class="p">)</span> <span class="o">==</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">BOOL</span><span class="p">:</span>
        <span class="n">attn_mask</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Where</span><span class="p">(</span>
            <span class="n">attn_mask</span><span class="p">,</span>
            <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">),</span>
            <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">),</span>
            <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">mul_qk_add</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Add</span><span class="p">(</span><span class="n">mul_qk</span><span class="p">,</span> <span class="n">attn_mask</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">mul_qk_add</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Add</span><span class="p">(</span><span class="n">mul_qk</span><span class="p">,</span> <span class="n">attn_mask</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>

    <span class="n">attn_weight</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">mul_qk_add</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">dropout_p</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">attn_weight</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span>
            <span class="n">attn_weight</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">dropout_p</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span>
        <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">MatMul</span><span class="p">(</span><span class="n">attn_weight</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span></div>



<span class="k">def</span> <span class="nf">_aten__scaled_dot_product_flash_attention_fillin_empty_outputs</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">query</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;_scaled_dot_product_flash_attention_fillin_empty_outputs&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">T</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">T</span><span class="p">]:</span>

    <span class="n">query_first_three_dims</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Slice</span><span class="p">(</span>
        <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Shape</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">),</span>
        <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="n">value_ints</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">),</span>
        <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="n">value_ints</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">),</span>
        <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">logsumexp</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Expand</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tensor_dtype_to_np_dtype</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">query</span><span class="p">))),</span>
        <span class="n">query_first_three_dims</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
        <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span>
    <span class="p">)</span>

    <span class="n">empty_tensor_int</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Cast</span><span class="p">(</span>
        <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">ConstantOfShape</span><span class="p">(</span>
            <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span>
                <span class="n">value</span><span class="o">=</span><span class="n">make_tensor</span><span class="p">(</span><span class="s2">&quot;Empty_INTS&quot;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">INT64</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[]),</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span>
            <span class="p">),</span>
            <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="n">to</span><span class="o">=</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">INT64</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
        <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span>
    <span class="p">)</span>
    <span class="n">empty_tensor_float</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">ConstantOfShape</span><span class="p">(</span>
        <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span>
            <span class="n">value</span><span class="o">=</span><span class="n">make_tensor</span><span class="p">(</span><span class="s2">&quot;Empty_FLOATS&quot;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">INT64</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[]),</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span>
        <span class="p">),</span>
        <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
        <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">outputs</span><span class="p">[</span><span class="mi">2</span><span class="p">]],</span>
    <span class="p">)</span>
    <span class="n">empty_int</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="n">value_int</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">outputs</span><span class="p">[</span><span class="mi">3</span><span class="p">]])</span>

    <span class="k">return</span> <span class="n">logsumexp</span><span class="p">,</span> <span class="n">empty_tensor_int</span><span class="p">,</span> <span class="n">empty_int</span><span class="p">,</span> <span class="n">empty_tensor_float</span>


<div class="viewcode-block" id="aten__scaled_dot_product_flash_attention_for_cpu">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten__scaled_dot_product_flash_attention_for_cpu">[docs]</a>
<span class="k">def</span> <span class="nf">aten__scaled_dot_product_flash_attention_for_cpu</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">query</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">key</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">value</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">dropout_p</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
    <span class="n">is_causal</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">attn_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">T</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">scale</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">return_debug_mask</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;_scaled_dot_product_flash_attention_for_cpu_default&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">T</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">T</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;_scaled_dot_product_flash_attention&quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="n">return_debug_mask</span><span class="p">,</span> <span class="s2">&quot;Not implemented when return_debug_mask is false.&quot;</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">aten_scaled_dot_product_attention</span><span class="p">(</span>
        <span class="n">g</span><span class="p">,</span>
        <span class="n">sts</span><span class="p">,</span>
        <span class="p">[</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span>
        <span class="n">query</span><span class="p">,</span>
        <span class="n">key</span><span class="p">,</span>
        <span class="n">value</span><span class="p">,</span>
        <span class="n">attn_mask</span><span class="o">=</span><span class="n">attn_mask</span><span class="p">,</span>
        <span class="n">dropout_p</span><span class="o">=</span><span class="n">dropout_p</span><span class="p">,</span>
        <span class="n">is_causal</span><span class="o">=</span><span class="n">is_causal</span><span class="p">,</span>
        <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;_scaled_dot_product_flash_attention_for_cpu_default&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="nb">str</span><span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Unexpected type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">result</span><span class="p">)</span><span class="si">}{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>

    <span class="c1"># The followings are not comsumed by the graph on llama 3 at least.</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="c1"># only need 2</span>
        <span class="n">query_first_three_dims</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Slice</span><span class="p">(</span>
            <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Shape</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">),</span>
            <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="n">value_ints</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">),</span>
            <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="n">value_ints</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">),</span>
            <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">logsumexp</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Expand</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tensor_dtype_to_np_dtype</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">query</span><span class="p">))),</span>
            <span class="n">query_first_three_dims</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
            <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">result</span><span class="p">,</span> <span class="n">logsumexp</span>

    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">8</span><span class="p">,</span> <span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;Unexpected number of outputs </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span><span class="si">}</span><span class="s2">, &quot;</span>
        <span class="sa">f</span><span class="s2">&quot;outputs=</span><span class="si">{</span><span class="n">outputs</span><span class="si">}{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="p">)</span>
    <span class="p">(</span>
        <span class="n">logsumexp</span><span class="p">,</span>
        <span class="n">empty_tensor_int</span><span class="p">,</span>
        <span class="n">empty_int</span><span class="p">,</span>
        <span class="n">empty_tensor_float</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">=</span> <span class="n">_aten__scaled_dot_product_flash_attention_fillin_empty_outputs</span><span class="p">(</span>
        <span class="n">g</span><span class="p">,</span> <span class="n">sts</span><span class="p">,</span> <span class="p">[</span><span class="n">outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">8</span><span class="p">]],</span> <span class="n">query</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span>
    <span class="p">)</span>

    <span class="n">empty_tensor_int2</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Identity</span><span class="p">(</span><span class="n">empty_tensor_int</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="n">empty_int2</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Identity</span><span class="p">(</span><span class="n">empty_int</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="n">empty_tensor_int2</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Identity</span><span class="p">(</span><span class="n">empty_tensor_int</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">(</span>
        <span class="n">result</span><span class="p">,</span>  <span class="c1"># 0</span>
        <span class="n">logsumexp</span><span class="p">,</span>  <span class="c1"># 1</span>
        <span class="n">empty_tensor_int</span><span class="p">,</span>  <span class="c1"># 2</span>
        <span class="n">empty_tensor_int2</span><span class="p">,</span>  <span class="c1"># 3</span>
        <span class="n">empty_int</span><span class="p">,</span>  <span class="c1"># 4</span>
        <span class="n">empty_int2</span><span class="p">,</span>  <span class="c1"># 5</span>
        <span class="n">empty_tensor_int</span><span class="p">,</span>  <span class="c1"># 6</span>
        <span class="n">empty_tensor_int2</span><span class="p">,</span>  <span class="c1"># 7</span>
        <span class="n">empty_tensor_float</span><span class="p">,</span>  <span class="c1"># 8</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="aten_select_int">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_select_int">[docs]</a>
<span class="k">def</span> <span class="nf">aten_select_int</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">index</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;gather&quot;</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
        <span class="n">dim</span><span class="p">,</span> <span class="nb">int</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Unexpected type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span><span class="si">}</span><span class="s2"> for dim</span><span class="si">{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
        <span class="n">index</span><span class="p">,</span> <span class="nb">int</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Unexpected type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">index</span><span class="p">)</span><span class="si">}</span><span class="s2"> for dim</span><span class="si">{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Gather</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_type</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">g</span><span class="o">.</span><span class="n">has_shape</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">dim</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
            <span class="k">assert</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span>
                <span class="n">shape</span>
            <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;shape is </span><span class="si">{</span><span class="n">shape</span><span class="si">}</span><span class="s2">, dim is </span><span class="si">{</span><span class="n">dim</span><span class="si">}{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="n">new_shape</span> <span class="o">=</span> <span class="p">[</span><span class="n">s</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">dim</span><span class="p">]</span>
            <span class="n">g</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">new_shape</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">g</span><span class="o">.</span><span class="n">get_rank</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">get_rank</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten__set_grad_enabled">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten__set_grad_enabled">[docs]</a>
<span class="k">def</span> <span class="nf">aten__set_grad_enabled</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span> <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">enable</span><span class="p">:</span> <span class="nb">bool</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the function returns a dummy which will be removed</span>
<span class="sd">    after the graph is created.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
        <span class="n">enable</span><span class="p">,</span> <span class="nb">bool</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Unexpected type for enable=</span><span class="si">{</span><span class="n">enable</span><span class="si">!r}{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">return</span> <span class="n">g</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Constant&quot;</span><span class="p">,</span> <span class="p">[],</span> <span class="n">value_floats</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;_set_grad_enabled&quot;</span><span class="p">)</span></div>



<div class="viewcode-block" id="aten_setitem">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_setitem">[docs]</a>
<span class="k">def</span> <span class="nf">aten_setitem</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">indices</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
    <span class="n">values</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;scatter&quot;</span>
    <span class="k">if</span> <span class="p">(</span>
        <span class="nb">isinstance</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span>
        <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span>
        <span class="ow">and</span> <span class="n">indices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">is</span> <span class="bp">Ellipsis</span>
        <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">indices</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="nb">slice</span><span class="p">)</span>
    <span class="p">):</span>
        <span class="n">s</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">aten_slice_scatter</span><span class="p">(</span>
            <span class="n">g</span><span class="p">,</span>
            <span class="n">sts</span><span class="p">,</span>
            <span class="n">outputs</span><span class="p">,</span>
            <span class="n">x</span><span class="p">,</span>
            <span class="n">values</span><span class="p">,</span>
            <span class="n">dim</span><span class="o">=</span><span class="n">g</span><span class="o">.</span><span class="n">get_rank</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>
            <span class="n">start</span><span class="o">=</span><span class="n">s</span><span class="o">.</span><span class="n">start</span><span class="p">,</span>
            <span class="n">end</span><span class="o">=</span><span class="n">s</span><span class="o">.</span><span class="n">stop</span><span class="p">,</span>
            <span class="n">step</span><span class="o">=</span><span class="n">s</span><span class="o">.</span><span class="n">step</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;setitem&quot;</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="c1"># if not sts:</span>
    <span class="c1">#    g.set_type(res, g.get_type(x))</span>
    <span class="c1">#    if g.has_shape(x):</span>
    <span class="c1">#        g.set_shape(res, g.get_shape(x))</span>
    <span class="c1">#    else:</span>
    <span class="c1">#        g.set_rank(res, g.get_rank(x))</span>
    <span class="c1"># return res</span>
    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;setitem not implemented for indices=</span><span class="si">{</span><span class="n">indices</span><span class="si">}{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="aten_slice_Tensor">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_slice_Tensor">[docs]</a>
<span class="k">def</span> <span class="nf">aten_slice_Tensor</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">start</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">end</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">step</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;slice&quot;</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="nb">int</span><span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;aten_slice_Tensor not implemented for dim=</span><span class="si">{</span><span class="n">dim</span><span class="si">!r}</span><span class="s2">&quot;</span>
    <span class="k">assert</span> <span class="n">g</span><span class="o">.</span><span class="n">is_dynamic_dimension</span><span class="p">(</span>
        <span class="n">start</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;aten_slice_Tensor not implemented for start=</span><span class="si">{</span><span class="n">start</span><span class="si">!r}{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">assert</span> <span class="n">end</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">g</span><span class="o">.</span><span class="n">is_dynamic_dimension</span><span class="p">(</span>
        <span class="n">end</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;aten_slice_Tensor not implemented for end=</span><span class="si">{</span><span class="n">end</span><span class="si">!r}{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">assert</span> <span class="n">step</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="nb">int</span><span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Not implemented for step=</span><span class="si">{</span><span class="n">step</span><span class="si">!r}</span><span class="s2">&quot;</span>
    <span class="k">if</span> <span class="n">end</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">end</span> <span class="o">=</span> <span class="n">start</span>
        <span class="n">start</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="n">start</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">end</span> <span class="o">==</span> <span class="mi">9223372036854775807</span> <span class="ow">and</span> <span class="n">step</span> <span class="ow">in</span> <span class="p">{</span><span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">}:</span>
        <span class="c1"># nothing to do</span>
        <span class="k">return</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Identity</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">g</span><span class="o">.</span><span class="n">get_dynamic_dimension</span><span class="p">(</span><span class="n">start</span><span class="p">),</span>
        <span class="n">g</span><span class="o">.</span><span class="n">get_dynamic_dimension</span><span class="p">(</span><span class="n">end</span><span class="p">),</span>
        <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">dim</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
    <span class="p">]</span>
    <span class="k">if</span> <span class="n">step</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">step</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">step</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Slice</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">*</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;slice_Tensor&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_type</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">is_static_dimension</span><span class="p">(</span><span class="n">start</span><span class="p">)</span> <span class="ow">and</span> <span class="n">is_static_dimension</span><span class="p">(</span><span class="n">end</span><span class="p">):</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">new_shape</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">_apply_slice_to_shape</span><span class="p">(</span>
                <span class="n">shape</span><span class="p">,</span> <span class="nb">slice</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">step</span><span class="p">),</span> <span class="n">axes</span><span class="o">=</span><span class="p">[</span><span class="n">dim</span><span class="p">],</span> <span class="n">expand_axes</span><span class="o">=</span><span class="p">[]</span>
            <span class="p">)</span>
            <span class="n">g</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">new_shape</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">g</span><span class="o">.</span><span class="n">set_rank</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">get_rank</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_slice_backward">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_slice_backward">[docs]</a>
<span class="k">def</span> <span class="nf">aten_slice_backward</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">grad_output</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">input_sizes</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">start</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">end</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">step</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;slice_backward&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;slice backward&quot;</span>
    <span class="k">assert</span> <span class="p">(</span>
        <span class="n">step</span> <span class="o">==</span> <span class="mi">1</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;slice_backward not implemented for step=</span><span class="si">{</span><span class="n">step</span><span class="si">}{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>

    <span class="n">itype</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">grad_output</span><span class="p">)</span>
    <span class="n">value</span> <span class="o">=</span> <span class="n">from_array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tensor_dtype_to_np_dtype</span><span class="p">(</span><span class="n">itype</span><span class="p">)))</span>

    <span class="n">inputs</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">if</span> <span class="n">g</span><span class="o">.</span><span class="n">has_shape</span><span class="p">(</span><span class="n">grad_output</span><span class="p">)</span> <span class="ow">and</span> <span class="n">is_static_shape</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(</span><span class="n">grad_output</span><span class="p">)):</span>
        <span class="n">name_s</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">_static&quot;</span>
        <span class="c1"># static version</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(</span><span class="n">grad_output</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">start</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">cst_shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
            <span class="n">cst_shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">=</span> <span class="n">start</span>
            <span class="n">cst</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">ConstantOfShape</span><span class="p">(</span>
                <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">cst_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">value</span><span class="o">=</span><span class="n">value</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name_s</span>
            <span class="p">)</span>
            <span class="n">inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cst</span><span class="p">)</span>

        <span class="n">inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">grad_output</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">end</span> <span class="o">&lt;</span> <span class="mi">9223372036854775807</span><span class="p">:</span>
            <span class="n">cst_shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
            <span class="n">cst_shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">=</span> <span class="n">input_sizes</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">-</span> <span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">-</span> <span class="n">start</span>
            <span class="n">cst</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">ConstantOfShape</span><span class="p">(</span>
                <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">cst_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">value</span><span class="o">=</span><span class="n">value</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name_s</span>
            <span class="p">)</span>
            <span class="n">inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cst</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="n">name_d</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">_dynamic&quot;</span>
        <span class="c1"># dynamic version</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Shape</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name_d</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">start</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">cst_shape</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">ScatterElements</span><span class="p">(</span>
                <span class="n">shape</span><span class="p">,</span>
                <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">dim</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
                <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">start</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
                <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">cst</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">ConstantOfShape</span><span class="p">(</span><span class="n">cst_shape</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">value</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name_d</span><span class="p">)</span>
            <span class="n">inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cst</span><span class="p">)</span>

        <span class="n">inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">grad_output</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">end</span> <span class="o">&lt;</span> <span class="mi">9223372036854775807</span><span class="p">:</span>
            <span class="n">shape_dim</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Gather</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">dim</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="n">name_d</span><span class="p">)</span>
            <span class="n">new_dim</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Sub</span><span class="p">(</span>
                <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">input_sizes</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">-</span> <span class="n">start</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">shape_dim</span>
            <span class="p">)</span>
            <span class="n">cst_shape</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">ScatterElements</span><span class="p">(</span>
                <span class="n">shape</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">dim</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">new_dim</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name_d</span>
            <span class="p">)</span>
            <span class="n">cst</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">ConstantOfShape</span><span class="p">(</span><span class="n">cst_shape</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">value</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name_d</span><span class="p">)</span>
            <span class="n">inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cst</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Concat</span><span class="p">(</span><span class="o">*</span><span class="n">inputs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Identity</span><span class="p">(</span><span class="o">*</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_type</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">grad_output</span><span class="p">))</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">input_sizes</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">res</span></div>



<span class="k">def</span> <span class="nf">_aten_slice_scatter_static</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">src</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">start</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">end</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">step</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;slice_scatter_static&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;slice scatter&quot;</span>
    <span class="k">assert</span> <span class="n">g</span><span class="o">.</span><span class="n">has_shape</span><span class="p">(</span>
        <span class="n">x</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;This implementation only works if shape of </span><span class="si">{</span><span class="n">x</span><span class="si">!r}</span><span class="s2"> is known</span><span class="si">{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="c1"># step 1</span>
    <span class="k">assert</span> <span class="n">start</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">g</span><span class="o">.</span><span class="n">is_dynamic_dimension</span><span class="p">(</span>
        <span class="n">start</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;slice_scatter not implemented for start=</span><span class="si">{</span><span class="n">start</span><span class="si">}{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">assert</span> <span class="n">end</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">g</span><span class="o">.</span><span class="n">is_dynamic_dimension</span><span class="p">(</span>
        <span class="n">end</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;slice_scatter not implemented for end=</span><span class="si">{</span><span class="n">end</span><span class="si">}{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">assert</span> <span class="n">step</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">is_static_dimension</span><span class="p">(</span>
        <span class="n">step</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;slice_scatter not implemented for end=</span><span class="si">{</span><span class="n">step</span><span class="si">}{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">dim_shape</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span>

    <span class="k">assert</span> <span class="n">is_static_dimension</span><span class="p">(</span>
        <span class="n">dim_shape</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;slice_scatter not implemented when shape=</span><span class="si">{</span><span class="n">shape</span><span class="si">}{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>

    <span class="n">index_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim_shape</span><span class="p">)</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">start</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="nb">int</span><span class="p">))</span> <span class="ow">and</span> <span class="p">(</span>
        <span class="n">end</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">end</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">end</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">index_2</span> <span class="o">=</span> <span class="n">index_1</span><span class="p">[</span><span class="n">start</span><span class="p">::</span><span class="n">step</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">index_2</span> <span class="o">=</span> <span class="n">index_1</span><span class="p">[</span><span class="n">start</span> <span class="ow">or</span> <span class="mi">0</span> <span class="p">:</span> <span class="n">end</span> <span class="p">:</span> <span class="n">step</span><span class="p">]</span>
        <span class="n">index_2</span> <span class="o">=</span> <span class="n">index_2</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">index_2</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Slice</span><span class="p">(</span>
            <span class="n">index_1</span><span class="p">,</span>
            <span class="n">g</span><span class="o">.</span><span class="n">get_dynamic_dimension</span><span class="p">(</span><span class="n">start</span><span class="p">),</span>
            <span class="p">(</span>
                <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">dim_shape</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">end</span> <span class="ow">is</span> <span class="kc">None</span>
                <span class="k">else</span> <span class="n">g</span><span class="o">.</span><span class="n">get_dynamic_dimension</span><span class="p">(</span><span class="n">end</span><span class="p">)</span>
            <span class="p">),</span>
            <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
            <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">step</span> <span class="ow">or</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
        <span class="p">)</span>

    <span class="c1"># step 2</span>

    <span class="n">resh</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Reshape</span><span class="p">(</span><span class="n">index_2</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">dim</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">ScatterND</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">resh</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">perm</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">get_rank</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">perm</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">perm</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">=</span> <span class="n">perm</span><span class="p">[</span><span class="n">dim</span><span class="p">],</span> <span class="n">perm</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Transpose</span><span class="p">(</span>
            <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">ScatterND</span><span class="p">(</span>
                <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="n">perm</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">),</span>
                <span class="n">resh</span><span class="p">,</span>
                <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Transpose</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="n">perm</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">),</span>
                <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="n">perm</span><span class="o">=</span><span class="n">perm</span><span class="p">,</span>
            <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_type</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span>


<span class="k">def</span> <span class="nf">_aten_slice_scatter_dynamic</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">src</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">start</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">end</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">step</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;slice_scatter_dynamic&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;slice scatter&quot;</span>
    <span class="c1"># step 1</span>
    <span class="k">assert</span> <span class="n">start</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">g</span><span class="o">.</span><span class="n">is_dynamic_dimension</span><span class="p">(</span>
        <span class="n">start</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;slice_scatter not implemented for start=</span><span class="si">{</span><span class="n">start</span><span class="si">}{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">assert</span> <span class="n">end</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">g</span><span class="o">.</span><span class="n">is_dynamic_dimension</span><span class="p">(</span>
        <span class="n">end</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;slice_scatter not implemented for end=</span><span class="si">{</span><span class="n">end</span><span class="si">}{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">assert</span> <span class="n">step</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">is_static_dimension</span><span class="p">(</span>
        <span class="n">step</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;slice_scatter not implemented for end=</span><span class="si">{</span><span class="n">step</span><span class="si">}{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>

    <span class="n">shape</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Shape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="n">dim_shape</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Gather</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">dim</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>

    <span class="n">index_1</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Range</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
        <span class="n">dim_shape</span><span class="p">,</span>
        <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
        <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">index_2</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Slice</span><span class="p">(</span>
        <span class="n">index_1</span><span class="p">,</span>
        <span class="n">g</span><span class="o">.</span><span class="n">get_dynamic_dimension</span><span class="p">(</span><span class="n">start</span><span class="p">),</span>
        <span class="p">(</span><span class="n">dim_shape</span> <span class="k">if</span> <span class="n">end</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">g</span><span class="o">.</span><span class="n">get_dynamic_dimension</span><span class="p">(</span><span class="n">end</span><span class="p">)),</span>
        <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
        <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">step</span> <span class="ow">or</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
    <span class="p">)</span>

    <span class="c1"># step 2</span>

    <span class="n">resh</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Reshape</span><span class="p">(</span><span class="n">index_2</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">dim</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">ScatterND</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">resh</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">perm</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">get_rank</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">perm</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">perm</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">=</span> <span class="n">perm</span><span class="p">[</span><span class="n">dim</span><span class="p">],</span> <span class="n">perm</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Transpose</span><span class="p">(</span>
            <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">ScatterND</span><span class="p">(</span>
                <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="n">perm</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">),</span>
                <span class="n">resh</span><span class="p">,</span>
                <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Transpose</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="n">perm</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">),</span>
                <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="n">perm</span><span class="o">=</span><span class="n">perm</span><span class="p">,</span>
            <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_type</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_rank</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">get_rank</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">res</span>


<div class="viewcode-block" id="aten_slice_scatter">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_slice_scatter">[docs]</a>
<span class="k">def</span> <span class="nf">aten_slice_scatter</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">src</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">start</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">end</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">step</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;slice scatter&quot;</span>
    <span class="k">if</span> <span class="n">g</span><span class="o">.</span><span class="n">has_shape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="ow">and</span> <span class="n">is_static_shape</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(</span><span class="n">x</span><span class="p">)):</span>
        <span class="k">return</span> <span class="n">_aten_slice_scatter_static</span><span class="p">(</span>
            <span class="n">g</span><span class="p">,</span>
            <span class="n">sts</span><span class="p">,</span>
            <span class="n">outputs</span><span class="p">,</span>
            <span class="n">x</span><span class="p">,</span>
            <span class="n">src</span><span class="p">,</span>
            <span class="n">dim</span><span class="p">,</span>
            <span class="n">start</span><span class="p">,</span>
            <span class="n">end</span><span class="p">,</span>
            <span class="n">step</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="n">name</span> <span class="ow">or</span> <span class="s2">&quot;slice_scatter_static&quot;</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">_aten_slice_scatter_dynamic</span><span class="p">(</span>
        <span class="n">g</span><span class="p">,</span>
        <span class="n">sts</span><span class="p">,</span>
        <span class="n">outputs</span><span class="p">,</span>
        <span class="n">x</span><span class="p">,</span>
        <span class="n">src</span><span class="p">,</span>
        <span class="n">dim</span><span class="p">,</span>
        <span class="n">start</span><span class="p">,</span>
        <span class="n">end</span><span class="p">,</span>
        <span class="n">step</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="n">name</span> <span class="ow">or</span> <span class="s2">&quot;slice_scatter_dynamic&quot;</span><span class="p">,</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="aten_sigmoid">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_sigmoid">[docs]</a>
<span class="k">def</span> <span class="nf">aten_sigmoid</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span> <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">x</span><span class="p">:</span> <span class="n">T</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;sigmoid&quot;</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_sigmoid_backward">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_sigmoid_backward">[docs]</a>
<span class="k">def</span> <span class="nf">aten_sigmoid_backward</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">out_grad</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    sigmoid backward</span>

<span class="sd">    See https://github.com/pytorch/pytorch/blob/main/torch/_decomp/decompositions.py#L108.</span>
<span class="sd">    conj_physical = identity for real number.</span>

<span class="sd">    ::</span>

<span class="sd">        return out_grad * (y * (1 - y)).conj_physical()</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">tensor_dtype_to_np_dtype</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
    <span class="n">_1y</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Sub</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">),</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;sigmoid_backward&quot;</span><span class="p">)</span>
    <span class="n">y1y</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Mul</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">_1y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;sigmoid_backward&quot;</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Mul</span><span class="p">(</span><span class="n">out_grad</span><span class="p">,</span> <span class="n">y1y</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;sigmoid_backward&quot;</span><span class="p">)</span>

    <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">_1y</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">y1y</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_silu">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_silu">[docs]</a>
<span class="k">def</span> <span class="nf">aten_silu</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">inplace</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;silu&quot;</span>
    <span class="k">assert</span> <span class="p">(</span>
        <span class="ow">not</span> <span class="n">inplace</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;inplace computation is not allowed with onnx</span><span class="si">{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Mul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;silu&quot;</span><span class="p">),</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;silu&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_sin">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_sin">[docs]</a>
<span class="k">def</span> <span class="nf">aten_sin</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span> <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;sin&quot;</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;sin&quot;</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Sin&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_sinh">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_sinh">[docs]</a>
<span class="k">def</span> <span class="nf">aten_sinh</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span> <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">x</span><span class="p">:</span> <span class="n">T</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;sinh&quot;</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Sinh&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;sinh&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_softmax">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_softmax">[docs]</a>
<span class="k">def</span> <span class="nf">aten_softmax</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">dtype</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;torch.dtype&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># noqa: F821</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;softmax&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;softmax&quot;</span>
    <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">itype</span> <span class="o">=</span> <span class="n">torch_dtype_to_onnx_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">xc</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Cast</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">to</span><span class="o">=</span><span class="n">itype</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">itype</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">xc</span> <span class="o">=</span> <span class="n">x</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">xc</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="n">xc</span><span class="p">,</span> <span class="n">itype</span><span class="o">=</span><span class="n">itype</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_softmax_int">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_softmax_int">[docs]</a>
<span class="k">def</span> <span class="nf">aten_softmax_int</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">dtype</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;torch.dtype&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># noqa: F821</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;softmax&quot;</span>
    <span class="k">return</span> <span class="n">aten_softmax</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">sts</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;softmax_int&quot;</span><span class="p">)</span></div>



<div class="viewcode-block" id="aten__softmax">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten__softmax">[docs]</a>
<span class="k">def</span> <span class="nf">aten__softmax</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">half_to_float</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;softmax&quot;</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="n">half_to_float</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Unexpected value for half_to_float=</span><span class="si">{</span><span class="n">half_to_float</span><span class="si">!r}</span><span class="s2">&quot;</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;_softmax&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten__softmax_backward_data">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten__softmax_backward_data">[docs]</a>
<span class="k">def</span> <span class="nf">aten__softmax_backward_data</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">grad_output</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">input_dtype</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;torch.dtype&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># noqa: F821</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;softmax backward&quot;</span>
    <span class="k">if</span> <span class="n">input_dtype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">itype</span> <span class="o">=</span> <span class="n">torch_dtype_to_onnx_dtype</span><span class="p">(</span><span class="n">input_dtype</span><span class="p">)</span>
        <span class="n">grad_outputc</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Cast</span><span class="p">(</span>
            <span class="n">grad_output</span><span class="p">,</span> <span class="n">to</span><span class="o">=</span><span class="n">itype</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;log_softmax_backward_data&quot;</span>
        <span class="p">)</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">grad_outputc</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">itype</span><span class="o">=</span><span class="n">itype</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">itype</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">grad_outputc</span> <span class="o">=</span> <span class="n">grad_output</span>

    <span class="n">new_grad_output</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Mul</span><span class="p">(</span><span class="n">grad_outputc</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">new_grad_output</span><span class="p">,</span> <span class="n">grad_outputc</span><span class="p">)</span>
    <span class="n">sums</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">ReduceSum</span><span class="p">(</span>
        <span class="n">new_grad_output</span><span class="p">,</span>
        <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">dim</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
        <span class="n">keepdims</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;softmax_backward_data&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">set_type_shape_reduce_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">sums</span><span class="p">,</span> <span class="n">new_grad_output</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="p">(</span><span class="n">dim</span><span class="p">,))</span>
    <span class="n">temp</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Mul</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">sums</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;softmax_backward_data&quot;</span><span class="p">)</span>
    <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">temp</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Sub</span><span class="p">(</span><span class="n">new_grad_output</span><span class="p">,</span> <span class="n">temp</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;softmax_backward_data&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="n">grad_outputc</span><span class="p">,</span> <span class="n">itype</span><span class="o">=</span><span class="n">itype</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_split_with_sizes">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_split_with_sizes">[docs]</a>
<span class="k">def</span> <span class="nf">aten_split_with_sizes</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">split_sizes</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;split_with_sizes&quot;</span><span class="p">,</span>
    <span class="n">use_sequence</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;split_to_sequence or split&quot;</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">split_sizes</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="n">all_int</span><span class="p">(</span>
        <span class="n">split_sizes</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Implemented when split_sizes (</span><span class="si">{</span><span class="n">split_sizes</span><span class="si">}</span><span class="s2">) is a constant</span><span class="si">{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="nb">int</span><span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;dim=</span><span class="si">{</span><span class="n">dim</span><span class="si">}</span><span class="s2"> is not an integer</span><span class="si">{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">d</span><span class="p">:</span> <span class="n">d</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">split_sizes</span><span class="p">)),</span> <span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;split_with_sizes only implemented when all sizes are positive &quot;</span>
        <span class="sa">f</span><span class="s2">&quot;but split_sizes=</span><span class="si">{</span><span class="n">split_sizes</span><span class="si">}{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="p">)</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">split_sizes</span><span class="p">)),</span> <span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;Number of outputs is unexpected, outputs=</span><span class="si">{</span><span class="n">outputs</span><span class="si">}</span><span class="s2">, &quot;</span>
        <span class="sa">f</span><span class="s2">&quot;split_sizes=</span><span class="si">{</span><span class="n">split_sizes</span><span class="si">}{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="p">)</span>
    <span class="n">init</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">make_initializer</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">split_sizes</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">use_sequence</span><span class="p">:</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;SplitToSequence&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">init</span><span class="p">],</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">g</span><span class="o">.</span><span class="n">has_shape</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
                <span class="n">new_shapes</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="n">shape</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                <span class="n">new_shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">split_sizes</span><span class="p">:</span>
                    <span class="n">new_shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">=</span> <span class="n">s</span>
                    <span class="n">new_shapes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">new_shape</span><span class="p">))</span>
                <span class="n">g</span><span class="o">.</span><span class="n">set_sequence</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">shapes</span><span class="o">=</span><span class="n">new_shapes</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">r</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_rank</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                <span class="n">g</span><span class="o">.</span><span class="n">set_sequence</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">types</span><span class="o">=</span><span class="p">[</span><span class="n">r</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">split_sizes</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">res</span>

    <span class="c1"># Split directly as tensors.</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">o</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">o</span><span class="si">}</span><span class="s2">#</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">split_sizes</span><span class="p">)]</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Split&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">init</span><span class="p">],</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">new_shapes</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">new_ranks</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">g</span><span class="o">.</span><span class="n">has_shape</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">new_shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">split_sizes</span><span class="p">:</span>
                <span class="n">new_shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">=</span> <span class="n">s</span>
                <span class="n">new_shapes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">new_shape</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">r</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_rank</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">new_ranks</span> <span class="o">=</span> <span class="p">[</span><span class="n">r</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">split_sizes</span><span class="p">]</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">o</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">res</span><span class="p">):</span>
            <span class="n">g</span><span class="o">.</span><span class="n">set_type</span><span class="p">(</span><span class="n">o</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">new_shapes</span><span class="p">:</span>
                <span class="n">g</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(</span><span class="n">o</span><span class="p">,</span> <span class="n">new_shape</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">g</span><span class="o">.</span><span class="n">get_rank</span><span class="p">(</span><span class="n">o</span><span class="p">,</span> <span class="n">new_ranks</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_sqrt">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_sqrt">[docs]</a>
<span class="k">def</span> <span class="nf">aten_sqrt</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span> <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">x</span><span class="p">:</span> <span class="n">T</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;sqrt&quot;</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Sqrt&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;sqrt&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_squeeze">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_squeeze">[docs]</a>
<span class="k">def</span> <span class="nf">aten_squeeze</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;squeeze&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;squeeze&quot;</span>
    <span class="k">return</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">SqueezeAnyOpset</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span></div>



<div class="viewcode-block" id="aten_squeeze_dim">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_squeeze_dim">[docs]</a>
<span class="k">def</span> <span class="nf">aten_squeeze_dim</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;squeeze&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;squeeze_dim&quot;</span>
    <span class="k">return</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">SqueezeAnyOpset</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">dim</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span></div>



<div class="viewcode-block" id="aten_sub">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_sub">[docs]</a>
<span class="k">def</span> <span class="nf">aten_sub</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;sub&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;sub&quot;</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">prepare_inputs_homogeneous_operator</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Sub</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_binary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_sub_Tensor">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_sub_Tensor">[docs]</a>
<span class="k">def</span> <span class="nf">aten_sub_Tensor</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;sub&quot;</span>
    <span class="k">assert</span> <span class="p">(</span>
        <span class="n">alpha</span> <span class="o">==</span> <span class="mi">1</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;sub_Tensor not implemented for alpha=</span><span class="si">{</span><span class="n">alpha</span><span class="si">}{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">return</span> <span class="n">aten_sub</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">sts</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;sub_Tensor&quot;</span><span class="p">)</span></div>



<div class="viewcode-block" id="aten_sum">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_sum">[docs]</a>
<span class="k">def</span> <span class="nf">aten_sum</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">dim</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">keepdim</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">dtype</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;torch.dtype&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># noqa: F821</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;sum&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;reducesum&quot;</span>
    <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">itype</span> <span class="o">=</span> <span class="n">torch_dtype_to_onnx_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">xc</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Cast</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">to</span><span class="o">=</span><span class="n">itype</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">xc</span> <span class="o">=</span> <span class="n">x</span>
    <span class="k">if</span> <span class="n">dim</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">ReduceSumAnyOpset</span><span class="p">(</span>
            <span class="n">xc</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="n">keepdim</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">adim</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">dim</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">adim</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">ReduceSumAnyOpset</span><span class="p">(</span>
            <span class="n">xc</span><span class="p">,</span> <span class="n">adim</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="n">keepdim</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_reduce_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="n">keepdim</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span></div>



<div class="viewcode-block" id="aten_sum_dim_IntList">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_sum_dim_IntList">[docs]</a>
<span class="k">def</span> <span class="nf">aten_sum_dim_IntList</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">dim</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]],</span>
    <span class="n">keepdim</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">dtype</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;torch.dtype&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># noqa: F821</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;reducesum&quot;</span>
    <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">aten_sum</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">sts</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">)</span>

    <span class="n">res</span> <span class="o">=</span> <span class="n">aten_sum</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">sts</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">)</span>
    <span class="n">itype</span> <span class="o">=</span> <span class="n">torch_dtype_to_onnx_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Cast</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">to</span><span class="o">=</span><span class="n">itype</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;sum_dim_IntList&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span></div>



<div class="viewcode-block" id="aten_sym_size_int">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_sym_size_int">[docs]</a>
<span class="k">def</span> <span class="nf">aten_sym_size_int</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;sym_size_int&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Shape + Gather</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Shape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Gather</span><span class="p">(</span>
        <span class="n">shape</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">dim</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="aten__to_copy">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten__to_copy">[docs]</a>
<span class="k">def</span> <span class="nf">aten__to_copy</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">dtype</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;torch.dtype&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># noqa: F821</span>
    <span class="n">layout</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;torch.device&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># noqa: F821</span>
    <span class="n">pin_memory</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">non_blocking</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">memory_format</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;identity&quot;</span>
    <span class="kn">import</span> <span class="nn">torch</span>

    <span class="k">assert</span> <span class="n">layout</span> <span class="ow">in</span> <span class="p">(</span>
        <span class="kc">None</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">strided</span><span class="p">,</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;_to_copy implemented with layout=</span><span class="si">{</span><span class="n">layout</span><span class="si">!r}</span><span class="s2">&quot;</span>
    <span class="c1"># assert device is None, f&quot;_to_copy implemented with device={device!r}&quot;</span>
    <span class="k">assert</span> <span class="n">pin_memory</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;_to_copy implemented with pin_memory=</span><span class="si">{</span><span class="n">pin_memory</span><span class="si">!r}</span><span class="s2">&quot;</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="n">non_blocking</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;_to_copy implemented with non_blocking=</span><span class="si">{</span><span class="n">non_blocking</span><span class="si">!r}</span><span class="s2">&quot;</span>
    <span class="k">assert</span> <span class="p">(</span>
        <span class="n">memory_format</span> <span class="ow">is</span> <span class="kc">None</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;_to_copy implemented with memory_format=</span><span class="si">{</span><span class="n">memory_format</span><span class="si">!r}</span><span class="s2">&quot;</span>
    <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Identity</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;_to_copy&quot;</span><span class="p">)</span>
    <span class="n">itype</span> <span class="o">=</span> <span class="n">torch_dtype_to_onnx_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Cast</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">to</span><span class="o">=</span><span class="n">itype</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;_to_copy&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">itype</span><span class="o">=</span><span class="n">itype</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_t">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_t">[docs]</a>
<span class="k">def</span> <span class="nf">aten_t</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;t&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;transpose&quot;</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_type</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">g</span><span class="o">.</span><span class="n">has_shape</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Unexpected shape=</span><span class="si">{</span><span class="n">shape</span><span class="si">}</span><span class="s2">, should be 2D&quot;</span>
            <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">g</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">g</span><span class="o">.</span><span class="n">set_rank</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">get_rank</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_tan">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_tan">[docs]</a>
<span class="k">def</span> <span class="nf">aten_tan</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span> <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">x</span><span class="p">:</span> <span class="n">T</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;tan&quot;</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Tan&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;tan&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_tanh">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_tanh">[docs]</a>
<span class="k">def</span> <span class="nf">aten_tanh</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span> <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">x</span><span class="p">:</span> <span class="n">T</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;tanh&quot;</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Tanh&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;tanh&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_tanh_backward">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_tanh_backward">[docs]</a>
<span class="k">def</span> <span class="nf">aten_tanh_backward</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">out_grad</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;tanh backward&quot;</span>
    <span class="c1"># out_grad * (1 - y * y)</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">tensor_dtype_to_np_dtype</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
    <span class="n">yy</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Pow</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;tanh_backward&quot;</span><span class="p">)</span>
    <span class="n">_1yy</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Sub</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">),</span> <span class="n">yy</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;tanh_backward&quot;</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Mul</span><span class="p">(</span><span class="n">out_grad</span><span class="p">,</span> <span class="n">_1yy</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;tanh_backward&quot;</span><span class="p">)</span>

    <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">_1yy</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<span class="k">def</span> <span class="nf">_aten_tensor_int1</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">input_name</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">indices</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
    <span class="n">axes</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">expand_axes</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;_aten_tensor_int1&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="nb">list</span><span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Unexpected type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">axes</span><span class="p">)</span><span class="si">}</span><span class="s2"> for axes&quot;</span>
    <span class="k">assert</span> <span class="n">all_int</span><span class="p">(</span><span class="n">axes</span><span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Expected only integer axis but got </span><span class="si">{</span><span class="n">axes</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">assert</span> <span class="n">all_int</span><span class="p">(</span><span class="n">indices</span><span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Expected only integer axis but got </span><span class="si">{</span><span class="n">indices</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">axes</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Length mismatch </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">axes</span><span class="p">)</span><span class="si">}</span><span class="s2"> != 1&quot;</span>

    <span class="c1"># axes</span>
    <span class="n">indices_name</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">unique_name</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">_indices&quot;</span><span class="p">)</span>
    <span class="n">g</span><span class="o">.</span><span class="n">make_initializer</span><span class="p">(</span><span class="n">indices_name</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span>

    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
        <span class="s2">&quot;Gather&quot;</span><span class="p">,</span>
        <span class="p">[</span><span class="n">input_name</span><span class="p">,</span> <span class="n">indices_name</span><span class="p">],</span>
        <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span>
        <span class="n">axis</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
        <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">expand_axes</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Not implemented when expand_axes=</span><span class="si">{</span><span class="n">expand_axes</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">input_name</span><span class="p">)</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_type</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">g</span><span class="o">.</span><span class="n">has_shape</span><span class="p">(</span><span class="n">input_name</span><span class="p">):</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(</span><span class="n">input_name</span><span class="p">)</span>
            <span class="n">new_shape</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">_apply_slice_to_shape</span><span class="p">(</span>
                <span class="n">shape</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="n">axes</span><span class="p">,</span> <span class="n">expand_axes</span><span class="o">=</span><span class="n">expand_axes</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">g</span><span class="o">.</span><span class="n">has_shape</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="ow">and</span> <span class="n">new_shape</span> <span class="o">!=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Shape for node </span><span class="si">{</span><span class="n">res</span><span class="si">!r}</span><span class="s2"> is already set to &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">g</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(</span><span class="n">res</span><span class="p">)</span><span class="si">}</span><span class="s2"> with type &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">res</span><span class="p">)</span><span class="si">}</span><span class="s2"> (expecting </span><span class="si">{</span><span class="n">dtype</span><span class="si">}</span><span class="s2">) &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;new_shape=</span><span class="si">{</span><span class="n">new_shape</span><span class="si">}</span><span class="s2">, shape=</span><span class="si">{</span><span class="n">shape</span><span class="si">}</span><span class="s2">, index_slice=</span><span class="si">{</span><span class="n">indices</span><span class="si">}</span><span class="s2">, &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;axes=</span><span class="si">{</span><span class="n">axes</span><span class="si">}</span><span class="s2">, expand_axes=</span><span class="si">{</span><span class="n">expand_axes</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
            <span class="n">g</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">new_shape</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">g</span><span class="o">.</span><span class="n">set_rank</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">get_rank</span><span class="p">(</span><span class="n">input_name</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">res</span>


<div class="viewcode-block" id="aten_tensor">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_tensor">[docs]</a>
<span class="k">def</span> <span class="nf">aten_tensor</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">indices</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="o">...</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;[..., :, ...]&quot;</span>
    <span class="k">if</span> <span class="n">indices</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># x is some data to convert into a Tensor</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="n">all_int_or_float</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">all_int</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
                <span class="n">cst</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">all_float</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
                <span class="n">cst</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Unable to convert to guess value dtype &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;for x=</span><span class="si">{</span><span class="n">x</span><span class="si">}{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

            <span class="k">return</span> <span class="n">g</span><span class="o">.</span><span class="n">make_initializer</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cst</span><span class="p">)</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Unable to convert a value into a tensor, x=</span><span class="si">{</span><span class="n">x</span><span class="si">}{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">indices</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="n">all_int</span><span class="p">(</span><span class="n">indices</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="k">return</span> <span class="n">_aten_tensor_int1</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">sts</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[])</span>
    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;Unable to handle getitem with indices=</span><span class="si">{</span><span class="n">indices</span><span class="si">}{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="aten_threshold_backward">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_threshold_backward">[docs]</a>
<span class="k">def</span> <span class="nf">aten_threshold_backward</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">grad_output</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;threshold_backward&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;lessorequal&quot;</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">tensor_dtype_to_np_dtype</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">grad_output</span><span class="p">))</span>
    <span class="n">le</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">LessOrEqual</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">threshold</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Where</span><span class="p">(</span>
        <span class="n">le</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">),</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span>
    <span class="p">)</span>
    <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">le</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">BOOL</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_transpose">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_transpose">[docs]</a>
<span class="k">def</span> <span class="nf">aten_transpose</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">input_name</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">dim0</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">dim1</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;transpose&quot;</span>
    <span class="n">perm</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">rank</span><span class="p">(</span><span class="n">input_name</span><span class="p">)))</span>
    <span class="n">perm</span><span class="p">[</span><span class="n">dim0</span><span class="p">],</span> <span class="n">perm</span><span class="p">[</span><span class="n">dim1</span><span class="p">]</span> <span class="o">=</span> <span class="n">perm</span><span class="p">[</span><span class="n">dim1</span><span class="p">],</span> <span class="n">perm</span><span class="p">[</span><span class="n">dim0</span><span class="p">]</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Transpose&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">input_name</span><span class="p">],</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="n">perm</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;transpose&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_type</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">input_name</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">g</span><span class="o">.</span><span class="n">has_shape</span><span class="p">(</span><span class="n">input_name</span><span class="p">):</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(</span><span class="n">input_name</span><span class="p">))</span>
            <span class="n">shape</span><span class="p">[</span><span class="n">dim0</span><span class="p">],</span> <span class="n">shape</span><span class="p">[</span><span class="n">dim1</span><span class="p">]</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="n">dim1</span><span class="p">],</span> <span class="n">shape</span><span class="p">[</span><span class="n">dim0</span><span class="p">]</span>
            <span class="n">g</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">))</span>
        <span class="k">elif</span> <span class="n">g</span><span class="o">.</span><span class="n">has_rank</span><span class="p">(</span><span class="n">input_name</span><span class="p">):</span>
            <span class="n">g</span><span class="o">.</span><span class="n">set_rank</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">g</span><span class="o">.</span><span class="n">has_rank</span><span class="p">(</span><span class="n">input_name</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_transpose_int">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_transpose_int">[docs]</a>
<span class="k">def</span> <span class="nf">aten_transpose_int</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">input_name</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">dim0</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">dim1</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;transpose&quot;</span>
    <span class="k">return</span> <span class="n">aten_transpose</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">sts</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">dim0</span><span class="p">,</span> <span class="n">dim1</span><span class="p">)</span></div>



<div class="viewcode-block" id="aten_tril">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_tril">[docs]</a>
<span class="k">def</span> <span class="nf">aten_tril</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">diagonal</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;tril&quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">diagonal</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Trilu</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Trilu</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">diagonal</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">upper</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_truediv">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_truediv">[docs]</a>
<span class="k">def</span> <span class="nf">aten_truediv</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span> <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">T</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;truediv&quot;</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">prepare_inputs_homogeneous_operator</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Div</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;truediv&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_binary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_triu">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_triu">[docs]</a>
<span class="k">def</span> <span class="nf">aten_triu</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">diagonal</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;trilu&quot;&quot;&quot;</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Trilu</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;triu&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_unsqueeze">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_unsqueeze">[docs]</a>
<span class="k">def</span> <span class="nf">aten_unsqueeze</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span> <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;unsqueeze&quot;</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="nb">int</span><span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Not implemented for dim=</span><span class="si">{</span><span class="n">dim</span><span class="si">!r}</span><span class="s2">&quot;</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">UnsqueezeAnyOpset</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">dim</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_type</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">g</span><span class="o">.</span><span class="n">has_shape</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
            <span class="n">shape</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">g</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">g</span><span class="o">.</span><span class="n">set_rank</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">get_rank</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten_view">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_view">[docs]</a>
<span class="k">def</span> <span class="nf">aten_view</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">size</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">node_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;view&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;slice&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
        <span class="n">asize</span> <span class="o">=</span> <span class="p">[</span><span class="n">size</span><span class="p">]</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="k">else</span> <span class="nb">list</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">is_static_shape</span><span class="p">(</span><span class="n">asize</span><span class="p">):</span>
            <span class="n">asize</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">asize</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="nb">len</span><span class="p">(</span><span class="n">asize</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
            <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Unexpected shape for view, size=</span><span class="si">{</span><span class="n">size</span><span class="si">}{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">elif</span> <span class="n">g</span><span class="o">.</span><span class="n">is_dynamic_shape</span><span class="p">(</span><span class="n">asize</span><span class="p">):</span>
            <span class="n">asize</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">make_shape_from_results</span><span class="p">(</span><span class="n">asize</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">node_name</span><span class="p">)</span>
            <span class="c1"># TODO: check that the shape is just a number</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;aten_view not implemented when size=</span><span class="si">{</span><span class="n">size</span><span class="si">!r}{</span><span class="n">g</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">asize</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">node_name</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
            <span class="n">set_type_shape_reshape</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">asize</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">res</span>

    <span class="n">csize</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Cast</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">to</span><span class="o">=</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">INT64</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">node_name</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">csize</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">node_name</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_reshape</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>



<div class="viewcode-block" id="aten__unsafe_view">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten__unsafe_view">[docs]</a>
<span class="k">def</span> <span class="nf">aten__unsafe_view</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span> <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="n">T</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;slice&quot;</span>
    <span class="k">return</span> <span class="n">aten_view</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">sts</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">node_name</span><span class="o">=</span><span class="s2">&quot;_unsafe_view&quot;</span><span class="p">)</span></div>



<div class="viewcode-block" id="aten_zeros">
<a class="viewcode-back" href="../../../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_zeros">[docs]</a>
<span class="k">def</span> <span class="nf">aten_zeros</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">size</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">dtype</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;torch.dtype&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># noqa: F821</span>
    <span class="n">layout</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;torch.device&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># noqa: F821</span>
    <span class="n">pin_memory</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">requires_grad</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;zeros&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;constantofshape&quot;</span>
    <span class="k">return</span> <span class="n">aten_full</span><span class="p">(</span>
        <span class="n">g</span><span class="p">,</span>
        <span class="n">sts</span><span class="p">,</span>
        <span class="n">outputs</span><span class="p">,</span>
        <span class="n">size</span><span class="p">,</span>
        <span class="n">fill_value</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">layout</span><span class="o">=</span><span class="n">layout</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
        <span class="n">pin_memory</span><span class="o">=</span><span class="n">pin_memory</span><span class="p">,</span>
        <span class="n">requires_grad</span><span class="o">=</span><span class="n">requires_grad</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
    <span class="p">)</span></div>

</pre></div>
        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          
          
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2023-2024
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer no-toc">
      
      
      
    </aside>
  </div>
</div><script src="../../../_static/documentation_options.js?v=a1637f0b"></script>
    <script src="../../../_static/doctools.js?v=888ff710"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/scripts/furo.js?v=4e2eecee"></script>
    </body>
</html>