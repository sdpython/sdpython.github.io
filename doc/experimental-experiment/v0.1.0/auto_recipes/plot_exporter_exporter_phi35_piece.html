<!doctype html>
<html class="no-js" lang="en" data-content_root="../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="Export Phi-3.5-mini-instruct with draft_export" href="plot_exporter_exporter_draft_mode.html" /><link rel="prev" title="Do no use Module as inputs!" href="plot_exporter_exporter_inputs.html" />

    <!-- Generated with Sphinx 8.1.3 and Furo 2024.08.06 -->
        <title>Export Phi-3.5-mini-instruct piece by piece - experimental-experiment 0.1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=354aac6f" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css?v=7f9a90b1" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css?v=4ae1632d" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=302659d7" />
    
    


<style>
  body {
    --color-code-background: #eeffcc;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">experimental-experiment 0.1.0 documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="../_static/logo.png" alt="Logo"/>
  </div>
  
  <span class="sidebar-brand-text">experimental-experiment 0.1.0 documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Contents</span></p>
<ul class="current">
<li class="toctree-l1 has-children"><a class="reference internal" href="../design/index.html">Design</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of Design</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../design/exporter.html">Custom Exporter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../design/optimizer.html">Pattern Optimizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../design/backends.html">Dynamo Backends</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../tutorial/index.html">Tutorial</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of Tutorial</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../tutorial/docker.html">Start from a docker</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../tutorial/exported.html">Supported Model Signatures</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of Supported Model Signatures</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../tutorial/exported_program.html">Exported Programs with Static Shapes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorial/exported_program_dynamic.html">Exported Programs with Dynamic Shapes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorial/exported_onnx.html">Exported into ONNX with Static Shapes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorial/exported_onnx_dynamic.html">Exported into ONNX with Dynamic Shapes</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api/index.html">API</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of API</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/gradient/index.html">.gradient</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of .gradient</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/gradient/ops/index.html">.gradient.ops</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle navigation of .gradient.ops</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/gradient/ops/op_broadcast_gradient_args.html">.gradient.ops.op_broadcast_gradient_args</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api/gradient/grad_helper.html">.gradient.grad_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/gradient/loss_helper.html">.gradient.loss_helper</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/reference/index.html">.reference</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle navigation of .reference</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/reference/ops/index.html">.reference.ops</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle navigation of .reference.ops</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_add_add_mul_mul.html">.reference.ops.op_add_add_mul_mul</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_average_pool_grad.html">.reference.ops.op_average_pool_grad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_cast_like.html">.reference.ops.op_cast_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_concat.html">.reference.ops.op_concat</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_constant_of_shape.html">.reference.ops.op_constant_of_shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_fused_matmul.html">.reference.ops.op_fused_matmul</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_gather_grad.html">.reference.ops.op_gather_grad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_memcpy_host.html">.reference.ops.op_memcpy_host</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_mul_sigmoid.html">.reference.ops.op_mul_sigmoid</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_negxplus1.html">.reference.ops.op_negxplus1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_quick_gelu.html">.reference.ops.op_quick_gelu</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_replace_zero.html">.reference.ops.op_replace_zero</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_rotary.html">.reference.ops.op_rotary</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_qlinear_average_pool.html">.reference.ops.op_qlinear_average_pool</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_qlinear_conv.html">.reference.ops.op_qlinear_conv</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_scatter_elements.html">.reference.ops.op_scatter_elements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_scatternd_of_shape.html">.reference.ops.op_scatternd_of_shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_simplified_layer_normalization.html">.reference.ops.op_simplified_layer_normalization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_slice.html">.reference.ops.op_slice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_transpose_cast.html">.reference.ops.op_transpose_cast</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_tri_matrix.html">.reference.ops.op_tri_matrix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api/reference/evaluator.html">.reference.evaluator</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/reference/ort_evaluator.html">.reference.ort_evaluator</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/reference/quantized_tensor.html">.reference.quantized_tensor</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/convert/index.html">.convert</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle navigation of .convert</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/convert/convert_helper.html">.convert.convert_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/convert/ort_helper.html">.convert.ort_helper</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/plotting/index.html">.plotting</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle navigation of .plotting</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/plotting/data.html">.plotting.data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/plotting/memory.html">.plotting.memory</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/torch_interpreter/index.html">.torch_interpreter</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><div class="visually-hidden">Toggle navigation of .torch_interpreter</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/_aten_functions.html">.torch_interpreter._aten_functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/_aten_functions_attention.html">.torch_interpreter._aten_functions_attention</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/_aten_methods.html">.torch_interpreter._aten_methods</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/_doc_.html">.torch_interpreter._doc_</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/_exceptions.html">.torch_interpreter._exceptions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/_prims_functions.html">.torch_interpreter._prims_functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/_torch_helper.html">.torch_interpreter._torch_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/aten_functions.html">.torch_interpreter.aten_functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/aten_methods.html">.torch_interpreter.aten_methods</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/dispatcher.html">.torch_interpreter.dispatcher</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/torch_interpreter/eval/index.html">.torch_interpreter.eval</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><div class="visually-hidden">Toggle navigation of .torch_interpreter.eval</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/torch_interpreter/eval/model_cases.html">.torch_interpreter.eval.model_cases</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/export_options.html">.torch_interpreter.export_options</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/interpreter.html">.torch_interpreter.interpreter</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/onnx_export.html">.torch_interpreter.onnx_export</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/onnx_export_errors.html">.torch_interpreter.onnx_export_errors</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/onnx_export_serialization.html">.torch_interpreter.onnx_export_serialization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/oxs_dispatcher.html">.torch_interpreter.oxs_dispatcher</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/oxs_opset.html">.torch_interpreter.oxs_opset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/piece_by_piece.html">.torch_interpreter.piece_by_piece</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/piece_by_piece_serialize.html">.torch_interpreter.piece_by_piece_serialize</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/torch_interpreter/patches/index.html">.torch_interpreter.patches</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" role="switch" type="checkbox"/><label for="toctree-checkbox-13"><div class="visually-hidden">Toggle navigation of .torch_interpreter.patches</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/torch_interpreter/patches/patch_torch.html">.torch_interpreter.patches.patch_torch</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/torch_interpreter/patches/patch_transformers.html">.torch_interpreter.patches.patch_transformers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/tracing.html">.torch_interpreter.tracing</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/torch_models/index.html">.torch_models</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" role="switch" type="checkbox"/><label for="toctree-checkbox-14"><div class="visually-hidden">Toggle navigation of .torch_models</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_models/diffusion_model_helper.html">.torch_models.diffusion_model_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_models/dump_helper.html">.torch_models.dump_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_models/llama_helper.html">.torch_models.llama_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_models/llm_model_helper.html">.torch_models.llm_model_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_models/llm_model_setup.html">.torch_models.llm_model_setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_models/mistral_helper.html">.torch_models.mistral_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_models/phi3_helper.html">.torch_models.phi3_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_models/phi_helper.html">.torch_models.phi_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_models/training_helper.html">.torch_models.training_helper</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/xbuilder/index.html">.xbuilder</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" role="switch" type="checkbox"/><label for="toctree-checkbox-15"><div class="visually-hidden">Toggle navigation of .xbuilder</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/xbuilder/_graph_builder_runtime.html">.xbuilder._graph_builder_runtime</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xbuilder/_onnx_helper.html">.xbuilder._onnx_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xbuilder/_shape_helper.html">.xbuilder._shape_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xbuilder/expression_dimension.html">.xbuilder.expression_dimension</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xbuilder/graph_builder.html">.xbuilder.graph_builder</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xbuilder/graph_builder_opset.html">.xbuilder.graph_builder_opset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xbuilder/model_container.html">.xbuilder.model_container</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xbuilder/optimization_options.html">.xbuilder.optimization_options</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xbuilder/shape_type_compute.html">.xbuilder.shape_type_compute</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xbuilder/type_inference.html">.xbuilder.type_inference</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/xoptim/index.html">.xoptim</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" role="switch" type="checkbox"/><label for="toctree-checkbox-16"><div class="visually-hidden">Toggle navigation of .xoptim</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/xoptim/patterns_investigation/index.html">.xoptim.patterns_investigation</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" role="switch" type="checkbox"/><label for="toctree-checkbox-17"><div class="visually-hidden">Toggle navigation of .xoptim.patterns_investigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_investigation/element_wise.html">.xoptim.patterns_investigation.element_wise</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_investigation/llm_patterns.html">.xoptim.patterns_investigation.llm_patterns</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/xoptim/patterns_ml/index.html">.xoptim.patterns_ml</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" role="switch" type="checkbox"/><label for="toctree-checkbox-18"><div class="visually-hidden">Toggle navigation of .xoptim.patterns_ml</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ml/tree_ensemble.html">.xoptim.patterns_ml.tree_ensemble</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/xoptim/patterns_exp/index.html">.xoptim.patterns_exp</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" role="switch" type="checkbox"/><label for="toctree-checkbox-19"><div class="visually-hidden">Toggle navigation of .xoptim.patterns_exp</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_exp/binary_operators.html">.xoptim.patterns_exp.binary_operators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_exp/constant_of_shape_scatter_nd.html">.xoptim.patterns_exp.constant_of_shape_scatter_nd</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_exp/constants.html">.xoptim.patterns_exp.constants</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_exp/simple_rotary.html">.xoptim.patterns_exp.simple_rotary</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_exp/unary_operators.html">.xoptim.patterns_exp.unary_operators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_exp/where_replace.html">.xoptim.patterns_exp.where_replace</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/xoptim/patterns/index.html">.xoptim.patterns</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" role="switch" type="checkbox"/><label for="toctree-checkbox-20"><div class="visually-hidden">Toggle navigation of .xoptim.patterns</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_any.html">.xoptim.patterns.onnx_any</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_cast.html">.xoptim.patterns.onnx_cast</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_clip.html">.xoptim.patterns.onnx_clip</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_constants.html">.xoptim.patterns.onnx_constants</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_conv.html">.xoptim.patterns.onnx_conv</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_dropout.html">.xoptim.patterns.onnx_dropout</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_equal.html">.xoptim.patterns.onnx_equal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_expand.html">.xoptim.patterns.onnx_expand</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_functions.html">.xoptim.patterns.onnx_functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_layer_normalization.html">.xoptim.patterns.onnx_layer_normalization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_matmul.html">.xoptim.patterns.onnx_matmul</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_mul.html">.xoptim.patterns.onnx_mul</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_reduce.html">.xoptim.patterns.onnx_reduce</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_reshape.html">.xoptim.patterns.onnx_reshape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_rotary.html">.xoptim.patterns.onnx_rotary</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_slice.html">.xoptim.patterns.onnx_slice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_split.html">.xoptim.patterns.onnx_split</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_sub.html">.xoptim.patterns.onnx_sub</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_sequence.html">.xoptim.patterns.onnx_sequence</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_transpose.html">.xoptim.patterns.onnx_transpose</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_unsqueeze.html">.xoptim.patterns.onnx_unsqueeze</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/xoptim/patterns_ort/index.html">.xoptim.patterns_ort</a><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" role="switch" type="checkbox"/><label for="toctree-checkbox-21"><div class="visually-hidden">Toggle navigation of .xoptim.patterns_ort</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ort/activation.html">.xoptim.patterns_ort.activation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ort/activation_grad.html">.xoptim.patterns_ort.activation_grad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ort/batch_normalization.html">.xoptim.patterns_ort.batch_normalization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ort/fused_conv.html">.xoptim.patterns_ort.fused_conv</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ort/fused_matmul.html">.xoptim.patterns_ort.fused_matmul</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ort/gather_grad.html">.xoptim.patterns_ort.gather_grad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ort/llm_optim.html">.xoptim.patterns_ort.llm_optim</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ort/simplified_layer_normalization.html">.xoptim.patterns_ort.simplified_layer_normalization</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/xoptim/patterns_fix/index.html">.xoptim.patterns_fix</a><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" role="switch" type="checkbox"/><label for="toctree-checkbox-22"><div class="visually-hidden">Toggle navigation of .xoptim.patterns_fix</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_fix/add_reduction_scatter_nd.html">.xoptim.patterns_fix.add_reduction_scatter_nd</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api/xoptim/graph_builder_optim.html">.xoptim.graph_builder_optim</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xoptim/order_optim.html">.xoptim.order_optim</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xoptim/patterns_api.html">.xoptim.patterns_api</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/torch_dynamo/index.html">.torch_dynamo</a><input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" role="switch" type="checkbox"/><label for="toctree-checkbox-23"><div class="visually-hidden">Toggle navigation of .torch_dynamo</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_dynamo/_dynamo_exporter.html">.torch_dynamo._dynamo_exporter</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_dynamo/backend_helper.html">.torch_dynamo.backend_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_dynamo/debug_backend.html">.torch_dynamo.debug_backend</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_dynamo/fast_backend.html">.torch_dynamo.fast_backend</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_dynamo/partition.html">experimental_experiment.torch_dynamo.partition</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/torch_bench/index.html">.torch_bench</a><input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" role="switch" type="checkbox"/><label for="toctree-checkbox-24"><div class="visually-hidden">Toggle navigation of .torch_bench</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_benchmark_runner.html">experimental_experiment.torch_bench._bash_bench_benchmark_runner</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_benchmark_runner_agg.html">experimental_experiment.torch_bench._bash_bench_benchmark_runner_agg</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_benchmark_runner_agg_helper.html">experimental_experiment.torch_bench._bash_bench_benchmark_runner_agg_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_cmd.html">experimental_experiment.torch_bench._bash_bench_cmd</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_model_runner.html">experimental_experiment.torch_bench._bash_bench_model_runner</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_models_helper.html">experimental_experiment.torch_bench._bash_bench_models_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_set_dummies.html">experimental_experiment.torch_bench._bash_bench_set_dummies</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_set_explicit.html">experimental_experiment.torch_bench._bash_bench_set_explicit</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_set_huggingface.html">experimental_experiment.torch_bench._bash_bench_set_huggingface</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_set_huggingface_big.html">experimental_experiment.torch_bench._bash_bench_set_huggingface_big</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_set_issues.html">experimental_experiment.torch_bench._bash_bench_set_issues</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_set_timm.html">experimental_experiment.torch_bench._bash_bench_set_timm</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_set_torchbench.html">experimental_experiment.torch_bench._bash_bench_set_torchbench</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_set_torchbench_ado.html">experimental_experiment.torch_bench._bash_bench_set_torchbench_ado</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_suites.html">experimental_experiment.torch_bench._bash_bench_suites</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_dort_cmd_common.html">experimental_experiment.torch_bench._dort_cmd_common</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_dort_cmd_common_models.html">experimental_experiment.torch_bench._dort_cmd_common_models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/bash_bench_agg.html">.torch_bench.bash_bench_agg</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/bash_bench_explicit.html">.torch_bench.bash_bench_explicit</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/bash_bench_huggingface.html">.torch_bench.bash_bench_huggingface</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/bash_bench_huggingface_big.html">.torch_bench.bash_bench_huggingface_big</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/bash_bench_issues.html">.torch_bench.bash_bench_issues</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/bash_bench_timm.html">.torch_bench.bash_bench_timm</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/bash_bench_torchbench.html">.torch_bench.bash_bench_torchbench</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/bash_bench_torchbench_ado.html">.torch_bench.bash_bench_torchbench_ado</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/bash_bench_untrained.html">.torch_bench.bash_bench_untrained</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/check_model.html">.torch_bench.check_model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/dort_bench.html">.torch_bench.dort_bench</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/dort_bench_profile.html">.torch_bench.dort_bench_profile</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/dort_profile.html">.torch_bench.dort_profile</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/export_model.html">.torch_bench.export_model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/export_model_helper.html">.torch_bench.export_model_helper</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api/_bench_test.html">._bench_test</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/_command_lines_parser.html">._command_lines_parser</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/args.html">.args</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bench_run.html">.bench_run</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/checks.html">.checks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/ext_test_case.html">.ext_test_case</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/helpers.html">.helpers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/memory_peak.html">.memory_peak</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/mini_onnx_builder.html">.mini_onnx_builder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/model_run.html">.model_run</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/onnx_tools.html">.onnx_tools</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/torch_test_helper.html">.torch_test_helper</a></li>
</ul>
</li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="../galleries.html">Galleries of Examples and Recipes</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" role="switch" type="checkbox"/><label for="toctree-checkbox-25"><div class="visually-hidden">Toggle navigation of Galleries of Examples and Recipes</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/index.html">Examples Gallery</a><input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" role="switch" type="checkbox"/><label for="toctree-checkbox-26"><div class="visually-hidden">Toggle navigation of Examples Gallery</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_custom_backend_101.html">101: A custom backend for torch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_linreg_101.html">101: Linear Regression and export to ONNX</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_optimize_101.html">101: Onnx Model Optimization based on Pattern Rewriting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_rewrite_101.html">101: Onnx Model Rewriting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_profile_existing_onnx_101.html">101: Profile an existing model with onnxruntime</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_export_101.html">101: Some dummy examples with torch.export.export</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_convolutation_matmul_102.html">102: Convolution and Matrix Multiplication</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_onnxscript_102.html">102: Examples with onnxscript</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_custom_backend_llama_102.html">102: Fuse kernels in a small Llama Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_llama_bench_102.html">102: Measure LLAMA speed</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_export_compile_102.html">102: Tweak onnx export</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_dort_201.html">201: Evaluate DORT</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_aot_201.html">201: Evaluate DORT Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_export_201.html">201: Evaluate different ways to export a torch model to ONNX</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_llama_diff_export_301.html">301: Compares LLAMA exporters</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_llama_diff_dort_301.html">301: Compares LLAMA exporters for onnxrt backend</a></li>
</ul>
</li>
<li class="toctree-l2 current has-children"><a class="reference internal" href="index.html">Exporter Recipes Gallery</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" role="switch" type="checkbox"/><label for="toctree-checkbox-27"><div class="visually-hidden">Toggle navigation of Exporter Recipes Gallery</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_exporter_lost_dynamic_dimension.html">A dynamic dimension lost by torch.export.export</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_exporter_dynamic_shapes.html">A few tricks about dynamic shapes</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_exporter_inputs.html">Do no use Module as inputs!</a></li>
<li class="toctree-l3 current current-page"><a class="current reference internal" href="#">Export Phi-3.5-mini-instruct piece by piece</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_exporter_draft_mode.html">Export Phi-3.5-mini-instruct with draft_export</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_exporter_reportibility.html">Export Phi-3.5-mini-instruct with report_exportability</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_exporter_with_dyamic_cache.html">Export a model using a custom type as input</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_recipes_oe_lr.html">Linear Regression and export to ONNX</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_coverage.html">Measures the exporter success on many test cases</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_recipes_c_phi2.html">to_onnx and Phi-2</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_recipes_c_custom_ops_inplace.html">to_onnx and a custom operator inplace</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_recipes_c_custom_ops_fct.html">to_onnx and a custom operator registered with a function</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_recipes_c_scan_pdist.html">to_onnx and a model with a loop (scan)</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_recipes_c_cond.html">to_onnx and a model with a test</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_recipes_c_ds.html">to_onnx and infer dynamic shapes</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_recipes_c_modules.html">to_onnx and submodules from LLMs</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_recipes_oe_phi2.html">torch.onnx.export and Phi-2</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_recipes_oe_cond.html">torch.onnx.export and a model with a test</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../command_lines.html">Command Lines</a><input class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" role="switch" type="checkbox"/><label for="toctree-checkbox-28"><div class="visually-hidden">Toggle navigation of Command Lines</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../bench/index.html">Benchmarks from the command line</a><input class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" role="switch" type="checkbox"/><label for="toctree-checkbox-29"><div class="visually-hidden">Toggle navigation of Benchmarks from the command line</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../bench/dort_bench.html">experimental_experiment.torch_bench.dort_bench</a></li>
<li class="toctree-l3"><a class="reference internal" href="../bench/dort_profile.html">experimental_experiment.torch_bench.dort_profile</a></li>
<li class="toctree-l3"><a class="reference internal" href="../bench/scripts.html">Interesting scripts or command lines</a></li>
<li class="toctree-l3"><a class="reference internal" href="../bench/bash_bench.html">Measuring the exporters on a short list of sets of models</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../tools/index.html">Tools from the command line</a><input class="toctree-checkbox" id="toctree-checkbox-30" name="toctree-checkbox-30" role="switch" type="checkbox"/><label for="toctree-checkbox-30"><div class="visually-hidden">Toggle navigation of Tools from the command line</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../tools/lighten.html">python -m experimental_experiment lighten and unlighten</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tools/optimize.html">python -m experimental_experiment optimize</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tools/print.html">python -m experimental_experiment print</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tools/run.html">python -m experimental_experiment run</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../miscellaneous/index.html">Miscellaneous</a><input class="toctree-checkbox" id="toctree-checkbox-31" name="toctree-checkbox-31" role="switch" type="checkbox"/><label for="toctree-checkbox-31"><div class="visually-hidden">Toggle navigation of Miscellaneous</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../miscellaneous/export_times.html">Export Times</a></li>
<li class="toctree-l2"><a class="reference internal" href="../miscellaneous/long_outputs.html">Long Outputs uneasy to read</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../miscellaneous/models/index.html">Supported Models By the Custom Backend</a><input class="toctree-checkbox" id="toctree-checkbox-32" name="toctree-checkbox-32" role="switch" type="checkbox"/><label for="toctree-checkbox-32"><div class="visually-hidden">Toggle navigation of Supported Models By the Custom Backend</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../miscellaneous/models/phi.html">Phi</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">More</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../CHANGELOGS.html">Change Logs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="../_sources/auto_recipes/plot_exporter_exporter_phi35_piece.rst" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-auto-recipes-plot-exporter-exporter-phi35-piece-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="export-phi-3-5-mini-instruct-piece-by-piece">
<span id="l-plot-exporter-exporter-phi35-piece"></span><span id="sphx-glr-auto-recipes-plot-exporter-exporter-phi35-piece-py"></span><h1>Export Phi-3.5-mini-instruct piece by piece<a class="headerlink" href="#export-phi-3-5-mini-instruct-piece-by-piece" title="Link to this heading">¶</a></h1>
<p><a class="reference external" href="https://pytorch.org/docs/main/export.html#torch.export.export" title="(in PyTorch vmain (2.7.0a0+git6b41f31 ))"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.export.export()</span></code></a> often breaks on big models because there
are control flows or instructions breaking the propagation of
dynamic shapes (see …). The function usually gives an indication where
the model implementation can be fixed but in case, that is not possible,
we can try to export the model piece by piece: every module
is converted separately from its submodule. A model can be exported even
if one of its submodules cannot.</p>
<section id="model">
<h2>Model<a class="headerlink" href="#model" title="Link to this heading">¶</a></h2>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pprint</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <a href="https://docs.python.org/3/library/typing.html#typing.Any" title="typing.Any" class="sphx-glr-backref-module-typing sphx-glr-backref-type-py-data"><a href="https://docs.python.org/3/library/typing.html#typing.Any" title="typing.Any" class="sphx-glr-backref-module-typing sphx-glr-backref-type-py-data"><span class="n">Any</span></a></a><span class="p">,</span> <a href="https://docs.python.org/3/library/typing.html#typing.Dict" title="typing.Dict" class="sphx-glr-backref-module-typing sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/typing.html#typing.Dict" title="typing.Dict" class="sphx-glr-backref-module-typing sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">Dict</span></a></a>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch._export.tools</span>
<span class="kn">import</span> <span class="nn">transformers</span>
<span class="kn">from</span> <span class="nn">experimental_experiment.helpers</span> <span class="kn">import</span> <a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/helpers.html#experimental_experiment.helpers.string_type" title="experimental_experiment.helpers.string_type" class="sphx-glr-backref-module-experimental_experiment-helpers sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/helpers.html#experimental_experiment.helpers.string_type" title="experimental_experiment.helpers.string_type" class="sphx-glr-backref-module-experimental_experiment-helpers sphx-glr-backref-type-py-function"><span class="n">string_type</span></a></a>
<span class="kn">from</span> <span class="nn">experimental_experiment.torch_interpreter.piece_by_piece</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">trace_execution_piece_by_piece</span><span class="p">,</span>
<span class="p">)</span>


<span class="k">def</span> <span class="nf">get_phi35_untrained</span><span class="p">(</span><span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <a href="https://docs.python.org/3/library/typing.html#typing.Dict" title="typing.Dict" class="sphx-glr-backref-module-typing sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/typing.html#typing.Dict" title="typing.Dict" class="sphx-glr-backref-module-typing sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">Dict</span></a></a><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <a href="https://docs.python.org/3/library/typing.html#typing.Any" title="typing.Any" class="sphx-glr-backref-module-typing sphx-glr-backref-type-py-data"><a href="https://docs.python.org/3/library/typing.html#typing.Any" title="typing.Any" class="sphx-glr-backref-module-typing sphx-glr-backref-type-py-data"><span class="n">Any</span></a></a><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Gets a non initialized model with two sets of inputs and different shapes.</span>

<span class="sd">    :param batch_size: batch size</span>
<span class="sd">    :param kwargs: to overwrite the configuration, example ``num_hidden_layers=1``</span>
<span class="sd">    :return: dictionary</span>

<span class="sd">    See `Phi-3.5-mini-instruct/config.json</span>
<span class="sd">    &lt;https://huggingface.co/microsoft/Phi-3.5-mini-instruct/blob/main/config.json&gt;`_.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;_name_or_path&quot;</span><span class="p">:</span> <span class="s2">&quot;Phi-3.5-mini-instruct&quot;</span><span class="p">,</span>
        <span class="s2">&quot;architectures&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;Phi3ForCausalLM&quot;</span><span class="p">],</span>
        <span class="s2">&quot;attention_dropout&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="s2">&quot;auto_map&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;AutoConfig&quot;</span><span class="p">:</span> <span class="s2">&quot;configuration_phi3.Phi3Config&quot;</span><span class="p">,</span>
            <span class="s2">&quot;AutoModelForCausalLM&quot;</span><span class="p">:</span> <span class="s2">&quot;modeling_phi3.Phi3ForCausalLM&quot;</span><span class="p">,</span>
        <span class="p">},</span>
        <span class="s2">&quot;bos_token_id&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
        <span class="s2">&quot;embd_pdrop&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="s2">&quot;eos_token_id&quot;</span><span class="p">:</span> <span class="mi">32000</span><span class="p">,</span>
        <span class="s2">&quot;hidden_act&quot;</span><span class="p">:</span> <span class="s2">&quot;silu&quot;</span><span class="p">,</span>
        <span class="s2">&quot;hidden_size&quot;</span><span class="p">:</span> <span class="mi">3072</span><span class="p">,</span>
        <span class="s2">&quot;initializer_range&quot;</span><span class="p">:</span> <span class="mf">0.02</span><span class="p">,</span>
        <span class="s2">&quot;intermediate_size&quot;</span><span class="p">:</span> <span class="mi">8192</span><span class="p">,</span>
        <span class="s2">&quot;max_position_embeddings&quot;</span><span class="p">:</span> <span class="mi">131072</span><span class="p">,</span>
        <span class="s2">&quot;model_type&quot;</span><span class="p">:</span> <span class="s2">&quot;phi3&quot;</span><span class="p">,</span>
        <span class="s2">&quot;num_attention_heads&quot;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
        <span class="s2">&quot;num_hidden_layers&quot;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
        <span class="s2">&quot;num_key_value_heads&quot;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
        <span class="s2">&quot;original_max_position_embeddings&quot;</span><span class="p">:</span> <span class="mi">4096</span><span class="p">,</span>
        <span class="s2">&quot;pad_token_id&quot;</span><span class="p">:</span> <span class="mi">32000</span><span class="p">,</span>
        <span class="s2">&quot;resid_pdrop&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="s2">&quot;rms_norm_eps&quot;</span><span class="p">:</span> <span class="mf">1e-05</span><span class="p">,</span>
        <span class="s2">&quot;rope_scaling&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;long_factor&quot;</span><span class="p">:</span> <span class="p">[</span>
                <span class="mf">1.0800000429153442</span><span class="p">,</span>
                <span class="mf">1.1100000143051147</span><span class="p">,</span>
                <span class="mf">1.1399999856948853</span><span class="p">,</span>
                <span class="mf">1.340000033378601</span><span class="p">,</span>
                <span class="mf">1.5899999141693115</span><span class="p">,</span>
                <span class="mf">1.600000023841858</span><span class="p">,</span>
                <span class="mf">1.6200000047683716</span><span class="p">,</span>
                <span class="mf">2.620000123977661</span><span class="p">,</span>
                <span class="mf">3.2300000190734863</span><span class="p">,</span>
                <span class="mf">3.2300000190734863</span><span class="p">,</span>
                <span class="mf">4.789999961853027</span><span class="p">,</span>
                <span class="mf">7.400000095367432</span><span class="p">,</span>
                <span class="mf">7.700000286102295</span><span class="p">,</span>
                <span class="mf">9.09000015258789</span><span class="p">,</span>
                <span class="mf">12.199999809265137</span><span class="p">,</span>
                <span class="mf">17.670000076293945</span><span class="p">,</span>
                <span class="mf">24.46000099182129</span><span class="p">,</span>
                <span class="mf">28.57000160217285</span><span class="p">,</span>
                <span class="mf">30.420001983642578</span><span class="p">,</span>
                <span class="mf">30.840002059936523</span><span class="p">,</span>
                <span class="mf">32.590003967285156</span><span class="p">,</span>
                <span class="mf">32.93000411987305</span><span class="p">,</span>
                <span class="mf">42.320003509521484</span><span class="p">,</span>
                <span class="mf">44.96000289916992</span><span class="p">,</span>
                <span class="mf">50.340003967285156</span><span class="p">,</span>
                <span class="mf">50.45000457763672</span><span class="p">,</span>
                <span class="mf">57.55000305175781</span><span class="p">,</span>
                <span class="mf">57.93000411987305</span><span class="p">,</span>
                <span class="mf">58.21000289916992</span><span class="p">,</span>
                <span class="mf">60.1400032043457</span><span class="p">,</span>
                <span class="mf">62.61000442504883</span><span class="p">,</span>
                <span class="mf">62.62000274658203</span><span class="p">,</span>
                <span class="mf">62.71000289916992</span><span class="p">,</span>
                <span class="mf">63.1400032043457</span><span class="p">,</span>
                <span class="mf">63.1400032043457</span><span class="p">,</span>
                <span class="mf">63.77000427246094</span><span class="p">,</span>
                <span class="mf">63.93000411987305</span><span class="p">,</span>
                <span class="mf">63.96000289916992</span><span class="p">,</span>
                <span class="mf">63.970001220703125</span><span class="p">,</span>
                <span class="mf">64.02999877929688</span><span class="p">,</span>
                <span class="mf">64.06999969482422</span><span class="p">,</span>
                <span class="mf">64.08000183105469</span><span class="p">,</span>
                <span class="mf">64.12000274658203</span><span class="p">,</span>
                <span class="mf">64.41000366210938</span><span class="p">,</span>
                <span class="mf">64.4800033569336</span><span class="p">,</span>
                <span class="mf">64.51000213623047</span><span class="p">,</span>
                <span class="mf">64.52999877929688</span><span class="p">,</span>
                <span class="mf">64.83999633789062</span><span class="p">,</span>
            <span class="p">],</span>
            <span class="s2">&quot;short_factor&quot;</span><span class="p">:</span> <span class="p">[</span>
                <span class="mf">1.0</span><span class="p">,</span>
                <span class="mf">1.0199999809265137</span><span class="p">,</span>
                <span class="mf">1.0299999713897705</span><span class="p">,</span>
                <span class="mf">1.0299999713897705</span><span class="p">,</span>
                <span class="mf">1.0499999523162842</span><span class="p">,</span>
                <span class="mf">1.0499999523162842</span><span class="p">,</span>
                <span class="mf">1.0499999523162842</span><span class="p">,</span>
                <span class="mf">1.0499999523162842</span><span class="p">,</span>
                <span class="mf">1.0499999523162842</span><span class="p">,</span>
                <span class="mf">1.0699999332427979</span><span class="p">,</span>
                <span class="mf">1.0999999046325684</span><span class="p">,</span>
                <span class="mf">1.1099998950958252</span><span class="p">,</span>
                <span class="mf">1.1599998474121094</span><span class="p">,</span>
                <span class="mf">1.1599998474121094</span><span class="p">,</span>
                <span class="mf">1.1699998378753662</span><span class="p">,</span>
                <span class="mf">1.2899998426437378</span><span class="p">,</span>
                <span class="mf">1.339999794960022</span><span class="p">,</span>
                <span class="mf">1.679999828338623</span><span class="p">,</span>
                <span class="mf">1.7899998426437378</span><span class="p">,</span>
                <span class="mf">1.8199998140335083</span><span class="p">,</span>
                <span class="mf">1.8499997854232788</span><span class="p">,</span>
                <span class="mf">1.8799997568130493</span><span class="p">,</span>
                <span class="mf">1.9099997282028198</span><span class="p">,</span>
                <span class="mf">1.9399996995925903</span><span class="p">,</span>
                <span class="mf">1.9899996519088745</span><span class="p">,</span>
                <span class="mf">2.0199997425079346</span><span class="p">,</span>
                <span class="mf">2.0199997425079346</span><span class="p">,</span>
                <span class="mf">2.0199997425079346</span><span class="p">,</span>
                <span class="mf">2.0199997425079346</span><span class="p">,</span>
                <span class="mf">2.0199997425079346</span><span class="p">,</span>
                <span class="mf">2.0199997425079346</span><span class="p">,</span>
                <span class="mf">2.0299997329711914</span><span class="p">,</span>
                <span class="mf">2.0299997329711914</span><span class="p">,</span>
                <span class="mf">2.0299997329711914</span><span class="p">,</span>
                <span class="mf">2.0299997329711914</span><span class="p">,</span>
                <span class="mf">2.0299997329711914</span><span class="p">,</span>
                <span class="mf">2.0299997329711914</span><span class="p">,</span>
                <span class="mf">2.0299997329711914</span><span class="p">,</span>
                <span class="mf">2.0299997329711914</span><span class="p">,</span>
                <span class="mf">2.0299997329711914</span><span class="p">,</span>
                <span class="mf">2.0799996852874756</span><span class="p">,</span>
                <span class="mf">2.0899996757507324</span><span class="p">,</span>
                <span class="mf">2.189999580383301</span><span class="p">,</span>
                <span class="mf">2.2199995517730713</span><span class="p">,</span>
                <span class="mf">2.5899994373321533</span><span class="p">,</span>
                <span class="mf">2.729999542236328</span><span class="p">,</span>
                <span class="mf">2.749999523162842</span><span class="p">,</span>
                <span class="mf">2.8399994373321533</span><span class="p">,</span>
            <span class="p">],</span>
            <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;longrope&quot;</span><span class="p">,</span>
        <span class="p">},</span>
        <span class="s2">&quot;rope_theta&quot;</span><span class="p">:</span> <span class="mf">10000.0</span><span class="p">,</span>
        <span class="s2">&quot;sliding_window&quot;</span><span class="p">:</span> <span class="mi">262144</span><span class="p">,</span>
        <span class="s2">&quot;tie_word_embeddings&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
        <span class="s2">&quot;torch_dtype&quot;</span><span class="p">:</span> <span class="s2">&quot;bfloat16&quot;</span><span class="p">,</span>
        <span class="s2">&quot;use_cache&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="s2">&quot;attention_bias&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
        <span class="s2">&quot;vocab_size&quot;</span><span class="p">:</span> <span class="mi">32064</span><span class="p">,</span>
    <span class="p">}</span>
    <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">conf</span> <span class="o">=</span> <span class="n">transformers</span><span class="o">.</span><span class="n">Phi3Config</span><span class="p">(</span><span class="o">**</span><span class="n">config</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <a href="https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">transformers</span><span class="o">.</span><span class="n">Phi3ForCausalLM</span></a></a><span class="p">(</span><span class="n">conf</span><span class="p">)</span>
    <a href="https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.eval" title="torch.nn.Module.eval" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method"><a href="https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.eval" title="torch.nn.Module.eval" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method"><span class="n">model</span><span class="o">.</span><span class="n">eval</span></a></a><span class="p">()</span>

    <span class="n">cache</span> <span class="o">=</span> <a href="https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">transformers</span><span class="o">.</span><span class="n">cache_utils</span><span class="o">.</span><span class="n">DynamicCache</span></a></a><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;num_hidden_layers&quot;</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;num_hidden_layers&quot;</span><span class="p">]):</span>
        <span class="n">cache</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <a href="https://pytorch.org/docs/main/generated/torch.randn.html#torch.randn" title="torch.randn" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><a href="https://pytorch.org/docs/main/generated/torch.randn.html#torch.randn" title="torch.randn" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a></a><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">96</span><span class="p">),</span> <a href="https://pytorch.org/docs/main/generated/torch.randn.html#torch.randn" title="torch.randn" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><a href="https://pytorch.org/docs/main/generated/torch.randn.html#torch.randn" title="torch.randn" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a></a><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">96</span><span class="p">),</span> <span class="n">i</span>
        <span class="p">)</span>
    <span class="n">cache2</span> <span class="o">=</span> <a href="https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">transformers</span><span class="o">.</span><span class="n">cache_utils</span><span class="o">.</span><span class="n">DynamicCache</span></a></a><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;num_hidden_layers&quot;</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;num_hidden_layers&quot;</span><span class="p">]):</span>
        <span class="n">cache2</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <a href="https://pytorch.org/docs/main/generated/torch.randn.html#torch.randn" title="torch.randn" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><a href="https://pytorch.org/docs/main/generated/torch.randn.html#torch.randn" title="torch.randn" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a></a><span class="p">(</span><span class="n">batch_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">96</span><span class="p">),</span>
            <a href="https://pytorch.org/docs/main/generated/torch.randn.html#torch.randn" title="torch.randn" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><a href="https://pytorch.org/docs/main/generated/torch.randn.html#torch.randn" title="torch.randn" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a></a><span class="p">(</span><span class="n">batch_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">96</span><span class="p">),</span>
            <span class="n">i</span><span class="p">,</span>
        <span class="p">)</span>

    <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">inputs</span></a></a> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
        <span class="n">input_ids</span><span class="o">=</span><a href="https://pytorch.org/docs/main/generated/torch.randint.html#torch.randint" title="torch.randint" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><a href="https://pytorch.org/docs/main/generated/torch.randint.html#torch.randint" title="torch.randint" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">randint</span></a></a><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">32064</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><a href="https://pytorch.org/docs/main/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://pytorch.org/docs/main/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch</span><span class="o">.</span><span class="n">int64</span></a></a><span class="p">),</span>
        <span class="n">attention_mask</span><span class="o">=</span><a href="https://pytorch.org/docs/main/generated/torch.ones.html#torch.ones" title="torch.ones" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><a href="https://pytorch.org/docs/main/generated/torch.ones.html#torch.ones" title="torch.ones" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">ones</span></a></a><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">33</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><a href="https://pytorch.org/docs/main/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://pytorch.org/docs/main/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch</span><span class="o">.</span><span class="n">int64</span></a></a><span class="p">),</span>
        <span class="n">past_key_values</span><span class="o">=</span><span class="n">cache</span><span class="p">,</span>
    <span class="p">)</span>
    <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">inputs2</span></a></a> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
        <span class="n">input_ids</span><span class="o">=</span><a href="https://pytorch.org/docs/main/generated/torch.randint.html#torch.randint" title="torch.randint" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><a href="https://pytorch.org/docs/main/generated/torch.randint.html#torch.randint" title="torch.randint" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">randint</span></a></a><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">32064</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><a href="https://pytorch.org/docs/main/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://pytorch.org/docs/main/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch</span><span class="o">.</span><span class="n">int64</span></a></a><span class="p">),</span>
        <span class="n">attention_mask</span><span class="o">=</span><a href="https://pytorch.org/docs/main/generated/torch.ones.html#torch.ones" title="torch.ones" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><a href="https://pytorch.org/docs/main/generated/torch.ones.html#torch.ones" title="torch.ones" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">ones</span></a></a><span class="p">((</span><span class="n">batch_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">35</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><a href="https://pytorch.org/docs/main/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://pytorch.org/docs/main/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch</span><span class="o">.</span><span class="n">int64</span></a></a><span class="p">),</span>
        <span class="n">past_key_values</span><span class="o">=</span><span class="n">cache2</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">inputs</span></a></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">inputs</span></a></a><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">inputs2</span></a></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">inputs2</span></a></a><span class="p">)</span>


<a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data</span></a></a> <span class="o">=</span> <span class="n">get_phi35_untrained</span><span class="p">(</span><span class="n">num_hidden_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">model</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">inputs</span></a></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">inputs2</span></a></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data</span></a></a><span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">],</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data</span></a></a><span class="p">[</span><span class="s2">&quot;inputs&quot;</span><span class="p">],</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data</span></a></a><span class="p">[</span><span class="s2">&quot;inputs2&quot;</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/helpers.html#experimental_experiment.helpers.string_type" title="experimental_experiment.helpers.string_type" class="sphx-glr-backref-module-experimental_experiment-helpers sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/helpers.html#experimental_experiment.helpers.string_type" title="experimental_experiment.helpers.string_type" class="sphx-glr-backref-module-experimental_experiment-helpers sphx-glr-backref-type-py-function"><span class="n">string_type</span></a></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">inputs</span></a></a><span class="p">,</span> <span class="n">with_shape</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>dict(input_ids:T7s2x3,attention_mask:T7s2x33,past_key_values:DynamicCache(key_cache=#2[T1s2x32x30x96,T1s2x32x30x96], value_cache=#2[T1s2x32x30x96,T1s2x32x30x96]))
</pre></div>
</div>
</section>
<section id="dynamic-shapes">
<h2>Dynamic Shapes<a class="headerlink" href="#dynamic-shapes" title="Link to this heading">¶</a></h2>
<p>We want to infer the dynamic shapes from the two sets of inputs we gave.
For that, we use a function to trace the execution of the model
including its submodules. It is going to execute the model twice
with the two sets of inputs and stores every intermediate input and output.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">diag</span> <span class="o">=</span> <span class="n">trace_execution_piece_by_piece</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">inputs</span></a></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">inputs2</span></a></a><span class="p">],</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[_trace_forward_execution]  __main__ - Phi3ForCausalLM
[_trace_forward_execution] .. model - Phi3Model
[_trace_forward_execution] .. lm_head - Linear
[trace_execution_piece_by_piece] run with dict(args:(),kwargs:dict(input_ids:T7s2x3,attention_mask:T7s2x33,past_key_values:DynamicCache(key_cache=#2[T1s2x32x30x96,T1s2x32x30x96], value_cache=#2[T1s2x32x30x96,T1s2x32x30x96])))
[__main__:Phi3ForCausalLM] &gt; **dict(input_ids:T7r2,attention_mask:T7r2,past_key_values:DynamicCache(key_cache=#2[T1r4,T1r4], value_cache=#2[T1r4,T1r4]))
[model:Phi3Model]   &gt; **dict(input_ids:T7r2,attention_mask:T7r2,position_ids:None,past_key_values:DynamicCache(key_cache=#2[T1r4,T1r4], value_cache=#2[T1r4,T1r4]),inputs_embeds:None,use_cache:None,output_attentions:bool,output_hidden_states:bool,return_dict:bool,cache_position:None)
[model:Phi3Model]   &lt; *dict(last_hidden_state:T1r3,past_key_values:DynamicCache(key_cache=#2[T1r4,T1r4], value_cache=#2[T1r4,T1r4]))
[lm_head:Linear]   &gt; T1r3
[lm_head:Linear]   &lt; T1r3
[__main__:Phi3ForCausalLM] &lt; *dict(logits:T1r3,past_key_values:DynamicCache(key_cache=#2[T1r4,T1r4], value_cache=#2[T1r4,T1r4]))
[trace_execution_piece_by_piece] run with dict(args:(),kwargs:dict(input_ids:T7s3x4,attention_mask:T7s3x35,past_key_values:DynamicCache(key_cache=#2[T1s3x32x31x96,T1s3x32x31x96], value_cache=#2[T1s3x32x31x96,T1s3x32x31x96])))
[__main__:Phi3ForCausalLM] &gt; **dict(input_ids:T7r2,attention_mask:T7r2,past_key_values:DynamicCache(key_cache=#2[T1r4,T1r4], value_cache=#2[T1r4,T1r4]))
[model:Phi3Model]   &gt; **dict(input_ids:T7r2,attention_mask:T7r2,position_ids:None,past_key_values:DynamicCache(key_cache=#2[T1r4,T1r4], value_cache=#2[T1r4,T1r4]),inputs_embeds:None,use_cache:None,output_attentions:bool,output_hidden_states:bool,return_dict:bool,cache_position:None)
[model:Phi3Model]   &lt; *dict(last_hidden_state:T1r3,past_key_values:DynamicCache(key_cache=#2[T1r4,T1r4], value_cache=#2[T1r4,T1r4]))
[lm_head:Linear]   &gt; T1r3
[lm_head:Linear]   &lt; T1r3
[__main__:Phi3ForCausalLM] &lt; *dict(logits:T1r3,past_key_values:DynamicCache(key_cache=#2[T1r4,T1r4], value_cache=#2[T1r4,T1r4]))
[trace_forward_execution] traced execution of model Phi3ForCausalLM
&gt;&gt;&gt; __main__: Phi3ForCausalLM
  &gt; ((),dict(input_ids:CT7s2x3[4664,31570:A17677.166666666668],attention_mask:CT7s2x33[1,1:A1.0],past_key_values:DynamicCache(key_cache=#2[CT1s2x32x30x96[-4.524319648742676,4.446798324584961:A0.00045197112875037246],CT1s2x32x30x96[-4.23585319519043,4.715499401092529:A-0.005312503596610355]], value_cache=#2[CT1s2x32x30x96[-4.324870586395264,4.5727949142456055:A-0.0008027056451969537],CT1s2x32x30x96[-4.677217960357666,5.006890296936035:A0.0019749061087091166]])))
  &gt; ((),dict(input_ids:CT7s3x4[608,30304:A20014.666666666668],attention_mask:CT7s3x35[1,1:A1.0],past_key_values:DynamicCache(key_cache=#2[CT1s3x32x31x96[-4.5164971351623535,4.401163578033447:A-0.0006134297668116055],CT1s3x32x31x96[-4.406899452209473,4.658656597137451:A-0.0018093928141991926]], value_cache=#2[CT1s3x32x31x96[-4.715044021606445,4.725687026977539:A0.0017272961305985642],CT1s3x32x31x96[-5.0299248695373535,5.066045761108398:A0.0021334321277751466]])))
    &gt;&gt;&gt; model: Phi3Model
      &gt; ((),dict(input_ids:CT7s2x3[4664,31570:A17677.166666666668],attention_mask:CT7s2x33[1,1:A1.0],position_ids:None,past_key_values:DynamicCache(key_cache=#2[CT1s2x32x30x96[-4.524319648742676,4.446798324584961:A0.00045197112875037246],CT1s2x32x30x96[-4.23585319519043,4.715499401092529:A-0.005312503596610355]], value_cache=#2[CT1s2x32x30x96[-4.324870586395264,4.5727949142456055:A-0.0008027056451969537],CT1s2x32x30x96[-4.677217960357666,5.006890296936035:A0.0019749061087091166]]),inputs_embeds:None,use_cache:None,output_attentions:bool=False,output_hidden_states:bool=False,return_dict:bool=True,cache_position:None))
      &gt; ((),dict(input_ids:CT7s3x4[608,30304:A20014.666666666668],attention_mask:CT7s3x35[1,1:A1.0],position_ids:None,past_key_values:DynamicCache(key_cache=#2[CT1s3x32x31x96[-4.5164971351623535,4.401163578033447:A-0.0006134297668116055],CT1s3x32x31x96[-4.406899452209473,4.658656597137451:A-0.0018093928141991926]], value_cache=#2[CT1s3x32x31x96[-4.715044021606445,4.725687026977539:A0.0017272961305985642],CT1s3x32x31x96[-5.0299248695373535,5.066045761108398:A0.0021334321277751466]]),inputs_embeds:None,use_cache:None,output_attentions:bool=False,output_hidden_states:bool=False,return_dict:bool=True,cache_position:None))
        &gt;&gt;&gt; embed_tokens: Embedding
          &gt; ((CT7s2x3[4664,31570:A17677.166666666668],),{})
          &gt; ((CT7s3x4[608,30304:A20014.666666666668],),{})
          &lt; (CT1s2x3x3072[-0.0765041932463646,0.07427593320608139:A4.3293902790490314e-05],)
          &lt; (CT1s3x4x3072[-0.07915466278791428,0.08391024172306061:A2.2362938498739677e-05],)
        &lt;&lt;&lt;
        &gt;&gt;&gt; layers[0]: Phi3DecoderLayer
          &gt; ((CT1s2x3x3072[-0.0765041932463646,0.07427593320608139:A4.3293902790490314e-05],),dict(attention_mask:CT1s2x1x3x33[-3.4028234663852886e+38,-0.0:A-1.0311586261773601e+37],position_ids:CT7s1x3[30,32:A31.0],past_key_value:DynamicCache(key_cache=#2[CT1s2x32x30x96[-4.524319648742676,4.446798324584961:A0.00045197112875037246],CT1s2x32x30x96[-4.23585319519043,4.715499401092529:A-0.005312503596610355]], value_cache=#2[CT1s2x32x30x96[-4.324870586395264,4.5727949142456055:A-0.0008027056451969537],CT1s2x32x30x96[-4.677217960357666,5.006890296936035:A0.0019749061087091166]]),output_attentions:bool=False,use_cache:bool=True,cache_position:CT7s3[30,32:A31.0],position_embeddings:(CT1s1x3x96[-1.1855769157409668,1.1902371644973755:A0.746652018013669],CT1s1x3x96[-1.1887905597686768,1.190193772315979:A0.1589894221542636])))
          &gt; ((CT1s3x4x3072[-0.07915466278791428,0.08391024172306061:A2.2362938498739677e-05],),dict(attention_mask:CT1s3x1x4x35[-3.4028234663852886e+38,-0.0:A-1.4583529141651237e+37],position_ids:CT7s1x4[31,34:A32.5],past_key_value:DynamicCache(key_cache=#2[CT1s3x32x31x96[-4.5164971351623535,4.401163578033447:A-0.0006134297668116055],CT1s3x32x31x96[-4.406899452209473,4.658656597137451:A-0.0018093928141991926]], value_cache=#2[CT1s3x32x31x96[-4.715044021606445,4.725687026977539:A0.0017272961305985642],CT1s3x32x31x96[-5.0299248695373535,5.066045761108398:A0.0021334321277751466]]),output_attentions:bool=False,use_cache:bool=True,cache_position:CT7s4[31,34:A32.5],position_embeddings:(CT1s1x4x96[-1.1855769157409668,1.190237045288086:A0.7129333875218435],CT1s1x4x96[-1.1719439029693604,1.1902378797531128:A0.18296290554159592])))
            &gt;&gt;&gt; self_attn: Phi3Attention
              &gt; ((),dict(hidden_states:CT1s2x3x3072[-3.8076090812683105,3.682769775390625:A0.00216633024901035],attention_mask:CT1s2x1x3x33[-3.4028234663852886e+38,-0.0:A-1.0311586261773601e+37],position_ids:CT7s1x3[30,32:A31.0],past_key_value:DynamicCache(key_cache=#2[CT1s2x32x30x96[-4.524319648742676,4.446798324584961:A0.00045197112875037246],CT1s2x32x30x96[-4.23585319519043,4.715499401092529:A-0.005312503596610355]], value_cache=#2[CT1s2x32x30x96[-4.324870586395264,4.5727949142456055:A-0.0008027056451969537],CT1s2x32x30x96[-4.677217960357666,5.006890296936035:A0.0019749061087091166]]),output_attentions:bool=False,use_cache:bool=True,cache_position:CT7s3[30,32:A31.0],position_embeddings:(CT1s1x3x96[-1.1855769157409668,1.1902371644973755:A0.746652018013669],CT1s1x3x96[-1.1887905597686768,1.190193772315979:A0.1589894221542636])))
              &gt; ((),dict(hidden_states:CT1s3x4x3072[-3.9569787979125977,4.13375186920166:A0.0011474127630010224],attention_mask:CT1s3x1x4x35[-3.4028234663852886e+38,-0.0:A-1.4583529141651237e+37],position_ids:CT7s1x4[31,34:A32.5],past_key_value:DynamicCache(key_cache=#2[CT1s3x32x31x96[-4.5164971351623535,4.401163578033447:A-0.0006134297668116055],CT1s3x32x31x96[-4.406899452209473,4.658656597137451:A-0.0018093928141991926]], value_cache=#2[CT1s3x32x31x96[-4.715044021606445,4.725687026977539:A0.0017272961305985642],CT1s3x32x31x96[-5.0299248695373535,5.066045761108398:A0.0021334321277751466]]),output_attentions:bool=False,use_cache:bool=True,cache_position:CT7s4[31,34:A32.5],position_embeddings:(CT1s1x4x96[-1.1855769157409668,1.190237045288086:A0.7129333875218435],CT1s1x4x96[-1.1719439029693604,1.1902378797531128:A0.18296290554159592])))
                &gt;&gt;&gt; o_proj: Linear
                  &gt; ((CT1s2x3x3072[-2.0857884883880615,2.227522850036621:A-0.00166854337468071],),{})
                  &gt; ((CT1s3x4x3072[-1.9925907850265503,2.740478515625:A-4.3969838686671224e-05],),{})
                  &lt; (CT1s2x3x3072[-1.7465921640396118,1.7467150688171387:A-0.00036754129455908295],)
                  &lt; (CT1s3x4x3072[-1.576282024383545,1.5121502876281738:A-0.0039008252983229064],)
                &lt;&lt;&lt;
                &gt;&gt;&gt; qkv_proj: Linear
                  &gt; ((CT1s2x3x3072[-3.8076090812683105,3.682769775390625:A0.00216633024901035],),{})
                  &gt; ((CT1s3x4x3072[-3.9569787979125977,4.13375186920166:A0.0011474127630010224],),{})
                  &lt; (CT1s2x3x9216[-4.55996561050415,4.785744667053223:A-0.0007797792564158752],)
                  &lt; (CT1s3x4x9216[-5.212952136993408,4.804689407348633:A0.003576188889704634],)
                &lt;&lt;&lt;
              &lt; (CT1s2x3x3072[-1.7465921640396118,1.7467150688171387:A-0.00036754129455908295],None)
              &lt; (CT1s3x4x3072[-1.576282024383545,1.5121502876281738:A-0.0039008252983229064],None)
            &lt;&lt;&lt;
            &gt;&gt;&gt; mlp: Phi3MLP
              &gt; ((CT1s2x3x3072[-3.766619920730591,3.8079004287719727:A-0.0007900578330600884],),{})
              &gt; ((CT1s3x4x3072[-4.20332670211792,4.075958251953125:A-0.010097015604570991],),{})
                &gt;&gt;&gt; gate_up_proj: Linear
                  &gt; ((CT1s2x3x3072[-3.766619920730591,3.8079004287719727:A-0.0007900578330600884],),{})
                  &gt; ((CT1s3x4x3072[-4.20332670211792,4.075958251953125:A-0.010097015604570991],),{})
                  &lt; (CT1s2x3x16384[-4.626908779144287,4.744266033172607:A0.0004144351753060012],)
                  &lt; (CT1s3x4x16384[-5.071014404296875,5.014136791229248:A0.002499560848283622],)
                &lt;&lt;&lt;
                &gt;&gt;&gt; down_proj: Linear
                  &gt; ((CT1s2x3x8192[-9.626221656799316,10.6359224319458:A-0.003712694137561807],),{})
                  &gt; ((CT1s3x4x8192[-10.604706764221191,13.27551555633545:A-0.0009531583248854041],),{})
                  &lt; (CT1s2x3x3072[-5.091585636138916,5.638833045959473:A0.013511776874464785],)
                  &lt; (CT1s3x4x3072[-5.19716215133667,5.227738857269287:A-0.003959400700043463],)
                &lt;&lt;&lt;
                &gt;&gt;&gt; activation_fn: SiLU
                  &gt; ((CT1s2x3x8192[-4.296870231628418,4.744266033172607:A-0.00018980784703141276],),{})
                  &gt; ((CT1s3x4x8192[-5.071014404296875,5.014136791229248:A-0.002123918648494557],),{})
                  &lt; (CT1s2x3x8192[-0.27846455574035645,4.70334005355835:A0.2433877349765435],)
                  &lt; (CT1s3x4x8192[-0.27846455574035645,4.981045722961426:A0.24466585338180846],)
                &lt;&lt;&lt;
              &lt; (CT1s2x3x3072[-5.091585636138916,5.638833045959473:A0.013511776874464785],)
              &lt; (CT1s3x4x3072[-5.19716215133667,5.227738857269287:A-0.003959400700043463],)
            &lt;&lt;&lt;
            &gt;&gt;&gt; input_layernorm: Phi3RMSNorm
              &gt; ((CT1s2x3x3072[-0.0765041932463646,0.07427593320608139:A4.3293902790490314e-05],),{})
              &gt; ((CT1s3x4x3072[-0.07915466278791428,0.08391024172306061:A2.2362938498739677e-05],),{})
              &lt; (CT1s2x3x3072[-3.8076090812683105,3.682769775390625:A0.00216633024901035],)
              &lt; (CT1s3x4x3072[-3.9569787979125977,4.13375186920166:A0.0011474127630010224],)
            &lt;&lt;&lt;
            &gt;&gt;&gt; post_attention_layernorm: Phi3RMSNorm
              &gt; ((CT1s2x3x3072[-1.716892957687378,1.7488868236541748:A-0.00032424742236179956],),{})
              &gt; ((CT1s3x4x3072[-1.5904587507247925,1.5101318359375:A-0.0038784623282745023],),{})
              &lt; (CT1s2x3x3072[-3.766619920730591,3.8079004287719727:A-0.0007900578330600884],)
              &lt; (CT1s3x4x3072[-4.20332670211792,4.075958251953125:A-0.010097015604570991],)
            &lt;&lt;&lt;
            &gt;&gt;&gt; resid_attn_dropout: Dropout
              &gt; ((CT1s2x3x3072[-1.7465921640396118,1.7467150688171387:A-0.00036754129455908295],),{})
              &gt; ((CT1s3x4x3072[-1.576282024383545,1.5121502876281738:A-0.0039008252983229064],),{})
              &lt; (CT1s2x3x3072[-1.7465921640396118,1.7467150688171387:A-0.00036754129455908295],)
              &lt; (CT1s3x4x3072[-1.576282024383545,1.5121502876281738:A-0.0039008252983229064],)
            &lt;&lt;&lt;
            &gt;&gt;&gt; resid_mlp_dropout: Dropout
              &gt; ((CT1s2x3x3072[-5.091585636138916,5.638833045959473:A0.013511776874464785],),{})
              &gt; ((CT1s3x4x3072[-5.19716215133667,5.227738857269287:A-0.003959400700043463],),{})
              &lt; (CT1s2x3x3072[-5.091585636138916,5.638833045959473:A0.013511776874464785],)
              &lt; (CT1s3x4x3072[-5.19716215133667,5.227738857269287:A-0.003959400700043463],)
            &lt;&lt;&lt;
          &lt; (CT1s2x3x3072[-5.3348307609558105,6.06136417388916:A0.013187529813725027],)
          &lt; (CT1s3x4x3072[-5.88392448425293,5.575860977172852:A-0.00783786298630831],)
        &lt;&lt;&lt;
        &gt;&gt;&gt; layers[1]: Phi3DecoderLayer
          &gt; ((CT1s2x3x3072[-5.3348307609558105,6.06136417388916:A0.013187529813725027],),dict(attention_mask:CT1s2x1x3x33[-3.4028234663852886e+38,-0.0:A-1.0311586261773601e+37],position_ids:CT7s1x3[30,32:A31.0],past_key_value:DynamicCache(key_cache=#2[CT1s2x32x33x96[-5.269703388214111,5.904300689697266:A-0.0008714742347480582],CT1s2x32x30x96[-4.23585319519043,4.715499401092529:A-0.005312503596610355]], value_cache=#2[CT1s2x32x33x96[-4.365392684936523,4.5727949142456055:A-0.0001598371759914454],CT1s2x32x30x96[-4.677217960357666,5.006890296936035:A0.0019749061087091166]]),output_attentions:bool=False,use_cache:bool=True,cache_position:CT7s3[30,32:A31.0],position_embeddings:(CT1s1x3x96[-1.1855769157409668,1.1902371644973755:A0.746652018013669],CT1s1x3x96[-1.1887905597686768,1.190193772315979:A0.1589894221542636])))
          &gt; ((CT1s3x4x3072[-5.88392448425293,5.575860977172852:A-0.00783786298630831],),dict(attention_mask:CT1s3x1x4x35[-3.4028234663852886e+38,-0.0:A-1.4583529141651237e+37],position_ids:CT7s1x4[31,34:A32.5],past_key_value:DynamicCache(key_cache=#2[CT1s3x32x35x96[-5.257526397705078,6.271761417388916:A5.3596344517194334e-05],CT1s3x32x31x96[-4.406899452209473,4.658656597137451:A-0.0018093928141991926]], value_cache=#2[CT1s3x32x35x96[-4.715044021606445,4.725687026977539:A0.0016024406523245105],CT1s3x32x31x96[-5.0299248695373535,5.066045761108398:A0.0021334321277751466]]),output_attentions:bool=False,use_cache:bool=True,cache_position:CT7s4[31,34:A32.5],position_embeddings:(CT1s1x4x96[-1.1855769157409668,1.190237045288086:A0.7129333875218435],CT1s1x4x96[-1.1719439029693604,1.1902378797531128:A0.18296290554159592])))
            &gt;&gt;&gt; self_attn: Phi3Attention
              &gt; ((),dict(hidden_states:CT1s2x3x3072[-3.71167254447937,4.351285934448242:A0.009349946014120251],attention_mask:CT1s2x1x3x33[-3.4028234663852886e+38,-0.0:A-1.0311586261773601e+37],position_ids:CT7s1x3[30,32:A31.0],past_key_value:DynamicCache(key_cache=#2[CT1s2x32x33x96[-5.269703388214111,5.904300689697266:A-0.0008714742347480582],CT1s2x32x30x96[-4.23585319519043,4.715499401092529:A-0.005312503596610355]], value_cache=#2[CT1s2x32x33x96[-4.365392684936523,4.5727949142456055:A-0.0001598371759914454],CT1s2x32x30x96[-4.677217960357666,5.006890296936035:A0.0019749061087091166]]),output_attentions:bool=False,use_cache:bool=True,cache_position:CT7s3[30,32:A31.0],position_embeddings:(CT1s1x3x96[-1.1855769157409668,1.1902371644973755:A0.746652018013669],CT1s1x3x96[-1.1887905597686768,1.190193772315979:A0.1589894221542636])))
              &gt; ((),dict(hidden_states:CT1s3x4x3072[-4.0989861488342285,3.8373234272003174:A-0.005813611555114445],attention_mask:CT1s3x1x4x35[-3.4028234663852886e+38,-0.0:A-1.4583529141651237e+37],position_ids:CT7s1x4[31,34:A32.5],past_key_value:DynamicCache(key_cache=#2[CT1s3x32x35x96[-5.257526397705078,6.271761417388916:A5.3596344517194334e-05],CT1s3x32x31x96[-4.406899452209473,4.658656597137451:A-0.0018093928141991926]], value_cache=#2[CT1s3x32x35x96[-4.715044021606445,4.725687026977539:A0.0016024406523245105],CT1s3x32x31x96[-5.0299248695373535,5.066045761108398:A0.0021334321277751466]]),output_attentions:bool=False,use_cache:bool=True,cache_position:CT7s4[31,34:A32.5],position_embeddings:(CT1s1x4x96[-1.1855769157409668,1.190237045288086:A0.7129333875218435],CT1s1x4x96[-1.1719439029693604,1.1902378797531128:A0.18296290554159592])))
                &gt;&gt;&gt; o_proj: Linear
                  &gt; ((CT1s2x3x3072[-2.0965793132781982,2.4613635540008545:A0.001581031349573831],),{})
                  &gt; ((CT1s3x4x3072[-2.2842745780944824,2.885471820831299:A-0.00010379927480992067],),{})
                  &lt; (CT1s2x3x3072[-1.727698802947998,1.9539368152618408:A-0.0024682869261406872],)
                  &lt; (CT1s3x4x3072[-1.7709965705871582,1.708268642425537:A0.0010327714551263195],)
                &lt;&lt;&lt;
                &gt;&gt;&gt; qkv_proj: Linear
                  &gt; ((CT1s2x3x3072[-3.71167254447937,4.351285934448242:A0.009349946014120251],),{})
                  &gt; ((CT1s3x4x3072[-4.0989861488342285,3.8373234272003174:A-0.005813611555114445],),{})
                  &lt; (CT1s2x3x9216[-4.554075717926025,4.405378818511963:A-0.004489510061266292],)
                  &lt; (CT1s3x4x9216[-4.208725929260254,5.463718891143799:A0.004831148010973047],)
                &lt;&lt;&lt;
              &lt; (CT1s2x3x3072[-1.727698802947998,1.9539368152618408:A-0.0024682869261406872],None)
              &lt; (CT1s3x4x3072[-1.7709965705871582,1.708268642425537:A0.0010327714551263195],None)
            &lt;&lt;&lt;
            &gt;&gt;&gt; mlp: Phi3MLP
              &gt; ((CT1s2x3x3072[-3.549666166305542,4.110150337219238:A0.007339953932229193],),{})
              &gt; ((CT1s3x4x3072[-4.205822467803955,4.059736251831055:A-0.004850264546526262],),{})
                &gt;&gt;&gt; gate_up_proj: Linear
                  &gt; ((CT1s2x3x3072[-3.549666166305542,4.110150337219238:A0.007339953932229193],),{})
                  &gt; ((CT1s3x4x3072[-4.205822467803955,4.059736251831055:A-0.004850264546526262],),{})
                  &lt; (CT1s2x3x16384[-4.71592903137207,4.544133186340332:A0.0010123075836598143],)
                  &lt; (CT1s3x4x16384[-5.153237819671631,5.296940803527832:A0.0010891516607924128],)
                &lt;&lt;&lt;
                &gt;&gt;&gt; down_proj: Linear
                  &gt; ((CT1s2x3x8192[-9.733989715576172,9.656818389892578:A-0.00035077506349431273],),{})
                  &gt; ((CT1s3x4x8192[-10.086795806884766,11.529891014099121:A0.004240172249181878],),{})
                  &lt; (CT1s2x3x3072[-5.305871963500977,5.178980827331543:A0.0036938989775308073],)
                  &lt; (CT1s3x4x3072[-6.050964832305908,5.4576826095581055:A0.0023353122698810897],)
                &lt;&lt;&lt;
                &gt;&gt;&gt; activation_fn: SiLU
                  &gt; ((CT1s2x3x8192[-4.71592903137207,4.544133186340332:A0.0006271271668936151],),{})
                  &gt; ((CT1s3x4x8192[-4.761664867401123,4.957876682281494:A-0.002479409858256195],),{})
                  &lt; (CT1s2x3x8192[-0.27846455574035645,4.496339797973633:A0.24618416685490122],)
                  &lt; (CT1s3x4x8192[-0.27846455574035645,4.923276424407959:A0.2438934481976652],)
                &lt;&lt;&lt;
              &lt; (CT1s2x3x3072[-5.305871963500977,5.178980827331543:A0.0036938989775308073],)
              &lt; (CT1s3x4x3072[-6.050964832305908,5.4576826095581055:A0.0023353122698810897],)
            &lt;&lt;&lt;
            &gt;&gt;&gt; input_layernorm: Phi3RMSNorm
              &gt; ((CT1s2x3x3072[-5.3348307609558105,6.06136417388916:A0.013187529813725027],),{})
              &gt; ((CT1s3x4x3072[-5.88392448425293,5.575860977172852:A-0.00783786298630831],),{})
              &lt; (CT1s2x3x3072[-3.71167254447937,4.351285934448242:A0.009349946014120251],)
              &lt; (CT1s3x4x3072[-4.0989861488342285,3.8373234272003174:A-0.005813611555114445],)
            &lt;&lt;&lt;
            &gt;&gt;&gt; post_attention_layernorm: Phi3RMSNorm
              &gt; ((CT1s2x3x3072[-5.136703968048096,5.932700157165527:A0.010719243169357165],),{})
              &gt; ((CT1s3x4x3072[-5.9217209815979,6.042370319366455:A-0.006805091526985052],),{})
              &lt; (CT1s2x3x3072[-3.549666166305542,4.110150337219238:A0.007339953932229193],)
              &lt; (CT1s3x4x3072[-4.205822467803955,4.059736251831055:A-0.004850264546526262],)
            &lt;&lt;&lt;
            &gt;&gt;&gt; resid_attn_dropout: Dropout
              &gt; ((CT1s2x3x3072[-1.727698802947998,1.9539368152618408:A-0.0024682869261406872],),{})
              &gt; ((CT1s3x4x3072[-1.7709965705871582,1.708268642425537:A0.0010327714551263195],),{})
              &lt; (CT1s2x3x3072[-1.727698802947998,1.9539368152618408:A-0.0024682869261406872],)
              &lt; (CT1s3x4x3072[-1.7709965705871582,1.708268642425537:A0.0010327714551263195],)
            &lt;&lt;&lt;
            &gt;&gt;&gt; resid_mlp_dropout: Dropout
              &gt; ((CT1s2x3x3072[-5.305871963500977,5.178980827331543:A0.0036938989775308073],),{})
              &gt; ((CT1s3x4x3072[-6.050964832305908,5.4576826095581055:A0.0023353122698810897],),{})
              &lt; (CT1s2x3x3072[-5.305871963500977,5.178980827331543:A0.0036938989775308073],)
              &lt; (CT1s3x4x3072[-6.050964832305908,5.4576826095581055:A0.0023353122698810897],)
            &lt;&lt;&lt;
          &lt; (CT1s2x3x3072[-8.349817276000977,9.60705280303955:A0.014413142231104657],)
          &lt; (CT1s3x4x3072[-7.1743621826171875,7.833809852600098:A-0.004469779496957926],)
        &lt;&lt;&lt;
        &gt;&gt;&gt; norm: Phi3RMSNorm
          &gt; ((CT1s2x3x3072[-8.349817276000977,9.60705280303955:A0.014413142231104657],),{})
          &gt; ((CT1s3x4x3072[-7.1743621826171875,7.833809852600098:A-0.004469779496957926],),{})
          &lt; (CT1s2x3x3072[-4.329084396362305,4.684192657470703:A0.0072901403956184335],)
          &lt; (CT1s3x4x3072[-3.6584055423736572,3.9267525672912598:A-0.002269768673042044],)
        &lt;&lt;&lt;
        &gt;&gt;&gt; rotary_emb: Phi3RotaryEmbedding
          &gt; ((CT1s2x3x3072[-0.0765041932463646,0.07427593320608139:A4.3293902790490314e-05],CT7s1x3[30,32:A31.0]),{})
          &gt; ((CT1s3x4x3072[-0.07915466278791428,0.08391024172306061:A2.2362938498739677e-05],CT7s1x4[31,34:A32.5]),{})
          &lt; (CT1s1x3x96[-1.1855769157409668,1.1902371644973755:A0.746652018013669],CT1s1x3x96[-1.1887905597686768,1.190193772315979:A0.1589894221542636])
          &lt; (CT1s1x4x96[-1.1855769157409668,1.190237045288086:A0.7129333875218435],CT1s1x4x96[-1.1719439029693604,1.1902378797531128:A0.18296290554159592])
        &lt;&lt;&lt;
      &lt; (dict(last_hidden_state:CT1s2x3x3072[-4.329084396362305,4.684192657470703:A0.0072901403956184335],past_key_values:DynamicCache(key_cache=#2[CT1s2x32x33x96[-5.269703388214111,5.904300689697266:A-0.0008714742347480582],CT1s2x32x33x96[-5.159628391265869,5.257333278656006:A-0.003930519807112116]], value_cache=#2[CT1s2x32x33x96[-4.365392684936523,4.5727949142456055:A-0.0001598371759914454],CT1s2x32x33x96[-4.677217960357666,5.006890296936035:A0.0021848251059774755]])),)
      &lt; (dict(last_hidden_state:CT1s3x4x3072[-3.6584055423736572,3.9267525672912598:A-0.002269768673042044],past_key_values:DynamicCache(key_cache=#2[CT1s3x32x35x96[-5.257526397705078,6.271761417388916:A5.3596344517194334e-05],CT1s3x32x35x96[-5.084636211395264,4.978662967681885:A-0.002626009440932474]], value_cache=#2[CT1s3x32x35x96[-4.715044021606445,4.725687026977539:A0.0016024406523245105],CT1s3x32x35x96[-5.0299248695373535,5.066045761108398:A0.001982277264531371]])),)
    &lt;&lt;&lt;
    &gt;&gt;&gt; lm_head: Linear
      &gt; ((CT1s2x3x3072[-4.329084396362305,4.684192657470703:A0.0072901403956184335],),{})
      &gt; ((CT1s3x4x3072[-3.6584055423736572,3.9267525672912598:A-0.002269768673042044],),{})
      &lt; (CT1s2x3x32064[-4.806385040283203,4.561767101287842:A-7.084682205524456e-05],)
      &lt; (CT1s3x4x32064[-4.770487308502197,5.134904384613037:A0.0011637009553284994],)
    &lt;&lt;&lt;
  &lt; (dict(logits:CT1s2x3x32064[-4.806385040283203,4.561767101287842:A-7.084682205524456e-05],past_key_values:DynamicCache(key_cache=#2[CT1s2x32x33x96[-5.269703388214111,5.904300689697266:A-0.0008714742347480582],CT1s2x32x33x96[-5.159628391265869,5.257333278656006:A-0.003930519807112116]], value_cache=#2[CT1s2x32x33x96[-4.365392684936523,4.5727949142456055:A-0.0001598371759914454],CT1s2x32x33x96[-4.677217960357666,5.006890296936035:A0.0021848251059774755]])),)
  &lt; (dict(logits:CT1s3x4x32064[-4.770487308502197,5.134904384613037:A0.0011637009553284994],past_key_values:DynamicCache(key_cache=#2[CT1s3x32x35x96[-5.257526397705078,6.271761417388916:A5.3596344517194334e-05],CT1s3x32x35x96[-5.084636211395264,4.978662967681885:A-0.002626009440932474]], value_cache=#2[CT1s3x32x35x96[-4.715044021606445,4.725687026977539:A0.0016024406523245105],CT1s3x32x35x96[-5.0299248695373535,5.066045761108398:A0.001982277264531371]])),)
&lt;&lt;&lt;
[_untrace_forward_execution]  __main__ - Phi3ForCausalLM
[_untrace_forward_execution] .. model - Phi3Model
[_untrace_forward_execution] .... embed_tokens - Embedding
[_untrace_forward_execution] .... layers[0] - Phi3DecoderLayer
[_untrace_forward_execution] ...... self_attn - Phi3Attention
[_untrace_forward_execution] ........ o_proj - Linear
[_untrace_forward_execution] ........ qkv_proj - Linear
[_untrace_forward_execution] ...... mlp - Phi3MLP
[_untrace_forward_execution] ........ gate_up_proj - Linear
[_untrace_forward_execution] ........ down_proj - Linear
[_untrace_forward_execution] ........ activation_fn - SiLU
[_untrace_forward_execution] ...... input_layernorm - Phi3RMSNorm
[_untrace_forward_execution] ...... post_attention_layernorm - Phi3RMSNorm
[_untrace_forward_execution] ...... resid_attn_dropout - Dropout
[_untrace_forward_execution] ...... resid_mlp_dropout - Dropout
[_untrace_forward_execution] .... layers[1] - Phi3DecoderLayer
[_untrace_forward_execution] ...... self_attn - Phi3Attention
[_untrace_forward_execution] ........ o_proj - Linear
[_untrace_forward_execution] ........ qkv_proj - Linear
[_untrace_forward_execution] ...... mlp - Phi3MLP
[_untrace_forward_execution] ........ gate_up_proj - Linear
[_untrace_forward_execution] ........ down_proj - Linear
[_untrace_forward_execution] ........ activation_fn - SiLU
[_untrace_forward_execution] ...... input_layernorm - Phi3RMSNorm
[_untrace_forward_execution] ...... post_attention_layernorm - Phi3RMSNorm
[_untrace_forward_execution] ...... resid_attn_dropout - Dropout
[_untrace_forward_execution] ...... resid_mlp_dropout - Dropout
[_untrace_forward_execution] .... norm - Phi3RMSNorm
[_untrace_forward_execution] .... rotary_emb - Phi3RotaryEmbedding
[_untrace_forward_execution] .. lm_head - Linear
</pre></div>
</div>
<p>Now we keep in memory every input/output for the submodules,
we can guess the dynamic shapes for every of them.
The final ones:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dynamic_shapes</span></a></a> <span class="o">=</span> <span class="n">diag</span><span class="o">.</span><span class="n">guess_dynamic_shapes</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The dynamic shapes are:&quot;</span><span class="p">)</span>
<a href="https://docs.python.org/3/library/pprint.html#pprint.pprint" title="pprint.pprint" class="sphx-glr-backref-module-pprint sphx-glr-backref-type-py-function"><a href="https://docs.python.org/3/library/pprint.html#pprint.pprint" title="pprint.pprint" class="sphx-glr-backref-module-pprint sphx-glr-backref-type-py-function"><span class="n">pprint</span><span class="o">.</span><span class="n">pprint</span></a></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dynamic_shapes</span></a></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>The dynamic shapes are:
((),
 {&#39;attention_mask&#39;: {0: &lt;_DimHint.DYNAMIC: 3&gt;, 1: &lt;_DimHint.DYNAMIC: 3&gt;},
  &#39;input_ids&#39;: {0: &lt;_DimHint.DYNAMIC: 3&gt;, 1: &lt;_DimHint.DYNAMIC: 3&gt;},
  &#39;past_key_values&#39;: [[{0: &lt;_DimHint.DYNAMIC: 3&gt;, 2: &lt;_DimHint.DYNAMIC: 3&gt;},
                       {0: &lt;_DimHint.DYNAMIC: 3&gt;, 2: &lt;_DimHint.DYNAMIC: 3&gt;}],
                      [{0: &lt;_DimHint.DYNAMIC: 3&gt;, 2: &lt;_DimHint.DYNAMIC: 3&gt;},
                       {0: &lt;_DimHint.DYNAMIC: 3&gt;, 2: &lt;_DimHint.DYNAMIC: 3&gt;}]]})
</pre></div>
</div>
<p>And all the dynamic shapes all along the traced submodules.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span>
    <span class="n">diag</span><span class="o">.</span><span class="n">pretty_text</span><span class="p">(</span>
        <span class="n">with_dynamic_shape</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">with_shape</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">with_min_max</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">with_device</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">with_inputs</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;&lt;_DimHint.DYNAMIC: 3&gt;&quot;</span><span class="p">,</span> <span class="s2">&quot;DYN&quot;</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&gt;&gt;&gt; __main__: Phi3ForCausalLM
  DS=((), {&#39;attention_mask&#39;: {0: DYN, 1: DYN}, &#39;input_ids&#39;: {0: DYN, 1: DYN}, &#39;past_key_values&#39;: [[{0: DYN, 2: DYN}, {0: DYN, 2: DYN}], [{0: DYN, 2: DYN}, {0: DYN, 2: DYN}]]})
    &gt;&gt;&gt; model: Phi3Model
      DS=((), {&#39;attention_mask&#39;: {0: DYN, 1: DYN}, &#39;cache_position&#39;: None, &#39;input_ids&#39;: {0: DYN, 1: DYN}, &#39;inputs_embeds&#39;: None, &#39;output_attentions&#39;: None, &#39;output_hidden_states&#39;: None, &#39;past_key_values&#39;: [[{0: DYN, 2: DYN}, {0: DYN, 2: DYN}], [{0: DYN, 2: DYN}, {0: DYN, 2: DYN}]], &#39;position_ids&#39;: None, &#39;return_dict&#39;: None, &#39;use_cache&#39;: None})
        &gt;&gt;&gt; embed_tokens: Embedding: DS=(({0: DYN, 1: DYN},), {}) &lt;&lt;&lt;
        &gt;&gt;&gt; layers[0]: Phi3DecoderLayer
          DS=(({0: DYN, 1: DYN},), {&#39;attention_mask&#39;: {0: DYN, 2: DYN, 3: DYN}, &#39;cache_position&#39;: {0: DYN}, &#39;output_attentions&#39;: None, &#39;past_key_value&#39;: [[{0: DYN, 2: DYN}, {0: DYN, 2: DYN}], [{0: DYN, 2: DYN}, {0: DYN, 2: DYN}]], &#39;position_embeddings&#39;: ({1: DYN}, {1: DYN}), &#39;position_ids&#39;: {1: DYN}, &#39;use_cache&#39;: None})
            &gt;&gt;&gt; self_attn: Phi3Attention
              DS=((), {&#39;attention_mask&#39;: {0: DYN, 2: DYN, 3: DYN}, &#39;cache_position&#39;: {0: DYN}, &#39;hidden_states&#39;: {0: DYN, 1: DYN}, &#39;output_attentions&#39;: None, &#39;past_key_value&#39;: [[{0: DYN, 2: DYN}, {0: DYN, 2: DYN}], [{0: DYN, 2: DYN}, {0: DYN, 2: DYN}]], &#39;position_embeddings&#39;: ({1: DYN}, {1: DYN}), &#39;position_ids&#39;: {1: DYN}, &#39;use_cache&#39;: None})
                &gt;&gt;&gt; o_proj: Linear: DS=(({0: DYN, 1: DYN},), {}) &lt;&lt;&lt;
                &gt;&gt;&gt; qkv_proj: Linear: DS=(({0: DYN, 1: DYN},), {}) &lt;&lt;&lt;
            &lt;&lt;&lt;
            &gt;&gt;&gt; mlp: Phi3MLP
              DS=(({0: DYN, 1: DYN},), {})
                &gt;&gt;&gt; gate_up_proj: Linear: DS=(({0: DYN, 1: DYN},), {}) &lt;&lt;&lt;
                &gt;&gt;&gt; down_proj: Linear: DS=(({0: DYN, 1: DYN},), {}) &lt;&lt;&lt;
                &gt;&gt;&gt; activation_fn: SiLU: DS=(({0: DYN, 1: DYN},), {}) &lt;&lt;&lt;
            &lt;&lt;&lt;
            &gt;&gt;&gt; input_layernorm: Phi3RMSNorm: DS=(({0: DYN, 1: DYN},), {}) &lt;&lt;&lt;
            &gt;&gt;&gt; post_attention_layernorm: Phi3RMSNorm: DS=(({0: DYN, 1: DYN},), {}) &lt;&lt;&lt;
            &gt;&gt;&gt; resid_attn_dropout: Dropout: DS=(({0: DYN, 1: DYN},), {}) &lt;&lt;&lt;
            &gt;&gt;&gt; resid_mlp_dropout: Dropout: DS=(({0: DYN, 1: DYN},), {}) &lt;&lt;&lt;
        &lt;&lt;&lt;
        &gt;&gt;&gt; layers[1]: Phi3DecoderLayer
          DS=(({0: DYN, 1: DYN},), {&#39;attention_mask&#39;: {0: DYN, 2: DYN, 3: DYN}, &#39;cache_position&#39;: {0: DYN}, &#39;output_attentions&#39;: None, &#39;past_key_value&#39;: [[{0: DYN, 2: DYN}, {0: DYN, 2: DYN}], [{0: DYN, 2: DYN}, {0: DYN, 2: DYN}]], &#39;position_embeddings&#39;: ({1: DYN}, {1: DYN}), &#39;position_ids&#39;: {1: DYN}, &#39;use_cache&#39;: None})
            &gt;&gt;&gt; self_attn: Phi3Attention
              DS=((), {&#39;attention_mask&#39;: {0: DYN, 2: DYN, 3: DYN}, &#39;cache_position&#39;: {0: DYN}, &#39;hidden_states&#39;: {0: DYN, 1: DYN}, &#39;output_attentions&#39;: None, &#39;past_key_value&#39;: [[{0: DYN, 2: DYN}, {0: DYN, 2: DYN}], [{0: DYN, 2: DYN}, {0: DYN, 2: DYN}]], &#39;position_embeddings&#39;: ({1: DYN}, {1: DYN}), &#39;position_ids&#39;: {1: DYN}, &#39;use_cache&#39;: None})
                &gt;&gt;&gt; o_proj: Linear: DS=(({0: DYN, 1: DYN},), {}) &lt;&lt;&lt;
                &gt;&gt;&gt; qkv_proj: Linear: DS=(({0: DYN, 1: DYN},), {}) &lt;&lt;&lt;
            &lt;&lt;&lt;
            &gt;&gt;&gt; mlp: Phi3MLP
              DS=(({0: DYN, 1: DYN},), {})
                &gt;&gt;&gt; gate_up_proj: Linear: DS=(({0: DYN, 1: DYN},), {}) &lt;&lt;&lt;
                &gt;&gt;&gt; down_proj: Linear: DS=(({0: DYN, 1: DYN},), {}) &lt;&lt;&lt;
                &gt;&gt;&gt; activation_fn: SiLU: DS=(({0: DYN, 1: DYN},), {}) &lt;&lt;&lt;
            &lt;&lt;&lt;
            &gt;&gt;&gt; input_layernorm: Phi3RMSNorm: DS=(({0: DYN, 1: DYN},), {}) &lt;&lt;&lt;
            &gt;&gt;&gt; post_attention_layernorm: Phi3RMSNorm: DS=(({0: DYN, 1: DYN},), {}) &lt;&lt;&lt;
            &gt;&gt;&gt; resid_attn_dropout: Dropout: DS=(({0: DYN, 1: DYN},), {}) &lt;&lt;&lt;
            &gt;&gt;&gt; resid_mlp_dropout: Dropout: DS=(({0: DYN, 1: DYN},), {}) &lt;&lt;&lt;
        &lt;&lt;&lt;
        &gt;&gt;&gt; norm: Phi3RMSNorm: DS=(({0: DYN, 1: DYN},), {}) &lt;&lt;&lt;
        &gt;&gt;&gt; rotary_emb: Phi3RotaryEmbedding: DS=(({0: DYN, 1: DYN}, {1: DYN}), {}) &lt;&lt;&lt;
    &lt;&lt;&lt;
    &gt;&gt;&gt; lm_head: Linear: DS=(({0: DYN, 1: DYN},), {}) &lt;&lt;&lt;
&lt;&lt;&lt;
</pre></div>
</div>
</section>
<section id="evaluate-the-export">
<h2>Evaluate the export<a class="headerlink" href="#evaluate-the-export" title="Link to this heading">¶</a></h2>
<p>In many cases, the export (to <a class="reference external" href="https://pytorch.org/docs/main/fx.html#torch.fx.Graph" title="(in PyTorch vmain (2.7.0a0+git6b41f31 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.fx.Graph</span></code></a>, to ONNX)
does not work on the first try. We need a way to understand
how much the model can be exported. It can be used to evaluate
the how much code needs to be rewritten or patched to be exportable.
The verbosity can be increase to show dynamic shapes, results
of the discrepancies.
Let’s display the module and its submodule first.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span>
    <span class="n">diag</span><span class="o">.</span><span class="n">pretty_text</span><span class="p">(</span>
        <span class="n">with_dynamic_shape</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">with_shape</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">with_min_max</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">with_device</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">with_inputs</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&gt;&gt;&gt; __main__: Phi3ForCausalLM
    &gt;&gt;&gt; model: Phi3Model
        &gt;&gt;&gt; embed_tokens: Embedding &lt;&lt;&lt;
        &gt;&gt;&gt; layers[0]: Phi3DecoderLayer
            &gt;&gt;&gt; self_attn: Phi3Attention
                &gt;&gt;&gt; o_proj: Linear &lt;&lt;&lt;
                &gt;&gt;&gt; qkv_proj: Linear &lt;&lt;&lt;
            &lt;&lt;&lt;
            &gt;&gt;&gt; mlp: Phi3MLP
                &gt;&gt;&gt; gate_up_proj: Linear &lt;&lt;&lt;
                &gt;&gt;&gt; down_proj: Linear &lt;&lt;&lt;
                &gt;&gt;&gt; activation_fn: SiLU &lt;&lt;&lt;
            &lt;&lt;&lt;
            &gt;&gt;&gt; input_layernorm: Phi3RMSNorm &lt;&lt;&lt;
            &gt;&gt;&gt; post_attention_layernorm: Phi3RMSNorm &lt;&lt;&lt;
            &gt;&gt;&gt; resid_attn_dropout: Dropout &lt;&lt;&lt;
            &gt;&gt;&gt; resid_mlp_dropout: Dropout &lt;&lt;&lt;
        &lt;&lt;&lt;
        &gt;&gt;&gt; layers[1]: Phi3DecoderLayer
            &gt;&gt;&gt; self_attn: Phi3Attention
                &gt;&gt;&gt; o_proj: Linear &lt;&lt;&lt;
                &gt;&gt;&gt; qkv_proj: Linear &lt;&lt;&lt;
            &lt;&lt;&lt;
            &gt;&gt;&gt; mlp: Phi3MLP
                &gt;&gt;&gt; gate_up_proj: Linear &lt;&lt;&lt;
                &gt;&gt;&gt; down_proj: Linear &lt;&lt;&lt;
                &gt;&gt;&gt; activation_fn: SiLU &lt;&lt;&lt;
            &lt;&lt;&lt;
            &gt;&gt;&gt; input_layernorm: Phi3RMSNorm &lt;&lt;&lt;
            &gt;&gt;&gt; post_attention_layernorm: Phi3RMSNorm &lt;&lt;&lt;
            &gt;&gt;&gt; resid_attn_dropout: Dropout &lt;&lt;&lt;
            &gt;&gt;&gt; resid_mlp_dropout: Dropout &lt;&lt;&lt;
        &lt;&lt;&lt;
        &gt;&gt;&gt; norm: Phi3RMSNorm &lt;&lt;&lt;
        &gt;&gt;&gt; rotary_emb: Phi3RotaryEmbedding &lt;&lt;&lt;
    &lt;&lt;&lt;
    &gt;&gt;&gt; lm_head: Linear &lt;&lt;&lt;
&lt;&lt;&lt;
</pre></div>
</div>
<p>The we try to export to see the submodule failing the whole model.
We can pickle the failing model and restore it to speedup
the refactoring to make it work.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;----------------------&quot;</span><span class="p">)</span>
<span class="n">ep</span> <span class="o">=</span> <span class="n">diag</span><span class="o">.</span><span class="n">try_export</span><span class="p">(</span>
    <span class="n">exporter</span><span class="o">=</span><span class="s2">&quot;fx&quot;</span><span class="p">,</span>
    <span class="n">use_dynamic_shapes</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">exporter_kwargs</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;success: </span><span class="si">{</span><span class="n">ep</span><span class="o">.</span><span class="n">status</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">diag</span><span class="o">.</span><span class="n">get_export_report</span><span class="p">())</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>----------------------

[try_export-FX]  __main__ - Phi3ForCausalLM --- FAIL, step=EXPORT, reason=Cannot associate shape [[{0: DYN, 2: DYN}, {0: DYN, 2: DYN}], [{0: DYN, 2: DYN}, {0: DYN, 2: DYN}]] specified at `dynamic_shapes[&#39;past_key_values&#39;]` to non-tensor type &lt;class &#39;transformers.cache_utils.DynamicCache&#39;&gt; at `inputs[&#39;past_key_values&#39;]` (expected None)
[try_export-FX] .. model - Phi3Model --- FAIL, step=EXPORT, reason=Cannot associate shape [[{0: DYN, 2: DYN}, {0: DYN, 2: DYN}], [{0: DYN, 2: DYN}, {0: DYN, 2: DYN}]] specified at `dynamic_shapes[&#39;past_key_values&#39;]` to non-tensor type &lt;class &#39;transformers.cache_utils.DynamicCache&#39;&gt; at `inputs[&#39;past_key_values&#39;]` (expected None)
[try_export-FX] .... embed_tokens - Embedding --- OK
[try_export-FX] .... layers[0] - Phi3DecoderLayer --- FAIL, step=EXPORT, reason=Cannot associate shape [[{0: DYN, 2: DYN}, {0: DYN, 2: DYN}], [{0: DYN, 2: DYN}, {0: DYN, 2: DYN}]] specified at `dynamic_shapes[&#39;past_key_value&#39;]` to non-tensor type &lt;class &#39;transformers.cache_utils.DynamicCache&#39;&gt; at `inputs[&#39;past_key_value&#39;]` (expected None)
[try_export-FX] ...... self_attn - Phi3Attention --- FAIL, step=EXPORT, reason=Cannot associate shape [[{0: DYN, 2: DYN}, {0: DYN, 2: DYN}], [{0: DYN, 2: DYN}, {0: DYN, 2: DYN}]] specified at `dynamic_shapes[&#39;past_key_value&#39;]` to non-tensor type &lt;class &#39;transformers.cache_utils.DynamicCache&#39;&gt; at `inputs[&#39;past_key_value&#39;]` (expected None)
[try_export-FX] ........ o_proj - Linear --- OK
[try_export-FX] ........ qkv_proj - Linear --- OK
[try_export-FX] ...... mlp - Phi3MLP --- OK
[try_export-FX] ...... input_layernorm - Phi3RMSNorm --- OK
[try_export-FX] ...... post_attention_layernorm - Phi3RMSNorm --- OK
[try_export-FX] ...... resid_attn_dropout - Dropout --- OK
[try_export-FX] ...... resid_mlp_dropout - Dropout --- OK
[try_export-FX] .... layers[1] - Phi3DecoderLayer --- FAIL, step=EXPORT, reason=Cannot associate shape [[{0: DYN, 2: DYN}, {0: DYN, 2: DYN}], [{0: DYN, 2: DYN}, {0: DYN, 2: DYN}]] specified at `dynamic_shapes[&#39;past_key_value&#39;]` to non-tensor type &lt;class &#39;transformers.cache_utils.DynamicCache&#39;&gt; at `inputs[&#39;past_key_value&#39;]` (expected None)
[try_export-FX] ...... self_attn - Phi3Attention --- FAIL, step=EXPORT, reason=Cannot associate shape [[{0: DYN, 2: DYN}, {0: DYN, 2: DYN}], [{0: DYN, 2: DYN}, {0: DYN, 2: DYN}]] specified at `dynamic_shapes[&#39;past_key_value&#39;]` to non-tensor type &lt;class &#39;transformers.cache_utils.DynamicCache&#39;&gt; at `inputs[&#39;past_key_value&#39;]` (expected None)
[try_export-FX] ........ o_proj - Linear --- OK
[try_export-FX] ........ qkv_proj - Linear --- OK
[try_export-FX] ...... mlp - Phi3MLP --- OK
[try_export-FX] ...... input_layernorm - Phi3RMSNorm --- OK
[try_export-FX] ...... post_attention_layernorm - Phi3RMSNorm --- OK
[try_export-FX] ...... resid_attn_dropout - Dropout --- OK
[try_export-FX] ...... resid_mlp_dropout - Dropout --- OK
[try_export-FX] .... norm - Phi3RMSNorm --- OK
[try_export-FX] .... rotary_emb - Phi3RotaryEmbedding --- FAIL, step=EXPORT, reason=Could not guard on data-dependent expression Eq(u0, 1) (unhinted: Eq(u0, 1)).  (Size-like symbols: none)
[try_export-FX] .... rotary_emb - Phi3RotaryEmbedding --- FAIL
[try_export-FX] .. lm_head - Linear --- OK
success: 2
__main__                         Phi3ForCausalLM       FAIL -- step=EXPORT, reason=&#39;Cannot associate shape [[{0: D...&#39;
..model                          Phi3Model             FAIL -- step=EXPORT, reason=&#39;Cannot associate shape [[{0: D...&#39;
....embed_tokens                 Embedding             OK -- ExportedProgram
....layers[0]                    Phi3DecoderLayer      FAIL -- step=EXPORT, reason=&#39;Cannot associate shape [[{0: D...&#39;
......self_attn                  Phi3Attention         FAIL -- step=EXPORT, reason=&#39;Cannot associate shape [[{0: D...&#39;
........o_proj                   Linear                OK -- ExportedProgram
........qkv_proj                 Linear                OK -- ExportedProgram
......mlp                        Phi3MLP               OK -- ExportedProgram
........gate_up_proj             Linear                OK as part of its owner
........down_proj                Linear                OK as part of its owner
........activation_fn            SiLU                  OK as part of its owner
......input_layernorm            Phi3RMSNorm           OK -- ExportedProgram
......post_attention_layernorm   Phi3RMSNorm           OK -- ExportedProgram
......resid_attn_dropout         Dropout               OK -- ExportedProgram
......resid_mlp_dropout          Dropout               OK -- ExportedProgram
....layers[1]                    Phi3DecoderLayer      FAIL -- step=EXPORT, reason=&#39;Cannot associate shape [[{0: D...&#39;
......self_attn                  Phi3Attention         FAIL -- step=EXPORT, reason=&#39;Cannot associate shape [[{0: D...&#39;
........o_proj                   Linear                OK -- ExportedProgram
........qkv_proj                 Linear                OK -- ExportedProgram
......mlp                        Phi3MLP               OK -- ExportedProgram
........gate_up_proj             Linear                OK as part of its owner
........down_proj                Linear                OK as part of its owner
........activation_fn            SiLU                  OK as part of its owner
......input_layernorm            Phi3RMSNorm           OK -- ExportedProgram
......post_attention_layernorm   Phi3RMSNorm           OK -- ExportedProgram
......resid_attn_dropout         Dropout               OK -- ExportedProgram
......resid_mlp_dropout          Dropout               OK -- ExportedProgram
....norm                         Phi3RMSNorm           OK -- ExportedProgram
....rotary_emb                   Phi3RotaryEmbedding   FAIL -- step=EXPORT, reason=&#39;Could not guard on data-depend...&#39;
..lm_head                        Linear                OK -- ExportedProgram
</pre></div>
</div>
</section>
<section id="replace-the-failing-module-by-a-custom-op">
<h2>Replace the failing module by a custom op<a class="headerlink" href="#replace-the-failing-module-by-a-custom-op" title="Link to this heading">¶</a></h2>
<p>The main module is not exportable because one piece cannot be exported.
But maybe if we assume it works, maybe everything else is working.
So let’s try to replace this class by a custom op.
This will be something for another example.</p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (0 minutes 9.513 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-recipes-plot-exporter-exporter-phi35-piece-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/6aa9aa07e36ac1aa1643da0bf3e38f0d/plot_exporter_exporter_phi35_piece.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_exporter_exporter_phi35_piece.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/267efdcf585b83af5aa72b6b95817131/plot_exporter_exporter_phi35_piece.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_exporter_exporter_phi35_piece.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../_downloads/1b8e64221afbb8509ca0eff85282e344/plot_exporter_exporter_phi35_piece.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">plot_exporter_exporter_phi35_piece.zip</span></code></a></p>
</div>
</div>
<p class="rubric">Related examples</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Tries torch._export.tools.report_exportability."><img alt="" src="../_images/sphx_glr_plot_exporter_exporter_reportibility_thumb.png" />
<p><a class="reference internal" href="plot_exporter_exporter_reportibility.html#sphx-glr-auto-recipes-plot-exporter-exporter-reportibility-py"><span class="std std-ref">Export Phi-3.5-mini-instruct with report_exportability</span></a></p>
  <div class="sphx-glr-thumbnail-title">Export Phi-3.5-mini-instruct with report_exportability</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Tries torch.export._draft_export.draft_export."><img alt="" src="../_images/sphx_glr_plot_exporter_exporter_draft_mode_thumb.png" />
<p><a class="reference internal" href="plot_exporter_exporter_draft_mode.html#sphx-glr-auto-recipes-plot-exporter-exporter-draft-mode-py"><span class="std std-ref">Export Phi-3.5-mini-instruct with draft_export</span></a></p>
  <div class="sphx-glr-thumbnail-title">Export Phi-3.5-mini-instruct with draft_export</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Exports model Phi-2. We use a dummy model. The main difficulty is to set the dynamic shapes properly."><img alt="" src="../_images/sphx_glr_plot_exporter_recipes_oe_phi2_thumb.png" />
<p><a class="reference internal" href="plot_exporter_recipes_oe_phi2.html#sphx-glr-auto-recipes-plot-exporter-recipes-oe-phi2-py"><span class="std std-ref">torch.onnx.export and Phi-2</span></a></p>
  <div class="sphx-glr-thumbnail-title">torch.onnx.export and Phi-2</div>
</div></div><p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="plot_exporter_exporter_draft_mode.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Export Phi-3.5-mini-instruct with draft_export</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="plot_exporter_exporter_inputs.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Do no use Module as inputs!</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2023-2024
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Export Phi-3.5-mini-instruct piece by piece</a><ul>
<li><a class="reference internal" href="#model">Model</a></li>
<li><a class="reference internal" href="#dynamic-shapes">Dynamic Shapes</a></li>
<li><a class="reference internal" href="#evaluate-the-export">Evaluate the export</a></li>
<li><a class="reference internal" href="#replace-the-failing-module-by-a-custom-op">Replace the failing module by a custom op</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../_static/documentation_options.js?v=a1637f0b"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/furo.js?v=5fa4622c"></script>
    </body>
</html>