<!doctype html>
<html class="no-js" lang="en" data-content_root="../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="Pattern Optimizer" href="optimizer.html" /><link rel="prev" title="Design" href="index.html" />

    <!-- Generated with Sphinx 7.2.6 and Furo 2024.08.06 -->
        <title>Custom Exporter - experimental-experiment 0.1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=354aac6f" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css?v=eafc0fe6" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=302659d7" />
    
    


<style>
  body {
    --color-code-background: #eeffcc;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">experimental-experiment 0.1.0 documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="../_static/logo.png" alt="Logo"/>
  </div>
  
  <span class="sidebar-brand-text">experimental-experiment 0.1.0 documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Contents</span></p>
<ul class="current">
<li class="toctree-l1 has-children"><a class="reference internal" href="../tutorial/index.html">Tutorial</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of Tutorial</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../tutorial/pytorch.html">pytorch and onnx</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of pytorch and onnx</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_linreg_101.html">101: Linear Regression and export to ONNX</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_custom_backend_101.html">101: A custom backend for torch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_optimize_101.html">101: Graph Optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_convolutation_matmul_102.html">102: Convolution and Matrix Multiplication</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_llama_bench_102.html">102: Measure LLAMA speed</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_export_201.html">201: Evaluate different ways to export a torch model to ONNX</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_dort_201.html">201: Evaluate DORT</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_aot_201.html">201: Evaluate DORT Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_llama_diff_export_301.html">301: Compares LLAMA exporters</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_llama_diff_dort_301.html">301: Compares LLAMA exporters for onnxrt backend</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../tutorial/onnx.html">onnx</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of onnx</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_profile_existing_onnx_101.html">101: Profile an existing model with onnxruntime</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../tutorial/errors.html">Frequent Exceptions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorial/docker.html">Start from a docker</a></li>
</ul>
</li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="index.html">Design</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of Design</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2 current current-page"><a class="current reference internal" href="#">Custom Exporter</a></li>
<li class="toctree-l2"><a class="reference internal" href="optimizer.html">Pattern Optimizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="backends.html">Dynamo Backends</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api/index.html">API</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of API</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../api/gradient.html">gradient</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/reference.html">reference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/graph_builder.html">graph_builder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/torch_model_container.html">TorchModelContainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/graph_builder_pattern.html">graph_builder_optim</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/graph_builder_patterns.html">Optimization Patterns</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/order_optimization.html">order_optim</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/interpreter.html">interpreter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/onnx_export.html">onnx_export</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/aten_function.html">aten_functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/aten_method.html">aten_methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/prims_function.html">aten_prims</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/convert.html">convert_tools</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/torch_dynamo.html">torch_dynamo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/torch_helper.html">torch_models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/dimension.html">Dimension</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/torch_test.html">Testing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/misc.html">Others…</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../auto_examples/index.html">Example gallery</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle navigation of Example gallery</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_optimize_101.html">101: Graph Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_profile_existing_onnx_101.html">101: Profile an existing model with onnxruntime</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_rewrite_101.html">101: Onnx Model Rewriting</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_torch_linreg_101.html">101: Linear Regression and export to ONNX</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_torch_custom_backend_101.html">101: A custom backend for torch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_convolutation_matmul_102.html">102: Convolution and Matrix Multiplication</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_llama_diff_export_301.html">301: Compares LLAMA exporters</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_llama_diff_dort_301.html">301: Compares LLAMA exporters for onnxrt backend</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_llama_bench_102.html">102: Measure LLAMA speed</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_torch_aot_201.html">201: Evaluate DORT Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_torch_dort_201.html">201: Evaluate DORT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_torch_export_201.html">201: Evaluate different ways to export a torch model to ONNX</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../models/index.html">Supported Models</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle navigation of Supported Models</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../models/torchtry.html">Tries with Undocumented</a></li>
<li class="toctree-l2"><a class="reference internal" href="../models/onnxrt.html">Use the custom exporter in torch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../models/example_bug.html">A script to report a bug</a></li>
<li class="toctree-l2"><a class="reference internal" href="../models/llama.html">LLaMa</a></li>
<li class="toctree-l2"><a class="reference internal" href="../models/mistral.html">Mistral</a></li>
<li class="toctree-l2"><a class="reference internal" href="../models/phi.html">Phi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../models/phi3.html">Phi3</a></li>
<li class="toctree-l2"><a class="reference internal" href="../models/speech2text.html">Speech2Text2ForCausalLM</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../bench/index.html">Benchmarks from the command line</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle navigation of Benchmarks from the command line</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../bench/dort_bench.html">experimental_experiment.torch_bench.dort_bench</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bench/dort_profile.html">experimental_experiment.torch_bench.dort_profile</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bench/bash_bench.html">Measuring the exporters on a short list of sets of models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bench/scripts.html">Interesting scripts or command lines</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../times.html">Times</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">More</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
<li class="toctree-l1"><a class="reference internal" href="../long_outputs.html">Long Outputs uneasy to read</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="../_sources/design/exporter.rst" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="custom-exporter">
<h1>Custom Exporter<a class="headerlink" href="#custom-exporter" title="Link to this heading">¶</a></h1>
<p>The exporter implemented in this package is built upon a classic
architecture with two main classes:</p>
<ul class="simple">
<li><p>a <a class="reference internal" href="../api/graph_builder.html#experimental_experiment.xbuilder.GraphBuilder" title="experimental_experiment.xbuilder.GraphBuilder"><code class="xref py py-class docutils literal notranslate"><span class="pre">GraphBuilder</span></code></a>,
it is a container for created nodes and initializers,
it stores additional information such as shapes, types, constants,
it providers methods to easily create nodes, provides unique names.</p></li>
<li><p>a <a class="reference internal" href="../api/interpreter.html#experimental_experiment.torch_interpreter.interpreter.DynamoInterpreter" title="experimental_experiment.torch_interpreter.interpreter.DynamoInterpreter"><code class="xref py py-class docutils literal notranslate"><span class="pre">DynamoInterpreter</span></code></a>,
this class goes through the model described as a <a class="reference external" href="https://pytorch.org/docs/stable/fx.html#torch.fx.GraphModule">GraphModule</a> and
calls the appropriate converting functions to translate every call
into an equivalent ONNX graph.</p></li>
</ul>
<p>Both classes are usually not seen by the user. They are called either by
function <a class="reference internal" href="../api/onnx_export.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx"><code class="xref py py-func docutils literal notranslate"><span class="pre">to_onnx</span></code></a>
which converts a model into an ONNX graph or through a custom backend:</p>
<ul class="simple">
<li><p><a class="reference internal" href="../api/torch_dynamo.html#experimental_experiment.torch_dynamo.onnx_custom_backend" title="experimental_experiment.torch_dynamo.onnx_custom_backend"><code class="xref py py-func docutils literal notranslate"><span class="pre">onnx_custom_backend</span></code></a>,
this backend leverages <a class="reference external" href="https://onnxruntime.ai/">onnxruntime</a> to run the inference, it is fast,</p></li>
<li><p><a class="reference internal" href="../api/torch_dynamo.html#experimental_experiment.torch_dynamo.onnx_debug_backend" title="experimental_experiment.torch_dynamo.onnx_debug_backend"><code class="xref py py-func docutils literal notranslate"><span class="pre">onnx_debug_backend</span></code></a>,
a backend using <a class="reference external" href="https://numpy.org/">numpy</a>, meant to debug, it is slow.</p></li>
</ul>
<p>This second backend calls the reference implementation through class
<a class="reference internal" href="../api/reference.html#experimental_experiment.reference.ExtendedReferenceEvaluator" title="experimental_experiment.reference.ExtendedReferenceEvaluator"><code class="xref py py-class docutils literal notranslate"><span class="pre">ExtendedReferenceEvaluator</span></code></a>.
This class extends <a class="reference external" href="https://onnx.ai/onnx/api/reference.html#onnx.reference.ReferenceEvaluator" title="(in ONNX v1.18.0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">ReferenceEvaluator</span></code></a>
from package <a class="reference external" href="https://onnx.ai/onnx/">onnx</a>.</p>
<section id="one-objective-speed">
<h2>One objective: SPEED<a class="headerlink" href="#one-objective-speed" title="Link to this heading">¶</a></h2>
<p>The only objective for this exporter is <strong>speed</strong>. It must be fast as the
size of the model to convert grows fast. The exporter may be one piece
of the backend calling <a class="reference external" href="https://onnxruntime.ai/">onnxruntime</a>. This only objective implies
a few constraints.</p>
<p><strong>multi-opset support</strong></p>
<p>The converter must support the conversion to different
<a class="reference external" href="ttps://onnx.ai/onnx/intro/concepts.html#what-is-an-opset-version">opsets</a> to avoid using the
<a class="reference external" href="https://onnx.ai/onnx/api/version_converter.html#onnx.version_converter.convert_version" title="(in ONNX v1.18.0)"><code class="xref py py-func docutils literal notranslate"><span class="pre">onnx.version_converter.convert_version()</span></code></a> which
does not fully work when the model includes other domain than the main one.</p>
<p><strong>use shape and type information</strong></p>
<p>The <a class="reference external" href="https://pytorch.org/docs/stable/fx.html#torch.fx.GraphModule">GraphModule</a> comes with the shape and type information
of the tensor it manipulates. It must be used to optimize
the onnx graph rather than using an optimizer after the conversion
happens.</p>
<p><strong>no decorators, no code interpretation</strong></p>
<p>Writing efficient code is easier when <em>the code you see is the code you get</em>.
A decorator hides some logic a developper must take into account
to avoid writing non efficient code. On the same level, translating
a python code into ONNX requires extra logic the developper does not
control.</p>
<p><strong>no fallback</strong></p>
<p>The implementation fails if it cannot find a solution to convert
the model into ONNX. There are some ways to go around that but
there are not enabled by default. The user must know if the exporter
follows a different way to produce the model.</p>
</section>
<section id="graphbuilder">
<h2>GraphBuilder<a class="headerlink" href="#graphbuilder" title="Link to this heading">¶</a></h2>
<p><a class="reference internal" href="../api/graph_builder.html#experimental_experiment.xbuilder.GraphBuilder" title="experimental_experiment.xbuilder.GraphBuilder"><code class="xref py py-class docutils literal notranslate"><span class="pre">GraphBuilder</span></code></a>
starts from empty or take an existing graph as an input.
In that case, the builder is usually used by an optimizer.</p>
<section id="internal-containers">
<h3>Internal containers<a class="headerlink" href="#internal-containers" title="Link to this heading">¶</a></h3>
<p>Beside the onnx structure, the builder holds information about
the requested opsets and the dynamic shapes.
During the conversion, it stores informations about</p>
<ul class="simple">
<li><p><cite>_unique_names</cite>: names already taken for results</p></li>
<li><p><cite>_unique_node_names</cite>: names already taken for node node</p></li>
<li><p><cite>_known_names</cite>: existing names</p></li>
<li><p><cite>_known_types</cite>: known type for every result, it must exist</p></li>
<li><p><cite>_known_shapes</cite>: known shape for every result, either shape or rank is known</p></li>
<li><p><cite>_known_ranks</cite>: declared ranks</p></li>
<li><p><cite>_known_value_shape</cite>: results known as shapes, the implementation tries
to capture the logic with string, <a class="reference external" href="https://www.sympy.org/en/index.html">sympy</a> could be used</p></li>
</ul>
<p>The model stores some constant, the builder assumes every node
taking only constant as inputs produces a new constant.</p>
<ul class="simple">
<li><p><cite>constants_</cite>: constant values</p></li>
<li><p><cite>constants_computed_</cite>: computed constant values, constant built from constant,
every computed constant is cached,</p></li>
</ul>
<p>The builder tries to minimize the number of intializers to create.
It stores a unique value for the small one:</p>
<ul class="simple">
<li><p><cite>_values</cite>: cache initializer value to merge those which are equal</p></li>
</ul>
<p>The forward/backward graphs may dynamic dimension as input.
Some results are reshaped based on this inputs.
The following container keep track of this information.</p>
<ul class="simple">
<li><p><cite>dynamic_objects</cite>: list of dynamic dimensions coming as inputs</p></li>
<li><p><cite>dynamic_objects_rev</cite>: reverse dictionary to fasten lookups</p></li>
<li><dl class="simple">
<dt><cite>_dynamic_alias</cite>: used when the user gives a different</dt><dd><p>name to the dynamic shapes</p>
</dd>
</dl>
</li>
</ul>
<p>Next container store dynamic shapes.</p>
<ul class="simple">
<li><p><cite>_cache_shape</cite>: cache concatenation of shapes</p></li>
</ul>
</section>
<section id="api">
<h3>API<a class="headerlink" href="#api" title="Link to this heading">¶</a></h3>
<p>The following methods are used to add onnx elements to the graph.</p>
<ul class="simple">
<li><p><a class="reference internal" href="../api/graph_builder.html#experimental_experiment.xbuilder.GraphBuilder.get_opset" title="experimental_experiment.xbuilder.GraphBuilder.get_opset"><code class="xref py py-meth docutils literal notranslate"><span class="pre">get_opset</span></code></a>:
get the value for a domain</p></li>
<li><p><a class="reference internal" href="../api/graph_builder.html#experimental_experiment.xbuilder.GraphBuilder.make_tensor_input" title="experimental_experiment.xbuilder.GraphBuilder.make_tensor_input"><code class="xref py py-meth docutils literal notranslate"><span class="pre">make_tensor_input</span></code></a>:
adds an input to the graph, <cite>is_dimension</cite> specifies if this input is a dynamic
dimension, a single integer,</p></li>
<li><p><a class="reference internal" href="../api/graph_builder.html#experimental_experiment.xbuilder.GraphBuilder.make_tensor_output" title="experimental_experiment.xbuilder.GraphBuilder.make_tensor_output"><code class="xref py py-meth docutils literal notranslate"><span class="pre">make_tensor_output</span></code></a>:
adds an output to the graph, <cite>is_dimension</cite> specifies if this output is a dynamic
dimension, a single integer,</p></li>
<li><p><a class="reference internal" href="../api/graph_builder.html#experimental_experiment.xbuilder.GraphBuilder.make_initializer" title="experimental_experiment.xbuilder.GraphBuilder.make_initializer"><code class="xref py py-meth docutils literal notranslate"><span class="pre">make_initializer</span></code></a>:
this method is used to add initializer to the graph,</p></li>
<li><p><a class="reference internal" href="../api/graph_builder.html#experimental_experiment.xbuilder.GraphBuilder.make_node" title="experimental_experiment.xbuilder.GraphBuilder.make_node"><code class="xref py py-meth docutils literal notranslate"><span class="pre">make_node</span></code></a>:
add a node to the graph</p></li>
<li><p><a class="reference internal" href="../api/graph_builder.html#experimental_experiment.xbuilder.GraphBuilder.to_onnx" title="experimental_experiment.xbuilder.GraphBuilder.to_onnx"><code class="xref py py-meth docutils literal notranslate"><span class="pre">to_onnx</span></code></a>:
produces the final ONNX</p></li>
</ul>
<p>Some needs are very common and deserve a dedicated method.</p>
<ul class="simple">
<li><p><a class="reference internal" href="../api/graph_builder.html#experimental_experiment.xbuilder.GraphBuilder.make_nodes" title="experimental_experiment.xbuilder.GraphBuilder.make_nodes"><code class="xref py py-meth docutils literal notranslate"><span class="pre">make_nodes</span></code></a>:
adds many nodes in one row, it renames the intermediate result if needed.</p></li>
<li><p><a class="reference internal" href="../api/graph_builder.html#experimental_experiment.xbuilder.GraphBuilder.get_attribute" title="experimental_experiment.xbuilder.GraphBuilder.get_attribute"><code class="xref py py-meth docutils literal notranslate"><span class="pre">get_attribute</span></code></a>:
retrieve an attribute from a NodeProto</p></li>
<li><p><a class="reference internal" href="../api/graph_builder.html#experimental_experiment.xbuilder.GraphBuilder.make_shape_from_results" title="experimental_experiment.xbuilder.GraphBuilder.make_shape_from_results"><code class="xref py py-meth docutils literal notranslate"><span class="pre">make_shape_from_results</span></code></a>:
makes a shape from a tuple having integer, string, or <cite>torch.SymInt</cite></p></li>
</ul>
<p>It is important to update the shape the information is available.</p>
<ul class="simple">
<li><p><a class="reference internal" href="../api/graph_builder.html#experimental_experiment.xbuilder.GraphBuilder.has_type" title="experimental_experiment.xbuilder.GraphBuilder.has_type"><code class="xref py py-meth docutils literal notranslate"><span class="pre">has_type</span></code></a></p></li>
<li><p><a class="reference internal" href="../api/graph_builder.html#experimental_experiment.xbuilder.GraphBuilder.has_shape" title="experimental_experiment.xbuilder.GraphBuilder.has_shape"><code class="xref py py-meth docutils literal notranslate"><span class="pre">has_shape</span></code></a></p></li>
<li><p><a class="reference internal" href="../api/graph_builder.html#experimental_experiment.xbuilder.GraphBuilder.has_rank" title="experimental_experiment.xbuilder.GraphBuilder.has_rank"><code class="xref py py-meth docutils literal notranslate"><span class="pre">has_rank</span></code></a></p></li>
<li><p><a class="reference internal" href="../api/graph_builder.html#experimental_experiment.xbuilder.GraphBuilder.has_dynamic_object" title="experimental_experiment.xbuilder.GraphBuilder.has_dynamic_object"><code class="xref py py-meth docutils literal notranslate"><span class="pre">has_dynamic_object</span></code></a></p></li>
<li><p><a class="reference internal" href="../api/graph_builder.html#experimental_experiment.xbuilder.GraphBuilder.is_sequence" title="experimental_experiment.xbuilder.GraphBuilder.is_sequence"><code class="xref py py-meth docutils literal notranslate"><span class="pre">is_sequence</span></code></a></p></li>
<li><p><a class="reference internal" href="../api/graph_builder.html#experimental_experiment.xbuilder.GraphBuilder.is_constant" title="experimental_experiment.xbuilder.GraphBuilder.is_constant"><code class="xref py py-meth docutils literal notranslate"><span class="pre">is_constant</span></code></a></p></li>
<li><p><a class="reference internal" href="../api/graph_builder.html#experimental_experiment.xbuilder.GraphBuilder.value_as_shape" title="experimental_experiment.xbuilder.GraphBuilder.value_as_shape"><code class="xref py py-meth docutils literal notranslate"><span class="pre">value_as_shape</span></code></a></p></li>
</ul>
<p>Get the information:</p>
<ul class="simple">
<li><p><a class="reference internal" href="../api/graph_builder.html#experimental_experiment.xbuilder.GraphBuilder.get_type" title="experimental_experiment.xbuilder.GraphBuilder.get_type"><code class="xref py py-meth docutils literal notranslate"><span class="pre">get_type</span></code></a></p></li>
<li><p><a class="reference internal" href="../api/graph_builder.html#experimental_experiment.xbuilder.GraphBuilder.get_shape" title="experimental_experiment.xbuilder.GraphBuilder.get_shape"><code class="xref py py-meth docutils literal notranslate"><span class="pre">get_shape</span></code></a></p></li>
<li><p><a class="reference internal" href="../api/graph_builder.html#experimental_experiment.xbuilder.GraphBuilder.get_sequence" title="experimental_experiment.xbuilder.GraphBuilder.get_sequence"><code class="xref py py-meth docutils literal notranslate"><span class="pre">get_sequence</span></code></a></p></li>
<li><p><a class="reference internal" href="../api/graph_builder.html#experimental_experiment.xbuilder.GraphBuilder.get_rank" title="experimental_experiment.xbuilder.GraphBuilder.get_rank"><code class="xref py py-meth docutils literal notranslate"><span class="pre">get_rank</span></code></a></p></li>
<li><p><a class="reference internal" href="../api/graph_builder.html#experimental_experiment.xbuilder.GraphBuilder.get_constant" title="experimental_experiment.xbuilder.GraphBuilder.get_constant"><code class="xref py py-meth docutils literal notranslate"><span class="pre">get_constant</span></code></a></p></li>
<li><p><a class="reference internal" href="../api/graph_builder.html#experimental_experiment.xbuilder.GraphBuilder.value_as_shape" title="experimental_experiment.xbuilder.GraphBuilder.value_as_shape"><code class="xref py py-meth docutils literal notranslate"><span class="pre">value_as_shape</span></code></a></p></li>
</ul>
<p>Set the information:</p>
<ul class="simple">
<li><p><a class="reference internal" href="../api/graph_builder.html#experimental_experiment.xbuilder.GraphBuilder.set_type" title="experimental_experiment.xbuilder.GraphBuilder.set_type"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_type</span></code></a></p></li>
<li><p><a class="reference internal" href="../api/graph_builder.html#experimental_experiment.xbuilder.GraphBuilder.set_shape" title="experimental_experiment.xbuilder.GraphBuilder.set_shape"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_shape</span></code></a></p></li>
<li><p><a class="reference internal" href="../api/graph_builder.html#experimental_experiment.xbuilder.GraphBuilder.set_rank" title="experimental_experiment.xbuilder.GraphBuilder.set_rank"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_rank</span></code></a></p></li>
<li><p><a class="reference internal" href="../api/graph_builder.html#experimental_experiment.xbuilder.GraphBuilder.set_sequence" title="experimental_experiment.xbuilder.GraphBuilder.set_sequence"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_sequence</span></code></a></p></li>
<li><p><a class="reference internal" href="../api/graph_builder.html#experimental_experiment.xbuilder.GraphBuilder.set_value_shape" title="experimental_experiment.xbuilder.GraphBuilder.set_value_shape"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_value_shape</span></code></a></p></li>
</ul>
<p>A function used to provide information to the user and calls in most of the error message:</p>
<ul class="simple">
<li><p><a class="reference internal" href="../api/graph_builder.html#experimental_experiment.xbuilder.GraphBuilder.get_debug_msg" title="experimental_experiment.xbuilder.GraphBuilder.get_debug_msg"><code class="xref py py-meth docutils literal notranslate"><span class="pre">get_debug_msg</span></code></a></p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">assert</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_known_ranks</span><span class="p">,</span> <span class="p">(</span>
  <span class="sa">f</span><span class="s2">&quot;Rank is unknown for result </span><span class="si">{</span><span class="n">name</span><span class="si">!r}</span><span class="s2">, &quot;</span>
  <span class="sa">f</span><span class="s2">&quot;known_shapes=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_known_ranks</span><span class="si">}{</span><span class="bp">self</span><span class="o">.</span><span class="n">get_debug_msg</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="example">
<h3>Example<a class="headerlink" href="#example" title="Link to this heading">¶</a></h3>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">onnx</span> <span class="kn">import</span> <span class="n">TensorProto</span>
<span class="kn">from</span> <span class="nn">experimental_experiment.xbuilder</span> <span class="kn">import</span> <span class="n">GraphBuilder</span>
<span class="kn">from</span> <span class="nn">experimental_experiment.reference</span> <span class="kn">import</span> <span class="n">ExtendedReferenceEvaluator</span>
<span class="kn">from</span> <span class="nn">onnx_array_api.plotting.text_plot</span> <span class="kn">import</span> <span class="n">onnx_simple_text_plot</span>


<span class="n">gr</span> <span class="o">=</span> <span class="n">GraphBuilder</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="n">ir_version</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
<span class="n">gr</span><span class="o">.</span><span class="n">make_tensor_input</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">(</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">),</span> <span class="n">is_dimension</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">weight</span> <span class="o">=</span> <span class="n">gr</span><span class="o">.</span><span class="n">make_initializer</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="n">bias</span> <span class="o">=</span> <span class="n">gr</span><span class="o">.</span><span class="n">make_initializer</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">mm</span> <span class="o">=</span> <span class="n">gr</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;MatMul&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="n">weight</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;n&quot;</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">gr</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Add&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">mm</span><span class="p">,</span> <span class="n">bias</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;Y&quot;</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;n&quot;</span><span class="p">)</span>
<span class="n">gr</span><span class="o">.</span><span class="n">make_tensor_output</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">(</span><span class="s2">&quot;a&quot;</span><span class="p">,),</span> <span class="n">indexed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">is_dimension</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">onx</span> <span class="o">=</span> <span class="n">gr</span><span class="o">.</span><span class="n">to_onnx</span><span class="p">()</span>

<span class="n">ref</span> <span class="o">=</span> <span class="n">ExtendedReferenceEvaluator</span><span class="p">(</span><span class="n">onx</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">ref</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;X&quot;</span><span class="p">:</span> <span class="n">x</span><span class="p">})[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">onnx_simple_text_plot</span><span class="p">(</span><span class="n">onx</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Without any information, the known shapes are:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">gr</span><span class="o">.</span><span class="n">_known_shapes</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Without any information, the known shapes are:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">gr</span><span class="o">.</span><span class="n">constants_</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The constant are not converted into TensorProto until the very end:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">gr</span><span class="o">.</span><span class="n">initializers_dict</span><span class="p">)</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="p">[[</span><span class="mf">1.561</span> <span class="mf">1.661</span> <span class="mf">1.761</span><span class="p">]</span>
     <span class="p">[</span><span class="mf">0.932</span> <span class="mf">1.032</span> <span class="mf">1.132</span><span class="p">]</span>
     <span class="p">[</span><span class="mf">1.141</span> <span class="mf">1.241</span> <span class="mf">1.341</span><span class="p">]</span>
     <span class="p">[</span><span class="mf">1.271</span> <span class="mf">1.371</span> <span class="mf">1.471</span><span class="p">]</span>
     <span class="p">[</span><span class="mf">1.119</span> <span class="mf">1.219</span> <span class="mf">1.319</span><span class="p">]]</span>
    <span class="n">opset</span><span class="p">:</span> <span class="n">domain</span><span class="o">=</span><span class="s1">&#39;&#39;</span> <span class="n">version</span><span class="o">=</span><span class="mi">18</span>
    <span class="nb">input</span><span class="p">:</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;X&#39;</span> <span class="nb">type</span><span class="o">=</span><span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">]</span>
    <span class="n">init</span><span class="p">:</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;init1_s3x1_&#39;</span> <span class="nb">type</span><span class="o">=</span><span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">--</span> <span class="n">array</span><span class="p">([</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">init</span><span class="p">:</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;init1_s1x3_&#39;</span> <span class="nb">type</span><span class="o">=</span><span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="o">--</span> <span class="n">array</span><span class="p">([</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">MatMul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">init1_s3x1_</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">_onx_matmul0</span>
      <span class="n">Add</span><span class="p">(</span><span class="n">_onx_matmul0</span><span class="p">,</span> <span class="n">init1_s1x3_</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Y</span>
    <span class="n">output</span><span class="p">:</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Y&#39;</span> <span class="nb">type</span><span class="o">=</span><span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">]</span>
    <span class="n">Without</span> <span class="nb">any</span> <span class="n">information</span><span class="p">,</span> <span class="n">the</span> <span class="n">known</span> <span class="n">shapes</span> <span class="n">are</span><span class="p">:</span>
    <span class="p">{</span><span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">),</span> <span class="s1">&#39;init1_s3x1_&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="s1">&#39;init1_s1x3_&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="s1">&#39;_onx_matmul0&#39;</span><span class="p">:</span> <span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="mi">3</span><span class="p">)}</span>
    <span class="n">Without</span> <span class="nb">any</span> <span class="n">information</span><span class="p">,</span> <span class="n">the</span> <span class="n">known</span> <span class="n">shapes</span> <span class="n">are</span><span class="p">:</span>
    <span class="p">{</span><span class="s1">&#39;init1_s3x1_&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;init1_s1x3_&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">}</span>
    <span class="n">The</span> <span class="n">constant</span> <span class="n">are</span> <span class="ow">not</span> <span class="n">converted</span> <span class="n">into</span> <span class="n">TensorProto</span> <span class="n">until</span> <span class="n">the</span> <span class="n">very</span> <span class="n">end</span><span class="p">:</span>
    <span class="p">{</span><span class="s1">&#39;init1_s3x1_&#39;</span><span class="p">:</span> <span class="n">array</span><span class="p">([[</span><span class="mf">0.4</span><span class="p">],</span>
           <span class="p">[</span><span class="mf">0.5</span><span class="p">],</span>
           <span class="p">[</span><span class="mf">0.6</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">),</span> <span class="s1">&#39;init1_s1x3_&#39;</span><span class="p">:</span> <span class="n">array</span><span class="p">([[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)}</span>
</pre></div>
</div>
<p>The constant are only computed on demand. Their conversion to TensorProto
only happens when method
<a class="reference internal" href="../api/graph_builder.html#experimental_experiment.xbuilder.GraphBuilder.to_onnx" title="experimental_experiment.xbuilder.GraphBuilder.to_onnx"><code class="xref py py-meth docutils literal notranslate"><span class="pre">to_onnx</span></code></a>
is called.</p>
</section>
<section id="debugging">
<h3>Debugging<a class="headerlink" href="#debugging" title="Link to this heading">¶</a></h3>
<p>An exception is raised an error is detected and it displays the result
of <a class="reference internal" href="../api/graph_builder.html#experimental_experiment.xbuilder.GraphBuilder.get_debug_msg" title="experimental_experiment.xbuilder.GraphBuilder.get_debug_msg"><code class="xref py py-meth docutils literal notranslate"><span class="pre">get_debug_msg</span></code></a>.</p>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">onnx</span> <span class="kn">import</span> <span class="n">TensorProto</span>
<span class="kn">from</span> <span class="nn">experimental_experiment.xbuilder</span> <span class="kn">import</span> <span class="n">GraphBuilder</span>
<span class="kn">from</span> <span class="nn">experimental_experiment.reference</span> <span class="kn">import</span> <span class="n">ExtendedReferenceEvaluator</span>
<span class="kn">from</span> <span class="nn">onnx_array_api.plotting.text_plot</span> <span class="kn">import</span> <span class="n">onnx_simple_text_plot</span>


<span class="n">gr</span> <span class="o">=</span> <span class="n">GraphBuilder</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="n">ir_version</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
<span class="n">gr</span><span class="o">.</span><span class="n">make_tensor_input</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">(</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">),</span> <span class="n">is_dimension</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">weight</span> <span class="o">=</span> <span class="n">gr</span><span class="o">.</span><span class="n">make_initializer</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="n">bias</span> <span class="o">=</span> <span class="n">gr</span><span class="o">.</span><span class="n">make_initializer</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">mm</span> <span class="o">=</span> <span class="n">gr</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;MatMul&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="n">weight</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;N1&quot;</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">gr</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Add&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">mm</span><span class="p">,</span> <span class="s2">&quot;bias&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;Y&quot;</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;N2&quot;</span><span class="p">)</span>
<span class="n">gr</span><span class="o">.</span><span class="n">make_tensor_output</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">(</span><span class="s2">&quot;a&quot;</span><span class="p">,),</span> <span class="n">indexed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">is_dimension</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">onx</span> <span class="o">=</span> <span class="n">gr</span><span class="o">.</span><span class="n">to_onnx</span><span class="p">()</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    
    [runpythonerror]
    
    Traceback (most recent call last):
        exec(obj, globs, loc)
      File &quot;&quot;, line 20, in &lt;module&gt;
      File &quot;&quot;, line 17, in run_python_script_139665913336960
      File &quot;/home/xadupre/github/experimental-experiment/experimental_experiment/xbuilder/graph_builder.py&quot;, line 2398, in make_node
        assert self.has_name(i), (
    AssertionError: Input &#39;bias&#39; does not exist for operator &#39;Add&#39;, inputs=[&#39;_onx_matmul0&#39;, &#39;bias&#39;], name=&#39;N2&#39; (ZYE)
    --DEBUG--
    --LOCAL FUNCTIONS--
    --SHAPE--
    dynamic_objects=
       a = &#39;a&#39;
       b = &#39;b&#39;
    dynamic_objects_rev=
       &#39;a&#39; = &lt;class &#39;list&#39;&gt;
           &#39;a&#39;
       &#39;b&#39; = &lt;class &#39;list&#39;&gt;
           &#39;b&#39;
    dynamic_dimensions_source={}
    dynamic_alias={}
    dynamic_shapes=None
    _known_value_shape={}
    _known_types={&#39;X&#39;: 1, &#39;_onx_matmul0&#39;: 1, &#39;init1_s1x3_&#39;: 1, &#39;init1_s3x1_&#39;: 1}
    _known_shapes={&#39;X&#39;: (&#39;a&#39;, &#39;b&#39;),
     &#39;_onx_matmul0&#39;: (&#39;a&#39;, 1),
     &#39;init1_s1x3_&#39;: (1, 3),
     &#39;init1_s3x1_&#39;: (3, 1)}
    _known_constants=[&#39;init1_s1x3_&#39;, &#39;init1_s3x1_&#39;]
    _known_ranks={}
    --TORCH-USERS--
    --TORCH-SHAPES--
    --ONNX--
    --
    [GraphBuilder-ZYE.make_tensor_input] X[1:axb]
    [GraphBuilder-ZYE.make_initializer] init1_s3x1_[float32:float32:[0.4000000059604645, 0.5, 0.6000000238418579]]
    [GraphBuilder-ZYE.make_initializer] init1_s1x3_[float32:float32:[0.4000000059604645, 0.5, 0.6000000238418579]]
    [GraphBuilder-ZYE.make_node] N1              [##:#  ] MatMul:[&#39;X&#39;, &#39;init1_s3x1_&#39;]-&gt;[&#39;_onx_matmul0&#39;]
    [GraphBuilder-ZYE] Message completed, there are 2 initializers, 1 nodes, 1 inputs, 1 outputs.
</pre></div>
</div>
<p>It shows the information currently available while building the model.
At the end the following lines appear.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">GraphBuilder</span><span class="o">-</span><span class="n">EAQ</span><span class="o">.</span><span class="n">make_node</span><span class="p">]</span> <span class="n">N1</span>              <span class="p">[</span><span class="c1">##:-  ] MatMul:[&#39;X&#39;, &#39;init1_s3x1_&#39;]-&gt;[&#39;_onx_matmul0&#39;]</span>
</pre></div>
</div>
<p>It says one node named <code class="docutils literal notranslate"><span class="pre">N1</span></code> was created. <code class="docutils literal notranslate"><span class="pre">##</span></code> means the shape and type are
known for the two inputs it has. <cite>-</cite> means nothing is known for the output.
When the type is specified, it shows the following:</p>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">onnx</span> <span class="kn">import</span> <span class="n">TensorProto</span>
<span class="kn">from</span> <span class="nn">experimental_experiment.xbuilder</span> <span class="kn">import</span> <span class="n">GraphBuilder</span>
<span class="kn">from</span> <span class="nn">experimental_experiment.reference</span> <span class="kn">import</span> <span class="n">ExtendedReferenceEvaluator</span>
<span class="kn">from</span> <span class="nn">onnx_array_api.plotting.text_plot</span> <span class="kn">import</span> <span class="n">onnx_simple_text_plot</span>


<span class="n">gr</span> <span class="o">=</span> <span class="n">GraphBuilder</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="n">ir_version</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
<span class="n">gr</span><span class="o">.</span><span class="n">make_tensor_input</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">(</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">),</span> <span class="n">is_dimension</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">weight</span> <span class="o">=</span> <span class="n">gr</span><span class="o">.</span><span class="n">make_initializer</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="n">bias</span> <span class="o">=</span> <span class="n">gr</span><span class="o">.</span><span class="n">make_initializer</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">mm</span> <span class="o">=</span> <span class="n">gr</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;MatMul&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="n">weight</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;N1&quot;</span><span class="p">)</span>
<span class="n">gr</span><span class="o">.</span><span class="n">set_type</span><span class="p">(</span><span class="n">mm</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">gr</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Add&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">mm</span><span class="p">,</span> <span class="s2">&quot;bias&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;Y&quot;</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;N2&quot;</span><span class="p">)</span>
<span class="n">gr</span><span class="o">.</span><span class="n">make_tensor_output</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">(</span><span class="s2">&quot;a&quot;</span><span class="p">,),</span> <span class="n">indexed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">is_dimension</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">onx</span> <span class="o">=</span> <span class="n">gr</span><span class="o">.</span><span class="n">to_onnx</span><span class="p">()</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    
    [runpythonerror]
    
    Traceback (most recent call last):
        exec(obj, globs, loc)
      File &quot;&quot;, line 21, in &lt;module&gt;
      File &quot;&quot;, line 18, in run_python_script_139665912115776
      File &quot;/home/xadupre/github/experimental-experiment/experimental_experiment/xbuilder/graph_builder.py&quot;, line 2398, in make_node
        assert self.has_name(i), (
    AssertionError: Input &#39;bias&#39; does not exist for operator &#39;Add&#39;, inputs=[&#39;_onx_matmul0&#39;, &#39;bias&#39;], name=&#39;N2&#39; (ADS)
    --DEBUG--
    --LOCAL FUNCTIONS--
    --SHAPE--
    dynamic_objects=
       a = &#39;a&#39;
       b = &#39;b&#39;
    dynamic_objects_rev=
       &#39;a&#39; = &lt;class &#39;list&#39;&gt;
           &#39;a&#39;
       &#39;b&#39; = &lt;class &#39;list&#39;&gt;
           &#39;b&#39;
    dynamic_dimensions_source={}
    dynamic_alias={}
    dynamic_shapes=None
    _known_value_shape={}
    _known_types={&#39;X&#39;: 1, &#39;_onx_matmul0&#39;: 1, &#39;init1_s1x3_&#39;: 1, &#39;init1_s3x1_&#39;: 1}
    _known_shapes={&#39;X&#39;: (&#39;a&#39;, &#39;b&#39;),
     &#39;_onx_matmul0&#39;: (&#39;a&#39;, 1),
     &#39;init1_s1x3_&#39;: (1, 3),
     &#39;init1_s3x1_&#39;: (3, 1)}
    _known_constants=[&#39;init1_s1x3_&#39;, &#39;init1_s3x1_&#39;]
    _known_ranks={}
    --TORCH-USERS--
    --TORCH-SHAPES--
    --ONNX--
    --
    [GraphBuilder-ADS.make_tensor_input] X[1:axb]
    [GraphBuilder-ADS.make_initializer] init1_s3x1_[float32:float32:[0.4000000059604645, 0.5, 0.6000000238418579]]
    [GraphBuilder-ADS.make_initializer] init1_s1x3_[float32:float32:[0.4000000059604645, 0.5, 0.6000000238418579]]
    [GraphBuilder-ADS.make_node] N1              [##:#  ] MatMul:[&#39;X&#39;, &#39;init1_s3x1_&#39;]-&gt;[&#39;_onx_matmul0&#39;]
    [GraphBuilder-ADS] Message completed, there are 2 initializers, 1 nodes, 1 inputs, 1 outputs.
</pre></div>
</div>
<p>It shows <code class="docutils literal notranslate"><span class="pre">U</span></code> when the type and rank are known, <code class="docutils literal notranslate"><span class="pre">#</span></code> if the type and shape are known.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">GraphBuilder</span><span class="o">-</span><span class="n">MJG</span><span class="o">.</span><span class="n">make_node</span><span class="p">]</span> <span class="n">N1</span>              <span class="p">[</span><span class="c1">##:U  ] MatMul:[&#39;X&#39;, &#39;init1_s3x1_&#39;]-&gt;[&#39;_onx_matmul0&#39;]</span>
</pre></div>
</div>
</section>
<section id="simplified-api">
<h3>Simplified API<a class="headerlink" href="#simplified-api" title="Link to this heading">¶</a></h3>
<p>For the most common nodes, there exists a shortcut
to make the syntax shorter.</p>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">onnx</span> <span class="kn">import</span> <span class="n">TensorProto</span>
<span class="kn">from</span> <span class="nn">experimental_experiment.xbuilder</span> <span class="kn">import</span> <span class="n">GraphBuilder</span>
<span class="kn">from</span> <span class="nn">experimental_experiment.reference</span> <span class="kn">import</span> <span class="n">ExtendedReferenceEvaluator</span>
<span class="kn">from</span> <span class="nn">onnx_array_api.plotting.text_plot</span> <span class="kn">import</span> <span class="n">onnx_simple_text_plot</span>


<span class="n">gr</span> <span class="o">=</span> <span class="n">GraphBuilder</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="n">ir_version</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
<span class="n">gr</span><span class="o">.</span><span class="n">make_tensor_input</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">(</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">),</span> <span class="n">is_dimension</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">mm</span> <span class="o">=</span> <span class="n">gr</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">MatMul</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">gr</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Add</span><span class="p">(</span><span class="n">mm</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Y&quot;</span><span class="p">])</span>
<span class="n">gr</span><span class="o">.</span><span class="n">make_tensor_output</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">(</span><span class="s2">&quot;a&quot;</span><span class="p">,),</span> <span class="n">indexed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">is_dimension</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">onx</span> <span class="o">=</span> <span class="n">gr</span><span class="o">.</span><span class="n">to_onnx</span><span class="p">()</span>

<span class="n">ref</span> <span class="o">=</span> <span class="n">ExtendedReferenceEvaluator</span><span class="p">(</span><span class="n">onx</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">ref</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;X&quot;</span><span class="p">:</span> <span class="n">x</span><span class="p">})[</span><span class="mi">0</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">onnx_simple_text_plot</span><span class="p">(</span><span class="n">onx</span><span class="p">))</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="p">[[</span><span class="mf">0.901</span> <span class="mf">1.001</span> <span class="mf">1.101</span><span class="p">]</span>
     <span class="p">[</span><span class="mf">0.712</span> <span class="mf">0.812</span> <span class="mf">0.912</span><span class="p">]</span>
     <span class="p">[</span><span class="mf">1.376</span> <span class="mf">1.476</span> <span class="mf">1.576</span><span class="p">]</span>
     <span class="p">[</span><span class="mf">1.332</span> <span class="mf">1.432</span> <span class="mf">1.532</span><span class="p">]</span>
     <span class="p">[</span><span class="mf">0.886</span> <span class="mf">0.986</span> <span class="mf">1.086</span><span class="p">]]</span>
    <span class="n">opset</span><span class="p">:</span> <span class="n">domain</span><span class="o">=</span><span class="s1">&#39;&#39;</span> <span class="n">version</span><span class="o">=</span><span class="mi">18</span>
    <span class="nb">input</span><span class="p">:</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;X&#39;</span> <span class="nb">type</span><span class="o">=</span><span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">]</span>
    <span class="n">init</span><span class="p">:</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;init1_s3x1_&#39;</span> <span class="nb">type</span><span class="o">=</span><span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">--</span> <span class="n">array</span><span class="p">([</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">init</span><span class="p">:</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;init1_s3_&#39;</span> <span class="nb">type</span><span class="o">=</span><span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,)</span> <span class="o">--</span> <span class="n">array</span><span class="p">([</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">MatMul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">init1_s3x1_</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">_onx_matmul0</span>
      <span class="n">Add</span><span class="p">(</span><span class="n">_onx_matmul0</span><span class="p">,</span> <span class="n">init1_s3_</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Y</span>
    <span class="n">output</span><span class="p">:</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Y&#39;</span> <span class="nb">type</span><span class="o">=</span><span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">]</span>
</pre></div>
</div>
</section>
<section id="optimizations">
<h3>Optimizations<a class="headerlink" href="#optimizations" title="Link to this heading">¶</a></h3>
<p><a class="reference internal" href="../api/graph_builder.html#experimental_experiment.xbuilder.GraphBuilder" title="experimental_experiment.xbuilder.GraphBuilder"><code class="xref py py-class docutils literal notranslate"><span class="pre">GraphBuilder</span></code></a>
implements three basic optimizations algorithms not using patterns.
Except constant folding, they are called by default.</p>
<ul class="simple">
<li><p><a class="reference internal" href="../api/graph_builder.html#experimental_experiment.xbuilder.GraphBuilder.remove_unused" title="experimental_experiment.xbuilder.GraphBuilder.remove_unused"><code class="xref py py-meth docutils literal notranslate"><span class="pre">remove_unused</span></code></a>:
removes unused nodes</p></li>
<li><p><a class="reference internal" href="../api/graph_builder.html#experimental_experiment.xbuilder.GraphBuilder.remove_identity_nodes" title="experimental_experiment.xbuilder.GraphBuilder.remove_identity_nodes"><code class="xref py py-meth docutils literal notranslate"><span class="pre">remove_identity_nodes</span></code></a>:
removes identity nodes</p></li>
<li><p><a class="reference internal" href="../api/graph_builder.html#experimental_experiment.xbuilder.GraphBuilder.constant_folding" title="experimental_experiment.xbuilder.GraphBuilder.constant_folding"><code class="xref py py-meth docutils literal notranslate"><span class="pre">constant_folding</span></code></a>:
replaces constant whenever it is possible and it makes sense</p></li>
</ul>
</section>
</section>
<section id="dynamointerpreter">
<h2>DynamoInterpreter<a class="headerlink" href="#dynamointerpreter" title="Link to this heading">¶</a></h2>
<p>Class <a class="reference internal" href="../api/interpreter.html#experimental_experiment.torch_interpreter.interpreter.DynamoInterpreter" title="experimental_experiment.torch_interpreter.interpreter.DynamoInterpreter"><code class="xref py py-class docutils literal notranslate"><span class="pre">DynamoInterpreter</span></code></a>
walks through a graph module and selects the best translation
for every part. It is a sequence of calls to internal functions
called <a class="reference external" href="https://pytorch.org/cppdocs/api/namespace_at.html#functions">aten functions</a>. It looks like the following:</p>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>


<span class="k">class</span> <span class="nc">Neuron</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_dims</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">n_targets</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Neuron</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_dims</span><span class="p">,</span> <span class="n">n_targets</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>


<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Neuron</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">graph</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">export</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">graph</span><span class="p">)</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="n">ExportedProgram</span><span class="p">:</span>
        <span class="k">class</span> <span class="nc">GraphModule</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
            <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p_linear_weight</span><span class="p">:</span> <span class="s2">&quot;f32[1, 3]&quot;</span><span class="p">,</span> <span class="n">p_linear_bias</span><span class="p">:</span> <span class="s2">&quot;f32[1]&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="s2">&quot;f32[5, 3]&quot;</span><span class="p">):</span>
                 <span class="c1"># </span>
                <span class="n">linear</span><span class="p">:</span> <span class="s2">&quot;f32[5, 1]&quot;</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">aten</span><span class="o">.</span><span class="n">linear</span><span class="o">.</span><span class="n">default</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p_linear_weight</span><span class="p">,</span> <span class="n">p_linear_bias</span><span class="p">);</span>  <span class="n">x</span> <span class="o">=</span> <span class="n">p_linear_weight</span> <span class="o">=</span> <span class="n">p_linear_bias</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="n">sigmoid</span><span class="p">:</span> <span class="s2">&quot;f32[5, 1]&quot;</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">aten</span><span class="o">.</span><span class="n">sigmoid</span><span class="o">.</span><span class="n">default</span><span class="p">(</span><span class="n">linear</span><span class="p">);</span>  <span class="n">linear</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="k">return</span> <span class="p">(</span><span class="n">sigmoid</span><span class="p">,)</span>
                
    <span class="n">Graph</span> <span class="n">signature</span><span class="p">:</span> <span class="n">ExportGraphSignature</span><span class="p">(</span><span class="n">input_specs</span><span class="o">=</span><span class="p">[</span><span class="n">InputSpec</span><span class="p">(</span><span class="n">kind</span><span class="o">=&lt;</span><span class="n">InputKind</span><span class="o">.</span><span class="n">PARAMETER</span><span class="p">:</span> <span class="mi">2</span><span class="o">&gt;</span><span class="p">,</span> <span class="n">arg</span><span class="o">=</span><span class="n">TensorArgument</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;p_linear_weight&#39;</span><span class="p">),</span> <span class="n">target</span><span class="o">=</span><span class="s1">&#39;linear.weight&#39;</span><span class="p">,</span> <span class="n">persistent</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span> <span class="n">InputSpec</span><span class="p">(</span><span class="n">kind</span><span class="o">=&lt;</span><span class="n">InputKind</span><span class="o">.</span><span class="n">PARAMETER</span><span class="p">:</span> <span class="mi">2</span><span class="o">&gt;</span><span class="p">,</span> <span class="n">arg</span><span class="o">=</span><span class="n">TensorArgument</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;p_linear_bias&#39;</span><span class="p">),</span> <span class="n">target</span><span class="o">=</span><span class="s1">&#39;linear.bias&#39;</span><span class="p">,</span> <span class="n">persistent</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span> <span class="n">InputSpec</span><span class="p">(</span><span class="n">kind</span><span class="o">=&lt;</span><span class="n">InputKind</span><span class="o">.</span><span class="n">USER_INPUT</span><span class="p">:</span> <span class="mi">1</span><span class="o">&gt;</span><span class="p">,</span> <span class="n">arg</span><span class="o">=</span><span class="n">TensorArgument</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">),</span> <span class="n">target</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">persistent</span><span class="o">=</span><span class="kc">None</span><span class="p">)],</span> <span class="n">output_specs</span><span class="o">=</span><span class="p">[</span><span class="n">OutputSpec</span><span class="p">(</span><span class="n">kind</span><span class="o">=&lt;</span><span class="n">OutputKind</span><span class="o">.</span><span class="n">USER_OUTPUT</span><span class="p">:</span> <span class="mi">1</span><span class="o">&gt;</span><span class="p">,</span> <span class="n">arg</span><span class="o">=</span><span class="n">TensorArgument</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">),</span> <span class="n">target</span><span class="o">=</span><span class="kc">None</span><span class="p">)])</span>
    <span class="n">Range</span> <span class="n">constraints</span><span class="p">:</span> <span class="p">{}</span>
</pre></div>
</div>
<p>The called function such as <code class="docutils literal notranslate"><span class="pre">torch.ops.aten.addmm.default</span></code> are well
identified and those cannot be converted into ONNX.
The interpret just maps this string to a function creating
the onnx implementation <a class="reference internal" href="../api/aten_function.html#experimental_experiment.torch_interpreter._aten_functions.aten_addmm" title="experimental_experiment.torch_interpreter._aten_functions.aten_addmm"><code class="xref py py-func docutils literal notranslate"><span class="pre">aten_addmm</span></code></a>
inside a dispatcher
<a class="reference internal" href="../api/interpreter.html#experimental_experiment.torch_interpreter.interpreter.DynamoInterpreter.run_node" title="experimental_experiment.torch_interpreter.interpreter.DynamoInterpreter.run_node"><code class="xref py py-meth docutils literal notranslate"><span class="pre">run_node</span></code></a>
which includes the following piece of code:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">op</span> <span class="o">==</span> <span class="s2">&quot;placeholder&quot;</span><span class="p">:</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
<span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">op</span> <span class="o">==</span> <span class="s2">&quot;call_function&quot;</span><span class="p">:</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">call_function</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
<span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">op</span> <span class="o">==</span> <span class="s2">&quot;output&quot;</span><span class="p">:</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
<span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">op</span> <span class="o">==</span> <span class="s2">&quot;call_module&quot;</span><span class="p">:</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">call_module</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
<span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">op</span> <span class="o">==</span> <span class="s2">&quot;get_attr&quot;</span><span class="p">:</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
<span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">op</span> <span class="o">==</span> <span class="s2">&quot;call_method&quot;</span><span class="p">:</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">call_method</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
</pre></div>
</div>
<section id="a-converting-function">
<h3>A converting function<a class="headerlink" href="#a-converting-function" title="Link to this heading">¶</a></h3>
<p>Let’s consider the easy converting following function.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">aten_addmm</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>

    <span class="n">a</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">b</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">c</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">beta</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;gemm&quot;</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Gemm</span><span class="p">(</span>
        <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="n">alpha</span><span class="p">),</span> <span class="n">beta</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="n">beta</span><span class="p">),</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;addmm&quot;</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_type</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">b</span><span class="p">))</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_rank</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span>
</pre></div>
</div>
<p>The three first arguments are the
<a class="reference internal" href="../api/graph_builder.html#experimental_experiment.xbuilder.GraphBuilder" title="experimental_experiment.xbuilder.GraphBuilder"><code class="xref py py-class docutils literal notranslate"><span class="pre">GraphBuilder</span></code></a>,
a boolean asking the function to set the shape and rank,
the output names to make sure the name are the same than the one in the graph
provided by torch. It helps debugging.</p>
</section>
<section id="shapes-and-types">
<h3>Shapes And Types<a class="headerlink" href="#shapes-and-types" title="Link to this heading">¶</a></h3>
<p>The function can assume the type is always filled.
The shapes should be set but in this case, only the rank is provided.
It is not mandatory but it helps the following functions to take
the right decision.
<a class="reference internal" href="../api/graph_builder.html#experimental_experiment.xbuilder.GraphBuilder" title="experimental_experiment.xbuilder.GraphBuilder"><code class="xref py py-class docutils literal notranslate"><span class="pre">GraphBuilder</span></code></a>
is setting the type and shape for a limited number of operator type
such as <cite>Identity</cite>. It should be better in the next versions.
Some helpers were already implemented to set shape or types
as shown in this function.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">aten_asin</span><span class="p">(</span><span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span> <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;asin&quot;</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Asin&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">outputs</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sts</span><span class="p">:</span>
        <span class="n">set_type_shape_unary_op</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span>
</pre></div>
</div>
<p>The boolean <code class="docutils literal notranslate"><span class="pre">sts</span></code> is <code class="docutils literal notranslate"><span class="pre">None</span></code> when the graph given by torch contains
no information about shape and type. Otherwise, the interpreter
gives them to the graph builder through <code class="docutils literal notranslate"><span class="pre">sts</span></code>.</p>
</section>
<section id="different-implementations">
<h3>Different Implementations<a class="headerlink" href="#different-implementations" title="Link to this heading">¶</a></h3>
<p>In the following case, the function adds a node <code class="docutils literal notranslate"><span class="pre">Identity</span></code>
or <code class="docutils literal notranslate"><span class="pre">CastLike</span></code> depending on the types. <code class="docutils literal notranslate"><span class="pre">CastLike</span></code> is only needed when types
are different. And the graph builder will remove the <code class="docutils literal notranslate"><span class="pre">Identity</span></code> node.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">aten_copy</span><span class="p">(</span>
    <span class="n">g</span><span class="p">:</span> <span class="n">GraphBuilder</span><span class="p">,</span>
    <span class="n">sts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">src</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">non_blocking</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="s2">&quot;identity&quot;</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="n">non_blocking</span><span class="p">,</span> <span class="s2">&quot;copy implemented when non_blocking is True&quot;</span>
    <span class="k">if</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">==</span> <span class="n">g</span><span class="o">.</span><span class="n">get_type</span><span class="p">(</span><span class="n">src</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">Identity</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;copy&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">g</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">CastLike</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;copy&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="conventions">
<h3>Conventions<a class="headerlink" href="#conventions" title="Link to this heading">¶</a></h3>
<p>The node should be given name based on the aten functions they
are part of. Doing that helps the developper to find where a failing
node comes from.</p>
</section>
<section id="functions">
<h3>Functions<a class="headerlink" href="#functions" title="Link to this heading">¶</a></h3>
<p>All the available functions are listed in one the those three pages:</p>
<ul class="simple">
<li><p><a class="reference internal" href="../api/aten_function.html#l-aten-functions"><span class="std std-ref">aten_functions</span></a>: functions</p></li>
<li><p><a class="reference internal" href="../api/aten_method.html#l-aten-methods"><span class="std std-ref">aten_methods</span></a>: methods</p></li>
<li><p><a class="reference internal" href="../api/prims_function.html#l-aten-prims"><span class="std std-ref">aten_prims</span></a>: primitives</p></li>
</ul>
<p>Every function added to these modules is automatically added
to the list of known converter functions.</p>
</section>
</section>
<section id="pratice">
<h2>Pratice<a class="headerlink" href="#pratice" title="Link to this heading">¶</a></h2>
<section id="id1">
<h3>Example<a class="headerlink" href="#id1" title="Link to this heading">¶</a></h3>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">onnx_array_api.plotting.text_plot</span> <span class="kn">import</span> <span class="n">onnx_simple_text_plot</span>
<span class="kn">from</span> <span class="nn">experimental_experiment.torch_interpreter</span> <span class="kn">import</span> <span class="n">to_onnx</span>


<span class="k">class</span> <span class="nc">Neuron</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_dims</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">n_targets</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Neuron</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_dims</span><span class="p">,</span> <span class="n">n_targets</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>


<span class="n">model</span> <span class="o">=</span> <span class="n">Neuron</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="n">onx</span> <span class="o">=</span> <span class="n">to_onnx</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,),</span> <span class="n">input_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="n">onnx_simple_text_plot</span><span class="p">(</span><span class="n">onx</span><span class="p">))</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="n">opset</span><span class="p">:</span> <span class="n">domain</span><span class="o">=</span><span class="s1">&#39;&#39;</span> <span class="n">version</span><span class="o">=</span><span class="mi">18</span>
    <span class="nb">input</span><span class="p">:</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;x&#39;</span> <span class="nb">type</span><span class="o">=</span><span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
    <span class="n">init</span><span class="p">:</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;p_linear_weight&#39;</span> <span class="nb">type</span><span class="o">=</span><span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="o">--</span> <span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">0.577</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.042</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.468</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">init</span><span class="p">:</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;p_linear_bias&#39;</span> <span class="nb">type</span><span class="o">=</span><span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,)</span> <span class="o">--</span> <span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">0.327</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">Gemm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p_linear_weight</span><span class="p">,</span> <span class="n">transA</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">transB</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">_onx_matmul0</span>
      <span class="n">Add</span><span class="p">(</span><span class="n">_onx_matmul0</span><span class="p">,</span> <span class="n">p_linear_bias</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">linear</span>
        <span class="n">Sigmoid</span><span class="p">(</span><span class="n">linear</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">output_0</span>
    <span class="n">output</span><span class="p">:</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;output_0&#39;</span> <span class="nb">type</span><span class="o">=</span><span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
<p>And visually:</p>
<div class="graphviz"><img src="../_images/graphviz-82a2bcb9771dc77c8a8e660267921038e02fdccc.png" alt="digraph{
  ranksep=0.25;
  nodesep=0.05;
  orientation=portrait;
  size=7;

  x [shape=box color=red label=&quot;x\nTensorProto.FLOAT\nshape=[5, 3]&quot; fontsize=10];

  output_0 [shape=box color=green label=&quot;output_0\nTensorProto.FLOAT\nshape=[5, 1]&quot; fontsize=10];

  p_linear_weight [shape=box label=&quot;p_linear_weight\nfloat32((1, 3))\n[[ 0.16878693 -0.00174342  0.28349072]]&quot; fontsize=10];
  p_linear_bias [shape=box label=&quot;p_linear_bias\nfloat32((1,))\n[-0.1685146]&quot; fontsize=10];

  _onx_matmul0 [shape=box label=&quot;_onx_matmul0&quot; fontsize=10];
  TransposeMatMulPattern__Opset [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Gemm\ntransA=0\ntransB=1&quot; fontsize=10];
  x -&gt; TransposeMatMulPattern__Opset;
  p_linear_weight -&gt; TransposeMatMulPattern__Opset;
  TransposeMatMulPattern__Opset -&gt; _onx_matmul0;

  linear [shape=box label=&quot;linear&quot; fontsize=10];
  Opset2 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Add&quot; fontsize=10];
  _onx_matmul0 -&gt; Opset2;
  p_linear_bias -&gt; Opset2;
  Opset2 -&gt; linear;

  Opset3 [shape=box style=&quot;filled,rounded&quot; color=orange label=&quot;Sigmoid&quot; fontsize=10];
  linear -&gt; Opset3;
  Opset3 -&gt; output_0;
}" class="graphviz" /></div>
</section>
<section id="id2">
<h3>Debugging<a class="headerlink" href="#id2" title="Link to this heading">¶</a></h3>
<p>There is no fallback by default. The converter fails if
the conversion to ONNX cannot happen. In that case, it tries to
give you some information why it failed.
(The example might succeed in the future.)</p>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">experimental_experiment.torch_interpreter</span> <span class="kn">import</span> <span class="n">to_onnx</span>


<span class="k">class</span> <span class="nc">Neuron</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_dims</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">n_targets</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Neuron</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_dims</span><span class="p">,</span> <span class="n">n_targets</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">celu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>


<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Neuron</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>


<span class="n">onx</span> <span class="o">=</span> <span class="n">to_onnx</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,),</span> <span class="n">input_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">])</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    
    [runpythonerror]
    
    Traceback (most recent call last):
        exec(obj, globs, loc)
      File &quot;&quot;, line 20, in &lt;module&gt;
      File &quot;&quot;, line 19, in run_python_script_139665914894336
      File &quot;/home/xadupre/github/experimental-experiment/experimental_experiment/torch_interpreter/onnx_export.py&quot;, line 506, in to_onnx
        builder.process(graph_module, interpreter)
      File &quot;/home/xadupre/github/experimental-experiment/experimental_experiment/xbuilder/graph_builder.py&quot;, line 3191, in process
        interpreter.run_node(node)
      File &quot;/home/xadupre/github/experimental-experiment/experimental_experiment/torch_interpreter/interpreter.py&quot;, line 116, in run_node
        res = self.call_function(node)
      File &quot;/home/xadupre/github/experimental-experiment/experimental_experiment/torch_interpreter/interpreter.py&quot;, line 923, in call_function
        raise FunctionNotFoundError(
    experimental_experiment.torch_interpreter._exceptions.FunctionNotFoundError: Unable to interpret function &lt;class &#39;torch._ops.OpOverload&#39;&gt;: &lt;OpOverload(op=&#39;aten.celu&#39;, overload=&#39;default&#39;)&gt;, searched for [&#39;aten::celu&#39;, &#39;celu_default&#39;] and attributes [&#39;__qualname__&#39;, &#39;__name__&#39;], args=(linear,), kwargs={}
    --DEBUG--
    --LOCAL FUNCTIONS--
    --SHAPE--
    dynamic_objects=
    dynamic_objects_rev=
    dynamic_dimensions_source={}
    dynamic_alias={}
    dynamic_shapes=None
    _known_value_shape={}
    _known_types={&#39;_onx_matmul0&#39;: 1,
     &#39;_onx_transpose0&#39;: 1,
     &#39;linear&#39;: 1,
     &#39;p_linear_bias&#39;: 1,
     &#39;p_linear_weight&#39;: 1,
     &#39;x&#39;: 1}
    _known_shapes={&#39;_onx_matmul0&#39;: (5, 1),
     &#39;_onx_transpose0&#39;: (3, 1),
     &#39;linear&#39;: (5, 1),
     &#39;p_linear_bias&#39;: (1,),
     &#39;p_linear_weight&#39;: (1, 3),
     &#39;x&#39;: (5, 3)}
    _known_constants=[&#39;_onx_transpose0&#39;, &#39;p_linear_bias&#39;, &#39;p_linear_weight&#39;]
    _known_ranks={}
    --TORCH-USERS--
    celu -&gt; {output}
    linear -&gt; {celu}
    p_linear_bias -&gt; {linear}
    p_linear_weight -&gt; {linear}
    x -&gt; {linear}
    --TORCH-SHAPES--
    p_linear_weight: (&#39;run_node&#39;, ((&#39;example_value&#39;, torch.float32, torch.Size([5, 1])), (&#39;val&#39;, torch.float32, torch.Size([1, 3])))) --- 1:2:(1, 3):
    p_linear_bias: (&#39;run_node&#39;, ((&#39;example_value&#39;, torch.float32, torch.Size([5, 1])), (&#39;val&#39;, torch.float32, torch.Size([1])))) --- 1:1:(1,):
    x: (&#39;run_node&#39;, (&#39;&#39;, (&#39;val&#39;, torch.float32, torch.Size([5, 3])))) --- 1:2:(5, 3):
    linear: (&#39;run_node&#39;, (&#39;&#39;, (&#39;val&#39;, torch.float32, torch.Size([5, 1])))) --- 1:2:(5, 1):
    celu: (&#39;run_node&#39;, (&#39;&#39;, (&#39;val&#39;, torch.float32, torch.Size([5, 1])))) --- :::
    --ONNX--
    -- process.graph_module --
    graph():
        %p_linear_weight : [num_users=1] = placeholder[target=p_linear_weight]
        %p_linear_bias : [num_users=1] = placeholder[target=p_linear_bias]
        %x : [num_users=1] = placeholder[target=x]
        %linear : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%x, %p_linear_weight, %p_linear_bias), kwargs = {})
        %celu : [num_users=1] = call_function[target=torch.ops.aten.celu.default](args = (%linear,), kwargs = {})
        return (celu,)
    -- process.progress --
    node 4/6 
    --
    [GraphBuilder-VVC.make_tensor_input] x[1:5x3]
    [GraphBuilder-VVC.make_initializer] p_linear_weight[torch.float32:torch.float32:[0.3692956864833832, 0.21570006012916565, -0.43409964442253113]]
    [GraphBuilder-VVC.make_initializer] p_linear_bias[torch.float32:torch.float32:[0.2567787766456604]]
    [GraphBuilder-VVC.make_node] linear          [#:#   ] Transpose:[&#39;p_linear_weight&#39;]-&gt;[&#39;_onx_transpose0&#39;]
    [GraphBuilder-VVC.make_node] Opset           [##:#  ] MatMul:[&#39;x&#39;, &#39;_onx_transpose0&#39;]-&gt;[&#39;_onx_matmul0&#39;]
    [GraphBuilder-VVC.make_node] Opset2          [##:#  ] Add:[&#39;_onx_matmul0&#39;, &#39;p_linear_bias&#39;]-&gt;[&#39;linear&#39;]
    [GraphBuilder-VVC] Message completed, there are 2 initializers, 3 nodes, 1 inputs, 1 outputs.
</pre></div>
</div>
<p>In particular, the first line of the error message. This one tells you there is currently no known
conversion of function <code class="docutils literal notranslate"><span class="pre">aten.celu</span></code>. A function <code class="docutils literal notranslate"><span class="pre">aten_celu</span></code> must be added
to the file <code class="docutils literal notranslate"><span class="pre">experimental_experiment.torch_interpreter._aten_functions</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Unable to interpret function &lt;class &#39;torch._ops.OpOverload&#39;&gt;: &lt;OpOverload(op=&#39;aten.celu&#39;, overload=&#39;default&#39;)&gt;,
searched for [&#39;aten::celu&#39;, &#39;celu_default&#39;] and attributes [&#39;__qualname__&#39;, &#39;__name__&#39;], args=(addmm,), kwargs={}
</pre></div>
</div>
<p>Below is the graph module:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">--</span> <span class="n">process</span><span class="o">.</span><span class="n">graph_module</span> <span class="o">--</span>
<span class="n">graph</span><span class="p">():</span>
    <span class="o">%</span><span class="n">arg0_1</span> <span class="p">:</span> <span class="p">[</span><span class="n">num_users</span><span class="o">=</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">placeholder</span><span class="p">[</span><span class="n">target</span><span class="o">=</span><span class="n">arg0_1</span><span class="p">]</span>
    <span class="o">%</span><span class="n">arg1_1</span> <span class="p">:</span> <span class="p">[</span><span class="n">num_users</span><span class="o">=</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">placeholder</span><span class="p">[</span><span class="n">target</span><span class="o">=</span><span class="n">arg1_1</span><span class="p">]</span>
    <span class="o">%</span><span class="n">arg2_1</span> <span class="p">:</span> <span class="p">[</span><span class="n">num_users</span><span class="o">=</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">placeholder</span><span class="p">[</span><span class="n">target</span><span class="o">=</span><span class="n">arg2_1</span><span class="p">]</span>
    <span class="o">%</span><span class="n">t</span> <span class="p">:</span> <span class="p">[</span><span class="n">num_users</span><span class="o">=</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">call_function</span><span class="p">[</span><span class="n">target</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">aten</span><span class="o">.</span><span class="n">t</span><span class="o">.</span><span class="n">default</span><span class="p">](</span><span class="n">args</span> <span class="o">=</span> <span class="p">(</span><span class="o">%</span><span class="n">arg0_1</span><span class="p">,),</span> <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{})</span>
    <span class="o">%</span><span class="n">addmm</span> <span class="p">:</span> <span class="p">[</span><span class="n">num_users</span><span class="o">=</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">call_function</span><span class="p">[</span><span class="n">target</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">aten</span><span class="o">.</span><span class="n">addmm</span><span class="o">.</span><span class="n">default</span><span class="p">](</span><span class="n">args</span> <span class="o">=</span> <span class="p">(</span><span class="o">%</span><span class="n">arg1_1</span><span class="p">,</span> <span class="o">%</span><span class="n">arg2_1</span><span class="p">,</span> <span class="o">%</span><span class="n">t</span><span class="p">),</span> <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{})</span>
    <span class="o">%</span><span class="n">celu</span> <span class="p">:</span> <span class="p">[</span><span class="n">num_users</span><span class="o">=</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">call_function</span><span class="p">[</span><span class="n">target</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">aten</span><span class="o">.</span><span class="n">celu</span><span class="o">.</span><span class="n">default</span><span class="p">](</span><span class="n">args</span> <span class="o">=</span> <span class="p">(</span><span class="o">%</span><span class="n">addmm</span><span class="p">,),</span> <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{})</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">celu</span><span class="p">,)</span>
<span class="o">--</span> <span class="n">process</span><span class="o">.</span><span class="n">progress</span> <span class="o">--</span>
<span class="n">node</span> <span class="mi">5</span><span class="o">/</span><span class="mi">7</span>
</pre></div>
</div>
<p>The last line tells you, it stopped at line 5/7 which helps to find what functions were called
before. Next is the information of all nodes added so far.
We can see that except this function, everything looks good and all shapes
are known.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">GraphBuilder</span><span class="o">-</span><span class="n">BQU</span><span class="o">.</span><span class="n">make_tensor_input</span><span class="p">]</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">5</span><span class="n">x3</span><span class="p">]</span>
<span class="p">[</span><span class="n">GraphBuilder</span><span class="o">-</span><span class="n">BQU</span><span class="o">.</span><span class="n">make_initializer</span><span class="p">]</span> <span class="n">arg0_1</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">:</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]):[</span><span class="o">-</span><span class="mf">0.44980645179748535</span><span class="p">,</span> <span class="mf">0.29780903458595276</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.32629191875457764</span><span class="p">]]</span>
<span class="p">[</span><span class="n">GraphBuilder</span><span class="o">-</span><span class="n">BQU</span><span class="o">.</span><span class="n">make_initializer</span><span class="p">]</span> <span class="n">arg1_1</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">:</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">]):[</span><span class="mf">0.2905656397342682</span><span class="p">]]</span>
<span class="p">[</span><span class="n">GraphBuilder</span><span class="o">-</span><span class="n">BQU</span><span class="o">.</span><span class="n">make_node</span><span class="p">]</span>                 <span class="p">[</span><span class="c1">#:#   ] Identity:[&#39;x&#39;]-&gt;[&#39;arg2_1&#39;]</span>
<span class="p">[</span><span class="n">GraphBuilder</span><span class="o">-</span><span class="n">BQU</span><span class="o">.</span><span class="n">make_node</span><span class="p">]</span> <span class="n">t</span>               <span class="p">[</span><span class="c1">#:#   ] Transpose:[&#39;arg0_1&#39;]-&gt;[&#39;t&#39;]</span>
<span class="p">[</span><span class="n">GraphBuilder</span><span class="o">-</span><span class="n">BQU</span><span class="o">.</span><span class="n">make_node</span><span class="p">]</span> <span class="n">addmm</span>           <span class="p">[</span><span class="c1">###:# ] Gemm:[&#39;arg2_1&#39;, &#39;t&#39;, &#39;arg1_1&#39;]-&gt;[&#39;addmm&#39;]</span>
</pre></div>
</div>
<p>There is also this section starting with <code class="docutils literal notranslate"><span class="pre">--TORCH-SHAPE--</span></code>
which shows which shapes are given by torch.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">--</span><span class="n">TORCH</span><span class="o">-</span><span class="n">SHAPES</span><span class="o">--</span>
<span class="n">arg0_1</span><span class="p">:</span> <span class="p">(</span><span class="s1">&#39;run_node&#39;</span><span class="p">,</span> <span class="p">((</span><span class="s1">&#39;example_value&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">])),</span> <span class="p">(</span><span class="s1">&#39;val&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]))))</span> <span class="o">---</span> <span class="mi">1</span><span class="p">:</span><span class="mi">2</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">):</span>
<span class="n">arg1_1</span><span class="p">:</span> <span class="p">(</span><span class="s1">&#39;run_node&#39;</span><span class="p">,</span> <span class="p">((</span><span class="s1">&#39;example_value&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">])),</span> <span class="p">(</span><span class="s1">&#39;val&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">]))))</span> <span class="o">---</span> <span class="mi">1</span><span class="p">:</span><span class="mi">1</span><span class="p">:(</span><span class="mi">1</span><span class="p">,):</span>
<span class="n">arg2_1</span><span class="p">:</span> <span class="p">(</span><span class="s1">&#39;run_node&#39;</span><span class="p">,</span> <span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="p">(</span><span class="s1">&#39;val&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">]))))</span> <span class="o">---</span> <span class="mi">1</span><span class="p">:</span><span class="mi">2</span><span class="p">:(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">):</span>
<span class="n">t</span><span class="p">:</span> <span class="p">(</span><span class="s1">&#39;run_node&#39;</span><span class="p">,</span> <span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="p">(</span><span class="s1">&#39;val&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))))</span> <span class="o">---</span> <span class="mi">1</span><span class="p">:</span><span class="mi">2</span><span class="p">:(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
<span class="n">addmm</span><span class="p">:</span> <span class="p">(</span><span class="s1">&#39;run_node&#39;</span><span class="p">,</span> <span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="p">(</span><span class="s1">&#39;val&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))))</span> <span class="o">---</span> <span class="mi">1</span><span class="p">:</span><span class="mi">2</span><span class="p">:(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
<span class="n">celu</span><span class="p">:</span> <span class="p">(</span><span class="s1">&#39;run_node&#39;</span><span class="p">,</span> <span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="p">(</span><span class="s1">&#39;val&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))))</span> <span class="o">---</span> <span class="p">:::</span>
</pre></div>
</div>
</section>
<section id="dynamic-shapes">
<h3>Dynamic Shapes<a class="headerlink" href="#dynamic-shapes" title="Link to this heading">¶</a></h3>
<p>It just needs to be added when calling function
<a class="reference internal" href="../api/onnx_export.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx"><code class="xref py py-func docutils literal notranslate"><span class="pre">to_onnx</span></code></a>:
<code class="docutils literal notranslate"><span class="pre">dynamic_shapes={&quot;x&quot;:</span> <span class="pre">{0:</span> <span class="pre">torch.export.Dim(&quot;batch&quot;)}}</span></code>.</p>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">onnx_array_api.plotting.text_plot</span> <span class="kn">import</span> <span class="n">onnx_simple_text_plot</span>
<span class="kn">from</span> <span class="nn">experimental_experiment.torch_interpreter</span> <span class="kn">import</span> <span class="n">to_onnx</span>


<span class="k">class</span> <span class="nc">Neuron</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_dims</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">n_targets</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Neuron</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_dims</span><span class="p">,</span> <span class="n">n_targets</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>


<span class="n">model</span> <span class="o">=</span> <span class="n">Neuron</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="n">onx</span> <span class="o">=</span> <span class="n">to_onnx</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="p">(</span><span class="n">x</span><span class="p">,),</span>
    <span class="n">input_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">],</span>
    <span class="n">dynamic_shapes</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;x&quot;</span><span class="p">:</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">export</span><span class="o">.</span><span class="n">Dim</span><span class="p">(</span><span class="s2">&quot;batch&quot;</span><span class="p">)}},</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">onnx_simple_text_plot</span><span class="p">(</span><span class="n">onx</span><span class="p">))</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="n">opset</span><span class="p">:</span> <span class="n">domain</span><span class="o">=</span><span class="s1">&#39;&#39;</span> <span class="n">version</span><span class="o">=</span><span class="mi">18</span>
    <span class="nb">input</span><span class="p">:</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;x&#39;</span> <span class="nb">type</span><span class="o">=</span><span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;batch&#39;</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
    <span class="n">init</span><span class="p">:</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;p_linear_weight&#39;</span> <span class="nb">type</span><span class="o">=</span><span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="o">--</span> <span class="n">array</span><span class="p">([</span> <span class="mf">0.444</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.151</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.506</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">init</span><span class="p">:</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;p_linear_bias&#39;</span> <span class="nb">type</span><span class="o">=</span><span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,)</span> <span class="o">--</span> <span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">0.252</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">Gemm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p_linear_weight</span><span class="p">,</span> <span class="n">transA</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">transB</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">_onx_matmul0</span>
      <span class="n">Add</span><span class="p">(</span><span class="n">_onx_matmul0</span><span class="p">,</span> <span class="n">p_linear_bias</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">linear</span>
        <span class="n">Sigmoid</span><span class="p">(</span><span class="n">linear</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">output_0</span>
    <span class="n">output</span><span class="p">:</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;output_0&#39;</span> <span class="nb">type</span><span class="o">=</span><span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;batch&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</section>
<section id="fallback">
<h3>Fallback<a class="headerlink" href="#fallback" title="Link to this heading">¶</a></h3>
<p>The current library does not always have a converting function
for evert aten functions implemented in torch. A mechanism exists
to intercept the function returned by the interpreter and replace it
by a function coming from another source such as <a class="reference external" href="https://github.com/microsoft/onnxscript">onnxscript</a>.</p>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">onnx_array_api.plotting.text_plot</span> <span class="kn">import</span> <span class="n">onnx_simple_text_plot</span>
<span class="kn">from</span> <span class="nn">experimental_experiment.torch_interpreter</span> <span class="kn">import</span> <span class="n">to_onnx</span>
<span class="kn">from</span> <span class="nn">experimental_experiment.torch_interpreter.oxs_dispatcher</span> <span class="kn">import</span> <span class="n">OxsDispatcher</span>


<span class="k">class</span> <span class="nc">Neuron</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_dims</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">n_targets</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Neuron</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_dims</span><span class="p">,</span> <span class="n">n_targets</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">celu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>


<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Neuron</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">onx</span> <span class="o">=</span> <span class="n">to_onnx</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,),</span> <span class="n">input_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">],</span> <span class="n">dispatcher</span><span class="o">=</span><span class="n">OxsDispatcher</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="n">onnx_simple_text_plot</span><span class="p">(</span><span class="n">onx</span><span class="p">))</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="n">opset</span><span class="p">:</span> <span class="n">domain</span><span class="o">=</span><span class="s1">&#39;&#39;</span> <span class="n">version</span><span class="o">=</span><span class="mi">18</span>
    <span class="nb">input</span><span class="p">:</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;x&#39;</span> <span class="nb">type</span><span class="o">=</span><span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
    <span class="n">init</span><span class="p">:</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;p_linear_weight&#39;</span> <span class="nb">type</span><span class="o">=</span><span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="o">--</span> <span class="n">array</span><span class="p">([</span> <span class="mf">0.11</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.296</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.417</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">init</span><span class="p">:</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;p_linear_bias&#39;</span> <span class="nb">type</span><span class="o">=</span><span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,)</span> <span class="o">--</span> <span class="n">array</span><span class="p">([</span><span class="mf">0.271</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">Gemm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p_linear_weight</span><span class="p">,</span> <span class="n">transA</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">transB</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">_onx_matmul0</span>
      <span class="n">Add</span><span class="p">(</span><span class="n">_onx_matmul0</span><span class="p">,</span> <span class="n">p_linear_bias</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">linear</span>
        <span class="n">Celu</span><span class="p">(</span><span class="n">linear</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.00</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">output_0</span>
    <span class="n">output</span><span class="p">:</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;output_0&#39;</span> <span class="nb">type</span><span class="o">=</span><span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</section>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="optimizer.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Pattern Optimizer</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="index.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Design</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2023-2024
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Custom Exporter</a><ul>
<li><a class="reference internal" href="#one-objective-speed">One objective: SPEED</a></li>
<li><a class="reference internal" href="#graphbuilder">GraphBuilder</a><ul>
<li><a class="reference internal" href="#internal-containers">Internal containers</a></li>
<li><a class="reference internal" href="#api">API</a></li>
<li><a class="reference internal" href="#example">Example</a></li>
<li><a class="reference internal" href="#debugging">Debugging</a></li>
<li><a class="reference internal" href="#simplified-api">Simplified API</a></li>
<li><a class="reference internal" href="#optimizations">Optimizations</a></li>
</ul>
</li>
<li><a class="reference internal" href="#dynamointerpreter">DynamoInterpreter</a><ul>
<li><a class="reference internal" href="#a-converting-function">A converting function</a></li>
<li><a class="reference internal" href="#shapes-and-types">Shapes And Types</a></li>
<li><a class="reference internal" href="#different-implementations">Different Implementations</a></li>
<li><a class="reference internal" href="#conventions">Conventions</a></li>
<li><a class="reference internal" href="#functions">Functions</a></li>
</ul>
</li>
<li><a class="reference internal" href="#pratice">Pratice</a><ul>
<li><a class="reference internal" href="#id1">Example</a></li>
<li><a class="reference internal" href="#id2">Debugging</a></li>
<li><a class="reference internal" href="#dynamic-shapes">Dynamic Shapes</a></li>
<li><a class="reference internal" href="#fallback">Fallback</a></li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../_static/documentation_options.js?v=a1637f0b"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/furo.js?v=5fa4622c"></script>
    </body>
</html>