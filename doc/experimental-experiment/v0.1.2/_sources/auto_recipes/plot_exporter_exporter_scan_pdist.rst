
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_recipes/plot_exporter_exporter_scan_pdist.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_recipes_plot_exporter_exporter_scan_pdist.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_recipes_plot_exporter_exporter_scan_pdist.py:


.. _l-plot-exporter-exporter-pdist:

Export a model with a loop (scan)
=================================

Control flow cannot be exported with a change.
The code of the model can be changed or patched
to introduce function :func:`torch.ops.higher_order.scan`.

Pairwise Distance
+++++++++++++++++

We appy loops to the pairwise distances (:class:`torch.nn.PairwiseDistance`).

.. GENERATED FROM PYTHON SOURCE LINES 16-38

.. code-block:: Python


    import scipy.spatial.distance as spd
    import torch


    class ModuleWithControlFlowLoop(torch.nn.Module):
        def forward(self, x, y):
            dist = torch.empty((x.shape[0], y.shape[0]), dtype=x.dtype)
            for i in range(x.shape[0]):
                sub = y - x[i : i + 1]
                d = torch.sqrt((sub * sub).sum(axis=1))
                dist[i, :] = d
            return dist


    model = ModuleWithControlFlowLoop()
    x = torch.randn(3, 4)
    y = torch.randn(5, 4)
    pwd = spd.cdist(x.numpy(), y.numpy())
    expected = torch.from_numpy(pwd)
    print(f"shape={pwd.shape}, discrepancies={torch.abs(expected - model(x,y)).max()}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    shape=(3, 5), discrepancies=2.2679853550755524e-07




.. GENERATED FROM PYTHON SOURCE LINES 39-41

:func:`torch.export.export` works because it unrolls the loop.
It works if the input size never change.

.. GENERATED FROM PYTHON SOURCE LINES 41-46

.. code-block:: Python



    ep = torch.export.export(model, (x, y))
    print(ep.graph)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    graph():
        %x : [num_users=3] = placeholder[target=x]
        %y : [num_users=3] = placeholder[target=y]
        %empty : [num_users=4] = call_function[target=torch.ops.aten.empty.memory_format](args = ([3, 5],), kwargs = {dtype: torch.float32, device: cpu, pin_memory: False})
        %slice_1 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%x, 0, 0, 1), kwargs = {})
        %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%y, %slice_1), kwargs = {})
        %mul : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub, %sub), kwargs = {})
        %sum_1 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul, [1]), kwargs = {})
        %sqrt : [num_users=1] = call_function[target=torch.ops.aten.sqrt.default](args = (%sum_1,), kwargs = {})
        %select : [num_users=1] = call_function[target=torch.ops.aten.select.int](args = (%empty, 0, 0), kwargs = {})
        %copy_ : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%select, %sqrt), kwargs = {})
        %slice_2 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%x, 0, 1, 2), kwargs = {})
        %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%y, %slice_2), kwargs = {})
        %mul_1 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_1, %sub_1), kwargs = {})
        %sum_2 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_1, [1]), kwargs = {})
        %sqrt_1 : [num_users=1] = call_function[target=torch.ops.aten.sqrt.default](args = (%sum_2,), kwargs = {})
        %select_1 : [num_users=1] = call_function[target=torch.ops.aten.select.int](args = (%empty, 0, 1), kwargs = {})
        %copy__1 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%select_1, %sqrt_1), kwargs = {})
        %slice_3 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%x, 0, 2, 3), kwargs = {})
        %sub_2 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%y, %slice_3), kwargs = {})
        %mul_2 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_2, %sub_2), kwargs = {})
        %sum_3 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_2, [1]), kwargs = {})
        %sqrt_2 : [num_users=1] = call_function[target=torch.ops.aten.sqrt.default](args = (%sum_3,), kwargs = {})
        %select_2 : [num_users=1] = call_function[target=torch.ops.aten.select.int](args = (%empty, 0, 2), kwargs = {})
        %copy__2 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%select_2, %sqrt_2), kwargs = {})
        return (empty,)




.. GENERATED FROM PYTHON SOURCE LINES 47-48

However, with dynamic shapes, that's another story.

.. GENERATED FROM PYTHON SOURCE LINES 48-60

.. code-block:: Python


    x_rows = torch.export.Dim("x_rows")
    y_rows = torch.export.Dim("y_rows")
    dim = torch.export.Dim("dim")
    try:
        ep = torch.export.export(
            model, (x, y), dynamic_shapes={"x": {0: x_rows, 1: dim}, "y": {0: y_rows, 1: dim}}
        )
        print(ep.graph)
    except Exception as e:
        print(e)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Constraints violated (x_rows)! For more information, run with TORCH_LOGS="+dynamic".
      - You marked x_rows as dynamic but your code specialized it to be a constant (3). If you're using mark_dynamic, either remove it or use maybe_mark_dynamic. If you're using Dim.DYNAMIC, replace it with either Dim.STATIC or Dim.AUTO.
    Suggested fixes:
      x_rows = 3

    The error above occurred when calling torch.export.export. If you would like to view some more information about this error, and get a list of all other errors that may occur in your export call, you can replace your `export()` call with `draft_export()`.




.. GENERATED FROM PYTHON SOURCE LINES 61-66

Suggested Patch
+++++++++++++++

We need to rewrite the module with function
:func:`torch.ops.higher_order.scan`.

.. GENERATED FROM PYTHON SOURCE LINES 66-88

.. code-block:: Python



    def dist(y: torch.Tensor, scanned_x: torch.Tensor):
        sub = y - scanned_x.reshape((1, -1))
        sq = sub * sub
        rd = torch.sqrt(sq.sum(axis=1))
        # clone --> UnsupportedAliasMutationException:
        # Combine_fn might be aliasing the input!
        return [y.clone(), rd]


    class ModuleWithControlFlowLoopScan(torch.nn.Module):

        def forward(self, x, y):
            _carry, out = torch.ops.higher_order.scan(dist, [y], [x], additional_inputs=[])
            return out


    model = ModuleWithControlFlowLoopScan()
    model_output = model(x, y)
    print(f"shape={pwd.shape}, discrepancies={torch.abs(expected - model_output).max()}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    shape=(3, 5), discrepancies=2.2679853550755524e-07




.. GENERATED FROM PYTHON SOURCE LINES 89-90

That works. Let's export again.

.. GENERATED FROM PYTHON SOURCE LINES 90-95

.. code-block:: Python


    ep = torch.export.export(
        model, (x, y), dynamic_shapes={"x": {0: x_rows, 1: dim}, "y": {0: y_rows, 1: dim}}
    )
    print(ep.graph)




.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    graph():
        %x : [num_users=1] = placeholder[target=x]
        %y : [num_users=1] = placeholder[target=y]
        %scan_combine_graph_0 : [num_users=1] = get_attr[target=scan_combine_graph_0]
        %scan : [num_users=2] = call_function[target=torch.ops.higher_order.scan](args = (%scan_combine_graph_0, [%y], [%x], ()), kwargs = {})
        %getitem : [num_users=0] = call_function[target=operator.getitem](args = (%scan, 0), kwargs = {})
        %getitem_1 : [num_users=1] = call_function[target=operator.getitem](args = (%scan, 1), kwargs = {})
        return (getitem_1,)





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 0.352 seconds)


.. _sphx_glr_download_auto_recipes_plot_exporter_exporter_scan_pdist.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_exporter_exporter_scan_pdist.ipynb <plot_exporter_exporter_scan_pdist.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_exporter_exporter_scan_pdist.py <plot_exporter_exporter_scan_pdist.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_exporter_exporter_scan_pdist.zip <plot_exporter_exporter_scan_pdist.zip>`


.. include:: plot_exporter_exporter_scan_pdist.recommendations


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
