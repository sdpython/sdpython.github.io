<!doctype html>
<html class="no-js" lang="en" data-content_root="../">
  <head><meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../genindex.html"><link rel="search" title="Search" href="../search.html"><link rel="next" title="Export Phi-3.5-mini-instruct with draft_export" href="plot_exporter_exporter_draft_mode.html"><link rel="prev" title="Check the exporter on a dummy from HuggingFace" href="plot_exporter_exporter_untrained_tinyllm.html">
        <link rel="prefetch" href="../_static/logo.png" as="image">

    <!-- Generated with Sphinx 8.2.3 and Furo 2025.09.25 -->
        <title>Export Phi-3.5-mini-instruct piece by piece - experimental-experiment 0.1.2 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=580074bf" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css?v=4ae1632d" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=8dab3a3b" />
    
    


<style>
  body {
    --color-code-background: #eeffcc;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle site navigation sidebar">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc" aria-label="Toggle table of contents sidebar">
<label class="overlay sidebar-overlay" for="__navigation"></label>
<label class="overlay toc-overlay" for="__toc"></label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <span class="icon"><svg><use href="#svg-menu"></use></svg></span>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">experimental-experiment 0.1.2 documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle" aria-label="Toggle Light / Dark / Auto color theme">
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <span class="icon"><svg><use href="#svg-toc"></use></svg></span>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="../_static/logo.png" alt="Logo"/>
  </div>
  
  <span class="sidebar-brand-text">experimental-experiment 0.1.2 documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Contents</span></p>
<ul class="current">
<li class="toctree-l1 has-children"><a class="reference internal" href="../design/index.html">Design</a><input aria-label="Toggle navigation of Design" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../design/exporter.html">Custom Exporter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../design/optimizer.html">Pattern Optimizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../design/backends.html">Dynamo Backends</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../tutorial/index.html">Tutorial</a><input aria-label="Toggle navigation of Tutorial" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../tutorial/shape.html">ShapeBuilder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorial/to_onnx.html">to_onnx: another export to investigate</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorial/errors.html">Unexpected Errors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorial/docker.html">Start from a docker</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api/index.html">API</a><input aria-label="Toggle navigation of API" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/gradient/index.html">.gradient</a><input aria-label="Toggle navigation of .gradient" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/gradient/ops/index.html">.gradient.ops</a><input aria-label="Toggle navigation of .gradient.ops" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/gradient/ops/op_broadcast_gradient_args.html">.gradient.ops.op_broadcast_gradient_args</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api/gradient/grad_helper.html">.gradient.grad_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/gradient/loss_helper.html">.gradient.loss_helper</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/reference/index.html">.reference</a><input aria-label="Toggle navigation of .reference" class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/reference/ops/index.html">.reference.ops</a><input aria-label="Toggle navigation of .reference.ops" class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_add_add_mul_mul.html">.reference.ops.op_add_add_mul_mul</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_average_pool_grad.html">.reference.ops.op_average_pool_grad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_cast_like.html">.reference.ops.op_cast_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_complex.html">.reference.ops.op_complex</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_concat.html">.reference.ops.op_concat</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_constant_of_shape.html">.reference.ops.op_constant_of_shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_fused_matmul.html">.reference.ops.op_fused_matmul</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_gather_grad.html">.reference.ops.op_gather_grad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_memcpy_host.html">.reference.ops.op_memcpy_host</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_mul_sigmoid.html">.reference.ops.op_mul_sigmoid</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_negxplus1.html">.reference.ops.op_negxplus1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_quick_gelu.html">.reference.ops.op_quick_gelu</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_replace_zero.html">.reference.ops.op_replace_zero</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_rotary.html">.reference.ops.op_rotary</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_qlinear_average_pool.html">.reference.ops.op_qlinear_average_pool</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_qlinear_conv.html">.reference.ops.op_qlinear_conv</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_scatter_elements.html">.reference.ops.op_scatter_elements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_scatternd_of_shape.html">.reference.ops.op_scatternd_of_shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_simplified_layer_normalization.html">.reference.ops.op_simplified_layer_normalization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_skip_layer_normalization.html">.reference.ops.op_skip_layer_normalization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_slice.html">.reference.ops.op_slice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_transpose_cast.html">.reference.ops.op_transpose_cast</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_tri_matrix.html">.reference.ops.op_tri_matrix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api/reference/evaluator.html">.reference.evaluator</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/reference/ort_evaluator.html">.reference.ort_evaluator</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/reference/quantized_tensor.html">.reference.quantized_tensor</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/convert/index.html">.convert</a><input aria-label="Toggle navigation of .convert" class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/convert/convert_helper.html">.convert.convert_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/convert/ort_helper.html">.convert.ort_helper</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/plotting/index.html">.plotting</a><input aria-label="Toggle navigation of .plotting" class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/plotting/data.html">.plotting.data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/plotting/memory.html">.plotting.memory</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/skl/index.html">.skl</a><input aria-label="Toggle navigation of .skl" class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/skl/convert.html">.skl.convert</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/skl/helpers.html">.skl.helpers</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/torch_interpreter/index.html">.torch_interpreter</a><input aria-label="Toggle navigation of .torch_interpreter" class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/_aten_functions.html">.torch_interpreter._aten_functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/_aten_functions_attention.html">.torch_interpreter._aten_functions_attention</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/_non_aten_functions.html">.torch_interpreter._non_aten_functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/_aten_methods.html">.torch_interpreter._aten_methods</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/_doc_.html">.torch_interpreter._doc_</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/_exceptions.html">.torch_interpreter._exceptions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/_prims_functions.html">.torch_interpreter._prims_functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/_torch_helper.html">.torch_interpreter._torch_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/aten_functions.html">.torch_interpreter.aten_functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/aten_methods.html">.torch_interpreter.aten_methods</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/dispatcher.html">.torch_interpreter.dispatcher</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/export_options.html">.torch_interpreter.export_options</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/interpreter.html">.torch_interpreter.interpreter</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/investigate_helper.html">.torch_interpreter.investigate_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/onnx_export.html">.torch_interpreter.onnx_export</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/oxs_dispatcher.html">.torch_interpreter.oxs_dispatcher</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/oxs_opset.html">.torch_interpreter.oxs_opset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/piece_by_piece.html">.torch_interpreter.piece_by_piece</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/piece_by_piece_serialize.html">.torch_interpreter.piece_by_piece_serialize</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/tracing.html">.torch_interpreter.tracing</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/torch_models/index.html">.torch_models</a><input aria-label="Toggle navigation of .torch_models" class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_models/dump_helper.html">.torch_models.dump_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_models/training_helper.html">.torch_models.training_helper</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/xbuilder/index.html">.xbuilder</a><input aria-label="Toggle navigation of .xbuilder" class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" role="switch" type="checkbox"/><label for="toctree-checkbox-13"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/xbuilder/_onnx_helper.html">.xbuilder._onnx_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xbuilder/graph_builder.html">.xbuilder.graph_builder</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xbuilder/graph_builder_opset.html">.xbuilder.graph_builder_opset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xbuilder/model_container.html">.xbuilder.model_container</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xbuilder/optimization_options.html">.xbuilder.optimization_options</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xbuilder/reverse_graph_builder.html">.xbuilder.reverse_graph_builder</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/xoptim/index.html">.xoptim</a><input aria-label="Toggle navigation of .xoptim" class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" role="switch" type="checkbox"/><label for="toctree-checkbox-14"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/xoptim/patterns_investigation/index.html">.xoptim.patterns_investigation</a><input aria-label="Toggle navigation of .xoptim.patterns_investigation" class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" role="switch" type="checkbox"/><label for="toctree-checkbox-15"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_investigation/element_wise.html">.xoptim.patterns_investigation.element_wise</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_investigation/llm_patterns.html">.xoptim.patterns_investigation.llm_patterns</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/xoptim/patterns_ml/index.html">.xoptim.patterns_ml</a><input aria-label="Toggle navigation of .xoptim.patterns_ml" class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" role="switch" type="checkbox"/><label for="toctree-checkbox-16"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ml/tree_ensemble.html">.xoptim.patterns_ml.tree_ensemble</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/xoptim/patterns_exp/index.html">.xoptim.patterns_exp</a><input aria-label="Toggle navigation of .xoptim.patterns_exp" class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" role="switch" type="checkbox"/><label for="toctree-checkbox-17"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_exp/binary_operators.html">.xoptim.patterns_exp.binary_operators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_exp/constant_of_shape_scatter_nd.html">.xoptim.patterns_exp.constant_of_shape_scatter_nd</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_exp/constants.html">.xoptim.patterns_exp.constants</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_exp/simple_rotary.html">.xoptim.patterns_exp.simple_rotary</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_exp/unary_operators.html">.xoptim.patterns_exp.unary_operators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_exp/where_replace.html">.xoptim.patterns_exp.where_replace</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/xoptim/patterns/index.html">.xoptim.patterns</a><input aria-label="Toggle navigation of .xoptim.patterns" class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" role="switch" type="checkbox"/><label for="toctree-checkbox-18"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_any.html">.xoptim.patterns.onnx_any</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_attention.html">.xoptim.patterns.onnx_attention</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_cast.html">.xoptim.patterns.onnx_cast</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_clip.html">.xoptim.patterns.onnx_clip</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_constants.html">.xoptim.patterns.onnx_constants</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_conv.html">.xoptim.patterns.onnx_conv</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_concat.html">.xoptim.patterns.onnx_concat</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_dropout.html">.xoptim.patterns.onnx_dropout</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_equal.html">.xoptim.patterns.onnx_equal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_expand.html">.xoptim.patterns.onnx_expand</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_functions.html">.xoptim.patterns.onnx_functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_layer_normalization.html">.xoptim.patterns.onnx_layer_normalization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_matmul.html">.xoptim.patterns.onnx_matmul</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_mul.html">.xoptim.patterns.onnx_mul</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_reduce.html">.xoptim.patterns.onnx_reduce</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_reshape.html">.xoptim.patterns.onnx_reshape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_rotary.html">.xoptim.patterns.onnx_rotary</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_shape.html">.xoptim.patterns.onnx_shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_slice.html">.xoptim.patterns.onnx_slice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_split.html">.xoptim.patterns.onnx_split</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_sub.html">.xoptim.patterns.onnx_sub</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_sequence.html">.xoptim.patterns.onnx_sequence</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_transpose.html">.xoptim.patterns.onnx_transpose</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_unsqueeze.html">.xoptim.patterns.onnx_unsqueeze</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/xoptim/patterns_ort/index.html">.xoptim.patterns_ort</a><input aria-label="Toggle navigation of .xoptim.patterns_ort" class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" role="switch" type="checkbox"/><label for="toctree-checkbox-19"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ort/activation.html">.xoptim.patterns_ort.activation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ort/activation_grad.html">.xoptim.patterns_ort.activation_grad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ort/batch_normalization.html">.xoptim.patterns_ort.batch_normalization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ort/fused_conv.html">.xoptim.patterns_ort.fused_conv</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ort/fused_matmul.html">.xoptim.patterns_ort.fused_matmul</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ort/gather_grad.html">.xoptim.patterns_ort.gather_grad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ort/llm_optim.html">.xoptim.patterns_ort.llm_optim</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ort/missing_kernels.html">.xoptim.patterns_ort.missing_kernels</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ort/simplified_layer_normalization.html">.xoptim.patterns_ort.simplified_layer_normalization</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/xoptim/patterns_fix/index.html">.xoptim.patterns_fix</a><input aria-label="Toggle navigation of .xoptim.patterns_fix" class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" role="switch" type="checkbox"/><label for="toctree-checkbox-20"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_fix/add_reduction_scatter_nd.html">.xoptim.patterns_fix.add_reduction_scatter_nd</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api/xoptim/graph_builder_optim.html">.xoptim.graph_builder_optim</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xoptim/order_optim.html">.xoptim.order_optim</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xoptim/patterns_api.html">.xoptim.patterns_api</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xoptim/repeated_optim.html">.xoptim.repeated_optim</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xoptim/unfused.html">.xoptim.unfused</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/xshape/index.html">.xshape</a><input aria-label="Toggle navigation of .xshape" class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" role="switch" type="checkbox"/><label for="toctree-checkbox-21"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/xshape/expressions_torch.html">.xshape.expressions_torch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xshape/evaluate_expressions.html">.xshape.evaluate_expressions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xshape/rename_expressions.html">.xshape.rename_expressions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xshape/simplify_expressions.html">.xshape.simplify_expressions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xshape/_builder_runtime.html">.xshape._builder_runtime</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xshape/_inference_runtime.html">.xshape._inference_runtime</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xshape/_shape_runtime.html">.xshape._shape_runtime</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xshape/_shape_helper.html">.xshape._shape_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xshape/_onnx_helper.html">.xshape._onnx_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xshape/shape_builder.html">.xshape.shape_builder</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xshape/shape_builder_impl.html">.xshape.shape_builder_impl</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xshape/shape_type_compute.html">.xshape.shape_type_compute</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xshape/type_inference.html">.xshape.type_inference</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/torch_dynamo/index.html">.torch_dynamo</a><input aria-label="Toggle navigation of .torch_dynamo" class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" role="switch" type="checkbox"/><label for="toctree-checkbox-22"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_dynamo/_dynamo_exporter.html">.torch_dynamo._dynamo_exporter</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_dynamo/backend_helper.html">.torch_dynamo.backend_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_dynamo/debug_backend.html">.torch_dynamo.debug_backend</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_dynamo/fast_backend.html">.torch_dynamo.fast_backend</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_dynamo/partition.html">experimental_experiment.torch_dynamo.partition</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/torch_bench/index.html">.torch_bench</a><input aria-label="Toggle navigation of .torch_bench" class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" role="switch" type="checkbox"/><label for="toctree-checkbox-23"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_benchmark_runner.html">experimental_experiment.torch_bench._bash_bench_benchmark_runner</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_benchmark_runner_agg.html">experimental_experiment.torch_bench._bash_bench_benchmark_runner_agg</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_benchmark_runner_agg_helper.html">experimental_experiment.torch_bench._bash_bench_benchmark_runner_agg_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_cmd.html">experimental_experiment.torch_bench._bash_bench_cmd</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_model_runner.html">experimental_experiment.torch_bench._bash_bench_model_runner</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_models_helper.html">experimental_experiment.torch_bench._bash_bench_models_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_set_dummies.html">experimental_experiment.torch_bench._bash_bench_set_dummies</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_set_explicit.html">experimental_experiment.torch_bench._bash_bench_set_explicit</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_set_huggingface.html">experimental_experiment.torch_bench._bash_bench_set_huggingface</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_set_timm.html">experimental_experiment.torch_bench._bash_bench_set_timm</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_set_torchbench.html">experimental_experiment.torch_bench._bash_bench_set_torchbench</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_set_torchbench_ado.html">experimental_experiment.torch_bench._bash_bench_set_torchbench_ado</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_untrained.html">experimental_experiment.torch_bench._bash_bench_untrained</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_dort_cmd_common.html">experimental_experiment.torch_bench._dort_cmd_common</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_dort_cmd_common_models.html">experimental_experiment.torch_bench._dort_cmd_common_models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/bash_bench_agg.html">.torch_bench.bash_bench_agg</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/bash_bench_explicit.html">.torch_bench.bash_bench_explicit</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/bash_bench_huggingface.html">.torch_bench.bash_bench_huggingface</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/bash_bench_timm.html">.torch_bench.bash_bench_timm</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/bash_bench_torchbench.html">.torch_bench.bash_bench_torchbench</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/bash_bench_torchbench_ado.html">.torch_bench.bash_bench_torchbench_ado</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/bash_bench_untrained.html">.torch_bench.bash_bench_untrained</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/check_model.html">.torch_bench.check_model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/dort_bench.html">.torch_bench.dort_bench</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/dort_bench_profile.html">.torch_bench.dort_bench_profile</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/dort_profile.html">.torch_bench.dort_profile</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/export_model.html">.torch_bench.export_model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/export_model_helper.html">.torch_bench.export_model_helper</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api/_bench_test.html">._bench_test</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/_command_lines_parser.html">._command_lines_parser</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/args.html">.args</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bench_run.html">.bench_run</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/checks.html">.checks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/export_helpers.html">.export_helpers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/ext_test_case.html">.ext_test_case</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/helpers.html">.helpers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/memory_peak.html">.memory_peak</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/model_run.html">.model_run</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/onnx_tools.html">.onnx_tools</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/ort_session.html">.ort_session</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/torch_test_helper.html">.torch_test_helper</a></li>
</ul>
</li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="../galleries.html">Galleries of Examples and Recipes</a><input aria-label="Toggle navigation of Galleries of Examples and Recipes" checked="" class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" role="switch" type="checkbox"/><label for="toctree-checkbox-24"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul class="current">
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/index.html">Examples Gallery</a><input aria-label="Toggle navigation of Examples Gallery" class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" role="switch" type="checkbox"/><label for="toctree-checkbox-25"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_custom_backend_101.html">101: A custom backend for torch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_linreg_101.html">101: Linear Regression and export to ONNX</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_optimize_101.html">101: Onnx Model Optimization based on Pattern Rewriting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_rewrite_101.html">101: Onnx Model Rewriting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_profile_existing_onnx_101.html">101: Profile an existing model with onnxruntime</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_export_101.html">101: Some dummy examples with torch.export.export</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_onnxscript_102.html">102: Examples with onnxscript</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_executorch_102.html">102: First test with ExecuTorch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_export_compile_102.html">102: Tweak onnx export</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_shape_inference.html">201: Better shape inference</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_export_201.html">201: Evaluate different ways to export a torch model to ONNX</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_sklearn_201.html">201: Use torch to export a scikit-learn model into ONNX</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_model_to_python.html">Playground for big optimization pattern</a></li>
</ul>
</li>
<li class="toctree-l2 current has-children"><a class="reference internal" href="index.html">Exporter Recipes Gallery</a><input aria-label="Toggle navigation of Exporter Recipes Gallery" checked="" class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" role="switch" type="checkbox"/><label for="toctree-checkbox-26"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_exporter_untrained_tinyllm.html">Check the exporter on a dummy from HuggingFace</a></li>
<li class="toctree-l3 current current-page"><a class="current reference internal" href="#">Export Phi-3.5-mini-instruct piece by piece</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_exporter_draft_mode.html">Export Phi-3.5-mini-instruct with draft_export</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_exporter_reportibility.html">Export Phi-3.5-mini-instruct with report_exportability</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_exporter_scan_pdist.html">Export a model with a loop (scan)</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_recipes_c_custom_ops_inplace.html">to_onnx and a custom operator inplace</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_recipes_c_custom_ops_fct.html">to_onnx and a custom operator registered with a function</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_recipes_c_cond.html">to_onnx and a model with a test</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_recipes_c_dynpad.html">to_onnx and padding one dimension to a mulitple of a constant</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_recipes_c_modules.html">to_onnx and submodules from LLMs</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../command_lines.html">Command Lines</a><input aria-label="Toggle navigation of Command Lines" class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" role="switch" type="checkbox"/><label for="toctree-checkbox-27"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../bench/index.html">Benchmarks from the command line</a><input aria-label="Toggle navigation of Benchmarks from the command line" class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" role="switch" type="checkbox"/><label for="toctree-checkbox-28"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../bench/dort_bench.html">experimental_experiment.torch_bench.dort_bench</a></li>
<li class="toctree-l3"><a class="reference internal" href="../bench/dort_profile.html">experimental_experiment.torch_bench.dort_profile</a></li>
<li class="toctree-l3"><a class="reference internal" href="../bench/scripts.html">Interesting scripts or command lines</a></li>
<li class="toctree-l3"><a class="reference internal" href="../bench/bash_bench.html">Measuring the exporters on a short list of sets of models</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../tools/index.html">Tools from the command line</a><input aria-label="Toggle navigation of Tools from the command line" class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" role="switch" type="checkbox"/><label for="toctree-checkbox-29"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../tools/lighten.html">python -m experimental_experiment lighten and unlighten</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tools/optimize.html">python -m experimental_experiment optimize</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tools/print.html">python -m experimental_experiment print</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tools/run.html">python -m experimental_experiment run</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../miscellaneous/index.html">Miscellaneous</a><input aria-label="Toggle navigation of Miscellaneous" class="toctree-checkbox" id="toctree-checkbox-30" name="toctree-checkbox-30" role="switch" type="checkbox"/><label for="toctree-checkbox-30"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../miscellaneous/export_times.html">Export Times</a></li>
<li class="toctree-l2"><a class="reference internal" href="../miscellaneous/long_outputs.html">Long Outputs uneasy to read</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">More</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="../_sources/auto_recipes/plot_exporter_exporter_phi35_piece.rst" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle" aria-label="Toggle Light / Dark / Auto color theme">
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <span class="icon"><svg><use href="#svg-toc"></use></svg></span>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-auto-recipes-plot-exporter-exporter-phi35-piece-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="export-phi-3-5-mini-instruct-piece-by-piece">
<span id="l-plot-exporter-exporter-phi35-piece"></span><span id="sphx-glr-auto-recipes-plot-exporter-exporter-phi35-piece-py"></span><h1>Export Phi-3.5-mini-instruct piece by piece<a class="headerlink" href="#export-phi-3-5-mini-instruct-piece-by-piece" title="Link to this heading"></a></h1>
<p><a class="reference external" href="https://docs.pytorch.org/docs/stable/export/api_reference.html#torch.export.export" title="(in PyTorch v2.9)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.export.export()</span></code></a> often breaks on big models because there
are control flows or instructions breaking the propagation of
dynamic shapes (see ). The function usually gives an indication where
the model implementation can be fixed but in case, that is not possible,
we can try to export the model piece by piece: every module
is converted separately from its submodule. A model can be exported even
if one of its submodules cannot.</p>
<section id="model">
<h2>Model<a class="headerlink" href="#model" title="Link to this heading"></a></h2>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pprint</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <a href="https://docs.python.org/3/library/typing.html#typing.Any" title="typing.Any" class="sphx-glr-backref-module-typing sphx-glr-backref-type-py-data"><a href="https://docs.python.org/3/library/typing.html#typing.Any" title="typing.Any" class="sphx-glr-backref-module-typing sphx-glr-backref-type-py-data"><span class="n">Any</span></a></a><span class="p">,</span> <a href="https://docs.python.org/3/library/typing.html#typing.Dict" title="typing.Dict" class="sphx-glr-backref-module-typing sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/typing.html#typing.Dict" title="typing.Dict" class="sphx-glr-backref-module-typing sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">Dict</span></a></a>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch._export.tools</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">transformers</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">onnx_diagnostic.helpers.cache_helper</span><span class="w"> </span><span class="kn">import</span> <a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/cache_helper.html#onnx_diagnostic.helpers.cache_helper.make_dynamic_cache" title="onnx_diagnostic.helpers.cache_helper.make_dynamic_cache" class="sphx-glr-backref-module-onnx_diagnostic-helpers-cache_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/cache_helper.html#onnx_diagnostic.helpers.cache_helper.make_dynamic_cache" title="onnx_diagnostic.helpers.cache_helper.make_dynamic_cache" class="sphx-glr-backref-module-onnx_diagnostic-helpers-cache_helper sphx-glr-backref-type-py-function"><span class="n">make_dynamic_cache</span></a></a>
<span class="kn">from</span><span class="w"> </span><span class="nn">experimental_experiment.helpers</span><span class="w"> </span><span class="kn">import</span> <a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/helpers.html#experimental_experiment.helpers.string_type" title="experimental_experiment.helpers.string_type" class="sphx-glr-backref-module-experimental_experiment-helpers sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/helpers.html#experimental_experiment.helpers.string_type" title="experimental_experiment.helpers.string_type" class="sphx-glr-backref-module-experimental_experiment-helpers sphx-glr-backref-type-py-function"><span class="n">string_type</span></a></a>
<span class="kn">from</span><span class="w"> </span><span class="nn">experimental_experiment.torch_interpreter.piece_by_piece</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/piece_by_piece.html#experimental_experiment.torch_interpreter.piece_by_piece.trace_execution_piece_by_piece" title="experimental_experiment.torch_interpreter.piece_by_piece.trace_execution_piece_by_piece" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter-piece_by_piece sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/piece_by_piece.html#experimental_experiment.torch_interpreter.piece_by_piece.trace_execution_piece_by_piece" title="experimental_experiment.torch_interpreter.piece_by_piece.trace_execution_piece_by_piece" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter-piece_by_piece sphx-glr-backref-type-py-function"><span class="n">trace_execution_piece_by_piece</span></a></a><span class="p">,</span>
<span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">get_phi35_untrained</span><span class="p">(</span><span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <a href="https://docs.python.org/3/library/typing.html#typing.Dict" title="typing.Dict" class="sphx-glr-backref-module-typing sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/typing.html#typing.Dict" title="typing.Dict" class="sphx-glr-backref-module-typing sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">Dict</span></a></a><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <a href="https://docs.python.org/3/library/typing.html#typing.Any" title="typing.Any" class="sphx-glr-backref-module-typing sphx-glr-backref-type-py-data"><a href="https://docs.python.org/3/library/typing.html#typing.Any" title="typing.Any" class="sphx-glr-backref-module-typing sphx-glr-backref-type-py-data"><span class="n">Any</span></a></a><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Gets a non initialized model with two sets of inputs and different shapes.</span>

<span class="sd">    :param batch_size: batch size</span>
<span class="sd">    :param kwargs: to overwrite the configuration, example ``num_hidden_layers=1``</span>
<span class="sd">    :return: dictionary</span>

<span class="sd">    See `Phi-3.5-mini-instruct/config.json</span>
<span class="sd">    &lt;https://huggingface.co/microsoft/Phi-3.5-mini-instruct/blob/main/config.json&gt;`_.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;_name_or_path&quot;</span><span class="p">:</span> <span class="s2">&quot;Phi-3.5-mini-instruct&quot;</span><span class="p">,</span>
        <span class="s2">&quot;architectures&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;Phi3ForCausalLM&quot;</span><span class="p">],</span>
        <span class="s2">&quot;attention_dropout&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="s2">&quot;auto_map&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;AutoConfig&quot;</span><span class="p">:</span> <span class="s2">&quot;configuration_phi3.Phi3Config&quot;</span><span class="p">,</span>
            <span class="s2">&quot;AutoModelForCausalLM&quot;</span><span class="p">:</span> <span class="s2">&quot;modeling_phi3.Phi3ForCausalLM&quot;</span><span class="p">,</span>
        <span class="p">},</span>
        <span class="s2">&quot;bos_token_id&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
        <span class="s2">&quot;embd_pdrop&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="s2">&quot;eos_token_id&quot;</span><span class="p">:</span> <span class="mi">32000</span><span class="p">,</span>
        <span class="s2">&quot;hidden_act&quot;</span><span class="p">:</span> <span class="s2">&quot;silu&quot;</span><span class="p">,</span>
        <span class="s2">&quot;hidden_size&quot;</span><span class="p">:</span> <span class="mi">3072</span><span class="p">,</span>
        <span class="s2">&quot;initializer_range&quot;</span><span class="p">:</span> <span class="mf">0.02</span><span class="p">,</span>
        <span class="s2">&quot;intermediate_size&quot;</span><span class="p">:</span> <span class="mi">8192</span><span class="p">,</span>
        <span class="s2">&quot;max_position_embeddings&quot;</span><span class="p">:</span> <span class="mi">131072</span><span class="p">,</span>
        <span class="s2">&quot;model_type&quot;</span><span class="p">:</span> <span class="s2">&quot;phi3&quot;</span><span class="p">,</span>
        <span class="s2">&quot;num_attention_heads&quot;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
        <span class="s2">&quot;num_hidden_layers&quot;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
        <span class="s2">&quot;num_key_value_heads&quot;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
        <span class="s2">&quot;original_max_position_embeddings&quot;</span><span class="p">:</span> <span class="mi">4096</span><span class="p">,</span>
        <span class="s2">&quot;pad_token_id&quot;</span><span class="p">:</span> <span class="mi">32000</span><span class="p">,</span>
        <span class="s2">&quot;resid_pdrop&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="s2">&quot;rms_norm_eps&quot;</span><span class="p">:</span> <span class="mf">1e-05</span><span class="p">,</span>
        <span class="s2">&quot;rope_scaling&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;long_factor&quot;</span><span class="p">:</span> <span class="p">[</span>
                <span class="mf">1.0800000429153442</span><span class="p">,</span>
                <span class="mf">1.1100000143051147</span><span class="p">,</span>
                <span class="mf">1.1399999856948853</span><span class="p">,</span>
                <span class="mf">1.340000033378601</span><span class="p">,</span>
                <span class="mf">1.5899999141693115</span><span class="p">,</span>
                <span class="mf">1.600000023841858</span><span class="p">,</span>
                <span class="mf">1.6200000047683716</span><span class="p">,</span>
                <span class="mf">2.620000123977661</span><span class="p">,</span>
                <span class="mf">3.2300000190734863</span><span class="p">,</span>
                <span class="mf">3.2300000190734863</span><span class="p">,</span>
                <span class="mf">4.789999961853027</span><span class="p">,</span>
                <span class="mf">7.400000095367432</span><span class="p">,</span>
                <span class="mf">7.700000286102295</span><span class="p">,</span>
                <span class="mf">9.09000015258789</span><span class="p">,</span>
                <span class="mf">12.199999809265137</span><span class="p">,</span>
                <span class="mf">17.670000076293945</span><span class="p">,</span>
                <span class="mf">24.46000099182129</span><span class="p">,</span>
                <span class="mf">28.57000160217285</span><span class="p">,</span>
                <span class="mf">30.420001983642578</span><span class="p">,</span>
                <span class="mf">30.840002059936523</span><span class="p">,</span>
                <span class="mf">32.590003967285156</span><span class="p">,</span>
                <span class="mf">32.93000411987305</span><span class="p">,</span>
                <span class="mf">42.320003509521484</span><span class="p">,</span>
                <span class="mf">44.96000289916992</span><span class="p">,</span>
                <span class="mf">50.340003967285156</span><span class="p">,</span>
                <span class="mf">50.45000457763672</span><span class="p">,</span>
                <span class="mf">57.55000305175781</span><span class="p">,</span>
                <span class="mf">57.93000411987305</span><span class="p">,</span>
                <span class="mf">58.21000289916992</span><span class="p">,</span>
                <span class="mf">60.1400032043457</span><span class="p">,</span>
                <span class="mf">62.61000442504883</span><span class="p">,</span>
                <span class="mf">62.62000274658203</span><span class="p">,</span>
                <span class="mf">62.71000289916992</span><span class="p">,</span>
                <span class="mf">63.1400032043457</span><span class="p">,</span>
                <span class="mf">63.1400032043457</span><span class="p">,</span>
                <span class="mf">63.77000427246094</span><span class="p">,</span>
                <span class="mf">63.93000411987305</span><span class="p">,</span>
                <span class="mf">63.96000289916992</span><span class="p">,</span>
                <span class="mf">63.970001220703125</span><span class="p">,</span>
                <span class="mf">64.02999877929688</span><span class="p">,</span>
                <span class="mf">64.06999969482422</span><span class="p">,</span>
                <span class="mf">64.08000183105469</span><span class="p">,</span>
                <span class="mf">64.12000274658203</span><span class="p">,</span>
                <span class="mf">64.41000366210938</span><span class="p">,</span>
                <span class="mf">64.4800033569336</span><span class="p">,</span>
                <span class="mf">64.51000213623047</span><span class="p">,</span>
                <span class="mf">64.52999877929688</span><span class="p">,</span>
                <span class="mf">64.83999633789062</span><span class="p">,</span>
            <span class="p">],</span>
            <span class="s2">&quot;short_factor&quot;</span><span class="p">:</span> <span class="p">[</span>
                <span class="mf">1.0</span><span class="p">,</span>
                <span class="mf">1.0199999809265137</span><span class="p">,</span>
                <span class="mf">1.0299999713897705</span><span class="p">,</span>
                <span class="mf">1.0299999713897705</span><span class="p">,</span>
                <span class="mf">1.0499999523162842</span><span class="p">,</span>
                <span class="mf">1.0499999523162842</span><span class="p">,</span>
                <span class="mf">1.0499999523162842</span><span class="p">,</span>
                <span class="mf">1.0499999523162842</span><span class="p">,</span>
                <span class="mf">1.0499999523162842</span><span class="p">,</span>
                <span class="mf">1.0699999332427979</span><span class="p">,</span>
                <span class="mf">1.0999999046325684</span><span class="p">,</span>
                <span class="mf">1.1099998950958252</span><span class="p">,</span>
                <span class="mf">1.1599998474121094</span><span class="p">,</span>
                <span class="mf">1.1599998474121094</span><span class="p">,</span>
                <span class="mf">1.1699998378753662</span><span class="p">,</span>
                <span class="mf">1.2899998426437378</span><span class="p">,</span>
                <span class="mf">1.339999794960022</span><span class="p">,</span>
                <span class="mf">1.679999828338623</span><span class="p">,</span>
                <span class="mf">1.7899998426437378</span><span class="p">,</span>
                <span class="mf">1.8199998140335083</span><span class="p">,</span>
                <span class="mf">1.8499997854232788</span><span class="p">,</span>
                <span class="mf">1.8799997568130493</span><span class="p">,</span>
                <span class="mf">1.9099997282028198</span><span class="p">,</span>
                <span class="mf">1.9399996995925903</span><span class="p">,</span>
                <span class="mf">1.9899996519088745</span><span class="p">,</span>
                <span class="mf">2.0199997425079346</span><span class="p">,</span>
                <span class="mf">2.0199997425079346</span><span class="p">,</span>
                <span class="mf">2.0199997425079346</span><span class="p">,</span>
                <span class="mf">2.0199997425079346</span><span class="p">,</span>
                <span class="mf">2.0199997425079346</span><span class="p">,</span>
                <span class="mf">2.0199997425079346</span><span class="p">,</span>
                <span class="mf">2.0299997329711914</span><span class="p">,</span>
                <span class="mf">2.0299997329711914</span><span class="p">,</span>
                <span class="mf">2.0299997329711914</span><span class="p">,</span>
                <span class="mf">2.0299997329711914</span><span class="p">,</span>
                <span class="mf">2.0299997329711914</span><span class="p">,</span>
                <span class="mf">2.0299997329711914</span><span class="p">,</span>
                <span class="mf">2.0299997329711914</span><span class="p">,</span>
                <span class="mf">2.0299997329711914</span><span class="p">,</span>
                <span class="mf">2.0299997329711914</span><span class="p">,</span>
                <span class="mf">2.0799996852874756</span><span class="p">,</span>
                <span class="mf">2.0899996757507324</span><span class="p">,</span>
                <span class="mf">2.189999580383301</span><span class="p">,</span>
                <span class="mf">2.2199995517730713</span><span class="p">,</span>
                <span class="mf">2.5899994373321533</span><span class="p">,</span>
                <span class="mf">2.729999542236328</span><span class="p">,</span>
                <span class="mf">2.749999523162842</span><span class="p">,</span>
                <span class="mf">2.8399994373321533</span><span class="p">,</span>
            <span class="p">],</span>
            <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;longrope&quot;</span><span class="p">,</span>
        <span class="p">},</span>
        <span class="s2">&quot;rope_theta&quot;</span><span class="p">:</span> <span class="mf">10000.0</span><span class="p">,</span>
        <span class="s2">&quot;sliding_window&quot;</span><span class="p">:</span> <span class="mi">262144</span><span class="p">,</span>
        <span class="s2">&quot;tie_word_embeddings&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
        <span class="s2">&quot;torch_dtype&quot;</span><span class="p">:</span> <span class="s2">&quot;bfloat16&quot;</span><span class="p">,</span>
        <span class="s2">&quot;use_cache&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="s2">&quot;attention_bias&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
        <span class="s2">&quot;vocab_size&quot;</span><span class="p">:</span> <span class="mi">32064</span><span class="p">,</span>
    <span class="p">}</span>
    <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">conf</span> <span class="o">=</span> <span class="n">transformers</span><span class="o">.</span><span class="n">Phi3Config</span><span class="p">(</span><span class="o">**</span><span class="n">config</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">transformers</span><span class="o">.</span><span class="n">Phi3ForCausalLM</span></a></a><span class="p">(</span><span class="n">conf</span><span class="p">)</span>
    <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.eval" title="torch.nn.Module.eval" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.eval" title="torch.nn.Module.eval" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method"><span class="n">model</span><span class="o">.</span><span class="n">eval</span></a></a><span class="p">()</span>

    <span class="n">cache</span> <span class="o">=</span> <a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/cache_helper.html#onnx_diagnostic.helpers.cache_helper.make_dynamic_cache" title="onnx_diagnostic.helpers.cache_helper.make_dynamic_cache" class="sphx-glr-backref-module-onnx_diagnostic-helpers-cache_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/cache_helper.html#onnx_diagnostic.helpers.cache_helper.make_dynamic_cache" title="onnx_diagnostic.helpers.cache_helper.make_dynamic_cache" class="sphx-glr-backref-module-onnx_diagnostic-helpers-cache_helper sphx-glr-backref-type-py-function"><span class="n">make_dynamic_cache</span></a></a><span class="p">(</span>
        <span class="p">[</span>
            <span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><a href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a></a><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">96</span><span class="p">),</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><a href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a></a><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">96</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;num_hidden_layers&quot;</span><span class="p">])</span>
        <span class="p">]</span>
    <span class="p">)</span>
    <span class="n">cache2</span> <span class="o">=</span> <a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/cache_helper.html#onnx_diagnostic.helpers.cache_helper.make_dynamic_cache" title="onnx_diagnostic.helpers.cache_helper.make_dynamic_cache" class="sphx-glr-backref-module-onnx_diagnostic-helpers-cache_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/cache_helper.html#onnx_diagnostic.helpers.cache_helper.make_dynamic_cache" title="onnx_diagnostic.helpers.cache_helper.make_dynamic_cache" class="sphx-glr-backref-module-onnx_diagnostic-helpers-cache_helper sphx-glr-backref-type-py-function"><span class="n">make_dynamic_cache</span></a></a><span class="p">(</span>
        <span class="p">[</span>
            <span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><a href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a></a><span class="p">(</span><span class="n">batch_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">96</span><span class="p">),</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><a href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a></a><span class="p">(</span><span class="n">batch_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">96</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;num_hidden_layers&quot;</span><span class="p">])</span>
        <span class="p">]</span>
    <span class="p">)</span>

    <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">inputs</span></a></a> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
        <span class="n">input_ids</span><span class="o">=</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.randint.html#torch.randint" title="torch.randint" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><a href="https://docs.pytorch.org/docs/stable/generated/torch.randint.html#torch.randint" title="torch.randint" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">randint</span></a></a><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">32064</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch</span><span class="o">.</span><span class="n">int64</span></a></a><span class="p">),</span>
        <span class="n">attention_mask</span><span class="o">=</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.ones.html#torch.ones" title="torch.ones" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><a href="https://docs.pytorch.org/docs/stable/generated/torch.ones.html#torch.ones" title="torch.ones" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">ones</span></a></a><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">33</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch</span><span class="o">.</span><span class="n">int64</span></a></a><span class="p">),</span>
        <span class="n">past_key_values</span><span class="o">=</span><span class="n">cache</span><span class="p">,</span>
    <span class="p">)</span>
    <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">inputs2</span></a></a> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
        <span class="n">input_ids</span><span class="o">=</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.randint.html#torch.randint" title="torch.randint" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><a href="https://docs.pytorch.org/docs/stable/generated/torch.randint.html#torch.randint" title="torch.randint" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">randint</span></a></a><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">32064</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch</span><span class="o">.</span><span class="n">int64</span></a></a><span class="p">),</span>
        <span class="n">attention_mask</span><span class="o">=</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.ones.html#torch.ones" title="torch.ones" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><a href="https://docs.pytorch.org/docs/stable/generated/torch.ones.html#torch.ones" title="torch.ones" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">ones</span></a></a><span class="p">((</span><span class="n">batch_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">35</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch</span><span class="o">.</span><span class="n">int64</span></a></a><span class="p">),</span>
        <span class="n">past_key_values</span><span class="o">=</span><span class="n">cache2</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">inputs</span></a></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">inputs</span></a></a><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">inputs2</span></a></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">inputs2</span></a></a><span class="p">)</span>


<a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data</span></a></a> <span class="o">=</span> <span class="n">get_phi35_untrained</span><span class="p">(</span><span class="n">num_hidden_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">model</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">inputs</span></a></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">inputs2</span></a></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data</span></a></a><span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">],</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data</span></a></a><span class="p">[</span><span class="s2">&quot;inputs&quot;</span><span class="p">],</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data</span></a></a><span class="p">[</span><span class="s2">&quot;inputs2&quot;</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/helpers.html#experimental_experiment.helpers.string_type" title="experimental_experiment.helpers.string_type" class="sphx-glr-backref-module-experimental_experiment-helpers sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/helpers.html#experimental_experiment.helpers.string_type" title="experimental_experiment.helpers.string_type" class="sphx-glr-backref-module-experimental_experiment-helpers sphx-glr-backref-type-py-function"><span class="n">string_type</span></a></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">inputs</span></a></a><span class="p">,</span> <span class="n">with_shape</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>dict(input_ids:T7s2x3,attention_mask:T7s2x33,past_key_values:DynamicCache(key_cache=#2[T1s2x32x30x96,T1s2x32x30x96], value_cache=#2[T1s2x32x30x96,T1s2x32x30x96]))
</pre></div>
</div>
</section>
<section id="dynamic-shapes">
<h2>Dynamic Shapes<a class="headerlink" href="#dynamic-shapes" title="Link to this heading"></a></h2>
<p>We want to infer the dynamic shapes from the two sets of inputs we gave.
For that, we use a function to trace the execution of the model
including its submodules. It is going to execute the model twice
with the two sets of inputs and stores every intermediate input and output.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/piece_by_piece.html#experimental_experiment.torch_interpreter.piece_by_piece.ModelDiagnoseOutput" title="experimental_experiment.torch_interpreter.piece_by_piece.ModelDiagnoseOutput" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter-piece_by_piece sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/piece_by_piece.html#experimental_experiment.torch_interpreter.piece_by_piece.ModelDiagnoseOutput" title="experimental_experiment.torch_interpreter.piece_by_piece.ModelDiagnoseOutput" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter-piece_by_piece sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">diag</span></a></a> <span class="o">=</span> <a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/piece_by_piece.html#experimental_experiment.torch_interpreter.piece_by_piece.trace_execution_piece_by_piece" title="experimental_experiment.torch_interpreter.piece_by_piece.trace_execution_piece_by_piece" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter-piece_by_piece sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/piece_by_piece.html#experimental_experiment.torch_interpreter.piece_by_piece.trace_execution_piece_by_piece" title="experimental_experiment.torch_interpreter.piece_by_piece.trace_execution_piece_by_piece" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter-piece_by_piece sphx-glr-backref-type-py-function"><span class="n">trace_execution_piece_by_piece</span></a></a><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">inputs</span></a></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">inputs2</span></a></a><span class="p">],</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[_trace_forward_execution] -trace-  M:__main__-Phi3ForCausalLM.forward
[_trace_forward_execution] -trace- .. M:model-Phi3Model.forward
[_trace_forward_execution] -trace- .... M:embed_tokens-Embedding.forward
[_trace_forward_execution] -trace- .... M:layers[0]-Phi3DecoderLayer.forward
[_trace_forward_execution] -trace- ...... M:self_attn-Phi3Attention.forward
[_trace_forward_execution] -trace- ........ M:o_proj-Linear.forward
[_trace_forward_execution] -trace- ........ M:qkv_proj-Linear.forward
[_trace_forward_execution] -trace- ...... M:mlp-Phi3MLP.forward
[_trace_forward_execution] -trace- ........ M:gate_up_proj-Linear.forward
[_trace_forward_execution] -trace- ........ M:down_proj-Linear.forward
[_trace_forward_execution] -trace- ........ M:activation_fn-SiLUActivation.forward
[_trace_forward_execution] -trace- ...... M:input_layernorm-Phi3RMSNorm.forward
[_trace_forward_execution] -trace- ...... M:post_attention_layernorm-Phi3RMSNorm.forward
[_trace_forward_execution] -trace- ...... M:resid_attn_dropout-Dropout.forward
[_trace_forward_execution] -trace- ...... M:resid_mlp_dropout-Dropout.forward
[_trace_forward_execution] -trace- .... M:layers[1]-Phi3DecoderLayer.forward
[_trace_forward_execution] -trace- ...... M:self_attn-Phi3Attention.forward
[_trace_forward_execution] -trace- ........ M:o_proj-Linear.forward
[_trace_forward_execution] -trace- ........ M:qkv_proj-Linear.forward
[_trace_forward_execution] -trace- ...... M:mlp-Phi3MLP.forward
[_trace_forward_execution] -trace- ........ M:gate_up_proj-Linear.forward
[_trace_forward_execution] -trace- ........ M:down_proj-Linear.forward
[_trace_forward_execution] -trace- ........ M:activation_fn-SiLUActivation.forward
[_trace_forward_execution] -trace- ...... M:input_layernorm-Phi3RMSNorm.forward
[_trace_forward_execution] -trace- ...... M:post_attention_layernorm-Phi3RMSNorm.forward
[_trace_forward_execution] -trace- ...... M:resid_attn_dropout-Dropout.forward
[_trace_forward_execution] -trace- ...... M:resid_mlp_dropout-Dropout.forward
[_trace_forward_execution] -trace- .... M:norm-Phi3RMSNorm.forward
[_trace_forward_execution] -trace- .... M:rotary_emb-Phi3RotaryEmbedding.forward
[_trace_forward_execution] -trace- .. M:lm_head-Linear.forward
[trace_execution_piece_by_piece] run with dict(args:(),kwargs:dict(input_ids:T7s2x3,attention_mask:T7s2x33,past_key_values:DynamicCache(key_cache=#2[T1s2x32x30x96,T1s2x32x30x96], value_cache=#2[T1s2x32x30x96,T1s2x32x30x96])))
[__main__:Phi3ForCausalLM] &gt; **dict(input_ids:T7r2,attention_mask:T7r2,past_key_values:DynamicCache(key_cache=#2[T1r4,T1r4], value_cache=#2[T1r4,T1r4]))
[model:Phi3Model]   &gt; **dict(input_ids:T7r2,attention_mask:T7r2,position_ids:None,past_key_values:DynamicCache(key_cache=#2[T1r4,T1r4], value_cache=#2[T1r4,T1r4]),inputs_embeds:None,use_cache:None,cache_position:None)
[embed_tokens:Embedding]     &gt; T7r2
[embed_tokens:Embedding]     &lt; T1r3
[rotary_emb:Phi3RotaryEmbedding]     &gt; *(T1r3,), **dict(position_ids:T7r2)
[rotary_emb:Phi3RotaryEmbedding]     &lt; *(T1r3,T1r3)
[layers[0]:Phi3DecoderLayer]     &gt; *(T1r3,), **dict(attention_mask:T9r4,position_ids:T7r2,past_key_values:DynamicCache(key_cache=#2[T1r4,T1r4], value_cache=#2[T1r4,T1r4]),use_cache:bool,cache_position:T7r1,position_embeddings:(T1r3,T1r3))
[input_layernorm:Phi3RMSNorm]       &gt; T1r3
[input_layernorm:Phi3RMSNorm]       &lt; T1r3
[self_attn:Phi3Attention]       &gt; **dict(hidden_states:T1r3,attention_mask:T9r4,position_ids:T7r2,past_key_values:DynamicCache(key_cache=#2[T1r4,T1r4], value_cache=#2[T1r4,T1r4]),use_cache:bool,cache_position:T7r1,position_embeddings:(T1r3,T1r3))
[qkv_proj:Linear]         &gt; T1r3
[qkv_proj:Linear]         &lt; T1r3
[o_proj:Linear]         &gt; T1r3
[o_proj:Linear]         &lt; T1r3
[self_attn:Phi3Attention]       &lt; *(T1r3,None)
[resid_attn_dropout:Dropout]       &gt; T1r3
[resid_attn_dropout:Dropout]       &lt; T1r3
[post_attention_layernorm:Phi3RMSNorm]       &gt; T1r3
[post_attention_layernorm:Phi3RMSNorm]       &lt; T1r3
[mlp:Phi3MLP]       &gt; T1r3
[gate_up_proj:Linear]         &gt; T1r3
[gate_up_proj:Linear]         &lt; T1r3
[activation_fn:SiLUActivation]         &gt; T1r3
[activation_fn:SiLUActivation]         &lt; T1r3
[down_proj:Linear]         &gt; T1r3
[down_proj:Linear]         &lt; T1r3
[mlp:Phi3MLP]       &lt; T1r3
[resid_mlp_dropout:Dropout]       &gt; T1r3
[resid_mlp_dropout:Dropout]       &lt; T1r3
[layers[0]:Phi3DecoderLayer]     &lt; T1r3
[layers[1]:Phi3DecoderLayer]     &gt; *(T1r3,), **dict(attention_mask:T9r4,position_ids:T7r2,past_key_values:DynamicCache(key_cache=#2[T1r4,T1r4], value_cache=#2[T1r4,T1r4]),use_cache:bool,cache_position:T7r1,position_embeddings:(T1r3,T1r3))
[input_layernorm:Phi3RMSNorm]       &gt; T1r3
[input_layernorm:Phi3RMSNorm]       &lt; T1r3
[self_attn:Phi3Attention]       &gt; **dict(hidden_states:T1r3,attention_mask:T9r4,position_ids:T7r2,past_key_values:DynamicCache(key_cache=#2[T1r4,T1r4], value_cache=#2[T1r4,T1r4]),use_cache:bool,cache_position:T7r1,position_embeddings:(T1r3,T1r3))
[qkv_proj:Linear]         &gt; T1r3
[qkv_proj:Linear]         &lt; T1r3
[o_proj:Linear]         &gt; T1r3
[o_proj:Linear]         &lt; T1r3
[self_attn:Phi3Attention]       &lt; *(T1r3,None)
[resid_attn_dropout:Dropout]       &gt; T1r3
[resid_attn_dropout:Dropout]       &lt; T1r3
[post_attention_layernorm:Phi3RMSNorm]       &gt; T1r3
[post_attention_layernorm:Phi3RMSNorm]       &lt; T1r3
[mlp:Phi3MLP]       &gt; T1r3
[gate_up_proj:Linear]         &gt; T1r3
[gate_up_proj:Linear]         &lt; T1r3
[activation_fn:SiLUActivation]         &gt; T1r3
[activation_fn:SiLUActivation]         &lt; T1r3
[down_proj:Linear]         &gt; T1r3
[down_proj:Linear]         &lt; T1r3
[mlp:Phi3MLP]       &lt; T1r3
[resid_mlp_dropout:Dropout]       &gt; T1r3
[resid_mlp_dropout:Dropout]       &lt; T1r3
[layers[1]:Phi3DecoderLayer]     &lt; T1r3
[norm:Phi3RMSNorm]     &gt; T1r3
[norm:Phi3RMSNorm]     &lt; T1r3
[model:Phi3Model]   &lt; *BaseModelOutputWithPast(last_hidden_state:T1r3,past_key_values:DynamicCache(key_cache=#2[T1r4,T1r4], value_cache=#2[T1r4,T1r4]))
[lm_head:Linear]   &gt; T1r3
[lm_head:Linear]   &lt; T1r3
[__main__:Phi3ForCausalLM] &lt; *CausalLMOutputWithPast(logits:T1r3,past_key_values:DynamicCache(key_cache=#2[T1r4,T1r4], value_cache=#2[T1r4,T1r4]))
[trace_execution_piece_by_piece] run with dict(args:(),kwargs:dict(input_ids:T7s3x4,attention_mask:T7s3x35,past_key_values:DynamicCache(key_cache=#2[T1s3x32x31x96,T1s3x32x31x96], value_cache=#2[T1s3x32x31x96,T1s3x32x31x96])))
[__main__:Phi3ForCausalLM] &gt; **dict(input_ids:T7r2,attention_mask:T7r2,past_key_values:DynamicCache(key_cache=#2[T1r4,T1r4], value_cache=#2[T1r4,T1r4]))
[model:Phi3Model]   &gt; **dict(input_ids:T7r2,attention_mask:T7r2,position_ids:None,past_key_values:DynamicCache(key_cache=#2[T1r4,T1r4], value_cache=#2[T1r4,T1r4]),inputs_embeds:None,use_cache:None,cache_position:None)
[embed_tokens:Embedding]     &gt; T7r2
[embed_tokens:Embedding]     &lt; T1r3
[rotary_emb:Phi3RotaryEmbedding]     &gt; *(T1r3,), **dict(position_ids:T7r2)
[rotary_emb:Phi3RotaryEmbedding]     &lt; *(T1r3,T1r3)
[layers[0]:Phi3DecoderLayer]     &gt; *(T1r3,), **dict(attention_mask:T9r4,position_ids:T7r2,past_key_values:DynamicCache(key_cache=#2[T1r4,T1r4], value_cache=#2[T1r4,T1r4]),use_cache:bool,cache_position:T7r1,position_embeddings:(T1r3,T1r3))
[input_layernorm:Phi3RMSNorm]       &gt; T1r3
[input_layernorm:Phi3RMSNorm]       &lt; T1r3
[self_attn:Phi3Attention]       &gt; **dict(hidden_states:T1r3,attention_mask:T9r4,position_ids:T7r2,past_key_values:DynamicCache(key_cache=#2[T1r4,T1r4], value_cache=#2[T1r4,T1r4]),use_cache:bool,cache_position:T7r1,position_embeddings:(T1r3,T1r3))
[qkv_proj:Linear]         &gt; T1r3
[qkv_proj:Linear]         &lt; T1r3
[o_proj:Linear]         &gt; T1r3
[o_proj:Linear]         &lt; T1r3
[self_attn:Phi3Attention]       &lt; *(T1r3,None)
[resid_attn_dropout:Dropout]       &gt; T1r3
[resid_attn_dropout:Dropout]       &lt; T1r3
[post_attention_layernorm:Phi3RMSNorm]       &gt; T1r3
[post_attention_layernorm:Phi3RMSNorm]       &lt; T1r3
[mlp:Phi3MLP]       &gt; T1r3
[gate_up_proj:Linear]         &gt; T1r3
[gate_up_proj:Linear]         &lt; T1r3
[activation_fn:SiLUActivation]         &gt; T1r3
[activation_fn:SiLUActivation]         &lt; T1r3
[down_proj:Linear]         &gt; T1r3
[down_proj:Linear]         &lt; T1r3
[mlp:Phi3MLP]       &lt; T1r3
[resid_mlp_dropout:Dropout]       &gt; T1r3
[resid_mlp_dropout:Dropout]       &lt; T1r3
[layers[0]:Phi3DecoderLayer]     &lt; T1r3
[layers[1]:Phi3DecoderLayer]     &gt; *(T1r3,), **dict(attention_mask:T9r4,position_ids:T7r2,past_key_values:DynamicCache(key_cache=#2[T1r4,T1r4], value_cache=#2[T1r4,T1r4]),use_cache:bool,cache_position:T7r1,position_embeddings:(T1r3,T1r3))
[input_layernorm:Phi3RMSNorm]       &gt; T1r3
[input_layernorm:Phi3RMSNorm]       &lt; T1r3
[self_attn:Phi3Attention]       &gt; **dict(hidden_states:T1r3,attention_mask:T9r4,position_ids:T7r2,past_key_values:DynamicCache(key_cache=#2[T1r4,T1r4], value_cache=#2[T1r4,T1r4]),use_cache:bool,cache_position:T7r1,position_embeddings:(T1r3,T1r3))
[qkv_proj:Linear]         &gt; T1r3
[qkv_proj:Linear]         &lt; T1r3
[o_proj:Linear]         &gt; T1r3
[o_proj:Linear]         &lt; T1r3
[self_attn:Phi3Attention]       &lt; *(T1r3,None)
[resid_attn_dropout:Dropout]       &gt; T1r3
[resid_attn_dropout:Dropout]       &lt; T1r3
[post_attention_layernorm:Phi3RMSNorm]       &gt; T1r3
[post_attention_layernorm:Phi3RMSNorm]       &lt; T1r3
[mlp:Phi3MLP]       &gt; T1r3
[gate_up_proj:Linear]         &gt; T1r3
[gate_up_proj:Linear]         &lt; T1r3
[activation_fn:SiLUActivation]         &gt; T1r3
[activation_fn:SiLUActivation]         &lt; T1r3
[down_proj:Linear]         &gt; T1r3
[down_proj:Linear]         &lt; T1r3
[mlp:Phi3MLP]       &lt; T1r3
[resid_mlp_dropout:Dropout]       &gt; T1r3
[resid_mlp_dropout:Dropout]       &lt; T1r3
[layers[1]:Phi3DecoderLayer]     &lt; T1r3
[norm:Phi3RMSNorm]     &gt; T1r3
[norm:Phi3RMSNorm]     &lt; T1r3
[model:Phi3Model]   &lt; *BaseModelOutputWithPast(last_hidden_state:T1r3,past_key_values:DynamicCache(key_cache=#2[T1r4,T1r4], value_cache=#2[T1r4,T1r4]))
[lm_head:Linear]   &gt; T1r3
[lm_head:Linear]   &lt; T1r3
[__main__:Phi3ForCausalLM] &lt; *CausalLMOutputWithPast(logits:T1r3,past_key_values:DynamicCache(key_cache=#2[T1r4,T1r4], value_cache=#2[T1r4,T1r4]))
[trace_forward_execution] traced execution of model Phi3ForCausalLM
&gt;&gt;&gt; __main__: Phi3ForCausalLM
  &gt; ((),dict(input_ids:CT7s2x3[2805,21466:A14035.333333333334],attention_mask:CT7s2x33[1,1:A1.0],past_key_values:DynamicCache(key_cache=#2[CT1s2x32x30x96[-5.321568965911865,4.642333030700684:A-0.0017679614187095713],CT1s2x32x30x96[-4.208118438720703,4.5439982414245605:A0.0016461648380537073]], value_cache=#2[CT1s2x32x30x96[-4.218534469604492,4.59930944442749:A-0.006064819536683874],CT1s2x32x30x96[-4.209028720855713,5.0260820388793945:A0.002745364887231304]])))
  &gt; ((),dict(input_ids:CT7s3x4[1693,26014:A13294.0],attention_mask:CT7s3x35[1,1:A1.0],past_key_values:DynamicCache(key_cache=#2[CT1s3x32x31x96[-4.695406436920166,4.258121490478516:A-0.0014835018764388604],CT1s3x32x31x96[-4.697518348693848,4.683842658996582:A-0.0008565901604404504]], value_cache=#2[CT1s3x32x31x96[-4.510615348815918,4.348228454589844:A0.0008330248852151018],CT1s3x32x31x96[-4.735829830169678,5.559142112731934:A0.00048002360800640374]])))
    &gt;&gt;&gt; model: Phi3Model
      &gt; ((),dict(input_ids:CT7s2x3[2805,21466:A14035.333333333334],attention_mask:CT7s2x33[1,1:A1.0],position_ids:None,past_key_values:DynamicCache(key_cache=#2[CT1s2x32x30x96[-5.321568965911865,4.642333030700684:A-0.0017679614187095713],CT1s2x32x30x96[-4.208118438720703,4.5439982414245605:A0.0016461648380537073]], value_cache=#2[CT1s2x32x30x96[-4.218534469604492,4.59930944442749:A-0.006064819536683874],CT1s2x32x30x96[-4.209028720855713,5.0260820388793945:A0.002745364887231304]]),inputs_embeds:None,use_cache:None,cache_position:None))
      &gt; ((),dict(input_ids:CT7s3x4[1693,26014:A13294.0],attention_mask:CT7s3x35[1,1:A1.0],position_ids:None,past_key_values:DynamicCache(key_cache=#2[CT1s3x32x31x96[-4.695406436920166,4.258121490478516:A-0.0014835018764388604],CT1s3x32x31x96[-4.697518348693848,4.683842658996582:A-0.0008565901604404504]], value_cache=#2[CT1s3x32x31x96[-4.510615348815918,4.348228454589844:A0.0008330248852151018],CT1s3x32x31x96[-4.735829830169678,5.559142112731934:A0.00048002360800640374]]),inputs_embeds:None,use_cache:None,cache_position:None))
        &gt;&gt;&gt; embed_tokens: Embedding
          &gt; ((CT7s2x3[2805,21466:A14035.333333333334],),{})
          &gt; ((CT7s3x4[1693,26014:A13294.0],),{})
          &lt; (CT1s2x3x3072[-0.09246909618377686,0.07369624078273773:A-3.130963592056255e-05],)
          &lt; (CT1s3x4x3072[-0.07948524504899979,0.07863165438175201:A6.865088794481968e-05],)
        &lt;&lt;&lt;
        &gt;&gt;&gt; layers[0]: Phi3DecoderLayer
          &gt; ((CT1s2x3x3072[-0.09246909618377686,0.07369624078273773:A-3.130963592056255e-05],),dict(attention_mask:CT9s2x1x3x33[False,True:A0.9696969696969697],position_ids:CT7s1x3[30,32:A31.0],past_key_values:DynamicCache(key_cache=#2[CT1s2x32x30x96[-5.321568965911865,4.642333030700684:A-0.0017679614187095713],CT1s2x32x30x96[-4.208118438720703,4.5439982414245605:A0.0016461648380537073]], value_cache=#2[CT1s2x32x30x96[-4.218534469604492,4.59930944442749:A-0.006064819536683874],CT1s2x32x30x96[-4.209028720855713,5.0260820388793945:A0.002745364887231304]]),use_cache:bool=True,cache_position:CT7s3[30,32:A31.0],position_embeddings:(CT1s1x3x96[-1.1855769157409668,1.1902371644973755:A0.746652018013669],CT1s1x3x96[-1.1887905597686768,1.190193772315979:A0.1589894221542636])))
          &gt; ((CT1s3x4x3072[-0.07948524504899979,0.07863165438175201:A6.865088794481968e-05],),dict(attention_mask:CT9s3x1x4x35[False,True:A0.9571428571428572],position_ids:CT7s1x4[31,34:A32.5],past_key_values:DynamicCache(key_cache=#2[CT1s3x32x31x96[-4.695406436920166,4.258121490478516:A-0.0014835018764388604],CT1s3x32x31x96[-4.697518348693848,4.683842658996582:A-0.0008565901604404504]], value_cache=#2[CT1s3x32x31x96[-4.510615348815918,4.348228454589844:A0.0008330248852151018],CT1s3x32x31x96[-4.735829830169678,5.559142112731934:A0.00048002360800640374]]),use_cache:bool=True,cache_position:CT7s4[31,34:A32.5],position_embeddings:(CT1s1x4x96[-1.1855769157409668,1.190237045288086:A0.7129333875218435],CT1s1x4x96[-1.1719439029693604,1.1902378797531128:A0.18296290554159592])))
            &gt;&gt;&gt; self_attn: Phi3Attention
              &gt; ((),dict(hidden_states:CT1s2x3x3072[-4.630746364593506,3.6906232833862305:A-0.0014726865415836737],attention_mask:CT9s2x1x3x33[False,True:A0.9696969696969697],position_ids:CT7s1x3[30,32:A31.0],past_key_values:DynamicCache(key_cache=#2[CT1s2x32x30x96[-5.321568965911865,4.642333030700684:A-0.0017679614187095713],CT1s2x32x30x96[-4.208118438720703,4.5439982414245605:A0.0016461648380537073]], value_cache=#2[CT1s2x32x30x96[-4.218534469604492,4.59930944442749:A-0.006064819536683874],CT1s2x32x30x96[-4.209028720855713,5.0260820388793945:A0.002745364887231304]]),use_cache:bool=True,cache_position:CT7s3[30,32:A31.0],position_embeddings:(CT1s1x3x96[-1.1855769157409668,1.1902371644973755:A0.746652018013669],CT1s1x3x96[-1.1887905597686768,1.190193772315979:A0.1589894221542636])))
              &gt; ((),dict(hidden_states:CT1s3x4x3072[-3.937323808670044,3.880868911743164:A0.003424602768633785],attention_mask:CT9s3x1x4x35[False,True:A0.9571428571428572],position_ids:CT7s1x4[31,34:A32.5],past_key_values:DynamicCache(key_cache=#2[CT1s3x32x31x96[-4.695406436920166,4.258121490478516:A-0.0014835018764388604],CT1s3x32x31x96[-4.697518348693848,4.683842658996582:A-0.0008565901604404504]], value_cache=#2[CT1s3x32x31x96[-4.510615348815918,4.348228454589844:A0.0008330248852151018],CT1s3x32x31x96[-4.735829830169678,5.559142112731934:A0.00048002360800640374]]),use_cache:bool=True,cache_position:CT7s4[31,34:A32.5],position_embeddings:(CT1s1x4x96[-1.1855769157409668,1.190237045288086:A0.7129333875218435],CT1s1x4x96[-1.1719439029693604,1.1902378797531128:A0.18296290554159592])))
                &gt;&gt;&gt; o_proj: Linear
                  &gt; ((CT1s2x3x3072[-2.6784136295318604,2.9553494453430176:A-0.006247291141995366],),{})
                  &gt; ((CT1s3x4x3072[-2.4470973014831543,2.807598114013672:A-1.320671074693062e-05],),{})
                  &lt; (CT1s2x3x3072[-1.6150957345962524,1.6153888702392578:A-0.0020455685180928006],)
                  &lt; (CT1s3x4x3072[-1.8017123937606812,1.5505903959274292:A-0.0004669091483088374],)
                &lt;&lt;&lt;
                &gt;&gt;&gt; qkv_proj: Linear
                  &gt; ((CT1s2x3x3072[-4.630746364593506,3.6906232833862305:A-0.0014726865415836737],),{})
                  &gt; ((CT1s3x4x3072[-3.937323808670044,3.880868911743164:A0.003424602768633785],),{})
                  &lt; (CT1s2x3x9216[-4.3074750900268555,4.560797691345215:A0.003889466427002238],)
                  &lt; (CT1s3x4x9216[-4.575429439544678,4.392276287078857:A0.0007742521622983784],)
                &lt;&lt;&lt;
              &lt; (CT1s2x3x3072[-1.6150957345962524,1.6153888702392578:A-0.0020455685180928006],None)
              &lt; (CT1s3x4x3072[-1.8017123937606812,1.5505903959274292:A-0.0004669091483088374],None)
            &lt;&lt;&lt;
            &gt;&gt;&gt; mlp: Phi3MLP
              &gt; ((CT1s2x3x3072[-3.89996600151062,3.892240524291992:A-0.005018209103335083],),{})
              &gt; ((CT1s3x4x3072[-4.527905464172363,3.8988120555877686:A-0.0010598260709656021],),{})
                &gt;&gt;&gt; gate_up_proj: Linear
                  &gt; ((CT1s2x3x3072[-3.89996600151062,3.892240524291992:A-0.005018209103335083],),{})
                  &gt; ((CT1s3x4x3072[-4.527905464172363,3.8988120555877686:A-0.0010598260709656021],),{})
                  &lt; (CT1s2x3x16384[-5.326481342315674,5.053717136383057:A-0.005484532955991976],)
                  &lt; (CT1s3x4x16384[-4.692765235900879,4.91367244720459:A0.003873056516350578],)
                &lt;&lt;&lt;
                &gt;&gt;&gt; down_proj: Linear
                  &gt; ((CT1s2x3x8192[-9.957571983337402,9.760546684265137:A0.0004086510726069791],),{})
                  &gt; ((CT1s3x4x8192[-10.153356552124023,12.667742729187012:A-0.0022295268024867926],),{})
                  &lt; (CT1s2x3x3072[-5.296715259552002,5.8315043449401855:A-0.0034154122044785457],)
                  &lt; (CT1s3x4x3072[-5.51116943359375,6.273403167724609:A0.005032625723124006],)
                &lt;&lt;&lt;
                &gt;&gt;&gt; activation_fn: SiLUActivation
                  &gt; ((CT1s2x3x8192[-5.326481342315674,5.053717136383057:A-0.011311644454508496],),{})
                  &gt; ((CT1s3x4x8192[-4.692765235900879,4.91367244720459:A0.009215649440452722],),{})
                  &lt; (CT1s2x3x8192[-0.27846455574035645,5.021651268005371:A0.24074798986483872],)
                  &lt; (CT1s3x4x8192[-0.27846455574035645,4.877842426300049:A0.251591828373712],)
                &lt;&lt;&lt;
              &lt; (CT1s2x3x3072[-5.296715259552002,5.8315043449401855:A-0.0034154122044785457],)
              &lt; (CT1s3x4x3072[-5.51116943359375,6.273403167724609:A0.005032625723124006],)
            &lt;&lt;&lt;
            &gt;&gt;&gt; input_layernorm: Phi3RMSNorm
              &gt; ((CT1s2x3x3072[-0.09246909618377686,0.07369624078273773:A-3.130963592056255e-05],),{})
              &gt; ((CT1s3x4x3072[-0.07948524504899979,0.07863165438175201:A6.865088794481968e-05],),{})
              &lt; (CT1s2x3x3072[-4.630746364593506,3.6906232833862305:A-0.0014726865415836737],)
              &lt; (CT1s3x4x3072[-3.937323808670044,3.880868911743164:A0.003424602768633785],)
            &lt;&lt;&lt;
            &gt;&gt;&gt; post_attention_layernorm: Phi3RMSNorm
              &gt; ((CT1s2x3x3072[-1.626574993133545,1.572633147239685:A-0.0020768782157681975],),{})
              &gt; ((CT1s3x4x3072[-1.7993048429489136,1.5446910858154297:A-0.00039825813672757075],),{})
              &lt; (CT1s2x3x3072[-3.89996600151062,3.892240524291992:A-0.005018209103335083],)
              &lt; (CT1s3x4x3072[-4.527905464172363,3.8988120555877686:A-0.0010598260709656021],)
            &lt;&lt;&lt;
            &gt;&gt;&gt; resid_attn_dropout: Dropout
              &gt; ((CT1s2x3x3072[-1.6150957345962524,1.6153888702392578:A-0.0020455685180928006],),{})
              &gt; ((CT1s3x4x3072[-1.8017123937606812,1.5505903959274292:A-0.0004669091483088374],),{})
              &lt; (CT1s2x3x3072[-1.6150957345962524,1.6153888702392578:A-0.0020455685180928006],)
              &lt; (CT1s3x4x3072[-1.8017123937606812,1.5505903959274292:A-0.0004669091483088374],)
            &lt;&lt;&lt;
            &gt;&gt;&gt; resid_mlp_dropout: Dropout
              &gt; ((CT1s2x3x3072[-5.296715259552002,5.8315043449401855:A-0.0034154122044785457],),{})
              &gt; ((CT1s3x4x3072[-5.51116943359375,6.273403167724609:A0.005032625723124006],),{})
              &lt; (CT1s2x3x3072[-5.296715259552002,5.8315043449401855:A-0.0034154122044785457],)
              &lt; (CT1s3x4x3072[-5.51116943359375,6.273403167724609:A0.005032625723124006],)
            &lt;&lt;&lt;
          &lt; (CT1s2x3x3072[-5.492254257202148,6.447257041931152:A-0.005492290605969983],)
          &lt; (CT1s3x4x3072[-5.337061405181885,6.1045732498168945:A0.0046343675318338586],)
        &lt;&lt;&lt;
        &gt;&gt;&gt; layers[1]: Phi3DecoderLayer
          &gt; ((CT1s2x3x3072[-5.492254257202148,6.447257041931152:A-0.005492290605969983],),dict(attention_mask:CT9s2x1x3x33[False,True:A0.9696969696969697],position_ids:CT7s1x3[30,32:A31.0],past_key_values:DynamicCache(key_cache=#2[CT1s2x32x33x96[-5.321568965911865,5.071047306060791:A-0.0010730019231920205],CT1s2x32x30x96[-4.208118438720703,4.5439982414245605:A0.0016461648380537073]], value_cache=#2[CT1s2x32x33x96[-4.218534469604492,4.59930944442749:A-0.005605154250588178],CT1s2x32x30x96[-4.209028720855713,5.0260820388793945:A0.002745364887231304]]),use_cache:bool=True,cache_position:CT7s3[30,32:A31.0],position_embeddings:(CT1s1x3x96[-1.1855769157409668,1.1902371644973755:A0.746652018013669],CT1s1x3x96[-1.1887905597686768,1.190193772315979:A0.1589894221542636])))
          &gt; ((CT1s3x4x3072[-5.337061405181885,6.1045732498168945:A0.0046343675318338586],),dict(attention_mask:CT9s3x1x4x35[False,True:A0.9571428571428572],position_ids:CT7s1x4[31,34:A32.5],past_key_values:DynamicCache(key_cache=#2[CT1s3x32x35x96[-5.2906494140625,4.7679948806762695:A-0.0028739331352421174],CT1s3x32x31x96[-4.697518348693848,4.683842658996582:A-0.0008565901604404504]], value_cache=#2[CT1s3x32x35x96[-4.575429439544678,4.348228454589844:A0.0014538525100350908],CT1s3x32x31x96[-4.735829830169678,5.559142112731934:A0.00048002360800640374]]),use_cache:bool=True,cache_position:CT7s4[31,34:A32.5],position_embeddings:(CT1s1x4x96[-1.1855769157409668,1.190237045288086:A0.7129333875218435],CT1s1x4x96[-1.1719439029693604,1.1902378797531128:A0.18296290554159592])))
            &gt;&gt;&gt; self_attn: Phi3Attention
              &gt; ((),dict(hidden_states:CT1s2x3x3072[-3.9389030933380127,4.539912223815918:A-0.0043732160782262225],attention_mask:CT9s2x1x3x33[False,True:A0.9696969696969697],position_ids:CT7s1x3[30,32:A31.0],past_key_values:DynamicCache(key_cache=#2[CT1s2x32x33x96[-5.321568965911865,5.071047306060791:A-0.0010730019231920205],CT1s2x32x30x96[-4.208118438720703,4.5439982414245605:A0.0016461648380537073]], value_cache=#2[CT1s2x32x33x96[-4.218534469604492,4.59930944442749:A-0.005605154250588178],CT1s2x32x30x96[-4.209028720855713,5.0260820388793945:A0.002745364887231304]]),use_cache:bool=True,cache_position:CT7s3[30,32:A31.0],position_embeddings:(CT1s1x3x96[-1.1855769157409668,1.1902371644973755:A0.746652018013669],CT1s1x3x96[-1.1887905597686768,1.190193772315979:A0.1589894221542636])))
              &gt; ((),dict(hidden_states:CT1s3x4x3072[-3.6848440170288086,4.238821983337402:A0.003227063433569624],attention_mask:CT9s3x1x4x35[False,True:A0.9571428571428572],position_ids:CT7s1x4[31,34:A32.5],past_key_values:DynamicCache(key_cache=#2[CT1s3x32x35x96[-5.2906494140625,4.7679948806762695:A-0.0028739331352421174],CT1s3x32x31x96[-4.697518348693848,4.683842658996582:A-0.0008565901604404504]], value_cache=#2[CT1s3x32x35x96[-4.575429439544678,4.348228454589844:A0.0014538525100350908],CT1s3x32x31x96[-4.735829830169678,5.559142112731934:A0.00048002360800640374]]),use_cache:bool=True,cache_position:CT7s4[31,34:A32.5],position_embeddings:(CT1s1x4x96[-1.1855769157409668,1.190237045288086:A0.7129333875218435],CT1s1x4x96[-1.1719439029693604,1.1902378797531128:A0.18296290554159592])))
                &gt;&gt;&gt; o_proj: Linear
                  &gt; ((CT1s2x3x3072[-2.4762864112854004,2.7124173641204834:A0.0026660227320708507],),{})
                  &gt; ((CT1s3x4x3072[-2.4498472213745117,2.3301873207092285:A0.004975156723096797],),{})
                  &lt; (CT1s2x3x3072[-1.697070598602295,1.7238038778305054:A-0.003707572536408558],)
                  &lt; (CT1s3x4x3072[-1.585153579711914,1.7237988710403442:A-0.0026312880371316774],)
                &lt;&lt;&lt;
                &gt;&gt;&gt; qkv_proj: Linear
                  &gt; ((CT1s2x3x3072[-3.9389030933380127,4.539912223815918:A-0.0043732160782262225],),{})
                  &gt; ((CT1s3x4x3072[-3.6848440170288086,4.238821983337402:A0.003227063433569624],),{})
                  &lt; (CT1s2x3x9216[-4.680721759796143,4.633952617645264:A0.0016646715417302268],)
                  &lt; (CT1s3x4x9216[-4.391646862030029,4.912417888641357:A0.007990984870226023],)
                &lt;&lt;&lt;
              &lt; (CT1s2x3x3072[-1.697070598602295,1.7238038778305054:A-0.003707572536408558],None)
              &lt; (CT1s3x4x3072[-1.585153579711914,1.7237988710403442:A-0.0026312880371316774],None)
            &lt;&lt;&lt;
            &gt;&gt;&gt; mlp: Phi3MLP
              &gt; ((CT1s2x3x3072[-4.085476398468018,4.620463848114014:A-0.006951781481834531],),{})
              &gt; ((CT1s3x4x3072[-3.741267442703247,3.943660020828247:A0.0013388905007409118],),{})
                &gt;&gt;&gt; gate_up_proj: Linear
                  &gt; ((CT1s2x3x3072[-4.085476398468018,4.620463848114014:A-0.006951781481834531],),{})
                  &gt; ((CT1s3x4x3072[-3.741267442703247,3.943660020828247:A0.0013388905007409118],),{})
                  &lt; (CT1s2x3x16384[-4.922957420349121,4.562531471252441:A0.004650305251132636],)
                  &lt; (CT1s3x4x16384[-4.949065208435059,5.174188137054443:A0.00030220871082479545],)
                &lt;&lt;&lt;
                &gt;&gt;&gt; down_proj: Linear
                  &gt; ((CT1s2x3x8192[-8.283615112304688,9.017322540283203:A0.005167366500767285],),{})
                  &gt; ((CT1s3x4x8192[-9.517515182495117,8.992436408996582:A-0.002715212943913454],),{})
                  &lt; (CT1s2x3x3072[-5.384060859680176,4.820015907287598:A-0.011407251573448067],)
                  &lt; (CT1s3x4x3072[-5.838794231414795,5.128146648406982:A0.0016962297066179923],)
                &lt;&lt;&lt;
                &gt;&gt;&gt; activation_fn: SiLUActivation
                  &gt; ((CT1s2x3x8192[-4.288193225860596,4.562531471252441:A-0.0010666609790395871],),{})
                  &gt; ((CT1s3x4x8192[-4.949065208435059,5.174188137054443:A0.0025969812957432246],),{})
                  &lt; (CT1s2x3x8192[-0.27846455574035645,4.515410423278809:A0.2449151218159792],)
                  &lt; (CT1s3x4x8192[-0.27846455574035645,5.1450629234313965:A0.2456222603444075],)
                &lt;&lt;&lt;
              &lt; (CT1s2x3x3072[-5.384060859680176,4.820015907287598:A-0.011407251573448067],)
              &lt; (CT1s3x4x3072[-5.838794231414795,5.128146648406982:A0.0016962297066179923],)
            &lt;&lt;&lt;
            &gt;&gt;&gt; input_layernorm: Phi3RMSNorm
              &gt; ((CT1s2x3x3072[-5.492254257202148,6.447257041931152:A-0.005492290605969983],),{})
              &gt; ((CT1s3x4x3072[-5.337061405181885,6.1045732498168945:A0.0046343675318338586],),{})
              &lt; (CT1s2x3x3072[-3.9389030933380127,4.539912223815918:A-0.0043732160782262225],)
              &lt; (CT1s3x4x3072[-3.6848440170288086,4.238821983337402:A0.003227063433569624],)
            &lt;&lt;&lt;
            &gt;&gt;&gt; post_attention_layernorm: Phi3RMSNorm
              &gt; ((CT1s2x3x3072[-6.087521553039551,6.884673595428467:A-0.009199862836592528],),{})
              &gt; ((CT1s3x4x3072[-5.423608779907227,5.876498699188232:A0.0020030792350098636],),{})
              &lt; (CT1s2x3x3072[-4.085476398468018,4.620463848114014:A-0.006951781481834531],)
              &lt; (CT1s3x4x3072[-3.741267442703247,3.943660020828247:A0.0013388905007409118],)
            &lt;&lt;&lt;
            &gt;&gt;&gt; resid_attn_dropout: Dropout
              &gt; ((CT1s2x3x3072[-1.697070598602295,1.7238038778305054:A-0.003707572536408558],),{})
              &gt; ((CT1s3x4x3072[-1.585153579711914,1.7237988710403442:A-0.0026312880371316774],),{})
              &lt; (CT1s2x3x3072[-1.697070598602295,1.7238038778305054:A-0.003707572536408558],)
              &lt; (CT1s3x4x3072[-1.585153579711914,1.7237988710403442:A-0.0026312880371316774],)
            &lt;&lt;&lt;
            &gt;&gt;&gt; resid_mlp_dropout: Dropout
              &gt; ((CT1s2x3x3072[-5.384060859680176,4.820015907287598:A-0.011407251573448067],),{})
              &gt; ((CT1s3x4x3072[-5.838794231414795,5.128146648406982:A0.0016962297066179923],),{})
              &lt; (CT1s2x3x3072[-5.384060859680176,4.820015907287598:A-0.011407251573448067],)
              &lt; (CT1s3x4x3072[-5.838794231414795,5.128146648406982:A0.0016962297066179923],)
            &lt;&lt;&lt;
          &lt; (CT1s2x3x3072[-8.117108345031738,8.247547149658203:A-0.020607114706055855],)
          &lt; (CT1s3x4x3072[-8.020179748535156,7.753192901611328:A0.003699309034244733],)
        &lt;&lt;&lt;
        &gt;&gt;&gt; norm: Phi3RMSNorm
          &gt; ((CT1s2x3x3072[-8.117108345031738,8.247547149658203:A-0.020607114706055855],),{})
          &gt; ((CT1s3x4x3072[-8.020179748535156,7.753192901611328:A0.003699309034244733],),{})
          &lt; (CT1s2x3x3072[-4.039342880249023,4.108699798583984:A-0.010241697305276453],)
          &lt; (CT1s3x4x3072[-4.0763678550720215,3.8849968910217285:A0.001773235593723715],)
        &lt;&lt;&lt;
        &gt;&gt;&gt; rotary_emb: Phi3RotaryEmbedding
          &gt; ((CT1s2x3x3072[-0.09246909618377686,0.07369624078273773:A-3.130963592056255e-05],),dict(position_ids:CT7s1x3[30,32:A31.0]))
          &gt; ((CT1s3x4x3072[-0.07948524504899979,0.07863165438175201:A6.865088794481968e-05],),dict(position_ids:CT7s1x4[31,34:A32.5]))
          &lt; (CT1s1x3x96[-1.1855769157409668,1.1902371644973755:A0.746652018013669],CT1s1x3x96[-1.1887905597686768,1.190193772315979:A0.1589894221542636])
          &lt; (CT1s1x4x96[-1.1855769157409668,1.190237045288086:A0.7129333875218435],CT1s1x4x96[-1.1719439029693604,1.1902378797531128:A0.18296290554159592])
        &lt;&lt;&lt;
      &lt; (dict(last_hidden_state:CT1s2x3x3072[-4.039342880249023,4.108699798583984:A-0.010241697305276453],past_key_values:DynamicCache(key_cache=#2[CT1s2x32x33x96[-5.321568965911865,5.071047306060791:A-0.0010730019231920205],CT1s2x32x33x96[-4.981376647949219,4.765379905700684:A0.0025422255894368135]], value_cache=#2[CT1s2x32x33x96[-4.218534469604492,4.59930944442749:A-0.005605154250588178],CT1s2x32x33x96[-4.646946907043457,5.0260820388793945:A0.001844236126241237]])),)
      &lt; (dict(last_hidden_state:CT1s3x4x3072[-4.0763678550720215,3.8849968910217285:A0.001773235593723715],past_key_values:DynamicCache(key_cache=#2[CT1s3x32x35x96[-5.2906494140625,4.7679948806762695:A-0.0028739331352421174],CT1s3x32x35x96[-5.3778486251831055,6.231717109680176:A-0.0017655372309230257]], value_cache=#2[CT1s3x32x35x96[-4.575429439544678,4.348228454589844:A0.0014538525100350908],CT1s3x32x35x96[-4.735829830169678,5.559142112731934:A0.0021215061804070365]])),)
    &lt;&lt;&lt;
    &gt;&gt;&gt; lm_head: Linear
      &gt; ((CT1s2x3x3072[-4.039342880249023,4.108699798583984:A-0.010241697305276453],),{})
      &gt; ((CT1s3x4x3072[-4.0763678550720215,3.8849968910217285:A0.001773235593723715],),{})
      &lt; (CT1s2x3x32064[-4.781582355499268,4.740781307220459:A-0.000884814476446486],)
      &lt; (CT1s3x4x32064[-5.196939945220947,5.246708869934082:A-0.0011729046776157495],)
    &lt;&lt;&lt;
  &lt; (dict(logits:CT1s2x3x32064[-4.781582355499268,4.740781307220459:A-0.000884814476446486],past_key_values:DynamicCache(key_cache=#2[CT1s2x32x33x96[-5.321568965911865,5.071047306060791:A-0.0010730019231920205],CT1s2x32x33x96[-4.981376647949219,4.765379905700684:A0.0025422255894368135]], value_cache=#2[CT1s2x32x33x96[-4.218534469604492,4.59930944442749:A-0.005605154250588178],CT1s2x32x33x96[-4.646946907043457,5.0260820388793945:A0.001844236126241237]])),)
  &lt; (dict(logits:CT1s3x4x32064[-5.196939945220947,5.246708869934082:A-0.0011729046776157495],past_key_values:DynamicCache(key_cache=#2[CT1s3x32x35x96[-5.2906494140625,4.7679948806762695:A-0.0028739331352421174],CT1s3x32x35x96[-5.3778486251831055,6.231717109680176:A-0.0017655372309230257]], value_cache=#2[CT1s3x32x35x96[-4.575429439544678,4.348228454589844:A0.0014538525100350908],CT1s3x32x35x96[-4.735829830169678,5.559142112731934:A0.0021215061804070365]])),)
&lt;&lt;&lt;
[_untrace_forward_execution]  M:__main__-Phi3ForCausalLM
[_untrace_forward_execution] .. M:model-Phi3Model
[_untrace_forward_execution] .... M:embed_tokens-Embedding
[_untrace_forward_execution] .... M:layers[0]-Phi3DecoderLayer
[_untrace_forward_execution] ...... M:self_attn-Phi3Attention
[_untrace_forward_execution] ........ M:o_proj-Linear
[_untrace_forward_execution] ........ M:qkv_proj-Linear
[_untrace_forward_execution] ...... M:mlp-Phi3MLP
[_untrace_forward_execution] ........ M:gate_up_proj-Linear
[_untrace_forward_execution] ........ M:down_proj-Linear
[_untrace_forward_execution] ........ M:activation_fn-SiLUActivation
[_untrace_forward_execution] ...... M:input_layernorm-Phi3RMSNorm
[_untrace_forward_execution] ...... M:post_attention_layernorm-Phi3RMSNorm
[_untrace_forward_execution] ...... M:resid_attn_dropout-Dropout
[_untrace_forward_execution] ...... M:resid_mlp_dropout-Dropout
[_untrace_forward_execution] .... M:layers[1]-Phi3DecoderLayer
[_untrace_forward_execution] ...... M:self_attn-Phi3Attention
[_untrace_forward_execution] ........ M:o_proj-Linear
[_untrace_forward_execution] ........ M:qkv_proj-Linear
[_untrace_forward_execution] ...... M:mlp-Phi3MLP
[_untrace_forward_execution] ........ M:gate_up_proj-Linear
[_untrace_forward_execution] ........ M:down_proj-Linear
[_untrace_forward_execution] ........ M:activation_fn-SiLUActivation
[_untrace_forward_execution] ...... M:input_layernorm-Phi3RMSNorm
[_untrace_forward_execution] ...... M:post_attention_layernorm-Phi3RMSNorm
[_untrace_forward_execution] ...... M:resid_attn_dropout-Dropout
[_untrace_forward_execution] ...... M:resid_mlp_dropout-Dropout
[_untrace_forward_execution] .... M:norm-Phi3RMSNorm
[_untrace_forward_execution] .... M:rotary_emb-Phi3RotaryEmbedding
[_untrace_forward_execution] .. M:lm_head-Linear
</pre></div>
</div>
<p>Now we keep in memory every input/output for the submodules,
we can guess the dynamic shapes for every of them.
The final ones:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dynamic_shapes</span></a></a> <span class="o">=</span> <a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/piece_by_piece.html#experimental_experiment.torch_interpreter.piece_by_piece.ModelDiagnoseOutput.guess_dynamic_shapes" title="experimental_experiment.torch_interpreter.piece_by_piece.ModelDiagnoseOutput.guess_dynamic_shapes" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter-piece_by_piece sphx-glr-backref-type-py-method"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/piece_by_piece.html#experimental_experiment.torch_interpreter.piece_by_piece.ModelDiagnoseOutput.guess_dynamic_shapes" title="experimental_experiment.torch_interpreter.piece_by_piece.ModelDiagnoseOutput.guess_dynamic_shapes" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter-piece_by_piece sphx-glr-backref-type-py-method"><span class="n">diag</span><span class="o">.</span><span class="n">guess_dynamic_shapes</span></a></a><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The dynamic shapes are:&quot;</span><span class="p">)</span>
<a href="https://docs.python.org/3/library/pprint.html#pprint.pprint" title="pprint.pprint" class="sphx-glr-backref-module-pprint sphx-glr-backref-type-py-function"><a href="https://docs.python.org/3/library/pprint.html#pprint.pprint" title="pprint.pprint" class="sphx-glr-backref-module-pprint sphx-glr-backref-type-py-function"><span class="n">pprint</span><span class="o">.</span><span class="n">pprint</span></a></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dynamic_shapes</span></a></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>The dynamic shapes are:
((),
 {&#39;attention_mask&#39;: {0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},
  &#39;input_ids&#39;: {0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},
  &#39;past_key_values&#39;: [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)},
                      {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)},
                      {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)},
                      {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}]})
</pre></div>
</div>
<p>And all the dynamic shapes all along the traced submodules.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span>
    <a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/piece_by_piece.html#experimental_experiment.torch_interpreter.piece_by_piece.ModelDiagnoseOutput.pretty_text" title="experimental_experiment.torch_interpreter.piece_by_piece.ModelDiagnoseOutput.pretty_text" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter-piece_by_piece sphx-glr-backref-type-py-method"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/piece_by_piece.html#experimental_experiment.torch_interpreter.piece_by_piece.ModelDiagnoseOutput.pretty_text" title="experimental_experiment.torch_interpreter.piece_by_piece.ModelDiagnoseOutput.pretty_text" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter-piece_by_piece sphx-glr-backref-type-py-method"><span class="n">diag</span><span class="o">.</span><span class="n">pretty_text</span></a></a><span class="p">(</span>
        <span class="n">with_dynamic_shape</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">with_shape</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">with_min_max</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">with_device</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">with_inputs</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;&lt;_DimHint.DYNAMIC: 3&gt;&quot;</span><span class="p">,</span> <span class="s2">&quot;DYN&quot;</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&gt;&gt;&gt; __main__: Phi3ForCausalLM
  DS=((), {&#39;attention_mask&#39;: {0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)}, &#39;input_ids&#39;: {0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)}, &#39;past_key_values&#39;: [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}]})
    &gt;&gt;&gt; model: Phi3Model
      DS=((), {&#39;attention_mask&#39;: {0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)}, &#39;cache_position&#39;: None, &#39;input_ids&#39;: {0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)}, &#39;inputs_embeds&#39;: None, &#39;past_key_values&#39;: [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}], &#39;position_ids&#39;: None, &#39;use_cache&#39;: None})
        &gt;&gt;&gt; embed_tokens: Embedding: DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {}) &lt;&lt;&lt;
        &gt;&gt;&gt; layers[0]: Phi3DecoderLayer
          DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {&#39;attention_mask&#39;: {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC), 3: DimHint(DYNAMIC)}, &#39;cache_position&#39;: {0: DimHint(DYNAMIC)}, &#39;past_key_values&#39;: [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}], &#39;position_embeddings&#39;: ({1: DimHint(DYNAMIC)}, {1: DimHint(DYNAMIC)}), &#39;position_ids&#39;: {1: DimHint(DYNAMIC)}, &#39;use_cache&#39;: None})
            &gt;&gt;&gt; self_attn: Phi3Attention
              DS=((), {&#39;attention_mask&#39;: {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC), 3: DimHint(DYNAMIC)}, &#39;cache_position&#39;: {0: DimHint(DYNAMIC)}, &#39;hidden_states&#39;: {0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)}, &#39;past_key_values&#39;: [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}], &#39;position_embeddings&#39;: ({1: DimHint(DYNAMIC)}, {1: DimHint(DYNAMIC)}), &#39;position_ids&#39;: {1: DimHint(DYNAMIC)}, &#39;use_cache&#39;: None})
                &gt;&gt;&gt; o_proj: Linear: DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {}) &lt;&lt;&lt;
                &gt;&gt;&gt; qkv_proj: Linear: DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {}) &lt;&lt;&lt;
            &lt;&lt;&lt;
            &gt;&gt;&gt; mlp: Phi3MLP
              DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {})
                &gt;&gt;&gt; gate_up_proj: Linear: DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {}) &lt;&lt;&lt;
                &gt;&gt;&gt; down_proj: Linear: DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {}) &lt;&lt;&lt;
                &gt;&gt;&gt; activation_fn: SiLUActivation: DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {}) &lt;&lt;&lt;
            &lt;&lt;&lt;
            &gt;&gt;&gt; input_layernorm: Phi3RMSNorm: DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {}) &lt;&lt;&lt;
            &gt;&gt;&gt; post_attention_layernorm: Phi3RMSNorm: DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {}) &lt;&lt;&lt;
            &gt;&gt;&gt; resid_attn_dropout: Dropout: DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {}) &lt;&lt;&lt;
            &gt;&gt;&gt; resid_mlp_dropout: Dropout: DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {}) &lt;&lt;&lt;
        &lt;&lt;&lt;
        &gt;&gt;&gt; layers[1]: Phi3DecoderLayer
          DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {&#39;attention_mask&#39;: {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC), 3: DimHint(DYNAMIC)}, &#39;cache_position&#39;: {0: DimHint(DYNAMIC)}, &#39;past_key_values&#39;: [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}], &#39;position_embeddings&#39;: ({1: DimHint(DYNAMIC)}, {1: DimHint(DYNAMIC)}), &#39;position_ids&#39;: {1: DimHint(DYNAMIC)}, &#39;use_cache&#39;: None})
            &gt;&gt;&gt; self_attn: Phi3Attention
              DS=((), {&#39;attention_mask&#39;: {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC), 3: DimHint(DYNAMIC)}, &#39;cache_position&#39;: {0: DimHint(DYNAMIC)}, &#39;hidden_states&#39;: {0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)}, &#39;past_key_values&#39;: [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}], &#39;position_embeddings&#39;: ({1: DimHint(DYNAMIC)}, {1: DimHint(DYNAMIC)}), &#39;position_ids&#39;: {1: DimHint(DYNAMIC)}, &#39;use_cache&#39;: None})
                &gt;&gt;&gt; o_proj: Linear: DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {}) &lt;&lt;&lt;
                &gt;&gt;&gt; qkv_proj: Linear: DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {}) &lt;&lt;&lt;
            &lt;&lt;&lt;
            &gt;&gt;&gt; mlp: Phi3MLP
              DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {})
                &gt;&gt;&gt; gate_up_proj: Linear: DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {}) &lt;&lt;&lt;
                &gt;&gt;&gt; down_proj: Linear: DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {}) &lt;&lt;&lt;
                &gt;&gt;&gt; activation_fn: SiLUActivation: DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {}) &lt;&lt;&lt;
            &lt;&lt;&lt;
            &gt;&gt;&gt; input_layernorm: Phi3RMSNorm: DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {}) &lt;&lt;&lt;
            &gt;&gt;&gt; post_attention_layernorm: Phi3RMSNorm: DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {}) &lt;&lt;&lt;
            &gt;&gt;&gt; resid_attn_dropout: Dropout: DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {}) &lt;&lt;&lt;
            &gt;&gt;&gt; resid_mlp_dropout: Dropout: DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {}) &lt;&lt;&lt;
        &lt;&lt;&lt;
        &gt;&gt;&gt; norm: Phi3RMSNorm: DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {}) &lt;&lt;&lt;
        &gt;&gt;&gt; rotary_emb: Phi3RotaryEmbedding: DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {&#39;position_ids&#39;: {1: DimHint(DYNAMIC)}}) &lt;&lt;&lt;
    &lt;&lt;&lt;
    &gt;&gt;&gt; lm_head: Linear: DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {}) &lt;&lt;&lt;
&lt;&lt;&lt;
</pre></div>
</div>
</section>
<section id="evaluate-the-export">
<h2>Evaluate the export<a class="headerlink" href="#evaluate-the-export" title="Link to this heading"></a></h2>
<p>In many cases, the export (to <a class="reference external" href="https://docs.pytorch.org/docs/stable/fx.html#torch.fx.Graph" title="(in PyTorch v2.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.fx.Graph</span></code></a>, to ONNX)
does not work on the first try. We need a way to understand
how much the model can be exported. It can be used to evaluate
the how much code needs to be rewritten or patched to be exportable.
The verbosity can be increase to show dynamic shapes, results
of the discrepancies.
Lets display the module and its submodule first.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span>
    <a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/piece_by_piece.html#experimental_experiment.torch_interpreter.piece_by_piece.ModelDiagnoseOutput.pretty_text" title="experimental_experiment.torch_interpreter.piece_by_piece.ModelDiagnoseOutput.pretty_text" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter-piece_by_piece sphx-glr-backref-type-py-method"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/piece_by_piece.html#experimental_experiment.torch_interpreter.piece_by_piece.ModelDiagnoseOutput.pretty_text" title="experimental_experiment.torch_interpreter.piece_by_piece.ModelDiagnoseOutput.pretty_text" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter-piece_by_piece sphx-glr-backref-type-py-method"><span class="n">diag</span><span class="o">.</span><span class="n">pretty_text</span></a></a><span class="p">(</span>
        <span class="n">with_dynamic_shape</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">with_shape</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">with_min_max</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">with_device</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">with_inputs</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&gt;&gt;&gt; __main__: Phi3ForCausalLM
    &gt;&gt;&gt; model: Phi3Model
        &gt;&gt;&gt; embed_tokens: Embedding &lt;&lt;&lt;
        &gt;&gt;&gt; layers[0]: Phi3DecoderLayer
            &gt;&gt;&gt; self_attn: Phi3Attention
                &gt;&gt;&gt; o_proj: Linear &lt;&lt;&lt;
                &gt;&gt;&gt; qkv_proj: Linear &lt;&lt;&lt;
            &lt;&lt;&lt;
            &gt;&gt;&gt; mlp: Phi3MLP
                &gt;&gt;&gt; gate_up_proj: Linear &lt;&lt;&lt;
                &gt;&gt;&gt; down_proj: Linear &lt;&lt;&lt;
                &gt;&gt;&gt; activation_fn: SiLUActivation &lt;&lt;&lt;
            &lt;&lt;&lt;
            &gt;&gt;&gt; input_layernorm: Phi3RMSNorm &lt;&lt;&lt;
            &gt;&gt;&gt; post_attention_layernorm: Phi3RMSNorm &lt;&lt;&lt;
            &gt;&gt;&gt; resid_attn_dropout: Dropout &lt;&lt;&lt;
            &gt;&gt;&gt; resid_mlp_dropout: Dropout &lt;&lt;&lt;
        &lt;&lt;&lt;
        &gt;&gt;&gt; layers[1]: Phi3DecoderLayer
            &gt;&gt;&gt; self_attn: Phi3Attention
                &gt;&gt;&gt; o_proj: Linear &lt;&lt;&lt;
                &gt;&gt;&gt; qkv_proj: Linear &lt;&lt;&lt;
            &lt;&lt;&lt;
            &gt;&gt;&gt; mlp: Phi3MLP
                &gt;&gt;&gt; gate_up_proj: Linear &lt;&lt;&lt;
                &gt;&gt;&gt; down_proj: Linear &lt;&lt;&lt;
                &gt;&gt;&gt; activation_fn: SiLUActivation &lt;&lt;&lt;
            &lt;&lt;&lt;
            &gt;&gt;&gt; input_layernorm: Phi3RMSNorm &lt;&lt;&lt;
            &gt;&gt;&gt; post_attention_layernorm: Phi3RMSNorm &lt;&lt;&lt;
            &gt;&gt;&gt; resid_attn_dropout: Dropout &lt;&lt;&lt;
            &gt;&gt;&gt; resid_mlp_dropout: Dropout &lt;&lt;&lt;
        &lt;&lt;&lt;
        &gt;&gt;&gt; norm: Phi3RMSNorm &lt;&lt;&lt;
        &gt;&gt;&gt; rotary_emb: Phi3RotaryEmbedding &lt;&lt;&lt;
    &lt;&lt;&lt;
    &gt;&gt;&gt; lm_head: Linear &lt;&lt;&lt;
&lt;&lt;&lt;
</pre></div>
</div>
<p>The we try to export to see the submodule failing the whole model.
We can pickle the failing model and restore it to speedup
the refactoring to make it work.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;----------------------&quot;</span><span class="p">)</span>
<a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/piece_by_piece.html#experimental_experiment.torch_interpreter.piece_by_piece.StatusExport" title="experimental_experiment.torch_interpreter.piece_by_piece.StatusExport" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter-piece_by_piece sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/piece_by_piece.html#experimental_experiment.torch_interpreter.piece_by_piece.StatusExport" title="experimental_experiment.torch_interpreter.piece_by_piece.StatusExport" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter-piece_by_piece sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ep</span></a></a> <span class="o">=</span> <a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/piece_by_piece.html#experimental_experiment.torch_interpreter.piece_by_piece.ModelDiagnoseOutput.try_export" title="experimental_experiment.torch_interpreter.piece_by_piece.ModelDiagnoseOutput.try_export" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter-piece_by_piece sphx-glr-backref-type-py-method"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/piece_by_piece.html#experimental_experiment.torch_interpreter.piece_by_piece.ModelDiagnoseOutput.try_export" title="experimental_experiment.torch_interpreter.piece_by_piece.ModelDiagnoseOutput.try_export" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter-piece_by_piece sphx-glr-backref-type-py-method"><span class="n">diag</span><span class="o">.</span><span class="n">try_export</span></a></a><span class="p">(</span>
    <span class="n">exporter</span><span class="o">=</span><span class="s2">&quot;fx&quot;</span><span class="p">,</span>
    <span class="n">use_dynamic_shapes</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">exporter_kwargs</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>----------------------

[torch_export] export starts with backed_size_oblivious=False
[try_export-FX]  M:__main__-Phi3ForCausalLM --- FAIL, step=EXPORT, reason=Cannot associate shape [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}] specified at `dynamic_shapes[&#39;past_key_values&#39;]` to non-tensor type &lt;class &#39;transformers.cache_utils.DynamicCache&#39;&gt; at `inputs[&#39;past_key_values&#39;]` (expected None) --- For more information about this error, see: https://pytorch.org/docs/main/generated/exportdb/index.html#dynamic-shapes-validation ---  --- The error above occurred when calling torch.export.export. If you would like to view some more information about this error, and get a list of all other errors that may occur in your export call, you can replace your `export()` call with `draft_export()`.[&#39;Traceback (most recent call last):\n&#39;, &#39;  File &quot;~/github/experimental-experiment/experimental_experiment/torch_interpreter/piece_by_piece.py&quot;, line 1573, in _try_export_no_bypass_export\n    ep = torch_export(\n         ^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/github/experimental-experiment/experimental_experiment/export_helpers.py&quot;, line 164, in torch_export\n    return torch.export.export(\n           ^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/__init__.py&quot;, line 311, in export\n    raise e\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/__init__.py&quot;, line 277, in export\n    return _export(\n           ^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 1272, in wrapper\n    raise e\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 1238, in wrapper\n    ep = fn(*args, **kwargs)\n         ^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/exported_program.py&quot;, line 124, in wrapper\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 2379, in _export\n    ep = _export_for_training(\n         ^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 1272, in wrapper\n    raise e\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 1238, in wrapper\n    ep = fn(*args, **kwargs)\n         ^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/exported_program.py&quot;, line 124, in wrapper\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 2187, in _export_for_training\n    export_artifact = export_func(\n                      ^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 2071, in _non_strict_export\n    ) = make_fake_inputs(\n        ^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/_export/non_strict_utils.py&quot;, line 414, in make_fake_inputs\n    _check_dynamic_shapes(combined_args, dynamic_shapes)\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py&quot;, line 1049, in _check_dynamic_shapes\n    _tree_map_with_path(check_shape, combined_args, dynamic_shapes, tree_name=&quot;inputs&quot;)\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py&quot;, line 630, in _tree_map_with_path\n    return tree_map_with_path(f, tree, *dynamic_shapes, is_leaf=is_leaf)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/utils/_pytree.py&quot;, line 2205, in tree_map_with_path\n    return treespec.unflatten(func(*xs) for xs in zip(*all_keypath_leaves, strict=True))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/utils/_pytree.py&quot;, line 1278, in unflatten\n    leaves = list(leaves)\n             ^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/utils/_pytree.py&quot;, line 2205, in &lt;genexpr&gt;\n    return treespec.unflatten(func(*xs) for xs in zip(*all_keypath_leaves, strict=True))\n                              ^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py&quot;, line 627, in f\n    return func(path, t, *dynamic_shapes)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py&quot;, line 1042, in check_shape\n    raise UserError(\n&#39;, &quot;torch._dynamo.exc.UserError: Cannot associate shape [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}] specified at `dynamic_shapes[&#39;past_key_values&#39;]` to non-tensor type &lt;class &#39;transformers.cache_utils.DynamicCache&#39;&gt; at `inputs[&#39;past_key_values&#39;]` (expected None)\nFor more information about this error, see: https://pytorch.org/docs/main/generated/exportdb/index.html#dynamic-shapes-validation\n\nThe error above occurred when calling torch.export.export. If you would like to view some more information about this error, and get a list of all other errors that may occur in your export call, you can replace your `export()` call with `draft_export()`.\n&quot;]
[torch_export] export starts with backed_size_oblivious=False
[try_export-FX] .. M:model-Phi3Model --- FAIL, step=EXPORT, reason=Cannot associate shape [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}] specified at `dynamic_shapes[&#39;past_key_values&#39;]` to non-tensor type &lt;class &#39;transformers.cache_utils.DynamicCache&#39;&gt; at `inputs[&#39;past_key_values&#39;]` (expected None) --- For more information about this error, see: https://pytorch.org/docs/main/generated/exportdb/index.html#dynamic-shapes-validation ---  --- The error above occurred when calling torch.export.export. If you would like to view some more information about this error, and get a list of all other errors that may occur in your export call, you can replace your `export()` call with `draft_export()`.[&#39;Traceback (most recent call last):\n&#39;, &#39;  File &quot;~/github/experimental-experiment/experimental_experiment/torch_interpreter/piece_by_piece.py&quot;, line 1573, in _try_export_no_bypass_export\n    ep = torch_export(\n         ^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/github/experimental-experiment/experimental_experiment/export_helpers.py&quot;, line 164, in torch_export\n    return torch.export.export(\n           ^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/__init__.py&quot;, line 311, in export\n    raise e\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/__init__.py&quot;, line 277, in export\n    return _export(\n           ^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 1272, in wrapper\n    raise e\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 1238, in wrapper\n    ep = fn(*args, **kwargs)\n         ^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/exported_program.py&quot;, line 124, in wrapper\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 2379, in _export\n    ep = _export_for_training(\n         ^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 1272, in wrapper\n    raise e\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 1238, in wrapper\n    ep = fn(*args, **kwargs)\n         ^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/exported_program.py&quot;, line 124, in wrapper\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 2187, in _export_for_training\n    export_artifact = export_func(\n                      ^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 2071, in _non_strict_export\n    ) = make_fake_inputs(\n        ^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/_export/non_strict_utils.py&quot;, line 414, in make_fake_inputs\n    _check_dynamic_shapes(combined_args, dynamic_shapes)\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py&quot;, line 1049, in _check_dynamic_shapes\n    _tree_map_with_path(check_shape, combined_args, dynamic_shapes, tree_name=&quot;inputs&quot;)\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py&quot;, line 630, in _tree_map_with_path\n    return tree_map_with_path(f, tree, *dynamic_shapes, is_leaf=is_leaf)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/utils/_pytree.py&quot;, line 2205, in tree_map_with_path\n    return treespec.unflatten(func(*xs) for xs in zip(*all_keypath_leaves, strict=True))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/utils/_pytree.py&quot;, line 1278, in unflatten\n    leaves = list(leaves)\n             ^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/utils/_pytree.py&quot;, line 2205, in &lt;genexpr&gt;\n    return treespec.unflatten(func(*xs) for xs in zip(*all_keypath_leaves, strict=True))\n                              ^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py&quot;, line 627, in f\n    return func(path, t, *dynamic_shapes)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py&quot;, line 1042, in check_shape\n    raise UserError(\n&#39;, &quot;torch._dynamo.exc.UserError: Cannot associate shape [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}] specified at `dynamic_shapes[&#39;past_key_values&#39;]` to non-tensor type &lt;class &#39;transformers.cache_utils.DynamicCache&#39;&gt; at `inputs[&#39;past_key_values&#39;]` (expected None)\nFor more information about this error, see: https://pytorch.org/docs/main/generated/exportdb/index.html#dynamic-shapes-validation\n\nThe error above occurred when calling torch.export.export. If you would like to view some more information about this error, and get a list of all other errors that may occur in your export call, you can replace your `export()` call with `draft_export()`.\n&quot;]
[torch_export] export starts with backed_size_oblivious=False
[try_export-FX] .... M:embed_tokens-Embedding --- OK:
[torch_export] export starts with backed_size_oblivious=False
[try_export-FX] .... M:layers[0]-Phi3DecoderLayer --- FAIL, step=EXPORT, reason=Cannot associate shape [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}] specified at `dynamic_shapes[&#39;past_key_values&#39;]` to non-tensor type &lt;class &#39;transformers.cache_utils.DynamicCache&#39;&gt; at `inputs[&#39;past_key_values&#39;]` (expected None) --- For more information about this error, see: https://pytorch.org/docs/main/generated/exportdb/index.html#dynamic-shapes-validation ---  --- The error above occurred when calling torch.export.export. If you would like to view some more information about this error, and get a list of all other errors that may occur in your export call, you can replace your `export()` call with `draft_export()`.[&#39;Traceback (most recent call last):\n&#39;, &#39;  File &quot;~/github/experimental-experiment/experimental_experiment/torch_interpreter/piece_by_piece.py&quot;, line 1573, in _try_export_no_bypass_export\n    ep = torch_export(\n         ^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/github/experimental-experiment/experimental_experiment/export_helpers.py&quot;, line 164, in torch_export\n    return torch.export.export(\n           ^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/__init__.py&quot;, line 311, in export\n    raise e\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/__init__.py&quot;, line 277, in export\n    return _export(\n           ^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 1272, in wrapper\n    raise e\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 1238, in wrapper\n    ep = fn(*args, **kwargs)\n         ^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/exported_program.py&quot;, line 124, in wrapper\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 2379, in _export\n    ep = _export_for_training(\n         ^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 1272, in wrapper\n    raise e\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 1238, in wrapper\n    ep = fn(*args, **kwargs)\n         ^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/exported_program.py&quot;, line 124, in wrapper\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 2187, in _export_for_training\n    export_artifact = export_func(\n                      ^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 2071, in _non_strict_export\n    ) = make_fake_inputs(\n        ^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/_export/non_strict_utils.py&quot;, line 414, in make_fake_inputs\n    _check_dynamic_shapes(combined_args, dynamic_shapes)\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py&quot;, line 1049, in _check_dynamic_shapes\n    _tree_map_with_path(check_shape, combined_args, dynamic_shapes, tree_name=&quot;inputs&quot;)\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py&quot;, line 630, in _tree_map_with_path\n    return tree_map_with_path(f, tree, *dynamic_shapes, is_leaf=is_leaf)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/utils/_pytree.py&quot;, line 2205, in tree_map_with_path\n    return treespec.unflatten(func(*xs) for xs in zip(*all_keypath_leaves, strict=True))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/utils/_pytree.py&quot;, line 1278, in unflatten\n    leaves = list(leaves)\n             ^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/utils/_pytree.py&quot;, line 2205, in &lt;genexpr&gt;\n    return treespec.unflatten(func(*xs) for xs in zip(*all_keypath_leaves, strict=True))\n                              ^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py&quot;, line 627, in f\n    return func(path, t, *dynamic_shapes)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py&quot;, line 1042, in check_shape\n    raise UserError(\n&#39;, &quot;torch._dynamo.exc.UserError: Cannot associate shape [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}] specified at `dynamic_shapes[&#39;past_key_values&#39;]` to non-tensor type &lt;class &#39;transformers.cache_utils.DynamicCache&#39;&gt; at `inputs[&#39;past_key_values&#39;]` (expected None)\nFor more information about this error, see: https://pytorch.org/docs/main/generated/exportdb/index.html#dynamic-shapes-validation\n\nThe error above occurred when calling torch.export.export. If you would like to view some more information about this error, and get a list of all other errors that may occur in your export call, you can replace your `export()` call with `draft_export()`.\n&quot;]
[torch_export] export starts with backed_size_oblivious=False
[try_export-FX] ...... M:self_attn-Phi3Attention --- FAIL, step=EXPORT, reason=Cannot associate shape [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}] specified at `dynamic_shapes[&#39;past_key_values&#39;]` to non-tensor type &lt;class &#39;transformers.cache_utils.DynamicCache&#39;&gt; at `inputs[&#39;past_key_values&#39;]` (expected None) --- For more information about this error, see: https://pytorch.org/docs/main/generated/exportdb/index.html#dynamic-shapes-validation ---  --- The error above occurred when calling torch.export.export. If you would like to view some more information about this error, and get a list of all other errors that may occur in your export call, you can replace your `export()` call with `draft_export()`.[&#39;Traceback (most recent call last):\n&#39;, &#39;  File &quot;~/github/experimental-experiment/experimental_experiment/torch_interpreter/piece_by_piece.py&quot;, line 1573, in _try_export_no_bypass_export\n    ep = torch_export(\n         ^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/github/experimental-experiment/experimental_experiment/export_helpers.py&quot;, line 164, in torch_export\n    return torch.export.export(\n           ^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/__init__.py&quot;, line 311, in export\n    raise e\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/__init__.py&quot;, line 277, in export\n    return _export(\n           ^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 1272, in wrapper\n    raise e\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 1238, in wrapper\n    ep = fn(*args, **kwargs)\n         ^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/exported_program.py&quot;, line 124, in wrapper\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 2379, in _export\n    ep = _export_for_training(\n         ^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 1272, in wrapper\n    raise e\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 1238, in wrapper\n    ep = fn(*args, **kwargs)\n         ^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/exported_program.py&quot;, line 124, in wrapper\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 2187, in _export_for_training\n    export_artifact = export_func(\n                      ^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 2071, in _non_strict_export\n    ) = make_fake_inputs(\n        ^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/_export/non_strict_utils.py&quot;, line 414, in make_fake_inputs\n    _check_dynamic_shapes(combined_args, dynamic_shapes)\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py&quot;, line 1049, in _check_dynamic_shapes\n    _tree_map_with_path(check_shape, combined_args, dynamic_shapes, tree_name=&quot;inputs&quot;)\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py&quot;, line 630, in _tree_map_with_path\n    return tree_map_with_path(f, tree, *dynamic_shapes, is_leaf=is_leaf)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/utils/_pytree.py&quot;, line 2205, in tree_map_with_path\n    return treespec.unflatten(func(*xs) for xs in zip(*all_keypath_leaves, strict=True))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/utils/_pytree.py&quot;, line 1278, in unflatten\n    leaves = list(leaves)\n             ^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/utils/_pytree.py&quot;, line 2205, in &lt;genexpr&gt;\n    return treespec.unflatten(func(*xs) for xs in zip(*all_keypath_leaves, strict=True))\n                              ^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py&quot;, line 627, in f\n    return func(path, t, *dynamic_shapes)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py&quot;, line 1042, in check_shape\n    raise UserError(\n&#39;, &quot;torch._dynamo.exc.UserError: Cannot associate shape [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}] specified at `dynamic_shapes[&#39;past_key_values&#39;]` to non-tensor type &lt;class &#39;transformers.cache_utils.DynamicCache&#39;&gt; at `inputs[&#39;past_key_values&#39;]` (expected None)\nFor more information about this error, see: https://pytorch.org/docs/main/generated/exportdb/index.html#dynamic-shapes-validation\n\nThe error above occurred when calling torch.export.export. If you would like to view some more information about this error, and get a list of all other errors that may occur in your export call, you can replace your `export()` call with `draft_export()`.\n&quot;]
[torch_export] export starts with backed_size_oblivious=False
[try_export-FX] ........ M:o_proj-Linear --- OK:
[torch_export] export starts with backed_size_oblivious=False
[try_export-FX] ........ M:qkv_proj-Linear --- OK:
[torch_export] export starts with backed_size_oblivious=False
[try_export-FX] ...... M:mlp-Phi3MLP --- OK:
[torch_export] export starts with backed_size_oblivious=False
[try_export-FX] ...... M:input_layernorm-Phi3RMSNorm --- OK:
[torch_export] export starts with backed_size_oblivious=False
[try_export-FX] ...... M:post_attention_layernorm-Phi3RMSNorm --- OK:
[torch_export] export starts with backed_size_oblivious=False
[try_export-FX] ...... M:resid_attn_dropout-Dropout --- OK:
[torch_export] export starts with backed_size_oblivious=False
[try_export-FX] ...... M:resid_mlp_dropout-Dropout --- OK:
[torch_export] export starts with backed_size_oblivious=False
[try_export-FX] .... M:layers[1]-Phi3DecoderLayer --- FAIL, step=EXPORT, reason=Cannot associate shape [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}] specified at `dynamic_shapes[&#39;past_key_values&#39;]` to non-tensor type &lt;class &#39;transformers.cache_utils.DynamicCache&#39;&gt; at `inputs[&#39;past_key_values&#39;]` (expected None) --- For more information about this error, see: https://pytorch.org/docs/main/generated/exportdb/index.html#dynamic-shapes-validation ---  --- The error above occurred when calling torch.export.export. If you would like to view some more information about this error, and get a list of all other errors that may occur in your export call, you can replace your `export()` call with `draft_export()`.[&#39;Traceback (most recent call last):\n&#39;, &#39;  File &quot;~/github/experimental-experiment/experimental_experiment/torch_interpreter/piece_by_piece.py&quot;, line 1573, in _try_export_no_bypass_export\n    ep = torch_export(\n         ^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/github/experimental-experiment/experimental_experiment/export_helpers.py&quot;, line 164, in torch_export\n    return torch.export.export(\n           ^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/__init__.py&quot;, line 311, in export\n    raise e\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/__init__.py&quot;, line 277, in export\n    return _export(\n           ^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 1272, in wrapper\n    raise e\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 1238, in wrapper\n    ep = fn(*args, **kwargs)\n         ^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/exported_program.py&quot;, line 124, in wrapper\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 2379, in _export\n    ep = _export_for_training(\n         ^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 1272, in wrapper\n    raise e\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 1238, in wrapper\n    ep = fn(*args, **kwargs)\n         ^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/exported_program.py&quot;, line 124, in wrapper\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 2187, in _export_for_training\n    export_artifact = export_func(\n                      ^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 2071, in _non_strict_export\n    ) = make_fake_inputs(\n        ^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/_export/non_strict_utils.py&quot;, line 414, in make_fake_inputs\n    _check_dynamic_shapes(combined_args, dynamic_shapes)\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py&quot;, line 1049, in _check_dynamic_shapes\n    _tree_map_with_path(check_shape, combined_args, dynamic_shapes, tree_name=&quot;inputs&quot;)\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py&quot;, line 630, in _tree_map_with_path\n    return tree_map_with_path(f, tree, *dynamic_shapes, is_leaf=is_leaf)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/utils/_pytree.py&quot;, line 2205, in tree_map_with_path\n    return treespec.unflatten(func(*xs) for xs in zip(*all_keypath_leaves, strict=True))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/utils/_pytree.py&quot;, line 1278, in unflatten\n    leaves = list(leaves)\n             ^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/utils/_pytree.py&quot;, line 2205, in &lt;genexpr&gt;\n    return treespec.unflatten(func(*xs) for xs in zip(*all_keypath_leaves, strict=True))\n                              ^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py&quot;, line 627, in f\n    return func(path, t, *dynamic_shapes)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py&quot;, line 1042, in check_shape\n    raise UserError(\n&#39;, &quot;torch._dynamo.exc.UserError: Cannot associate shape [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}] specified at `dynamic_shapes[&#39;past_key_values&#39;]` to non-tensor type &lt;class &#39;transformers.cache_utils.DynamicCache&#39;&gt; at `inputs[&#39;past_key_values&#39;]` (expected None)\nFor more information about this error, see: https://pytorch.org/docs/main/generated/exportdb/index.html#dynamic-shapes-validation\n\nThe error above occurred when calling torch.export.export. If you would like to view some more information about this error, and get a list of all other errors that may occur in your export call, you can replace your `export()` call with `draft_export()`.\n&quot;]
[torch_export] export starts with backed_size_oblivious=False
[try_export-FX] ...... M:self_attn-Phi3Attention --- FAIL, step=EXPORT, reason=Cannot associate shape [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}] specified at `dynamic_shapes[&#39;past_key_values&#39;]` to non-tensor type &lt;class &#39;transformers.cache_utils.DynamicCache&#39;&gt; at `inputs[&#39;past_key_values&#39;]` (expected None) --- For more information about this error, see: https://pytorch.org/docs/main/generated/exportdb/index.html#dynamic-shapes-validation ---  --- The error above occurred when calling torch.export.export. If you would like to view some more information about this error, and get a list of all other errors that may occur in your export call, you can replace your `export()` call with `draft_export()`.[&#39;Traceback (most recent call last):\n&#39;, &#39;  File &quot;~/github/experimental-experiment/experimental_experiment/torch_interpreter/piece_by_piece.py&quot;, line 1573, in _try_export_no_bypass_export\n    ep = torch_export(\n         ^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/github/experimental-experiment/experimental_experiment/export_helpers.py&quot;, line 164, in torch_export\n    return torch.export.export(\n           ^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/__init__.py&quot;, line 311, in export\n    raise e\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/__init__.py&quot;, line 277, in export\n    return _export(\n           ^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 1272, in wrapper\n    raise e\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 1238, in wrapper\n    ep = fn(*args, **kwargs)\n         ^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/exported_program.py&quot;, line 124, in wrapper\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 2379, in _export\n    ep = _export_for_training(\n         ^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 1272, in wrapper\n    raise e\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 1238, in wrapper\n    ep = fn(*args, **kwargs)\n         ^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/exported_program.py&quot;, line 124, in wrapper\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 2187, in _export_for_training\n    export_artifact = export_func(\n                      ^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 2071, in _non_strict_export\n    ) = make_fake_inputs(\n        ^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/_export/non_strict_utils.py&quot;, line 414, in make_fake_inputs\n    _check_dynamic_shapes(combined_args, dynamic_shapes)\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py&quot;, line 1049, in _check_dynamic_shapes\n    _tree_map_with_path(check_shape, combined_args, dynamic_shapes, tree_name=&quot;inputs&quot;)\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py&quot;, line 630, in _tree_map_with_path\n    return tree_map_with_path(f, tree, *dynamic_shapes, is_leaf=is_leaf)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/utils/_pytree.py&quot;, line 2205, in tree_map_with_path\n    return treespec.unflatten(func(*xs) for xs in zip(*all_keypath_leaves, strict=True))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/utils/_pytree.py&quot;, line 1278, in unflatten\n    leaves = list(leaves)\n             ^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/utils/_pytree.py&quot;, line 2205, in &lt;genexpr&gt;\n    return treespec.unflatten(func(*xs) for xs in zip(*all_keypath_leaves, strict=True))\n                              ^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py&quot;, line 627, in f\n    return func(path, t, *dynamic_shapes)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py&quot;, line 1042, in check_shape\n    raise UserError(\n&#39;, &quot;torch._dynamo.exc.UserError: Cannot associate shape [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}] specified at `dynamic_shapes[&#39;past_key_values&#39;]` to non-tensor type &lt;class &#39;transformers.cache_utils.DynamicCache&#39;&gt; at `inputs[&#39;past_key_values&#39;]` (expected None)\nFor more information about this error, see: https://pytorch.org/docs/main/generated/exportdb/index.html#dynamic-shapes-validation\n\nThe error above occurred when calling torch.export.export. If you would like to view some more information about this error, and get a list of all other errors that may occur in your export call, you can replace your `export()` call with `draft_export()`.\n&quot;]
[torch_export] export starts with backed_size_oblivious=False
[try_export-FX] ........ M:o_proj-Linear --- OK:
[torch_export] export starts with backed_size_oblivious=False
[try_export-FX] ........ M:qkv_proj-Linear --- OK:
[torch_export] export starts with backed_size_oblivious=False
[try_export-FX] ...... M:mlp-Phi3MLP --- OK:
[torch_export] export starts with backed_size_oblivious=False
[try_export-FX] ...... M:input_layernorm-Phi3RMSNorm --- OK:
[torch_export] export starts with backed_size_oblivious=False
[try_export-FX] ...... M:post_attention_layernorm-Phi3RMSNorm --- OK:
[torch_export] export starts with backed_size_oblivious=False
[try_export-FX] ...... M:resid_attn_dropout-Dropout --- OK:
[torch_export] export starts with backed_size_oblivious=False
[try_export-FX] ...... M:resid_mlp_dropout-Dropout --- OK:
[torch_export] export starts with backed_size_oblivious=False
[try_export-FX] .... M:norm-Phi3RMSNorm --- OK:
[torch_export] export starts with backed_size_oblivious=False



def forward(self, arg0_1: &quot;f32[48]&quot;, arg1_1: &quot;f32[s77, s27, 3072]&quot;, arg2_1: &quot;i64[1, s9]&quot;):
    # No stacktrace found for following nodes
    _set_grad_enabled = torch._C._set_grad_enabled(False);  _set_grad_enabled = None
    max_1: &quot;i64[]&quot; = torch.ops.aten.max.default(arg2_1);  arg2_1 = None
    add: &quot;i64[]&quot; = torch.ops.aten.add.Tensor(max_1, 1);  max_1 = None
    gt: &quot;b8[]&quot; = torch.ops.aten.gt.Scalar(add, 4096);  add = None
    ne: &quot;b8[]&quot; = torch.ops.aten.ne.Scalar(gt, 0);  gt = None
    item: &quot;Sym(Eq(u0, 1))&quot; = torch.ops.aten.item.default(ne);  ne = item = None
    _set_grad_enabled_1 = torch._C._set_grad_enabled(True);  _set_grad_enabled_1 = None




def forward(self, arg0_1: &quot;f32[48]&quot;, arg1_1: &quot;f32[s77, s27, 3072]&quot;, arg2_1: &quot;i64[1, s9]&quot;):
    # No stacktrace found for following nodes
    _set_grad_enabled = torch._C._set_grad_enabled(False);  _set_grad_enabled = None
    max_1: &quot;i64[]&quot; = torch.ops.aten.max.default(arg2_1);  arg2_1 = None
    add: &quot;i64[]&quot; = torch.ops.aten.add.Tensor(max_1, 1);  max_1 = None
    gt: &quot;b8[]&quot; = torch.ops.aten.gt.Scalar(add, 4096);  add = None
    ne: &quot;b8[]&quot; = torch.ops.aten.ne.Scalar(gt, 0);  gt = None
    item: &quot;Sym(Eq(u0, 1))&quot; = torch.ops.aten.item.default(ne);  ne = item = None
    _set_grad_enabled_1 = torch._C._set_grad_enabled(True);  _set_grad_enabled_1 = None

[try_export-FX] .... M:rotary_emb-Phi3RotaryEmbedding --- FAIL, step=EXPORT, reason=Could not guard on data-dependent expression Eq(u0, 1) (unhinted: Eq(u0, 1)).  (Size-like symbols: none) ---  --- consider using data-dependent friendly APIs such as guard_or_false, guard_or_true and statically_known_true. --- Caused by: (_export/non_strict_utils.py:1140 in __torch_function__) --- For more information, run with TORCH_LOGS=&quot;dynamic&quot; --- For extended logs when we create symbols, also add TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL=&quot;u0&quot; --- If you suspect the guard was triggered from C++, add TORCHDYNAMO_EXTENDED_DEBUG_CPP=1 --- For more debugging help, see https://docs.google.com/document/d/1HSuTTVvYH1pTew89Rtpeu84Ht3nQEFTYhAX3Ypa_xJs/edit?usp=sharing ---  --- For C++ stack trace, run with TORCHDYNAMO_EXTENDED_DEBUG_CPP=1 ---  --- The following call raised this error: ---   File &quot;~/github/transformers/src/transformers/modeling_rope_utils.py&quot;, line 61, in longrope_frequency_update ---     if seq_len &gt; original_max_position_embeddings: ---  ---  --- The error above occurred when calling torch.export.export. If you would like to view some more information about this error, and get a list of all other errors that may occur in your export call, you can replace your `export()` call with `draft_export()`.[&#39;Traceback (most recent call last):\n&#39;, &#39;  File &quot;~/github/experimental-experiment/experimental_experiment/torch_interpreter/piece_by_piece.py&quot;, line 1573, in _try_export_no_bypass_export\n    ep = torch_export(\n         ^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/github/experimental-experiment/experimental_experiment/export_helpers.py&quot;, line 164, in torch_export\n    return torch.export.export(\n           ^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/__init__.py&quot;, line 311, in export\n    raise e\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/__init__.py&quot;, line 277, in export\n    return _export(\n           ^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 1272, in wrapper\n    raise e\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 1238, in wrapper\n    ep = fn(*args, **kwargs)\n         ^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/exported_program.py&quot;, line 124, in wrapper\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 2379, in _export\n    ep = _export_for_training(\n         ^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 1272, in wrapper\n    raise e\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 1238, in wrapper\n    ep = fn(*args, **kwargs)\n         ^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/exported_program.py&quot;, line 124, in wrapper\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 2187, in _export_for_training\n    export_artifact = export_func(\n                      ^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 2118, in _non_strict_export\n    aten_export_artifact = _to_aten_func(\n                           ^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 1906, in _export_to_aten_ir_make_fx\n    gm, graph_signature = transform(_make_fx_helper)(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 2036, in _aot_export_non_strict\n    gm, sig = aot_export(stack, wrapped_mod, args, kwargs=kwargs, **flags)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 1818, in _make_fx_helper\n    gm = make_fx(\n         ^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py&quot;, line 2722, in wrapped\n    return make_fx_tracer.trace(f, *args)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py&quot;, line 2629, in trace\n    return self._trace_inner(f, *args)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py&quot;, line 2591, in _trace_inner\n    t = dispatch_trace(\n        ^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/_compile.py&quot;, line 54, in inner\n    return disable_fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py&quot;, line 1193, in _fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py&quot;, line 1461, in dispatch_trace\n    graph = tracer.trace(root, concrete_args)  # type: ignore[arg-type]\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py&quot;, line 2179, in trace\n    res = super().trace(root, concrete_args)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py&quot;, line 1193, in _fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/fx/_symbolic_trace.py&quot;, line 879, in trace\n    (self.create_arg(fn(*args)),),\n                     ^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py&quot;, line 1527, in wrapped\n    out = f(*tensors)  # type:ignore[call-arg]\n          ^^^^^^^^^^^\n&#39;, &#39;  File &quot;&lt;string&gt;&quot;, line 1, in &lt;lambda&gt;\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 1705, in wrapped_fn\n    return tuple(flat_fn(*args))\n                 ^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/utils.py&quot;, line 193, in flat_fn\n    tree_out = fn(*args, **kwargs)\n               ^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/graph_capture_wrappers.py&quot;, line 1378, in functional_call\n    out = mod(*args[params_len:], **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/fx/_symbolic_trace.py&quot;, line 853, in module_call_wrapper\n    return self.call_module(mod, forward, args, kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py&quot;, line 2267, in call_module\n    return Tracer.call_module(self, m, forward, args, kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/fx/_symbolic_trace.py&quot;, line 569, in call_module\n    ret_val = forward(*args, **kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/fx/_symbolic_trace.py&quot;, line 846, in forward\n    return _orig_module_call(mod, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/nn/modules/module.py&quot;, line 1776, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/nn/modules/module.py&quot;, line 1787, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py&quot;, line 2020, in forward\n    tree_out = mod(*args, **kwargs)\n               ^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/fx/_symbolic_trace.py&quot;, line 853, in module_call_wrapper\n    return self.call_module(mod, forward, args, kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py&quot;, line 2267, in call_module\n    return Tracer.call_module(self, m, forward, args, kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/fx/_symbolic_trace.py&quot;, line 569, in call_module\n    ret_val = forward(*args, **kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/fx/_symbolic_trace.py&quot;, line 846, in forward\n    return _orig_module_call(mod, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/nn/modules/module.py&quot;, line 1776, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/nn/modules/module.py&quot;, line 1787, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/utils/_contextlib.py&quot;, line 124, in decorate_context\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/github/transformers/src/transformers/modeling_rope_utils.py&quot;, line 124, in wrapper\n    longrope_frequency_update(self, position_ids, device=x.device, **kwargs)\n&#39;, &#39;  File &quot;~/github/transformers/src/transformers/modeling_rope_utils.py&quot;, line 61, in longrope_frequency_update\n    if seq_len &gt; original_max_position_embeddings:\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py&quot;, line 1578, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py&quot;, line 1649, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/_export/non_strict_utils.py&quot;, line 1140, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py&quot;, line 543, in guard_bool\n    r = self.evaluate()\n        ^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py&quot;, line 517, in evaluate\n    return self.shape_env.evaluate_sym_node(self, size_oblivious)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py&quot;, line 7326, in evaluate_sym_node\n    return self.evaluate_expr(\n           ^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py&quot;, line 7421, in evaluate_expr\n    return self._inner_evaluate_expr(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/fx/experimental/recording.py&quot;, line 273, in wrapper\n    return retlog(fn(*args, **kwargs))\n                  ^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py&quot;, line 7444, in _inner_evaluate_expr\n    return self._evaluate_expr(\n           ^^^^^^^^^^^^^^^^^^^^\n&#39;, &#39;  File &quot;~/vv/this312/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py&quot;, line 7663, in _evaluate_expr\n    raise self._make_data_dependent_error(\n&#39;, &#39;torch.fx.experimental.symbolic_shapes.GuardOnDataDependentSymNode: Could not guard on data-dependent expression Eq(u0, 1) (unhinted: Eq(u0, 1)).  (Size-like symbols: none)\n\nconsider using data-dependent friendly APIs such as guard_or_false, guard_or_true and statically_known_true.\nCaused by: (_export/non_strict_utils.py:1140 in __torch_function__)\nFor more information, run with TORCH_LOGS=&quot;dynamic&quot;\nFor extended logs when we create symbols, also add TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL=&quot;u0&quot;\nIf you suspect the guard was triggered from C++, add TORCHDYNAMO_EXTENDED_DEBUG_CPP=1\nFor more debugging help, see https://docs.google.com/document/d/1HSuTTVvYH1pTew89Rtpeu84Ht3nQEFTYhAX3Ypa_xJs/edit?usp=sharing\n\nFor C++ stack trace, run with TORCHDYNAMO_EXTENDED_DEBUG_CPP=1\n\nThe following call raised this error:\n  File &quot;~/github/transformers/src/transformers/modeling_rope_utils.py&quot;, line 61, in longrope_frequency_update\n    if seq_len &gt; original_max_position_embeddings:\n\n\nThe error above occurred when calling torch.export.export. If you would like to view some more information about this error, and get a list of all other errors that may occur in your export call, you can replace your `export()` call with `draft_export()`.\n&#39;]
[try_export-FX] .... M:rotary_emb-Phi3RotaryEmbedding --- FAIL: Could not guard on data-depend...
[torch_export] export starts with backed_size_oblivious=False
[try_export-FX] .. M:lm_head-Linear --- OK:
</pre></div>
</div>
<p>Lets display a report.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;success: </span><span class="si">{</span><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/piece_by_piece.html#experimental_experiment.torch_interpreter.piece_by_piece.StatusExportCode" title="experimental_experiment.torch_interpreter.piece_by_piece.StatusExportCode" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter-piece_by_piece sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/piece_by_piece.html#experimental_experiment.torch_interpreter.piece_by_piece.StatusExportCode" title="experimental_experiment.torch_interpreter.piece_by_piece.StatusExportCode" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter-piece_by_piece sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ep</span><span class="o">.</span><span class="n">status</span></a></a><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/piece_by_piece.html#experimental_experiment.torch_interpreter.piece_by_piece.ModelDiagnoseOutput.get_export_report" title="experimental_experiment.torch_interpreter.piece_by_piece.ModelDiagnoseOutput.get_export_report" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter-piece_by_piece sphx-glr-backref-type-py-method"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/piece_by_piece.html#experimental_experiment.torch_interpreter.piece_by_piece.ModelDiagnoseOutput.get_export_report" title="experimental_experiment.torch_interpreter.piece_by_piece.ModelDiagnoseOutput.get_export_report" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter-piece_by_piece sphx-glr-backref-type-py-method"><span class="n">diag</span><span class="o">.</span><span class="n">get_export_report</span></a></a><span class="p">())</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>success: 2
__main__                         Phi3ForCausalLM       FAIL -- step=EXPORT, reason=&#39;Cannot associate shape [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint...&#39;
..model                          Phi3Model             FAIL -- step=EXPORT, reason=&#39;Cannot associate shape [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint...&#39;
....embed_tokens                 Embedding             OK -- ExportedProgram
....layers[0]                    Phi3DecoderLayer      FAIL -- step=EXPORT, reason=&#39;Cannot associate shape [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint...&#39;
......self_attn                  Phi3Attention         FAIL -- step=EXPORT, reason=&#39;Cannot associate shape [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint...&#39;
........o_proj                   Linear                OK -- ExportedProgram
........qkv_proj                 Linear                OK -- ExportedProgram
......mlp                        Phi3MLP               OK -- ExportedProgram
........gate_up_proj             Linear                &lt;OK-2i-0&gt;
........down_proj                Linear                &lt;OK-2i-0&gt;
........activation_fn            SiLUActivation        &lt;OK-2i-0&gt;
......input_layernorm            Phi3RMSNorm           OK -- ExportedProgram
......post_attention_layernorm   Phi3RMSNorm           OK -- ExportedProgram
......resid_attn_dropout         Dropout               OK -- ExportedProgram
......resid_mlp_dropout          Dropout               OK -- ExportedProgram
....layers[1]                    Phi3DecoderLayer      FAIL -- step=EXPORT, reason=&#39;Cannot associate shape [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint...&#39;
......self_attn                  Phi3Attention         FAIL -- step=EXPORT, reason=&#39;Cannot associate shape [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint...&#39;
........o_proj                   Linear                OK -- ExportedProgram
........qkv_proj                 Linear                OK -- ExportedProgram
......mlp                        Phi3MLP               OK -- ExportedProgram
........gate_up_proj             Linear                &lt;OK-2i-0&gt;
........down_proj                Linear                &lt;OK-2i-0&gt;
........activation_fn            SiLUActivation        &lt;OK-2i-0&gt;
......input_layernorm            Phi3RMSNorm           OK -- ExportedProgram
......post_attention_layernorm   Phi3RMSNorm           OK -- ExportedProgram
......resid_attn_dropout         Dropout               OK -- ExportedProgram
......resid_mlp_dropout          Dropout               OK -- ExportedProgram
....norm                         Phi3RMSNorm           OK -- ExportedProgram
....rotary_emb                   Phi3RotaryEmbedding   FAIL -- step=EXPORT, reason=&#39;Could not guard on data-dependent expression Eq(u0, 1) (unhinted: Eq(u0, 1)).  (Size-like symbols: n...&#39;
..lm_head                        Linear                OK -- ExportedProgram
</pre></div>
</div>
</section>
<section id="replace-the-failing-module-by-a-custom-op">
<h2>Replace the failing module by a custom op<a class="headerlink" href="#replace-the-failing-module-by-a-custom-op" title="Link to this heading"></a></h2>
<p>The main module is not exportable because one piece cannot be exported.
But maybe if we assume it works, maybe everything else is working.
So lets try to replace this class by a custom op.
This will be something for another example.</p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (0 minutes 5.387 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-recipes-plot-exporter-exporter-phi35-piece-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/6aa9aa07e36ac1aa1643da0bf3e38f0d/plot_exporter_exporter_phi35_piece.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_exporter_exporter_phi35_piece.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/267efdcf585b83af5aa72b6b95817131/plot_exporter_exporter_phi35_piece.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_exporter_exporter_phi35_piece.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../_downloads/1b8e64221afbb8509ca0eff85282e344/plot_exporter_exporter_phi35_piece.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">plot_exporter_exporter_phi35_piece.zip</span></code></a></p>
</div>
</div>
<p class="rubric">Related examples</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Tries torch._export.tools.report_exportability."><img alt="" src="../_images/sphx_glr_plot_exporter_exporter_reportibility_thumb.png" />
<p><a class="reference internal" href="plot_exporter_exporter_reportibility.html"><span class="doc">Export Phi-3.5-mini-instruct with report_exportability</span></a></p>
  <div class="sphx-glr-thumbnail-title">Export Phi-3.5-mini-instruct with report_exportability</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Tries torch.export._draft_export.draft_export."><img alt="" src="../_images/sphx_glr_plot_exporter_exporter_draft_mode_thumb.png" />
<p><a class="reference internal" href="plot_exporter_exporter_draft_mode.html"><span class="doc">Export Phi-3.5-mini-instruct with draft_export</span></a></p>
  <div class="sphx-glr-thumbnail-title">Export Phi-3.5-mini-instruct with draft_export</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Every conversion task must be tested on a large scale. One huge source of model is HuggingFace. We focus on the model Tiny-LLM. To avoid downloading any weigths, we write a function creating a random model based on the same architecture."><img alt="" src="../_images/sphx_glr_plot_exporter_exporter_untrained_tinyllm_thumb.png" />
<p><a class="reference internal" href="plot_exporter_exporter_untrained_tinyllm.html"><span class="doc">Check the exporter on a dummy from HuggingFace</span></a></p>
  <div class="sphx-glr-thumbnail-title">Check the exporter on a dummy from HuggingFace</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Big models are hard to read once converted into onnx. Let&#x27;s see how to improve their readibility. The code is inspired from LLM from scratch with Pytorch."><img alt="" src="../_images/sphx_glr_plot_exporter_recipes_c_modules_thumb.png" />
<p><a class="reference internal" href="plot_exporter_recipes_c_modules.html"><span class="doc">to_onnx and submodules from LLMs</span></a></p>
  <div class="sphx-glr-thumbnail-title">to_onnx and submodules from LLMs</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Control flow cannot be exported with a change. The code of the model can be changed or patched to introduce function torch.cond."><img alt="" src="../_images/sphx_glr_plot_exporter_recipes_c_cond_thumb.png" />
<p><a class="reference internal" href="plot_exporter_recipes_c_cond.html"><span class="doc">to_onnx and a model with a test</span></a></p>
  <div class="sphx-glr-thumbnail-title">to_onnx and a model with a test</div>
</div></div><p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="plot_exporter_exporter_draft_mode.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Export Phi-3.5-mini-instruct with draft_export</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="plot_exporter_exporter_untrained_tinyllm.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Check the exporter on a dummy from HuggingFace</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2023-2024
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Export Phi-3.5-mini-instruct piece by piece</a><ul>
<li><a class="reference internal" href="#model">Model</a></li>
<li><a class="reference internal" href="#dynamic-shapes">Dynamic Shapes</a></li>
<li><a class="reference internal" href="#evaluate-the-export">Evaluate the export</a></li>
<li><a class="reference internal" href="#replace-the-failing-module-by-a-custom-op">Replace the failing module by a custom op</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../_static/documentation_options.js?v=0deb7d70"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/furo.js?v=46bd48cc"></script>
    </body>
</html>