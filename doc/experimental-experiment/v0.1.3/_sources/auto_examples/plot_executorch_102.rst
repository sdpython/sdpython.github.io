
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_executorch_102.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_plot_executorch_102.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_executorch_102.py:


.. _l-plot-executorch-102:

102: First test with ExecuTorch
===============================

This script demonstrates :epkg:`ExecuTorch` on a very simple example,
see also :epkg:`ExecuTorch Tutorial`,
:epkg:`ExecuTorch Runtime Python API Reference`.

Convert a Model
+++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 14-54

.. code-block:: Python


    from pathlib import Path
    import torch

    try:
        from executorch.exir import (
            EdgeProgramManager,
            to_edge,
            ExecutorchProgramManager,
            ExecutorchBackendConfig,
        )
        from executorch.runtime import Verification, Runtime, Program, Method

        # This line is needed when executing to_backend.
        from executorch.exir.backend.test.backend_with_compiler_demo import (  # noqa
            BackendWithCompilerDemo,
        )

        executorch = True
    except ImportError:
        print("executorch is not installed.")
        executorch = None


    class Neuron(torch.nn.Module):
        def __init__(self, n_dims: int = 5, n_targets: int = 3):
            super().__init__()
            self.linear = torch.nn.Linear(n_dims, n_targets)

        def forward(self, x):
            z = self.linear(x)
            return torch.sigmoid(z)


    inputs = (torch.randn(1, 5),)
    model = Neuron()
    expected = model(*inputs)
    exported_program = torch.export.export(model, inputs)
    print(exported_program.graph)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    executorch is not installed.
    graph():
        %p_linear_weight : [num_users=1] = placeholder[target=p_linear_weight]
        %p_linear_bias : [num_users=1] = placeholder[target=p_linear_bias]
        %x : [num_users=1] = placeholder[target=x]
        %linear : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%x, %p_linear_weight, %p_linear_bias), kwargs = {})
        %sigmoid : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%linear,), kwargs = {})
        return (sigmoid,)




.. GENERATED FROM PYTHON SOURCE LINES 55-56

Conversion to an `EdgeProgramManager`.

.. GENERATED FROM PYTHON SOURCE LINES 56-61

.. code-block:: Python


    if executorch:
        edge_program: EdgeProgramManager = to_edge(exported_program)
        print(f"edge_program {edge_program!r}")








.. GENERATED FROM PYTHON SOURCE LINES 62-63

Serializes.

.. GENERATED FROM PYTHON SOURCE LINES 63-77

.. code-block:: Python


    if executorch:
        save_path = "plot_executorch_101.pte"
        executorch_program: ExecutorchProgramManager = edge_program.to_executorch(
            ExecutorchBackendConfig(
                passes=[],  # User-defined passes
            )
        )

        with open(save_path, "wb") as file:
            file.write(executorch_program.buffer)
        print(f"model saved into {save_path!r}")









.. GENERATED FROM PYTHON SOURCE LINES 78-91

It can be specialized for a specific backend.

::

      from executorch.exir.backend.backend_api import LoweredBackendModule, to_backend

      lowered_module: LoweredBackendModule = to_backend(
          "BackendWithCompilerDemo",
          to_be_lowered_module,
          [],
      )
      with open(save_path, "wb") as f:
          f.write(lowered_module.buffer())

.. GENERATED FROM PYTHON SOURCE LINES 93-95

Execution
+++++++++

.. GENERATED FROM PYTHON SOURCE LINES 95-108

.. code-block:: Python


    if executorch:
        et_runtime: Runtime = Runtime.get()
        program: Program = et_runtime.load_program(
            Path("plot_executorch_101.pte"), verification=Verification.Minimal
        )

        print("Program methods:", program.method_names)
        forward: Method = program.load_method("forward")

        outputs = forward.execute(inputs)
        print("forward:", forward)








.. GENERATED FROM PYTHON SOURCE LINES 109-110

Let's compare.

.. GENERATED FROM PYTHON SOURCE LINES 110-114

.. code-block:: Python


    if executorch:
        diff = torch.abs(outputs[0] - expected).max()
        print("max discrepancies:", diff)








.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 0.028 seconds)


.. _sphx_glr_download_auto_examples_plot_executorch_102.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_executorch_102.ipynb <plot_executorch_102.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_executorch_102.py <plot_executorch_102.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_executorch_102.zip <plot_executorch_102.zip>`


.. include:: plot_executorch_102.recommendations


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
