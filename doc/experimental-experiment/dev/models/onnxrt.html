<!doctype html>
<html class="no-js" lang="en" data-content_root="../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="A script to report a bug" href="example_bug.html" /><link rel="prev" title="Tries with Undocumented" href="torchtry.html" />

    <!-- Generated with Sphinx 7.2.6 and Furo 2024.05.06 -->
        <title>Use the custom exporter in torch - experimental-experiment 0.1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=387cc868" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css?v=7f9a90b1" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css?v=eafc0fe6" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=61a4c737" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=36a5483c" />
    
    


<style>
  body {
    --color-code-background: #eeffcc;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" /
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">experimental-experiment 0.1.0 documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="../_static/logo.png" alt="Logo"/>
  </div>
  
  <span class="sidebar-brand-text">experimental-experiment 0.1.0 documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Contents</span></p>
<ul class="current">
<li class="toctree-l1 has-children"><a class="reference internal" href="../tutorial/index.html">Tutorial</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of Tutorial</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../tutorial/pytorch.html">pytorch and onnx</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of pytorch and onnx</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_linreg_101.html">101: Linear Regression and export to ONNX</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_custom_backend_101.html">101: A custom backend for torch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_optimize_101.html">101: Graph Optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_convolutation_matmul_102.html">102: Convolution and Matrix Multiplication</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_llama_bench_102.html">102: Measure LLAMA speed</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_export_201.html">201: Evaluate different ways to export a torch model to ONNX</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_dort_201.html">201: Evaluate DORT</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_aot_201.html">201: Evaluate DORT Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_llama_diff_export_301.html">301: Compares LLAMA exporters</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_llama_diff_dort_301.html">301: Compares LLAMA exporters for onnxrt backend</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../tutorial/onnx.html">onnx</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of onnx</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_profile_existing_onnx_101.html">101: Profile an existing model with onnxruntime</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../tutorial/errors.html">Frequent Exceptions</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../design/index.html">Design</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of Design</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../design/exporter.html">Custom Exporter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../design/optimizer.html">Pattern Optimizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../design/backends.html">Dynamo Backends</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api/index.html">API</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of API</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../api/gradient.html">gradient</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/reference.html">reference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/graph_builder.html">graph_builder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/torch_model_container.html">TorchModelContainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/graph_builder_pattern.html">graph_builder_optim</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/graph_builder_patterns.html">Optimization Patterns</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/order_optimization.html">order_optim</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/interpreter.html">interpreter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/onnx_export.html">onnx_export</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/aten_function.html">aten_functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/aten_method.html">aten_methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/prims_function.html">aten_prims</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/convert.html">convert_tools</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/torch_dynamo.html">torch_dynamo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/misc.html">Others…</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/torch_helper.html">torch_models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/dimension.html">Dimension</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/torch_test.html">Testing</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../auto_examples/index.html">Example gallery</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle navigation of Example gallery</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_optimize_101.html">101: Graph Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_profile_existing_onnx_101.html">101: Profile an existing model with onnxruntime</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_torch_linreg_101.html">101: Linear Regression and export to ONNX</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_torch_custom_backend_101.html">101: A custom backend for torch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_convolutation_matmul_102.html">102: Convolution and Matrix Multiplication</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_llama_diff_export_301.html">301: Compares LLAMA exporters</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_llama_diff_dort_301.html">301: Compares LLAMA exporters for onnxrt backend</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_llama_bench_102.html">102: Measure LLAMA speed</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_torch_aot_201.html">201: Evaluate DORT Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_torch_dort_201.html">201: Evaluate DORT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/plot_torch_export_201.html">201: Evaluate different ways to export a torch model to ONNX</a></li>
</ul>
</li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="index.html">Supported Models</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle navigation of Supported Models</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="torchtry.html">Tries with Undocumented</a></li>
<li class="toctree-l2 current current-page"><a class="current reference internal" href="#">Use the custom exporter in torch</a></li>
<li class="toctree-l2"><a class="reference internal" href="example_bug.html">A script to report a bug</a></li>
<li class="toctree-l2"><a class="reference internal" href="llama.html">LLaMa</a></li>
<li class="toctree-l2"><a class="reference internal" href="mistral.html">Mistral</a></li>
<li class="toctree-l2"><a class="reference internal" href="phi.html">Phi</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../bench/index.html">Benchmark from the command line</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle navigation of Benchmark from the command line</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../bench/dort_bench.html">experimental_experiment.torch_bench.dort_bench</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bench/dort_profile.html">experimental_experiment.torch_bench.dort_profile</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bench/scripts.html">Interesting scripts or command lines</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../times.html">Times</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">More</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../CHANGELOGS.html">Change Logs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
<li class="toctree-l1"><a class="reference internal" href="../long_outputs.html">Long Outputs uneasy to read</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="../_sources/models/onnxrt.rst" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="use-the-custom-exporter-in-torch">
<h1>Use the custom exporter in torch<a class="headerlink" href="#use-the-custom-exporter-in-torch" title="Link to this heading">¶</a></h1>
<p><em>Subject to change</em></p>
<section id="file-onnxruntime-py">
<h2>File <cite>onnxruntime.py</cite><a class="headerlink" href="#file-onnxruntime-py" title="Link to this heading">¶</a></h2>
<p>This change enables the custom rewriter is an environment variable is enabled.
Look for substring <code class="docutils literal notranslate"><span class="pre">TODO:</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">_ort_acclerated_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph_module</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">GraphModule</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;This function replaces GraphModule._wrapped_call in compiled model.</span>

<span class="sd">    The _wrapped_call is the underlying implementation of forward method. Replacing</span>
<span class="sd">    it means we delegate the computation to _ort_acclerated_call and therefore</span>
<span class="sd">    onnxruntime.InferenceSession.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">cached_execution_info_per_session</span> <span class="o">=</span> <span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_all_ort_execution_info</span><span class="o">.</span><span class="n">search_reusable_session_execution_info</span><span class="p">(</span>
            <span class="n">graph_module</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span>
        <span class="p">)</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">cached_execution_info_per_session</span><span class="p">:</span>
        <span class="n">onnx_session</span> <span class="o">=</span> <span class="n">cached_execution_info_per_session</span><span class="o">.</span><span class="n">session</span>
        <span class="n">input_names</span> <span class="o">=</span> <span class="n">cached_execution_info_per_session</span><span class="o">.</span><span class="n">input_names</span>
        <span class="n">output_names</span> <span class="o">=</span> <span class="n">cached_execution_info_per_session</span><span class="o">.</span><span class="n">output_names</span>
        <span class="n">input_value_infos</span> <span class="o">=</span> <span class="n">cached_execution_info_per_session</span><span class="o">.</span><span class="n">input_value_infos</span>
        <span class="n">output_value_infos</span> <span class="o">=</span> <span class="n">cached_execution_info_per_session</span><span class="o">.</span><span class="n">output_value_infos</span>
        <span class="n">input_devices</span> <span class="o">=</span> <span class="n">cached_execution_info_per_session</span><span class="o">.</span><span class="n">input_devices</span>
        <span class="n">output_devices</span> <span class="o">=</span> <span class="n">cached_execution_info_per_session</span><span class="o">.</span><span class="n">output_devices</span>
        <span class="n">prim_outputs</span> <span class="o">=</span> <span class="n">cached_execution_info_per_session</span><span class="o">.</span><span class="n">example_outputs</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># It&#39;s first time seeing such as graph. Let&#39;s make a new session</span>
        <span class="c1"># (type: onnxruntime.InferenceSession) for it.</span>

        <span class="c1">##########################</span>
        <span class="c1"># TODO: Insert these lines</span>
        <span class="c1">##########################</span>

        <span class="n">use_other_rewriter</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;ONNXRT_CHANGE_REWRITER&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;1&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">use_other_rewriter</span><span class="p">:</span>
            <span class="kn">from</span> <span class="nn">experimental_experiment.torch_interpreter</span> <span class="kn">import</span> <span class="n">to_onnx</span>
            <span class="kn">from</span> <span class="nn">experimental_experiment.torch_interpreter._torch_models</span> <span class="kn">import</span> <span class="n">create_input_names</span>
            <span class="kn">from</span> <span class="nn">experimental_experiment.xbuilder</span> <span class="kn">import</span> <span class="n">OptimizationOptions</span>
            <span class="kn">from</span> <span class="nn">experimental_experiment.torch_interpreter.oxs_dispatcher</span> <span class="kn">import</span> <span class="n">OxsDispatcher</span>

            <span class="n">input_names</span> <span class="o">=</span> <span class="n">input_names</span> <span class="o">=</span> <span class="n">create_input_names</span><span class="p">(</span><span class="n">graph_module</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span>
            <span class="n">dispatcher</span> <span class="o">=</span> <span class="n">OxsDispatcher</span><span class="p">()</span>
            <span class="n">target_opset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_resolved_onnx_exporter_options</span><span class="o">.</span><span class="n">onnx_registry</span><span class="o">.</span><span class="n">opset_version</span>
            <span class="n">options</span> <span class="o">=</span> <span class="n">OptimizationOptions</span><span class="p">(</span>
                <span class="n">remove_unused</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">constant_folding</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">patterns</span><span class="o">=</span><span class="s2">&quot;default&quot;</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">onnx_model</span><span class="p">,</span> <span class="n">builder</span> <span class="o">=</span> <span class="n">to_onnx</span><span class="p">(</span>
                <span class="n">graph_module</span><span class="p">,</span>
                <span class="nb">tuple</span><span class="p">(</span><span class="n">args</span><span class="p">),</span>
                <span class="n">input_names</span><span class="o">=</span><span class="n">input_names</span><span class="p">,</span>
                <span class="n">options</span><span class="o">=</span><span class="n">options</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">target_opset</span><span class="o">=</span><span class="n">target_opset</span><span class="p">,</span>
                <span class="n">return_builder</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dispatcher</span><span class="o">=</span><span class="n">dispatcher</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="k">def</span> <span class="nf">maybe_map_to_meta_val</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="s2">&quot;meta&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="s2">&quot;val&quot;</span> <span class="ow">in</span> <span class="n">value</span><span class="o">.</span><span class="n">meta</span><span class="p">:</span>
                    <span class="c1"># Select outputs with &quot;val&quot; information. Without &quot;val&quot;,</span>
                    <span class="c1"># it&#39;s not possible access output_arg.meta[&quot;val&quot;].device.</span>
                    <span class="k">return</span> <span class="n">value</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s2">&quot;val&quot;</span><span class="p">]</span>
                <span class="k">return</span> <span class="n">value</span>

            <span class="n">extracted_outputs</span> <span class="o">=</span> <span class="n">_extract_graph_module_outputs</span><span class="p">(</span><span class="n">graph_module</span><span class="p">)</span>
            <span class="n">prim_outputs</span> <span class="o">=</span> <span class="n">_pytree</span><span class="o">.</span><span class="n">tree_map</span><span class="p">(</span><span class="n">maybe_map_to_meta_val</span><span class="p">,</span> <span class="n">extracted_outputs</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>

        <span class="c1">####################################</span>
        <span class="c1"># TODO: end of the insertion</span>
        <span class="c1"># TODO: indent what follows</span>
        <span class="c1">####################################</span>

            <span class="n">graph_module</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">_internal</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">passes</span><span class="o">.</span><span class="n">MovePlaceholderToFront</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_resolved_onnx_exporter_options</span><span class="o">.</span><span class="n">diagnostic_context</span><span class="p">,</span>
                <span class="n">graph_module</span><span class="p">,</span>
            <span class="p">)</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
            <span class="c1"># Generate reference outputs. They are used to indicate output</span>
            <span class="c1"># tensors&#39; types and devices when calling ORT.</span>
            <span class="c1">#</span>
            <span class="c1"># WARNING: The downstream code should not change prim_outputs and</span>
            <span class="c1"># this backend should always produces output with schema identical to prim_outputs&#39;.</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_resolved_onnx_exporter_options</span><span class="o">.</span><span class="n">dynamic_shapes</span><span class="p">:</span>
                <span class="c1"># No pre-allocation when dynamic shape is enabled.</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">preallocate_output</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="n">extracted_outputs</span> <span class="o">=</span> <span class="n">_extract_graph_module_outputs</span><span class="p">(</span><span class="n">graph_module</span><span class="p">)</span>

                <span class="k">def</span> <span class="nf">maybe_map_to_meta_val</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="s2">&quot;meta&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="s2">&quot;val&quot;</span> <span class="ow">in</span> <span class="n">value</span><span class="o">.</span><span class="n">meta</span><span class="p">:</span>
                        <span class="c1"># Select outputs with &quot;val&quot; information. Without &quot;val&quot;,</span>
                        <span class="c1"># it&#39;s not possible access output_arg.meta[&quot;val&quot;].device.</span>
                        <span class="k">return</span> <span class="n">value</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s2">&quot;val&quot;</span><span class="p">]</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">return</span> <span class="n">value</span>

                <span class="n">prim_outputs</span> <span class="o">=</span> <span class="n">_pytree</span><span class="o">.</span><span class="n">tree_map</span><span class="p">(</span>
                    <span class="n">maybe_map_to_meta_val</span><span class="p">,</span> <span class="n">extracted_outputs</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">prim_outputs</span> <span class="o">=</span> <span class="n">FakeTensorProp</span><span class="p">(</span><span class="n">graph_module</span><span class="p">)</span><span class="o">.</span><span class="n">propagate</span><span class="p">(</span>
                        <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
                    <span class="p">)</span>
                <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;FakeTensorProb failed for </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">graph_module</span><span class="p">)</span>
                    <span class="c1"># When FakeTensorProp fails, it is not possible to preallocate output buffers</span>
                    <span class="c1"># because the output shapes are not inferred.</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">preallocate_output</span> <span class="o">=</span> <span class="kc">False</span>

                    <span class="c1"># rethrow FakeTensorProb failure because it is not yet currently handled.</span>
                    <span class="k">raise</span>

            <span class="c1"># Create the object to iterate through the nodes in graph one-by-one</span>
            <span class="c1"># and calls the corresponding ONNX exporter for each node.</span>
            <span class="n">fx_interpreter</span> <span class="o">=</span> <span class="n">fx_onnx_interpreter</span><span class="o">.</span><span class="n">FxOnnxInterpreter</span><span class="p">(</span>
                <span class="n">diagnostic_context</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_resolved_onnx_exporter_options</span><span class="o">.</span><span class="n">diagnostic_context</span>
            <span class="p">)</span>
            <span class="c1"># Cast FX variables if they will result schema-mismatch when searching</span>
            <span class="c1"># for ONNX operator. E.g., add(double_tensor, int_tensor) is fine in PyTorch,</span>
            <span class="c1"># but ONNX expects add(double_tensor, double_tensor).</span>
            <span class="n">graph_module</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">_internal</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">passes</span><span class="o">.</span><span class="n">InsertTypePromotion</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_resolved_onnx_exporter_options</span><span class="o">.</span><span class="n">diagnostic_context</span><span class="p">,</span> <span class="n">graph_module</span>
            <span class="p">)</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
            <span class="c1"># Start the per-node exporting process. It&#39;s conceptually a for loop</span>
            <span class="c1"># scanning through the nodes in the graph.</span>
            <span class="n">exported</span> <span class="o">=</span> <span class="n">fx_interpreter</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                <span class="n">fx_graph_module</span><span class="o">=</span><span class="n">graph_module</span><span class="p">,</span>
                <span class="n">onnxfunction_dispatcher</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_resolved_onnx_exporter_options</span><span class="o">.</span><span class="n">onnxfunction_dispatcher</span><span class="p">,</span>
                <span class="n">op_level_debug</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_resolved_onnx_exporter_options</span><span class="o">.</span><span class="n">op_level_debug</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="c1"># Convert the exported result to ONNX ModelProto.</span>
            <span class="n">onnx_model</span> <span class="o">=</span> <span class="n">exported</span><span class="o">.</span><span class="n">to_model_proto</span><span class="p">(</span>
                <span class="n">opset_version</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_resolved_onnx_exporter_options</span><span class="o">.</span><span class="n">onnx_registry</span><span class="o">.</span><span class="n">opset_version</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1">####################################</span>
        <span class="c1"># TODO: end of the modification</span>
        <span class="c1">####################################</span>

        <span class="c1"># Modify ONNX model using pre-registered graph transforms.</span>
        <span class="c1"># They are in-place modifications for avoiding unnecessary</span>
        <span class="c1"># copy of ONNX initializers.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_options</span><span class="o">.</span><span class="n">pre_ort_model_transforms</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">transform</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_options</span><span class="o">.</span><span class="n">pre_ort_model_transforms</span><span class="p">:</span>
                <span class="n">transform</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">)</span>

        <span class="n">onnx_model_bytes</span> <span class="o">=</span> <span class="n">onnx_model</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;ONNXRT_DUMP_PATH&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">):</span>
            <span class="c1"># If not empty, environment variable ONNXRT_DUMP_PATH defined the path</span>
            <span class="c1"># where generated onnx files should be stored.</span>
            <span class="c1"># This module keeps a global variables keeping track of the</span>
            <span class="c1"># stored models.</span>
            <span class="c1"># If ONNXRT_DUMP_PATH=&quot;dumped/dumped_model_&quot;</span>
            <span class="c1"># The first file name will be &#39;dumped/dumped_model_0.onnx&#39;.</span>
            <span class="c1"># For every dumped model, a text file &#39;dumped/dumped_model_0.txt&#39;</span>
            <span class="c1"># is created as well to contain the string representing the graph_module.</span>
            <span class="n">_dump_onnx_model</span><span class="p">(</span><span class="n">onnx_model_bytes</span><span class="p">,</span> <span class="n">graph_module</span><span class="o">=</span><span class="n">graph_module</span><span class="p">)</span>

        <span class="c1"># Initialize a ORT session to execute this ONNX model.</span>
        <span class="c1"># Note that TorchDynamo assumes all inputs/outputs are on the</span>
        <span class="c1"># same device, but it&#39;s subject to change (very likely with</span>
        <span class="c1"># dynamic shape support), so we add execution providers</span>
        <span class="c1"># based on the logic in _select_eps: (explicitly preferred EPs,</span>
        <span class="c1"># EPs inferred from inputs or graph, and the fallback default EP)/</span>
        <span class="c1">#</span>
        <span class="c1"># TODO(wschin): enable external allocators.</span>
        <span class="c1"># See https://github.com/pytorch/pytorch/issues/106867</span>
        <span class="n">onnx_session</span> <span class="o">=</span> <span class="n">onnxruntime</span><span class="o">.</span><span class="n">InferenceSession</span><span class="p">(</span>
            <span class="n">path_or_bytes</span><span class="o">=</span><span class="n">onnx_model_bytes</span><span class="p">,</span>
            <span class="n">sess_options</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_options</span><span class="o">.</span><span class="n">ort_session_options</span><span class="p">,</span>
            <span class="n">providers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_select_eps</span><span class="p">(</span><span class="n">graph_module</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="c1"># Cache ORT session. It&#39;s reused for the same &quot;graph_module&quot;.</span>
        <span class="c1"># Generate ONNX model and extract its input and output names.</span>
        <span class="n">input_names</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">input</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="nb">input</span> <span class="ow">in</span> <span class="n">onnx_model</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">input</span><span class="p">)</span>
        <span class="n">output_names</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">onnx_model</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>
        <span class="n">input_devices</span> <span class="o">=</span> <span class="n">_get_onnx_devices</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
        <span class="c1"># Cache devices for inputs and outputs. They are used to invoke</span>
        <span class="c1"># ORT session. Output devices indicate where (e.g., GPU or CPU)</span>
        <span class="c1"># to store outputs</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prim_outputs</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">output_devices</span> <span class="o">=</span> <span class="n">_get_onnx_devices</span><span class="p">(</span><span class="n">prim_outputs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">output_devices</span> <span class="o">=</span> <span class="n">_get_onnx_devices</span><span class="p">((</span><span class="n">prim_outputs</span><span class="p">,))</span>

        <span class="n">input_value_infos</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">input</span> <span class="k">for</span> <span class="nb">input</span> <span class="ow">in</span> <span class="n">onnx_model</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">input</span><span class="p">)</span>
        <span class="n">output_value_infos</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">output</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">onnx_model</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>

        <span class="n">execution_info_per_session</span> <span class="o">=</span> <span class="n">OrtExecutionInfoPerSession</span><span class="p">(</span>
            <span class="n">session</span><span class="o">=</span><span class="n">onnx_session</span><span class="p">,</span>
            <span class="n">input_names</span><span class="o">=</span><span class="n">input_names</span><span class="p">,</span>
            <span class="n">input_value_infos</span><span class="o">=</span><span class="n">input_value_infos</span><span class="p">,</span>
            <span class="n">output_names</span><span class="o">=</span><span class="n">output_names</span><span class="p">,</span>
            <span class="n">output_value_infos</span><span class="o">=</span><span class="n">output_value_infos</span><span class="p">,</span>
            <span class="n">input_devices</span><span class="o">=</span><span class="n">input_devices</span><span class="p">,</span>
            <span class="n">output_devices</span><span class="o">=</span><span class="n">output_devices</span><span class="p">,</span>
            <span class="n">example_outputs</span><span class="o">=</span><span class="n">prim_outputs</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_all_ort_execution_info</span><span class="o">.</span><span class="n">cache_session_execution_info</span><span class="p">(</span>
            <span class="n">graph_module</span><span class="p">,</span> <span class="n">execution_info_per_session</span>
        <span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">execution_count</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="c1"># ORT always returns a tuple of outputs. If the original output is a tensor,</span>
    <span class="c1"># ORT output&#39;s first element must be extracted and returned. Otherwise, type</span>
    <span class="c1"># mismatch may happen in downstream computation.</span>
    <span class="n">is_single_tensor_output</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prim_outputs</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
    <span class="n">normalized_prim_outputs</span> <span class="o">=</span> <span class="p">(</span>
        <span class="p">(</span><span class="n">prim_outputs</span><span class="p">,)</span> <span class="k">if</span> <span class="n">is_single_tensor_output</span> <span class="k">else</span> <span class="n">prim_outputs</span>
    <span class="p">)</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">normalized_prim_outputs</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span>
        <span class="nb">isinstance</span><span class="p">(</span><span class="n">elem</span><span class="p">,</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">SymInt</span><span class="p">,</span> <span class="nb">int</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">normalized_prim_outputs</span>
    <span class="p">)</span>

    <span class="n">_nvtx_range_push</span><span class="p">(</span><span class="s2">&quot;run_onnx_session_with_ortvaluevector&quot;</span><span class="p">)</span>
    <span class="n">onnx_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
        <span class="n">onnx_session</span><span class="p">,</span>
        <span class="n">input_names</span><span class="p">,</span>
        <span class="n">args</span><span class="p">,</span>
        <span class="n">input_devices</span><span class="p">,</span>
        <span class="n">output_names</span><span class="p">,</span>
        <span class="n">normalized_prim_outputs</span><span class="p">,</span>
        <span class="n">output_devices</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_options</span><span class="o">.</span><span class="n">preallocate_output</span><span class="p">,</span>
        <span class="n">input_value_infos</span><span class="p">,</span>
        <span class="n">normalized_prim_outputs</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">_nvtx_range_pop</span><span class="p">()</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_assert_allclose_to_baseline</span><span class="p">:</span>
        <span class="c1"># Compute baseline.</span>
        <span class="n">baseline_outputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_prims</span><span class="o">.</span><span class="n">executor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span>
            <span class="n">graph_module</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">executor</span><span class="o">=</span><span class="s2">&quot;aten&quot;</span>
        <span class="p">)</span>
        <span class="n">normalized_baseline_ouptuts</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">(</span><span class="n">baseline_outputs</span><span class="p">,)</span> <span class="k">if</span> <span class="n">is_single_tensor_output</span> <span class="k">else</span> <span class="n">baseline_outputs</span>
        <span class="p">)</span>
        <span class="c1"># Ensure every output tensor is close to the corresponding baseline.</span>
        <span class="k">for</span> <span class="n">onnx_output</span><span class="p">,</span> <span class="n">baseline_output</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
            <span class="n">onnx_outputs</span><span class="p">,</span> <span class="n">normalized_baseline_ouptuts</span>
        <span class="p">):</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_close</span><span class="p">(</span><span class="n">onnx_output</span><span class="p">,</span> <span class="n">baseline_output</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">onnx_outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">is_single_tensor_output</span> <span class="k">else</span> <span class="n">onnx_outputs</span>
</pre></div>
</div>
</section>
<section id="examples">
<h2>Examples<a class="headerlink" href="#examples" title="Link to this heading">¶</a></h2>
<section id="baseline">
<h3>Baseline<a class="headerlink" href="#baseline" title="Link to this heading">¶</a></h3>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">onnx</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.onnx</span>
<span class="kn">from</span> <span class="nn">experimental_experiment.torch_models.training_helper</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">make_aot_ort</span><span class="p">,</span>
    <span class="n">train_loop</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">experimental_experiment.torch_models.dump_helper</span> <span class="kn">import</span> <span class="n">dump_onnx</span>

<span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
    <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">LlamaConfig</span>
    <span class="kn">from</span> <span class="nn">transformers.models.llama.modeling_llama</span> <span class="kn">import</span> <span class="n">LlamaModel</span>


<span class="k">def</span> <span class="nf">ids_tensor</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">):</span>
    <span class="n">total_dims</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="n">shape</span><span class="p">:</span>
        <span class="n">total_dims</span> <span class="o">*=</span> <span class="n">dim</span>

    <span class="n">values</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">total_dims</span><span class="p">):</span>
        <span class="n">values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">vocab_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>


<span class="n">config</span> <span class="o">=</span> <span class="n">LlamaConfig</span><span class="p">(</span>
    <span class="n">hidden_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">num_hidden_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">vocab_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
    <span class="n">intermediate_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">max_position_embeddings</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
    <span class="n">num_attention_heads</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">config</span><span class="o">.</span><span class="n">_attn_implementation</span> <span class="o">=</span> <span class="s2">&quot;eager&quot;</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">LlamaModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

<span class="n">batch</span><span class="p">,</span> <span class="n">seq</span><span class="p">,</span> <span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span>

<span class="n">input_ids</span> <span class="o">=</span> <span class="n">ids_tensor</span><span class="p">([</span><span class="n">batch</span><span class="p">,</span> <span class="n">seq</span><span class="p">],</span> <span class="n">vocab_size</span><span class="p">)</span>
<span class="n">input_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tril</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">seq</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

<span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">input_mask</span><span class="p">)</span>

<span class="n">local_aot_ort</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">make_aot_ort</span><span class="p">(</span>
    <span class="n">dynamic</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">rewrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>

<span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
    <span class="n">optimized_mod</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="n">local_aot_ort</span><span class="p">,</span> <span class="n">fullgraph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">dump_onnx</span><span class="p">(</span><span class="s2">&quot;dort-llama-ort&quot;</span><span class="p">,</span> <span class="n">folder</span><span class="o">=</span><span class="s2">&quot;dump_llama&quot;</span><span class="p">,</span> <span class="n">clean</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="n">train_loop</span><span class="p">(</span><span class="n">optimized_mod</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">input_mask</span><span class="p">)</span>

<span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="n">_</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s2">&quot;dump_llama&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">_</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.onnx&quot;</span><span class="p">)]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------------------------&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;exported model: </span><span class="si">{</span><span class="n">names</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">names</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;NODES in </span><span class="si">{name!r}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">onx</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">&quot;dump_llama&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">node</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">onx</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">onx</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="p">)</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">node</span><span class="o">.</span><span class="n">op_type</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="si">}</span><span class="s2"> -&gt; </span><span class="si">{</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    [2024-05-23 13:23:08,901] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
    Applied 1 of general pattern rewrite rules.
    Applied 0 of general pattern rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific pattern rewrite rules.
    Applied 0 of general pattern rewrite rules.
    Applied 0 of general pattern rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific pattern rewrite rules.
    ------------------------------------------
    exported model: [&#39;dort-llama-ort_1.onnx&#39;, &#39;dort-llama-ort_0.onnx&#39;]
    
    NODES in {name!r}
    1/305: Cos [&#39;cat&#39;] -&gt; [&#39;cos&#39;]
    2/305: Constant [] -&gt; [&#39;_val_34&#39;]
    3/305: Pow [&#39;add_7&#39;, &#39;_val_34&#39;] -&gt; [&#39;pow_5&#39;]
    4/305: Constant [] -&gt; [&#39;aten_view_114_size_0&#39;]
    5/305: Reshape [&#39;mm_4&#39;, &#39;aten_view_114_size_0&#39;] -&gt; [&#39;view_23&#39;]
    6/305: Constant [] -&gt; [&#39;aten_view_116_size_0&#39;]
    7/305: Reshape [&#39;mm_5&#39;, &#39;aten_view_116_size_0&#39;] -&gt; [&#39;view_25&#39;]
    8/305: Constant [] -&gt; [&#39;aten_view_121_size_0&#39;]
    9/305: Reshape [&#39;mm_3&#39;, &#39;aten_view_121_size_0&#39;] -&gt; [&#39;view_21&#39;]
    10/305: Mul [&#39;embedding&#39;, &#39;rsqrt&#39;] -&gt; [&#39;mul_1&#39;]
    11/305: Mul [&#39;tangents_1&#39;, &#39;primals_3&#39;] -&gt; [&#39;mul_13&#39;]
    12/305: Mul [&#39;add_7&#39;, &#39;rsqrt_2&#39;] -&gt; [&#39;mul_11&#39;]
    13/305: Constant [] -&gt; [&#39;_val_50&#39;]
    14/305: Pow [&#39;embedding&#39;, &#39;_val_50&#39;] -&gt; [&#39;pow_9&#39;]
    15/305: Sin [&#39;cat&#39;] -&gt; [&#39;sin&#39;]
    16/305: Constant [] -&gt; [&#39;_val_53&#39;]
    17/305: Equal [&#39;primals_13&#39;, &#39;_val_53&#39;] -&gt; [&#39;eq_1&#39;]
    18/305: Constant [] -&gt; [&#39;aten_unsqueeze_133_dim_0&#39;]
    19/305: Unsqueeze [&#39;cos&#39;, &#39;aten_unsqueeze_133_dim_0&#39;] -&gt; [&#39;unsqueeze_10&#39;]
    20/305: Constant [] -&gt; [&#39;_val_57&#39;]
    21/305: Mul [&#39;pow_5&#39;, &#39;_val_57&#39;] -&gt; [&#39;mul_19&#39;]
    22/305: Mul [&#39;view_23&#39;, &#39;sigmoid&#39;] -&gt; [&#39;mul_9&#39;]
    23/305: Constant [] -&gt; [&#39;fill&#39;]
    24/305: Constant [] -&gt; [&#39;alpha__1&#39;]
    25/305: Mul [&#39;view_21&#39;, &#39;alpha__1&#39;] -&gt; [&#39;other_1__1&#39;]
    26/305: Add [&#39;embedding&#39;, &#39;other_1__1&#39;] -&gt; [&#39;add_5&#39;]
    27/305: Mul [&#39;mul_13&#39;, &#39;add_7&#39;] -&gt; [&#39;mul_15&#39;]
    28/305: Mul [&#39;mul_13&#39;, &#39;rsqrt_2&#39;] -&gt; [&#39;mul_16&#39;]
    29/305: Mul [&#39;tangents_1&#39;, &#39;mul_11&#39;] -&gt; [&#39;mul_14&#39;]
    30/305: Constant [] -&gt; [&#39;_val_68&#39;]
    31/305: Mul [&#39;pow_9&#39;, &#39;_val_68&#39;] -&gt; [&#39;mul_46&#39;]
    32/305: Constant [] -&gt; [&#39;aten_unsqueeze_147_dim_0&#39;]
    33/305: Unsqueeze [&#39;sin&#39;, &#39;aten_unsqueeze_147_dim_0&#39;] -&gt; [&#39;unsqueeze_11&#39;]
    34/305: Constant [] -&gt; [&#39;aten_unsqueeze_148_dim_0&#39;]
    35/305: Unsqueeze [&#39;eq_1&#39;, &#39;aten_unsqueeze_148_dim_0&#39;] -&gt; [&#39;unsqueeze_12&#39;]
    36/305: Constant [] -&gt; [&#39;alpha__2&#39;]
    37/305: Mul [&#39;sigmoid&#39;, &#39;alpha__2&#39;] -&gt; [&#39;other_1__2&#39;]
    38/305: Sub [&#39;fill&#39;, &#39;other_1__2&#39;] -&gt; [&#39;sub&#39;]
    39/305: Mul [&#39;add_5&#39;, &#39;rsqrt_1&#39;] -&gt; [&#39;mul_7&#39;]
    40/305: Constant [] -&gt; [&#39;_val_75&#39;]
    41/305: Pow [&#39;add_5&#39;, &#39;_val_75&#39;] -&gt; [&#39;pow_7&#39;]
    42/305: Constant [] -&gt; [&#39;_val_79&#39;]
    43/305: ReduceSum [&#39;mul_15&#39;, &#39;_val_79&#39;] -&gt; [&#39;sum_2&#39;]
    44/305: Constant [] -&gt; [&#39;_val_81&#39;]
    45/305: ReduceSum [&#39;mul_14&#39;, &#39;_val_81&#39;] -&gt; [&#39;sum_1&#39;]
    46/305: Mul [&#39;view_23&#39;, &#39;sub&#39;] -&gt; [&#39;mul_23&#39;]
    47/305: Constant [] -&gt; [&#39;_val_85&#39;]
    48/305: Mul [&#39;pow_7&#39;, &#39;_val_85&#39;] -&gt; [&#39;mul_32&#39;]
    49/305: Constant [] -&gt; [&#39;_val_89&#39;]
    50/305: Mul [&#39;sum_2&#39;, &#39;_val_89&#39;] -&gt; [&#39;mul_17&#39;]
    51/305: Constant [] -&gt; [&#39;aten_view_169_size_0&#39;]
    52/305: Reshape [&#39;sum_1&#39;, &#39;aten_view_169_size_0&#39;] -&gt; [&#39;view_28&#39;]
    53/305: Constant [] -&gt; [&#39;aten_add_173_other_1&#39;]
    54/305: Add [&#39;mul_23&#39;, &#39;aten_add_173_other_1&#39;] -&gt; [&#39;add_10&#39;]
    55/305: Constant [] -&gt; [&#39;scalar_tensor_default_1&#39;]
    56/305: Pow [&#39;rsqrt_1&#39;, &#39;scalar_tensor_default_1&#39;] -&gt; [&#39;pow_6&#39;]
    57/305: Constant [] -&gt; [&#39;scalar_tensor_default_2&#39;]
    58/305: Pow [&#39;rsqrt&#39;, &#39;scalar_tensor_default_2&#39;] -&gt; [&#39;pow_8&#39;]
    59/305: Constant [] -&gt; [&#39;scalar_tensor_default_3&#39;]
    60/305: Pow [&#39;rsqrt_2&#39;, &#39;scalar_tensor_default_3&#39;] -&gt; [&#39;pow_4&#39;]
    61/305: Mul [&#39;sigmoid&#39;, &#39;add_10&#39;] -&gt; [&#39;mul_24&#39;]
    62/305: Mul [&#39;mul_17&#39;, &#39;pow_4&#39;] -&gt; [&#39;mul_18&#39;]
    63/305: Constant [] -&gt; [&#39;aten_expand_186_size_1&#39;]
    64/305: Expand [&#39;mul_18&#39;, &#39;aten_expand_186_size_1&#39;] -&gt; [&#39;expand_9&#39;]
    65/305: Constant [] -&gt; [&#39;scalar_tensor_default_4&#39;]
    66/305: Div [&#39;expand_9&#39;, &#39;scalar_tensor_default_4&#39;] -&gt; [&#39;div_1&#39;]
    67/305: Mul [&#39;div_1&#39;, &#39;mul_19&#39;] -&gt; [&#39;mul_20&#39;]
    68/305: Constant [] -&gt; [&#39;alpha__3&#39;]
    69/305: Mul [&#39;mul_20&#39;, &#39;alpha__3&#39;] -&gt; [&#39;other_1__3&#39;]
    70/305: Add [&#39;mul_16&#39;, &#39;other_1__3&#39;] -&gt; [&#39;add_9&#39;]
    71/305: Constant [] -&gt; [&#39;aten_view_193_size_0&#39;]
    72/305: Reshape [&#39;add_9&#39;, &#39;aten_view_193_size_0&#39;] -&gt; [&#39;view_29&#39;]
    73/305: Transpose [&#39;view_29&#39;] -&gt; [&#39;t_7&#39;]
    74/305: MatMul [&#39;view_29&#39;, &#39;t_9&#39;] -&gt; [&#39;mm_8&#39;]
    75/305: MatMul [&#39;t_7&#39;, &#39;view_26&#39;] -&gt; [&#39;mm_7&#39;]
    76/305: Constant [] -&gt; [&#39;aten_view_198_size_0&#39;]
    77/305: Reshape [&#39;mm_8&#39;, &#39;aten_view_198_size_0&#39;] -&gt; [&#39;view_30&#39;]
    78/305: Transpose [&#39;mm_7&#39;] -&gt; [&#39;t_8&#39;]
    79/305: Mul [&#39;view_30&#39;, &#39;mul_9&#39;] -&gt; [&#39;mul_21&#39;]
    80/305: Mul [&#39;view_30&#39;, &#39;view_25&#39;] -&gt; [&#39;mul_22&#39;]
    81/305: Transpose [&#39;t_8&#39;] -&gt; [&#39;t_10&#39;]
    82/305: Constant [] -&gt; [&#39;aten_view_204_size_0&#39;]
    83/305: Reshape [&#39;mul_21&#39;, &#39;aten_view_204_size_0&#39;] -&gt; [&#39;view_31&#39;]
    84/305: Mul [&#39;mul_22&#39;, &#39;mul_24&#39;] -&gt; [&#39;mul_25&#39;]
    85/305: Transpose [&#39;view_31&#39;] -&gt; [&#39;t_11&#39;]
    86/305: MatMul [&#39;view_31&#39;, &#39;t_13&#39;] -&gt; [&#39;mm_10&#39;]
    87/305: Constant [] -&gt; [&#39;aten_view_209_size_0&#39;]
    88/305: Reshape [&#39;mul_25&#39;, &#39;aten_view_209_size_0&#39;] -&gt; [&#39;view_33&#39;]
    89/305: MatMul [&#39;t_11&#39;, &#39;view_22&#39;] -&gt; [&#39;mm_9&#39;]
    90/305: Constant [] -&gt; [&#39;aten_view_212_size_0&#39;]
    91/305: Reshape [&#39;mm_10&#39;, &#39;aten_view_212_size_0&#39;] -&gt; [&#39;view_32&#39;]
    92/305: Transpose [&#39;view_33&#39;] -&gt; [&#39;t_15&#39;]
    93/305: MatMul [&#39;view_33&#39;, &#39;t_17&#39;] -&gt; [&#39;mm_12&#39;]
    94/305: Transpose [&#39;mm_9&#39;] -&gt; [&#39;t_12&#39;]
    95/305: MatMul [&#39;t_15&#39;, &#39;view_22&#39;] -&gt; [&#39;mm_11&#39;]
    96/305: Constant [] -&gt; [&#39;aten_view_218_size_0&#39;]
    97/305: Reshape [&#39;mm_12&#39;, &#39;aten_view_218_size_0&#39;] -&gt; [&#39;view_34&#39;]
    98/305: Transpose [&#39;t_12&#39;] -&gt; [&#39;t_14&#39;]
    99/305: Transpose [&#39;mm_11&#39;] -&gt; [&#39;t_16&#39;]
    100/305: Constant [] -&gt; [&#39;alpha__4&#39;]
    101/305: Mul [&#39;view_34&#39;, &#39;alpha__4&#39;] -&gt; [&#39;other_1__4&#39;]
    102/305: Add [&#39;view_32&#39;, &#39;other_1__4&#39;] -&gt; [&#39;add_11&#39;]
    103/305: Transpose [&#39;t_16&#39;] -&gt; [&#39;t_18&#39;]
    104/305: Mul [&#39;add_11&#39;, &#39;primals_2&#39;] -&gt; [&#39;mul_26&#39;]
    105/305: Mul [&#39;add_11&#39;, &#39;mul_7&#39;] -&gt; [&#39;mul_27&#39;]
    106/305: Mul [&#39;mul_26&#39;, &#39;add_5&#39;] -&gt; [&#39;mul_28&#39;]
    107/305: Mul [&#39;mul_26&#39;, &#39;rsqrt_1&#39;] -&gt; [&#39;mul_29&#39;]
    108/305: Constant [] -&gt; [&#39;_val_150&#39;]
    109/305: ReduceSum [&#39;mul_27&#39;, &#39;_val_150&#39;] -&gt; [&#39;sum_3&#39;]
    110/305: Constant [] -&gt; [&#39;_val_152&#39;]
    111/305: ReduceSum [&#39;mul_28&#39;, &#39;_val_152&#39;] -&gt; [&#39;sum_4&#39;]
    112/305: Constant [] -&gt; [&#39;alpha__5&#39;]
    113/305: Mul [&#39;mul_29&#39;, &#39;alpha__5&#39;] -&gt; [&#39;other_1__5&#39;]
    114/305: Add [&#39;add_9&#39;, &#39;other_1__5&#39;] -&gt; [&#39;add_12&#39;]
    115/305: Constant [] -&gt; [&#39;aten_view_233_size_0&#39;]
    116/305: Reshape [&#39;sum_3&#39;, &#39;aten_view_233_size_0&#39;] -&gt; [&#39;view_35&#39;]
    117/305: Constant [] -&gt; [&#39;_val_157&#39;]
    118/305: Mul [&#39;sum_4&#39;, &#39;_val_157&#39;] -&gt; [&#39;mul_30&#39;]
    119/305: Mul [&#39;mul_30&#39;, &#39;pow_6&#39;] -&gt; [&#39;mul_31&#39;]
    120/305: Constant [] -&gt; [&#39;aten_expand_238_size_1&#39;]
    121/305: Expand [&#39;mul_31&#39;, &#39;aten_expand_238_size_1&#39;] -&gt; [&#39;expand_10&#39;]
    122/305: Constant [] -&gt; [&#39;scalar_tensor_default_5&#39;]
    123/305: Div [&#39;expand_10&#39;, &#39;scalar_tensor_default_5&#39;] -&gt; [&#39;div_2&#39;]
    124/305: Mul [&#39;div_2&#39;, &#39;mul_32&#39;] -&gt; [&#39;mul_33&#39;]
    125/305: Constant [] -&gt; [&#39;alpha__6&#39;]
    126/305: Mul [&#39;mul_33&#39;, &#39;alpha__6&#39;] -&gt; [&#39;other_1__6&#39;]
    127/305: Add [&#39;add_12&#39;, &#39;other_1__6&#39;] -&gt; [&#39;add_13&#39;]
    128/305: Constant [] -&gt; [&#39;aten_view_245_size_0&#39;]
    129/305: Reshape [&#39;add_13&#39;, &#39;aten_view_245_size_0&#39;] -&gt; [&#39;view_36&#39;]
    130/305: Transpose [&#39;view_36&#39;] -&gt; [&#39;t_19&#39;]
    131/305: MatMul [&#39;view_36&#39;, &#39;t_21&#39;] -&gt; [&#39;mm_14&#39;]
    132/305: MatMul [&#39;t_19&#39;, &#39;view_20&#39;] -&gt; [&#39;mm_13&#39;]
    133/305: Constant [] -&gt; [&#39;aten_view_250_size_0&#39;]
    134/305: Reshape [&#39;mm_14&#39;, &#39;aten_view_250_size_0&#39;] -&gt; [&#39;view_37&#39;]
    135/305: Transpose [&#39;mm_13&#39;] -&gt; [&#39;t_20&#39;]
    136/305: Constant [] -&gt; [&#39;aten_view_253_size_0&#39;]
    137/305: Reshape [&#39;view_37&#39;, &#39;aten_view_253_size_0&#39;] -&gt; [&#39;view_38&#39;]
    138/305: Transpose [&#39;t_20&#39;] -&gt; [&#39;t_22&#39;]
    139/305: Transpose [&#39;view_38&#39;] -&gt; [&#39;transpose_6&#39;]
    140/305: Constant [] -&gt; [&#39;aten_view_258_size_0&#39;]
    141/305: Reshape [&#39;transpose_6&#39;, &#39;aten_view_258_size_0&#39;] -&gt; [&#39;view_39&#39;]
    142/305: MatMul [&#39;transpose_7&#39;, &#39;view_39&#39;] -&gt; [&#39;bmm_3&#39;]
    143/305: MatMul [&#39;view_39&#39;, &#39;transpose_8&#39;] -&gt; [&#39;bmm_4&#39;]
    144/305: Constant [] -&gt; [&#39;aten_view_262_size_0&#39;]
    145/305: Reshape [&#39;bmm_3&#39;, &#39;aten_view_262_size_0&#39;] -&gt; [&#39;view_40&#39;]
    146/305: Constant [] -&gt; [&#39;aten_view_264_size_0&#39;]
    147/305: Reshape [&#39;bmm_4&#39;, &#39;aten_view_264_size_0&#39;] -&gt; [&#39;view_41&#39;]
    148/305: Constant [] -&gt; [&#39;alpha__7&#39;]
    149/305: Mul [&#39;view_40&#39;, &#39;alpha__7&#39;] -&gt; [&#39;other_1__7&#39;]
    150/305: Add [&#39;tangents_3&#39;, &#39;other_1__7&#39;] -&gt; [&#39;add_14&#39;]
    151/305: Mul [&#39;view_41&#39;, &#39;detach_13&#39;] -&gt; [&#39;mul_34&#39;]
    152/305: Transpose [&#39;add_14&#39;] -&gt; [&#39;transpose_12&#39;]
    153/305: Constant [] -&gt; [&#39;_val_191&#39;]
    154/305: ReduceSum [&#39;mul_34&#39;, &#39;_val_191&#39;] -&gt; [&#39;sum_5&#39;]
    155/305: Mul [&#39;detach_13&#39;, &#39;sum_5&#39;] -&gt; [&#39;mul_35&#39;]
    156/305: Constant [] -&gt; [&#39;aten_view_273_size_0&#39;]
    157/305: Reshape [&#39;transpose_12&#39;, &#39;aten_view_273_size_0&#39;] -&gt; [&#39;view_45&#39;]
    158/305: Constant [] -&gt; [&#39;alpha__8&#39;]
    159/305: Mul [&#39;mul_35&#39;, &#39;alpha__8&#39;] -&gt; [&#39;other_1__8&#39;]
    160/305: Sub [&#39;mul_34&#39;, &#39;other_1__8&#39;] -&gt; [&#39;sub_1&#39;]
    161/305: Constant [] -&gt; [&#39;aten_view_276_size_0&#39;]
    162/305: Reshape [&#39;view_45&#39;, &#39;aten_view_276_size_0&#39;] -&gt; [&#39;view_48&#39;]
    163/305: Constant [] -&gt; [&#39;_val_200&#39;]
    164/305: Div [&#39;sub_1&#39;, &#39;_val_200&#39;] -&gt; [&#39;div_3&#39;]
    165/305: Transpose [&#39;view_48&#39;] -&gt; [&#39;t_23&#39;]
    166/305: MatMul [&#39;view_48&#39;, &#39;t_25&#39;] -&gt; [&#39;mm_16&#39;]
    167/305: Constant [] -&gt; [&#39;aten_view_282_size_0&#39;]
    168/305: Reshape [&#39;div_3&#39;, &#39;aten_view_282_size_0&#39;] -&gt; [&#39;view_42&#39;]
    169/305: MatMul [&#39;t_23&#39;, &#39;view_1&#39;] -&gt; [&#39;mm_15&#39;]
    170/305: Constant [] -&gt; [&#39;aten_view_285_size_0&#39;]
    171/305: Reshape [&#39;mm_16&#39;, &#39;aten_view_285_size_0&#39;] -&gt; [&#39;view_49&#39;]
    172/305: MatMul [&#39;transpose_9&#39;, &#39;view_42&#39;] -&gt; [&#39;bmm_5&#39;]
    173/305: MatMul [&#39;view_42&#39;, &#39;transpose_10&#39;] -&gt; [&#39;bmm_6&#39;]
    174/305: Transpose [&#39;mm_15&#39;] -&gt; [&#39;t_24&#39;]
    175/305: Constant [] -&gt; [&#39;aten_view_290_size_0&#39;]
    176/305: Reshape [&#39;bmm_5&#39;, &#39;aten_view_290_size_0&#39;] -&gt; [&#39;view_43&#39;]
    177/305: Constant [] -&gt; [&#39;aten_view_292_size_0&#39;]
    178/305: Reshape [&#39;bmm_6&#39;, &#39;aten_view_292_size_0&#39;] -&gt; [&#39;view_44&#39;]
    179/305: Transpose [&#39;t_24&#39;] -&gt; [&#39;t_26&#39;]
    180/305: Transpose [&#39;view_43&#39;] -&gt; [&#39;transpose_11&#39;]
    181/305: Mul [&#39;view_44&#39;, &#39;unsqueeze_11&#39;] -&gt; [&#39;mul_38&#39;]
    182/305: Mul [&#39;view_44&#39;, &#39;unsqueeze_10&#39;] -&gt; [&#39;mul_39&#39;]
    183/305: Constant [] -&gt; [&#39;alpha__9&#39;]
    184/305: Mul [&#39;transpose_11&#39;, &#39;alpha__9&#39;] -&gt; [&#39;other_1__9&#39;]
    185/305: Add [&#39;tangents_2&#39;, &#39;other_1__9&#39;] -&gt; [&#39;add_15&#39;]
    186/305: Constant [] -&gt; [&#39;_val_224&#39;]
    187/305: Constant [] -&gt; [&#39;_val_228&#39;]
    188/305: Constant [] -&gt; [&#39;_val_232&#39;]
    189/305: Constant [] -&gt; [&#39;_val_236&#39;]
    190/305: Slice [&#39;mul_38&#39;, &#39;_val_224&#39;, &#39;_val_228&#39;, &#39;_val_232&#39;, &#39;_val_236&#39;] -&gt; [&#39;slice_36&#39;]
    191/305: Constant [] -&gt; [&#39;_val_241&#39;]
    192/305: Constant [] -&gt; [&#39;_val_245&#39;]
    193/305: Constant [] -&gt; [&#39;_val_249&#39;]
    194/305: Constant [] -&gt; [&#39;_val_253&#39;]
    195/305: Slice [&#39;mul_38&#39;, &#39;_val_241&#39;, &#39;_val_245&#39;, &#39;_val_249&#39;, &#39;_val_253&#39;] -&gt; [&#39;slice_37&#39;]
    196/305: Mul [&#39;add_15&#39;, &#39;unsqueeze_11&#39;] -&gt; [&#39;mul_36&#39;]
    197/305: Mul [&#39;add_15&#39;, &#39;unsqueeze_10&#39;] -&gt; [&#39;mul_37&#39;]
    198/305: Neg [&#39;slice_36&#39;] -&gt; [&#39;neg_3&#39;]
    199/305: Constant [] -&gt; [&#39;_val_263&#39;]
    200/305: Constant [] -&gt; [&#39;_val_267&#39;]
    201/305: Constant [] -&gt; [&#39;_val_271&#39;]
    202/305: Constant [] -&gt; [&#39;_val_275&#39;]
    203/305: Slice [&#39;mul_36&#39;, &#39;_val_263&#39;, &#39;_val_267&#39;, &#39;_val_271&#39;, &#39;_val_275&#39;] -&gt; [&#39;slice_34&#39;]
    204/305: Constant [] -&gt; [&#39;_val_280&#39;]
    205/305: Constant [] -&gt; [&#39;_val_284&#39;]
    206/305: Constant [] -&gt; [&#39;_val_288&#39;]
    207/305: Constant [] -&gt; [&#39;_val_292&#39;]
    208/305: Slice [&#39;mul_36&#39;, &#39;_val_280&#39;, &#39;_val_284&#39;, &#39;_val_288&#39;, &#39;_val_292&#39;] -&gt; [&#39;slice_35&#39;]
    209/305: Constant [] -&gt; [&#39;_val_311&#39;]
    210/305: Transpose [&#39;slice_37&#39;] -&gt; [&#39;_val_312&#39;]
    211/305: Constant [] -&gt; [&#39;_val_313&#39;]
    212/305: ScatterND [&#39;_val_313&#39;, &#39;_val_311&#39;, &#39;_val_312&#39;] -&gt; [&#39;_val_314&#39;]
    213/305: Transpose [&#39;_val_314&#39;] -&gt; [&#39;slice_scatter_6&#39;]
    214/305: Neg [&#39;slice_34&#39;] -&gt; [&#39;neg_2&#39;]
    215/305: Constant [] -&gt; [&#39;_val_334&#39;]
    216/305: Transpose [&#39;neg_3&#39;] -&gt; [&#39;_val_335&#39;]
    217/305: Constant [] -&gt; [&#39;_val_336&#39;]
    218/305: ScatterND [&#39;_val_336&#39;, &#39;_val_334&#39;, &#39;_val_335&#39;] -&gt; [&#39;_val_337&#39;]
    219/305: Transpose [&#39;_val_337&#39;] -&gt; [&#39;slice_scatter_5&#39;]
    220/305: Constant [] -&gt; [&#39;_val_356&#39;]
    221/305: Transpose [&#39;slice_35&#39;] -&gt; [&#39;_val_357&#39;]
    222/305: Constant [] -&gt; [&#39;_val_358&#39;]
    223/305: ScatterND [&#39;_val_358&#39;, &#39;_val_356&#39;, &#39;_val_357&#39;] -&gt; [&#39;_val_359&#39;]
    224/305: Transpose [&#39;_val_359&#39;] -&gt; [&#39;slice_scatter_4&#39;]
    225/305: Constant [] -&gt; [&#39;alpha__10&#39;]
    226/305: Mul [&#39;slice_scatter_6&#39;, &#39;alpha__10&#39;] -&gt; [&#39;other_1__10&#39;]
    227/305: Add [&#39;slice_scatter_5&#39;, &#39;other_1__10&#39;] -&gt; [&#39;add_18&#39;]
    228/305: Constant [] -&gt; [&#39;_val_377&#39;]
    229/305: Transpose [&#39;neg_2&#39;] -&gt; [&#39;_val_378&#39;]
    230/305: Constant [] -&gt; [&#39;_val_379&#39;]
    231/305: ScatterND [&#39;_val_379&#39;, &#39;_val_377&#39;, &#39;_val_378&#39;] -&gt; [&#39;_val_380&#39;]
    232/305: Transpose [&#39;_val_380&#39;] -&gt; [&#39;slice_scatter_3&#39;]
    233/305: Constant [] -&gt; [&#39;alpha__11&#39;]
    234/305: Mul [&#39;mul_39&#39;, &#39;alpha__11&#39;] -&gt; [&#39;other_1__11&#39;]
    235/305: Add [&#39;add_18&#39;, &#39;other_1__11&#39;] -&gt; [&#39;add_19&#39;]
    236/305: Constant [] -&gt; [&#39;alpha__12&#39;]
    237/305: Mul [&#39;slice_scatter_4&#39;, &#39;alpha__12&#39;] -&gt; [&#39;other_1__12&#39;]
    238/305: Add [&#39;slice_scatter_3&#39;, &#39;other_1__12&#39;] -&gt; [&#39;add_16&#39;]
    239/305: Transpose [&#39;add_19&#39;] -&gt; [&#39;transpose_14&#39;]
    240/305: Constant [] -&gt; [&#39;alpha__13&#39;]
    241/305: Mul [&#39;mul_37&#39;, &#39;alpha__13&#39;] -&gt; [&#39;other_1__13&#39;]
    242/305: Add [&#39;add_16&#39;, &#39;other_1__13&#39;] -&gt; [&#39;add_17&#39;]
    243/305: Transpose [&#39;add_17&#39;] -&gt; [&#39;transpose_13&#39;]
    244/305: Constant [] -&gt; [&#39;aten_view_466_size_0&#39;]
    245/305: Reshape [&#39;transpose_14&#39;, &#39;aten_view_466_size_0&#39;] -&gt; [&#39;view_47&#39;]
    246/305: Constant [] -&gt; [&#39;aten_view_469_size_0&#39;]
    247/305: Reshape [&#39;view_47&#39;, &#39;aten_view_469_size_0&#39;] -&gt; [&#39;view_52&#39;]
    248/305: Constant [] -&gt; [&#39;aten_view_471_size_0&#39;]
    249/305: Reshape [&#39;transpose_13&#39;, &#39;aten_view_471_size_0&#39;] -&gt; [&#39;view_46&#39;]
    250/305: Transpose [&#39;view_52&#39;] -&gt; [&#39;t_31&#39;]
    251/305: MatMul [&#39;view_52&#39;, &#39;t_33&#39;] -&gt; [&#39;mm_20&#39;]
    252/305: Constant [] -&gt; [&#39;aten_view_475_size_0&#39;]
    253/305: Reshape [&#39;view_46&#39;, &#39;aten_view_475_size_0&#39;] -&gt; [&#39;view_50&#39;]
    254/305: MatMul [&#39;t_31&#39;, &#39;view_1&#39;] -&gt; [&#39;mm_19&#39;]
    255/305: Constant [] -&gt; [&#39;aten_view_478_size_0&#39;]
    256/305: Reshape [&#39;mm_20&#39;, &#39;aten_view_478_size_0&#39;] -&gt; [&#39;view_53&#39;]
    257/305: Transpose [&#39;view_50&#39;] -&gt; [&#39;t_27&#39;]
    258/305: MatMul [&#39;view_50&#39;, &#39;t_29&#39;] -&gt; [&#39;mm_18&#39;]
    259/305: Transpose [&#39;mm_19&#39;] -&gt; [&#39;t_32&#39;]
    260/305: MatMul [&#39;t_27&#39;, &#39;view_1&#39;] -&gt; [&#39;mm_17&#39;]
    261/305: Constant [] -&gt; [&#39;aten_view_484_size_0&#39;]
    262/305: Reshape [&#39;mm_18&#39;, &#39;aten_view_484_size_0&#39;] -&gt; [&#39;view_51&#39;]
    263/305: Transpose [&#39;t_32&#39;] -&gt; [&#39;t_34&#39;]
    264/305: Transpose [&#39;mm_17&#39;] -&gt; [&#39;t_28&#39;]
    265/305: Constant [] -&gt; [&#39;alpha__14&#39;]
    266/305: Mul [&#39;view_51&#39;, &#39;alpha__14&#39;] -&gt; [&#39;other_1__14&#39;]
    267/305: Add [&#39;view_49&#39;, &#39;other_1__14&#39;] -&gt; [&#39;add_20&#39;]
    268/305: Transpose [&#39;t_28&#39;] -&gt; [&#39;t_30&#39;]
    269/305: Constant [] -&gt; [&#39;alpha__15&#39;]
    270/305: Mul [&#39;view_53&#39;, &#39;alpha__15&#39;] -&gt; [&#39;other_1__15&#39;]
    271/305: Add [&#39;add_20&#39;, &#39;other_1__15&#39;] -&gt; [&#39;add_21&#39;]
    272/305: Mul [&#39;add_21&#39;, &#39;primals_1&#39;] -&gt; [&#39;mul_40&#39;]
    273/305: Mul [&#39;add_21&#39;, &#39;mul_1&#39;] -&gt; [&#39;mul_41&#39;]
    274/305: Mul [&#39;mul_40&#39;, &#39;embedding&#39;] -&gt; [&#39;mul_42&#39;]
    275/305: Mul [&#39;mul_40&#39;, &#39;rsqrt&#39;] -&gt; [&#39;mul_43&#39;]
    276/305: Constant [] -&gt; [&#39;_val_417&#39;]
    277/305: ReduceSum [&#39;mul_41&#39;, &#39;_val_417&#39;] -&gt; [&#39;sum_6&#39;]
    278/305: Constant [] -&gt; [&#39;_val_419&#39;]
    279/305: ReduceSum [&#39;mul_42&#39;, &#39;_val_419&#39;] -&gt; [&#39;sum_7&#39;]
    280/305: Constant [] -&gt; [&#39;alpha__16&#39;]
    281/305: Mul [&#39;mul_43&#39;, &#39;alpha__16&#39;] -&gt; [&#39;other_1__16&#39;]
    282/305: Add [&#39;add_13&#39;, &#39;other_1__16&#39;] -&gt; [&#39;add_22&#39;]
    283/305: Constant [] -&gt; [&#39;aten_view_500_size_0&#39;]
    284/305: Reshape [&#39;sum_6&#39;, &#39;aten_view_500_size_0&#39;] -&gt; [&#39;view_54&#39;]
    285/305: Constant [] -&gt; [&#39;_val_424&#39;]
    286/305: Mul [&#39;sum_7&#39;, &#39;_val_424&#39;] -&gt; [&#39;mul_44&#39;]
    287/305: Mul [&#39;mul_44&#39;, &#39;pow_8&#39;] -&gt; [&#39;mul_45&#39;]
    288/305: Constant [] -&gt; [&#39;aten_expand_505_size_1&#39;]
    289/305: Expand [&#39;mul_45&#39;, &#39;aten_expand_505_size_1&#39;] -&gt; [&#39;expand_11&#39;]
    290/305: Constant [] -&gt; [&#39;scalar_tensor_default_6&#39;]
    291/305: Div [&#39;expand_11&#39;, &#39;scalar_tensor_default_6&#39;] -&gt; [&#39;div_4&#39;]
    292/305: Mul [&#39;div_4&#39;, &#39;mul_46&#39;] -&gt; [&#39;mul_47&#39;]
    293/305: Constant [] -&gt; [&#39;alpha__17&#39;]
    294/305: Mul [&#39;mul_47&#39;, &#39;alpha__17&#39;] -&gt; [&#39;other_1__17&#39;]
    295/305: Add [&#39;add_22&#39;, &#39;other_1__17&#39;] -&gt; [&#39;add_23&#39;]
    296/305: Constant [] -&gt; [&#39;aten_masked_fill_512_value_cast&#39;]
    297/305: Where [&#39;unsqueeze_12&#39;, &#39;aten_masked_fill_512_value_cast&#39;, &#39;add_23&#39;] -&gt; [&#39;masked_fill_1&#39;]
    298/305: Constant [] -&gt; [&#39;_val_436&#39;]
    299/305: ConstantOfShape [&#39;_val_436&#39;] -&gt; [&#39;aten_new_zeros_514_result&#39;]
    300/305: SequenceConstruct [&#39;primals_13&#39;] -&gt; [&#39;438&#39;]
    301/305: Constant [] -&gt; [&#39;int64_0__18&#39;]
    302/305: SequenceAt [&#39;438&#39;, &#39;int64_0__18&#39;] -&gt; [&#39;index__18&#39;]
    303/305: Constant [] -&gt; [&#39;int64_m1_1d__18&#39;]
    304/305: Unsqueeze [&#39;index__18&#39;, &#39;int64_m1_1d__18&#39;] -&gt; [&#39;new_index__18&#39;]
    305/305: ScatterND [&#39;aten_new_zeros_514_result&#39;, &#39;new_index__18&#39;, &#39;masked_fill_1&#39;] -&gt; [&#39;_unsafe_index_put&#39;]
    
    NODES in {name!r}
    1/275: Gather [&#39;primals_4&#39;, &#39;primals_13&#39;] -&gt; [&#39;embedding&#39;]
    2/275: Transpose [&#39;primals_8&#39;] -&gt; [&#39;t_3&#39;]
    3/275: Constant [] -&gt; [&#39;_val_22&#39;]
    4/275: Constant [] -&gt; [&#39;_val_23&#39;]
    5/275: Constant [] -&gt; [&#39;size_0__1&#39;]
    6/275: Constant [] -&gt; [&#39;fill_value_1__1&#39;]
    7/275: Expand [&#39;fill_value_1__1&#39;, &#39;size_0__1&#39;] -&gt; [&#39;full&#39;]
    8/275: Constant [] -&gt; [&#39;_val_36&#39;]
    9/275: Constant [] -&gt; [&#39;_val_40&#39;]
    10/275: Constant [] -&gt; [&#39;_val_44&#39;]
    11/275: Constant [] -&gt; [&#39;_val_48&#39;]
    12/275: Slice [&#39;primals_14&#39;, &#39;_val_36&#39;, &#39;_val_40&#39;, &#39;_val_44&#39;, &#39;_val_48&#39;] -&gt; [&#39;slice_8&#39;]
    13/275: Transpose [&#39;primals_9&#39;] -&gt; [&#39;t_4&#39;]
    14/275: Transpose [&#39;primals_10&#39;] -&gt; [&#39;t_5&#39;]
    15/275: Transpose [&#39;primals_11&#39;] -&gt; [&#39;t_6&#39;]
    16/275: Transpose [&#39;primals_5&#39;] -&gt; [&#39;t&#39;]
    17/275: Transpose [&#39;primals_6&#39;] -&gt; [&#39;t_1&#39;]
    18/275: Transpose [&#39;primals_7&#39;] -&gt; [&#39;t_2&#39;]
    19/275: Constant [] -&gt; [&#39;aten_unsqueeze_187_dim_0&#39;]
    20/275: Unsqueeze [&#39;primals_12&#39;, &#39;aten_unsqueeze_187_dim_0&#39;] -&gt; [&#39;unsqueeze_7&#39;]
    21/275: Constant [] -&gt; [&#39;scalar_tensor_default&#39;]
    22/275: Pow [&#39;embedding&#39;, &#39;scalar_tensor_default&#39;] -&gt; [&#39;pow_1&#39;]
    23/275: Transpose [&#39;t_3&#39;] -&gt; [&#39;t_21&#39;]
    24/275: Constant [] -&gt; [&#39;aten_triu_195_diagonal&#39;]
    25/275: Trilu [&#39;full&#39;, &#39;aten_triu_195_diagonal&#39;] -&gt; [&#39;triu&#39;]
    26/275: Constant [] -&gt; [&#39;aten_unsqueeze_196_dim_0&#39;]
    27/275: Unsqueeze [&#39;slice_8&#39;, &#39;aten_unsqueeze_196_dim_0&#39;] -&gt; [&#39;unsqueeze_5&#39;]
    28/275: Transpose [&#39;t_4&#39;] -&gt; [&#39;t_17&#39;]
    29/275: Transpose [&#39;t_5&#39;] -&gt; [&#39;t_13&#39;]
    30/275: Transpose [&#39;t_6&#39;] -&gt; [&#39;t_9&#39;]
    31/275: Transpose [&#39;t&#39;] -&gt; [&#39;t_33&#39;]
    32/275: Transpose [&#39;t_1&#39;] -&gt; [&#39;t_29&#39;]
    33/275: Transpose [&#39;t_2&#39;] -&gt; [&#39;t_25&#39;]
    34/275: Constant [] -&gt; [&#39;_val_75&#39;]
    35/275: Constant [] -&gt; [&#39;_val_79&#39;]
    36/275: Constant [] -&gt; [&#39;_val_83&#39;]
    37/275: Constant [] -&gt; [&#39;_val_87&#39;]
    38/275: Slice [&#39;unsqueeze_7&#39;, &#39;_val_75&#39;, &#39;_val_79&#39;, &#39;_val_83&#39;, &#39;_val_87&#39;] -&gt; [&#39;slice_21&#39;]
    39/275: Constant [] -&gt; [&#39;_val_89&#39;]
    40/275: ReduceMean [&#39;pow_1&#39;, &#39;_val_89&#39;] -&gt; [&#39;mean&#39;]
    41/275: Constant [] -&gt; [&#39;gt&#39;]
    42/275: Constant [] -&gt; [&#39;aten_unsqueeze_240_dim_0&#39;]
    43/275: Unsqueeze [&#39;unsqueeze_5&#39;, &#39;aten_unsqueeze_240_dim_0&#39;] -&gt; [&#39;unsqueeze_6&#39;]
    44/275: Constant [] -&gt; [&#39;aten_unsqueeze_241_dim_0&#39;]
    45/275: Unsqueeze [&#39;slice_21&#39;, &#39;aten_unsqueeze_241_dim_0&#39;] -&gt; [&#39;unsqueeze_8&#39;]
    46/275: Constant [] -&gt; [&#39;aten_add_243_other_1&#39;]
    47/275: Add [&#39;mean&#39;, &#39;aten_add_243_other_1&#39;] -&gt; [&#39;add_1&#39;]
    48/275: Cast [&#39;gt&#39;] -&gt; [&#39;convert_element_type_default&#39;]
    49/275: Mul [&#39;triu&#39;, &#39;convert_element_type_default&#39;] -&gt; [&#39;mul&#39;]
    50/275: Constant [] -&gt; [&#39;_val_119&#39;]
    51/275: Constant [] -&gt; [&#39;_val_123&#39;]
    52/275: Constant [] -&gt; [&#39;_val_127&#39;]
    53/275: Constant [] -&gt; [&#39;_val_131&#39;]
    54/275: Slice [&#39;unsqueeze_6&#39;, &#39;_val_119&#39;, &#39;_val_123&#39;, &#39;_val_127&#39;, &#39;_val_131&#39;] -&gt; [&#39;slice_9&#39;]
    55/275: Constant [] -&gt; [&#39;aten_expand_265_size_1&#39;]
    56/275: Expand [&#39;unsqueeze_8&#39;, &#39;aten_expand_265_size_1&#39;] -&gt; [&#39;expand_2&#39;]
    57/275: Sqrt [&#39;add_1&#39;] -&gt; [&#39;aten_rsqrt_266_tmp&#39;]
    58/275: Reciprocal [&#39;aten_rsqrt_266_tmp&#39;] -&gt; [&#39;rsqrt&#39;]
    59/275: Constant [] -&gt; [&#39;aten_unsqueeze_284_dim_0&#39;]
    60/275: Unsqueeze [&#39;mul&#39;, &#39;aten_unsqueeze_284_dim_0&#39;] -&gt; [&#39;unsqueeze_3&#39;]
    61/275: Constant [] -&gt; [&#39;aten_expand_286_size_1&#39;]
    62/275: Expand [&#39;expand_2&#39;, &#39;aten_expand_286_size_1&#39;] -&gt; [&#39;expand_3&#39;]
    63/275: Mul [&#39;embedding&#39;, &#39;rsqrt&#39;] -&gt; [&#39;mul_1&#39;]
    64/275: Constant [] -&gt; [&#39;aten_unsqueeze_289_dim_0&#39;]
    65/275: Unsqueeze [&#39;unsqueeze_3&#39;, &#39;aten_unsqueeze_289_dim_0&#39;] -&gt; [&#39;unsqueeze_4&#39;]
    66/275: Mul [&#39;primals_1&#39;, &#39;mul_1&#39;] -&gt; [&#39;mul_2&#39;]
    67/275: Constant [] -&gt; [&#39;_val_167&#39;]
    68/275: Constant [] -&gt; [&#39;_val_171&#39;]
    69/275: Constant [] -&gt; [&#39;_val_175&#39;]
    70/275: Constant [] -&gt; [&#39;_val_179&#39;]
    71/275: Slice [&#39;unsqueeze_4&#39;, &#39;_val_167&#39;, &#39;_val_171&#39;, &#39;_val_175&#39;, &#39;_val_179&#39;] -&gt; [&#39;slice_3&#39;]
    72/275: Constant [] -&gt; [&#39;aten_view_313_size_0&#39;]
    73/275: Reshape [&#39;mul_2&#39;, &#39;aten_view_313_size_0&#39;] -&gt; [&#39;view_1&#39;]
    74/275: Constant [] -&gt; [&#39;view_11&#39;]
    75/275: Constant [] -&gt; [&#39;_val_188&#39;]
    76/275: Constant [] -&gt; [&#39;_val_192&#39;]
    77/275: Constant [] -&gt; [&#39;_val_196&#39;]
    78/275: Constant [] -&gt; [&#39;_val_200&#39;]
    79/275: Slice [&#39;slice_3&#39;, &#39;_val_188&#39;, &#39;_val_192&#39;, &#39;_val_196&#39;, &#39;_val_200&#39;] -&gt; [&#39;slice_4&#39;]
    80/275: MatMul [&#39;view_1&#39;, &#39;t&#39;] -&gt; [&#39;mm&#39;]
    81/275: MatMul [&#39;view_1&#39;, &#39;t_1&#39;] -&gt; [&#39;mm_1&#39;]
    82/275: MatMul [&#39;view_1&#39;, &#39;t_2&#39;] -&gt; [&#39;mm_2&#39;]
    83/275: Constant [] -&gt; [&#39;aten_expand_338_size_1&#39;]
    84/275: Expand [&#39;slice_4&#39;, &#39;aten_expand_338_size_1&#39;] -&gt; [&#39;expand_1&#39;]
    85/275: Constant [] -&gt; [&#39;aten_view_340_size_0&#39;]
    86/275: Reshape [&#39;mm&#39;, &#39;aten_view_340_size_0&#39;] -&gt; [&#39;view_2&#39;]
    87/275: Constant [] -&gt; [&#39;aten_view_342_size_0&#39;]
    88/275: Reshape [&#39;mm_1&#39;, &#39;aten_view_342_size_0&#39;] -&gt; [&#39;view_4&#39;]
    89/275: Constant [] -&gt; [&#39;aten_view_344_size_0&#39;]
    90/275: Reshape [&#39;mm_2&#39;, &#39;aten_view_344_size_0&#39;] -&gt; [&#39;view_6&#39;]
    91/275: MatMul [&#39;expand_3&#39;, &#39;view_11&#39;] -&gt; [&#39;view_12&#39;]
    92/275: Constant [] -&gt; [&#39;aten_view_349_size_0&#39;]
    93/275: Reshape [&#39;view_2&#39;, &#39;aten_view_349_size_0&#39;] -&gt; [&#39;view_7&#39;]
    94/275: Constant [] -&gt; [&#39;aten_view_351_size_0&#39;]
    95/275: Reshape [&#39;view_4&#39;, &#39;aten_view_351_size_0&#39;] -&gt; [&#39;view_8&#39;]
    96/275: Constant [] -&gt; [&#39;aten_view_353_size_0&#39;]
    97/275: Reshape [&#39;view_6&#39;, &#39;aten_view_353_size_0&#39;] -&gt; [&#39;view_9&#39;]
    98/275: Transpose [&#39;view_12&#39;] -&gt; [&#39;transpose_3&#39;]
    99/275: Constant [] -&gt; [&#39;_val_227&#39;]
    100/275: Constant [] -&gt; [&#39;_val_231&#39;]
    101/275: Constant [] -&gt; [&#39;_val_235&#39;]
    102/275: Constant [] -&gt; [&#39;_val_239&#39;]
    103/275: Slice [&#39;expand_1&#39;, &#39;_val_227&#39;, &#39;_val_231&#39;, &#39;_val_235&#39;, &#39;_val_239&#39;] -&gt; [&#39;slice_5&#39;]
    104/275: Transpose [&#39;view_7&#39;] -&gt; [&#39;transpose&#39;]
    105/275: Transpose [&#39;view_8&#39;] -&gt; [&#39;transpose_1&#39;]
    106/275: Transpose [&#39;view_9&#39;] -&gt; [&#39;transpose_2&#39;]
    107/275: Concat [&#39;transpose_3&#39;, &#39;transpose_3&#39;] -&gt; [&#39;cat&#39;]
    108/275: Constant [] -&gt; [&#39;_val_249&#39;]
    109/275: Constant [] -&gt; [&#39;_val_253&#39;]
    110/275: Constant [] -&gt; [&#39;_val_257&#39;]
    111/275: Constant [] -&gt; [&#39;_val_261&#39;]
    112/275: Slice [&#39;slice_5&#39;, &#39;_val_249&#39;, &#39;_val_253&#39;, &#39;_val_257&#39;, &#39;_val_261&#39;] -&gt; [&#39;slice_6&#39;]
    113/275: Constant [] -&gt; [&#39;_val_266&#39;]
    114/275: Constant [] -&gt; [&#39;_val_270&#39;]
    115/275: Constant [] -&gt; [&#39;_val_274&#39;]
    116/275: Constant [] -&gt; [&#39;_val_278&#39;]
    117/275: Slice [&#39;transpose&#39;, &#39;_val_266&#39;, &#39;_val_270&#39;, &#39;_val_274&#39;, &#39;_val_278&#39;] -&gt; [&#39;slice_24&#39;]
    118/275: Constant [] -&gt; [&#39;_val_283&#39;]
    119/275: Constant [] -&gt; [&#39;_val_287&#39;]
    120/275: Constant [] -&gt; [&#39;_val_291&#39;]
    121/275: Constant [] -&gt; [&#39;_val_295&#39;]
    122/275: Slice [&#39;transpose&#39;, &#39;_val_283&#39;, &#39;_val_287&#39;, &#39;_val_291&#39;, &#39;_val_295&#39;] -&gt; [&#39;slice_25&#39;]
    123/275: Constant [] -&gt; [&#39;_val_300&#39;]
    124/275: Constant [] -&gt; [&#39;_val_304&#39;]
    125/275: Constant [] -&gt; [&#39;_val_308&#39;]
    126/275: Constant [] -&gt; [&#39;_val_312&#39;]
    127/275: Slice [&#39;transpose_1&#39;, &#39;_val_300&#39;, &#39;_val_304&#39;, &#39;_val_308&#39;, &#39;_val_312&#39;] -&gt; [&#39;slice_26&#39;]
    128/275: Constant [] -&gt; [&#39;_val_317&#39;]
    129/275: Constant [] -&gt; [&#39;_val_321&#39;]
    130/275: Constant [] -&gt; [&#39;_val_325&#39;]
    131/275: Constant [] -&gt; [&#39;_val_329&#39;]
    132/275: Slice [&#39;transpose_1&#39;, &#39;_val_317&#39;, &#39;_val_321&#39;, &#39;_val_325&#39;, &#39;_val_329&#39;] -&gt; [&#39;slice_27&#39;]
    133/275: Constant [] -&gt; [&#39;aten_expand_463_size_1&#39;]
    134/275: Expand [&#39;transpose_2&#39;, &#39;aten_expand_463_size_1&#39;] -&gt; [&#39;expand_8&#39;]
    135/275: Cos [&#39;cat&#39;] -&gt; [&#39;cos&#39;]
    136/275: Sin [&#39;cat&#39;] -&gt; [&#39;sin&#39;]
    137/275: Constant [] -&gt; [&#39;_val_338&#39;]
    138/275: Constant [] -&gt; [&#39;_val_342&#39;]
    139/275: Constant [] -&gt; [&#39;_val_346&#39;]
    140/275: Constant [] -&gt; [&#39;_val_350&#39;]
    141/275: Slice [&#39;slice_6&#39;, &#39;_val_338&#39;, &#39;_val_342&#39;, &#39;_val_346&#39;, &#39;_val_350&#39;] -&gt; [&#39;slice_7&#39;]
    142/275: Neg [&#39;slice_25&#39;] -&gt; [&#39;neg&#39;]
    143/275: Neg [&#39;slice_27&#39;] -&gt; [&#39;neg_1&#39;]
    144/275: Constant [] -&gt; [&#39;aten_unsqueeze_486_dim_0&#39;]
    145/275: Unsqueeze [&#39;cos&#39;, &#39;aten_unsqueeze_486_dim_0&#39;] -&gt; [&#39;unsqueeze_10&#39;]
    146/275: Constant [] -&gt; [&#39;aten_unsqueeze_487_dim_0&#39;]
    147/275: Unsqueeze [&#39;sin&#39;, &#39;aten_unsqueeze_487_dim_0&#39;] -&gt; [&#39;unsqueeze_11&#39;]
    148/275: Constant [] -&gt; [&#39;alpha__2&#39;]
    149/275: Mul [&#39;slice_9&#39;, &#39;alpha__2&#39;] -&gt; [&#39;other_1__2&#39;]
    150/275: Add [&#39;slice_7&#39;, &#39;other_1__2&#39;] -&gt; [&#39;add&#39;]
    151/275: Concat [&#39;neg&#39;, &#39;slice_24&#39;] -&gt; [&#39;cat_1&#39;]
    152/275: Concat [&#39;neg_1&#39;, &#39;slice_26&#39;] -&gt; [&#39;cat_2&#39;]
    153/275: Constant [] -&gt; [&#39;aten_view_494_size_0&#39;]
    154/275: Reshape [&#39;expand_8&#39;, &#39;aten_view_494_size_0&#39;] -&gt; [&#39;view_17&#39;]
    155/275: Mul [&#39;transpose&#39;, &#39;unsqueeze_10&#39;] -&gt; [&#39;mul_3&#39;]
    156/275: Mul [&#39;transpose_1&#39;, &#39;unsqueeze_10&#39;] -&gt; [&#39;mul_5&#39;]
    157/275: Constant [] -&gt; [&#39;scalar_tensor_default_1&#39;]
    158/275: Equal [&#39;add&#39;, &#39;scalar_tensor_default_1&#39;] -&gt; [&#39;eq&#39;]
    159/275: Mul [&#39;cat_1&#39;, &#39;unsqueeze_11&#39;] -&gt; [&#39;mul_4&#39;]
    160/275: Mul [&#39;cat_2&#39;, &#39;unsqueeze_11&#39;] -&gt; [&#39;mul_6&#39;]
    161/275: Transpose [&#39;view_17&#39;] -&gt; [&#39;transpose_8&#39;]
    162/275: Constant [] -&gt; [&#39;_val_372&#39;]
    163/275: Where [&#39;eq&#39;, &#39;_val_372&#39;, &#39;slice_7&#39;] -&gt; [&#39;masked_fill&#39;]
    164/275: Constant [] -&gt; [&#39;alpha__3&#39;]
    165/275: Mul [&#39;mul_4&#39;, &#39;alpha__3&#39;] -&gt; [&#39;other_1__3&#39;]
    166/275: Add [&#39;mul_3&#39;, &#39;other_1__3&#39;] -&gt; [&#39;add_2&#39;]
    167/275: Constant [] -&gt; [&#39;alpha__4&#39;]
    168/275: Mul [&#39;mul_6&#39;, &#39;alpha__4&#39;] -&gt; [&#39;other_1__4&#39;]
    169/275: Add [&#39;mul_5&#39;, &#39;other_1__4&#39;] -&gt; [&#39;add_3&#39;]
    170/275: Constant [] -&gt; [&#39;aten_expand_509_size_1&#39;]
    171/275: Expand [&#39;add_2&#39;, &#39;aten_expand_509_size_1&#39;] -&gt; [&#39;expand_5&#39;]
    172/275: Transpose [&#39;add_3&#39;] -&gt; [&#39;transpose_4&#39;]
    173/275: Constant [] -&gt; [&#39;_val_395&#39;]
    174/275: Transpose [&#39;masked_fill&#39;] -&gt; [&#39;_val_396&#39;]
    175/275: Transpose [&#39;slice_6&#39;] -&gt; [&#39;_val_397&#39;]
    176/275: ScatterND [&#39;_val_397&#39;, &#39;_val_395&#39;, &#39;_val_396&#39;] -&gt; [&#39;_val_398&#39;]
    177/275: Transpose [&#39;_val_398&#39;] -&gt; [&#39;slice_scatter&#39;]
    178/275: Constant [] -&gt; [&#39;aten_expand_533_size_1&#39;]
    179/275: Expand [&#39;transpose_4&#39;, &#39;aten_expand_533_size_1&#39;] -&gt; [&#39;expand_6&#39;]
    180/275: Constant [] -&gt; [&#39;_val_418&#39;]
    181/275: Transpose [&#39;slice_scatter&#39;] -&gt; [&#39;_val_419&#39;]
    182/275: Transpose [&#39;slice_5&#39;] -&gt; [&#39;_val_420&#39;]
    183/275: ScatterND [&#39;_val_420&#39;, &#39;_val_418&#39;, &#39;_val_419&#39;] -&gt; [&#39;_val_421&#39;]
    184/275: Transpose [&#39;_val_421&#39;] -&gt; [&#39;slice_scatter_1&#39;]
    185/275: Constant [] -&gt; [&#39;aten_view_555_size_0&#39;]
    186/275: Reshape [&#39;expand_5&#39;, &#39;aten_view_555_size_0&#39;] -&gt; [&#39;view_13&#39;]
    187/275: Constant [] -&gt; [&#39;_val_441&#39;]
    188/275: ScatterND [&#39;expand_1&#39;, &#39;_val_441&#39;, &#39;slice_scatter_1&#39;] -&gt; [&#39;slice_scatter_2&#39;]
    189/275: Transpose [&#39;view_13&#39;] -&gt; [&#39;transpose_9&#39;]
    190/275: Constant [] -&gt; [&#39;aten_view_576_size_0&#39;]
    191/275: Reshape [&#39;expand_6&#39;, &#39;aten_view_576_size_0&#39;] -&gt; [&#39;view_14&#39;]
    192/275: Constant [] -&gt; [&#39;_val_449&#39;]
    193/275: Constant [] -&gt; [&#39;_val_453&#39;]
    194/275: Constant [] -&gt; [&#39;_val_457&#39;]
    195/275: Constant [] -&gt; [&#39;_val_461&#39;]
    196/275: Slice [&#39;slice_scatter_2&#39;, &#39;_val_449&#39;, &#39;_val_453&#39;, &#39;_val_457&#39;, &#39;_val_461&#39;] -&gt; [&#39;slice_31&#39;]
    197/275: MatMul [&#39;view_13&#39;, &#39;view_14&#39;] -&gt; [&#39;bmm_1&#39;]
    198/275: Transpose [&#39;view_14&#39;] -&gt; [&#39;transpose_10&#39;]
    199/275: Constant [] -&gt; [&#39;_val_468&#39;]
    200/275: Constant [] -&gt; [&#39;_val_472&#39;]
    201/275: Constant [] -&gt; [&#39;_val_476&#39;]
    202/275: Constant [] -&gt; [&#39;_val_480&#39;]
    203/275: Slice [&#39;slice_31&#39;, &#39;_val_468&#39;, &#39;_val_472&#39;, &#39;_val_476&#39;, &#39;_val_480&#39;] -&gt; [&#39;slice_32&#39;]
    204/275: Constant [] -&gt; [&#39;aten_view_614_size_0&#39;]
    205/275: Reshape [&#39;bmm_1&#39;, &#39;aten_view_614_size_0&#39;] -&gt; [&#39;view_15&#39;]
    206/275: Constant [] -&gt; [&#39;_val_487&#39;]
    207/275: Constant [] -&gt; [&#39;_val_491&#39;]
    208/275: Constant [] -&gt; [&#39;_val_495&#39;]
    209/275: Constant [] -&gt; [&#39;_val_499&#39;]
    210/275: Slice [&#39;slice_32&#39;, &#39;_val_487&#39;, &#39;_val_491&#39;, &#39;_val_495&#39;, &#39;_val_499&#39;] -&gt; [&#39;slice_33&#39;]
    211/275: Constant [] -&gt; [&#39;_val_501&#39;]
    212/275: Div [&#39;view_15&#39;, &#39;_val_501&#39;] -&gt; [&#39;div&#39;]
    213/275: Constant [] -&gt; [&#39;alpha__5&#39;]
    214/275: Mul [&#39;slice_33&#39;, &#39;alpha__5&#39;] -&gt; [&#39;other_1__5&#39;]
    215/275: Add [&#39;div&#39;, &#39;other_1__5&#39;] -&gt; [&#39;add_4&#39;]
    216/275: Softmax [&#39;add_4&#39;] -&gt; [&#39;_softmax&#39;]
    217/275: Constant [] -&gt; [&#39;aten_expand_640_size_1&#39;]
    218/275: Expand [&#39;_softmax&#39;, &#39;aten_expand_640_size_1&#39;] -&gt; [&#39;expand_7&#39;]
    219/275: Constant [] -&gt; [&#39;aten_view_643_size_0&#39;]
    220/275: Reshape [&#39;expand_7&#39;, &#39;aten_view_643_size_0&#39;] -&gt; [&#39;view_16&#39;]
    221/275: Identity [&#39;_softmax&#39;] -&gt; [&#39;detach_13&#39;]
    222/275: MatMul [&#39;view_16&#39;, &#39;view_17&#39;] -&gt; [&#39;bmm_2&#39;]
    223/275: Transpose [&#39;view_16&#39;] -&gt; [&#39;transpose_7&#39;]
    224/275: Constant [] -&gt; [&#39;aten_view_648_size_0&#39;]
    225/275: Reshape [&#39;bmm_2&#39;, &#39;aten_view_648_size_0&#39;] -&gt; [&#39;view_18&#39;]
    226/275: Transpose [&#39;view_18&#39;] -&gt; [&#39;transpose_5&#39;]
    227/275: Constant [] -&gt; [&#39;aten_view_652_size_0&#39;]
    228/275: Reshape [&#39;transpose_5&#39;, &#39;aten_view_652_size_0&#39;] -&gt; [&#39;view_19&#39;]
    229/275: Constant [] -&gt; [&#39;aten_view_654_size_0&#39;]
    230/275: Reshape [&#39;view_19&#39;, &#39;aten_view_654_size_0&#39;] -&gt; [&#39;view_20&#39;]
    231/275: MatMul [&#39;view_20&#39;, &#39;t_3&#39;] -&gt; [&#39;mm_3&#39;]
    232/275: Constant [] -&gt; [&#39;aten_view_657_size_0&#39;]
    233/275: Reshape [&#39;mm_3&#39;, &#39;aten_view_657_size_0&#39;] -&gt; [&#39;view_21&#39;]
    234/275: Constant [] -&gt; [&#39;alpha__6&#39;]
    235/275: Mul [&#39;view_21&#39;, &#39;alpha__6&#39;] -&gt; [&#39;other_1__6&#39;]
    236/275: Add [&#39;embedding&#39;, &#39;other_1__6&#39;] -&gt; [&#39;add_5&#39;]
    237/275: Constant [] -&gt; [&#39;scalar_tensor_default_2&#39;]
    238/275: Pow [&#39;add_5&#39;, &#39;scalar_tensor_default_2&#39;] -&gt; [&#39;pow_2&#39;]
    239/275: Constant [] -&gt; [&#39;_val_531&#39;]
    240/275: ReduceMean [&#39;pow_2&#39;, &#39;_val_531&#39;] -&gt; [&#39;mean_1&#39;]
    241/275: Constant [] -&gt; [&#39;aten_add_665_other_1&#39;]
    242/275: Add [&#39;mean_1&#39;, &#39;aten_add_665_other_1&#39;] -&gt; [&#39;add_6&#39;]
    243/275: Sqrt [&#39;add_6&#39;] -&gt; [&#39;aten_rsqrt_666_tmp&#39;]
    244/275: Reciprocal [&#39;aten_rsqrt_666_tmp&#39;] -&gt; [&#39;rsqrt_1&#39;]
    245/275: Mul [&#39;add_5&#39;, &#39;rsqrt_1&#39;] -&gt; [&#39;mul_7&#39;]
    246/275: Mul [&#39;primals_2&#39;, &#39;mul_7&#39;] -&gt; [&#39;mul_8&#39;]
    247/275: Constant [] -&gt; [&#39;aten_view_670_size_0&#39;]
    248/275: Reshape [&#39;mul_8&#39;, &#39;aten_view_670_size_0&#39;] -&gt; [&#39;view_22&#39;]
    249/275: MatMul [&#39;view_22&#39;, &#39;t_4&#39;] -&gt; [&#39;mm_4&#39;]
    250/275: MatMul [&#39;view_22&#39;, &#39;t_5&#39;] -&gt; [&#39;mm_5&#39;]
    251/275: Constant [] -&gt; [&#39;aten_view_674_size_0&#39;]
    252/275: Reshape [&#39;mm_4&#39;, &#39;aten_view_674_size_0&#39;] -&gt; [&#39;view_23&#39;]
    253/275: Constant [] -&gt; [&#39;aten_view_676_size_0&#39;]
    254/275: Reshape [&#39;mm_5&#39;, &#39;aten_view_676_size_0&#39;] -&gt; [&#39;view_25&#39;]
    255/275: Sigmoid [&#39;view_23&#39;] -&gt; [&#39;sigmoid&#39;]
    256/275: Mul [&#39;view_23&#39;, &#39;sigmoid&#39;] -&gt; [&#39;mul_9&#39;]
    257/275: Mul [&#39;mul_9&#39;, &#39;view_25&#39;] -&gt; [&#39;mul_10&#39;]
    258/275: Constant [] -&gt; [&#39;aten_view_681_size_0&#39;]
    259/275: Reshape [&#39;mul_10&#39;, &#39;aten_view_681_size_0&#39;] -&gt; [&#39;view_26&#39;]
    260/275: MatMul [&#39;view_26&#39;, &#39;t_6&#39;] -&gt; [&#39;mm_6&#39;]
    261/275: Constant [] -&gt; [&#39;aten_view_684_size_0&#39;]
    262/275: Reshape [&#39;mm_6&#39;, &#39;aten_view_684_size_0&#39;] -&gt; [&#39;view_27&#39;]
    263/275: Constant [] -&gt; [&#39;alpha__7&#39;]
    264/275: Mul [&#39;view_27&#39;, &#39;alpha__7&#39;] -&gt; [&#39;other_1__7&#39;]
    265/275: Add [&#39;add_5&#39;, &#39;other_1__7&#39;] -&gt; [&#39;add_7&#39;]
    266/275: Constant [] -&gt; [&#39;scalar_tensor_default_3&#39;]
    267/275: Pow [&#39;add_7&#39;, &#39;scalar_tensor_default_3&#39;] -&gt; [&#39;pow_3&#39;]
    268/275: Constant [] -&gt; [&#39;_val_558&#39;]
    269/275: ReduceMean [&#39;pow_3&#39;, &#39;_val_558&#39;] -&gt; [&#39;mean_2&#39;]
    270/275: Constant [] -&gt; [&#39;aten_add_692_other_1&#39;]
    271/275: Add [&#39;mean_2&#39;, &#39;aten_add_692_other_1&#39;] -&gt; [&#39;add_8&#39;]
    272/275: Sqrt [&#39;add_8&#39;] -&gt; [&#39;aten_rsqrt_693_tmp&#39;]
    273/275: Reciprocal [&#39;aten_rsqrt_693_tmp&#39;] -&gt; [&#39;rsqrt_2&#39;]
    274/275: Mul [&#39;add_7&#39;, &#39;rsqrt_2&#39;] -&gt; [&#39;mul_11&#39;]
    275/275: Mul [&#39;primals_3&#39;, &#39;mul_11&#39;] -&gt; [&#39;mul_12&#39;]
    [runpythonerror]
    /home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/exporter.py:137: UserWarning: torch.onnx.dynamo_export only implements opset version 18 for now. If you need to use a different opset version, please register them with register_custom_op.
      warnings.warn(
    2024-05-23 13:23:19,503 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue return_val due to large size 4194304.
    2024-05-23 13:23:19,503 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue full due to large size 4194304.
    2024-05-23 13:23:19,594 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue triu due to large size 4194304.
    2024-05-23 13:23:19,705 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue convert_element_type_default due to large size 4194304.
    2024-05-23 13:23:19,714 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue mul due to large size 4194304.
    2024-05-23 13:23:19,747 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue return_val due to large size 4194304.
    2024-05-23 13:23:19,748 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue unsqueeze_3 due to large size 4194304.
    2024-05-23 13:23:19,758 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue return_val due to large size 4194304.
    2024-05-23 13:23:19,758 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue unsqueeze_4 due to large size 4194304.
    2024-05-23 13:23:19,786 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue slice_3 due to large size 4194304.
    2024-05-23 13:23:19,805 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue slice_4 due to large size 4194304.
    2024-05-23 13:23:19,818 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue return_val due to large size 8388608.
    2024-05-23 13:23:19,818 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue expand_1 due to large size 8388608.
    2024-05-23 13:23:19,832 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue clone due to large size 8388608.
    2024-05-23 13:23:19,850 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue slice_5 due to large size 8388608.
    2024-05-23 13:23:19,865 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue slice_6 due to large size 8388608.
    2024-05-23 13:23:19,944 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue slice_7 due to large size 8388608.
    2024-05-23 13:23:19,980 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue _val_397 due to large size 8388608.
    2024-05-23 13:23:19,999 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue _val_420 due to large size 8388608.
    2024-05-23 13:23:20,624 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue return_val due to large size 4194304.
    2024-05-23 13:23:20,625 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue full due to large size 4194304.
    2024-05-23 13:23:20,634 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue triu due to large size 4194304.
    2024-05-23 13:23:20,650 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue convert_element_type_default due to large size 4194304.
    2024-05-23 13:23:20,654 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue mul due to large size 4194304.
    2024-05-23 13:23:20,661 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue unsqueeze_3 due to large size 4194304.
    2024-05-23 13:23:20,663 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue unsqueeze_4 due to large size 4194304.
    2024-05-23 13:23:20,666 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue slice_3 due to large size 4194304.
    2024-05-23 13:23:20,670 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue slice_4 due to large size 4194304.
    2024-05-23 13:23:20,674 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue expand_1 due to large size 8388608.
    2024-05-23 13:23:20,682 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue slice_5 due to large size 8388608.
    2024-05-23 13:23:20,686 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue slice_6 due to large size 8388608.
    2024-05-23 13:23:20,700 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue slice_7 due to large size 8388608.
    2024-05-23 13:23:20,714 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue _val_397 due to large size 8388608.
    2024-05-23 13:23:20,719 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue _val_420 due to large size 8388608.
    [0;93m2024-05-23 13:23:21.133425400 [W:onnxruntime:, graph.cc:4051 CleanUnusedInitializersAndNodeArgs] Removing initializer &#39;_val_23&#39;. It is not used by any node and should be removed from the model.[m
    [0;93m2024-05-23 13:23:21.133562300 [W:onnxruntime:, graph.cc:4051 CleanUnusedInitializersAndNodeArgs] Removing initializer &#39;_val_22&#39;. It is not used by any node and should be removed from the model.[m
</pre></div>
</div>
</section>
<section id="with-the-custom-exporter">
<h3>With the custom exporter<a class="headerlink" href="#with-the-custom-exporter" title="Link to this heading">¶</a></h3>
<p>&lt;&lt;&lt;</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">onnx</span>

<span class="c1"># from onnx_array_api.plotting.text_plot import onnx_simple_text_plot</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.onnx</span>
<span class="kn">from</span> <span class="nn">experimental_experiment.torch_models.training_helper</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">make_aot_ort</span><span class="p">,</span>
    <span class="n">train_loop</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">experimental_experiment.torch_models.dump_helper</span> <span class="kn">import</span> <span class="n">dump_onnx</span>

<span class="c1"># from experimental_experiment.torch_interpreter import to_onnx</span>

<span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
    <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">LlamaConfig</span>
    <span class="kn">from</span> <span class="nn">transformers.models.llama.modeling_llama</span> <span class="kn">import</span> <span class="n">LlamaModel</span>


<span class="k">def</span> <span class="nf">ids_tensor</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">):</span>
    <span class="n">total_dims</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="n">shape</span><span class="p">:</span>
        <span class="n">total_dims</span> <span class="o">*=</span> <span class="n">dim</span>

    <span class="n">values</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">total_dims</span><span class="p">):</span>
        <span class="n">values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">vocab_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>


<span class="n">config</span> <span class="o">=</span> <span class="n">LlamaConfig</span><span class="p">(</span>
    <span class="n">hidden_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">num_hidden_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">vocab_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
    <span class="n">intermediate_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">max_position_embeddings</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
    <span class="n">num_attention_heads</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">config</span><span class="o">.</span><span class="n">_attn_implementation</span> <span class="o">=</span> <span class="s2">&quot;eager&quot;</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">LlamaModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

<span class="n">batch</span><span class="p">,</span> <span class="n">seq</span><span class="p">,</span> <span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span>

<span class="n">input_ids</span> <span class="o">=</span> <span class="n">ids_tensor</span><span class="p">([</span><span class="n">batch</span><span class="p">,</span> <span class="n">seq</span><span class="p">],</span> <span class="n">vocab_size</span><span class="p">)</span>
<span class="n">input_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tril</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">seq</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

<span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">input_mask</span><span class="p">)</span>

<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;ONNXRT_CHANGE_REWRITER&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;1&quot;</span>

<span class="n">local_aot_ort</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">make_aot_ort</span><span class="p">(</span>
    <span class="n">dynamic</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>

<span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
    <span class="n">optimized_mod</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="n">local_aot_ort</span><span class="p">,</span> <span class="n">fullgraph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">dump_onnx</span><span class="p">(</span><span class="s2">&quot;dort-llama-ort&quot;</span><span class="p">,</span> <span class="n">folder</span><span class="o">=</span><span class="s2">&quot;dump_llama&quot;</span><span class="p">,</span> <span class="n">clean</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="n">train_loop</span><span class="p">(</span><span class="n">optimized_mod</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">input_mask</span><span class="p">)</span>

<span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="n">_</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s2">&quot;dump_llama&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">_</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.onnx&quot;</span><span class="p">)]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------------------------&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;exported model: </span><span class="si">{</span><span class="n">names</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">names</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;NODES in </span><span class="si">{name!r}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">onx</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">&quot;dump_llama&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">node</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">onx</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">onx</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="p">)</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">node</span><span class="o">.</span><span class="n">op_type</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="si">}</span><span class="s2"> -&gt; </span><span class="si">{</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;ONNXRT_CHANGE_REWRITER&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;0&quot;</span>
</pre></div>
</div>
<p>&gt;&gt;&gt;</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    [2024-05-23 13:23:47,366] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
    Applied 1 of general pattern rewrite rules.
    Applied 0 of general pattern rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific pattern rewrite rules.
    Applied 0 of general pattern rewrite rules.
    Applied 0 of general pattern rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific function rewrite rules.
    Applied 0 of onnxruntime specific pattern rewrite rules.
    ------------------------------------------
    exported model: [&#39;dort-llama-ort_1.onnx&#39;, &#39;dort-llama-ort_0.onnx&#39;]
    
    NODES in {name!r}
    1/305: Sin [&#39;cat&#39;] -&gt; [&#39;sin&#39;]
    2/305: Constant [] -&gt; [&#39;_val_34&#39;]
    3/305: Equal [&#39;primals_13&#39;, &#39;_val_34&#39;] -&gt; [&#39;eq_1&#39;]
    4/305: Cos [&#39;cat&#39;] -&gt; [&#39;cos&#39;]
    5/305: Constant [] -&gt; [&#39;_val_38&#39;]
    6/305: Pow [&#39;add_7&#39;, &#39;_val_38&#39;] -&gt; [&#39;pow_5&#39;]
    7/305: Constant [] -&gt; [&#39;aten_view_118_size_0&#39;]
    8/305: Reshape [&#39;mm_4&#39;, &#39;aten_view_118_size_0&#39;] -&gt; [&#39;view_23&#39;]
    9/305: Constant [] -&gt; [&#39;aten_view_120_size_0&#39;]
    10/305: Reshape [&#39;mm_5&#39;, &#39;aten_view_120_size_0&#39;] -&gt; [&#39;view_25&#39;]
    11/305: Constant [] -&gt; [&#39;aten_view_125_size_0&#39;]
    12/305: Reshape [&#39;mm_3&#39;, &#39;aten_view_125_size_0&#39;] -&gt; [&#39;view_21&#39;]
    13/305: Mul [&#39;embedding&#39;, &#39;rsqrt&#39;] -&gt; [&#39;mul_1&#39;]
    14/305: Mul [&#39;tangents_1&#39;, &#39;primals_3&#39;] -&gt; [&#39;mul_13&#39;]
    15/305: Mul [&#39;add_7&#39;, &#39;rsqrt_2&#39;] -&gt; [&#39;mul_11&#39;]
    16/305: Constant [] -&gt; [&#39;_val_54&#39;]
    17/305: Pow [&#39;embedding&#39;, &#39;_val_54&#39;] -&gt; [&#39;pow_9&#39;]
    18/305: Constant [] -&gt; [&#39;aten_unsqueeze_133_dim_0&#39;]
    19/305: Unsqueeze [&#39;sin&#39;, &#39;aten_unsqueeze_133_dim_0&#39;] -&gt; [&#39;unsqueeze_11&#39;]
    20/305: Constant [] -&gt; [&#39;aten_unsqueeze_134_dim_0&#39;]
    21/305: Unsqueeze [&#39;eq_1&#39;, &#39;aten_unsqueeze_134_dim_0&#39;] -&gt; [&#39;unsqueeze_12&#39;]
    22/305: Constant [] -&gt; [&#39;aten_unsqueeze_136_dim_0&#39;]
    23/305: Unsqueeze [&#39;cos&#39;, &#39;aten_unsqueeze_136_dim_0&#39;] -&gt; [&#39;unsqueeze_10&#39;]
    24/305: Constant [] -&gt; [&#39;_val_60&#39;]
    25/305: Mul [&#39;pow_5&#39;, &#39;_val_60&#39;] -&gt; [&#39;mul_19&#39;]
    26/305: Mul [&#39;view_23&#39;, &#39;sigmoid&#39;] -&gt; [&#39;mul_9&#39;]
    27/305: Constant [] -&gt; [&#39;fill&#39;]
    28/305: Constant [] -&gt; [&#39;alpha__1&#39;]
    29/305: Mul [&#39;view_21&#39;, &#39;alpha__1&#39;] -&gt; [&#39;other_1__1&#39;]
    30/305: Add [&#39;embedding&#39;, &#39;other_1__1&#39;] -&gt; [&#39;add_5&#39;]
    31/305: Mul [&#39;mul_13&#39;, &#39;add_7&#39;] -&gt; [&#39;mul_15&#39;]
    32/305: Mul [&#39;mul_13&#39;, &#39;rsqrt_2&#39;] -&gt; [&#39;mul_16&#39;]
    33/305: Mul [&#39;tangents_1&#39;, &#39;mul_11&#39;] -&gt; [&#39;mul_14&#39;]
    34/305: Constant [] -&gt; [&#39;_val_71&#39;]
    35/305: Mul [&#39;pow_9&#39;, &#39;_val_71&#39;] -&gt; [&#39;mul_46&#39;]
    36/305: Constant [] -&gt; [&#39;alpha__2&#39;]
    37/305: Mul [&#39;sigmoid&#39;, &#39;alpha__2&#39;] -&gt; [&#39;other_1__2&#39;]
    38/305: Sub [&#39;fill&#39;, &#39;other_1__2&#39;] -&gt; [&#39;sub&#39;]
    39/305: Mul [&#39;add_5&#39;, &#39;rsqrt_1&#39;] -&gt; [&#39;mul_7&#39;]
    40/305: Constant [] -&gt; [&#39;_val_76&#39;]
    41/305: Pow [&#39;add_5&#39;, &#39;_val_76&#39;] -&gt; [&#39;pow_7&#39;]
    42/305: Constant [] -&gt; [&#39;_val_80&#39;]
    43/305: ReduceSum [&#39;mul_15&#39;, &#39;_val_80&#39;] -&gt; [&#39;sum_2&#39;]
    44/305: Constant [] -&gt; [&#39;_val_82&#39;]
    45/305: ReduceSum [&#39;mul_14&#39;, &#39;_val_82&#39;] -&gt; [&#39;sum_1&#39;]
    46/305: Mul [&#39;view_23&#39;, &#39;sub&#39;] -&gt; [&#39;mul_23&#39;]
    47/305: Constant [] -&gt; [&#39;_val_86&#39;]
    48/305: Mul [&#39;pow_7&#39;, &#39;_val_86&#39;] -&gt; [&#39;mul_32&#39;]
    49/305: Constant [] -&gt; [&#39;_val_90&#39;]
    50/305: Mul [&#39;sum_2&#39;, &#39;_val_90&#39;] -&gt; [&#39;mul_17&#39;]
    51/305: Constant [] -&gt; [&#39;aten_view_170_size_0&#39;]
    52/305: Reshape [&#39;sum_1&#39;, &#39;aten_view_170_size_0&#39;] -&gt; [&#39;view_28&#39;]
    53/305: Constant [] -&gt; [&#39;scalar_tensor_default&#39;]
    54/305: Pow [&#39;rsqrt_2&#39;, &#39;scalar_tensor_default&#39;] -&gt; [&#39;pow_4&#39;]
    55/305: Constant [] -&gt; [&#39;aten_add_176_other_1&#39;]
    56/305: Add [&#39;mul_23&#39;, &#39;aten_add_176_other_1&#39;] -&gt; [&#39;add_10&#39;]
    57/305: Constant [] -&gt; [&#39;scalar_tensor_default_2&#39;]
    58/305: Pow [&#39;rsqrt_1&#39;, &#39;scalar_tensor_default_2&#39;] -&gt; [&#39;pow_6&#39;]
    59/305: Constant [] -&gt; [&#39;scalar_tensor_default_3&#39;]
    60/305: Pow [&#39;rsqrt&#39;, &#39;scalar_tensor_default_3&#39;] -&gt; [&#39;pow_8&#39;]
    61/305: Mul [&#39;mul_17&#39;, &#39;pow_4&#39;] -&gt; [&#39;mul_18&#39;]
    62/305: Mul [&#39;sigmoid&#39;, &#39;add_10&#39;] -&gt; [&#39;mul_24&#39;]
    63/305: Constant [] -&gt; [&#39;aten_expand_186_size_1&#39;]
    64/305: Expand [&#39;mul_18&#39;, &#39;aten_expand_186_size_1&#39;] -&gt; [&#39;expand_9&#39;]
    65/305: Constant [] -&gt; [&#39;scalar_tensor_default_4&#39;]
    66/305: Div [&#39;expand_9&#39;, &#39;scalar_tensor_default_4&#39;] -&gt; [&#39;div_1&#39;]
    67/305: Mul [&#39;div_1&#39;, &#39;mul_19&#39;] -&gt; [&#39;mul_20&#39;]
    68/305: Constant [] -&gt; [&#39;alpha__3&#39;]
    69/305: Mul [&#39;mul_20&#39;, &#39;alpha__3&#39;] -&gt; [&#39;other_1__3&#39;]
    70/305: Add [&#39;mul_16&#39;, &#39;other_1__3&#39;] -&gt; [&#39;add_9&#39;]
    71/305: Constant [] -&gt; [&#39;aten_view_193_size_0&#39;]
    72/305: Reshape [&#39;add_9&#39;, &#39;aten_view_193_size_0&#39;] -&gt; [&#39;view_29&#39;]
    73/305: Transpose [&#39;view_29&#39;] -&gt; [&#39;t_7&#39;]
    74/305: MatMul [&#39;view_29&#39;, &#39;t_9&#39;] -&gt; [&#39;mm_8&#39;]
    75/305: MatMul [&#39;t_7&#39;, &#39;view_26&#39;] -&gt; [&#39;mm_7&#39;]
    76/305: Constant [] -&gt; [&#39;aten_view_198_size_0&#39;]
    77/305: Reshape [&#39;mm_8&#39;, &#39;aten_view_198_size_0&#39;] -&gt; [&#39;view_30&#39;]
    78/305: Transpose [&#39;mm_7&#39;] -&gt; [&#39;t_8&#39;]
    79/305: Mul [&#39;view_30&#39;, &#39;mul_9&#39;] -&gt; [&#39;mul_21&#39;]
    80/305: Mul [&#39;view_30&#39;, &#39;view_25&#39;] -&gt; [&#39;mul_22&#39;]
    81/305: Transpose [&#39;t_8&#39;] -&gt; [&#39;t_10&#39;]
    82/305: Constant [] -&gt; [&#39;aten_view_204_size_0&#39;]
    83/305: Reshape [&#39;mul_21&#39;, &#39;aten_view_204_size_0&#39;] -&gt; [&#39;view_31&#39;]
    84/305: Mul [&#39;mul_22&#39;, &#39;mul_24&#39;] -&gt; [&#39;mul_25&#39;]
    85/305: Transpose [&#39;view_31&#39;] -&gt; [&#39;t_11&#39;]
    86/305: MatMul [&#39;view_31&#39;, &#39;t_13&#39;] -&gt; [&#39;mm_10&#39;]
    87/305: Constant [] -&gt; [&#39;aten_view_209_size_0&#39;]
    88/305: Reshape [&#39;mul_25&#39;, &#39;aten_view_209_size_0&#39;] -&gt; [&#39;view_33&#39;]
    89/305: MatMul [&#39;t_11&#39;, &#39;view_22&#39;] -&gt; [&#39;mm_9&#39;]
    90/305: Constant [] -&gt; [&#39;aten_view_212_size_0&#39;]
    91/305: Reshape [&#39;mm_10&#39;, &#39;aten_view_212_size_0&#39;] -&gt; [&#39;view_32&#39;]
    92/305: Transpose [&#39;view_33&#39;] -&gt; [&#39;t_15&#39;]
    93/305: MatMul [&#39;view_33&#39;, &#39;t_17&#39;] -&gt; [&#39;mm_12&#39;]
    94/305: Transpose [&#39;mm_9&#39;] -&gt; [&#39;t_12&#39;]
    95/305: MatMul [&#39;t_15&#39;, &#39;view_22&#39;] -&gt; [&#39;mm_11&#39;]
    96/305: Constant [] -&gt; [&#39;aten_view_218_size_0&#39;]
    97/305: Reshape [&#39;mm_12&#39;, &#39;aten_view_218_size_0&#39;] -&gt; [&#39;view_34&#39;]
    98/305: Transpose [&#39;t_12&#39;] -&gt; [&#39;t_14&#39;]
    99/305: Transpose [&#39;mm_11&#39;] -&gt; [&#39;t_16&#39;]
    100/305: Constant [] -&gt; [&#39;alpha__4&#39;]
    101/305: Mul [&#39;view_34&#39;, &#39;alpha__4&#39;] -&gt; [&#39;other_1__4&#39;]
    102/305: Add [&#39;view_32&#39;, &#39;other_1__4&#39;] -&gt; [&#39;add_11&#39;]
    103/305: Transpose [&#39;t_16&#39;] -&gt; [&#39;t_18&#39;]
    104/305: Mul [&#39;add_11&#39;, &#39;primals_2&#39;] -&gt; [&#39;mul_26&#39;]
    105/305: Mul [&#39;add_11&#39;, &#39;mul_7&#39;] -&gt; [&#39;mul_27&#39;]
    106/305: Mul [&#39;mul_26&#39;, &#39;add_5&#39;] -&gt; [&#39;mul_28&#39;]
    107/305: Mul [&#39;mul_26&#39;, &#39;rsqrt_1&#39;] -&gt; [&#39;mul_29&#39;]
    108/305: Constant [] -&gt; [&#39;_val_150&#39;]
    109/305: ReduceSum [&#39;mul_27&#39;, &#39;_val_150&#39;] -&gt; [&#39;sum_3&#39;]
    110/305: Constant [] -&gt; [&#39;_val_152&#39;]
    111/305: ReduceSum [&#39;mul_28&#39;, &#39;_val_152&#39;] -&gt; [&#39;sum_4&#39;]
    112/305: Constant [] -&gt; [&#39;alpha__5&#39;]
    113/305: Mul [&#39;mul_29&#39;, &#39;alpha__5&#39;] -&gt; [&#39;other_1__5&#39;]
    114/305: Add [&#39;add_9&#39;, &#39;other_1__5&#39;] -&gt; [&#39;add_12&#39;]
    115/305: Constant [] -&gt; [&#39;aten_view_233_size_0&#39;]
    116/305: Reshape [&#39;sum_3&#39;, &#39;aten_view_233_size_0&#39;] -&gt; [&#39;view_35&#39;]
    117/305: Constant [] -&gt; [&#39;_val_157&#39;]
    118/305: Mul [&#39;sum_4&#39;, &#39;_val_157&#39;] -&gt; [&#39;mul_30&#39;]
    119/305: Mul [&#39;mul_30&#39;, &#39;pow_6&#39;] -&gt; [&#39;mul_31&#39;]
    120/305: Constant [] -&gt; [&#39;aten_expand_238_size_1&#39;]
    121/305: Expand [&#39;mul_31&#39;, &#39;aten_expand_238_size_1&#39;] -&gt; [&#39;expand_10&#39;]
    122/305: Constant [] -&gt; [&#39;scalar_tensor_default_5&#39;]
    123/305: Div [&#39;expand_10&#39;, &#39;scalar_tensor_default_5&#39;] -&gt; [&#39;div_2&#39;]
    124/305: Mul [&#39;div_2&#39;, &#39;mul_32&#39;] -&gt; [&#39;mul_33&#39;]
    125/305: Constant [] -&gt; [&#39;alpha__6&#39;]
    126/305: Mul [&#39;mul_33&#39;, &#39;alpha__6&#39;] -&gt; [&#39;other_1__6&#39;]
    127/305: Add [&#39;add_12&#39;, &#39;other_1__6&#39;] -&gt; [&#39;add_13&#39;]
    128/305: Constant [] -&gt; [&#39;aten_view_245_size_0&#39;]
    129/305: Reshape [&#39;add_13&#39;, &#39;aten_view_245_size_0&#39;] -&gt; [&#39;view_36&#39;]
    130/305: Transpose [&#39;view_36&#39;] -&gt; [&#39;t_19&#39;]
    131/305: MatMul [&#39;view_36&#39;, &#39;t_21&#39;] -&gt; [&#39;mm_14&#39;]
    132/305: MatMul [&#39;t_19&#39;, &#39;view_20&#39;] -&gt; [&#39;mm_13&#39;]
    133/305: Constant [] -&gt; [&#39;aten_view_250_size_0&#39;]
    134/305: Reshape [&#39;mm_14&#39;, &#39;aten_view_250_size_0&#39;] -&gt; [&#39;view_37&#39;]
    135/305: Transpose [&#39;mm_13&#39;] -&gt; [&#39;t_20&#39;]
    136/305: Constant [] -&gt; [&#39;aten_view_253_size_0&#39;]
    137/305: Reshape [&#39;view_37&#39;, &#39;aten_view_253_size_0&#39;] -&gt; [&#39;view_38&#39;]
    138/305: Transpose [&#39;t_20&#39;] -&gt; [&#39;t_22&#39;]
    139/305: Transpose [&#39;view_38&#39;] -&gt; [&#39;transpose_6&#39;]
    140/305: Constant [] -&gt; [&#39;aten_view_258_size_0&#39;]
    141/305: Reshape [&#39;transpose_6&#39;, &#39;aten_view_258_size_0&#39;] -&gt; [&#39;view_39&#39;]
    142/305: MatMul [&#39;transpose_7&#39;, &#39;view_39&#39;] -&gt; [&#39;bmm_3&#39;]
    143/305: MatMul [&#39;view_39&#39;, &#39;transpose_8&#39;] -&gt; [&#39;bmm_4&#39;]
    144/305: Constant [] -&gt; [&#39;aten_view_262_size_0&#39;]
    145/305: Reshape [&#39;bmm_3&#39;, &#39;aten_view_262_size_0&#39;] -&gt; [&#39;view_40&#39;]
    146/305: Constant [] -&gt; [&#39;aten_view_264_size_0&#39;]
    147/305: Reshape [&#39;bmm_4&#39;, &#39;aten_view_264_size_0&#39;] -&gt; [&#39;view_41&#39;]
    148/305: Constant [] -&gt; [&#39;alpha__7&#39;]
    149/305: Mul [&#39;view_40&#39;, &#39;alpha__7&#39;] -&gt; [&#39;other_1__7&#39;]
    150/305: Add [&#39;tangents_3&#39;, &#39;other_1__7&#39;] -&gt; [&#39;add_14&#39;]
    151/305: Mul [&#39;view_41&#39;, &#39;detach_13&#39;] -&gt; [&#39;mul_34&#39;]
    152/305: Transpose [&#39;add_14&#39;] -&gt; [&#39;transpose_12&#39;]
    153/305: Constant [] -&gt; [&#39;_val_191&#39;]
    154/305: ReduceSum [&#39;mul_34&#39;, &#39;_val_191&#39;] -&gt; [&#39;sum_5&#39;]
    155/305: Mul [&#39;detach_13&#39;, &#39;sum_5&#39;] -&gt; [&#39;mul_35&#39;]
    156/305: Constant [] -&gt; [&#39;aten_view_273_size_0&#39;]
    157/305: Reshape [&#39;transpose_12&#39;, &#39;aten_view_273_size_0&#39;] -&gt; [&#39;view_45&#39;]
    158/305: Constant [] -&gt; [&#39;alpha__8&#39;]
    159/305: Mul [&#39;mul_35&#39;, &#39;alpha__8&#39;] -&gt; [&#39;other_1__8&#39;]
    160/305: Sub [&#39;mul_34&#39;, &#39;other_1__8&#39;] -&gt; [&#39;sub_1&#39;]
    161/305: Constant [] -&gt; [&#39;aten_view_276_size_0&#39;]
    162/305: Reshape [&#39;view_45&#39;, &#39;aten_view_276_size_0&#39;] -&gt; [&#39;view_48&#39;]
    163/305: Constant [] -&gt; [&#39;_val_200&#39;]
    164/305: Div [&#39;sub_1&#39;, &#39;_val_200&#39;] -&gt; [&#39;div_3&#39;]
    165/305: Transpose [&#39;view_48&#39;] -&gt; [&#39;t_23&#39;]
    166/305: MatMul [&#39;view_48&#39;, &#39;t_25&#39;] -&gt; [&#39;mm_16&#39;]
    167/305: Constant [] -&gt; [&#39;aten_view_282_size_0&#39;]
    168/305: Reshape [&#39;div_3&#39;, &#39;aten_view_282_size_0&#39;] -&gt; [&#39;view_42&#39;]
    169/305: MatMul [&#39;t_23&#39;, &#39;view_1&#39;] -&gt; [&#39;mm_15&#39;]
    170/305: Constant [] -&gt; [&#39;aten_view_285_size_0&#39;]
    171/305: Reshape [&#39;mm_16&#39;, &#39;aten_view_285_size_0&#39;] -&gt; [&#39;view_49&#39;]
    172/305: MatMul [&#39;transpose_9&#39;, &#39;view_42&#39;] -&gt; [&#39;bmm_5&#39;]
    173/305: MatMul [&#39;view_42&#39;, &#39;transpose_10&#39;] -&gt; [&#39;bmm_6&#39;]
    174/305: Transpose [&#39;mm_15&#39;] -&gt; [&#39;t_24&#39;]
    175/305: Constant [] -&gt; [&#39;aten_view_290_size_0&#39;]
    176/305: Reshape [&#39;bmm_5&#39;, &#39;aten_view_290_size_0&#39;] -&gt; [&#39;view_43&#39;]
    177/305: Constant [] -&gt; [&#39;aten_view_292_size_0&#39;]
    178/305: Reshape [&#39;bmm_6&#39;, &#39;aten_view_292_size_0&#39;] -&gt; [&#39;view_44&#39;]
    179/305: Transpose [&#39;t_24&#39;] -&gt; [&#39;t_26&#39;]
    180/305: Transpose [&#39;view_43&#39;] -&gt; [&#39;transpose_11&#39;]
    181/305: Mul [&#39;view_44&#39;, &#39;unsqueeze_11&#39;] -&gt; [&#39;mul_38&#39;]
    182/305: Mul [&#39;view_44&#39;, &#39;unsqueeze_10&#39;] -&gt; [&#39;mul_39&#39;]
    183/305: Constant [] -&gt; [&#39;alpha__9&#39;]
    184/305: Mul [&#39;transpose_11&#39;, &#39;alpha__9&#39;] -&gt; [&#39;other_1__9&#39;]
    185/305: Add [&#39;tangents_2&#39;, &#39;other_1__9&#39;] -&gt; [&#39;add_15&#39;]
    186/305: Constant [] -&gt; [&#39;_val_224&#39;]
    187/305: Constant [] -&gt; [&#39;_val_228&#39;]
    188/305: Constant [] -&gt; [&#39;_val_232&#39;]
    189/305: Constant [] -&gt; [&#39;_val_236&#39;]
    190/305: Slice [&#39;mul_38&#39;, &#39;_val_224&#39;, &#39;_val_228&#39;, &#39;_val_232&#39;, &#39;_val_236&#39;] -&gt; [&#39;slice_36&#39;]
    191/305: Constant [] -&gt; [&#39;_val_241&#39;]
    192/305: Constant [] -&gt; [&#39;_val_245&#39;]
    193/305: Constant [] -&gt; [&#39;_val_249&#39;]
    194/305: Constant [] -&gt; [&#39;_val_253&#39;]
    195/305: Slice [&#39;mul_38&#39;, &#39;_val_241&#39;, &#39;_val_245&#39;, &#39;_val_249&#39;, &#39;_val_253&#39;] -&gt; [&#39;slice_37&#39;]
    196/305: Mul [&#39;add_15&#39;, &#39;unsqueeze_11&#39;] -&gt; [&#39;mul_36&#39;]
    197/305: Mul [&#39;add_15&#39;, &#39;unsqueeze_10&#39;] -&gt; [&#39;mul_37&#39;]
    198/305: Neg [&#39;slice_36&#39;] -&gt; [&#39;neg_3&#39;]
    199/305: Constant [] -&gt; [&#39;_val_263&#39;]
    200/305: Constant [] -&gt; [&#39;_val_267&#39;]
    201/305: Constant [] -&gt; [&#39;_val_271&#39;]
    202/305: Constant [] -&gt; [&#39;_val_275&#39;]
    203/305: Slice [&#39;mul_36&#39;, &#39;_val_263&#39;, &#39;_val_267&#39;, &#39;_val_271&#39;, &#39;_val_275&#39;] -&gt; [&#39;slice_34&#39;]
    204/305: Constant [] -&gt; [&#39;_val_280&#39;]
    205/305: Constant [] -&gt; [&#39;_val_284&#39;]
    206/305: Constant [] -&gt; [&#39;_val_288&#39;]
    207/305: Constant [] -&gt; [&#39;_val_292&#39;]
    208/305: Slice [&#39;mul_36&#39;, &#39;_val_280&#39;, &#39;_val_284&#39;, &#39;_val_288&#39;, &#39;_val_292&#39;] -&gt; [&#39;slice_35&#39;]
    209/305: Constant [] -&gt; [&#39;_val_311&#39;]
    210/305: Transpose [&#39;slice_37&#39;] -&gt; [&#39;_val_312&#39;]
    211/305: Constant [] -&gt; [&#39;_val_313&#39;]
    212/305: ScatterND [&#39;_val_313&#39;, &#39;_val_311&#39;, &#39;_val_312&#39;] -&gt; [&#39;_val_314&#39;]
    213/305: Transpose [&#39;_val_314&#39;] -&gt; [&#39;slice_scatter_6&#39;]
    214/305: Neg [&#39;slice_34&#39;] -&gt; [&#39;neg_2&#39;]
    215/305: Constant [] -&gt; [&#39;_val_334&#39;]
    216/305: Transpose [&#39;neg_3&#39;] -&gt; [&#39;_val_335&#39;]
    217/305: Constant [] -&gt; [&#39;_val_336&#39;]
    218/305: ScatterND [&#39;_val_336&#39;, &#39;_val_334&#39;, &#39;_val_335&#39;] -&gt; [&#39;_val_337&#39;]
    219/305: Transpose [&#39;_val_337&#39;] -&gt; [&#39;slice_scatter_5&#39;]
    220/305: Constant [] -&gt; [&#39;_val_356&#39;]
    221/305: Transpose [&#39;slice_35&#39;] -&gt; [&#39;_val_357&#39;]
    222/305: Constant [] -&gt; [&#39;_val_358&#39;]
    223/305: ScatterND [&#39;_val_358&#39;, &#39;_val_356&#39;, &#39;_val_357&#39;] -&gt; [&#39;_val_359&#39;]
    224/305: Transpose [&#39;_val_359&#39;] -&gt; [&#39;slice_scatter_4&#39;]
    225/305: Constant [] -&gt; [&#39;alpha__10&#39;]
    226/305: Mul [&#39;slice_scatter_6&#39;, &#39;alpha__10&#39;] -&gt; [&#39;other_1__10&#39;]
    227/305: Add [&#39;slice_scatter_5&#39;, &#39;other_1__10&#39;] -&gt; [&#39;add_18&#39;]
    228/305: Constant [] -&gt; [&#39;_val_377&#39;]
    229/305: Transpose [&#39;neg_2&#39;] -&gt; [&#39;_val_378&#39;]
    230/305: Constant [] -&gt; [&#39;_val_379&#39;]
    231/305: ScatterND [&#39;_val_379&#39;, &#39;_val_377&#39;, &#39;_val_378&#39;] -&gt; [&#39;_val_380&#39;]
    232/305: Transpose [&#39;_val_380&#39;] -&gt; [&#39;slice_scatter_3&#39;]
    233/305: Constant [] -&gt; [&#39;alpha__11&#39;]
    234/305: Mul [&#39;mul_39&#39;, &#39;alpha__11&#39;] -&gt; [&#39;other_1__11&#39;]
    235/305: Add [&#39;add_18&#39;, &#39;other_1__11&#39;] -&gt; [&#39;add_19&#39;]
    236/305: Constant [] -&gt; [&#39;alpha__12&#39;]
    237/305: Mul [&#39;slice_scatter_4&#39;, &#39;alpha__12&#39;] -&gt; [&#39;other_1__12&#39;]
    238/305: Add [&#39;slice_scatter_3&#39;, &#39;other_1__12&#39;] -&gt; [&#39;add_16&#39;]
    239/305: Transpose [&#39;add_19&#39;] -&gt; [&#39;transpose_14&#39;]
    240/305: Constant [] -&gt; [&#39;alpha__13&#39;]
    241/305: Mul [&#39;mul_37&#39;, &#39;alpha__13&#39;] -&gt; [&#39;other_1__13&#39;]
    242/305: Add [&#39;add_16&#39;, &#39;other_1__13&#39;] -&gt; [&#39;add_17&#39;]
    243/305: Transpose [&#39;add_17&#39;] -&gt; [&#39;transpose_13&#39;]
    244/305: Constant [] -&gt; [&#39;aten_view_466_size_0&#39;]
    245/305: Reshape [&#39;transpose_14&#39;, &#39;aten_view_466_size_0&#39;] -&gt; [&#39;view_47&#39;]
    246/305: Constant [] -&gt; [&#39;aten_view_469_size_0&#39;]
    247/305: Reshape [&#39;view_47&#39;, &#39;aten_view_469_size_0&#39;] -&gt; [&#39;view_52&#39;]
    248/305: Constant [] -&gt; [&#39;aten_view_471_size_0&#39;]
    249/305: Reshape [&#39;transpose_13&#39;, &#39;aten_view_471_size_0&#39;] -&gt; [&#39;view_46&#39;]
    250/305: Transpose [&#39;view_52&#39;] -&gt; [&#39;t_31&#39;]
    251/305: MatMul [&#39;view_52&#39;, &#39;t_33&#39;] -&gt; [&#39;mm_20&#39;]
    252/305: Constant [] -&gt; [&#39;aten_view_475_size_0&#39;]
    253/305: Reshape [&#39;view_46&#39;, &#39;aten_view_475_size_0&#39;] -&gt; [&#39;view_50&#39;]
    254/305: MatMul [&#39;t_31&#39;, &#39;view_1&#39;] -&gt; [&#39;mm_19&#39;]
    255/305: Constant [] -&gt; [&#39;aten_view_478_size_0&#39;]
    256/305: Reshape [&#39;mm_20&#39;, &#39;aten_view_478_size_0&#39;] -&gt; [&#39;view_53&#39;]
    257/305: Transpose [&#39;view_50&#39;] -&gt; [&#39;t_27&#39;]
    258/305: MatMul [&#39;view_50&#39;, &#39;t_29&#39;] -&gt; [&#39;mm_18&#39;]
    259/305: Transpose [&#39;mm_19&#39;] -&gt; [&#39;t_32&#39;]
    260/305: MatMul [&#39;t_27&#39;, &#39;view_1&#39;] -&gt; [&#39;mm_17&#39;]
    261/305: Constant [] -&gt; [&#39;aten_view_484_size_0&#39;]
    262/305: Reshape [&#39;mm_18&#39;, &#39;aten_view_484_size_0&#39;] -&gt; [&#39;view_51&#39;]
    263/305: Transpose [&#39;t_32&#39;] -&gt; [&#39;t_34&#39;]
    264/305: Transpose [&#39;mm_17&#39;] -&gt; [&#39;t_28&#39;]
    265/305: Constant [] -&gt; [&#39;alpha__14&#39;]
    266/305: Mul [&#39;view_51&#39;, &#39;alpha__14&#39;] -&gt; [&#39;other_1__14&#39;]
    267/305: Add [&#39;view_49&#39;, &#39;other_1__14&#39;] -&gt; [&#39;add_20&#39;]
    268/305: Transpose [&#39;t_28&#39;] -&gt; [&#39;t_30&#39;]
    269/305: Constant [] -&gt; [&#39;alpha__15&#39;]
    270/305: Mul [&#39;view_53&#39;, &#39;alpha__15&#39;] -&gt; [&#39;other_1__15&#39;]
    271/305: Add [&#39;add_20&#39;, &#39;other_1__15&#39;] -&gt; [&#39;add_21&#39;]
    272/305: Mul [&#39;add_21&#39;, &#39;primals_1&#39;] -&gt; [&#39;mul_40&#39;]
    273/305: Mul [&#39;add_21&#39;, &#39;mul_1&#39;] -&gt; [&#39;mul_41&#39;]
    274/305: Mul [&#39;mul_40&#39;, &#39;embedding&#39;] -&gt; [&#39;mul_42&#39;]
    275/305: Mul [&#39;mul_40&#39;, &#39;rsqrt&#39;] -&gt; [&#39;mul_43&#39;]
    276/305: Constant [] -&gt; [&#39;_val_417&#39;]
    277/305: ReduceSum [&#39;mul_41&#39;, &#39;_val_417&#39;] -&gt; [&#39;sum_6&#39;]
    278/305: Constant [] -&gt; [&#39;_val_419&#39;]
    279/305: ReduceSum [&#39;mul_42&#39;, &#39;_val_419&#39;] -&gt; [&#39;sum_7&#39;]
    280/305: Constant [] -&gt; [&#39;alpha__16&#39;]
    281/305: Mul [&#39;mul_43&#39;, &#39;alpha__16&#39;] -&gt; [&#39;other_1__16&#39;]
    282/305: Add [&#39;add_13&#39;, &#39;other_1__16&#39;] -&gt; [&#39;add_22&#39;]
    283/305: Constant [] -&gt; [&#39;aten_view_500_size_0&#39;]
    284/305: Reshape [&#39;sum_6&#39;, &#39;aten_view_500_size_0&#39;] -&gt; [&#39;view_54&#39;]
    285/305: Constant [] -&gt; [&#39;_val_424&#39;]
    286/305: Mul [&#39;sum_7&#39;, &#39;_val_424&#39;] -&gt; [&#39;mul_44&#39;]
    287/305: Mul [&#39;mul_44&#39;, &#39;pow_8&#39;] -&gt; [&#39;mul_45&#39;]
    288/305: Constant [] -&gt; [&#39;aten_expand_505_size_1&#39;]
    289/305: Expand [&#39;mul_45&#39;, &#39;aten_expand_505_size_1&#39;] -&gt; [&#39;expand_11&#39;]
    290/305: Constant [] -&gt; [&#39;scalar_tensor_default_6&#39;]
    291/305: Div [&#39;expand_11&#39;, &#39;scalar_tensor_default_6&#39;] -&gt; [&#39;div_4&#39;]
    292/305: Mul [&#39;div_4&#39;, &#39;mul_46&#39;] -&gt; [&#39;mul_47&#39;]
    293/305: Constant [] -&gt; [&#39;alpha__17&#39;]
    294/305: Mul [&#39;mul_47&#39;, &#39;alpha__17&#39;] -&gt; [&#39;other_1__17&#39;]
    295/305: Add [&#39;add_22&#39;, &#39;other_1__17&#39;] -&gt; [&#39;add_23&#39;]
    296/305: Constant [] -&gt; [&#39;aten_masked_fill_512_value_cast&#39;]
    297/305: Where [&#39;unsqueeze_12&#39;, &#39;aten_masked_fill_512_value_cast&#39;, &#39;add_23&#39;] -&gt; [&#39;masked_fill_1&#39;]
    298/305: Constant [] -&gt; [&#39;_val_436&#39;]
    299/305: ConstantOfShape [&#39;_val_436&#39;] -&gt; [&#39;aten_new_zeros_514_result&#39;]
    300/305: SequenceConstruct [&#39;primals_13&#39;] -&gt; [&#39;438&#39;]
    301/305: Constant [] -&gt; [&#39;int64_0__18&#39;]
    302/305: SequenceAt [&#39;438&#39;, &#39;int64_0__18&#39;] -&gt; [&#39;index__18&#39;]
    303/305: Constant [] -&gt; [&#39;int64_m1_1d__18&#39;]
    304/305: Unsqueeze [&#39;index__18&#39;, &#39;int64_m1_1d__18&#39;] -&gt; [&#39;new_index__18&#39;]
    305/305: ScatterND [&#39;aten_new_zeros_514_result&#39;, &#39;new_index__18&#39;, &#39;masked_fill_1&#39;] -&gt; [&#39;_unsafe_index_put&#39;]
    
    NODES in {name!r}
    1/275: Gather [&#39;primals_4&#39;, &#39;primals_13&#39;] -&gt; [&#39;embedding&#39;]
    2/275: Transpose [&#39;primals_8&#39;] -&gt; [&#39;t_3&#39;]
    3/275: Constant [] -&gt; [&#39;_val_22&#39;]
    4/275: Constant [] -&gt; [&#39;_val_23&#39;]
    5/275: Constant [] -&gt; [&#39;size_0__1&#39;]
    6/275: Constant [] -&gt; [&#39;fill_value_1__1&#39;]
    7/275: Expand [&#39;fill_value_1__1&#39;, &#39;size_0__1&#39;] -&gt; [&#39;full&#39;]
    8/275: Constant [] -&gt; [&#39;_val_36&#39;]
    9/275: Constant [] -&gt; [&#39;_val_40&#39;]
    10/275: Constant [] -&gt; [&#39;_val_44&#39;]
    11/275: Constant [] -&gt; [&#39;_val_48&#39;]
    12/275: Slice [&#39;primals_14&#39;, &#39;_val_36&#39;, &#39;_val_40&#39;, &#39;_val_44&#39;, &#39;_val_48&#39;] -&gt; [&#39;slice_8&#39;]
    13/275: Transpose [&#39;primals_9&#39;] -&gt; [&#39;t_4&#39;]
    14/275: Transpose [&#39;primals_10&#39;] -&gt; [&#39;t_5&#39;]
    15/275: Transpose [&#39;primals_11&#39;] -&gt; [&#39;t_6&#39;]
    16/275: Transpose [&#39;primals_5&#39;] -&gt; [&#39;t&#39;]
    17/275: Transpose [&#39;primals_6&#39;] -&gt; [&#39;t_1&#39;]
    18/275: Transpose [&#39;primals_7&#39;] -&gt; [&#39;t_2&#39;]
    19/275: Constant [] -&gt; [&#39;aten_unsqueeze_187_dim_0&#39;]
    20/275: Unsqueeze [&#39;primals_12&#39;, &#39;aten_unsqueeze_187_dim_0&#39;] -&gt; [&#39;unsqueeze_7&#39;]
    21/275: Constant [] -&gt; [&#39;scalar_tensor_default&#39;]
    22/275: Pow [&#39;embedding&#39;, &#39;scalar_tensor_default&#39;] -&gt; [&#39;pow_1&#39;]
    23/275: Transpose [&#39;t_3&#39;] -&gt; [&#39;t_21&#39;]
    24/275: Constant [] -&gt; [&#39;aten_triu_195_diagonal&#39;]
    25/275: Trilu [&#39;full&#39;, &#39;aten_triu_195_diagonal&#39;] -&gt; [&#39;triu&#39;]
    26/275: Constant [] -&gt; [&#39;aten_unsqueeze_196_dim_0&#39;]
    27/275: Unsqueeze [&#39;slice_8&#39;, &#39;aten_unsqueeze_196_dim_0&#39;] -&gt; [&#39;unsqueeze_5&#39;]
    28/275: Transpose [&#39;t_4&#39;] -&gt; [&#39;t_17&#39;]
    29/275: Transpose [&#39;t_5&#39;] -&gt; [&#39;t_13&#39;]
    30/275: Transpose [&#39;t_6&#39;] -&gt; [&#39;t_9&#39;]
    31/275: Transpose [&#39;t&#39;] -&gt; [&#39;t_33&#39;]
    32/275: Transpose [&#39;t_1&#39;] -&gt; [&#39;t_29&#39;]
    33/275: Transpose [&#39;t_2&#39;] -&gt; [&#39;t_25&#39;]
    34/275: Constant [] -&gt; [&#39;_val_75&#39;]
    35/275: Constant [] -&gt; [&#39;_val_79&#39;]
    36/275: Constant [] -&gt; [&#39;_val_83&#39;]
    37/275: Constant [] -&gt; [&#39;_val_87&#39;]
    38/275: Slice [&#39;unsqueeze_7&#39;, &#39;_val_75&#39;, &#39;_val_79&#39;, &#39;_val_83&#39;, &#39;_val_87&#39;] -&gt; [&#39;slice_21&#39;]
    39/275: Constant [] -&gt; [&#39;_val_89&#39;]
    40/275: ReduceMean [&#39;pow_1&#39;, &#39;_val_89&#39;] -&gt; [&#39;mean&#39;]
    41/275: Constant [] -&gt; [&#39;gt&#39;]
    42/275: Constant [] -&gt; [&#39;aten_unsqueeze_240_dim_0&#39;]
    43/275: Unsqueeze [&#39;unsqueeze_5&#39;, &#39;aten_unsqueeze_240_dim_0&#39;] -&gt; [&#39;unsqueeze_6&#39;]
    44/275: Constant [] -&gt; [&#39;aten_unsqueeze_241_dim_0&#39;]
    45/275: Unsqueeze [&#39;slice_21&#39;, &#39;aten_unsqueeze_241_dim_0&#39;] -&gt; [&#39;unsqueeze_8&#39;]
    46/275: Constant [] -&gt; [&#39;aten_add_243_other_1&#39;]
    47/275: Add [&#39;mean&#39;, &#39;aten_add_243_other_1&#39;] -&gt; [&#39;add_1&#39;]
    48/275: Cast [&#39;gt&#39;] -&gt; [&#39;convert_element_type_default&#39;]
    49/275: Mul [&#39;triu&#39;, &#39;convert_element_type_default&#39;] -&gt; [&#39;mul&#39;]
    50/275: Constant [] -&gt; [&#39;_val_119&#39;]
    51/275: Constant [] -&gt; [&#39;_val_123&#39;]
    52/275: Constant [] -&gt; [&#39;_val_127&#39;]
    53/275: Constant [] -&gt; [&#39;_val_131&#39;]
    54/275: Slice [&#39;unsqueeze_6&#39;, &#39;_val_119&#39;, &#39;_val_123&#39;, &#39;_val_127&#39;, &#39;_val_131&#39;] -&gt; [&#39;slice_9&#39;]
    55/275: Constant [] -&gt; [&#39;aten_expand_265_size_1&#39;]
    56/275: Expand [&#39;unsqueeze_8&#39;, &#39;aten_expand_265_size_1&#39;] -&gt; [&#39;expand_2&#39;]
    57/275: Sqrt [&#39;add_1&#39;] -&gt; [&#39;aten_rsqrt_266_tmp&#39;]
    58/275: Reciprocal [&#39;aten_rsqrt_266_tmp&#39;] -&gt; [&#39;rsqrt&#39;]
    59/275: Constant [] -&gt; [&#39;aten_unsqueeze_284_dim_0&#39;]
    60/275: Unsqueeze [&#39;mul&#39;, &#39;aten_unsqueeze_284_dim_0&#39;] -&gt; [&#39;unsqueeze_3&#39;]
    61/275: Constant [] -&gt; [&#39;aten_expand_286_size_1&#39;]
    62/275: Expand [&#39;expand_2&#39;, &#39;aten_expand_286_size_1&#39;] -&gt; [&#39;expand_3&#39;]
    63/275: Mul [&#39;embedding&#39;, &#39;rsqrt&#39;] -&gt; [&#39;mul_1&#39;]
    64/275: Constant [] -&gt; [&#39;aten_unsqueeze_289_dim_0&#39;]
    65/275: Unsqueeze [&#39;unsqueeze_3&#39;, &#39;aten_unsqueeze_289_dim_0&#39;] -&gt; [&#39;unsqueeze_4&#39;]
    66/275: Mul [&#39;primals_1&#39;, &#39;mul_1&#39;] -&gt; [&#39;mul_2&#39;]
    67/275: Constant [] -&gt; [&#39;_val_167&#39;]
    68/275: Constant [] -&gt; [&#39;_val_171&#39;]
    69/275: Constant [] -&gt; [&#39;_val_175&#39;]
    70/275: Constant [] -&gt; [&#39;_val_179&#39;]
    71/275: Slice [&#39;unsqueeze_4&#39;, &#39;_val_167&#39;, &#39;_val_171&#39;, &#39;_val_175&#39;, &#39;_val_179&#39;] -&gt; [&#39;slice_3&#39;]
    72/275: Constant [] -&gt; [&#39;aten_view_313_size_0&#39;]
    73/275: Reshape [&#39;mul_2&#39;, &#39;aten_view_313_size_0&#39;] -&gt; [&#39;view_1&#39;]
    74/275: Constant [] -&gt; [&#39;view_11&#39;]
    75/275: Constant [] -&gt; [&#39;_val_188&#39;]
    76/275: Constant [] -&gt; [&#39;_val_192&#39;]
    77/275: Constant [] -&gt; [&#39;_val_196&#39;]
    78/275: Constant [] -&gt; [&#39;_val_200&#39;]
    79/275: Slice [&#39;slice_3&#39;, &#39;_val_188&#39;, &#39;_val_192&#39;, &#39;_val_196&#39;, &#39;_val_200&#39;] -&gt; [&#39;slice_4&#39;]
    80/275: MatMul [&#39;view_1&#39;, &#39;t&#39;] -&gt; [&#39;mm&#39;]
    81/275: MatMul [&#39;view_1&#39;, &#39;t_1&#39;] -&gt; [&#39;mm_1&#39;]
    82/275: MatMul [&#39;view_1&#39;, &#39;t_2&#39;] -&gt; [&#39;mm_2&#39;]
    83/275: Constant [] -&gt; [&#39;aten_expand_338_size_1&#39;]
    84/275: Expand [&#39;slice_4&#39;, &#39;aten_expand_338_size_1&#39;] -&gt; [&#39;expand_1&#39;]
    85/275: Constant [] -&gt; [&#39;aten_view_340_size_0&#39;]
    86/275: Reshape [&#39;mm&#39;, &#39;aten_view_340_size_0&#39;] -&gt; [&#39;view_2&#39;]
    87/275: Constant [] -&gt; [&#39;aten_view_342_size_0&#39;]
    88/275: Reshape [&#39;mm_1&#39;, &#39;aten_view_342_size_0&#39;] -&gt; [&#39;view_4&#39;]
    89/275: Constant [] -&gt; [&#39;aten_view_344_size_0&#39;]
    90/275: Reshape [&#39;mm_2&#39;, &#39;aten_view_344_size_0&#39;] -&gt; [&#39;view_6&#39;]
    91/275: MatMul [&#39;expand_3&#39;, &#39;view_11&#39;] -&gt; [&#39;view_12&#39;]
    92/275: Constant [] -&gt; [&#39;aten_view_349_size_0&#39;]
    93/275: Reshape [&#39;view_2&#39;, &#39;aten_view_349_size_0&#39;] -&gt; [&#39;view_7&#39;]
    94/275: Constant [] -&gt; [&#39;aten_view_351_size_0&#39;]
    95/275: Reshape [&#39;view_4&#39;, &#39;aten_view_351_size_0&#39;] -&gt; [&#39;view_8&#39;]
    96/275: Constant [] -&gt; [&#39;aten_view_353_size_0&#39;]
    97/275: Reshape [&#39;view_6&#39;, &#39;aten_view_353_size_0&#39;] -&gt; [&#39;view_9&#39;]
    98/275: Transpose [&#39;view_12&#39;] -&gt; [&#39;transpose_3&#39;]
    99/275: Constant [] -&gt; [&#39;_val_227&#39;]
    100/275: Constant [] -&gt; [&#39;_val_231&#39;]
    101/275: Constant [] -&gt; [&#39;_val_235&#39;]
    102/275: Constant [] -&gt; [&#39;_val_239&#39;]
    103/275: Slice [&#39;expand_1&#39;, &#39;_val_227&#39;, &#39;_val_231&#39;, &#39;_val_235&#39;, &#39;_val_239&#39;] -&gt; [&#39;slice_5&#39;]
    104/275: Transpose [&#39;view_7&#39;] -&gt; [&#39;transpose&#39;]
    105/275: Transpose [&#39;view_8&#39;] -&gt; [&#39;transpose_1&#39;]
    106/275: Transpose [&#39;view_9&#39;] -&gt; [&#39;transpose_2&#39;]
    107/275: Concat [&#39;transpose_3&#39;, &#39;transpose_3&#39;] -&gt; [&#39;cat&#39;]
    108/275: Constant [] -&gt; [&#39;_val_249&#39;]
    109/275: Constant [] -&gt; [&#39;_val_253&#39;]
    110/275: Constant [] -&gt; [&#39;_val_257&#39;]
    111/275: Constant [] -&gt; [&#39;_val_261&#39;]
    112/275: Slice [&#39;slice_5&#39;, &#39;_val_249&#39;, &#39;_val_253&#39;, &#39;_val_257&#39;, &#39;_val_261&#39;] -&gt; [&#39;slice_6&#39;]
    113/275: Constant [] -&gt; [&#39;_val_266&#39;]
    114/275: Constant [] -&gt; [&#39;_val_270&#39;]
    115/275: Constant [] -&gt; [&#39;_val_274&#39;]
    116/275: Constant [] -&gt; [&#39;_val_278&#39;]
    117/275: Slice [&#39;transpose&#39;, &#39;_val_266&#39;, &#39;_val_270&#39;, &#39;_val_274&#39;, &#39;_val_278&#39;] -&gt; [&#39;slice_24&#39;]
    118/275: Constant [] -&gt; [&#39;_val_283&#39;]
    119/275: Constant [] -&gt; [&#39;_val_287&#39;]
    120/275: Constant [] -&gt; [&#39;_val_291&#39;]
    121/275: Constant [] -&gt; [&#39;_val_295&#39;]
    122/275: Slice [&#39;transpose&#39;, &#39;_val_283&#39;, &#39;_val_287&#39;, &#39;_val_291&#39;, &#39;_val_295&#39;] -&gt; [&#39;slice_25&#39;]
    123/275: Constant [] -&gt; [&#39;_val_300&#39;]
    124/275: Constant [] -&gt; [&#39;_val_304&#39;]
    125/275: Constant [] -&gt; [&#39;_val_308&#39;]
    126/275: Constant [] -&gt; [&#39;_val_312&#39;]
    127/275: Slice [&#39;transpose_1&#39;, &#39;_val_300&#39;, &#39;_val_304&#39;, &#39;_val_308&#39;, &#39;_val_312&#39;] -&gt; [&#39;slice_26&#39;]
    128/275: Constant [] -&gt; [&#39;_val_317&#39;]
    129/275: Constant [] -&gt; [&#39;_val_321&#39;]
    130/275: Constant [] -&gt; [&#39;_val_325&#39;]
    131/275: Constant [] -&gt; [&#39;_val_329&#39;]
    132/275: Slice [&#39;transpose_1&#39;, &#39;_val_317&#39;, &#39;_val_321&#39;, &#39;_val_325&#39;, &#39;_val_329&#39;] -&gt; [&#39;slice_27&#39;]
    133/275: Constant [] -&gt; [&#39;aten_expand_463_size_1&#39;]
    134/275: Expand [&#39;transpose_2&#39;, &#39;aten_expand_463_size_1&#39;] -&gt; [&#39;expand_8&#39;]
    135/275: Cos [&#39;cat&#39;] -&gt; [&#39;cos&#39;]
    136/275: Sin [&#39;cat&#39;] -&gt; [&#39;sin&#39;]
    137/275: Constant [] -&gt; [&#39;_val_338&#39;]
    138/275: Constant [] -&gt; [&#39;_val_342&#39;]
    139/275: Constant [] -&gt; [&#39;_val_346&#39;]
    140/275: Constant [] -&gt; [&#39;_val_350&#39;]
    141/275: Slice [&#39;slice_6&#39;, &#39;_val_338&#39;, &#39;_val_342&#39;, &#39;_val_346&#39;, &#39;_val_350&#39;] -&gt; [&#39;slice_7&#39;]
    142/275: Neg [&#39;slice_25&#39;] -&gt; [&#39;neg&#39;]
    143/275: Neg [&#39;slice_27&#39;] -&gt; [&#39;neg_1&#39;]
    144/275: Constant [] -&gt; [&#39;aten_unsqueeze_486_dim_0&#39;]
    145/275: Unsqueeze [&#39;cos&#39;, &#39;aten_unsqueeze_486_dim_0&#39;] -&gt; [&#39;unsqueeze_10&#39;]
    146/275: Constant [] -&gt; [&#39;aten_unsqueeze_487_dim_0&#39;]
    147/275: Unsqueeze [&#39;sin&#39;, &#39;aten_unsqueeze_487_dim_0&#39;] -&gt; [&#39;unsqueeze_11&#39;]
    148/275: Constant [] -&gt; [&#39;alpha__2&#39;]
    149/275: Mul [&#39;slice_9&#39;, &#39;alpha__2&#39;] -&gt; [&#39;other_1__2&#39;]
    150/275: Add [&#39;slice_7&#39;, &#39;other_1__2&#39;] -&gt; [&#39;add&#39;]
    151/275: Concat [&#39;neg&#39;, &#39;slice_24&#39;] -&gt; [&#39;cat_1&#39;]
    152/275: Concat [&#39;neg_1&#39;, &#39;slice_26&#39;] -&gt; [&#39;cat_2&#39;]
    153/275: Constant [] -&gt; [&#39;aten_view_494_size_0&#39;]
    154/275: Reshape [&#39;expand_8&#39;, &#39;aten_view_494_size_0&#39;] -&gt; [&#39;view_17&#39;]
    155/275: Mul [&#39;transpose&#39;, &#39;unsqueeze_10&#39;] -&gt; [&#39;mul_3&#39;]
    156/275: Mul [&#39;transpose_1&#39;, &#39;unsqueeze_10&#39;] -&gt; [&#39;mul_5&#39;]
    157/275: Constant [] -&gt; [&#39;scalar_tensor_default_1&#39;]
    158/275: Equal [&#39;add&#39;, &#39;scalar_tensor_default_1&#39;] -&gt; [&#39;eq&#39;]
    159/275: Mul [&#39;cat_1&#39;, &#39;unsqueeze_11&#39;] -&gt; [&#39;mul_4&#39;]
    160/275: Mul [&#39;cat_2&#39;, &#39;unsqueeze_11&#39;] -&gt; [&#39;mul_6&#39;]
    161/275: Transpose [&#39;view_17&#39;] -&gt; [&#39;transpose_8&#39;]
    162/275: Constant [] -&gt; [&#39;_val_372&#39;]
    163/275: Where [&#39;eq&#39;, &#39;_val_372&#39;, &#39;slice_7&#39;] -&gt; [&#39;masked_fill&#39;]
    164/275: Constant [] -&gt; [&#39;alpha__3&#39;]
    165/275: Mul [&#39;mul_4&#39;, &#39;alpha__3&#39;] -&gt; [&#39;other_1__3&#39;]
    166/275: Add [&#39;mul_3&#39;, &#39;other_1__3&#39;] -&gt; [&#39;add_2&#39;]
    167/275: Constant [] -&gt; [&#39;alpha__4&#39;]
    168/275: Mul [&#39;mul_6&#39;, &#39;alpha__4&#39;] -&gt; [&#39;other_1__4&#39;]
    169/275: Add [&#39;mul_5&#39;, &#39;other_1__4&#39;] -&gt; [&#39;add_3&#39;]
    170/275: Constant [] -&gt; [&#39;aten_expand_509_size_1&#39;]
    171/275: Expand [&#39;add_2&#39;, &#39;aten_expand_509_size_1&#39;] -&gt; [&#39;expand_5&#39;]
    172/275: Transpose [&#39;add_3&#39;] -&gt; [&#39;transpose_4&#39;]
    173/275: Constant [] -&gt; [&#39;_val_395&#39;]
    174/275: Transpose [&#39;masked_fill&#39;] -&gt; [&#39;_val_396&#39;]
    175/275: Transpose [&#39;slice_6&#39;] -&gt; [&#39;_val_397&#39;]
    176/275: ScatterND [&#39;_val_397&#39;, &#39;_val_395&#39;, &#39;_val_396&#39;] -&gt; [&#39;_val_398&#39;]
    177/275: Transpose [&#39;_val_398&#39;] -&gt; [&#39;slice_scatter&#39;]
    178/275: Constant [] -&gt; [&#39;aten_expand_533_size_1&#39;]
    179/275: Expand [&#39;transpose_4&#39;, &#39;aten_expand_533_size_1&#39;] -&gt; [&#39;expand_6&#39;]
    180/275: Constant [] -&gt; [&#39;_val_418&#39;]
    181/275: Transpose [&#39;slice_scatter&#39;] -&gt; [&#39;_val_419&#39;]
    182/275: Transpose [&#39;slice_5&#39;] -&gt; [&#39;_val_420&#39;]
    183/275: ScatterND [&#39;_val_420&#39;, &#39;_val_418&#39;, &#39;_val_419&#39;] -&gt; [&#39;_val_421&#39;]
    184/275: Transpose [&#39;_val_421&#39;] -&gt; [&#39;slice_scatter_1&#39;]
    185/275: Constant [] -&gt; [&#39;aten_view_555_size_0&#39;]
    186/275: Reshape [&#39;expand_5&#39;, &#39;aten_view_555_size_0&#39;] -&gt; [&#39;view_13&#39;]
    187/275: Constant [] -&gt; [&#39;_val_441&#39;]
    188/275: ScatterND [&#39;expand_1&#39;, &#39;_val_441&#39;, &#39;slice_scatter_1&#39;] -&gt; [&#39;slice_scatter_2&#39;]
    189/275: Transpose [&#39;view_13&#39;] -&gt; [&#39;transpose_9&#39;]
    190/275: Constant [] -&gt; [&#39;aten_view_576_size_0&#39;]
    191/275: Reshape [&#39;expand_6&#39;, &#39;aten_view_576_size_0&#39;] -&gt; [&#39;view_14&#39;]
    192/275: Constant [] -&gt; [&#39;_val_449&#39;]
    193/275: Constant [] -&gt; [&#39;_val_453&#39;]
    194/275: Constant [] -&gt; [&#39;_val_457&#39;]
    195/275: Constant [] -&gt; [&#39;_val_461&#39;]
    196/275: Slice [&#39;slice_scatter_2&#39;, &#39;_val_449&#39;, &#39;_val_453&#39;, &#39;_val_457&#39;, &#39;_val_461&#39;] -&gt; [&#39;slice_31&#39;]
    197/275: MatMul [&#39;view_13&#39;, &#39;view_14&#39;] -&gt; [&#39;bmm_1&#39;]
    198/275: Transpose [&#39;view_14&#39;] -&gt; [&#39;transpose_10&#39;]
    199/275: Constant [] -&gt; [&#39;_val_468&#39;]
    200/275: Constant [] -&gt; [&#39;_val_472&#39;]
    201/275: Constant [] -&gt; [&#39;_val_476&#39;]
    202/275: Constant [] -&gt; [&#39;_val_480&#39;]
    203/275: Slice [&#39;slice_31&#39;, &#39;_val_468&#39;, &#39;_val_472&#39;, &#39;_val_476&#39;, &#39;_val_480&#39;] -&gt; [&#39;slice_32&#39;]
    204/275: Constant [] -&gt; [&#39;aten_view_614_size_0&#39;]
    205/275: Reshape [&#39;bmm_1&#39;, &#39;aten_view_614_size_0&#39;] -&gt; [&#39;view_15&#39;]
    206/275: Constant [] -&gt; [&#39;_val_487&#39;]
    207/275: Constant [] -&gt; [&#39;_val_491&#39;]
    208/275: Constant [] -&gt; [&#39;_val_495&#39;]
    209/275: Constant [] -&gt; [&#39;_val_499&#39;]
    210/275: Slice [&#39;slice_32&#39;, &#39;_val_487&#39;, &#39;_val_491&#39;, &#39;_val_495&#39;, &#39;_val_499&#39;] -&gt; [&#39;slice_33&#39;]
    211/275: Constant [] -&gt; [&#39;_val_501&#39;]
    212/275: Div [&#39;view_15&#39;, &#39;_val_501&#39;] -&gt; [&#39;div&#39;]
    213/275: Constant [] -&gt; [&#39;alpha__5&#39;]
    214/275: Mul [&#39;slice_33&#39;, &#39;alpha__5&#39;] -&gt; [&#39;other_1__5&#39;]
    215/275: Add [&#39;div&#39;, &#39;other_1__5&#39;] -&gt; [&#39;add_4&#39;]
    216/275: Softmax [&#39;add_4&#39;] -&gt; [&#39;_softmax&#39;]
    217/275: Constant [] -&gt; [&#39;aten_expand_640_size_1&#39;]
    218/275: Expand [&#39;_softmax&#39;, &#39;aten_expand_640_size_1&#39;] -&gt; [&#39;expand_7&#39;]
    219/275: Constant [] -&gt; [&#39;aten_view_643_size_0&#39;]
    220/275: Reshape [&#39;expand_7&#39;, &#39;aten_view_643_size_0&#39;] -&gt; [&#39;view_16&#39;]
    221/275: Identity [&#39;_softmax&#39;] -&gt; [&#39;detach_13&#39;]
    222/275: MatMul [&#39;view_16&#39;, &#39;view_17&#39;] -&gt; [&#39;bmm_2&#39;]
    223/275: Transpose [&#39;view_16&#39;] -&gt; [&#39;transpose_7&#39;]
    224/275: Constant [] -&gt; [&#39;aten_view_648_size_0&#39;]
    225/275: Reshape [&#39;bmm_2&#39;, &#39;aten_view_648_size_0&#39;] -&gt; [&#39;view_18&#39;]
    226/275: Transpose [&#39;view_18&#39;] -&gt; [&#39;transpose_5&#39;]
    227/275: Constant [] -&gt; [&#39;aten_view_652_size_0&#39;]
    228/275: Reshape [&#39;transpose_5&#39;, &#39;aten_view_652_size_0&#39;] -&gt; [&#39;view_19&#39;]
    229/275: Constant [] -&gt; [&#39;aten_view_654_size_0&#39;]
    230/275: Reshape [&#39;view_19&#39;, &#39;aten_view_654_size_0&#39;] -&gt; [&#39;view_20&#39;]
    231/275: MatMul [&#39;view_20&#39;, &#39;t_3&#39;] -&gt; [&#39;mm_3&#39;]
    232/275: Constant [] -&gt; [&#39;aten_view_657_size_0&#39;]
    233/275: Reshape [&#39;mm_3&#39;, &#39;aten_view_657_size_0&#39;] -&gt; [&#39;view_21&#39;]
    234/275: Constant [] -&gt; [&#39;alpha__6&#39;]
    235/275: Mul [&#39;view_21&#39;, &#39;alpha__6&#39;] -&gt; [&#39;other_1__6&#39;]
    236/275: Add [&#39;embedding&#39;, &#39;other_1__6&#39;] -&gt; [&#39;add_5&#39;]
    237/275: Constant [] -&gt; [&#39;scalar_tensor_default_2&#39;]
    238/275: Pow [&#39;add_5&#39;, &#39;scalar_tensor_default_2&#39;] -&gt; [&#39;pow_2&#39;]
    239/275: Constant [] -&gt; [&#39;_val_531&#39;]
    240/275: ReduceMean [&#39;pow_2&#39;, &#39;_val_531&#39;] -&gt; [&#39;mean_1&#39;]
    241/275: Constant [] -&gt; [&#39;aten_add_665_other_1&#39;]
    242/275: Add [&#39;mean_1&#39;, &#39;aten_add_665_other_1&#39;] -&gt; [&#39;add_6&#39;]
    243/275: Sqrt [&#39;add_6&#39;] -&gt; [&#39;aten_rsqrt_666_tmp&#39;]
    244/275: Reciprocal [&#39;aten_rsqrt_666_tmp&#39;] -&gt; [&#39;rsqrt_1&#39;]
    245/275: Mul [&#39;add_5&#39;, &#39;rsqrt_1&#39;] -&gt; [&#39;mul_7&#39;]
    246/275: Mul [&#39;primals_2&#39;, &#39;mul_7&#39;] -&gt; [&#39;mul_8&#39;]
    247/275: Constant [] -&gt; [&#39;aten_view_670_size_0&#39;]
    248/275: Reshape [&#39;mul_8&#39;, &#39;aten_view_670_size_0&#39;] -&gt; [&#39;view_22&#39;]
    249/275: MatMul [&#39;view_22&#39;, &#39;t_4&#39;] -&gt; [&#39;mm_4&#39;]
    250/275: MatMul [&#39;view_22&#39;, &#39;t_5&#39;] -&gt; [&#39;mm_5&#39;]
    251/275: Constant [] -&gt; [&#39;aten_view_674_size_0&#39;]
    252/275: Reshape [&#39;mm_4&#39;, &#39;aten_view_674_size_0&#39;] -&gt; [&#39;view_23&#39;]
    253/275: Constant [] -&gt; [&#39;aten_view_676_size_0&#39;]
    254/275: Reshape [&#39;mm_5&#39;, &#39;aten_view_676_size_0&#39;] -&gt; [&#39;view_25&#39;]
    255/275: Sigmoid [&#39;view_23&#39;] -&gt; [&#39;sigmoid&#39;]
    256/275: Mul [&#39;view_23&#39;, &#39;sigmoid&#39;] -&gt; [&#39;mul_9&#39;]
    257/275: Mul [&#39;mul_9&#39;, &#39;view_25&#39;] -&gt; [&#39;mul_10&#39;]
    258/275: Constant [] -&gt; [&#39;aten_view_681_size_0&#39;]
    259/275: Reshape [&#39;mul_10&#39;, &#39;aten_view_681_size_0&#39;] -&gt; [&#39;view_26&#39;]
    260/275: MatMul [&#39;view_26&#39;, &#39;t_6&#39;] -&gt; [&#39;mm_6&#39;]
    261/275: Constant [] -&gt; [&#39;aten_view_684_size_0&#39;]
    262/275: Reshape [&#39;mm_6&#39;, &#39;aten_view_684_size_0&#39;] -&gt; [&#39;view_27&#39;]
    263/275: Constant [] -&gt; [&#39;alpha__7&#39;]
    264/275: Mul [&#39;view_27&#39;, &#39;alpha__7&#39;] -&gt; [&#39;other_1__7&#39;]
    265/275: Add [&#39;add_5&#39;, &#39;other_1__7&#39;] -&gt; [&#39;add_7&#39;]
    266/275: Constant [] -&gt; [&#39;scalar_tensor_default_3&#39;]
    267/275: Pow [&#39;add_7&#39;, &#39;scalar_tensor_default_3&#39;] -&gt; [&#39;pow_3&#39;]
    268/275: Constant [] -&gt; [&#39;_val_558&#39;]
    269/275: ReduceMean [&#39;pow_3&#39;, &#39;_val_558&#39;] -&gt; [&#39;mean_2&#39;]
    270/275: Constant [] -&gt; [&#39;aten_add_692_other_1&#39;]
    271/275: Add [&#39;mean_2&#39;, &#39;aten_add_692_other_1&#39;] -&gt; [&#39;add_8&#39;]
    272/275: Sqrt [&#39;add_8&#39;] -&gt; [&#39;aten_rsqrt_693_tmp&#39;]
    273/275: Reciprocal [&#39;aten_rsqrt_693_tmp&#39;] -&gt; [&#39;rsqrt_2&#39;]
    274/275: Mul [&#39;add_7&#39;, &#39;rsqrt_2&#39;] -&gt; [&#39;mul_11&#39;]
    275/275: Mul [&#39;primals_3&#39;, &#39;mul_11&#39;] -&gt; [&#39;mul_12&#39;]
    [runpythonerror]
    /home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/exporter.py:137: UserWarning: torch.onnx.dynamo_export only implements opset version 18 for now. If you need to use a different opset version, please register them with register_custom_op.
      warnings.warn(
    2024-05-23 13:23:56,684 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue return_val due to large size 4194304.
    2024-05-23 13:23:56,684 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue full due to large size 4194304.
    2024-05-23 13:23:56,732 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue triu due to large size 4194304.
    2024-05-23 13:23:56,801 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue convert_element_type_default due to large size 4194304.
    2024-05-23 13:23:56,809 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue mul due to large size 4194304.
    2024-05-23 13:23:56,828 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue return_val due to large size 4194304.
    2024-05-23 13:23:56,828 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue unsqueeze_3 due to large size 4194304.
    2024-05-23 13:23:56,832 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue return_val due to large size 4194304.
    2024-05-23 13:23:56,833 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue unsqueeze_4 due to large size 4194304.
    2024-05-23 13:23:56,845 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue slice_3 due to large size 4194304.
    2024-05-23 13:23:56,856 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue slice_4 due to large size 4194304.
    2024-05-23 13:23:56,864 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue return_val due to large size 8388608.
    2024-05-23 13:23:56,865 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue expand_1 due to large size 8388608.
    2024-05-23 13:23:56,875 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue clone due to large size 8388608.
    2024-05-23 13:23:56,888 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue slice_5 due to large size 8388608.
    2024-05-23 13:23:56,897 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue slice_6 due to large size 8388608.
    2024-05-23 13:23:56,936 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue slice_7 due to large size 8388608.
    2024-05-23 13:23:56,958 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue _val_397 due to large size 8388608.
    2024-05-23 13:23:56,968 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue _val_420 due to large size 8388608.
    2024-05-23 13:23:57,260 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue return_val due to large size 4194304.
    2024-05-23 13:23:57,261 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue full due to large size 4194304.
    2024-05-23 13:23:57,266 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue triu due to large size 4194304.
    2024-05-23 13:23:57,277 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue convert_element_type_default due to large size 4194304.
    2024-05-23 13:23:57,278 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue mul due to large size 4194304.
    2024-05-23 13:23:57,281 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue unsqueeze_3 due to large size 4194304.
    2024-05-23 13:23:57,282 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue unsqueeze_4 due to large size 4194304.
    2024-05-23 13:23:57,283 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue slice_3 due to large size 4194304.
    2024-05-23 13:23:57,286 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue slice_4 due to large size 4194304.
    2024-05-23 13:23:57,290 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue expand_1 due to large size 8388608.
    2024-05-23 13:23:57,295 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue slice_5 due to large size 8388608.
    2024-05-23 13:23:57,297 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue slice_6 due to large size 8388608.
    2024-05-23 13:23:57,305 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue slice_7 due to large size 8388608.
    2024-05-23 13:23:57,312 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue _val_397 due to large size 8388608.
    2024-05-23 13:23:57,314 onnxscript.optimizer.constant_folding [WARNING] - Skip storing constant folded nvalue _val_420 due to large size 8388608.
    [0;93m2024-05-23 13:23:57.586155000 [W:onnxruntime:, graph.cc:4051 CleanUnusedInitializersAndNodeArgs] Removing initializer &#39;_val_23&#39;. It is not used by any node and should be removed from the model.[m
    [0;93m2024-05-23 13:23:57.586257600 [W:onnxruntime:, graph.cc:4051 CleanUnusedInitializersAndNodeArgs] Removing initializer &#39;_val_22&#39;. It is not used by any node and should be removed from the model.[m
</pre></div>
</div>
</section>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="example_bug.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">A script to report a bug</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="torchtry.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Tries with Undocumented</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2023-2024
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Use the custom exporter in torch</a><ul>
<li><a class="reference internal" href="#file-onnxruntime-py">File <cite>onnxruntime.py</cite></a></li>
<li><a class="reference internal" href="#examples">Examples</a><ul>
<li><a class="reference internal" href="#baseline">Baseline</a></li>
<li><a class="reference internal" href="#with-the-custom-exporter">With the custom exporter</a></li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../_static/documentation_options.js?v=a1637f0b"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/furo.js?v=4e2eecee"></script>
    </body>
</html>