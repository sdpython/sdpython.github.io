<!doctype html>
<html class="no-js" lang="en" data-content_root="../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="to_onnx: Rename Dynamic Shapes" href="plot_exporter_recipes_c_named_ds_auto.html" /><link rel="prev" title="to_onnx and padding one dimension to a mulitple of a constant" href="plot_exporter_recipes_c_dynpad.html" />

    <!-- Generated with Sphinx 8.1.3 and Furo 2024.08.06 -->
        <title>to_onnx and submodules from LLMs - experimental-experiment 0.1.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=354aac6f" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css?v=7f9a90b1" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css?v=4ae1632d" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=302659d7" />
    
    


<style>
  body {
    --color-code-background: #eeffcc;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">experimental-experiment 0.1.1 documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="../_static/logo.png" alt="Logo"/>
  </div>
  
  <span class="sidebar-brand-text">experimental-experiment 0.1.1 documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Contents</span></p>
<ul class="current">
<li class="toctree-l1 has-children"><a class="reference internal" href="../design/index.html">Design</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of Design</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../design/exporter.html">Custom Exporter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../design/optimizer.html">Pattern Optimizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../design/backends.html">Dynamo Backends</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../tutorial/index.html">Tutorial</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of Tutorial</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../tutorial/errors.html">Unexpected Errors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorial/docker.html">Start from a docker</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api/index.html">API</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of API</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/gradient/index.html">.gradient</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of .gradient</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/gradient/ops/index.html">.gradient.ops</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of .gradient.ops</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/gradient/ops/op_broadcast_gradient_args.html">.gradient.ops.op_broadcast_gradient_args</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api/gradient/grad_helper.html">.gradient.grad_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/gradient/loss_helper.html">.gradient.loss_helper</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/reference/index.html">.reference</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle navigation of .reference</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/reference/ops/index.html">.reference.ops</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle navigation of .reference.ops</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_add_add_mul_mul.html">.reference.ops.op_add_add_mul_mul</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_average_pool_grad.html">.reference.ops.op_average_pool_grad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_cast_like.html">.reference.ops.op_cast_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_complex.html">.reference.ops.op_complex</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_concat.html">.reference.ops.op_concat</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_constant_of_shape.html">.reference.ops.op_constant_of_shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_fused_matmul.html">.reference.ops.op_fused_matmul</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_gather_grad.html">.reference.ops.op_gather_grad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_memcpy_host.html">.reference.ops.op_memcpy_host</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_mul_sigmoid.html">.reference.ops.op_mul_sigmoid</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_negxplus1.html">.reference.ops.op_negxplus1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_quick_gelu.html">.reference.ops.op_quick_gelu</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_replace_zero.html">.reference.ops.op_replace_zero</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_rotary.html">.reference.ops.op_rotary</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_qlinear_average_pool.html">.reference.ops.op_qlinear_average_pool</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_qlinear_conv.html">.reference.ops.op_qlinear_conv</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_scatter_elements.html">.reference.ops.op_scatter_elements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_scatternd_of_shape.html">.reference.ops.op_scatternd_of_shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_simplified_layer_normalization.html">.reference.ops.op_simplified_layer_normalization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_skip_layer_normalization.html">.reference.ops.op_skip_layer_normalization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_slice.html">.reference.ops.op_slice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_transpose_cast.html">.reference.ops.op_transpose_cast</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_tri_matrix.html">.reference.ops.op_tri_matrix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api/reference/evaluator.html">.reference.evaluator</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/reference/ort_evaluator.html">.reference.ort_evaluator</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/reference/quantized_tensor.html">.reference.quantized_tensor</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/convert/index.html">.convert</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle navigation of .convert</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/convert/convert_helper.html">.convert.convert_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/convert/ort_helper.html">.convert.ort_helper</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/plotting/index.html">.plotting</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle navigation of .plotting</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/plotting/data.html">.plotting.data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/plotting/memory.html">.plotting.memory</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/skl/index.html">.skl</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle navigation of .skl</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/skl/convert.html">.skl.convert</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/skl/helpers.html">.skl.helpers</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/torch_interpreter/index.html">.torch_interpreter</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><div class="visually-hidden">Toggle navigation of .torch_interpreter</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/_aten_functions.html">.torch_interpreter._aten_functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/_aten_functions_attention.html">.torch_interpreter._aten_functions_attention</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/_non_aten_functions.html">.torch_interpreter._non_aten_functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/_aten_methods.html">.torch_interpreter._aten_methods</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/_doc_.html">.torch_interpreter._doc_</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/_exceptions.html">.torch_interpreter._exceptions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/_prims_functions.html">.torch_interpreter._prims_functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/_torch_helper.html">.torch_interpreter._torch_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/aten_functions.html">.torch_interpreter.aten_functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/aten_methods.html">.torch_interpreter.aten_methods</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/dispatcher.html">.torch_interpreter.dispatcher</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/export_options.html">.torch_interpreter.export_options</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/interpreter.html">.torch_interpreter.interpreter</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/investigate_helper.html">.torch_interpreter.investigate_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/onnx_export.html">.torch_interpreter.onnx_export</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/oxs_dispatcher.html">.torch_interpreter.oxs_dispatcher</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/oxs_opset.html">.torch_interpreter.oxs_opset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/piece_by_piece.html">.torch_interpreter.piece_by_piece</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/piece_by_piece_serialize.html">.torch_interpreter.piece_by_piece_serialize</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/tracing.html">.torch_interpreter.tracing</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/torch_models/index.html">.torch_models</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><div class="visually-hidden">Toggle navigation of .torch_models</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_models/diffusion_model_helper.html">.torch_models.diffusion_model_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_models/dump_helper.html">.torch_models.dump_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_models/llama_helper.html">.torch_models.llama_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_models/llm_model_helper.html">.torch_models.llm_model_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_models/llm_model_setup.html">.torch_models.llm_model_setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_models/mistral_helper.html">.torch_models.mistral_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_models/phi3_helper.html">.torch_models.phi3_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_models/phi_helper.html">.torch_models.phi_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_models/training_helper.html">.torch_models.training_helper</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/xbuilder/index.html">.xbuilder</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" role="switch" type="checkbox"/><label for="toctree-checkbox-13"><div class="visually-hidden">Toggle navigation of .xbuilder</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/xbuilder/_graph_builder_runtime.html">.xbuilder._graph_builder_runtime</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xbuilder/_onnx_helper.html">.xbuilder._onnx_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xbuilder/_shape_helper.html">.xbuilder._shape_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xbuilder/expression_dimension.html">.xbuilder.expression_dimension</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xbuilder/graph_builder.html">.xbuilder.graph_builder</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xbuilder/graph_builder_opset.html">.xbuilder.graph_builder_opset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xbuilder/model_container.html">.xbuilder.model_container</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xbuilder/optimization_options.html">.xbuilder.optimization_options</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xbuilder/reverse_graph_builder.html">.xbuilder.reverse_graph_builder</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xbuilder/shape_type_compute.html">.xbuilder.shape_type_compute</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xbuilder/type_inference.html">.xbuilder.type_inference</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/xoptim/index.html">.xoptim</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" role="switch" type="checkbox"/><label for="toctree-checkbox-14"><div class="visually-hidden">Toggle navigation of .xoptim</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/xoptim/patterns_investigation/index.html">.xoptim.patterns_investigation</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" role="switch" type="checkbox"/><label for="toctree-checkbox-15"><div class="visually-hidden">Toggle navigation of .xoptim.patterns_investigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_investigation/element_wise.html">.xoptim.patterns_investigation.element_wise</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_investigation/llm_patterns.html">.xoptim.patterns_investigation.llm_patterns</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/xoptim/patterns_ml/index.html">.xoptim.patterns_ml</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" role="switch" type="checkbox"/><label for="toctree-checkbox-16"><div class="visually-hidden">Toggle navigation of .xoptim.patterns_ml</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ml/tree_ensemble.html">.xoptim.patterns_ml.tree_ensemble</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/xoptim/patterns_exp/index.html">.xoptim.patterns_exp</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" role="switch" type="checkbox"/><label for="toctree-checkbox-17"><div class="visually-hidden">Toggle navigation of .xoptim.patterns_exp</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_exp/binary_operators.html">.xoptim.patterns_exp.binary_operators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_exp/constant_of_shape_scatter_nd.html">.xoptim.patterns_exp.constant_of_shape_scatter_nd</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_exp/constants.html">.xoptim.patterns_exp.constants</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_exp/simple_rotary.html">.xoptim.patterns_exp.simple_rotary</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_exp/unary_operators.html">.xoptim.patterns_exp.unary_operators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_exp/where_replace.html">.xoptim.patterns_exp.where_replace</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/xoptim/patterns/index.html">.xoptim.patterns</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" role="switch" type="checkbox"/><label for="toctree-checkbox-18"><div class="visually-hidden">Toggle navigation of .xoptim.patterns</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_any.html">.xoptim.patterns.onnx_any</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_cast.html">.xoptim.patterns.onnx_cast</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_clip.html">.xoptim.patterns.onnx_clip</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_constants.html">.xoptim.patterns.onnx_constants</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_conv.html">.xoptim.patterns.onnx_conv</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_dropout.html">.xoptim.patterns.onnx_dropout</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_equal.html">.xoptim.patterns.onnx_equal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_expand.html">.xoptim.patterns.onnx_expand</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_functions.html">.xoptim.patterns.onnx_functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_layer_normalization.html">.xoptim.patterns.onnx_layer_normalization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_matmul.html">.xoptim.patterns.onnx_matmul</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_mul.html">.xoptim.patterns.onnx_mul</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_reduce.html">.xoptim.patterns.onnx_reduce</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_reshape.html">.xoptim.patterns.onnx_reshape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_rotary.html">.xoptim.patterns.onnx_rotary</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_slice.html">.xoptim.patterns.onnx_slice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_split.html">.xoptim.patterns.onnx_split</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_sub.html">.xoptim.patterns.onnx_sub</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_sequence.html">.xoptim.patterns.onnx_sequence</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_transpose.html">.xoptim.patterns.onnx_transpose</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_unsqueeze.html">.xoptim.patterns.onnx_unsqueeze</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/xoptim/patterns_ort/index.html">.xoptim.patterns_ort</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" role="switch" type="checkbox"/><label for="toctree-checkbox-19"><div class="visually-hidden">Toggle navigation of .xoptim.patterns_ort</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ort/activation.html">.xoptim.patterns_ort.activation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ort/activation_grad.html">.xoptim.patterns_ort.activation_grad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ort/attention_patterns.html">.xoptim.patterns_ort.attention_patterns</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ort/batch_normalization.html">.xoptim.patterns_ort.batch_normalization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ort/fused_conv.html">.xoptim.patterns_ort.fused_conv</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ort/fused_matmul.html">.xoptim.patterns_ort.fused_matmul</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ort/gather_grad.html">.xoptim.patterns_ort.gather_grad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ort/llm_optim.html">.xoptim.patterns_ort.llm_optim</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ort/simplified_layer_normalization.html">.xoptim.patterns_ort.simplified_layer_normalization</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/xoptim/patterns_fix/index.html">.xoptim.patterns_fix</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" role="switch" type="checkbox"/><label for="toctree-checkbox-20"><div class="visually-hidden">Toggle navigation of .xoptim.patterns_fix</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_fix/add_reduction_scatter_nd.html">.xoptim.patterns_fix.add_reduction_scatter_nd</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api/xoptim/graph_builder_optim.html">.xoptim.graph_builder_optim</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xoptim/order_optim.html">.xoptim.order_optim</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xoptim/patterns_api.html">.xoptim.patterns_api</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xoptim/unfused.html">.xoptim.unfused</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/torch_dynamo/index.html">.torch_dynamo</a><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" role="switch" type="checkbox"/><label for="toctree-checkbox-21"><div class="visually-hidden">Toggle navigation of .torch_dynamo</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_dynamo/_dynamo_exporter.html">.torch_dynamo._dynamo_exporter</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_dynamo/backend_helper.html">.torch_dynamo.backend_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_dynamo/debug_backend.html">.torch_dynamo.debug_backend</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_dynamo/fast_backend.html">.torch_dynamo.fast_backend</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_dynamo/partition.html">experimental_experiment.torch_dynamo.partition</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/torch_bench/index.html">.torch_bench</a><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" role="switch" type="checkbox"/><label for="toctree-checkbox-22"><div class="visually-hidden">Toggle navigation of .torch_bench</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_benchmark_runner.html">experimental_experiment.torch_bench._bash_bench_benchmark_runner</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_benchmark_runner_agg.html">experimental_experiment.torch_bench._bash_bench_benchmark_runner_agg</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_benchmark_runner_agg_helper.html">experimental_experiment.torch_bench._bash_bench_benchmark_runner_agg_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_cmd.html">experimental_experiment.torch_bench._bash_bench_cmd</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_model_runner.html">experimental_experiment.torch_bench._bash_bench_model_runner</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_models_helper.html">experimental_experiment.torch_bench._bash_bench_models_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_set_dummies.html">experimental_experiment.torch_bench._bash_bench_set_dummies</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_set_explicit.html">experimental_experiment.torch_bench._bash_bench_set_explicit</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_set_huggingface.html">experimental_experiment.torch_bench._bash_bench_set_huggingface</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_set_huggingface_big.html">experimental_experiment.torch_bench._bash_bench_set_huggingface_big</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_set_issues.html">experimental_experiment.torch_bench._bash_bench_set_issues</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_set_timm.html">experimental_experiment.torch_bench._bash_bench_set_timm</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_set_torchbench.html">experimental_experiment.torch_bench._bash_bench_set_torchbench</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_set_torchbench_ado.html">experimental_experiment.torch_bench._bash_bench_set_torchbench_ado</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_untrained.html">experimental_experiment.torch_bench._bash_bench_untrained</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_dort_cmd_common.html">experimental_experiment.torch_bench._dort_cmd_common</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_dort_cmd_common_models.html">experimental_experiment.torch_bench._dort_cmd_common_models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/bash_bench_agg.html">.torch_bench.bash_bench_agg</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/bash_bench_explicit.html">.torch_bench.bash_bench_explicit</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/bash_bench_huggingface.html">.torch_bench.bash_bench_huggingface</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/bash_bench_huggingface_big.html">.torch_bench.bash_bench_huggingface_big</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/bash_bench_issues.html">.torch_bench.bash_bench_issues</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/bash_bench_timm.html">.torch_bench.bash_bench_timm</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/bash_bench_torchbench.html">.torch_bench.bash_bench_torchbench</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/bash_bench_torchbench_ado.html">.torch_bench.bash_bench_torchbench_ado</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/bash_bench_untrained.html">.torch_bench.bash_bench_untrained</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/check_model.html">.torch_bench.check_model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/dort_bench.html">.torch_bench.dort_bench</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/dort_bench_profile.html">.torch_bench.dort_bench_profile</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/dort_profile.html">.torch_bench.dort_profile</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/export_model.html">.torch_bench.export_model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/export_model_helper.html">.torch_bench.export_model_helper</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api/_bench_test.html">._bench_test</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/_command_lines_parser.html">._command_lines_parser</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/args.html">.args</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bench_run.html">.bench_run</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/checks.html">.checks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/ext_test_case.html">.ext_test_case</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/helpers.html">.helpers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/memory_peak.html">.memory_peak</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/mini_onnx_builder.html">.mini_onnx_builder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/model_run.html">.model_run</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/onnx_tools.html">.onnx_tools</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/ort_session.html">.ort_session</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/torch_test_helper.html">.torch_test_helper</a></li>
</ul>
</li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="../galleries.html">Galleries of Examples and Recipes</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" role="switch" type="checkbox"/><label for="toctree-checkbox-23"><div class="visually-hidden">Toggle navigation of Galleries of Examples and Recipes</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/index.html">Examples Gallery</a><input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" role="switch" type="checkbox"/><label for="toctree-checkbox-24"><div class="visually-hidden">Toggle navigation of Examples Gallery</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_custom_backend_101.html">101: A custom backend for torch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_linreg_101.html">101: Linear Regression and export to ONNX</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_optimize_101.html">101: Onnx Model Optimization based on Pattern Rewriting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_rewrite_101.html">101: Onnx Model Rewriting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_profile_existing_onnx_101.html">101: Profile an existing model with onnxruntime</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_export_101.html">101: Some dummy examples with torch.export.export</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_convolutation_matmul_102.html">102: Convolution and Matrix Multiplication</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_onnxscript_102.html">102: Examples with onnxscript</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_custom_backend_llama_102.html">102: Fuse kernels in a small Llama Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_llama_bench_102.html">102: Measure LLAMA speed</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_export_compile_102.html">102: Tweak onnx export</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_dort_201.html">201: Evaluate DORT</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_aot_201.html">201: Evaluate DORT Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_export_201.html">201: Evaluate different ways to export a torch model to ONNX</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_sklearn_201.html">201: Use torch to export a scikit-learn model into ONNX</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_llama_diff_export_301.html">301: Compares LLAMA exporters</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_llama_diff_dort_301.html">301: Compares LLAMA exporters for onnxrt backend</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_model_to_python.html">Playground for big optimization pattern</a></li>
</ul>
</li>
<li class="toctree-l2 current has-children"><a class="reference internal" href="index.html">Exporter Recipes Gallery</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" role="switch" type="checkbox"/><label for="toctree-checkbox-25"><div class="visually-hidden">Toggle navigation of Exporter Recipes Gallery</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_exporter_lost_dynamic_dimension.html">A dynamic dimension lost by torch.export.export</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_exporter_untrained_tinyllm.html">Check the exporter on a dummy from HuggingFace</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_exporter_inputs.html">Do no use Module as inputs!</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_exporter_phi35_piece.html">Export Phi-3.5-mini-instruct piece by piece</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_exporter_draft_mode.html">Export Phi-3.5-mini-instruct with draft_export</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_exporter_reportibility.html">Export Phi-3.5-mini-instruct with report_exportability</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_exporter_with_dynamic_cache.html">Export a model using a custom type as input</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_exporter_scan_pdist.html">Export a model with a loop (scan)</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_exporter_infer_ds.html">Infer dynamic shapes before exporting</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_recipes_oe_lr.html">Linear Regression and export to ONNX</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_coverage.html">Measures the exporter success on many test cases</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_exporter_dynamic_shapes_auto.html">Use DYNAMIC or AUTO when dynamic shapes has constraints</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_recipes_c_phi2.html">to_onnx and Phi-2</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_recipes_c_custom_ops_inplace.html">to_onnx and a custom operator inplace</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_recipes_c_custom_ops_fct.html">to_onnx and a custom operator registered with a function</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_recipes_c_scan_pdist.html">to_onnx and a model with a loop (scan)</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_recipes_c_cond.html">to_onnx and a model with a test</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_recipes_c_dynpad.html">to_onnx and padding one dimension to a mulitple of a constant</a></li>
<li class="toctree-l3 current current-page"><a class="current reference internal" href="#">to_onnx and submodules from LLMs</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_recipes_c_named_ds_auto.html">to_onnx: Rename Dynamic Shapes</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_recipes_oe_phi2.html">torch.onnx.export and Phi-2</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_recipes_oe_custom_ops_inplace.html">torch.onnx.export and a custom operator inplace</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_recipes_oe_custom_ops_fct.html">torch.onnx.export and a custom operator registered with a function</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_recipes_oe_cond.html">torch.onnx.export and a model with a test</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_recipes_oe_dynpad.html">torch.onnx.export and padding one dimension to a mulitple of a constant</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_recipes_oe_named_ds_auto.html">torch.onnx.export: Rename Dynamic Shapes</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../command_lines.html">Command Lines</a><input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" role="switch" type="checkbox"/><label for="toctree-checkbox-26"><div class="visually-hidden">Toggle navigation of Command Lines</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../bench/index.html">Benchmarks from the command line</a><input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" role="switch" type="checkbox"/><label for="toctree-checkbox-27"><div class="visually-hidden">Toggle navigation of Benchmarks from the command line</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../bench/dort_bench.html">experimental_experiment.torch_bench.dort_bench</a></li>
<li class="toctree-l3"><a class="reference internal" href="../bench/dort_profile.html">experimental_experiment.torch_bench.dort_profile</a></li>
<li class="toctree-l3"><a class="reference internal" href="../bench/scripts.html">Interesting scripts or command lines</a></li>
<li class="toctree-l3"><a class="reference internal" href="../bench/bash_bench.html">Measuring the exporters on a short list of sets of models</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../tools/index.html">Tools from the command line</a><input class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" role="switch" type="checkbox"/><label for="toctree-checkbox-28"><div class="visually-hidden">Toggle navigation of Tools from the command line</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../tools/lighten.html">python -m experimental_experiment lighten and unlighten</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tools/optimize.html">python -m experimental_experiment optimize</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tools/print.html">python -m experimental_experiment print</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tools/run.html">python -m experimental_experiment run</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../miscellaneous/index.html">Miscellaneous</a><input class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" role="switch" type="checkbox"/><label for="toctree-checkbox-29"><div class="visually-hidden">Toggle navigation of Miscellaneous</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../miscellaneous/export_times.html">Export Times</a></li>
<li class="toctree-l2"><a class="reference internal" href="../miscellaneous/long_outputs.html">Long Outputs uneasy to read</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../miscellaneous/models/index.html">Supported Models By the Custom Backend</a><input class="toctree-checkbox" id="toctree-checkbox-30" name="toctree-checkbox-30" role="switch" type="checkbox"/><label for="toctree-checkbox-30"><div class="visually-hidden">Toggle navigation of Supported Models By the Custom Backend</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../miscellaneous/models/phi.html">Phi</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">More</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../CHANGELOGS.html">Change Logs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="../_sources/auto_recipes/plot_exporter_recipes_c_modules.rst" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-auto-recipes-plot-exporter-recipes-c-modules-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="to-onnx-and-submodules-from-llms">
<span id="l-plot-exporter-recipes-custom-modules"></span><span id="sphx-glr-auto-recipes-plot-exporter-recipes-c-modules-py"></span><h1>to_onnx and submodules from LLMs<a class="headerlink" href="#to-onnx-and-submodules-from-llms" title="Link to this heading"></a></h1>
<p>Big models are hard to read once converted into onnx.
Lets see how to improve their readibility.
The code is inspired from
<a class="reference external" href="https://medium.com/&#64;msouza.os/llm-from-scratch-with-pytorch-9f21808c6319">LLM from scratch with Pytorch</a>.</p>
<section id="a-simple-llm">
<h2>A simple LLM<a class="headerlink" href="#a-simple-llm" title="Link to this heading"></a></h2>
<p>All comments were removed from the code to make it less verbose.
A few fixes were applied to the original code.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">onnx</span>
<span class="kn">from</span> <span class="nn">onnx.inliner</span> <span class="kn">import</span> <a href="https://onnx.ai/onnx/api/inliner.html#onnx.inliner.inline_local_functions" title="onnx.inliner.inline_local_functions" class="sphx-glr-backref-module-onnx-inliner sphx-glr-backref-type-py-function"><a href="https://onnx.ai/onnx/api/inliner.html#onnx.inliner.inline_local_functions" title="onnx.inliner.inline_local_functions" class="sphx-glr-backref-module-onnx-inliner sphx-glr-backref-type-py-function"><a href="https://onnx.ai/onnx/api/inliner.html#onnx.inliner.inline_local_functions" title="onnx.inliner.inline_local_functions" class="sphx-glr-backref-module-onnx-inliner sphx-glr-backref-type-py-function"><a href="https://onnx.ai/onnx/api/inliner.html#onnx.inliner.inline_local_functions" title="onnx.inliner.inline_local_functions" class="sphx-glr-backref-module-onnx-inliner sphx-glr-backref-type-py-function"><span class="n">inline_local_functions</span></a></a></a></a>
<span class="kn">from</span> <span class="nn">onnx_array_api.plotting.graphviz_helper</span> <span class="kn">import</span> <a href="https://sdpython.github.io/doc/onnx-array-api/dev/api/plotting.html#onnx_array_api.plotting.graphviz_helper.plot_dot" title="onnx_array_api.plotting.graphviz_helper.plot_dot" class="sphx-glr-backref-module-onnx_array_api-plotting-graphviz_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-array-api/dev/api/plotting.html#onnx_array_api.plotting.graphviz_helper.plot_dot" title="onnx_array_api.plotting.graphviz_helper.plot_dot" class="sphx-glr-backref-module-onnx_array_api-plotting-graphviz_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-array-api/dev/api/plotting.html#onnx_array_api.plotting.graphviz_helper.plot_dot" title="onnx_array_api.plotting.graphviz_helper.plot_dot" class="sphx-glr-backref-module-onnx_array_api-plotting-graphviz_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-array-api/dev/api/plotting.html#onnx_array_api.plotting.graphviz_helper.plot_dot" title="onnx_array_api.plotting.graphviz_helper.plot_dot" class="sphx-glr-backref-module-onnx_array_api-plotting-graphviz_helper sphx-glr-backref-type-py-function"><span class="n">plot_dot</span></a></a></a></a>
<span class="kn">from</span> <span class="nn">onnx_array_api.reference</span> <span class="kn">import</span> <a href="https://sdpython.github.io/doc/onnx-array-api/dev/api/reference.html#onnx_array_api.reference.compare_onnx_execution" title="onnx_array_api.reference.compare_onnx_execution" class="sphx-glr-backref-module-onnx_array_api-reference sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-array-api/dev/api/reference.html#onnx_array_api.reference.compare_onnx_execution" title="onnx_array_api.reference.compare_onnx_execution" class="sphx-glr-backref-module-onnx_array_api-reference sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-array-api/dev/api/reference.html#onnx_array_api.reference.compare_onnx_execution" title="onnx_array_api.reference.compare_onnx_execution" class="sphx-glr-backref-module-onnx_array_api-reference sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-array-api/dev/api/reference.html#onnx_array_api.reference.compare_onnx_execution" title="onnx_array_api.reference.compare_onnx_execution" class="sphx-glr-backref-module-onnx_array_api-reference sphx-glr-backref-type-py-function"><span class="n">compare_onnx_execution</span></a></a></a></a>
<span class="kn">from</span> <span class="nn">onnx_diagnostic.helpers</span> <span class="kn">import</span> <a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/index.html#onnx_diagnostic.helpers.max_diff" title="onnx_diagnostic.helpers.max_diff" class="sphx-glr-backref-module-onnx_diagnostic-helpers sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/index.html#onnx_diagnostic.helpers.max_diff" title="onnx_diagnostic.helpers.max_diff" class="sphx-glr-backref-module-onnx_diagnostic-helpers sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/index.html#onnx_diagnostic.helpers.max_diff" title="onnx_diagnostic.helpers.max_diff" class="sphx-glr-backref-module-onnx_diagnostic-helpers sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/index.html#onnx_diagnostic.helpers.max_diff" title="onnx_diagnostic.helpers.max_diff" class="sphx-glr-backref-module-onnx_diagnostic-helpers sphx-glr-backref-type-py-function"><span class="n">max_diff</span></a></a></a></a>
<span class="kn">from</span> <span class="nn">onnx_diagnostic.helpers.onnx_helper</span> <span class="kn">import</span> <a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><span class="n">pretty_onnx</span></a></a></a></a>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">onnxruntime</span> <span class="kn">import</span> <a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession" title="onnxruntime.capi.onnxruntime_inference_collection.InferenceSession" class="sphx-glr-backref-module-onnxruntime-capi-onnxruntime_inference_collection sphx-glr-backref-type-py-class"><a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession" title="onnxruntime.capi.onnxruntime_inference_collection.InferenceSession" class="sphx-glr-backref-module-onnxruntime-capi-onnxruntime_inference_collection sphx-glr-backref-type-py-class"><a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession" title="onnxruntime.capi.onnxruntime_inference_collection.InferenceSession" class="sphx-glr-backref-module-onnxruntime-capi-onnxruntime_inference_collection sphx-glr-backref-type-py-class"><a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession" title="onnxruntime.capi.onnxruntime_inference_collection.InferenceSession" class="sphx-glr-backref-module-onnxruntime-capi-onnxruntime_inference_collection sphx-glr-backref-type-py-class"><span class="n">InferenceSession</span></a></a></a></a>
<span class="kn">from</span> <span class="nn">experimental_experiment.reference</span> <span class="kn">import</span> <a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/reference/index.html#experimental_experiment.reference.ExtendedReferenceEvaluator" title="experimental_experiment.reference.ExtendedReferenceEvaluator" class="sphx-glr-backref-module-experimental_experiment-reference sphx-glr-backref-type-py-class"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/reference/index.html#experimental_experiment.reference.ExtendedReferenceEvaluator" title="experimental_experiment.reference.ExtendedReferenceEvaluator" class="sphx-glr-backref-module-experimental_experiment-reference sphx-glr-backref-type-py-class"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/reference/index.html#experimental_experiment.reference.ExtendedReferenceEvaluator" title="experimental_experiment.reference.ExtendedReferenceEvaluator" class="sphx-glr-backref-module-experimental_experiment-reference sphx-glr-backref-type-py-class"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/reference/index.html#experimental_experiment.reference.ExtendedReferenceEvaluator" title="experimental_experiment.reference.ExtendedReferenceEvaluator" class="sphx-glr-backref-module-experimental_experiment-reference sphx-glr-backref-type-py-class"><span class="n">ExtendedReferenceEvaluator</span></a></a></a></a>
<span class="kn">from</span> <span class="nn">experimental_experiment.torch_interpreter</span> <span class="kn">import</span> <a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter sphx-glr-backref-type-py-function"><span class="n">to_onnx</span></a></a></a></a>
<span class="kn">from</span> <span class="nn">experimental_experiment.xbuilder</span> <span class="kn">import</span> <a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/xbuilder/index.html#experimental_experiment.xbuilder.OptimizationOptions" title="experimental_experiment.xbuilder.OptimizationOptions" class="sphx-glr-backref-module-experimental_experiment-xbuilder sphx-glr-backref-type-py-class"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/xbuilder/index.html#experimental_experiment.xbuilder.OptimizationOptions" title="experimental_experiment.xbuilder.OptimizationOptions" class="sphx-glr-backref-module-experimental_experiment-xbuilder sphx-glr-backref-type-py-class"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/xbuilder/index.html#experimental_experiment.xbuilder.OptimizationOptions" title="experimental_experiment.xbuilder.OptimizationOptions" class="sphx-glr-backref-module-experimental_experiment-xbuilder sphx-glr-backref-type-py-class"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/xbuilder/index.html#experimental_experiment.xbuilder.OptimizationOptions" title="experimental_experiment.xbuilder.OptimizationOptions" class="sphx-glr-backref-module-experimental_experiment-xbuilder sphx-glr-backref-type-py-class"><span class="n">OptimizationOptions</span></a></a></a></a>


<span class="k">class</span> <span class="nc">Embedding</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a></a></a></a><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Embedding.html#torch.nn.Embedding" title="torch.nn.Embedding" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Embedding.html#torch.nn.Embedding" title="torch.nn.Embedding" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Embedding.html#torch.nn.Embedding" title="torch.nn.Embedding" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Embedding.html#torch.nn.Embedding" title="torch.nn.Embedding" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span></a></a></a></a><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pe</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Embedding.html#torch.nn.Embedding" title="torch.nn.Embedding" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Embedding.html#torch.nn.Embedding" title="torch.nn.Embedding" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Embedding.html#torch.nn.Embedding" title="torch.nn.Embedding" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Embedding.html#torch.nn.Embedding" title="torch.nn.Embedding" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span></a></a></a></a><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">word_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">word_pe</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pe</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">word_emb</span> <span class="o">+</span> <span class="n">word_pe</span>


<span class="k">class</span> <span class="nc">AttentionBlock</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a></a></a></a><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">context_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">query</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a></a></a></a><span class="p">(</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">key</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a></a></a></a><span class="p">(</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a></a></a></a><span class="p">(</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="n">ones</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/main/generated/torch.ones.html#torch.ones" title="torch.ones" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><a href="https://docs.pytorch.org/docs/main/generated/torch.ones.html#torch.ones" title="torch.ones" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><a href="https://docs.pytorch.org/docs/main/generated/torch.ones.html#torch.ones" title="torch.ones" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><a href="https://docs.pytorch.org/docs/main/generated/torch.ones.html#torch.ones" title="torch.ones" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">ones</span></a></a></a></a><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">[</span><span class="n">context_size</span><span class="p">,</span> <span class="n">context_size</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><a href="https://docs.pytorch.org/docs/main/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch</span><span class="o">.</span><span class="n">float</span></a></a></a></a><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;mask&quot;</span><span class="p">,</span> <span class="n">tensor</span><span class="o">=</span><a href="https://docs.pytorch.org/docs/main/generated/torch.tril.html#torch.tril" title="torch.tril" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><a href="https://docs.pytorch.org/docs/main/generated/torch.tril.html#torch.tril" title="torch.tril" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><a href="https://docs.pytorch.org/docs/main/generated/torch.tril.html#torch.tril" title="torch.tril" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><a href="https://docs.pytorch.org/docs/main/generated/torch.tril.html#torch.tril" title="torch.tril" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">tril</span></a></a></a></a><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">ones</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">B</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">C</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>

        <span class="n">query</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">key</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">value</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">qk</span> <span class="o">=</span> <span class="n">query</span> <span class="o">@</span> <span class="n">key</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">C</span><span class="o">**-</span><span class="mf">0.5</span>
        <span class="n">attention</span> <span class="o">=</span> <span class="n">qk</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="p">[:</span><span class="n">T</span><span class="p">,</span> <span class="p">:</span><span class="n">T</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;-inf&quot;</span><span class="p">))</span>
        <span class="n">attention</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/main/generated/torch.nn.functional.softmax.html#torch.nn.functional.softmax" title="torch.nn.functional.softmax" class="sphx-glr-backref-module-torch-nn-functional sphx-glr-backref-type-py-function"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.functional.softmax.html#torch.nn.functional.softmax" title="torch.nn.functional.softmax" class="sphx-glr-backref-module-torch-nn-functional sphx-glr-backref-type-py-function"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.functional.softmax.html#torch.nn.functional.softmax" title="torch.nn.functional.softmax" class="sphx-glr-backref-module-torch-nn-functional sphx-glr-backref-type-py-function"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.functional.softmax.html#torch.nn.functional.softmax" title="torch.nn.functional.softmax" class="sphx-glr-backref-module-torch-nn-functional sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span></a></a></a></a><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">attention</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim</span></a></a></a></a><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">=</span> <span class="n">attention</span> <span class="o">@</span> <span class="n">value</span>
        <span class="k">return</span> <span class="n">out</span>


<span class="k">class</span> <span class="nc">MultiAttentionBlock</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a></a></a></a><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">context_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/main/generated/torch.nn.ModuleList.html#torch.nn.ModuleList" title="torch.nn.ModuleList" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.ModuleList.html#torch.nn.ModuleList" title="torch.nn.ModuleList" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.ModuleList.html#torch.nn.ModuleList" title="torch.nn.ModuleList" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.ModuleList.html#torch.nn.ModuleList" title="torch.nn.ModuleList" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span></a></a></a></a><span class="p">(</span>
            <span class="n">modules</span><span class="o">=</span><span class="p">[</span><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">AttentionBlock</span></a></a></a></a><span class="p">(</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">context_size</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_heads</span><span class="p">)]</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a></a></a></a><span class="p">(</span>
            <span class="n">in_features</span><span class="o">=</span><span class="n">embedding_dim</span> <span class="o">*</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">embedding_dim</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/main/generated/torch.cat.html#torch.cat" title="torch.cat" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><a href="https://docs.pytorch.org/docs/main/generated/torch.cat.html#torch.cat" title="torch.cat" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><a href="https://docs.pytorch.org/docs/main/generated/torch.cat.html#torch.cat" title="torch.cat" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><a href="https://docs.pytorch.org/docs/main/generated/torch.cat.html#torch.cat" title="torch.cat" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">cat</span></a></a></a></a><span class="p">(</span><span class="n">tensors</span><span class="o">=</span><span class="p">[</span><span class="n">attention</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">attention</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">],</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim</span></a></a></a></a><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>


<span class="k">class</span> <span class="nc">FeedForward</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a></a></a></a><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">ff_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear_1</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a></a></a></a><span class="p">(</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">ff_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/main/generated/torch.nn.ReLU.html#torch.nn.ReLU" title="torch.nn.ReLU" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.ReLU.html#torch.nn.ReLU" title="torch.nn.ReLU" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.ReLU.html#torch.nn.ReLU" title="torch.nn.ReLU" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.ReLU.html#torch.nn.ReLU" title="torch.nn.ReLU" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span></a></a></a></a><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear_2</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a></a></a></a><span class="p">(</span><span class="n">ff_dim</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>


<span class="k">class</span> <span class="nc">DecoderLayer</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a></a></a></a><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">context_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">ff_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">MultiAttentionBlock</span></a></a></a></a><span class="p">(</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">context_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feed_forward</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">FeedForward</span></a></a></a></a><span class="p">(</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">ff_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm_1</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/main/generated/torch.nn.LayerNorm.html#torch.nn.LayerNorm" title="torch.nn.LayerNorm" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.LayerNorm.html#torch.nn.LayerNorm" title="torch.nn.LayerNorm" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.LayerNorm.html#torch.nn.LayerNorm" title="torch.nn.LayerNorm" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.LayerNorm.html#torch.nn.LayerNorm" title="torch.nn.LayerNorm" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span></a></a></a></a><span class="p">(</span><span class="n">normalized_shape</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm_2</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/main/generated/torch.nn.LayerNorm.html#torch.nn.LayerNorm" title="torch.nn.LayerNorm" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.LayerNorm.html#torch.nn.LayerNorm" title="torch.nn.LayerNorm" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.LayerNorm.html#torch.nn.LayerNorm" title="torch.nn.LayerNorm" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.LayerNorm.html#torch.nn.LayerNorm" title="torch.nn.LayerNorm" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span></a></a></a></a><span class="p">(</span><span class="n">normalized_shape</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x_norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">attention</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">x_norm</span><span class="p">)</span>
        <span class="n">attention</span> <span class="o">=</span> <span class="n">attention</span> <span class="o">+</span> <span class="n">x</span>

        <span class="n">attention_norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_2</span><span class="p">(</span><span class="n">attention</span><span class="p">)</span>
        <span class="n">ff</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feed_forward</span><span class="p">(</span><span class="n">attention_norm</span><span class="p">)</span>
        <span class="n">ff</span> <span class="o">=</span> <span class="n">ff</span> <span class="o">+</span> <span class="n">attention</span>

        <span class="k">return</span> <span class="n">ff</span>


<span class="k">class</span> <span class="nc">LLM</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a></a></a></a><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">vocab_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1024</span><span class="p">,</span>
        <span class="n">embedding_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span>
        <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
        <span class="n">context_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span>
        <span class="n">ff_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">Embedding</span></a></a></a></a><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">DecoderLayer</span></a></a></a></a><span class="p">(</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">context_size</span><span class="p">,</span> <span class="n">ff_dim</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_ids</span></a></a></a></a><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_ids</span></a></a></a></a><span class="p">)</span>
        <a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">y</span></a></a></a></a> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">y</span></a></a></a></a>


<span class="n">llm</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">LLM</span></a></a></a></a><span class="p">()</span>
<a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim</span></a></a></a></a> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
<a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_ids</span></a></a></a></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/main/generated/torch.randint.html#torch.randint" title="torch.randint" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><a href="https://docs.pytorch.org/docs/main/generated/torch.randint.html#torch.randint" title="torch.randint" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><a href="https://docs.pytorch.org/docs/main/generated/torch.randint.html#torch.randint" title="torch.randint" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><a href="https://docs.pytorch.org/docs/main/generated/torch.randint.html#torch.randint" title="torch.randint" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">randint</span></a></a></a></a><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim</span></a></a></a></a><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/main/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch</span><span class="o">.</span><span class="n">int64</span></a></a></a></a><span class="p">)</span>
<a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">y</span></a></a></a></a> <span class="o">=</span> <span class="n">llm</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_ids</span></a></a></a></a><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;output: shape=</span><span class="si">{</span><a href="https://docs.pytorch.org/docs/main/size.html#torch.Size" title="torch.Size" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/size.html#torch.Size" title="torch.Size" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/size.html#torch.Size" title="torch.Size" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/size.html#torch.Size" title="torch.Size" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">y</span><span class="o">.</span><span class="n">shape</span></a></a></a></a><span class="si">}</span><span class="s2">, min=</span><span class="si">{</span><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">y</span></a></a></a></a><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="si">}</span><span class="s2">, max=</span><span class="si">{</span><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">y</span></a></a></a></a><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>output: shape=torch.Size([1, 30, 16]), min=-3.806222438812256, max=4.5326056480407715
</pre></div>
</div>
</section>
<section id="first-conversion-to-onnx">
<h2>First conversion to ONNX<a class="headerlink" href="#first-conversion-to-onnx" title="Link to this heading"></a></h2>
<p>The conversion relies on <a class="reference external" href="https://docs.pytorch.org/docs/main/export.html#torch.export.export" title="(in PyTorch vmain (2.8.0a0+gitd5f6422 ))"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.export.export()</span></code></a>.
which gives:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.pytorch.org/docs/main/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ep</span></a></a></a></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/main/export.html#torch.export.export" title="torch.export.export" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-function"><a href="https://docs.pytorch.org/docs/main/export.html#torch.export.export" title="torch.export.export" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-function"><a href="https://docs.pytorch.org/docs/main/export.html#torch.export.export" title="torch.export.export" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-function"><a href="https://docs.pytorch.org/docs/main/export.html#torch.export.export" title="torch.export.export" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">export</span><span class="o">.</span><span class="n">export</span></a></a></a></a><span class="p">(</span><span class="n">llm</span><span class="p">,</span> <span class="p">(</span><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_ids</span></a></a></a></a><span class="p">,))</span>
<span class="nb">print</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/main/export.html#torch.export.ExportedProgram.graph" title="torch.export.ExportedProgram.graph" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-attribute"><a href="https://docs.pytorch.org/docs/main/export.html#torch.export.ExportedProgram.graph" title="torch.export.ExportedProgram.graph" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-attribute"><a href="https://docs.pytorch.org/docs/main/export.html#torch.export.ExportedProgram.graph" title="torch.export.ExportedProgram.graph" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-attribute"><a href="https://docs.pytorch.org/docs/main/export.html#torch.export.ExportedProgram.graph" title="torch.export.ExportedProgram.graph" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-attribute"><span class="n">ep</span><span class="o">.</span><span class="n">graph</span></a></a></a></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>graph():
    %p_embedding_embedding_weight : [num_users=1] = placeholder[target=p_embedding_embedding_weight]
    %p_embedding_pe_weight : [num_users=1] = placeholder[target=p_embedding_pe_weight]
    %p_decoder_attention_attention_0_query_weight : [num_users=1] = placeholder[target=p_decoder_attention_attention_0_query_weight]
    %p_decoder_attention_attention_0_key_weight : [num_users=1] = placeholder[target=p_decoder_attention_attention_0_key_weight]
    %p_decoder_attention_attention_0_value_weight : [num_users=1] = placeholder[target=p_decoder_attention_attention_0_value_weight]
    %p_decoder_attention_attention_1_query_weight : [num_users=1] = placeholder[target=p_decoder_attention_attention_1_query_weight]
    %p_decoder_attention_attention_1_key_weight : [num_users=1] = placeholder[target=p_decoder_attention_attention_1_key_weight]
    %p_decoder_attention_attention_1_value_weight : [num_users=1] = placeholder[target=p_decoder_attention_attention_1_value_weight]
    %p_decoder_attention_linear_weight : [num_users=1] = placeholder[target=p_decoder_attention_linear_weight]
    %p_decoder_attention_linear_bias : [num_users=1] = placeholder[target=p_decoder_attention_linear_bias]
    %p_decoder_feed_forward_linear_1_weight : [num_users=1] = placeholder[target=p_decoder_feed_forward_linear_1_weight]
    %p_decoder_feed_forward_linear_1_bias : [num_users=1] = placeholder[target=p_decoder_feed_forward_linear_1_bias]
    %p_decoder_feed_forward_linear_2_weight : [num_users=1] = placeholder[target=p_decoder_feed_forward_linear_2_weight]
    %p_decoder_feed_forward_linear_2_bias : [num_users=1] = placeholder[target=p_decoder_feed_forward_linear_2_bias]
    %p_decoder_norm_1_weight : [num_users=1] = placeholder[target=p_decoder_norm_1_weight]
    %p_decoder_norm_1_bias : [num_users=1] = placeholder[target=p_decoder_norm_1_bias]
    %p_decoder_norm_2_weight : [num_users=1] = placeholder[target=p_decoder_norm_2_weight]
    %p_decoder_norm_2_bias : [num_users=1] = placeholder[target=p_decoder_norm_2_bias]
    %b_decoder_attention_attention_0_mask : [num_users=1] = placeholder[target=b_decoder_attention_attention_0_mask]
    %b_decoder_attention_attention_1_mask : [num_users=1] = placeholder[target=b_decoder_attention_attention_1_mask]
    %input_ids : [num_users=2] = placeholder[target=input_ids]
    %embedding : [num_users=1] = call_function[target=torch.ops.aten.embedding.default](args = (%p_embedding_embedding_weight, %input_ids), kwargs = {})
    %embedding_1 : [num_users=1] = call_function[target=torch.ops.aten.embedding.default](args = (%p_embedding_pe_weight, %input_ids), kwargs = {})
    %add : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%embedding, %embedding_1), kwargs = {})
    %layer_norm : [num_users=6] = call_function[target=torch.ops.aten.layer_norm.default](args = (%add, [16], %p_decoder_norm_1_weight, %p_decoder_norm_1_bias), kwargs = {})
    %linear : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%layer_norm, %p_decoder_attention_attention_0_query_weight), kwargs = {})
    %linear_1 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%layer_norm, %p_decoder_attention_attention_0_key_weight), kwargs = {})
    %linear_2 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%layer_norm, %p_decoder_attention_attention_0_value_weight), kwargs = {})
    %transpose : [num_users=1] = call_function[target=torch.ops.aten.transpose.int](args = (%linear_1, -2, -1), kwargs = {})
    %matmul : [num_users=1] = call_function[target=torch.ops.aten.matmul.default](args = (%linear, %transpose), kwargs = {})
    %mul : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%matmul, 0.25), kwargs = {})
    %slice_1 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%b_decoder_attention_attention_0_mask, 0, None, 30), kwargs = {})
    %slice_2 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_1, 1, None, 30), kwargs = {})
    %eq : [num_users=1] = call_function[target=torch.ops.aten.eq.Scalar](args = (%slice_2, 0), kwargs = {})
    %masked_fill : [num_users=1] = call_function[target=torch.ops.aten.masked_fill.Scalar](args = (%mul, %eq, -inf), kwargs = {})
    %softmax : [num_users=1] = call_function[target=torch.ops.aten.softmax.int](args = (%masked_fill, -1), kwargs = {})
    %matmul_1 : [num_users=1] = call_function[target=torch.ops.aten.matmul.default](args = (%softmax, %linear_2), kwargs = {})
    %linear_3 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%layer_norm, %p_decoder_attention_attention_1_query_weight), kwargs = {})
    %linear_4 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%layer_norm, %p_decoder_attention_attention_1_key_weight), kwargs = {})
    %linear_5 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%layer_norm, %p_decoder_attention_attention_1_value_weight), kwargs = {})
    %transpose_1 : [num_users=1] = call_function[target=torch.ops.aten.transpose.int](args = (%linear_4, -2, -1), kwargs = {})
    %matmul_2 : [num_users=1] = call_function[target=torch.ops.aten.matmul.default](args = (%linear_3, %transpose_1), kwargs = {})
    %mul_1 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%matmul_2, 0.25), kwargs = {})
    %slice_3 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%b_decoder_attention_attention_1_mask, 0, None, 30), kwargs = {})
    %slice_4 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_3, 1, None, 30), kwargs = {})
    %eq_1 : [num_users=1] = call_function[target=torch.ops.aten.eq.Scalar](args = (%slice_4, 0), kwargs = {})
    %masked_fill_1 : [num_users=1] = call_function[target=torch.ops.aten.masked_fill.Scalar](args = (%mul_1, %eq_1, -inf), kwargs = {})
    %softmax_1 : [num_users=1] = call_function[target=torch.ops.aten.softmax.int](args = (%masked_fill_1, -1), kwargs = {})
    %matmul_3 : [num_users=1] = call_function[target=torch.ops.aten.matmul.default](args = (%softmax_1, %linear_5), kwargs = {})
    %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%matmul_1, %matmul_3], -1), kwargs = {})
    %linear_6 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%cat, %p_decoder_attention_linear_weight, %p_decoder_attention_linear_bias), kwargs = {})
    %add_1 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%linear_6, %add), kwargs = {})
    %layer_norm_1 : [num_users=1] = call_function[target=torch.ops.aten.layer_norm.default](args = (%add_1, [16], %p_decoder_norm_2_weight, %p_decoder_norm_2_bias), kwargs = {})
    %linear_7 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%layer_norm_1, %p_decoder_feed_forward_linear_1_weight, %p_decoder_feed_forward_linear_1_bias), kwargs = {})
    %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%linear_7,), kwargs = {})
    %linear_8 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%relu, %p_decoder_feed_forward_linear_2_weight, %p_decoder_feed_forward_linear_2_bias), kwargs = {})
    %add_2 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%linear_8, %add_1), kwargs = {})
    return (add_2,)
</pre></div>
</div>
<p>Then function <a class="reference internal" href="../api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx"><code class="xref py py-func docutils literal notranslate"><span class="pre">to_onnx</span></code></a>
converts it into ONNX.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx</span></a></a></a></a> <span class="o">=</span> <a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter sphx-glr-backref-type-py-function"><span class="n">to_onnx</span></a></a></a></a><span class="p">(</span><span class="n">llm</span><span class="p">,</span> <span class="p">(</span><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_ids</span></a></a></a></a><span class="p">,))</span>
<span class="nb">print</span><span class="p">(</span><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><span class="n">pretty_onnx</span></a></a></a></a><span class="p">(</span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx</span></a></a></a></a><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>opset: domain=&#39;&#39; version=18
input: name=&#39;input_ids&#39; type=dtype(&#39;int64&#39;) shape=[1, 30]
init: name=&#39;b_decoder_attention_attention_0_mask&#39; type=float32 shape=(256, 256)-- DynamoInterpret.placeholder.0
init: name=&#39;b_decoder_attention_attention_1_mask&#39; type=float32 shape=(256, 256)-- DynamoInterpret.placeholder.0
init: name=&#39;init1_s1_3&#39; type=float32 shape=(1,) -- array([-inf], dtype=float32)-- Opset.make_node.1/Small##Opset.make_node.1/Small
init: name=&#39;_onx_transpose_p_decoder_attention_attention_0_query_weight0&#39; type=float32 shape=(16, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_attention_attention_0_query_weight)##p_decoder_attention_attention_0_query_weight/DynamoInterpret.placeholder.1/P(decoder.attention.attention.0.query.weight)
init: name=&#39;_onx_transpose_p_decoder_attention_attention_0_key_weight0&#39; type=float32 shape=(16, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_attention_attention_0_key_weight)##p_decoder_attention_attention_0_key_weight/DynamoInterpret.placeholder.1/P(decoder.attention.attention.0.key.weight)
init: name=&#39;_onx_transpose_p_decoder_attention_attention_0_value_weight0&#39; type=float32 shape=(16, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_attention_attention_0_value_weight)##p_decoder_attention_attention_0_value_weight/DynamoInterpret.placeholder.1/P(decoder.attention.attention.0.value.weight)
init: name=&#39;_reshape_init1_s_0&#39; type=float32 shape=(1,) -- array([0.25], dtype=float32)-- GraphBuilder.constant_folding.from/fold(init1_s_,init7_s1_1)##init1_s_/shape_type_compute._cast_inputs.1(mul_Tensor)##shape_type_compute._cast_inputs.1(mul_Tensor)##init7_s1_1/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape
init: name=&#39;_reshape_init1_s_20&#39; type=float32 shape=(1,) -- array([0.], dtype=float32)-- GraphBuilder.constant_folding.from/fold(init1_s_2,init7_s1_1)##init1_s_2/shape_type_compute._cast_inputs.0##shape_type_compute._cast_inputs.0##init7_s1_1/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape
init: name=&#39;_onx_transpose_p_decoder_attention_attention_1_query_weight0&#39; type=float32 shape=(16, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_attention_attention_1_query_weight)##p_decoder_attention_attention_1_query_weight/DynamoInterpret.placeholder.1/P(decoder.attention.attention.1.query.weight)
init: name=&#39;_onx_transpose_p_decoder_attention_attention_1_key_weight0&#39; type=float32 shape=(16, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_attention_attention_1_key_weight)##p_decoder_attention_attention_1_key_weight/DynamoInterpret.placeholder.1/P(decoder.attention.attention.1.key.weight)
init: name=&#39;_onx_transpose_p_decoder_attention_attention_1_value_weight0&#39; type=float32 shape=(16, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_attention_attention_1_value_weight)##p_decoder_attention_attention_1_value_weight/DynamoInterpret.placeholder.1/P(decoder.attention.attention.1.value.weight)
init: name=&#39;_reshape_init1_s_02&#39; type=float32 shape=(1,) -- array([0.25], dtype=float32)-- GraphBuilder.constant_folding.from/fold(init1_s_,init7_s1_1)##init1_s_/shape_type_compute._cast_inputs.1(mul_Tensor)##shape_type_compute._cast_inputs.1(mul_Tensor)##init7_s1_1/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape
init: name=&#39;_reshape_init1_s_202&#39; type=float32 shape=(1,) -- array([0.], dtype=float32)-- GraphBuilder.constant_folding.from/fold(init1_s_2,init7_s1_1)##init1_s_2/shape_type_compute._cast_inputs.0##shape_type_compute._cast_inputs.0##init7_s1_1/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape
init: name=&#39;_onx_transpose_p_decoder_attention_linear_weight0&#39; type=float32 shape=(32, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_attention_linear_weight)##p_decoder_attention_linear_weight/DynamoInterpret.placeholder.1/P(decoder.attention.linear.weight)
init: name=&#39;_onx_transpose_p_decoder_feed_forward_linear_1_weight0&#39; type=float32 shape=(16, 128)-- GraphBuilder.constant_folding.from/fold(p_decoder_feed_forward_linear_1_weight)##p_decoder_feed_forward_linear_1_weight/DynamoInterpret.placeholder.1/P(decoder.feed_forward.linear_1.weight)
init: name=&#39;_onx_transpose_p_decoder_feed_forward_linear_2_weight0&#39; type=float32 shape=(128, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_feed_forward_linear_2_weight)##p_decoder_feed_forward_linear_2_weight/DynamoInterpret.placeholder.1/P(decoder.feed_forward.linear_2.weight)
init: name=&#39;init1_s16_&#39; type=float32 shape=(16,)                      -- LayerNormalizationPattern.apply.scale##LayerNormalizationPattern.apply.scale
init: name=&#39;init1_s16_2&#39; type=float32 shape=(16,)                     -- LayerNormalizationPattern.apply.bias##LayerNormalizationPattern.apply.bias
init: name=&#39;SliceSlicePattern_init7_s1_0_start&#39; type=int64 shape=(2,) -- array([0, 0])-- GraphBuilder.constant_folding.from/fold(init7_s1_0)##init7_s1_0/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape
init: name=&#39;SliceSlicePattern_init7_s1_30_end&#39; type=int64 shape=(2,) -- array([30, 30])-- GraphBuilder.constant_folding.from/fold(init7_s1_30)##init7_s1_30/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape
init: name=&#39;SliceSlicePattern_init7_s1_1_axis&#39; type=int64 shape=(2,) -- array([0, 1])-- GraphBuilder.constant_folding.from/fold(init7_s1_0,init7_s1_1)##init7_s1_0/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##init7_s1_1/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape
init: name=&#39;SliceSlicePattern_init7_s1_0_start2&#39; type=int64 shape=(2,) -- array([0, 0])-- GraphBuilder.constant_folding.from/fold(init7_s1_0)##init7_s1_0/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape
init: name=&#39;SliceSlicePattern_init7_s1_30_end2&#39; type=int64 shape=(2,) -- array([30, 30])-- GraphBuilder.constant_folding.from/fold(init7_s1_30)##init7_s1_30/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape
init: name=&#39;SliceSlicePattern_init7_s1_1_axis2&#39; type=int64 shape=(2,) -- array([0, 1])-- GraphBuilder.constant_folding.from/fold(init7_s1_0,init7_s1_1)##init7_s1_0/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##init7_s1_1/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape
init: name=&#39;embedding.embedding.weight&#39; type=float32 shape=(1024, 16) -- DynamoInterpret.placeholder.1/P(embedding.embedding.weight)
init: name=&#39;embedding.pe.weight&#39; type=float32 shape=(1024, 16)        -- DynamoInterpret.placeholder.1/P(embedding.pe.weight)
init: name=&#39;decoder.attention.linear.bias&#39; type=float32 shape=(16,)   -- DynamoInterpret.placeholder.1/P(decoder.attention.linear.bias)
init: name=&#39;decoder.feed_forward.linear_1.bias&#39; type=float32 shape=(128,)-- DynamoInterpret.placeholder.1/P(decoder.feed_forward.linear_1.bias)
init: name=&#39;decoder.feed_forward.linear_2.bias&#39; type=float32 shape=(16,)-- DynamoInterpret.placeholder.1/P(decoder.feed_forward.linear_2.bias)
Gather(embedding.embedding.weight, input_ids) -&gt; embedding
Gather(embedding.pe.weight, input_ids) -&gt; embedding_1
  Add(embedding, embedding_1) -&gt; add
    LayerNormalization(add, init1_s16_, init1_s16_2, axis=-1, epsilon=0.00, stash_type=1) -&gt; _onx_div_sub_add00
      MatMul(_onx_div_sub_add00, _onx_transpose_p_decoder_attention_attention_0_query_weight0) -&gt; linear
MatMul(_onx_div_sub_add00, _onx_transpose_p_decoder_attention_attention_0_key_weight0) -&gt; linear_1
  Transpose(linear_1, perm=[0,2,1]) -&gt; transpose
    MatMul(linear, transpose) -&gt; matmul
      Mul(matmul, _reshape_init1_s_0) -&gt; _onx_mul_matmul0
MatMul(_onx_div_sub_add00, _onx_transpose_p_decoder_attention_attention_0_value_weight0) -&gt; linear_2
Slice(b_decoder_attention_attention_0_mask, SliceSlicePattern_init7_s1_0_start, SliceSlicePattern_init7_s1_30_end, SliceSlicePattern_init7_s1_1_axis) -&gt; slice_2
  Equal(slice_2, _reshape_init1_s_20) -&gt; eq
    Where(eq, init1_s1_3, _onx_mul_matmul0) -&gt; masked_fill
      Softmax(masked_fill, axis=-1) -&gt; softmax
  MatMul(softmax, linear_2) -&gt; matmul_1
MatMul(_onx_div_sub_add00, _onx_transpose_p_decoder_attention_attention_1_query_weight0) -&gt; linear_3
MatMul(_onx_div_sub_add00, _onx_transpose_p_decoder_attention_attention_1_key_weight0) -&gt; linear_4
  Transpose(linear_4, perm=[0,2,1]) -&gt; transpose_1
  MatMul(linear_3, transpose_1) -&gt; matmul_2
    Mul(matmul_2, _reshape_init1_s_02) -&gt; _onx_mul_matmul_20
MatMul(_onx_div_sub_add00, _onx_transpose_p_decoder_attention_attention_1_value_weight0) -&gt; linear_5
Slice(b_decoder_attention_attention_1_mask, SliceSlicePattern_init7_s1_0_start2, SliceSlicePattern_init7_s1_30_end2, SliceSlicePattern_init7_s1_1_axis2) -&gt; slice_4
  Equal(slice_4, _reshape_init1_s_202) -&gt; eq_1
    Where(eq_1, init1_s1_3, _onx_mul_matmul_20) -&gt; masked_fill_1
      Softmax(masked_fill_1, axis=-1) -&gt; softmax_1
  MatMul(softmax_1, linear_5) -&gt; matmul_3
    Concat(matmul_1, matmul_3, axis=-1) -&gt; cat
      MatMul(cat, _onx_transpose_p_decoder_attention_linear_weight0) -&gt; _onx_matmul_cat0
        Add(_onx_matmul_cat0, decoder.attention.linear.bias) -&gt; linear_6
    Add(linear_6, add) -&gt; add_1
      LayerNormalization(add_1, init1_s16_, init1_s16_2, axis=-1, epsilon=0.00, stash_type=1) -&gt; _onx_div_sub_add_100
        MatMul(_onx_div_sub_add_100, _onx_transpose_p_decoder_feed_forward_linear_1_weight0) -&gt; _onx_matmul_layer_norm_10
          Add(_onx_matmul_layer_norm_10, decoder.feed_forward.linear_1.bias) -&gt; linear_7
            Relu(linear_7) -&gt; relu
              MatMul(relu, _onx_transpose_p_decoder_feed_forward_linear_2_weight0) -&gt; _onx_matmul_relu0
                Add(_onx_matmul_relu0, decoder.feed_forward.linear_2.bias) -&gt; linear_8
      Add(linear_8, add_1) -&gt; output_0
output: name=&#39;output_0&#39; type=dtype(&#39;float32&#39;) shape=[1, 30, 16]
</pre></div>
</div>
<p>Lets check there is no discrepancy.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession" title="onnxruntime.capi.onnxruntime_inference_collection.InferenceSession" class="sphx-glr-backref-module-onnxruntime-capi-onnxruntime_inference_collection sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession" title="onnxruntime.capi.onnxruntime_inference_collection.InferenceSession" class="sphx-glr-backref-module-onnxruntime-capi-onnxruntime_inference_collection sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession" title="onnxruntime.capi.onnxruntime_inference_collection.InferenceSession" class="sphx-glr-backref-module-onnxruntime-capi-onnxruntime_inference_collection sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession" title="onnxruntime.capi.onnxruntime_inference_collection.InferenceSession" class="sphx-glr-backref-module-onnxruntime-capi-onnxruntime_inference_collection sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sess</span></a></a></a></a> <span class="o">=</span> <a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession" title="onnxruntime.capi.onnxruntime_inference_collection.InferenceSession" class="sphx-glr-backref-module-onnxruntime-capi-onnxruntime_inference_collection sphx-glr-backref-type-py-class"><a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession" title="onnxruntime.capi.onnxruntime_inference_collection.InferenceSession" class="sphx-glr-backref-module-onnxruntime-capi-onnxruntime_inference_collection sphx-glr-backref-type-py-class"><a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession" title="onnxruntime.capi.onnxruntime_inference_collection.InferenceSession" class="sphx-glr-backref-module-onnxruntime-capi-onnxruntime_inference_collection sphx-glr-backref-type-py-class"><a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession" title="onnxruntime.capi.onnxruntime_inference_collection.InferenceSession" class="sphx-glr-backref-module-onnxruntime-capi-onnxruntime_inference_collection sphx-glr-backref-type-py-class"><span class="n">InferenceSession</span></a></a></a></a><span class="p">(</span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx</span></a></a></a></a><span class="o">.</span><span class="n">SerializeToString</span><span class="p">(),</span> <span class="n">providers</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;CPUExecutionProvider&quot;</span><span class="p">])</span>
<a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">feeds</span></a></a></a></a> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_ids</span></a></a></a></a><span class="o">=</span><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_ids</span></a></a></a></a><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
<a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">got</span></a></a></a></a> <span class="o">=</span> <a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession.run" title="onnxruntime.InferenceSession.run" class="sphx-glr-backref-module-onnxruntime sphx-glr-backref-type-py-method"><a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession.run" title="onnxruntime.InferenceSession.run" class="sphx-glr-backref-module-onnxruntime sphx-glr-backref-type-py-method"><a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession.run" title="onnxruntime.InferenceSession.run" class="sphx-glr-backref-module-onnxruntime sphx-glr-backref-type-py-method"><a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession.run" title="onnxruntime.InferenceSession.run" class="sphx-glr-backref-module-onnxruntime sphx-glr-backref-type-py-method"><span class="n">sess</span><span class="o">.</span><span class="n">run</span></a></a></a></a><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">feeds</span></a></a></a></a><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

<a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">diff</span></a></a></a></a> <span class="o">=</span> <a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/index.html#onnx_diagnostic.helpers.max_diff" title="onnx_diagnostic.helpers.max_diff" class="sphx-glr-backref-module-onnx_diagnostic-helpers sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/index.html#onnx_diagnostic.helpers.max_diff" title="onnx_diagnostic.helpers.max_diff" class="sphx-glr-backref-module-onnx_diagnostic-helpers sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/index.html#onnx_diagnostic.helpers.max_diff" title="onnx_diagnostic.helpers.max_diff" class="sphx-glr-backref-module-onnx_diagnostic-helpers sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/index.html#onnx_diagnostic.helpers.max_diff" title="onnx_diagnostic.helpers.max_diff" class="sphx-glr-backref-module-onnx_diagnostic-helpers sphx-glr-backref-type-py-function"><span class="n">max_diff</span></a></a></a></a><span class="p">(</span><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">y</span></a></a></a></a><span class="p">,</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">got</span></a></a></a></a><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;output: shape=</span><span class="si">{</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">got</span><span class="o">.</span><span class="n">shape</span></a></a></a></a><span class="si">}</span><span class="s2">, min=</span><span class="si">{</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">got</span></a></a></a></a><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="si">}</span><span class="s2">, max=</span><span class="si">{</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">got</span></a></a></a></a><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;max discrepancy=</span><span class="si">{</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">diff</span></a></a></a></a><span class="p">[</span><span class="s1">&#39;abs&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>output: shape=(1, 30, 16), min=-3.806222438812256, max=4.5326056480407715
max discrepancy=4.76837158203125e-07
</pre></div>
</div>
<p>Lets save the ONNX model.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">onnx</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx</span></a></a></a></a><span class="p">,</span> <span class="s2">&quot;plot_exporter_recipes_c_modules.inlined.onnx&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="onnx-with-submodules">
<h2>ONNX with submodules<a class="headerlink" href="#onnx-with-submodules" title="Link to this heading"></a></h2>
<p>Lets produce an ONNX model with submodules.
Function <a class="reference internal" href="../api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx"><code class="xref py py-func docutils literal notranslate"><span class="pre">to_onnx</span></code></a>
is calling the function <a class="reference external" href="https://docs.pytorch.org/docs/main/export.html#torch.export.unflatten.unflatten" title="(in PyTorch vmain (2.8.0a0+gitd5f6422 ))"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.export.unflatten.unflatten()</span></code></a>
under the hood. The fx graph looks like the following.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.pytorch.org/docs/main/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ep</span></a></a></a></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/main/export.html#torch.export.export" title="torch.export.export" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-function"><a href="https://docs.pytorch.org/docs/main/export.html#torch.export.export" title="torch.export.export" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-function"><a href="https://docs.pytorch.org/docs/main/export.html#torch.export.export" title="torch.export.export" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-function"><a href="https://docs.pytorch.org/docs/main/export.html#torch.export.export" title="torch.export.export" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">export</span><span class="o">.</span><span class="n">export</span></a></a></a></a><span class="p">(</span><span class="n">llm</span><span class="p">,</span> <span class="p">(</span><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_ids</span></a></a></a></a><span class="p">,))</span>
<span class="n">unflatten_ep</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/main/export.html#module-torch.export.unflatten" title="torch.export.unflatten" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-module"><a href="https://docs.pytorch.org/docs/main/export.html#module-torch.export.unflatten" title="torch.export.unflatten" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-module"><a href="https://docs.pytorch.org/docs/main/export.html#module-torch.export.unflatten" title="torch.export.unflatten" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-module"><a href="https://docs.pytorch.org/docs/main/export.html#module-torch.export.unflatten" title="torch.export.unflatten" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-module"><span class="n">torch</span><span class="o">.</span><span class="n">export</span><span class="o">.</span><span class="n">unflatten</span></a></a></a></a><span class="p">(</span><a href="https://docs.pytorch.org/docs/main/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ep</span></a></a></a></a><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/main/fx.html#torch.fx.Graph" title="torch.fx.Graph" class="sphx-glr-backref-module-torch-fx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/fx.html#torch.fx.Graph" title="torch.fx.Graph" class="sphx-glr-backref-module-torch-fx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/fx.html#torch.fx.Graph" title="torch.fx.Graph" class="sphx-glr-backref-module-torch-fx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/fx.html#torch.fx.Graph" title="torch.fx.Graph" class="sphx-glr-backref-module-torch-fx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">unflatten_ep</span><span class="o">.</span><span class="n">graph</span></a></a></a></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>graph():
    %input_ids : [num_users=1] = placeholder[target=input_ids]
    %embedding : [num_users=1] = call_module[target=embedding](args = (%input_ids,), kwargs = {})
    %decoder : [num_users=1] = call_module[target=decoder](args = (%embedding,), kwargs = {})
    return (decoder,)
</pre></div>
</div>
<p>The exported graph looks simpler and shows something like:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="n">decoder</span> <span class="p">:</span> <span class="p">[</span><span class="n">num_users</span><span class="o">=</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">call_module</span><span class="p">[</span><span class="n">target</span><span class="o">=</span><span class="n">decoder</span><span class="p">](</span><span class="n">args</span> <span class="o">=</span> <span class="p">(</span><span class="o">%</span><span class="n">embedding</span><span class="p">,),</span> <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{})</span>
</pre></div>
</div>
<p>It preserves the hierarchy but it does not necessarily preserves the signatures
of the initial modules. Thats was not one of our goals.
The tricky part is module called (<em>embedding</em>) is not an instance <code class="docutils literal notranslate"><span class="pre">Embedding</span></code>
but an instance of <a class="reference external" href="https://github.com/pytorch/pytorch/blob/main/torch/export/unflatten.py#L116">InterpreterModule</a>
and contains the fx nodes contributing to the submodule and coming from the
previous graph.</p>
<p>Now the ONNX graph.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx_module</span></a></a></a></a> <span class="o">=</span> <a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter sphx-glr-backref-type-py-function"><span class="n">to_onnx</span></a></a></a></a><span class="p">(</span><span class="n">llm</span><span class="p">,</span> <span class="p">(</span><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_ids</span></a></a></a></a><span class="p">,),</span> <span class="n">export_modules_as_functions</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><span class="n">pretty_onnx</span></a></a></a></a><span class="p">(</span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx_module</span></a></a></a></a><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>opset: domain=&#39;&#39; version=18
opset: domain=&#39;aten_local_function&#39; version=1
input: name=&#39;input_ids&#39; type=dtype(&#39;int64&#39;) shape=[1, 30]
init: name=&#39;embedding.embedding.weight&#39; type=float32 shape=(1024, 16) -- GraphBuilder.make_local_function/from(embedding.embedding.weight)
init: name=&#39;embedding.pe.weight&#39; type=float32 shape=(1024, 16)        -- GraphBuilder.make_local_function/from(embedding.pe.weight)
init: name=&#39;mask&#39; type=float32 shape=(256, 256)                       -- GraphBuilder.make_local_function/from(mask)
init: name=&#39;_onx_transpose_weight0&#39; type=float32 shape=(16, 16)       -- GraphBuilder.make_local_function/from(_onx_transpose_weight0)
init: name=&#39;_onx_transpose_weight02&#39; type=float32 shape=(16, 16)      -- GraphBuilder.make_local_function/from(_onx_transpose_weight02)
init: name=&#39;_onx_transpose_weight03&#39; type=float32 shape=(16, 16)      -- GraphBuilder.make_local_function/from(_onx_transpose_weight03)
init: name=&#39;mask2&#39; type=float32 shape=(256, 256)                      -- GraphBuilder.make_local_function/from(mask2)
init: name=&#39;_onx_transpose_weight04&#39; type=float32 shape=(16, 16)      -- GraphBuilder.make_local_function/from(_onx_transpose_weight04)
init: name=&#39;_onx_transpose_weight022&#39; type=float32 shape=(16, 16)     -- GraphBuilder.make_local_function/from(_onx_transpose_weight022)
init: name=&#39;_onx_transpose_weight032&#39; type=float32 shape=(16, 16)     -- GraphBuilder.make_local_function/from(_onx_transpose_weight032)
init: name=&#39;_onx_transpose_weight05&#39; type=float32 shape=(32, 16)      -- GraphBuilder.make_local_function/from(_onx_transpose_weight05)
init: name=&#39;decoder.feed_forward.linear_1.bias&#39; type=float32 shape=(128,)-- GraphBuilder.make_local_function/from(decoder.feed_forward.linear_1.bias)
init: name=&#39;_onx_transpose_weight06&#39; type=float32 shape=(16, 128)     -- GraphBuilder.make_local_function/from(_onx_transpose_weight06)
init: name=&#39;_onx_transpose_weight023&#39; type=float32 shape=(128, 16)    -- GraphBuilder.make_local_function/from(_onx_transpose_weight023)
Constant(value=[1.0, 1.0,...) -&gt; init1_s16_
Gather(embedding.embedding.weight, input_ids) -&gt; embedding2
Gather(embedding.pe.weight, input_ids) -&gt; pe
  Add(embedding2, pe) -&gt; embedding
Constant(value=[0.0, 0.0,...) -&gt; init1_s16_2
  LayerNormalization(embedding, init1_s16_, init1_s16_2, axis=-1, epsilon=0.00, stash_type=1) -&gt; norm_1
    MatMul(norm_1, _onx_transpose_weight0) -&gt; query
Constant(value=[-inf]) -&gt; init1_s1_
Constant(value=[0.25]) -&gt; _reshape_init1_s_0
Constant(value=[0.0]) -&gt; _reshape_init1_s_20
Constant(value=[0, 0]) -&gt; SliceSlicePattern_init7_s1_0_start
Constant(value=[30, 30]) -&gt; SliceSlicePattern_init7_s1_30_end
Constant(value=[0, 1]) -&gt; SliceSlicePattern_init7_s1_1_axis
  Slice(mask, SliceSlicePattern_init7_s1_0_start, SliceSlicePattern_init7_s1_30_end, SliceSlicePattern_init7_s1_1_axis) -&gt; slice_2
  Equal(slice_2, _reshape_init1_s_20) -&gt; eq
MatMul(norm_1, _onx_transpose_weight02) -&gt; key
  Transpose(key, perm=[0,2,1]) -&gt; transpose
    MatMul(query, transpose) -&gt; matmul
  Mul(matmul, _reshape_init1_s_0) -&gt; _onx_mul_matmul0
  Where(eq, init1_s1_, _onx_mul_matmul0) -&gt; masked_fill
    Softmax(masked_fill, axis=-1) -&gt; softmax
MatMul(norm_1, _onx_transpose_weight03) -&gt; value
  MatMul(softmax, value) -&gt; attention_0
Constant(value=[-inf]) -&gt; init1_s1_2
Constant(value=[0.25]) -&gt; _reshape_init1_s_02
Constant(value=[0.0]) -&gt; _reshape_init1_s_202
Constant(value=[0, 0]) -&gt; SliceSlicePattern_init7_s1_0_start2
Constant(value=[30, 30]) -&gt; SliceSlicePattern_init7_s1_30_end2
Constant(value=[0, 1]) -&gt; SliceSlicePattern_init7_s1_1_axis2
  Slice(mask2, SliceSlicePattern_init7_s1_0_start2, SliceSlicePattern_init7_s1_30_end2, SliceSlicePattern_init7_s1_1_axis2) -&gt; slice_22
  Equal(slice_22, _reshape_init1_s_202) -&gt; eq2
MatMul(norm_1, _onx_transpose_weight04) -&gt; query2
MatMul(norm_1, _onx_transpose_weight022) -&gt; key2
  Transpose(key2, perm=[0,2,1]) -&gt; transpose2
  MatMul(query2, transpose2) -&gt; matmul2
  Mul(matmul2, _reshape_init1_s_02) -&gt; _onx_mul_matmul02
  Where(eq2, init1_s1_2, _onx_mul_matmul02) -&gt; masked_fill2
    Softmax(masked_fill2, axis=-1) -&gt; softmax2
MatMul(norm_1, _onx_transpose_weight032) -&gt; value2
  MatMul(softmax2, value2) -&gt; attention_1
    Concat(attention_0, attention_1, axis=-1) -&gt; cat
      MatMul(cat, _onx_transpose_weight05) -&gt; _onx_matmul_cat0
Constant(value=[0.0656113...) -&gt; bias
  Add(_onx_matmul_cat0, bias) -&gt; attention
    Add(attention, embedding) -&gt; add_1
Constant(value=[1.0, 1.0,...) -&gt; init1_s16_3
Constant(value=[0.0, 0.0,...) -&gt; init1_s16_22
  LayerNormalization(add_1, init1_s16_3, init1_s16_22, axis=-1, epsilon=0.00, stash_type=1) -&gt; norm_2
    MatMul(norm_2, _onx_transpose_weight06) -&gt; _onx_matmul_layer_norm_10
      Add(_onx_matmul_layer_norm_10, decoder.feed_forward.linear_1.bias) -&gt; linear_1
        Relu(linear_1) -&gt; relu
          MatMul(relu, _onx_transpose_weight023) -&gt; _onx_matmul_relu0
Constant(value=[-0.025308...) -&gt; bias2
  Add(_onx_matmul_relu0, bias2) -&gt; feed_forward
    Add(feed_forward, add_1) -&gt; output_0
output: name=&#39;output_0&#39; type=dtype(&#39;float32&#39;) shape=[1, 30, 16]
</pre></div>
</div>
<p>We check again there is no new discrepancies.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession" title="onnxruntime.capi.onnxruntime_inference_collection.InferenceSession" class="sphx-glr-backref-module-onnxruntime-capi-onnxruntime_inference_collection sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession" title="onnxruntime.capi.onnxruntime_inference_collection.InferenceSession" class="sphx-glr-backref-module-onnxruntime-capi-onnxruntime_inference_collection sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession" title="onnxruntime.capi.onnxruntime_inference_collection.InferenceSession" class="sphx-glr-backref-module-onnxruntime-capi-onnxruntime_inference_collection sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession" title="onnxruntime.capi.onnxruntime_inference_collection.InferenceSession" class="sphx-glr-backref-module-onnxruntime-capi-onnxruntime_inference_collection sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sess</span></a></a></a></a> <span class="o">=</span> <a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession" title="onnxruntime.capi.onnxruntime_inference_collection.InferenceSession" class="sphx-glr-backref-module-onnxruntime-capi-onnxruntime_inference_collection sphx-glr-backref-type-py-class"><a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession" title="onnxruntime.capi.onnxruntime_inference_collection.InferenceSession" class="sphx-glr-backref-module-onnxruntime-capi-onnxruntime_inference_collection sphx-glr-backref-type-py-class"><a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession" title="onnxruntime.capi.onnxruntime_inference_collection.InferenceSession" class="sphx-glr-backref-module-onnxruntime-capi-onnxruntime_inference_collection sphx-glr-backref-type-py-class"><a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession" title="onnxruntime.capi.onnxruntime_inference_collection.InferenceSession" class="sphx-glr-backref-module-onnxruntime-capi-onnxruntime_inference_collection sphx-glr-backref-type-py-class"><span class="n">InferenceSession</span></a></a></a></a><span class="p">(</span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx_module</span></a></a></a></a><span class="o">.</span><span class="n">SerializeToString</span><span class="p">(),</span> <span class="n">providers</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;CPUExecutionProvider&quot;</span><span class="p">])</span>
<a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">feeds</span></a></a></a></a> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_ids</span></a></a></a></a><span class="o">=</span><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_ids</span></a></a></a></a><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
<a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">got</span></a></a></a></a> <span class="o">=</span> <a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession.run" title="onnxruntime.InferenceSession.run" class="sphx-glr-backref-module-onnxruntime sphx-glr-backref-type-py-method"><a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession.run" title="onnxruntime.InferenceSession.run" class="sphx-glr-backref-module-onnxruntime sphx-glr-backref-type-py-method"><a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession.run" title="onnxruntime.InferenceSession.run" class="sphx-glr-backref-module-onnxruntime sphx-glr-backref-type-py-method"><a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession.run" title="onnxruntime.InferenceSession.run" class="sphx-glr-backref-module-onnxruntime sphx-glr-backref-type-py-method"><span class="n">sess</span><span class="o">.</span><span class="n">run</span></a></a></a></a><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">feeds</span></a></a></a></a><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

<a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">diff</span></a></a></a></a> <span class="o">=</span> <a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/index.html#onnx_diagnostic.helpers.max_diff" title="onnx_diagnostic.helpers.max_diff" class="sphx-glr-backref-module-onnx_diagnostic-helpers sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/index.html#onnx_diagnostic.helpers.max_diff" title="onnx_diagnostic.helpers.max_diff" class="sphx-glr-backref-module-onnx_diagnostic-helpers sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/index.html#onnx_diagnostic.helpers.max_diff" title="onnx_diagnostic.helpers.max_diff" class="sphx-glr-backref-module-onnx_diagnostic-helpers sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/index.html#onnx_diagnostic.helpers.max_diff" title="onnx_diagnostic.helpers.max_diff" class="sphx-glr-backref-module-onnx_diagnostic-helpers sphx-glr-backref-type-py-function"><span class="n">max_diff</span></a></a></a></a><span class="p">(</span><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">y</span></a></a></a></a><span class="p">,</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">got</span></a></a></a></a><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;output: shape=</span><span class="si">{</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">got</span><span class="o">.</span><span class="n">shape</span></a></a></a></a><span class="si">}</span><span class="s2">, min=</span><span class="si">{</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">got</span></a></a></a></a><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="si">}</span><span class="s2">, max=</span><span class="si">{</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">got</span></a></a></a></a><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;max discrepancy=</span><span class="si">{</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">diff</span></a></a></a></a><span class="p">[</span><span class="s1">&#39;abs&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>output: shape=(1, 30, 16), min=-3.806222438812256, max=4.5326056480407715
max discrepancy=4.76837158203125e-07
</pre></div>
</div>
<p>Lets save the ONNX model.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">onnx</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx_module</span></a></a></a></a><span class="p">,</span> <span class="s2">&quot;plot_exporter_recipes_c_modules.module.onnx&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>And visually.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://sdpython.github.io/doc/onnx-array-api/dev/api/plotting.html#onnx_array_api.plotting.graphviz_helper.plot_dot" title="onnx_array_api.plotting.graphviz_helper.plot_dot" class="sphx-glr-backref-module-onnx_array_api-plotting-graphviz_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-array-api/dev/api/plotting.html#onnx_array_api.plotting.graphviz_helper.plot_dot" title="onnx_array_api.plotting.graphviz_helper.plot_dot" class="sphx-glr-backref-module-onnx_array_api-plotting-graphviz_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-array-api/dev/api/plotting.html#onnx_array_api.plotting.graphviz_helper.plot_dot" title="onnx_array_api.plotting.graphviz_helper.plot_dot" class="sphx-glr-backref-module-onnx_array_api-plotting-graphviz_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-array-api/dev/api/plotting.html#onnx_array_api.plotting.graphviz_helper.plot_dot" title="onnx_array_api.plotting.graphviz_helper.plot_dot" class="sphx-glr-backref-module-onnx_array_api-plotting-graphviz_helper sphx-glr-backref-type-py-function"><span class="n">plot_dot</span></a></a></a></a><span class="p">(</span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx_module</span></a></a></a></a><span class="p">)</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_plot_exporter_recipes_c_modules_001.png" srcset="../_images/sphx_glr_plot_exporter_recipes_c_modules_001.png" alt="plot exporter recipes c modules" class = "sphx-glr-single-img"/></section>
<section id="inlining">
<h2>Inlining<a class="headerlink" href="#inlining" title="Link to this heading"></a></h2>
<p>The ONNX graph can still be inline after this.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx_inlined</span></a></a></a></a> <span class="o">=</span> <a href="https://onnx.ai/onnx/api/inliner.html#onnx.inliner.inline_local_functions" title="onnx.inliner.inline_local_functions" class="sphx-glr-backref-module-onnx-inliner sphx-glr-backref-type-py-function"><a href="https://onnx.ai/onnx/api/inliner.html#onnx.inliner.inline_local_functions" title="onnx.inliner.inline_local_functions" class="sphx-glr-backref-module-onnx-inliner sphx-glr-backref-type-py-function"><a href="https://onnx.ai/onnx/api/inliner.html#onnx.inliner.inline_local_functions" title="onnx.inliner.inline_local_functions" class="sphx-glr-backref-module-onnx-inliner sphx-glr-backref-type-py-function"><a href="https://onnx.ai/onnx/api/inliner.html#onnx.inliner.inline_local_functions" title="onnx.inliner.inline_local_functions" class="sphx-glr-backref-module-onnx-inliner sphx-glr-backref-type-py-function"><span class="n">inline_local_functions</span></a></a></a></a><span class="p">(</span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx_module</span></a></a></a></a><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><span class="n">pretty_onnx</span></a></a></a></a><span class="p">(</span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx_inlined</span></a></a></a></a><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>opset: domain=&#39;&#39; version=18
opset: domain=&#39;aten_local_function&#39; version=1
input: name=&#39;input_ids&#39; type=dtype(&#39;int64&#39;) shape=[1, 30]
init: name=&#39;embedding.embedding.weight&#39; type=float32 shape=(1024, 16) -- GraphBuilder.make_local_function/from(embedding.embedding.weight)
init: name=&#39;embedding.pe.weight&#39; type=float32 shape=(1024, 16)        -- GraphBuilder.make_local_function/from(embedding.pe.weight)
init: name=&#39;mask&#39; type=float32 shape=(256, 256)                       -- GraphBuilder.make_local_function/from(mask)
init: name=&#39;_onx_transpose_weight0&#39; type=float32 shape=(16, 16)       -- GraphBuilder.make_local_function/from(_onx_transpose_weight0)
init: name=&#39;_onx_transpose_weight02&#39; type=float32 shape=(16, 16)      -- GraphBuilder.make_local_function/from(_onx_transpose_weight02)
init: name=&#39;_onx_transpose_weight03&#39; type=float32 shape=(16, 16)      -- GraphBuilder.make_local_function/from(_onx_transpose_weight03)
init: name=&#39;mask2&#39; type=float32 shape=(256, 256)                      -- GraphBuilder.make_local_function/from(mask2)
init: name=&#39;_onx_transpose_weight04&#39; type=float32 shape=(16, 16)      -- GraphBuilder.make_local_function/from(_onx_transpose_weight04)
init: name=&#39;_onx_transpose_weight022&#39; type=float32 shape=(16, 16)     -- GraphBuilder.make_local_function/from(_onx_transpose_weight022)
init: name=&#39;_onx_transpose_weight032&#39; type=float32 shape=(16, 16)     -- GraphBuilder.make_local_function/from(_onx_transpose_weight032)
init: name=&#39;_onx_transpose_weight05&#39; type=float32 shape=(32, 16)      -- GraphBuilder.make_local_function/from(_onx_transpose_weight05)
init: name=&#39;decoder.feed_forward.linear_1.bias&#39; type=float32 shape=(128,)-- GraphBuilder.make_local_function/from(decoder.feed_forward.linear_1.bias)
init: name=&#39;_onx_transpose_weight06&#39; type=float32 shape=(16, 128)     -- GraphBuilder.make_local_function/from(_onx_transpose_weight06)
init: name=&#39;_onx_transpose_weight023&#39; type=float32 shape=(128, 16)    -- GraphBuilder.make_local_function/from(_onx_transpose_weight023)
Constant(value=[1.0, 1.0,...) -&gt; init1_s16_
Gather(embedding.embedding.weight, input_ids) -&gt; embedding2
Gather(embedding.pe.weight, input_ids) -&gt; pe
  Add(embedding2, pe) -&gt; embedding
Constant(value=[0.0, 0.0,...) -&gt; init1_s16_2
  LayerNormalization(embedding, init1_s16_, init1_s16_2, axis=-1, epsilon=0.00, stash_type=1) -&gt; norm_1
    MatMul(norm_1, _onx_transpose_weight0) -&gt; query
Constant(value=[-inf]) -&gt; init1_s1_
Constant(value=[0.25]) -&gt; _reshape_init1_s_0
Constant(value=[0.0]) -&gt; _reshape_init1_s_20
Constant(value=[0, 0]) -&gt; SliceSlicePattern_init7_s1_0_start
Constant(value=[30, 30]) -&gt; SliceSlicePattern_init7_s1_30_end
Constant(value=[0, 1]) -&gt; SliceSlicePattern_init7_s1_1_axis
  Slice(mask, SliceSlicePattern_init7_s1_0_start, SliceSlicePattern_init7_s1_30_end, SliceSlicePattern_init7_s1_1_axis) -&gt; slice_2
  Equal(slice_2, _reshape_init1_s_20) -&gt; eq
MatMul(norm_1, _onx_transpose_weight02) -&gt; key
  Transpose(key, perm=[0,2,1]) -&gt; transpose
    MatMul(query, transpose) -&gt; matmul
  Mul(matmul, _reshape_init1_s_0) -&gt; _onx_mul_matmul0
  Where(eq, init1_s1_, _onx_mul_matmul0) -&gt; masked_fill
    Softmax(masked_fill, axis=-1) -&gt; softmax
MatMul(norm_1, _onx_transpose_weight03) -&gt; value
  MatMul(softmax, value) -&gt; attention_0
Constant(value=[-inf]) -&gt; init1_s1_2
Constant(value=[0.25]) -&gt; _reshape_init1_s_02
Constant(value=[0.0]) -&gt; _reshape_init1_s_202
Constant(value=[0, 0]) -&gt; SliceSlicePattern_init7_s1_0_start2
Constant(value=[30, 30]) -&gt; SliceSlicePattern_init7_s1_30_end2
Constant(value=[0, 1]) -&gt; SliceSlicePattern_init7_s1_1_axis2
  Slice(mask2, SliceSlicePattern_init7_s1_0_start2, SliceSlicePattern_init7_s1_30_end2, SliceSlicePattern_init7_s1_1_axis2) -&gt; slice_22
  Equal(slice_22, _reshape_init1_s_202) -&gt; eq2
MatMul(norm_1, _onx_transpose_weight04) -&gt; query2
MatMul(norm_1, _onx_transpose_weight022) -&gt; key2
  Transpose(key2, perm=[0,2,1]) -&gt; transpose2
  MatMul(query2, transpose2) -&gt; matmul2
  Mul(matmul2, _reshape_init1_s_02) -&gt; _onx_mul_matmul02
  Where(eq2, init1_s1_2, _onx_mul_matmul02) -&gt; masked_fill2
    Softmax(masked_fill2, axis=-1) -&gt; softmax2
MatMul(norm_1, _onx_transpose_weight032) -&gt; value2
  MatMul(softmax2, value2) -&gt; attention_1
    Concat(attention_0, attention_1, axis=-1) -&gt; cat
      MatMul(cat, _onx_transpose_weight05) -&gt; _onx_matmul_cat0
Constant(value=[0.0656113...) -&gt; bias
  Add(_onx_matmul_cat0, bias) -&gt; attention
    Add(attention, embedding) -&gt; add_1
Constant(value=[1.0, 1.0,...) -&gt; init1_s16_3
Constant(value=[0.0, 0.0,...) -&gt; init1_s16_22
  LayerNormalization(add_1, init1_s16_3, init1_s16_22, axis=-1, epsilon=0.00, stash_type=1) -&gt; norm_2
    MatMul(norm_2, _onx_transpose_weight06) -&gt; _onx_matmul_layer_norm_10
      Add(_onx_matmul_layer_norm_10, decoder.feed_forward.linear_1.bias) -&gt; linear_1
        Relu(linear_1) -&gt; relu
          MatMul(relu, _onx_transpose_weight023) -&gt; _onx_matmul_relu0
Constant(value=[-0.025308...) -&gt; bias2
  Add(_onx_matmul_relu0, bias2) -&gt; feed_forward
    Add(feed_forward, add_1) -&gt; output_0
output: name=&#39;output_0&#39; type=dtype(&#39;float32&#39;) shape=[1, 30, 16]
</pre></div>
</div>
</section>
<section id="optimizations">
<h2>Optimizations<a class="headerlink" href="#optimizations" title="Link to this heading"></a></h2>
<p>The ONNX graph produced by the exporter without any optimization is very verbose
and less efficient. Thats why some optimizations are made to the model by default.
It is also possible to introduce kernels implemented in <a class="reference external" href="https://onnxruntime.ai/">onnxruntime</a>.
Lets how it goes.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx_optimized</span></a></a></a></a> <span class="o">=</span> <a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter sphx-glr-backref-type-py-function"><span class="n">to_onnx</span></a></a></a></a><span class="p">(</span>
    <span class="n">llm</span><span class="p">,</span>
    <span class="p">(</span><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_ids</span></a></a></a></a><span class="p">,),</span>
    <span class="n">options</span><span class="o">=</span><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/xbuilder/index.html#experimental_experiment.xbuilder.OptimizationOptions" title="experimental_experiment.xbuilder.OptimizationOptions" class="sphx-glr-backref-module-experimental_experiment-xbuilder sphx-glr-backref-type-py-class"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/xbuilder/index.html#experimental_experiment.xbuilder.OptimizationOptions" title="experimental_experiment.xbuilder.OptimizationOptions" class="sphx-glr-backref-module-experimental_experiment-xbuilder sphx-glr-backref-type-py-class"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/xbuilder/index.html#experimental_experiment.xbuilder.OptimizationOptions" title="experimental_experiment.xbuilder.OptimizationOptions" class="sphx-glr-backref-module-experimental_experiment-xbuilder sphx-glr-backref-type-py-class"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/xbuilder/index.html#experimental_experiment.xbuilder.OptimizationOptions" title="experimental_experiment.xbuilder.OptimizationOptions" class="sphx-glr-backref-module-experimental_experiment-xbuilder sphx-glr-backref-type-py-class"><span class="n">OptimizationOptions</span></a></a></a></a><span class="p">(</span>
        <span class="n">patterns</span><span class="o">=</span><span class="s2">&quot;default+onnxruntime&quot;</span><span class="p">,</span> <span class="n">constant_folding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span>
    <span class="p">),</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><span class="n">pretty_onnx</span></a></a></a></a><span class="p">(</span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx_optimized</span></a></a></a></a><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[GraphBuilder-ZWA.optimize] start with 73 nodes
[GraphBuilder-ZWA.optimize] #patterns=66
[GraphBuilder-ZWA.remove_unused] remove_initializer 1:1/47:embedding.embedding.weight:torch.float32[torch.Size([1024, 16])]
[GraphBuilder-ZWA.remove_unused] remove_initializer 2:3/47:embedding.pe.weight:torch.float32[torch.Size([1024, 16])]
[GraphBuilder-ZWA.remove_unused] remove_initializer 3:5/47:decoder.attention.attention.0.query.weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-ZWA.remove_unused] remove_initializer 4:7/47:decoder.attention.attention.0.key.weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-ZWA.remove_unused] remove_initializer 5:9/47:decoder.attention.attention.0.value.weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-ZWA.remove_unused] remove_initializer 6:11/47:decoder.attention.attention.1.query.weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-ZWA.remove_unused] remove_initializer 7:13/47:decoder.attention.attention.1.key.weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-ZWA.remove_unused] remove_initializer 8:15/47:decoder.attention.attention.1.value.weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-ZWA.remove_unused] remove_initializer 9:17/47:decoder.attention.linear.weight:torch.float32[torch.Size([16, 32])]
[GraphBuilder-ZWA.remove_unused] remove_initializer 10:19/47:decoder.attention.linear.bias:torch.float32[torch.Size([16])]
[GraphBuilder-ZWA.remove_unused] remove_initializer 11:21/47:decoder.feed_forward.linear_1.weight:torch.float32[torch.Size([128, 16])]
[GraphBuilder-ZWA.remove_unused] remove_initializer 12:23/47:decoder.feed_forward.linear_1.bias:torch.float32[torch.Size([128])]
[GraphBuilder-ZWA.remove_unused] remove_initializer 13:25/47:decoder.feed_forward.linear_2.weight:torch.float32[torch.Size([16, 128])]
[GraphBuilder-ZWA.remove_unused] remove_initializer 14:27/47:decoder.feed_forward.linear_2.bias:torch.float32[torch.Size([16])]
[GraphBuilder-ZWA.remove_unused] remove_initializer 15:29/47:decoder.norm_1.weight:torch.float32[torch.Size([16])]
[GraphBuilder-ZWA.remove_unused] remove_initializer 16:31/47:decoder.norm_1.bias:torch.float32[torch.Size([16])]
[GraphBuilder-ZWA.remove_unused] remove_initializer 17:33/47:decoder.norm_2.weight:torch.float32[torch.Size([16])]
[GraphBuilder-ZWA.remove_unused] remove_initializer 18:35/47:decoder.norm_2.bias:torch.float32[torch.Size([16])]
[GraphBuilder-ZWA.remove_unused] remove_initializer 1:2/46:p_decoder_attention_attention_0_query_weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-ZWA.remove_unused] remove_initializer 2:3/46:p_decoder_attention_attention_0_key_weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-ZWA.remove_unused] remove_initializer 3:4/46:p_decoder_attention_attention_0_value_weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-ZWA.remove_unused] remove_initializer 4:5/46:p_decoder_attention_attention_1_query_weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-ZWA.remove_unused] remove_initializer 5:6/46:p_decoder_attention_attention_1_key_weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-ZWA.remove_unused] remove_initializer 6:7/46:p_decoder_attention_attention_1_value_weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-ZWA.remove_unused] remove_initializer 7:8/46:p_decoder_attention_linear_weight:torch.float32[torch.Size([16, 32])]
[GraphBuilder-ZWA.remove_unused] remove_initializer 8:10/46:p_decoder_feed_forward_linear_1_weight:torch.float32[torch.Size([128, 16])]
[GraphBuilder-ZWA.remove_unused] remove_initializer 9:12/46:p_decoder_feed_forward_linear_2_weight:torch.float32[torch.Size([16, 128])]
[GraphBuilder-ZWA.remove_unused] remove_initializer 10:18/46:b_decoder_attention_attention_0_mask:torch.float32[torch.Size([256, 256])]
[GraphBuilder-ZWA.remove_unused] remove_initializer 11:19/46:b_decoder_attention_attention_1_mask:torch.float32[torch.Size([256, 256])]
[GraphBuilder-ZWA.remove_unused] remove_initializer 12:23/46:init1_s_:float32[()]
[GraphBuilder-ZWA.remove_unused] remove_initializer 13:24/46:init7_s1_1:int64[(1,)]
[GraphBuilder-ZWA.remove_unused] remove_initializer 14:25/46:init7_s1_0:int64[(1,)]
[GraphBuilder-ZWA.remove_unused] remove_initializer 15:26/46:init7_s1_30:int64[(1,)]
[GraphBuilder-ZWA.remove_unused] remove_initializer 16:27/46:init1_s_2:float32[()]
[GraphBuilder-ZWA.remove_unused] remove_initializer 17:33/46:slice_1:torch.float32[torch.Size([30, 256])]
[GraphBuilder-ZWA.remove_unused] remove_initializer 18:40/46:slice_3:torch.float32[torch.Size([30, 256])]
[GraphBuilderPatternOptimization-ZWA.optimize] start with 53 nodes, 28 initializers, 66 patterns, priorities=[0, 1, 2, 3]
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern   1/66 - P0 - BatchNormalizationPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern   2/66 - P0 - BatchNormalizationTrainingPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern   3/66 - P0 - CastPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern   4/66 - P0 - ConvBiasNullPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern   5/66 - P0 - ExpandPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern   6/66 - P0 - GeluErfPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern   7/66 - P0 - GeluOrtPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern   8/66 - P0 - GeluPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern   9/66 - P0 - IdentityPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  10/66 - P0 - LeakyReluPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  11/66 - P0 - ReshapePattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  12/66 - P0 - ReshapeReshapePattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  13/66 - P0 - SameChildrenPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  14/66 - P0 - SoftmaxCrossEntropyLossCastPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  15/66 - P0 - SqueezeUnsqueezePattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  16/66 - P0 - TransposeReshapeTransposePattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  17/66 - P0 - TransposeTransposePattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  18/66 - P0 - UnsqueezeUnsqueezePattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  19/66 - P1 - BiasGeluPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  20/66 - P1 - BiasSoftmaxPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  21/66 - P1 - CastCastBinaryPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  22/66 - P1 - CastLayerNormalizationCastPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  23/66 - P1 - CastOpCastPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  24/66 - P1 - ClipClipPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  25/66 - P1 - ComputationCastOpCastPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  26/66 - P1 - DropoutPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  27/66 - P1 - ExpandBroadcastPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  28/66 - P1 - ExpandSwapPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  29/66 - P1 - FastGeluPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  30/66 - P1 - GemmTransposePattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  31/66 - P1 - LayerNormalizationPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  32/66 - P1 - LayerNormalizationScalePattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  33/66 - P1 - MatMulReshape2Of3Pattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  34/66 - P1 - MulMulMatMulPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  35/66 - P1 - MulMulMulScalarPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  36/66 - P1 - OrtBatchNormalizationTrainingPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  37/66 - P1 - QuickGeluPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  38/66 - P1 - ReduceReshapePattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  39/66 - P1 - ReduceSumNormalizePattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  40/66 - P1 - Reshape2Of3Pattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  41/66 - P1 - ReshapeMatMulReshapePattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  42/66 - P1 - ReshapeReshapeBinaryPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  43/66 - P1 - RotaryConcatPartPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  44/66 - P1 - SequenceConstructAtPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  45/66 - P1 - SimplifiedLayerNormalizationPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  46/66 - P1 - SkipLayerNormalizationPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  47/66 - P1 - SliceSlicePattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  48/66 - P1 - SlicesSplitPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  49/66 - P1 - SoftmaxGradPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  50/66 - P1 - SplitConcatPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  51/66 - P1 - Sub1MulPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  52/66 - P1 - SwitchOrderBinaryPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  53/66 - P1 - SwitchReshapeActivationPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  54/66 - P1 - TransposeEqualReshapePattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  55/66 - P1 - TransposeMatMulPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  56/66 - P1 - TransposeReshapeMatMulPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  57/66 - P1 - UnsqueezeEqualPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  58/66 - P2 - FusedConvPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  59/66 - P2 - FusedMatMulDivPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  60/66 - P2 - FusedMatMulPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  61/66 - P3 - AttentionPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  62/66 - P3 - FusedMatMulTransposePattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  63/66 - P3 - FusedMatMulx2Pattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  64/66 - P3 - MatMulAddPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  65/66 - P3 - ReshapeGemmPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] use pattern  66/66 - P3 - TransposeFusedMatMulBPattern()
[GraphBuilderPatternOptimization-ZWA.optimize] iteration 0: 53 nodes, priority=0
[GraphBuilderPatternOptimization-ZWA.optimize] applies 6 matches, 2*CastPattern, 4*IdentityPattern - time=0.006 | max_time=SoftmaxCrossEntropyLossCastPattern:0.002
[GraphBuilderPatternOptimization-ZWA.optimize] iteration 1: 47 nodes, priority=0
[GraphBuilderPatternOptimization-ZWA.optimize] increase priority to 1
[GraphBuilderPatternOptimization-ZWA.optimize] iteration 2: 47 nodes, priority=1
[GraphBuilderPatternOptimization-ZWA.optimize] applies 2 matches, 2*LayerNormalizationPattern - time=0.004 | max_time=IdentityPattern:0.000
[GraphBuilderPatternOptimization-ZWA.optimize] iteration 3: 35 nodes, priority=1
[GraphBuilderPatternOptimization-ZWA.optimize] applies 2 matches, 2*SkipLayerNormalizationPattern - time=0.003 | max_time=IdentityPattern:0.000
[GraphBuilderPatternOptimization-ZWA.optimize] iteration 4: 33 nodes, priority=1
[GraphBuilderPatternOptimization-ZWA.optimize] increase priority to 2
[GraphBuilderPatternOptimization-ZWA.optimize] iteration 5: 33 nodes, priority=2
[GraphBuilderPatternOptimization-ZWA.optimize] applies 2 matches, 2*FusedMatMulPattern - time=0.003 | max_time=IdentityPattern:0.000
[GraphBuilderPatternOptimization-ZWA.optimize] iteration 6: 29 nodes, priority=2
[GraphBuilderPatternOptimization-ZWA.optimize] increase priority to 3
[GraphBuilderPatternOptimization-ZWA.optimize] iteration 7: 29 nodes, priority=3
[GraphBuilderPatternOptimization-ZWA.optimize] stops current_priority_index=4, priorities=[0, 1, 2, 3]
[GraphBuilderPatternOptimization-ZWA.optimize] done after 8 iterations with 29 nodes in 0.033
    STAT apply_CastPattern +2 -2 #it=1 maxmatch=1 i=2 - time=0.000173841996002011
    STAT apply_FusedMatMulPattern +2 -6 #it=1 maxmatch=1 i=2 - time=0.00043014800030505285
    STAT apply_IdentityPattern +4 -4 #it=1 maxmatch=5 i=4 - time=0.00024007700267247856
    STAT apply_LayerNormalizationPattern +2 -14 #it=1 maxmatch=1 i=2 - time=0.00044869499834021553
    STAT apply_SkipLayerNormalizationPattern +2 -4 #it=1 maxmatch=1 i=2 - time=0.00013733400555793196
    STAT build_graph_for_pattern +0 -0 #it=8 maxmatch=0 i=0 - time=0.0014058530068723485
    STAT check_pattern_00 +0 -0 #it=1 maxmatch=0 i=0 - time=0.0001476519973948598
    STAT check_pattern_A0 +0 -0 #it=4 maxmatch=0 i=0 - time=0.0012261480078450404
    STAT check_pattern_B0 +0 -0 #it=3 maxmatch=0 i=0 - time=0.00028686600126093253
    STAT match_AttentionPattern +0 -0 #it=1 maxmatch=0 i=0 - time=2.561399742262438e-05
    STAT match_BatchNormalizationPattern +0 -0 #it=8 maxmatch=0 i=0 - time=0.0002683900165720843
    STAT match_BatchNormalizationTrainingPattern +0 -0 #it=8 maxmatch=0 i=0 - time=0.00021369899332057685
    STAT match_BiasGeluPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00013751999358646572
    STAT match_BiasSoftmaxPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00012267099373275414
    STAT match_CastCastBinaryPattern +0 -0 #it=6 maxmatch=0 i=0 - time=0.00042915101221296936
    STAT match_CastLayerNormalizationCastPattern +0 -0 #it=6 maxmatch=0 i=0 - time=0.0002062719941022806
    STAT match_CastOpCastPattern +0 -0 #it=6 maxmatch=0 i=0 - time=0.00039391099562635645
    STAT match_CastPattern +0 -0 #it=8 maxmatch=2 i=2 - time=0.0002374749892624095
    STAT match_ClipClipPattern +0 -0 #it=6 maxmatch=0 i=0 - time=0.00014003500109538436
    STAT match_ComputationCastOpCastPattern +0 -0 #it=6 maxmatch=0 i=0 - time=0.00023889500880613923
    STAT match_ConvBiasNullPattern +0 -0 #it=8 maxmatch=2 i=0 - time=0.00020226900232955813
    STAT match_DropoutPattern +0 -0 #it=6 maxmatch=0 i=0 - time=0.00012630200217245147
    STAT match_ExpandBroadcastPattern +0 -0 #it=6 maxmatch=0 i=0 - time=0.0001336939967586659
    STAT match_ExpandPattern +0 -0 #it=8 maxmatch=2 i=0 - time=0.0001983599941013381
    STAT match_ExpandSwapPattern +0 -0 #it=6 maxmatch=0 i=0 - time=0.00012818598770536482
    STAT match_FastGeluPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00013789199147140607
    STAT match_FusedConvPattern +0 -0 #it=3 maxmatch=0 i=0 - time=6.229200516827404e-05
    STAT match_FusedMatMulDivPattern +0 -0 #it=3 maxmatch=2 i=0 - time=0.00018165100482292473
    STAT match_FusedMatMulPattern +0 -0 #it=3 maxmatch=2 i=2 - time=0.00036033200012752786
    STAT match_FusedMatMulTransposePattern +0 -0 #it=1 maxmatch=0 i=0 - time=6.089899397920817e-05
    STAT match_FusedMatMulx2Pattern +0 -0 #it=1 maxmatch=0 i=0 - time=5.9845006035175174e-05
    STAT match_GeluErfPattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.0017957130112336017
    STAT match_GeluOrtPattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.0026028189895441756
    STAT match_GeluPattern +0 -0 #it=8 maxmatch=2 i=0 - time=6.459995347540826e-06
    STAT match_GemmTransposePattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0001596389920450747
    STAT match_IdentityPattern +0 -0 #it=8 maxmatch=6 i=4 - time=0.00223082799493568
    STAT match_LayerNormalizationPattern +0 -0 #it=6 maxmatch=2 i=2 - time=0.00026810899726115167
    STAT match_LayerNormalizationScalePattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0001514590039732866
    STAT match_LeakyReluPattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.002048662005108781
    STAT match_MatMulAddPattern +0 -0 #it=1 maxmatch=0 i=0 - time=5.953899380983785e-05
    STAT match_MatMulReshape2Of3Pattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0006744000129401684
    STAT match_MulMulMatMulPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0003577850147848949
    STAT match_MulMulMulScalarPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0002119630080414936
    STAT match_OrtBatchNormalizationTrainingPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0002014479978242889
    STAT match_QuickGeluPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00013585301348939538
    STAT match_ReduceReshapePattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00018921001174021512
    STAT match_ReduceSumNormalizePattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00018153598648495972
    STAT match_Reshape2Of3Pattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0004234040097799152
    STAT match_ReshapeGemmPattern +0 -0 #it=1 maxmatch=0 i=0 - time=2.0284998754505068e-05
    STAT match_ReshapeMatMulReshapePattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00030415500077651814
    STAT match_ReshapePattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.00020345000666566193
    STAT match_ReshapeReshapeBinaryPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00027579999732552096
    STAT match_ReshapeReshapePattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.0002137810006388463
    STAT match_RotaryConcatPartPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00019520599016686901
    STAT match_SameChildrenPattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.0006518419977510348
    STAT match_SequenceConstructAtPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00014285900397226214
    STAT match_SimplifiedLayerNormalizationPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.000290568990749307
    STAT match_SkipLayerNormalizationPattern +0 -0 #it=6 maxmatch=2 i=2 - time=0.00020128698815824464
    STAT match_SliceSlicePattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0001317569985985756
    STAT match_SlicesSplitPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00013952799781691283
    STAT match_SoftmaxCrossEntropyLossCastPattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.00408375401457306
    STAT match_SoftmaxGradPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0001676660103839822
    STAT match_SplitConcatPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0001409980104654096
    STAT match_SqueezeUnsqueezePattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.00022318900300888345
    STAT match_Sub1MulPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00019362599414307624
    STAT match_SwitchOrderBinaryPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00042318199848523363
    STAT match_SwitchReshapeActivationPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0002227019940619357
    STAT match_TransposeEqualReshapePattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00021736099006375298
    STAT match_TransposeFusedMatMulBPattern +0 -0 #it=1 maxmatch=0 i=0 - time=9.86179948085919e-05
    STAT match_TransposeMatMulPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00032966199796646833
    STAT match_TransposeReshapeMatMulPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00034290101029910147
    STAT match_TransposeReshapeTransposePattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.0002329110211576335
    STAT match_TransposeTransposePattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.00033013800566550344
    STAT match_UnsqueezeEqualPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0002353209929424338
    STAT match_UnsqueezeUnsqueezePattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.0002007650036830455
    STAT remove_identity_nodes +9 -15 #it=3 maxmatch=0 i=0 - time=0.0007423379938700236
--MODEL: 29 nodes, 1 inputs, 1 outputs, 30 initializers--
         INPUT:   1 x 7t
     INPUT-SEQ:   1 x Falset
        OUTPUT:   1 x 1t
    OUTPUT-SEQ:   1 x Falset
          INIT:  29 x 1t
          INIT:   1 x 7t
          NODE:   4 x Add
          NODE:   1 x Concat
          NODE:   2 x Equal
          NODE:   2 x Gather
          NODE:  11 x MatMul
          NODE:   1 x Relu
          NODE:   2 x Softmax
          NODE:   2 x Where
          NODE:   2 x com.microsoft.FusedMatMul
          NODE:   2 x com.microsoft.SkipLayerNormalization
--MODEL: 29 nodes, 1 inputs, 1 outputs, 30 initializers--DETAILED--
     INPUT:   1 x 7t[1x30]
    OUTPUT:   1 x 1t[1x30x16]
      INIT:   2 x 1t[1024x16]
      INIT:   1 x 1t[128]
      INIT:   1 x 1t[128x16]
      INIT:   8 x 1t[16]
      INIT:   1 x 1t[16x128]
      INIT:   6 x 1t[16x16]
      INIT:   7 x 1t[1]
      INIT:   2 x 1t[30x30]
      INIT:   1 x 1t[32x16]
      INIT:   1 x 7t[1]
      NODE:   1 x Add -SIG- 1t[1x30x128], 1t[128]
      NODE:   2 x Add -SIG- 1t[1x30x16], 1t[16]
      NODE:   1 x Add -SIG- 1t[1x30x16], 1t[1x30x16]
      NODE:   1 x Concat -SIG- 1t[1x30x16], 1t[1x30x16]
      NODE:   2 x Equal -SIG- 1t[30x30], 1t[1]
      NODE:   2 x Gather -SIG- 1t[1024x16], 7t[1x30]
      NODE:   1 x MatMul -SIG- 1t[1x30x128], 1t[128x16]
      NODE:   1 x MatMul -SIG- 1t[1x30x16], 1t[16x128]
      NODE:   6 x MatMul -SIG- 1t[1x30x16], 1t[16x16]
      NODE:   2 x MatMul -SIG- 1t[1x30x30], 1t[1x30x16]
      NODE:   1 x MatMul -SIG- 1t[1x30x32], 1t[32x16]
      NODE:   1 x Relu -SIG- 1t[1x30x128]
      NODE:   2 x Softmax -SIG- 1t[1x30x30]
      NODE:   2 x Where -SIG- 9t[30x30], 1t[1], 1t[1x30x30]
      NODE:   2 x com.microsoft.FusedMatMul -SIG- 1t[1x30x16], 1t[1x30x16]
      NODE:   2 x com.microsoft.SkipLayerNormalization -SIG- 1t[1x30x16], 1t[1x30x16], 1t[16], 1t[16]
[GraphBuilder-ZWA.remove_unused] remove_initializer 1:5/30:p_decoder_norm_1_weight:torch.float32[torch.Size([16])]
[GraphBuilder-ZWA.remove_unused] remove_initializer 2:6/30:p_decoder_norm_1_bias:torch.float32[torch.Size([16])]
[GraphBuilder-ZWA.remove_unused] remove_initializer 3:7/30:p_decoder_norm_2_weight:torch.float32[torch.Size([16])]
[GraphBuilder-ZWA.remove_unused] remove_initializer 4:8/30:p_decoder_norm_2_bias:torch.float32[torch.Size([16])]
[GraphBuilder-ZWA.remove_unused] remove_initializer 5:9/30:init7_s1_-1:int64[(1,)]
[GraphBuilder-ZWA.remove_unused] remove_initializer 6:10/30:init1_s1_:float32[(1,)]
[GraphBuilder-ZWA.remove_unused] remove_initializer 7:11/30:init1_s1_2:float32[(1,)]
[GraphBuilder-ZWA.remove_unused] remove_initializer 8:16/30:_reshape_init1_s_0:float32[(1,)]
[GraphBuilder-ZWA.remove_unused] remove_initializer 9:22/30:_reshape_init1_s_02:float32[(1,)]
[GraphBuilder-ZWA.optimize] done with 29 nodes in 0.042
opset: domain=&#39;&#39; version=18
opset: domain=&#39;com.microsoft&#39; version=1
input: name=&#39;input_ids&#39; type=dtype(&#39;int64&#39;) shape=[1, 30]
init: name=&#39;init1_s1_3&#39; type=float32 shape=(1,) -- array([-inf], dtype=float32)-- Opset.make_node.1/Small##Opset.make_node.1/Small
init: name=&#39;_onx_transpose_p_decoder_attention_attention_0_query_weight0&#39; type=float32 shape=(16, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_attention_attention_0_query_weight)##p_decoder_attention_attention_0_query_weight/DynamoInterpret.placeholder.1/P(decoder.attention.attention.0.query.weight)
init: name=&#39;_onx_transpose_p_decoder_attention_attention_0_key_weight0&#39; type=float32 shape=(16, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_attention_attention_0_key_weight)##p_decoder_attention_attention_0_key_weight/DynamoInterpret.placeholder.1/P(decoder.attention.attention.0.key.weight)
init: name=&#39;_onx_transpose_p_decoder_attention_attention_0_value_weight0&#39; type=float32 shape=(16, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_attention_attention_0_value_weight)##p_decoder_attention_attention_0_value_weight/DynamoInterpret.placeholder.1/P(decoder.attention.attention.0.value.weight)
init: name=&#39;slice_2&#39; type=float32 shape=(30, 30)                      -- GraphBuilder.constant_folding.from/fold(init7_s1_0,init7_s1_1,init7_s1_30,slice_1)##slice_1/GraphBuilder.constant_folding.from/fold(b_decoder_attention_attention_0_mask,init7_s1_0,init7_s1_30)##b_decoder_attention_attention_0_mask/DynamoInterpret.placeholder.0##init7_s1_0/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##init7_s1_30/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##init7_s1_0/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##init7_s1_30/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##init7_s1_1/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape
init: name=&#39;_reshape_init1_s_20&#39; type=float32 shape=(1,) -- array([0.], dtype=float32)-- GraphBuilder.constant_folding.from/fold(init1_s_2,init7_s1_1)##init1_s_2/shape_type_compute._cast_inputs.0##shape_type_compute._cast_inputs.0##init7_s1_1/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape
init: name=&#39;_onx_transpose_p_decoder_attention_attention_1_query_weight0&#39; type=float32 shape=(16, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_attention_attention_1_query_weight)##p_decoder_attention_attention_1_query_weight/DynamoInterpret.placeholder.1/P(decoder.attention.attention.1.query.weight)
init: name=&#39;_onx_transpose_p_decoder_attention_attention_1_key_weight0&#39; type=float32 shape=(16, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_attention_attention_1_key_weight)##p_decoder_attention_attention_1_key_weight/DynamoInterpret.placeholder.1/P(decoder.attention.attention.1.key.weight)
init: name=&#39;_onx_transpose_p_decoder_attention_attention_1_value_weight0&#39; type=float32 shape=(16, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_attention_attention_1_value_weight)##p_decoder_attention_attention_1_value_weight/DynamoInterpret.placeholder.1/P(decoder.attention.attention.1.value.weight)
init: name=&#39;slice_4&#39; type=float32 shape=(30, 30)                      -- GraphBuilder.constant_folding.from/fold(init7_s1_0,init7_s1_1,init7_s1_30,slice_3)##slice_3/GraphBuilder.constant_folding.from/fold(b_decoder_attention_attention_1_mask,init7_s1_0,init7_s1_30)##b_decoder_attention_attention_1_mask/DynamoInterpret.placeholder.0##init7_s1_0/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##init7_s1_30/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##init7_s1_0/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##init7_s1_30/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##init7_s1_1/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape
init: name=&#39;_reshape_init1_s_202&#39; type=float32 shape=(1,) -- array([0.], dtype=float32)-- GraphBuilder.constant_folding.from/fold(init1_s_2,init7_s1_1)##init1_s_2/shape_type_compute._cast_inputs.0##shape_type_compute._cast_inputs.0##init7_s1_1/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape
init: name=&#39;_onx_transpose_p_decoder_attention_linear_weight0&#39; type=float32 shape=(32, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_attention_linear_weight)##p_decoder_attention_linear_weight/DynamoInterpret.placeholder.1/P(decoder.attention.linear.weight)
init: name=&#39;_onx_transpose_p_decoder_feed_forward_linear_1_weight0&#39; type=float32 shape=(16, 128)-- GraphBuilder.constant_folding.from/fold(p_decoder_feed_forward_linear_1_weight)##p_decoder_feed_forward_linear_1_weight/DynamoInterpret.placeholder.1/P(decoder.feed_forward.linear_1.weight)
init: name=&#39;_onx_transpose_p_decoder_feed_forward_linear_2_weight0&#39; type=float32 shape=(128, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_feed_forward_linear_2_weight)##p_decoder_feed_forward_linear_2_weight/DynamoInterpret.placeholder.1/P(decoder.feed_forward.linear_2.weight)
init: name=&#39;init1_s16_&#39; type=float32 shape=(16,)                      -- LayerNormalizationPattern.apply.scale##LayerNormalizationPattern.apply.scale
init: name=&#39;init1_s16_2&#39; type=float32 shape=(16,)                     -- LayerNormalizationPattern.apply.bias##LayerNormalizationPattern.apply.bias
init: name=&#39;embedding.embedding.weight&#39; type=float32 shape=(1024, 16) -- DynamoInterpret.placeholder.1/P(embedding.embedding.weight)
init: name=&#39;embedding.pe.weight&#39; type=float32 shape=(1024, 16)        -- DynamoInterpret.placeholder.1/P(embedding.pe.weight)
init: name=&#39;decoder.attention.linear.bias&#39; type=float32 shape=(16,)   -- DynamoInterpret.placeholder.1/P(decoder.attention.linear.bias)
init: name=&#39;decoder.feed_forward.linear_1.bias&#39; type=float32 shape=(128,)-- DynamoInterpret.placeholder.1/P(decoder.feed_forward.linear_1.bias)
init: name=&#39;decoder.feed_forward.linear_2.bias&#39; type=float32 shape=(16,)-- DynamoInterpret.placeholder.1/P(decoder.feed_forward.linear_2.bias)
Equal(slice_2, _reshape_init1_s_20) -&gt; eq
Gather(embedding.embedding.weight, input_ids) -&gt; embedding
Gather(embedding.pe.weight, input_ids) -&gt; embedding_1
  SkipLayerNormalization[com.microsoft](embedding, embedding_1, init1_s16_, init1_s16_2, epsilon=0.00) -&gt; _onx_div_sub_add00, unused, unused2, add
    MatMul(_onx_div_sub_add00, _onx_transpose_p_decoder_attention_attention_0_query_weight0) -&gt; linear
MatMul(_onx_div_sub_add00, _onx_transpose_p_decoder_attention_attention_0_key_weight0) -&gt; linear_1
  FusedMatMul[com.microsoft](linear, linear_1, alpha=0.25, transA=0, transB=1, transBatchA=0, transBatchB=0) -&gt; _onx_mul_matmul0
  Where(eq, init1_s1_3, _onx_mul_matmul0) -&gt; masked_fill
    Softmax(masked_fill, axis=-1) -&gt; softmax
MatMul(_onx_div_sub_add00, _onx_transpose_p_decoder_attention_attention_0_value_weight0) -&gt; linear_2
  MatMul(softmax, linear_2) -&gt; matmul_1
MatMul(_onx_div_sub_add00, _onx_transpose_p_decoder_attention_attention_1_query_weight0) -&gt; linear_3
MatMul(_onx_div_sub_add00, _onx_transpose_p_decoder_attention_attention_1_key_weight0) -&gt; linear_4
  FusedMatMul[com.microsoft](linear_3, linear_4, alpha=0.25, transA=0, transB=1, transBatchA=0, transBatchB=0) -&gt; _onx_mul_matmul_20
MatMul(_onx_div_sub_add00, _onx_transpose_p_decoder_attention_attention_1_value_weight0) -&gt; linear_5
Equal(slice_4, _reshape_init1_s_202) -&gt; eq_1
  Where(eq_1, init1_s1_3, _onx_mul_matmul_20) -&gt; masked_fill_1
    Softmax(masked_fill_1, axis=-1) -&gt; softmax_1
  MatMul(softmax_1, linear_5) -&gt; matmul_3
    Concat(matmul_1, matmul_3, axis=-1) -&gt; cat
      MatMul(cat, _onx_transpose_p_decoder_attention_linear_weight0) -&gt; _onx_matmul_cat0
        Add(_onx_matmul_cat0, decoder.attention.linear.bias) -&gt; linear_6
    SkipLayerNormalization[com.microsoft](linear_6, add, init1_s16_, init1_s16_2, epsilon=0.00) -&gt; _onx_div_sub_add_100, unused3, unused4, add_1
      MatMul(_onx_div_sub_add_100, _onx_transpose_p_decoder_feed_forward_linear_1_weight0) -&gt; _onx_matmul_layer_norm_10
        Add(_onx_matmul_layer_norm_10, decoder.feed_forward.linear_1.bias) -&gt; linear_7
          Relu(linear_7) -&gt; relu
            MatMul(relu, _onx_transpose_p_decoder_feed_forward_linear_2_weight0) -&gt; _onx_matmul_relu0
              Add(_onx_matmul_relu0, decoder.feed_forward.linear_2.bias) -&gt; linear_8
      Add(linear_8, add_1) -&gt; output_0
output: name=&#39;output_0&#39; type=dtype(&#39;float32&#39;) shape=[1, 30, 16]
</pre></div>
</div>
<p>This shows a kernel <code class="docutils literal notranslate"><span class="pre">FusedMatMul[com.microsoft]</span></code> which implement a kernel equivalent Gemm
but working for any tensors, not only 2D.
How does it work on the model which keeps exports the moduels as local functions?
The optimizer optimizes every local function independantly.
We reduce the verbosity</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx_module_optimized</span></a></a></a></a> <span class="o">=</span> <a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter sphx-glr-backref-type-py-function"><span class="n">to_onnx</span></a></a></a></a><span class="p">(</span>
    <span class="n">llm</span><span class="p">,</span>
    <span class="p">(</span><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_ids</span></a></a></a></a><span class="p">,),</span>
    <span class="n">options</span><span class="o">=</span><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/xbuilder/index.html#experimental_experiment.xbuilder.OptimizationOptions" title="experimental_experiment.xbuilder.OptimizationOptions" class="sphx-glr-backref-module-experimental_experiment-xbuilder sphx-glr-backref-type-py-class"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/xbuilder/index.html#experimental_experiment.xbuilder.OptimizationOptions" title="experimental_experiment.xbuilder.OptimizationOptions" class="sphx-glr-backref-module-experimental_experiment-xbuilder sphx-glr-backref-type-py-class"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/xbuilder/index.html#experimental_experiment.xbuilder.OptimizationOptions" title="experimental_experiment.xbuilder.OptimizationOptions" class="sphx-glr-backref-module-experimental_experiment-xbuilder sphx-glr-backref-type-py-class"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/xbuilder/index.html#experimental_experiment.xbuilder.OptimizationOptions" title="experimental_experiment.xbuilder.OptimizationOptions" class="sphx-glr-backref-module-experimental_experiment-xbuilder sphx-glr-backref-type-py-class"><span class="n">OptimizationOptions</span></a></a></a></a><span class="p">(</span><span class="n">patterns</span><span class="o">=</span><span class="s2">&quot;default+onnxruntime&quot;</span><span class="p">,</span> <span class="n">constant_folding</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <span class="n">export_modules_as_functions</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><span class="n">pretty_onnx</span></a></a></a></a><span class="p">(</span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx_module_optimized</span></a></a></a></a><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>opset: domain=&#39;&#39; version=18
opset: domain=&#39;aten_local_function&#39; version=1
opset: domain=&#39;com.microsoft&#39; version=1
input: name=&#39;input_ids&#39; type=dtype(&#39;int64&#39;) shape=[1, 30]
init: name=&#39;embedding.embedding.weight&#39; type=float32 shape=(1024, 16) -- GraphBuilder.make_local_function/from(embedding.embedding.weight)
init: name=&#39;embedding.pe.weight&#39; type=float32 shape=(1024, 16)        -- GraphBuilder.make_local_function/from(embedding.pe.weight)
init: name=&#39;_onx_transpose_weight0&#39; type=float32 shape=(16, 16)       -- GraphBuilder.make_local_function/from(_onx_transpose_weight0)
init: name=&#39;_onx_transpose_weight02&#39; type=float32 shape=(16, 16)      -- GraphBuilder.make_local_function/from(_onx_transpose_weight02)
init: name=&#39;_onx_transpose_weight03&#39; type=float32 shape=(16, 16)      -- GraphBuilder.make_local_function/from(_onx_transpose_weight03)
init: name=&#39;slice_2&#39; type=float32 shape=(30, 30)                      -- GraphBuilder.make_local_function/from(slice_2)
init: name=&#39;_onx_transpose_weight04&#39; type=float32 shape=(16, 16)      -- GraphBuilder.make_local_function/from(_onx_transpose_weight04)
init: name=&#39;_onx_transpose_weight022&#39; type=float32 shape=(16, 16)     -- GraphBuilder.make_local_function/from(_onx_transpose_weight022)
init: name=&#39;_onx_transpose_weight032&#39; type=float32 shape=(16, 16)     -- GraphBuilder.make_local_function/from(_onx_transpose_weight032)
init: name=&#39;slice_4&#39; type=float32 shape=(30, 30)                      -- GraphBuilder.make_local_function/from(slice_4)
init: name=&#39;_onx_transpose_weight05&#39; type=float32 shape=(32, 16)      -- GraphBuilder.make_local_function/from(_onx_transpose_weight05)
init: name=&#39;decoder.feed_forward.linear_1.bias&#39; type=float32 shape=(128,)-- GraphBuilder.make_local_function/from(decoder.feed_forward.linear_1.bias)
init: name=&#39;_onx_transpose_weight06&#39; type=float32 shape=(16, 128)     -- GraphBuilder.make_local_function/from(_onx_transpose_weight06)
init: name=&#39;_onx_transpose_weight023&#39; type=float32 shape=(128, 16)    -- GraphBuilder.make_local_function/from(_onx_transpose_weight023)
init: name=&#39;init1_s16_3&#39; type=float32 shape=(16,)                     -- GraphBuilder.constant_folding.from/fold()
init: name=&#39;init1_s16_22&#39; type=float32 shape=(16,)                    -- GraphBuilder.constant_folding.from/fold()
init: name=&#39;init1_s16_&#39; type=float32 shape=(16,)                      -- GraphBuilder.constant_folding.from/fold()
init: name=&#39;init1_s16_2&#39; type=float32 shape=(16,)                     -- GraphBuilder.constant_folding.from/fold()
init: name=&#39;bias2&#39; type=float32 shape=(16,)                           -- GraphBuilder.constant_folding.from/fold()
init: name=&#39;bias&#39; type=float32 shape=(16,)                            -- GraphBuilder.constant_folding.from/fold()
init: name=&#39;init1_s1_2&#39; type=float32 shape=(1,) -- array([-inf], dtype=float32)-- GraphBuilder.constant_folding.from/fold()
init: name=&#39;_reshape_init1_s_202&#39; type=float32 shape=(1,) -- array([0.], dtype=float32)-- GraphBuilder.constant_folding.from/fold()
init: name=&#39;init1_s1_&#39; type=float32 shape=(1,) -- array([-inf], dtype=float32)-- GraphBuilder.constant_folding.from/fold()
init: name=&#39;_reshape_init1_s_20&#39; type=float32 shape=(1,) -- array([0.], dtype=float32)-- GraphBuilder.constant_folding.from/fold()
Equal(slice_2, _reshape_init1_s_20) -&gt; eq
Gather(embedding.embedding.weight, input_ids) -&gt; embedding2
Gather(embedding.pe.weight, input_ids) -&gt; pe
  SkipLayerNormalization[com.microsoft](embedding2, pe, init1_s16_, init1_s16_2, epsilon=0.00) -&gt; norm_1, unused, unused2, embedding
    MatMul(norm_1, _onx_transpose_weight0) -&gt; query
MatMul(norm_1, _onx_transpose_weight02) -&gt; key
  FusedMatMul[com.microsoft](query, key, alpha=0.25, transA=0, transB=1, transBatchA=0, transBatchB=0) -&gt; _onx_mul_matmul0
  Where(eq, init1_s1_, _onx_mul_matmul0) -&gt; masked_fill
    Softmax(masked_fill, axis=-1) -&gt; softmax
MatMul(norm_1, _onx_transpose_weight03) -&gt; value
  MatMul(softmax, value) -&gt; attention_0
MatMul(norm_1, _onx_transpose_weight04) -&gt; query2
MatMul(norm_1, _onx_transpose_weight022) -&gt; key2
  FusedMatMul[com.microsoft](query2, key2, alpha=0.25, transA=0, transB=1, transBatchA=0, transBatchB=0) -&gt; _onx_mul_matmul02
MatMul(norm_1, _onx_transpose_weight032) -&gt; value2
Equal(slice_4, _reshape_init1_s_202) -&gt; eq2
  Where(eq2, init1_s1_2, _onx_mul_matmul02) -&gt; masked_fill2
    Softmax(masked_fill2, axis=-1) -&gt; softmax2
  MatMul(softmax2, value2) -&gt; attention_1
    Concat(attention_0, attention_1, axis=-1) -&gt; cat
      MatMul(cat, _onx_transpose_weight05) -&gt; _onx_matmul_cat0
        Add(_onx_matmul_cat0, bias) -&gt; attention
    Add(attention, embedding) -&gt; add_1
      LayerNormalization(add_1, init1_s16_3, init1_s16_22, axis=-1, epsilon=0.00, stash_type=1) -&gt; norm_2
        MatMul(norm_2, _onx_transpose_weight06) -&gt; _onx_matmul_layer_norm_10
          Add(_onx_matmul_layer_norm_10, decoder.feed_forward.linear_1.bias) -&gt; linear_1
            Relu(linear_1) -&gt; relu
              MatMul(relu, _onx_transpose_weight023) -&gt; _onx_matmul_relu0
                Add(_onx_matmul_relu0, bias2) -&gt; feed_forward
      Add(feed_forward, add_1) -&gt; output_0
output: name=&#39;output_0&#39; type=dtype(&#39;float32&#39;) shape=[1, 30, 16]
</pre></div>
</div>
<p>It seems to be working as well on this simple case even though the optimizers were
not tested on such models. However, keeping the submodule information might be useful
to implement optimizer for a fmaily of models sharing the same components.</p>
</section>
<section id="optimizations-for-cuda">
<h2>Optimizations for CUDA<a class="headerlink" href="#optimizations-for-cuda" title="Link to this heading"></a></h2>
<p>The optimizer may have a different behaviour knowning the model is running on CUDA.
It may use different kernels and do different optimization if needed.
That may not be the good place to do it as the runtime may choose to run one kernel on CPU,
another one on CUDA. The current optimization does not know that and
is not able to decide which provider would be more useful for some kernels.
This coudl even be decided at runtime.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx_cuda_optimized</span></a></a></a></a> <span class="o">=</span> <a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter sphx-glr-backref-type-py-function"><span class="n">to_onnx</span></a></a></a></a><span class="p">(</span>
    <span class="n">llm</span><span class="p">,</span>
    <span class="p">(</span><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_ids</span></a></a></a></a><span class="p">,),</span>
    <span class="n">options</span><span class="o">=</span><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/xbuilder/index.html#experimental_experiment.xbuilder.OptimizationOptions" title="experimental_experiment.xbuilder.OptimizationOptions" class="sphx-glr-backref-module-experimental_experiment-xbuilder sphx-glr-backref-type-py-class"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/xbuilder/index.html#experimental_experiment.xbuilder.OptimizationOptions" title="experimental_experiment.xbuilder.OptimizationOptions" class="sphx-glr-backref-module-experimental_experiment-xbuilder sphx-glr-backref-type-py-class"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/xbuilder/index.html#experimental_experiment.xbuilder.OptimizationOptions" title="experimental_experiment.xbuilder.OptimizationOptions" class="sphx-glr-backref-module-experimental_experiment-xbuilder sphx-glr-backref-type-py-class"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/xbuilder/index.html#experimental_experiment.xbuilder.OptimizationOptions" title="experimental_experiment.xbuilder.OptimizationOptions" class="sphx-glr-backref-module-experimental_experiment-xbuilder sphx-glr-backref-type-py-class"><span class="n">OptimizationOptions</span></a></a></a></a><span class="p">(</span>
        <span class="n">patterns</span><span class="o">=</span><span class="s2">&quot;default+onnxruntime&quot;</span><span class="p">,</span> <span class="n">constant_folding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">processor</span><span class="o">=</span><span class="s2">&quot;CUDA&quot;</span>
    <span class="p">),</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><span class="n">pretty_onnx</span></a></a></a></a><span class="p">(</span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx_cuda_optimized</span></a></a></a></a><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[GraphBuilder-VNC.optimize] start with 73 nodes
[GraphBuilder-VNC.optimize] #patterns=66
[GraphBuilder-VNC.remove_unused] remove_initializer 1:1/47:embedding.embedding.weight:torch.float32[torch.Size([1024, 16])]
[GraphBuilder-VNC.remove_unused] remove_initializer 2:3/47:embedding.pe.weight:torch.float32[torch.Size([1024, 16])]
[GraphBuilder-VNC.remove_unused] remove_initializer 3:5/47:decoder.attention.attention.0.query.weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-VNC.remove_unused] remove_initializer 4:7/47:decoder.attention.attention.0.key.weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-VNC.remove_unused] remove_initializer 5:9/47:decoder.attention.attention.0.value.weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-VNC.remove_unused] remove_initializer 6:11/47:decoder.attention.attention.1.query.weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-VNC.remove_unused] remove_initializer 7:13/47:decoder.attention.attention.1.key.weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-VNC.remove_unused] remove_initializer 8:15/47:decoder.attention.attention.1.value.weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-VNC.remove_unused] remove_initializer 9:17/47:decoder.attention.linear.weight:torch.float32[torch.Size([16, 32])]
[GraphBuilder-VNC.remove_unused] remove_initializer 10:19/47:decoder.attention.linear.bias:torch.float32[torch.Size([16])]
[GraphBuilder-VNC.remove_unused] remove_initializer 11:21/47:decoder.feed_forward.linear_1.weight:torch.float32[torch.Size([128, 16])]
[GraphBuilder-VNC.remove_unused] remove_initializer 12:23/47:decoder.feed_forward.linear_1.bias:torch.float32[torch.Size([128])]
[GraphBuilder-VNC.remove_unused] remove_initializer 13:25/47:decoder.feed_forward.linear_2.weight:torch.float32[torch.Size([16, 128])]
[GraphBuilder-VNC.remove_unused] remove_initializer 14:27/47:decoder.feed_forward.linear_2.bias:torch.float32[torch.Size([16])]
[GraphBuilder-VNC.remove_unused] remove_initializer 15:29/47:decoder.norm_1.weight:torch.float32[torch.Size([16])]
[GraphBuilder-VNC.remove_unused] remove_initializer 16:31/47:decoder.norm_1.bias:torch.float32[torch.Size([16])]
[GraphBuilder-VNC.remove_unused] remove_initializer 17:33/47:decoder.norm_2.weight:torch.float32[torch.Size([16])]
[GraphBuilder-VNC.remove_unused] remove_initializer 18:35/47:decoder.norm_2.bias:torch.float32[torch.Size([16])]
[GraphBuilder-VNC.remove_unused] remove_initializer 1:2/46:p_decoder_attention_attention_0_query_weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-VNC.remove_unused] remove_initializer 2:3/46:p_decoder_attention_attention_0_key_weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-VNC.remove_unused] remove_initializer 3:4/46:p_decoder_attention_attention_0_value_weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-VNC.remove_unused] remove_initializer 4:5/46:p_decoder_attention_attention_1_query_weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-VNC.remove_unused] remove_initializer 5:6/46:p_decoder_attention_attention_1_key_weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-VNC.remove_unused] remove_initializer 6:7/46:p_decoder_attention_attention_1_value_weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-VNC.remove_unused] remove_initializer 7:8/46:p_decoder_attention_linear_weight:torch.float32[torch.Size([16, 32])]
[GraphBuilder-VNC.remove_unused] remove_initializer 8:10/46:p_decoder_feed_forward_linear_1_weight:torch.float32[torch.Size([128, 16])]
[GraphBuilder-VNC.remove_unused] remove_initializer 9:12/46:p_decoder_feed_forward_linear_2_weight:torch.float32[torch.Size([16, 128])]
[GraphBuilder-VNC.remove_unused] remove_initializer 10:18/46:b_decoder_attention_attention_0_mask:torch.float32[torch.Size([256, 256])]
[GraphBuilder-VNC.remove_unused] remove_initializer 11:19/46:b_decoder_attention_attention_1_mask:torch.float32[torch.Size([256, 256])]
[GraphBuilder-VNC.remove_unused] remove_initializer 12:23/46:init1_s_:float32[()]
[GraphBuilder-VNC.remove_unused] remove_initializer 13:24/46:init7_s1_1:int64[(1,)]
[GraphBuilder-VNC.remove_unused] remove_initializer 14:25/46:init7_s1_0:int64[(1,)]
[GraphBuilder-VNC.remove_unused] remove_initializer 15:26/46:init7_s1_30:int64[(1,)]
[GraphBuilder-VNC.remove_unused] remove_initializer 16:27/46:init1_s_2:float32[()]
[GraphBuilder-VNC.remove_unused] remove_initializer 17:33/46:slice_1:torch.float32[torch.Size([30, 256])]
[GraphBuilder-VNC.remove_unused] remove_initializer 18:40/46:slice_3:torch.float32[torch.Size([30, 256])]
[GraphBuilderPatternOptimization-VNC.optimize] start with 53 nodes, 28 initializers, 66 patterns, priorities=[0, 1, 2, 3]
[GraphBuilderPatternOptimization-VNC.optimize] use pattern   1/66 - P0 - BatchNormalizationPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern   2/66 - P0 - BatchNormalizationTrainingPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern   3/66 - P0 - CastPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern   4/66 - P0 - ConvBiasNullPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern   5/66 - P0 - ExpandPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern   6/66 - P0 - GeluErfPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern   7/66 - P0 - GeluOrtPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern   8/66 - P0 - GeluPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern   9/66 - P0 - IdentityPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  10/66 - P0 - LeakyReluPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  11/66 - P0 - ReshapePattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  12/66 - P0 - ReshapeReshapePattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  13/66 - P0 - SameChildrenPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  14/66 - P0 - SoftmaxCrossEntropyLossCastPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  15/66 - P0 - SqueezeUnsqueezePattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  16/66 - P0 - TransposeReshapeTransposePattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  17/66 - P0 - TransposeTransposePattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  18/66 - P0 - UnsqueezeUnsqueezePattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  19/66 - P1 - BiasGeluPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  20/66 - P1 - BiasSoftmaxPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  21/66 - P1 - CastCastBinaryPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  22/66 - P1 - CastLayerNormalizationCastPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  23/66 - P1 - CastOpCastPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  24/66 - P1 - ClipClipPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  25/66 - P1 - ComputationCastOpCastPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  26/66 - P1 - DropoutPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  27/66 - P1 - ExpandBroadcastPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  28/66 - P1 - ExpandSwapPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  29/66 - P1 - FastGeluPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  30/66 - P1 - GemmTransposePattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  31/66 - P1 - LayerNormalizationPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  32/66 - P1 - LayerNormalizationScalePattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  33/66 - P1 - MatMulReshape2Of3Pattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  34/66 - P1 - MulMulMatMulPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  35/66 - P1 - MulMulMulScalarPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  36/66 - P1 - OrtBatchNormalizationTrainingPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  37/66 - P1 - QuickGeluPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  38/66 - P1 - ReduceReshapePattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  39/66 - P1 - ReduceSumNormalizePattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  40/66 - P1 - Reshape2Of3Pattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  41/66 - P1 - ReshapeMatMulReshapePattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  42/66 - P1 - ReshapeReshapeBinaryPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  43/66 - P1 - RotaryConcatPartPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  44/66 - P1 - SequenceConstructAtPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  45/66 - P1 - SimplifiedLayerNormalizationPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  46/66 - P1 - SkipLayerNormalizationPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  47/66 - P1 - SliceSlicePattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  48/66 - P1 - SlicesSplitPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  49/66 - P1 - SoftmaxGradPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  50/66 - P1 - SplitConcatPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  51/66 - P1 - Sub1MulPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  52/66 - P1 - SwitchOrderBinaryPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  53/66 - P1 - SwitchReshapeActivationPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  54/66 - P1 - TransposeEqualReshapePattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  55/66 - P1 - TransposeMatMulPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  56/66 - P1 - TransposeReshapeMatMulPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  57/66 - P1 - UnsqueezeEqualPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  58/66 - P2 - FusedConvPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  59/66 - P2 - FusedMatMulDivPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  60/66 - P2 - FusedMatMulPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  61/66 - P3 - AttentionPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  62/66 - P3 - FusedMatMulTransposePattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  63/66 - P3 - FusedMatMulx2Pattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  64/66 - P3 - MatMulAddPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  65/66 - P3 - ReshapeGemmPattern()
[GraphBuilderPatternOptimization-VNC.optimize] use pattern  66/66 - P3 - TransposeFusedMatMulBPattern()
[GraphBuilderPatternOptimization-VNC.optimize] iteration 0: 53 nodes, priority=0
[GraphBuilderPatternOptimization-VNC.optimize] applies 6 matches, 2*CastPattern, 4*IdentityPattern - time=0.008 | max_time=SoftmaxCrossEntropyLossCastPattern:0.002
[GraphBuilderPatternOptimization-VNC.optimize] iteration 1: 47 nodes, priority=0
[GraphBuilderPatternOptimization-VNC.optimize] increase priority to 1
[GraphBuilderPatternOptimization-VNC.optimize] iteration 2: 47 nodes, priority=1
[GraphBuilderPatternOptimization-VNC.optimize] applies 2 matches, 2*LayerNormalizationPattern - time=0.004 | max_time=IdentityPattern:0.000
[GraphBuilderPatternOptimization-VNC.optimize] iteration 3: 35 nodes, priority=1
[GraphBuilderPatternOptimization-VNC.optimize] applies 2 matches, 2*SkipLayerNormalizationPattern - time=0.003 | max_time=IdentityPattern:0.000
[GraphBuilderPatternOptimization-VNC.optimize] iteration 4: 33 nodes, priority=1
[GraphBuilderPatternOptimization-VNC.optimize] increase priority to 2
[GraphBuilderPatternOptimization-VNC.optimize] iteration 5: 33 nodes, priority=2
[GraphBuilderPatternOptimization-VNC.optimize] applies 2 matches, 2*FusedMatMulPattern - time=0.003 | max_time=IdentityPattern:0.000
[GraphBuilderPatternOptimization-VNC.optimize] iteration 6: 29 nodes, priority=2
[GraphBuilderPatternOptimization-VNC.optimize] increase priority to 3
[GraphBuilderPatternOptimization-VNC.optimize] iteration 7: 29 nodes, priority=3
[GraphBuilderPatternOptimization-VNC.optimize] stops current_priority_index=4, priorities=[0, 1, 2, 3]
[GraphBuilderPatternOptimization-VNC.optimize] done after 8 iterations with 29 nodes in 0.038
    STAT apply_CastPattern +2 -2 #it=1 maxmatch=1 i=2 - time=0.00026056999195134267
    STAT apply_FusedMatMulPattern +2 -6 #it=1 maxmatch=1 i=2 - time=0.0005157869964023121
    STAT apply_IdentityPattern +4 -4 #it=1 maxmatch=5 i=4 - time=0.00030466200405498967
    STAT apply_LayerNormalizationPattern +2 -14 #it=1 maxmatch=1 i=2 - time=0.0005376979970606044
    STAT apply_SkipLayerNormalizationPattern +2 -4 #it=1 maxmatch=1 i=2 - time=0.00022099500347394496
    STAT build_graph_for_pattern +0 -0 #it=8 maxmatch=0 i=0 - time=0.0014846519916318357
    STAT check_pattern_00 +0 -0 #it=1 maxmatch=0 i=0 - time=0.00021267700503813103
    STAT check_pattern_A0 +0 -0 #it=4 maxmatch=0 i=0 - time=0.0015150120161706582
    STAT check_pattern_B0 +0 -0 #it=3 maxmatch=0 i=0 - time=0.0003633899978012778
    STAT match_AttentionPattern +0 -0 #it=1 maxmatch=0 i=0 - time=2.4903994926717132e-05
    STAT match_BatchNormalizationPattern +0 -0 #it=8 maxmatch=0 i=0 - time=0.0004113059985684231
    STAT match_BatchNormalizationTrainingPattern +0 -0 #it=8 maxmatch=0 i=0 - time=0.00028710500191664323
    STAT match_BiasGeluPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0001591440086485818
    STAT match_BiasSoftmaxPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0002895809957408346
    STAT match_CastCastBinaryPattern +0 -0 #it=6 maxmatch=0 i=0 - time=0.0004520799921010621
    STAT match_CastLayerNormalizationCastPattern +0 -0 #it=6 maxmatch=0 i=0 - time=0.0002281540000694804
    STAT match_CastOpCastPattern +0 -0 #it=6 maxmatch=0 i=0 - time=0.0004967470013070852
    STAT match_CastPattern +0 -0 #it=8 maxmatch=2 i=2 - time=0.00029728899971814826
    STAT match_ClipClipPattern +0 -0 #it=6 maxmatch=0 i=0 - time=0.00015165000513661653
    STAT match_ComputationCastOpCastPattern +0 -0 #it=6 maxmatch=0 i=0 - time=0.00026441601221449673
    STAT match_ConvBiasNullPattern +0 -0 #it=8 maxmatch=2 i=0 - time=0.00024405600561294705
    STAT match_DropoutPattern +0 -0 #it=6 maxmatch=0 i=0 - time=0.0001320449955528602
    STAT match_ExpandBroadcastPattern +0 -0 #it=6 maxmatch=0 i=0 - time=0.0001397379965055734
    STAT match_ExpandPattern +0 -0 #it=8 maxmatch=2 i=0 - time=0.0002740909985732287
    STAT match_ExpandSwapPattern +0 -0 #it=6 maxmatch=0 i=0 - time=0.00014128500333754346
    STAT match_FastGeluPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00014789899432798848
    STAT match_FusedConvPattern +0 -0 #it=3 maxmatch=0 i=0 - time=6.449100328609347e-05
    STAT match_FusedMatMulDivPattern +0 -0 #it=3 maxmatch=2 i=0 - time=0.00014306599769042805
    STAT match_FusedMatMulPattern +0 -0 #it=3 maxmatch=2 i=2 - time=0.00035403600486461073
    STAT match_FusedMatMulTransposePattern +0 -0 #it=1 maxmatch=0 i=0 - time=7.892500434536487e-05
    STAT match_FusedMatMulx2Pattern +0 -0 #it=1 maxmatch=0 i=0 - time=5.7320998166687787e-05
    STAT match_GeluErfPattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.00228474000323331
    STAT match_GeluOrtPattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.003075333996093832
    STAT match_GeluPattern +0 -0 #it=8 maxmatch=2 i=0 - time=7.80199479777366e-06
    STAT match_GemmTransposePattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0001459740087739192
    STAT match_IdentityPattern +0 -0 #it=8 maxmatch=6 i=4 - time=0.0026902310055447742
    STAT match_LayerNormalizationPattern +0 -0 #it=6 maxmatch=2 i=2 - time=0.0003888280116370879
    STAT match_LayerNormalizationScalePattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00018430400814395398
    STAT match_LeakyReluPattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.0028149299978394993
    STAT match_MatMulAddPattern +0 -0 #it=1 maxmatch=0 i=0 - time=6.969700189074501e-05
    STAT match_MatMulReshape2Of3Pattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0006638829945586622
    STAT match_MulMulMatMulPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00035725799534702674
    STAT match_MulMulMulScalarPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0002011279866565019
    STAT match_OrtBatchNormalizationTrainingPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00024763400870142505
    STAT match_QuickGeluPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0001439319967175834
    STAT match_ReduceReshapePattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00020257899450371042
    STAT match_ReduceSumNormalizePattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00015912499657133594
    STAT match_Reshape2Of3Pattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0004544649927993305
    STAT match_ReshapeGemmPattern +0 -0 #it=1 maxmatch=0 i=0 - time=1.912900188472122e-05
    STAT match_ReshapeMatMulReshapePattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00032406898390036076
    STAT match_ReshapePattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.00033377300132997334
    STAT match_ReshapeReshapeBinaryPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0002825109986588359
    STAT match_ReshapeReshapePattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.00026791998971020803
    STAT match_RotaryConcatPartPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00020742399647133425
    STAT match_SameChildrenPattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.0007477519975509495
    STAT match_SequenceConstructAtPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00014944799477234483
    STAT match_SimplifiedLayerNormalizationPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00028798499261029065
    STAT match_SkipLayerNormalizationPattern +0 -0 #it=6 maxmatch=2 i=2 - time=0.0001661589994910173
    STAT match_SliceSlicePattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00013994799519423395
    STAT match_SlicesSplitPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00015538500883849338
    STAT match_SoftmaxCrossEntropyLossCastPattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.004016680999484379
    STAT match_SoftmaxGradPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00013662099809153005
    STAT match_SplitConcatPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00014305799413705245
    STAT match_SqueezeUnsqueezePattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.0002699020114960149
    STAT match_Sub1MulPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00016476198652526364
    STAT match_SwitchOrderBinaryPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00046992699935799465
    STAT match_SwitchReshapeActivationPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00022256100055528805
    STAT match_TransposeEqualReshapePattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00022111900034360588
    STAT match_TransposeFusedMatMulBPattern +0 -0 #it=1 maxmatch=0 i=0 - time=9.120399772655219e-05
    STAT match_TransposeMatMulPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0003470090086921118
    STAT match_TransposeReshapeMatMulPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00034353700175415725
    STAT match_TransposeReshapeTransposePattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.00026978999812854454
    STAT match_TransposeTransposePattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.00026462300593266264
    STAT match_UnsqueezeEqualPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00023889799922471866
    STAT match_UnsqueezeUnsqueezePattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.0002689320099307224
    STAT remove_identity_nodes +9 -15 #it=3 maxmatch=0 i=0 - time=0.0008166290062945336
--MODEL: 29 nodes, 1 inputs, 1 outputs, 30 initializers--
         INPUT:   1 x 7t
     INPUT-SEQ:   1 x Falset
        OUTPUT:   1 x 1t
    OUTPUT-SEQ:   1 x Falset
          INIT:  29 x 1t
          INIT:   1 x 7t
          NODE:   4 x Add
          NODE:   1 x Concat
          NODE:   2 x Equal
          NODE:   2 x Gather
          NODE:  11 x MatMul
          NODE:   1 x Relu
          NODE:   2 x Softmax
          NODE:   2 x Where
          NODE:   2 x com.microsoft.FusedMatMul
          NODE:   2 x com.microsoft.SkipLayerNormalization
--MODEL: 29 nodes, 1 inputs, 1 outputs, 30 initializers--DETAILED--
     INPUT:   1 x 7t[1x30]
    OUTPUT:   1 x 1t[1x30x16]
      INIT:   2 x 1t[1024x16]
      INIT:   1 x 1t[128]
      INIT:   1 x 1t[128x16]
      INIT:   8 x 1t[16]
      INIT:   1 x 1t[16x128]
      INIT:   6 x 1t[16x16]
      INIT:   7 x 1t[1]
      INIT:   2 x 1t[30x30]
      INIT:   1 x 1t[32x16]
      INIT:   1 x 7t[1]
      NODE:   1 x Add -SIG- 1t[1x30x128], 1t[128]
      NODE:   2 x Add -SIG- 1t[1x30x16], 1t[16]
      NODE:   1 x Add -SIG- 1t[1x30x16], 1t[1x30x16]
      NODE:   1 x Concat -SIG- 1t[1x30x16], 1t[1x30x16]
      NODE:   2 x Equal -SIG- 1t[30x30], 1t[1]
      NODE:   2 x Gather -SIG- 1t[1024x16], 7t[1x30]
      NODE:   1 x MatMul -SIG- 1t[1x30x128], 1t[128x16]
      NODE:   1 x MatMul -SIG- 1t[1x30x16], 1t[16x128]
      NODE:   6 x MatMul -SIG- 1t[1x30x16], 1t[16x16]
      NODE:   2 x MatMul -SIG- 1t[1x30x30], 1t[1x30x16]
      NODE:   1 x MatMul -SIG- 1t[1x30x32], 1t[32x16]
      NODE:   1 x Relu -SIG- 1t[1x30x128]
      NODE:   2 x Softmax -SIG- 1t[1x30x30]
      NODE:   2 x Where -SIG- 9t[30x30], 1t[1], 1t[1x30x30]
      NODE:   2 x com.microsoft.FusedMatMul -SIG- 1t[1x30x16], 1t[1x30x16]
      NODE:   2 x com.microsoft.SkipLayerNormalization -SIG- 1t[1x30x16], 1t[1x30x16], 1t[16], 1t[16]
[GraphBuilder-VNC.remove_unused] remove_initializer 1:5/30:p_decoder_norm_1_weight:torch.float32[torch.Size([16])]
[GraphBuilder-VNC.remove_unused] remove_initializer 2:6/30:p_decoder_norm_1_bias:torch.float32[torch.Size([16])]
[GraphBuilder-VNC.remove_unused] remove_initializer 3:7/30:p_decoder_norm_2_weight:torch.float32[torch.Size([16])]
[GraphBuilder-VNC.remove_unused] remove_initializer 4:8/30:p_decoder_norm_2_bias:torch.float32[torch.Size([16])]
[GraphBuilder-VNC.remove_unused] remove_initializer 5:9/30:init7_s1_-1:int64[(1,)]
[GraphBuilder-VNC.remove_unused] remove_initializer 6:10/30:init1_s1_:float32[(1,)]
[GraphBuilder-VNC.remove_unused] remove_initializer 7:11/30:init1_s1_2:float32[(1,)]
[GraphBuilder-VNC.remove_unused] remove_initializer 8:16/30:_reshape_init1_s_0:float32[(1,)]
[GraphBuilder-VNC.remove_unused] remove_initializer 9:22/30:_reshape_init1_s_02:float32[(1,)]
[GraphBuilder-VNC.optimize] done with 29 nodes in 0.050
opset: domain=&#39;&#39; version=18
opset: domain=&#39;com.microsoft&#39; version=1
input: name=&#39;input_ids&#39; type=dtype(&#39;int64&#39;) shape=[1, 30]
init: name=&#39;init1_s1_3&#39; type=float32 shape=(1,) -- array([-inf], dtype=float32)-- Opset.make_node.1/Small##Opset.make_node.1/Small
init: name=&#39;_onx_transpose_p_decoder_attention_attention_0_query_weight0&#39; type=float32 shape=(16, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_attention_attention_0_query_weight)##p_decoder_attention_attention_0_query_weight/DynamoInterpret.placeholder.1/P(decoder.attention.attention.0.query.weight)
init: name=&#39;_onx_transpose_p_decoder_attention_attention_0_key_weight0&#39; type=float32 shape=(16, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_attention_attention_0_key_weight)##p_decoder_attention_attention_0_key_weight/DynamoInterpret.placeholder.1/P(decoder.attention.attention.0.key.weight)
init: name=&#39;_onx_transpose_p_decoder_attention_attention_0_value_weight0&#39; type=float32 shape=(16, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_attention_attention_0_value_weight)##p_decoder_attention_attention_0_value_weight/DynamoInterpret.placeholder.1/P(decoder.attention.attention.0.value.weight)
init: name=&#39;slice_2&#39; type=float32 shape=(30, 30)                      -- GraphBuilder.constant_folding.from/fold(init7_s1_0,init7_s1_1,init7_s1_30,slice_1)##slice_1/GraphBuilder.constant_folding.from/fold(b_decoder_attention_attention_0_mask,init7_s1_0,init7_s1_30)##b_decoder_attention_attention_0_mask/DynamoInterpret.placeholder.0##init7_s1_0/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##init7_s1_30/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##init7_s1_0/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##init7_s1_30/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##init7_s1_1/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape
init: name=&#39;_reshape_init1_s_20&#39; type=float32 shape=(1,) -- array([0.], dtype=float32)-- GraphBuilder.constant_folding.from/fold(init1_s_2,init7_s1_1)##init1_s_2/shape_type_compute._cast_inputs.0##shape_type_compute._cast_inputs.0##init7_s1_1/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape
init: name=&#39;_onx_transpose_p_decoder_attention_attention_1_query_weight0&#39; type=float32 shape=(16, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_attention_attention_1_query_weight)##p_decoder_attention_attention_1_query_weight/DynamoInterpret.placeholder.1/P(decoder.attention.attention.1.query.weight)
init: name=&#39;_onx_transpose_p_decoder_attention_attention_1_key_weight0&#39; type=float32 shape=(16, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_attention_attention_1_key_weight)##p_decoder_attention_attention_1_key_weight/DynamoInterpret.placeholder.1/P(decoder.attention.attention.1.key.weight)
init: name=&#39;_onx_transpose_p_decoder_attention_attention_1_value_weight0&#39; type=float32 shape=(16, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_attention_attention_1_value_weight)##p_decoder_attention_attention_1_value_weight/DynamoInterpret.placeholder.1/P(decoder.attention.attention.1.value.weight)
init: name=&#39;slice_4&#39; type=float32 shape=(30, 30)                      -- GraphBuilder.constant_folding.from/fold(init7_s1_0,init7_s1_1,init7_s1_30,slice_3)##slice_3/GraphBuilder.constant_folding.from/fold(b_decoder_attention_attention_1_mask,init7_s1_0,init7_s1_30)##b_decoder_attention_attention_1_mask/DynamoInterpret.placeholder.0##init7_s1_0/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##init7_s1_30/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##init7_s1_0/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##init7_s1_30/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##init7_s1_1/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape
init: name=&#39;_reshape_init1_s_202&#39; type=float32 shape=(1,) -- array([0.], dtype=float32)-- GraphBuilder.constant_folding.from/fold(init1_s_2,init7_s1_1)##init1_s_2/shape_type_compute._cast_inputs.0##shape_type_compute._cast_inputs.0##init7_s1_1/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape
init: name=&#39;_onx_transpose_p_decoder_attention_linear_weight0&#39; type=float32 shape=(32, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_attention_linear_weight)##p_decoder_attention_linear_weight/DynamoInterpret.placeholder.1/P(decoder.attention.linear.weight)
init: name=&#39;_onx_transpose_p_decoder_feed_forward_linear_1_weight0&#39; type=float32 shape=(16, 128)-- GraphBuilder.constant_folding.from/fold(p_decoder_feed_forward_linear_1_weight)##p_decoder_feed_forward_linear_1_weight/DynamoInterpret.placeholder.1/P(decoder.feed_forward.linear_1.weight)
init: name=&#39;_onx_transpose_p_decoder_feed_forward_linear_2_weight0&#39; type=float32 shape=(128, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_feed_forward_linear_2_weight)##p_decoder_feed_forward_linear_2_weight/DynamoInterpret.placeholder.1/P(decoder.feed_forward.linear_2.weight)
init: name=&#39;init1_s16_&#39; type=float32 shape=(16,)                      -- LayerNormalizationPattern.apply.scale##LayerNormalizationPattern.apply.scale
init: name=&#39;init1_s16_2&#39; type=float32 shape=(16,)                     -- LayerNormalizationPattern.apply.bias##LayerNormalizationPattern.apply.bias
init: name=&#39;embedding.embedding.weight&#39; type=float32 shape=(1024, 16) -- DynamoInterpret.placeholder.1/P(embedding.embedding.weight)
init: name=&#39;embedding.pe.weight&#39; type=float32 shape=(1024, 16)        -- DynamoInterpret.placeholder.1/P(embedding.pe.weight)
init: name=&#39;decoder.attention.linear.bias&#39; type=float32 shape=(16,)   -- DynamoInterpret.placeholder.1/P(decoder.attention.linear.bias)
init: name=&#39;decoder.feed_forward.linear_1.bias&#39; type=float32 shape=(128,)-- DynamoInterpret.placeholder.1/P(decoder.feed_forward.linear_1.bias)
init: name=&#39;decoder.feed_forward.linear_2.bias&#39; type=float32 shape=(16,)-- DynamoInterpret.placeholder.1/P(decoder.feed_forward.linear_2.bias)
Equal(slice_2, _reshape_init1_s_20) -&gt; eq
Gather(embedding.embedding.weight, input_ids) -&gt; embedding
Gather(embedding.pe.weight, input_ids) -&gt; embedding_1
  SkipLayerNormalization[com.microsoft](embedding, embedding_1, init1_s16_, init1_s16_2, epsilon=0.00) -&gt; _onx_div_sub_add00, unused, unused2, add
    MatMul(_onx_div_sub_add00, _onx_transpose_p_decoder_attention_attention_0_query_weight0) -&gt; linear
MatMul(_onx_div_sub_add00, _onx_transpose_p_decoder_attention_attention_0_key_weight0) -&gt; linear_1
  FusedMatMul[com.microsoft](linear, linear_1, alpha=0.25, transA=0, transB=1, transBatchA=0, transBatchB=0) -&gt; _onx_mul_matmul0
  Where(eq, init1_s1_3, _onx_mul_matmul0) -&gt; masked_fill
    Softmax(masked_fill, axis=-1) -&gt; softmax
MatMul(_onx_div_sub_add00, _onx_transpose_p_decoder_attention_attention_0_value_weight0) -&gt; linear_2
  MatMul(softmax, linear_2) -&gt; matmul_1
MatMul(_onx_div_sub_add00, _onx_transpose_p_decoder_attention_attention_1_query_weight0) -&gt; linear_3
MatMul(_onx_div_sub_add00, _onx_transpose_p_decoder_attention_attention_1_key_weight0) -&gt; linear_4
  FusedMatMul[com.microsoft](linear_3, linear_4, alpha=0.25, transA=0, transB=1, transBatchA=0, transBatchB=0) -&gt; _onx_mul_matmul_20
MatMul(_onx_div_sub_add00, _onx_transpose_p_decoder_attention_attention_1_value_weight0) -&gt; linear_5
Equal(slice_4, _reshape_init1_s_202) -&gt; eq_1
  Where(eq_1, init1_s1_3, _onx_mul_matmul_20) -&gt; masked_fill_1
    Softmax(masked_fill_1, axis=-1) -&gt; softmax_1
  MatMul(softmax_1, linear_5) -&gt; matmul_3
    Concat(matmul_1, matmul_3, axis=-1) -&gt; cat
      MatMul(cat, _onx_transpose_p_decoder_attention_linear_weight0) -&gt; _onx_matmul_cat0
        Add(_onx_matmul_cat0, decoder.attention.linear.bias) -&gt; linear_6
    SkipLayerNormalization[com.microsoft](linear_6, add, init1_s16_, init1_s16_2, epsilon=0.00) -&gt; _onx_div_sub_add_100, unused3, unused4, add_1
      MatMul(_onx_div_sub_add_100, _onx_transpose_p_decoder_feed_forward_linear_1_weight0) -&gt; _onx_matmul_layer_norm_10
        Add(_onx_matmul_layer_norm_10, decoder.feed_forward.linear_1.bias) -&gt; linear_7
          Relu(linear_7) -&gt; relu
            MatMul(relu, _onx_transpose_p_decoder_feed_forward_linear_2_weight0) -&gt; _onx_matmul_relu0
              Add(_onx_matmul_relu0, decoder.feed_forward.linear_2.bias) -&gt; linear_8
      Add(linear_8, add_1) -&gt; output_0
output: name=&#39;output_0&#39; type=dtype(&#39;float32&#39;) shape=[1, 30, 16]
</pre></div>
</div>
</section>
<section id="comparison-optimized-and-not-optimized">
<h2>Comparison optimized and not optimized?<a class="headerlink" href="#comparison-optimized-and-not-optimized" title="Link to this heading"></a></h2>
<p>The following tools is trying to match the node and shape inference
from two models. If they are not too different, the functions
is able to find out the differences. We can use to see
which operators were fused into bigger ones only implemented by
<a class="reference external" href="https://onnxruntime.ai/">onnxruntime</a>.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">res1</span></a></a></a></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">res2</span></a></a></a></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">align</span></a></a></a></a><span class="p">,</span> <a href="https://sdpython.github.io/doc/onnx-array-api/dev/api/reference.html#onnx_array_api.reference.DistanceExecution" title="onnx_array_api.reference.DistanceExecution" class="sphx-glr-backref-module-onnx_array_api-reference sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://sdpython.github.io/doc/onnx-array-api/dev/api/reference.html#onnx_array_api.reference.DistanceExecution" title="onnx_array_api.reference.DistanceExecution" class="sphx-glr-backref-module-onnx_array_api-reference sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://sdpython.github.io/doc/onnx-array-api/dev/api/reference.html#onnx_array_api.reference.DistanceExecution" title="onnx_array_api.reference.DistanceExecution" class="sphx-glr-backref-module-onnx_array_api-reference sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://sdpython.github.io/doc/onnx-array-api/dev/api/reference.html#onnx_array_api.reference.DistanceExecution" title="onnx_array_api.reference.DistanceExecution" class="sphx-glr-backref-module-onnx_array_api-reference sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dc</span></a></a></a></a> <span class="o">=</span> <a href="https://sdpython.github.io/doc/onnx-array-api/dev/api/reference.html#onnx_array_api.reference.compare_onnx_execution" title="onnx_array_api.reference.compare_onnx_execution" class="sphx-glr-backref-module-onnx_array_api-reference sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-array-api/dev/api/reference.html#onnx_array_api.reference.compare_onnx_execution" title="onnx_array_api.reference.compare_onnx_execution" class="sphx-glr-backref-module-onnx_array_api-reference sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-array-api/dev/api/reference.html#onnx_array_api.reference.compare_onnx_execution" title="onnx_array_api.reference.compare_onnx_execution" class="sphx-glr-backref-module-onnx_array_api-reference sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-array-api/dev/api/reference.html#onnx_array_api.reference.compare_onnx_execution" title="onnx_array_api.reference.compare_onnx_execution" class="sphx-glr-backref-module-onnx_array_api-reference sphx-glr-backref-type-py-function"><span class="n">compare_onnx_execution</span></a></a></a></a><span class="p">(</span>
    <a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx</span></a></a></a></a><span class="p">,</span> <a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx_optimized</span></a></a></a></a><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="bp">cls</span><span class="o">=</span><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/reference/index.html#experimental_experiment.reference.ExtendedReferenceEvaluator" title="experimental_experiment.reference.ExtendedReferenceEvaluator" class="sphx-glr-backref-module-experimental_experiment-reference sphx-glr-backref-type-py-class"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/reference/index.html#experimental_experiment.reference.ExtendedReferenceEvaluator" title="experimental_experiment.reference.ExtendedReferenceEvaluator" class="sphx-glr-backref-module-experimental_experiment-reference sphx-glr-backref-type-py-class"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/reference/index.html#experimental_experiment.reference.ExtendedReferenceEvaluator" title="experimental_experiment.reference.ExtendedReferenceEvaluator" class="sphx-glr-backref-module-experimental_experiment-reference sphx-glr-backref-type-py-class"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/reference/index.html#experimental_experiment.reference.ExtendedReferenceEvaluator" title="experimental_experiment.reference.ExtendedReferenceEvaluator" class="sphx-glr-backref-module-experimental_experiment-reference sphx-glr-backref-type-py-class"><span class="n">ExtendedReferenceEvaluator</span></a></a></a></a>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------&quot;</span><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">text</span></a></a></a></a> <span class="o">=</span> <a href="https://sdpython.github.io/doc/onnx-array-api/dev/api/reference.html#onnx_array_api.reference.DistanceExecution.to_str" title="onnx_array_api.reference.DistanceExecution.to_str" class="sphx-glr-backref-module-onnx_array_api-reference sphx-glr-backref-type-py-method"><a href="https://sdpython.github.io/doc/onnx-array-api/dev/api/reference.html#onnx_array_api.reference.DistanceExecution.to_str" title="onnx_array_api.reference.DistanceExecution.to_str" class="sphx-glr-backref-module-onnx_array_api-reference sphx-glr-backref-type-py-method"><a href="https://sdpython.github.io/doc/onnx-array-api/dev/api/reference.html#onnx_array_api.reference.DistanceExecution.to_str" title="onnx_array_api.reference.DistanceExecution.to_str" class="sphx-glr-backref-module-onnx_array_api-reference sphx-glr-backref-type-py-method"><a href="https://sdpython.github.io/doc/onnx-array-api/dev/api/reference.html#onnx_array_api.reference.DistanceExecution.to_str" title="onnx_array_api.reference.DistanceExecution.to_str" class="sphx-glr-backref-module-onnx_array_api-reference sphx-glr-backref-type-py-method"><span class="n">dc</span><span class="o">.</span><span class="n">to_str</span></a></a></a></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">res1</span></a></a></a></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">res2</span></a></a></a></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">align</span></a></a></a></a><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">text</span></a></a></a></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[compare_onnx_execution] generate inputs
[compare_onnx_execution] execute with 1 inputs
[compare_onnx_execution] execute first model
[compare_onnx_execution] got 68 results
[compare_onnx_execution] execute second model
[compare_onnx_execution] got 68 results (first model)
[compare_onnx_execution] got 58 results (second model)
[compare_onnx_execution] compute edit distance
[compare_onnx_execution] got 68 pairs
[compare_onnx_execution] done
------------
001 ~ | INITIA float32  2:256x256            AOCQ                 b_ | INITIA float32  1:1                  ?AAA                 in
002 - | INITIA float32  2:256x256            AOCQ                 b_ |
003 - | INITIA float32  1:1                  ?AAA                 in |
004 = | INITIA float32  2:16x16              ABAB                 _o | INITIA float32  2:16x16              ABAB                 _o
005 = | INITIA float32  2:16x16              AAAA                 _o | INITIA float32  2:16x16              AAAA                 _o
006 = | INITIA float32  2:16x16              ABAB                 _o | INITIA float32  2:16x16              ABAB                 _o
007 ~ | INITIA float32  1:1                  AAAA                 _r | INITIA float32  2:30x30              KGSP                 sl
008 = | INITIA float32  1:1                  AAAA                 _r | INITIA float32  1:1                  AAAA                 _r
009 = | INITIA float32  2:16x16              AACB                 _o | INITIA float32  2:16x16              AACB                 _o
010 = | INITIA float32  2:16x16              BBAZ                 _o | INITIA float32  2:16x16              BBAZ                 _o
011 = | INITIA float32  2:16x16              BZYZ                 _o | INITIA float32  2:16x16              BZYZ                 _o
012 ~ | INITIA float32  1:1                  AAAA                 _r | INITIA float32  2:30x30              KGSP                 sl
013 = | INITIA float32  1:1                  AAAA                 _r | INITIA float32  1:1                  AAAA                 _r
014 = | INITIA float32  2:32x16              ZAAB                 _o | INITIA float32  2:32x16              ZAAB                 _o
015 = | INITIA float32  2:16x128             AFZT                 _o | INITIA float32  2:16x128             AFZT                 _o
016 = | INITIA float32  2:128x16             AAAB                 _o | INITIA float32  2:128x16             AAAB                 _o
017 = | INITIA float32  1:16                 EEEE                 in | INITIA float32  1:16                 EEEE                 in
018 = | INITIA float32  1:16                 AAAA                 in | INITIA float32  1:16                 AAAA                 in
019 - | INITIA int64    1:2                  AAAA                 Sl |
020 - | INITIA int64    1:2                  EEAA                 Sl |
021 - | INITIA int64    1:2                  ABAA                 Sl |
022 - | INITIA int64    1:2                  AAAA                 Sl |
023 - | INITIA int64    1:2                  EEAA                 Sl |
024 - | INITIA int64    1:2                  ABAA                 Sl |
025 = | INITIA float32  2:1024x16            SCTO                 em | INITIA float32  2:1024x16            SCTO                 em
026 = | INITIA float32  2:1024x16            BMVK                 em | INITIA float32  2:1024x16            BMVK                 em
027 = | INITIA float32  1:16                 AAAA                 de | INITIA float32  1:16                 AAAA                 de
028 = | INITIA float32  1:128                AAAA                 de | INITIA float32  1:128                AAAA                 de
029 = | INITIA float32  1:16                 AAAA                 de | INITIA float32  1:16                 AAAA                 de
030 = | INPUT  int64    2:1x30               COAD                 in | INPUT  int64    2:1x30               COAD                 in
031 = | RESULT float32  3:1x30x16            ASVG Gather          em | RESULT float32  3:1x30x16            ASVG Gather          em
032 = | RESULT float32  3:1x30x16            HATW Gather          em | RESULT float32  3:1x30x16            HATW Gather          em
033 ~ | RESULT float32  3:1x30x16            ISNB Add             ad | RESULT float32  3:1x30x16            CYAA SkipLayerNormal _o
034 ~ | RESULT float32  3:1x30x16            CYAA LayerNormalizat _o | RESULT float32  3:1x30x1             ACAA SkipLayerNormal un
035 ~ | RESULT float32  3:1x30x16            WAXA MatMul          li | RESULT float32  3:1x30x1             GFGE SkipLayerNormal un
036 ~ | RESULT float32  3:1x30x16            FGFA MatMul          li | RESULT float32  3:1x30x16            ISNB SkipLayerNormal ad
037 ~ | RESULT float32  3:1x30x16            XTUU MatMul          li | RESULT float32  3:1x30x16            WAXA MatMul          li
038 ~ | RESULT float32  3:1x16x30            NFYC Transpose       tr | RESULT float32  3:1x30x16            FGFA MatMul          li
039 ~ | RESULT float32  3:1x30x30            EAHJ MatMul          ma | RESULT float32  3:1x30x30            BUIC FusedMatMul     _o
040 ~ | RESULT float32  3:1x30x30            BUIC Mul             _o | RESULT float32  3:1x30x16            XTUU MatMul          li
041 - | RESULT float32  2:30x30              KGSP Slice           sl |
042 = | RESULT bool     2:30x30              HLZC Equal           eq | RESULT bool     2:30x30              HLZC Equal           eq
043 = | RESULT float32  3:1x30x30            ???? Where           ma | RESULT float32  3:1x30x30            ???? Where           ma
044 = | RESULT float32  3:1x30x30            IHHH Softmax         so | RESULT float32  3:1x30x30            IHHH Softmax         so
045 = | RESULT float32  3:1x30x16            TVUU MatMul          ma | RESULT float32  3:1x30x16            TVUU MatMul          ma
046 = | RESULT float32  3:1x30x16            NBDY MatMul          li | RESULT float32  3:1x30x16            NBDY MatMul          li
047 = | RESULT float32  3:1x30x16            VASX MatMul          li | RESULT float32  3:1x30x16            VASX MatMul          li
048 ~ | RESULT float32  3:1x30x16            IZSY MatMul          li | RESULT float32  3:1x30x30            RCYW FusedMatMul     _o
049 ~ | RESULT float32  3:1x16x30            AOUZ Transpose       tr | RESULT float32  3:1x30x16            IZSY MatMul          li
050 ~ | RESULT float32  3:1x30x30            QLQJ MatMul          ma | RESULT bool     2:30x30              HLZC Equal           eq
051 ~ | RESULT float32  3:1x30x30            RCYW Mul             _o | RESULT float32  3:1x30x30            ???? Where           ma
052 ~ | RESULT float32  2:30x30              KGSP Slice           sl | RESULT float32  3:1x30x30            IGHH Softmax         so
053 - | RESULT bool     2:30x30              HLZC Equal           eq |
054 ~ | RESULT float32  3:1x30x30            ???? Where           ma | RESULT float32  3:1x30x16            QCGG MatMul          ma
055 ~ | RESULT float32  3:1x30x30            IGHH Softmax         so | RESULT float32  3:1x30x32            IYZC Concat          ca
056 ~ | RESULT float32  3:1x30x16            QCGG MatMul          ma | RESULT float32  3:1x30x16            AAAC MatMul          _o
057 ~ | RESULT float32  3:1x30x32            IYZC Concat          ca | RESULT float32  3:1x30x16            ZYAA Add             li
058 ~ | RESULT float32  3:1x30x16            AAAC MatMul          _o | RESULT float32  3:1x30x16            CYAA SkipLayerNormal _o
059 ~ | RESULT float32  3:1x30x16            ZYAA Add             li | RESULT float32  3:1x30x1             ABAA SkipLayerNormal un
060 ~ | RESULT float32  3:1x30x16            GQNC Add             ad | RESULT float32  3:1x30x1             GFGE SkipLayerNormal un
061 ~ | RESULT float32  3:1x30x16            CYAA LayerNormalizat _o | RESULT float32  3:1x30x16            GQNC SkipLayerNormal ad
062 = | RESULT float32  3:1x30x128           LJDZ MatMul          _o | RESULT float32  3:1x30x128           LJDZ MatMul          _o
063 = | RESULT float32  3:1x30x128           JHBX Add             li | RESULT float32  3:1x30x128           JHBX Add             li
064 = | RESULT float32  3:1x30x128           NHIT Relu            re | RESULT float32  3:1x30x128           NHIT Relu            re
065 = | RESULT float32  3:1x30x16            CDCA MatMul          _o | RESULT float32  3:1x30x16            CDCA MatMul          _o
066 = | RESULT float32  3:1x30x16            DFEC Add             li | RESULT float32  3:1x30x16            DFEC Add             li
067 = | RESULT float32  3:1x30x16            KVRE Add             ou | RESULT float32  3:1x30x16            KVRE Add             ou
068 = | OUTPUT float32  3:1x30x16            KVRE                 ou | OUTPUT float32  3:1x30x16            KVRE                 ou
</pre></div>
</div>
<p>The conversion should handle dynamic shapes as well as the input sequence
can be of any length. But thats a topic for another example.</p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (0 minutes 2.474 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-recipes-plot-exporter-recipes-c-modules-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/cb5ea34f3427dcee1ab63090ed6a2e2b/plot_exporter_recipes_c_modules.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_exporter_recipes_c_modules.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/ef2c9223bf91adc2ae05ba5115daa19e/plot_exporter_recipes_c_modules.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_exporter_recipes_c_modules.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../_downloads/4a095e9b122b9cb32142c72045f9a49c/plot_exporter_recipes_c_modules.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">plot_exporter_recipes_c_modules.zip</span></code></a></p>
</div>
</div>
<p class="rubric">Related examples</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="This is a frequent task which does not play well with dynamic shapes. Let&#x27;s see how to avoid using torch.cond."><img alt="" src="../_images/sphx_glr_plot_exporter_recipes_c_dynpad_thumb.png" />
<p><a class="reference internal" href="plot_exporter_recipes_c_dynpad.html#sphx-glr-auto-recipes-plot-exporter-recipes-c-dynpad-py"><span class="std std-ref">to_onnx and padding one dimension to a mulitple of a constant</span></a></p>
  <div class="sphx-glr-thumbnail-title">to_onnx and padding one dimension to a mulitple of a constant</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This is a frequent task which does not play well with dynamic shapes. Let&#x27;s see how to avoid using torch.cond."><img alt="" src="../_images/sphx_glr_plot_exporter_recipes_oe_dynpad_thumb.png" />
<p><a class="reference internal" href="plot_exporter_recipes_oe_dynpad.html#sphx-glr-auto-recipes-plot-exporter-recipes-oe-dynpad-py"><span class="std std-ref">torch.onnx.export and padding one dimension to a mulitple of a constant</span></a></p>
  <div class="sphx-glr-thumbnail-title">torch.onnx.export and padding one dimension to a mulitple of a constant</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Every conversion task must be tested on a large scale. One huge source of model is HuggingFace. We focus on the model Tiny-LLM. To avoid downloading any weigths, we write a function creating a random model based on the same architecture."><img alt="" src="../_images/sphx_glr_plot_exporter_exporter_untrained_tinyllm_thumb.png" />
<p><a class="reference internal" href="plot_exporter_exporter_untrained_tinyllm.html#sphx-glr-auto-recipes-plot-exporter-exporter-untrained-tinyllm-py"><span class="std std-ref">Check the exporter on a dummy from HuggingFace</span></a></p>
  <div class="sphx-glr-thumbnail-title">Check the exporter on a dummy from HuggingFace</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Exports model Phi-2. We use a dummy model. The main difficulty is to set the dynamic shapes properly. If there is an issue, you can go to the following line: torch/fx/experimental/symbolic_shapes.py#L5965 and look for log.info(&quot;set_replacement %s = %s (%s) %s&quot;, a, tgt, msg, tgt_bound) and add before or after, something like:"><img alt="" src="../_images/sphx_glr_plot_exporter_recipes_c_phi2_thumb.png" />
<p><a class="reference internal" href="plot_exporter_recipes_c_phi2.html#sphx-glr-auto-recipes-plot-exporter-recipes-c-phi2-py"><span class="std std-ref">to_onnx and Phi-2</span></a></p>
  <div class="sphx-glr-thumbnail-title">to_onnx and Phi-2</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="torch.export.export often breaks on big models because there are control flows or instructions breaking the propagation of dynamic shapes (see ...). The function usually gives an indication where the model implementation can be fixed but in case, that is not possible, we can try to export the model piece by piece: every module is converted separately from its submodule. A model can be exported even if one of its submodules cannot."><img alt="" src="../_images/sphx_glr_plot_exporter_exporter_phi35_piece_thumb.png" />
<p><a class="reference internal" href="plot_exporter_exporter_phi35_piece.html#sphx-glr-auto-recipes-plot-exporter-exporter-phi35-piece-py"><span class="std std-ref">Export Phi-3.5-mini-instruct piece by piece</span></a></p>
  <div class="sphx-glr-thumbnail-title">Export Phi-3.5-mini-instruct piece by piece</div>
</div></div><p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="plot_exporter_recipes_c_named_ds_auto.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">to_onnx: Rename Dynamic Shapes</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="plot_exporter_recipes_c_dynpad.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">to_onnx and padding one dimension to a mulitple of a constant</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2023-2024
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">to_onnx and submodules from LLMs</a><ul>
<li><a class="reference internal" href="#a-simple-llm">A simple LLM</a></li>
<li><a class="reference internal" href="#first-conversion-to-onnx">First conversion to ONNX</a></li>
<li><a class="reference internal" href="#onnx-with-submodules">ONNX with submodules</a></li>
<li><a class="reference internal" href="#inlining">Inlining</a></li>
<li><a class="reference internal" href="#optimizations">Optimizations</a></li>
<li><a class="reference internal" href="#optimizations-for-cuda">Optimizations for CUDA</a></li>
<li><a class="reference internal" href="#comparison-optimized-and-not-optimized">Comparison optimized and not optimized?</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../_static/documentation_options.js?v=1a9ffd16"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/furo.js?v=5fa4622c"></script>
    </body>
</html>