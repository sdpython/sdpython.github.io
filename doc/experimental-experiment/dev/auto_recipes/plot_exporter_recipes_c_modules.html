<!doctype html>
<html class="no-js" lang="en" data-content_root="../">
  <head><meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../genindex.html"><link rel="search" title="Search" href="../search.html"><link rel="next" title="Command Lines" href="../command_lines.html"><link rel="prev" title="to_onnx and padding one dimension to a mulitple of a constant" href="plot_exporter_recipes_c_dynpad.html">
        <link rel="prefetch" href="../_static/logo.png" as="image">

    <!-- Generated with Sphinx 8.2.3 and Furo 2025.09.25 -->
        <title>to_onnx and submodules from LLMs - experimental-experiment 0.1.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=580074bf" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css?v=7f9a90b1" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css?v=4ae1632d" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=8dab3a3b" />
    
    


<style>
  body {
    --color-code-background: #eeffcc;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle site navigation sidebar">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc" aria-label="Toggle table of contents sidebar">
<label class="overlay sidebar-overlay" for="__navigation"></label>
<label class="overlay toc-overlay" for="__toc"></label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <span class="icon"><svg><use href="#svg-menu"></use></svg></span>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">experimental-experiment 0.1.1 documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle" aria-label="Toggle Light / Dark / Auto color theme">
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <span class="icon"><svg><use href="#svg-toc"></use></svg></span>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="../_static/logo.png" alt="Logo"/>
  </div>
  
  <span class="sidebar-brand-text">experimental-experiment 0.1.1 documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Contents</span></p>
<ul class="current">
<li class="toctree-l1 has-children"><a class="reference internal" href="../design/index.html">Design</a><input aria-label="Toggle navigation of Design" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../design/exporter.html">Custom Exporter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../design/optimizer.html">Pattern Optimizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../design/backends.html">Dynamo Backends</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../tutorial/index.html">Tutorial</a><input aria-label="Toggle navigation of Tutorial" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../tutorial/shape.html">ShapeBuilder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorial/to_onnx.html">to_onnx: another export to investigate</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorial/errors.html">Unexpected Errors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorial/docker.html">Start from a docker</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api/index.html">API</a><input aria-label="Toggle navigation of API" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/gradient/index.html">.gradient</a><input aria-label="Toggle navigation of .gradient" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/gradient/ops/index.html">.gradient.ops</a><input aria-label="Toggle navigation of .gradient.ops" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/gradient/ops/op_broadcast_gradient_args.html">.gradient.ops.op_broadcast_gradient_args</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api/gradient/grad_helper.html">.gradient.grad_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/gradient/loss_helper.html">.gradient.loss_helper</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/reference/index.html">.reference</a><input aria-label="Toggle navigation of .reference" class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/reference/ops/index.html">.reference.ops</a><input aria-label="Toggle navigation of .reference.ops" class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_add_add_mul_mul.html">.reference.ops.op_add_add_mul_mul</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_average_pool_grad.html">.reference.ops.op_average_pool_grad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_cast_like.html">.reference.ops.op_cast_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_complex.html">.reference.ops.op_complex</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_concat.html">.reference.ops.op_concat</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_constant_of_shape.html">.reference.ops.op_constant_of_shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_fused_matmul.html">.reference.ops.op_fused_matmul</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_gather_grad.html">.reference.ops.op_gather_grad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_memcpy_host.html">.reference.ops.op_memcpy_host</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_mul_sigmoid.html">.reference.ops.op_mul_sigmoid</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_negxplus1.html">.reference.ops.op_negxplus1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_quick_gelu.html">.reference.ops.op_quick_gelu</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_replace_zero.html">.reference.ops.op_replace_zero</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_rotary.html">.reference.ops.op_rotary</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_qlinear_average_pool.html">.reference.ops.op_qlinear_average_pool</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_qlinear_conv.html">.reference.ops.op_qlinear_conv</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_scatter_elements.html">.reference.ops.op_scatter_elements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_scatternd_of_shape.html">.reference.ops.op_scatternd_of_shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_simplified_layer_normalization.html">.reference.ops.op_simplified_layer_normalization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_skip_layer_normalization.html">.reference.ops.op_skip_layer_normalization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_slice.html">.reference.ops.op_slice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_transpose_cast.html">.reference.ops.op_transpose_cast</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/reference/ops/op_tri_matrix.html">.reference.ops.op_tri_matrix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api/reference/evaluator.html">.reference.evaluator</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/reference/ort_evaluator.html">.reference.ort_evaluator</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/reference/quantized_tensor.html">.reference.quantized_tensor</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/convert/index.html">.convert</a><input aria-label="Toggle navigation of .convert" class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/convert/convert_helper.html">.convert.convert_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/convert/ort_helper.html">.convert.ort_helper</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/plotting/index.html">.plotting</a><input aria-label="Toggle navigation of .plotting" class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/plotting/data.html">.plotting.data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/plotting/memory.html">.plotting.memory</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/skl/index.html">.skl</a><input aria-label="Toggle navigation of .skl" class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/skl/convert.html">.skl.convert</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/skl/helpers.html">.skl.helpers</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/torch_interpreter/index.html">.torch_interpreter</a><input aria-label="Toggle navigation of .torch_interpreter" class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/_aten_functions.html">.torch_interpreter._aten_functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/_aten_functions_attention.html">.torch_interpreter._aten_functions_attention</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/_non_aten_functions.html">.torch_interpreter._non_aten_functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/_aten_methods.html">.torch_interpreter._aten_methods</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/_doc_.html">.torch_interpreter._doc_</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/_exceptions.html">.torch_interpreter._exceptions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/_prims_functions.html">.torch_interpreter._prims_functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/_torch_helper.html">.torch_interpreter._torch_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/aten_functions.html">.torch_interpreter.aten_functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/aten_methods.html">.torch_interpreter.aten_methods</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/dispatcher.html">.torch_interpreter.dispatcher</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/export_options.html">.torch_interpreter.export_options</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/interpreter.html">.torch_interpreter.interpreter</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/investigate_helper.html">.torch_interpreter.investigate_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/onnx_export.html">.torch_interpreter.onnx_export</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/oxs_dispatcher.html">.torch_interpreter.oxs_dispatcher</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/oxs_opset.html">.torch_interpreter.oxs_opset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/piece_by_piece.html">.torch_interpreter.piece_by_piece</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/piece_by_piece_serialize.html">.torch_interpreter.piece_by_piece_serialize</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_interpreter/tracing.html">.torch_interpreter.tracing</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/torch_models/index.html">.torch_models</a><input aria-label="Toggle navigation of .torch_models" class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_models/dump_helper.html">.torch_models.dump_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_models/training_helper.html">.torch_models.training_helper</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/xbuilder/index.html">.xbuilder</a><input aria-label="Toggle navigation of .xbuilder" class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" role="switch" type="checkbox"/><label for="toctree-checkbox-13"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/xbuilder/_onnx_helper.html">.xbuilder._onnx_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xbuilder/graph_builder.html">.xbuilder.graph_builder</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xbuilder/graph_builder_opset.html">.xbuilder.graph_builder_opset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xbuilder/model_container.html">.xbuilder.model_container</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xbuilder/optimization_options.html">.xbuilder.optimization_options</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xbuilder/reverse_graph_builder.html">.xbuilder.reverse_graph_builder</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/xoptim/index.html">.xoptim</a><input aria-label="Toggle navigation of .xoptim" class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" role="switch" type="checkbox"/><label for="toctree-checkbox-14"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/xoptim/patterns_investigation/index.html">.xoptim.patterns_investigation</a><input aria-label="Toggle navigation of .xoptim.patterns_investigation" class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" role="switch" type="checkbox"/><label for="toctree-checkbox-15"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_investigation/element_wise.html">.xoptim.patterns_investigation.element_wise</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_investigation/llm_patterns.html">.xoptim.patterns_investigation.llm_patterns</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/xoptim/patterns_ml/index.html">.xoptim.patterns_ml</a><input aria-label="Toggle navigation of .xoptim.patterns_ml" class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" role="switch" type="checkbox"/><label for="toctree-checkbox-16"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ml/tree_ensemble.html">.xoptim.patterns_ml.tree_ensemble</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/xoptim/patterns_exp/index.html">.xoptim.patterns_exp</a><input aria-label="Toggle navigation of .xoptim.patterns_exp" class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" role="switch" type="checkbox"/><label for="toctree-checkbox-17"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_exp/binary_operators.html">.xoptim.patterns_exp.binary_operators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_exp/constant_of_shape_scatter_nd.html">.xoptim.patterns_exp.constant_of_shape_scatter_nd</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_exp/constants.html">.xoptim.patterns_exp.constants</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_exp/simple_rotary.html">.xoptim.patterns_exp.simple_rotary</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_exp/unary_operators.html">.xoptim.patterns_exp.unary_operators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_exp/where_replace.html">.xoptim.patterns_exp.where_replace</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/xoptim/patterns/index.html">.xoptim.patterns</a><input aria-label="Toggle navigation of .xoptim.patterns" class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" role="switch" type="checkbox"/><label for="toctree-checkbox-18"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_any.html">.xoptim.patterns.onnx_any</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_attention.html">.xoptim.patterns.onnx_attention</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_cast.html">.xoptim.patterns.onnx_cast</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_clip.html">.xoptim.patterns.onnx_clip</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_constants.html">.xoptim.patterns.onnx_constants</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_conv.html">.xoptim.patterns.onnx_conv</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_dropout.html">.xoptim.patterns.onnx_dropout</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_equal.html">.xoptim.patterns.onnx_equal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_expand.html">.xoptim.patterns.onnx_expand</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_functions.html">.xoptim.patterns.onnx_functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_layer_normalization.html">.xoptim.patterns.onnx_layer_normalization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_matmul.html">.xoptim.patterns.onnx_matmul</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_mul.html">.xoptim.patterns.onnx_mul</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_reduce.html">.xoptim.patterns.onnx_reduce</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_reshape.html">.xoptim.patterns.onnx_reshape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_rotary.html">.xoptim.patterns.onnx_rotary</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_shape.html">.xoptim.patterns.onnx_shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_slice.html">.xoptim.patterns.onnx_slice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_split.html">.xoptim.patterns.onnx_split</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_sub.html">.xoptim.patterns.onnx_sub</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_sequence.html">.xoptim.patterns.onnx_sequence</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_transpose.html">.xoptim.patterns.onnx_transpose</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns/onnx_unsqueeze.html">.xoptim.patterns.onnx_unsqueeze</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/xoptim/patterns_ort/index.html">.xoptim.patterns_ort</a><input aria-label="Toggle navigation of .xoptim.patterns_ort" class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" role="switch" type="checkbox"/><label for="toctree-checkbox-19"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ort/activation.html">.xoptim.patterns_ort.activation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ort/activation_grad.html">.xoptim.patterns_ort.activation_grad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ort/batch_normalization.html">.xoptim.patterns_ort.batch_normalization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ort/fused_conv.html">.xoptim.patterns_ort.fused_conv</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ort/fused_matmul.html">.xoptim.patterns_ort.fused_matmul</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ort/gather_grad.html">.xoptim.patterns_ort.gather_grad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ort/llm_optim.html">.xoptim.patterns_ort.llm_optim</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ort/missing_kernels.html">.xoptim.patterns_ort.missing_kernels</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_ort/simplified_layer_normalization.html">.xoptim.patterns_ort.simplified_layer_normalization</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/xoptim/patterns_fix/index.html">.xoptim.patterns_fix</a><input aria-label="Toggle navigation of .xoptim.patterns_fix" class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" role="switch" type="checkbox"/><label for="toctree-checkbox-20"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/xoptim/patterns_fix/add_reduction_scatter_nd.html">.xoptim.patterns_fix.add_reduction_scatter_nd</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api/xoptim/graph_builder_optim.html">.xoptim.graph_builder_optim</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xoptim/order_optim.html">.xoptim.order_optim</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xoptim/patterns_api.html">.xoptim.patterns_api</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xoptim/repeated_optim.html">.xoptim.repeated_optim</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xoptim/unfused.html">.xoptim.unfused</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/xshape/index.html">.xshape</a><input aria-label="Toggle navigation of .xshape" class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" role="switch" type="checkbox"/><label for="toctree-checkbox-21"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/xshape/expressions_torch.html">.xshape.expressions_torch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xshape/evaluate_expressions.html">.xshape.evaluate_expressions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xshape/rename_expressions.html">.xshape.rename_expressions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xshape/simplify_expressions.html">.xshape.simplify_expressions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xshape/_builder_runtime.html">.xshape._builder_runtime</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xshape/_inference_runtime.html">.xshape._inference_runtime</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xshape/_shape_runtime.html">.xshape._shape_runtime</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xshape/_shape_helper.html">.xshape._shape_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xshape/_onnx_helper.html">.xshape._onnx_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xshape/shape_builder.html">.xshape.shape_builder</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xshape/shape_builder_impl.html">.xshape.shape_builder_impl</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xshape/shape_type_compute.html">.xshape.shape_type_compute</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/xshape/type_inference.html">.xshape.type_inference</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/torch_dynamo/index.html">.torch_dynamo</a><input aria-label="Toggle navigation of .torch_dynamo" class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" role="switch" type="checkbox"/><label for="toctree-checkbox-22"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_dynamo/_dynamo_exporter.html">.torch_dynamo._dynamo_exporter</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_dynamo/backend_helper.html">.torch_dynamo.backend_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_dynamo/debug_backend.html">.torch_dynamo.debug_backend</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_dynamo/fast_backend.html">.torch_dynamo.fast_backend</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_dynamo/partition.html">experimental_experiment.torch_dynamo.partition</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/torch_bench/index.html">.torch_bench</a><input aria-label="Toggle navigation of .torch_bench" class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" role="switch" type="checkbox"/><label for="toctree-checkbox-23"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_benchmark_runner.html">experimental_experiment.torch_bench._bash_bench_benchmark_runner</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_benchmark_runner_agg.html">experimental_experiment.torch_bench._bash_bench_benchmark_runner_agg</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_benchmark_runner_agg_helper.html">experimental_experiment.torch_bench._bash_bench_benchmark_runner_agg_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_cmd.html">experimental_experiment.torch_bench._bash_bench_cmd</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_model_runner.html">experimental_experiment.torch_bench._bash_bench_model_runner</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_models_helper.html">experimental_experiment.torch_bench._bash_bench_models_helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_set_dummies.html">experimental_experiment.torch_bench._bash_bench_set_dummies</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_set_explicit.html">experimental_experiment.torch_bench._bash_bench_set_explicit</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_set_huggingface.html">experimental_experiment.torch_bench._bash_bench_set_huggingface</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_set_timm.html">experimental_experiment.torch_bench._bash_bench_set_timm</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_set_torchbench.html">experimental_experiment.torch_bench._bash_bench_set_torchbench</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_set_torchbench_ado.html">experimental_experiment.torch_bench._bash_bench_set_torchbench_ado</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_bash_bench_untrained.html">experimental_experiment.torch_bench._bash_bench_untrained</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_dort_cmd_common.html">experimental_experiment.torch_bench._dort_cmd_common</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/_dort_cmd_common_models.html">experimental_experiment.torch_bench._dort_cmd_common_models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/bash_bench_agg.html">.torch_bench.bash_bench_agg</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/bash_bench_explicit.html">.torch_bench.bash_bench_explicit</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/bash_bench_huggingface.html">.torch_bench.bash_bench_huggingface</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/bash_bench_timm.html">.torch_bench.bash_bench_timm</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/bash_bench_torchbench.html">.torch_bench.bash_bench_torchbench</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/bash_bench_torchbench_ado.html">.torch_bench.bash_bench_torchbench_ado</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/bash_bench_untrained.html">.torch_bench.bash_bench_untrained</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/check_model.html">.torch_bench.check_model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/dort_bench.html">.torch_bench.dort_bench</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/dort_bench_profile.html">.torch_bench.dort_bench_profile</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/dort_profile.html">.torch_bench.dort_profile</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/export_model.html">.torch_bench.export_model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/torch_bench/export_model_helper.html">.torch_bench.export_model_helper</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api/_bench_test.html">._bench_test</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/_command_lines_parser.html">._command_lines_parser</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/args.html">.args</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bench_run.html">.bench_run</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/checks.html">.checks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/export_helpers.html">.export_helpers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/ext_test_case.html">.ext_test_case</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/helpers.html">.helpers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/memory_peak.html">.memory_peak</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/model_run.html">.model_run</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/onnx_tools.html">.onnx_tools</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/ort_session.html">.ort_session</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/torch_test_helper.html">.torch_test_helper</a></li>
</ul>
</li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="../galleries.html">Galleries of Examples and Recipes</a><input aria-label="Toggle navigation of Galleries of Examples and Recipes" checked="" class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" role="switch" type="checkbox"/><label for="toctree-checkbox-24"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul class="current">
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/index.html">Examples Gallery</a><input aria-label="Toggle navigation of Examples Gallery" class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" role="switch" type="checkbox"/><label for="toctree-checkbox-25"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_custom_backend_101.html">101: A custom backend for torch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_linreg_101.html">101: Linear Regression and export to ONNX</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_optimize_101.html">101: Onnx Model Optimization based on Pattern Rewriting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_rewrite_101.html">101: Onnx Model Rewriting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_profile_existing_onnx_101.html">101: Profile an existing model with onnxruntime</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_export_101.html">101: Some dummy examples with torch.export.export</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_onnxscript_102.html">102: Examples with onnxscript</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_executorch_102.html">102: First test with ExecuTorch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_export_compile_102.html">102: Tweak onnx export</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_shape_inference.html">201: Better shape inference</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_export_201.html">201: Evaluate different ways to export a torch model to ONNX</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_torch_sklearn_201.html">201: Use torch to export a scikit-learn model into ONNX</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/plot_model_to_python.html">Playground for big optimization pattern</a></li>
</ul>
</li>
<li class="toctree-l2 current has-children"><a class="reference internal" href="index.html">Exporter Recipes Gallery</a><input aria-label="Toggle navigation of Exporter Recipes Gallery" checked="" class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" role="switch" type="checkbox"/><label for="toctree-checkbox-26"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_exporter_untrained_tinyllm.html">Check the exporter on a dummy from HuggingFace</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_exporter_phi35_piece.html">Export Phi-3.5-mini-instruct piece by piece</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_exporter_draft_mode.html">Export Phi-3.5-mini-instruct with draft_export</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_exporter_reportibility.html">Export Phi-3.5-mini-instruct with report_exportability</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_exporter_scan_pdist.html">Export a model with a loop (scan)</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_recipes_c_custom_ops_inplace.html">to_onnx and a custom operator inplace</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_recipes_c_custom_ops_fct.html">to_onnx and a custom operator registered with a function</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_recipes_c_cond.html">to_onnx and a model with a test</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_exporter_recipes_c_dynpad.html">to_onnx and padding one dimension to a mulitple of a constant</a></li>
<li class="toctree-l3 current current-page"><a class="current reference internal" href="#">to_onnx and submodules from LLMs</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../command_lines.html">Command Lines</a><input aria-label="Toggle navigation of Command Lines" class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" role="switch" type="checkbox"/><label for="toctree-checkbox-27"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../bench/index.html">Benchmarks from the command line</a><input aria-label="Toggle navigation of Benchmarks from the command line" class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" role="switch" type="checkbox"/><label for="toctree-checkbox-28"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../bench/dort_bench.html">experimental_experiment.torch_bench.dort_bench</a></li>
<li class="toctree-l3"><a class="reference internal" href="../bench/dort_profile.html">experimental_experiment.torch_bench.dort_profile</a></li>
<li class="toctree-l3"><a class="reference internal" href="../bench/scripts.html">Interesting scripts or command lines</a></li>
<li class="toctree-l3"><a class="reference internal" href="../bench/bash_bench.html">Measuring the exporters on a short list of sets of models</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../tools/index.html">Tools from the command line</a><input aria-label="Toggle navigation of Tools from the command line" class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" role="switch" type="checkbox"/><label for="toctree-checkbox-29"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../tools/lighten.html">python -m experimental_experiment lighten and unlighten</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tools/optimize.html">python -m experimental_experiment optimize</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tools/print.html">python -m experimental_experiment print</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tools/run.html">python -m experimental_experiment run</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../miscellaneous/index.html">Miscellaneous</a><input aria-label="Toggle navigation of Miscellaneous" class="toctree-checkbox" id="toctree-checkbox-30" name="toctree-checkbox-30" role="switch" type="checkbox"/><label for="toctree-checkbox-30"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../miscellaneous/export_times.html">Export Times</a></li>
<li class="toctree-l2"><a class="reference internal" href="../miscellaneous/long_outputs.html">Long Outputs uneasy to read</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">More</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../CHANGELOGS.html">Change Logs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="../_sources/auto_recipes/plot_exporter_recipes_c_modules.rst" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle" aria-label="Toggle Light / Dark / Auto color theme">
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <span class="icon"><svg><use href="#svg-toc"></use></svg></span>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-auto-recipes-plot-exporter-recipes-c-modules-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="to-onnx-and-submodules-from-llms">
<span id="l-plot-exporter-recipes-custom-modules"></span><span id="sphx-glr-auto-recipes-plot-exporter-recipes-c-modules-py"></span><h1>to_onnx and submodules from LLMs<a class="headerlink" href="#to-onnx-and-submodules-from-llms" title="Link to this heading"></a></h1>
<p>Big models are hard to read once converted into onnx.
Lets see how to improve their readibility.
The code is inspired from
<a class="reference external" href="https://medium.com/&#64;msouza.os/llm-from-scratch-with-pytorch-9f21808c6319">LLM from scratch with Pytorch</a>.</p>
<section id="a-simple-llm">
<h2>A simple LLM<a class="headerlink" href="#a-simple-llm" title="Link to this heading"></a></h2>
<p>All comments were removed from the code to make it less verbose.
A few fixes were applied to the original code.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">onnx</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">onnx.inliner</span><span class="w"> </span><span class="kn">import</span> <a href="https://onnx.ai/onnx/api/inliner.html#onnx.inliner.inline_local_functions" title="onnx.inliner.inline_local_functions" class="sphx-glr-backref-module-onnx-inliner sphx-glr-backref-type-py-function"><a href="https://onnx.ai/onnx/api/inliner.html#onnx.inliner.inline_local_functions" title="onnx.inliner.inline_local_functions" class="sphx-glr-backref-module-onnx-inliner sphx-glr-backref-type-py-function"><a href="https://onnx.ai/onnx/api/inliner.html#onnx.inliner.inline_local_functions" title="onnx.inliner.inline_local_functions" class="sphx-glr-backref-module-onnx-inliner sphx-glr-backref-type-py-function"><span class="n">inline_local_functions</span></a></a></a>
<span class="kn">from</span><span class="w"> </span><span class="nn">onnx_array_api.plotting.graphviz_helper</span><span class="w"> </span><span class="kn">import</span> <a href="https://sdpython.github.io/doc/onnx-array-api/dev/api/plotting.html#onnx_array_api.plotting.graphviz_helper.plot_dot" title="onnx_array_api.plotting.graphviz_helper.plot_dot" class="sphx-glr-backref-module-onnx_array_api-plotting-graphviz_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-array-api/dev/api/plotting.html#onnx_array_api.plotting.graphviz_helper.plot_dot" title="onnx_array_api.plotting.graphviz_helper.plot_dot" class="sphx-glr-backref-module-onnx_array_api-plotting-graphviz_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-array-api/dev/api/plotting.html#onnx_array_api.plotting.graphviz_helper.plot_dot" title="onnx_array_api.plotting.graphviz_helper.plot_dot" class="sphx-glr-backref-module-onnx_array_api-plotting-graphviz_helper sphx-glr-backref-type-py-function"><span class="n">plot_dot</span></a></a></a>
<span class="kn">from</span><span class="w"> </span><span class="nn">onnx_array_api.reference</span><span class="w"> </span><span class="kn">import</span> <a href="https://sdpython.github.io/doc/onnx-array-api/dev/api/reference.html#onnx_array_api.reference.compare_onnx_execution" title="onnx_array_api.reference.compare_onnx_execution" class="sphx-glr-backref-module-onnx_array_api-reference sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-array-api/dev/api/reference.html#onnx_array_api.reference.compare_onnx_execution" title="onnx_array_api.reference.compare_onnx_execution" class="sphx-glr-backref-module-onnx_array_api-reference sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-array-api/dev/api/reference.html#onnx_array_api.reference.compare_onnx_execution" title="onnx_array_api.reference.compare_onnx_execution" class="sphx-glr-backref-module-onnx_array_api-reference sphx-glr-backref-type-py-function"><span class="n">compare_onnx_execution</span></a></a></a>
<span class="kn">from</span><span class="w"> </span><span class="nn">onnx_diagnostic.helpers</span><span class="w"> </span><span class="kn">import</span> <a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/index.html#onnx_diagnostic.helpers.max_diff" title="onnx_diagnostic.helpers.max_diff" class="sphx-glr-backref-module-onnx_diagnostic-helpers sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/index.html#onnx_diagnostic.helpers.max_diff" title="onnx_diagnostic.helpers.max_diff" class="sphx-glr-backref-module-onnx_diagnostic-helpers sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/index.html#onnx_diagnostic.helpers.max_diff" title="onnx_diagnostic.helpers.max_diff" class="sphx-glr-backref-module-onnx_diagnostic-helpers sphx-glr-backref-type-py-function"><span class="n">max_diff</span></a></a></a>
<span class="kn">from</span><span class="w"> </span><span class="nn">onnx_diagnostic.helpers.onnx_helper</span><span class="w"> </span><span class="kn">import</span> <a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><span class="n">pretty_onnx</span></a></a></a>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">onnxruntime</span><span class="w"> </span><span class="kn">import</span> <a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession" title="onnxruntime.capi.onnxruntime_inference_collection.InferenceSession" class="sphx-glr-backref-module-onnxruntime-capi-onnxruntime_inference_collection sphx-glr-backref-type-py-class"><a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession" title="onnxruntime.capi.onnxruntime_inference_collection.InferenceSession" class="sphx-glr-backref-module-onnxruntime-capi-onnxruntime_inference_collection sphx-glr-backref-type-py-class"><a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession" title="onnxruntime.capi.onnxruntime_inference_collection.InferenceSession" class="sphx-glr-backref-module-onnxruntime-capi-onnxruntime_inference_collection sphx-glr-backref-type-py-class"><span class="n">InferenceSession</span></a></a></a>
<span class="kn">from</span><span class="w"> </span><span class="nn">experimental_experiment.reference</span><span class="w"> </span><span class="kn">import</span> <a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/reference/index.html#experimental_experiment.reference.ExtendedReferenceEvaluator" title="experimental_experiment.reference.ExtendedReferenceEvaluator" class="sphx-glr-backref-module-experimental_experiment-reference sphx-glr-backref-type-py-class"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/reference/index.html#experimental_experiment.reference.ExtendedReferenceEvaluator" title="experimental_experiment.reference.ExtendedReferenceEvaluator" class="sphx-glr-backref-module-experimental_experiment-reference sphx-glr-backref-type-py-class"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/reference/index.html#experimental_experiment.reference.ExtendedReferenceEvaluator" title="experimental_experiment.reference.ExtendedReferenceEvaluator" class="sphx-glr-backref-module-experimental_experiment-reference sphx-glr-backref-type-py-class"><span class="n">ExtendedReferenceEvaluator</span></a></a></a>
<span class="kn">from</span><span class="w"> </span><span class="nn">experimental_experiment.torch_interpreter</span><span class="w"> </span><span class="kn">import</span> <a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter sphx-glr-backref-type-py-function"><span class="n">to_onnx</span></a></a></a>
<span class="kn">from</span><span class="w"> </span><span class="nn">experimental_experiment.xbuilder</span><span class="w"> </span><span class="kn">import</span> <a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/xbuilder/index.html#experimental_experiment.xbuilder.OptimizationOptions" title="experimental_experiment.xbuilder.OptimizationOptions" class="sphx-glr-backref-module-experimental_experiment-xbuilder sphx-glr-backref-type-py-class"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/xbuilder/index.html#experimental_experiment.xbuilder.OptimizationOptions" title="experimental_experiment.xbuilder.OptimizationOptions" class="sphx-glr-backref-module-experimental_experiment-xbuilder sphx-glr-backref-type-py-class"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/xbuilder/index.html#experimental_experiment.xbuilder.OptimizationOptions" title="experimental_experiment.xbuilder.OptimizationOptions" class="sphx-glr-backref-module-experimental_experiment-xbuilder sphx-glr-backref-type-py-class"><span class="n">OptimizationOptions</span></a></a></a>


<span class="k">class</span><span class="w"> </span><span class="nc">Embedding</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a></a></a><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding" title="torch.nn.Embedding" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding" title="torch.nn.Embedding" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding" title="torch.nn.Embedding" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span></a></a></a><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pe</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding" title="torch.nn.Embedding" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding" title="torch.nn.Embedding" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding" title="torch.nn.Embedding" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span></a></a></a><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">word_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">word_pe</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pe</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">word_emb</span> <span class="o">+</span> <span class="n">word_pe</span>


<span class="k">class</span><span class="w"> </span><span class="nc">AttentionBlock</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a></a></a><span class="p">):</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">context_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">query</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a></a></a><span class="p">(</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">key</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a></a></a><span class="p">(</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a></a></a><span class="p">(</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="n">ones</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.ones.html#torch.ones" title="torch.ones" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><a href="https://docs.pytorch.org/docs/stable/generated/torch.ones.html#torch.ones" title="torch.ones" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><a href="https://docs.pytorch.org/docs/stable/generated/torch.ones.html#torch.ones" title="torch.ones" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">ones</span></a></a></a><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">[</span><span class="n">context_size</span><span class="p">,</span> <span class="n">context_size</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><a href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch</span><span class="o">.</span><span class="n">float</span></a></a></a><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;mask&quot;</span><span class="p">,</span> <span class="n">tensor</span><span class="o">=</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.tril.html#torch.tril" title="torch.tril" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><a href="https://docs.pytorch.org/docs/stable/generated/torch.tril.html#torch.tril" title="torch.tril" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><a href="https://docs.pytorch.org/docs/stable/generated/torch.tril.html#torch.tril" title="torch.tril" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">tril</span></a></a></a><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">ones</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">_B</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">C</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>

        <span class="n">query</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">key</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">value</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">qk</span> <span class="o">=</span> <span class="n">query</span> <span class="o">@</span> <span class="n">key</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">C</span><span class="o">**-</span><span class="mf">0.5</span>
        <span class="n">attention</span> <span class="o">=</span> <span class="n">qk</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="p">[:</span><span class="n">T</span><span class="p">,</span> <span class="p">:</span><span class="n">T</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;-inf&quot;</span><span class="p">))</span>
        <span class="n">attention</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.functional.softmax.html#torch.nn.functional.softmax" title="torch.nn.functional.softmax" class="sphx-glr-backref-module-torch-nn-functional sphx-glr-backref-type-py-function"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.functional.softmax.html#torch.nn.functional.softmax" title="torch.nn.functional.softmax" class="sphx-glr-backref-module-torch-nn-functional sphx-glr-backref-type-py-function"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.functional.softmax.html#torch.nn.functional.softmax" title="torch.nn.functional.softmax" class="sphx-glr-backref-module-torch-nn-functional sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span></a></a></a><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">attention</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim</span></a></a></a><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">=</span> <span class="n">attention</span> <span class="o">@</span> <span class="n">value</span>
        <span class="k">return</span> <span class="n">out</span>


<span class="k">class</span><span class="w"> </span><span class="nc">MultiAttentionBlock</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a></a></a><span class="p">):</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">context_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.ModuleList.html#torch.nn.ModuleList" title="torch.nn.ModuleList" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.ModuleList.html#torch.nn.ModuleList" title="torch.nn.ModuleList" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.ModuleList.html#torch.nn.ModuleList" title="torch.nn.ModuleList" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span></a></a></a><span class="p">(</span>
            <span class="n">modules</span><span class="o">=</span><span class="p">[</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">AttentionBlock</span></a></a></a><span class="p">(</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">context_size</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_heads</span><span class="p">)]</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a></a></a><span class="p">(</span>
            <span class="n">in_features</span><span class="o">=</span><span class="n">embedding_dim</span> <span class="o">*</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">embedding_dim</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.cat.html#torch.cat" title="torch.cat" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><a href="https://docs.pytorch.org/docs/stable/generated/torch.cat.html#torch.cat" title="torch.cat" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><a href="https://docs.pytorch.org/docs/stable/generated/torch.cat.html#torch.cat" title="torch.cat" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">cat</span></a></a></a><span class="p">(</span><span class="n">tensors</span><span class="o">=</span><span class="p">[</span><span class="n">attention</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">attention</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">],</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim</span></a></a></a><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>


<span class="k">class</span><span class="w"> </span><span class="nc">FeedForward</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a></a></a><span class="p">):</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">ff_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear_1</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a></a></a><span class="p">(</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">ff_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU" title="torch.nn.ReLU" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU" title="torch.nn.ReLU" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU" title="torch.nn.ReLU" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span></a></a></a><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear_2</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a></a></a><span class="p">(</span><span class="n">ff_dim</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>


<span class="k">class</span><span class="w"> </span><span class="nc">DecoderLayer</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a></a></a><span class="p">):</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">context_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">ff_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">MultiAttentionBlock</span></a></a></a><span class="p">(</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">context_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feed_forward</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">FeedForward</span></a></a></a><span class="p">(</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">ff_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm_1</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html#torch.nn.LayerNorm" title="torch.nn.LayerNorm" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html#torch.nn.LayerNorm" title="torch.nn.LayerNorm" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html#torch.nn.LayerNorm" title="torch.nn.LayerNorm" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span></a></a></a><span class="p">(</span><span class="n">normalized_shape</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm_2</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html#torch.nn.LayerNorm" title="torch.nn.LayerNorm" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html#torch.nn.LayerNorm" title="torch.nn.LayerNorm" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html#torch.nn.LayerNorm" title="torch.nn.LayerNorm" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span></a></a></a><span class="p">(</span><span class="n">normalized_shape</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x_norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">attention</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">x_norm</span><span class="p">)</span>
        <span class="n">attention</span> <span class="o">=</span> <span class="n">attention</span> <span class="o">+</span> <span class="n">x</span>

        <span class="n">attention_norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_2</span><span class="p">(</span><span class="n">attention</span><span class="p">)</span>
        <span class="n">ff</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feed_forward</span><span class="p">(</span><span class="n">attention_norm</span><span class="p">)</span>
        <span class="n">ff</span> <span class="o">=</span> <span class="n">ff</span> <span class="o">+</span> <span class="n">attention</span>

        <span class="k">return</span> <span class="n">ff</span>


<span class="k">class</span><span class="w"> </span><span class="nc">LLM</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a></a></a><span class="p">):</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">vocab_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1024</span><span class="p">,</span>
        <span class="n">embedding_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span>
        <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
        <span class="n">context_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span>
        <span class="n">ff_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">Embedding</span></a></a></a><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">DecoderLayer</span></a></a></a><span class="p">(</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">context_size</span><span class="p">,</span> <span class="n">ff_dim</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_ids</span></a></a></a><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_ids</span></a></a></a><span class="p">)</span>
        <a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">y</span></a></a></a> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">y</span></a></a></a>


<span class="n">llm</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">LLM</span></a></a></a><span class="p">()</span>
<a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim</span></a></a></a> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
<a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_ids</span></a></a></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.randint.html#torch.randint" title="torch.randint" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><a href="https://docs.pytorch.org/docs/stable/generated/torch.randint.html#torch.randint" title="torch.randint" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><a href="https://docs.pytorch.org/docs/stable/generated/torch.randint.html#torch.randint" title="torch.randint" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">randint</span></a></a></a><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim</span></a></a></a><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch</span><span class="o">.</span><span class="n">int64</span></a></a></a><span class="p">)</span>
<a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">y</span></a></a></a> <span class="o">=</span> <span class="n">llm</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_ids</span></a></a></a><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;output: shape=</span><span class="si">{</span><a href="https://docs.pytorch.org/docs/stable/size.html#torch.Size" title="torch.Size" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/size.html#torch.Size" title="torch.Size" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/size.html#torch.Size" title="torch.Size" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">y</span><span class="o">.</span><span class="n">shape</span></a></a></a><span class="si">}</span><span class="s2">, min=</span><span class="si">{</span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">y</span></a></a></a><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="si">}</span><span class="s2">, max=</span><span class="si">{</span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">y</span></a></a></a><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>output: shape=torch.Size([1, 30, 16]), min=-4.500553607940674, max=5.789700508117676
</pre></div>
</div>
</section>
<section id="first-conversion-to-onnx">
<h2>First conversion to ONNX<a class="headerlink" href="#first-conversion-to-onnx" title="Link to this heading"></a></h2>
<p>The conversion relies on <a class="reference external" href="https://docs.pytorch.org/docs/stable/export/api_reference.html#torch.export.export" title="(in PyTorch v2.9)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.export.export()</span></code></a>.
which gives:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.pytorch.org/docs/stable/export/api_reference.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/export/api_reference.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/export/api_reference.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ep</span></a></a></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/export/api_reference.html#torch.export.export" title="torch.export.export" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-function"><a href="https://docs.pytorch.org/docs/stable/export/api_reference.html#torch.export.export" title="torch.export.export" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-function"><a href="https://docs.pytorch.org/docs/stable/export/api_reference.html#torch.export.export" title="torch.export.export" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">export</span><span class="o">.</span><span class="n">export</span></a></a></a><span class="p">(</span><span class="n">llm</span><span class="p">,</span> <span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_ids</span></a></a></a><span class="p">,))</span>
<span class="nb">print</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/export/api_reference.html#torch.export.ExportedProgram.graph" title="torch.export.ExportedProgram.graph" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-property"><a href="https://docs.pytorch.org/docs/stable/export/api_reference.html#torch.export.ExportedProgram.graph" title="torch.export.ExportedProgram.graph" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-property"><a href="https://docs.pytorch.org/docs/stable/export/api_reference.html#torch.export.ExportedProgram.graph" title="torch.export.ExportedProgram.graph" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-property"><span class="n">ep</span><span class="o">.</span><span class="n">graph</span></a></a></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>graph():
    %p_embedding_embedding_weight : [num_users=1] = placeholder[target=p_embedding_embedding_weight]
    %p_embedding_pe_weight : [num_users=1] = placeholder[target=p_embedding_pe_weight]
    %p_decoder_attention_attention_0_query_weight : [num_users=1] = placeholder[target=p_decoder_attention_attention_0_query_weight]
    %p_decoder_attention_attention_0_key_weight : [num_users=1] = placeholder[target=p_decoder_attention_attention_0_key_weight]
    %p_decoder_attention_attention_0_value_weight : [num_users=1] = placeholder[target=p_decoder_attention_attention_0_value_weight]
    %p_decoder_attention_attention_1_query_weight : [num_users=1] = placeholder[target=p_decoder_attention_attention_1_query_weight]
    %p_decoder_attention_attention_1_key_weight : [num_users=1] = placeholder[target=p_decoder_attention_attention_1_key_weight]
    %p_decoder_attention_attention_1_value_weight : [num_users=1] = placeholder[target=p_decoder_attention_attention_1_value_weight]
    %p_decoder_attention_linear_weight : [num_users=1] = placeholder[target=p_decoder_attention_linear_weight]
    %p_decoder_attention_linear_bias : [num_users=1] = placeholder[target=p_decoder_attention_linear_bias]
    %p_decoder_feed_forward_linear_1_weight : [num_users=1] = placeholder[target=p_decoder_feed_forward_linear_1_weight]
    %p_decoder_feed_forward_linear_1_bias : [num_users=1] = placeholder[target=p_decoder_feed_forward_linear_1_bias]
    %p_decoder_feed_forward_linear_2_weight : [num_users=1] = placeholder[target=p_decoder_feed_forward_linear_2_weight]
    %p_decoder_feed_forward_linear_2_bias : [num_users=1] = placeholder[target=p_decoder_feed_forward_linear_2_bias]
    %p_decoder_norm_1_weight : [num_users=1] = placeholder[target=p_decoder_norm_1_weight]
    %p_decoder_norm_1_bias : [num_users=1] = placeholder[target=p_decoder_norm_1_bias]
    %p_decoder_norm_2_weight : [num_users=1] = placeholder[target=p_decoder_norm_2_weight]
    %p_decoder_norm_2_bias : [num_users=1] = placeholder[target=p_decoder_norm_2_bias]
    %b_decoder_attention_attention_0_mask : [num_users=1] = placeholder[target=b_decoder_attention_attention_0_mask]
    %b_decoder_attention_attention_1_mask : [num_users=1] = placeholder[target=b_decoder_attention_attention_1_mask]
    %input_ids : [num_users=2] = placeholder[target=input_ids]
    %embedding : [num_users=1] = call_function[target=torch.ops.aten.embedding.default](args = (%p_embedding_embedding_weight, %input_ids), kwargs = {})
    %embedding_1 : [num_users=1] = call_function[target=torch.ops.aten.embedding.default](args = (%p_embedding_pe_weight, %input_ids), kwargs = {})
    %add : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%embedding, %embedding_1), kwargs = {})
    %layer_norm : [num_users=6] = call_function[target=torch.ops.aten.layer_norm.default](args = (%add, [16], %p_decoder_norm_1_weight, %p_decoder_norm_1_bias), kwargs = {})
    %linear : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%layer_norm, %p_decoder_attention_attention_0_query_weight), kwargs = {})
    %linear_1 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%layer_norm, %p_decoder_attention_attention_0_key_weight), kwargs = {})
    %linear_2 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%layer_norm, %p_decoder_attention_attention_0_value_weight), kwargs = {})
    %transpose : [num_users=1] = call_function[target=torch.ops.aten.transpose.int](args = (%linear_1, -2, -1), kwargs = {})
    %matmul : [num_users=1] = call_function[target=torch.ops.aten.matmul.default](args = (%linear, %transpose), kwargs = {})
    %mul : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%matmul, 0.25), kwargs = {})
    %slice_1 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%b_decoder_attention_attention_0_mask, 0, 0, 30), kwargs = {})
    %slice_2 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_1, 1, 0, 30), kwargs = {})
    %eq : [num_users=1] = call_function[target=torch.ops.aten.eq.Scalar](args = (%slice_2, 0), kwargs = {})
    %masked_fill : [num_users=1] = call_function[target=torch.ops.aten.masked_fill.Scalar](args = (%mul, %eq, -inf), kwargs = {})
    %softmax : [num_users=1] = call_function[target=torch.ops.aten.softmax.int](args = (%masked_fill, -1), kwargs = {})
    %matmul_1 : [num_users=1] = call_function[target=torch.ops.aten.matmul.default](args = (%softmax, %linear_2), kwargs = {})
    %linear_3 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%layer_norm, %p_decoder_attention_attention_1_query_weight), kwargs = {})
    %linear_4 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%layer_norm, %p_decoder_attention_attention_1_key_weight), kwargs = {})
    %linear_5 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%layer_norm, %p_decoder_attention_attention_1_value_weight), kwargs = {})
    %transpose_1 : [num_users=1] = call_function[target=torch.ops.aten.transpose.int](args = (%linear_4, -2, -1), kwargs = {})
    %matmul_2 : [num_users=1] = call_function[target=torch.ops.aten.matmul.default](args = (%linear_3, %transpose_1), kwargs = {})
    %mul_1 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%matmul_2, 0.25), kwargs = {})
    %slice_3 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%b_decoder_attention_attention_1_mask, 0, 0, 30), kwargs = {})
    %slice_4 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_3, 1, 0, 30), kwargs = {})
    %eq_1 : [num_users=1] = call_function[target=torch.ops.aten.eq.Scalar](args = (%slice_4, 0), kwargs = {})
    %masked_fill_1 : [num_users=1] = call_function[target=torch.ops.aten.masked_fill.Scalar](args = (%mul_1, %eq_1, -inf), kwargs = {})
    %softmax_1 : [num_users=1] = call_function[target=torch.ops.aten.softmax.int](args = (%masked_fill_1, -1), kwargs = {})
    %matmul_3 : [num_users=1] = call_function[target=torch.ops.aten.matmul.default](args = (%softmax_1, %linear_5), kwargs = {})
    %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%matmul_1, %matmul_3], -1), kwargs = {})
    %linear_6 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%cat, %p_decoder_attention_linear_weight, %p_decoder_attention_linear_bias), kwargs = {})
    %add_1 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%linear_6, %add), kwargs = {})
    %layer_norm_1 : [num_users=1] = call_function[target=torch.ops.aten.layer_norm.default](args = (%add_1, [16], %p_decoder_norm_2_weight, %p_decoder_norm_2_bias), kwargs = {})
    %linear_7 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%layer_norm_1, %p_decoder_feed_forward_linear_1_weight, %p_decoder_feed_forward_linear_1_bias), kwargs = {})
    %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%linear_7,), kwargs = {})
    %linear_8 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%relu, %p_decoder_feed_forward_linear_2_weight, %p_decoder_feed_forward_linear_2_bias), kwargs = {})
    %add_2 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%linear_8, %add_1), kwargs = {})
    return (add_2,)
</pre></div>
</div>
<p>Then function <a class="reference internal" href="../api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx"><code class="xref py py-func docutils literal notranslate"><span class="pre">to_onnx</span></code></a>
converts it into ONNX.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx</span></a></a></a> <span class="o">=</span> <a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter sphx-glr-backref-type-py-function"><span class="n">to_onnx</span></a></a></a><span class="p">(</span><span class="n">llm</span><span class="p">,</span> <span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_ids</span></a></a></a><span class="p">,))</span>
<span class="nb">print</span><span class="p">(</span><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><span class="n">pretty_onnx</span></a></a></a><span class="p">(</span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx</span></a></a></a><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>opset: domain=&#39;&#39; version=18
input: name=&#39;input_ids&#39; type=dtype(&#39;int64&#39;) shape=[1, 30]
init: name=&#39;b_decoder_attention_attention_0_mask&#39; type=float32 shape=(256, 256)-- DynamoInterpret.placeholder.0
init: name=&#39;b_decoder_attention_attention_1_mask&#39; type=float32 shape=(256, 256)-- DynamoInterpret.placeholder.0
init: name=&#39;init7_s1_1&#39; type=int64 shape=(1,) -- array([1])           -- Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape
init: name=&#39;init7_s1_0&#39; type=int64 shape=(1,) -- array([0])           -- Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape
init: name=&#39;init7_s1_30&#39; type=int64 shape=(1,) -- array([30])         -- Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape
init: name=&#39;init1_s1_3&#39; type=float32 shape=(1,) -- array([-inf], dtype=float32)-- Opset.make_node.1/Small##Opset.make_node.1/Small
init: name=&#39;p_decoder_attention_attention_0_query_weight::T10&#39; type=float32 shape=(16, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_attention_attention_0_query_weight)##p_decoder_attention_attention_0_query_weight/DynamoInterpret.placeholder.1/P(decoder.attention.attention.0.query.weight)
init: name=&#39;p_decoder_attention_attention_0_key_weight::T10&#39; type=float32 shape=(16, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_attention_attention_0_key_weight)##p_decoder_attention_attention_0_key_weight/DynamoInterpret.placeholder.1/P(decoder.attention.attention.0.key.weight)
init: name=&#39;p_decoder_attention_attention_0_value_weight::T10&#39; type=float32 shape=(16, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_attention_attention_0_value_weight)##p_decoder_attention_attention_0_value_weight/DynamoInterpret.placeholder.1/P(decoder.attention.attention.0.value.weight)
init: name=&#39;init1_s_::RSh1&#39; type=float32 shape=(1,) -- array([0.25], dtype=float32)-- GraphBuilder.constant_folding.from/fold(init1_s_,init7_s1_1)##init1_s_/shape_type_compute._cast_inputs.1(mul_Tensor)##shape_type_compute._cast_inputs.1(mul_Tensor)##init7_s1_1/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape
init: name=&#39;init1_s_2::RSh1&#39; type=float32 shape=(1,) -- array([0.], dtype=float32)-- GraphBuilder.constant_folding.from/fold(init1_s_2,init7_s1_1)##init1_s_2/shape_type_compute._cast_inputs.0##shape_type_compute._cast_inputs.0##init7_s1_1/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape
init: name=&#39;p_decoder_attention_attention_1_query_weight::T10&#39; type=float32 shape=(16, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_attention_attention_1_query_weight)##p_decoder_attention_attention_1_query_weight/DynamoInterpret.placeholder.1/P(decoder.attention.attention.1.query.weight)
init: name=&#39;p_decoder_attention_attention_1_key_weight::T10&#39; type=float32 shape=(16, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_attention_attention_1_key_weight)##p_decoder_attention_attention_1_key_weight/DynamoInterpret.placeholder.1/P(decoder.attention.attention.1.key.weight)
init: name=&#39;p_decoder_attention_attention_1_value_weight::T10&#39; type=float32 shape=(16, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_attention_attention_1_value_weight)##p_decoder_attention_attention_1_value_weight/DynamoInterpret.placeholder.1/P(decoder.attention.attention.1.value.weight)
init: name=&#39;p_decoder_attention_linear_weight::T10&#39; type=float32 shape=(32, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_attention_linear_weight)##p_decoder_attention_linear_weight/DynamoInterpret.placeholder.1/P(decoder.attention.linear.weight)
init: name=&#39;p_decoder_feed_forward_linear_1_weight::T10&#39; type=float32 shape=(16, 128)-- GraphBuilder.constant_folding.from/fold(p_decoder_feed_forward_linear_1_weight)##p_decoder_feed_forward_linear_1_weight/DynamoInterpret.placeholder.1/P(decoder.feed_forward.linear_1.weight)
init: name=&#39;p_decoder_feed_forward_linear_2_weight::T10&#39; type=float32 shape=(128, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_feed_forward_linear_2_weight)##p_decoder_feed_forward_linear_2_weight/DynamoInterpret.placeholder.1/P(decoder.feed_forward.linear_2.weight)
init: name=&#39;init1_s16_&#39; type=float32 shape=(16,)                      -- LayerNormalizationPattern.apply.scale##LayerNormalizationPattern.apply.scale
init: name=&#39;init1_s16_2&#39; type=float32 shape=(16,)                     -- LayerNormalizationPattern.apply.bias##LayerNormalizationPattern.apply.bias
init: name=&#39;embedding.embedding.weight&#39; type=float32 shape=(1024, 16) -- DynamoInterpret.placeholder.1/P(embedding.embedding.weight)
init: name=&#39;embedding.pe.weight&#39; type=float32 shape=(1024, 16)        -- DynamoInterpret.placeholder.1/P(embedding.pe.weight)
init: name=&#39;decoder.attention.linear.bias&#39; type=float32 shape=(16,)   -- DynamoInterpret.placeholder.1/P(decoder.attention.linear.bias)
init: name=&#39;decoder.feed_forward.linear_1.bias&#39; type=float32 shape=(128,)-- DynamoInterpret.placeholder.1/P(decoder.feed_forward.linear_1.bias)
init: name=&#39;decoder.feed_forward.linear_2.bias&#39; type=float32 shape=(16,)-- DynamoInterpret.placeholder.1/P(decoder.feed_forward.linear_2.bias)
Concat(init7_s1_0, init7_s1_1, axis=0) -&gt; SliceSlicePattern_init7_s1_1_axis
Concat(init7_s1_30, init7_s1_30, axis=0) -&gt; SliceSlicePattern_init7_s1_30_end
Concat(init7_s1_0, init7_s1_0, axis=0) -&gt; SliceSlicePattern_init7_s1_0_start
  Slice(b_decoder_attention_attention_0_mask, SliceSlicePattern_init7_s1_0_start, SliceSlicePattern_init7_s1_30_end, SliceSlicePattern_init7_s1_1_axis) -&gt; slice_2
    Equal(slice_2, init1_s_2::RSh1) -&gt; eq
Gather(embedding.embedding.weight, input_ids) -&gt; embedding
Gather(embedding.pe.weight, input_ids) -&gt; embedding_1
  Add(embedding, embedding_1) -&gt; add
    LayerNormalization(add, init1_s16_, init1_s16_2, axis=-1, epsilon=0.00, stash_type=1) -&gt; _onx_div_sub_add
      MatMul(_onx_div_sub_add, p_decoder_attention_attention_0_query_weight::T10) -&gt; linear
MatMul(_onx_div_sub_add, p_decoder_attention_attention_0_key_weight::T10) -&gt; linear_1
  Transpose(linear_1, perm=[0,2,1]) -&gt; transpose
    MatMul(linear, transpose) -&gt; matmul
      Mul(matmul, init1_s_::RSh1) -&gt; _onx_mul_matmul
      Where(eq, init1_s1_3, _onx_mul_matmul) -&gt; masked_fill
        Softmax(masked_fill, axis=-1) -&gt; softmax
      MatMul(_onx_div_sub_add, p_decoder_attention_attention_0_value_weight::T10) -&gt; linear_2
        MatMul(softmax, linear_2) -&gt; matmul_1
      MatMul(_onx_div_sub_add, p_decoder_attention_attention_1_query_weight::T10) -&gt; linear_3
MatMul(_onx_div_sub_add, p_decoder_attention_attention_1_key_weight::T10) -&gt; linear_4
  Transpose(linear_4, perm=[0,2,1]) -&gt; transpose_1
    MatMul(linear_3, transpose_1) -&gt; matmul_2
      Mul(matmul_2, init1_s_::RSh1) -&gt; _onx_mul_matmul_2
MatMul(_onx_div_sub_add, p_decoder_attention_attention_1_value_weight::T10) -&gt; linear_5
Slice(b_decoder_attention_attention_1_mask, SliceSlicePattern_init7_s1_0_start, SliceSlicePattern_init7_s1_30_end, SliceSlicePattern_init7_s1_1_axis) -&gt; slice_4
  Equal(slice_4, init1_s_2::RSh1) -&gt; eq_1
    Where(eq_1, init1_s1_3, _onx_mul_matmul_2) -&gt; masked_fill_1
      Softmax(masked_fill_1, axis=-1) -&gt; softmax_1
  MatMul(softmax_1, linear_5) -&gt; matmul_3
    Concat(matmul_1, matmul_3, axis=-1) -&gt; cat
      MatMul(cat, p_decoder_attention_linear_weight::T10) -&gt; _onx_matmul_cat
        Add(_onx_matmul_cat, decoder.attention.linear.bias) -&gt; linear_6
    Add(linear_6, add) -&gt; add_1
      LayerNormalization(add_1, init1_s16_, init1_s16_2, axis=-1, epsilon=0.00, stash_type=1) -&gt; _onx_div_sub_add_1
        MatMul(_onx_div_sub_add_1, p_decoder_feed_forward_linear_1_weight::T10) -&gt; _onx_matmul_layer_norm_1
          Add(_onx_matmul_layer_norm_1, decoder.feed_forward.linear_1.bias) -&gt; linear_7
            Relu(linear_7) -&gt; relu
              MatMul(relu, p_decoder_feed_forward_linear_2_weight::T10) -&gt; _onx_matmul_relu
                Add(_onx_matmul_relu, decoder.feed_forward.linear_2.bias) -&gt; linear_8
      Add(linear_8, add_1) -&gt; output_0
output: name=&#39;output_0&#39; type=dtype(&#39;float32&#39;) shape=[1, 30, 16]
</pre></div>
</div>
<p>Lets check there is no discrepancy.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession" title="onnxruntime.capi.onnxruntime_inference_collection.InferenceSession" class="sphx-glr-backref-module-onnxruntime-capi-onnxruntime_inference_collection sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession" title="onnxruntime.capi.onnxruntime_inference_collection.InferenceSession" class="sphx-glr-backref-module-onnxruntime-capi-onnxruntime_inference_collection sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession" title="onnxruntime.capi.onnxruntime_inference_collection.InferenceSession" class="sphx-glr-backref-module-onnxruntime-capi-onnxruntime_inference_collection sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sess</span></a></a></a> <span class="o">=</span> <a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession" title="onnxruntime.capi.onnxruntime_inference_collection.InferenceSession" class="sphx-glr-backref-module-onnxruntime-capi-onnxruntime_inference_collection sphx-glr-backref-type-py-class"><a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession" title="onnxruntime.capi.onnxruntime_inference_collection.InferenceSession" class="sphx-glr-backref-module-onnxruntime-capi-onnxruntime_inference_collection sphx-glr-backref-type-py-class"><a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession" title="onnxruntime.capi.onnxruntime_inference_collection.InferenceSession" class="sphx-glr-backref-module-onnxruntime-capi-onnxruntime_inference_collection sphx-glr-backref-type-py-class"><span class="n">InferenceSession</span></a></a></a><span class="p">(</span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx</span></a></a></a><span class="o">.</span><span class="n">SerializeToString</span><span class="p">(),</span> <span class="n">providers</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;CPUExecutionProvider&quot;</span><span class="p">])</span>
<a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">feeds</span></a></a></a> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_ids</span></a></a></a><span class="o">=</span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_ids</span></a></a></a><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
<a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">got</span></a></a></a> <span class="o">=</span> <a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession.run" title="onnxruntime.InferenceSession.run" class="sphx-glr-backref-module-onnxruntime sphx-glr-backref-type-py-method"><a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession.run" title="onnxruntime.InferenceSession.run" class="sphx-glr-backref-module-onnxruntime sphx-glr-backref-type-py-method"><a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession.run" title="onnxruntime.InferenceSession.run" class="sphx-glr-backref-module-onnxruntime sphx-glr-backref-type-py-method"><span class="n">sess</span><span class="o">.</span><span class="n">run</span></a></a></a><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">feeds</span></a></a></a><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

<a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">diff</span></a></a></a> <span class="o">=</span> <a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/index.html#onnx_diagnostic.helpers.max_diff" title="onnx_diagnostic.helpers.max_diff" class="sphx-glr-backref-module-onnx_diagnostic-helpers sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/index.html#onnx_diagnostic.helpers.max_diff" title="onnx_diagnostic.helpers.max_diff" class="sphx-glr-backref-module-onnx_diagnostic-helpers sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/index.html#onnx_diagnostic.helpers.max_diff" title="onnx_diagnostic.helpers.max_diff" class="sphx-glr-backref-module-onnx_diagnostic-helpers sphx-glr-backref-type-py-function"><span class="n">max_diff</span></a></a></a><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">y</span></a></a></a><span class="p">,</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">got</span></a></a></a><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;output: shape=</span><span class="si">{</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">got</span><span class="o">.</span><span class="n">shape</span></a></a></a><span class="si">}</span><span class="s2">, min=</span><span class="si">{</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">got</span></a></a></a><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="si">}</span><span class="s2">, max=</span><span class="si">{</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">got</span></a></a></a><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;max discrepancy=</span><span class="si">{</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">diff</span></a></a></a><span class="p">[</span><span class="s1">&#39;abs&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>output: shape=(1, 30, 16), min=-4.500553607940674, max=5.789700508117676
max discrepancy=4.76837158203125e-07
</pre></div>
</div>
<p>Lets save the ONNX model.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">onnx</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx</span></a></a></a><span class="p">,</span> <span class="s2">&quot;plot_exporter_recipes_c_modules.inlined.onnx&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="onnx-with-submodules">
<h2>ONNX with submodules<a class="headerlink" href="#onnx-with-submodules" title="Link to this heading"></a></h2>
<p>Lets produce an ONNX model with submodules.
Function <a class="reference internal" href="../api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx"><code class="xref py py-func docutils literal notranslate"><span class="pre">to_onnx</span></code></a>
is calling the function <a class="reference external" href="https://docs.pytorch.org/docs/stable/export/api_reference.html#torch.export.unflatten.unflatten" title="(in PyTorch v2.9)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.export.unflatten.unflatten()</span></code></a>
under the hood. The fx graph looks like the following.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.pytorch.org/docs/stable/export/api_reference.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/export/api_reference.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/export/api_reference.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ep</span></a></a></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/export/api_reference.html#torch.export.export" title="torch.export.export" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-function"><a href="https://docs.pytorch.org/docs/stable/export/api_reference.html#torch.export.export" title="torch.export.export" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-function"><a href="https://docs.pytorch.org/docs/stable/export/api_reference.html#torch.export.export" title="torch.export.export" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">export</span><span class="o">.</span><span class="n">export</span></a></a></a><span class="p">(</span><span class="n">llm</span><span class="p">,</span> <span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_ids</span></a></a></a><span class="p">,))</span>
<span class="n">unflatten_ep</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/export/api_reference.html#module-torch.export.unflatten" title="torch.export.unflatten" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-module"><a href="https://docs.pytorch.org/docs/stable/export/api_reference.html#module-torch.export.unflatten" title="torch.export.unflatten" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-module"><a href="https://docs.pytorch.org/docs/stable/export/api_reference.html#module-torch.export.unflatten" title="torch.export.unflatten" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-module"><span class="n">torch</span><span class="o">.</span><span class="n">export</span><span class="o">.</span><span class="n">unflatten</span></a></a></a><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/export/api_reference.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/export/api_reference.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/export/api_reference.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ep</span></a></a></a><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/fx.html#torch.fx.Graph" title="torch.fx.Graph" class="sphx-glr-backref-module-torch-fx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/fx.html#torch.fx.Graph" title="torch.fx.Graph" class="sphx-glr-backref-module-torch-fx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/fx.html#torch.fx.Graph" title="torch.fx.Graph" class="sphx-glr-backref-module-torch-fx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">unflatten_ep</span><span class="o">.</span><span class="n">graph</span></a></a></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>/usr/lib/python3.12/copyreg.py:99: FutureWarning: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.
  return cls.__new__(cls, *args)
graph():
    %input_ids : [num_users=1] = placeholder[target=input_ids]
    %embedding : [num_users=1] = call_module[target=embedding](args = (%input_ids,), kwargs = {})
    %decoder : [num_users=1] = call_module[target=decoder](args = (%embedding,), kwargs = {})
    return (decoder,)
</pre></div>
</div>
<p>The exported graph looks simpler and shows something like:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="n">decoder</span> <span class="p">:</span> <span class="p">[</span><span class="n">num_users</span><span class="o">=</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">call_module</span><span class="p">[</span><span class="n">target</span><span class="o">=</span><span class="n">decoder</span><span class="p">](</span><span class="n">args</span> <span class="o">=</span> <span class="p">(</span><span class="o">%</span><span class="n">embedding</span><span class="p">,),</span> <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{})</span>
</pre></div>
</div>
<p>It preserves the hierarchy but it does not necessarily preserves the signatures
of the initial modules. Thats was not one of our goals.
The tricky part is module called (<em>embedding</em>) is not an instance <code class="docutils literal notranslate"><span class="pre">Embedding</span></code>
but an instance of <a class="reference external" href="https://github.com/pytorch/pytorch/blob/main/torch/export/unflatten.py#L116">InterpreterModule</a>
and contains the fx nodes contributing to the submodule and coming from the
previous graph.</p>
<p>Now the ONNX graph.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx_module</span></a></a></a> <span class="o">=</span> <a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter sphx-glr-backref-type-py-function"><span class="n">to_onnx</span></a></a></a><span class="p">(</span><span class="n">llm</span><span class="p">,</span> <span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_ids</span></a></a></a><span class="p">,),</span> <span class="n">export_modules_as_functions</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><span class="n">pretty_onnx</span></a></a></a><span class="p">(</span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx_module</span></a></a></a><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>/usr/lib/python3.12/copyreg.py:99: FutureWarning: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.
  return cls.__new__(cls, *args)
opset: domain=&#39;&#39; version=18
opset: domain=&#39;aten_local_function&#39; version=1
input: name=&#39;input_ids&#39; type=dtype(&#39;int64&#39;) shape=[1, 30]
init: name=&#39;embedding.embedding.weight&#39; type=float32 shape=(1024, 16) -- GraphBuilder.make_local_function/from(embedding.embedding.weight)
init: name=&#39;embedding.pe.weight&#39; type=float32 shape=(1024, 16)        -- GraphBuilder.make_local_function/from(embedding.pe.weight)
init: name=&#39;mask&#39; type=float32 shape=(256, 256)                       -- GraphBuilder.make_local_function/from(mask)
init: name=&#39;weight::T10&#39; type=float32 shape=(16, 16)                  -- GraphBuilder.make_local_function/from(weight::T10)
init: name=&#39;weight::T102&#39; type=float32 shape=(16, 16)                 -- GraphBuilder.make_local_function/from(weight::T102)
init: name=&#39;weight::T103&#39; type=float32 shape=(16, 16)                 -- GraphBuilder.make_local_function/from(weight::T103)
init: name=&#39;mask2&#39; type=float32 shape=(256, 256)                      -- GraphBuilder.make_local_function/from(mask2)
init: name=&#39;weight::T104&#39; type=float32 shape=(16, 16)                 -- GraphBuilder.make_local_function/from(weight::T104)
init: name=&#39;weight::T1022&#39; type=float32 shape=(16, 16)                -- GraphBuilder.make_local_function/from(weight::T1022)
init: name=&#39;weight::T1032&#39; type=float32 shape=(16, 16)                -- GraphBuilder.make_local_function/from(weight::T1032)
init: name=&#39;weight::T105&#39; type=float32 shape=(32, 16)                 -- GraphBuilder.make_local_function/from(weight::T105)
init: name=&#39;decoder.feed_forward.linear_1.bias&#39; type=float32 shape=(128,)-- GraphBuilder.make_local_function/from(decoder.feed_forward.linear_1.bias)
init: name=&#39;weight::T106&#39; type=float32 shape=(16, 128)                -- GraphBuilder.make_local_function/from(weight::T106)
init: name=&#39;weight::T1023&#39; type=float32 shape=(128, 16)               -- GraphBuilder.make_local_function/from(weight::T1023)
Constant(value=[1.0, 1.0,...) -&gt; init1_s16_
Gather(embedding.embedding.weight, input_ids) -&gt; embedding2
Gather(embedding.pe.weight, input_ids) -&gt; pe
  Add(embedding2, pe) -&gt; embedding
Constant(value=[0.0, 0.0,...) -&gt; init1_s16_2
  LayerNormalization(embedding, init1_s16_, init1_s16_2, axis=-1, epsilon=0.00, stash_type=1) -&gt; norm_1
    MatMul(norm_1, weight::T10) -&gt; query
Constant(value=[-inf]) -&gt; init1_s1_
Constant(value=[0.25]) -&gt; init1_s_::RSh1
Constant(value=[0.0]) -&gt; init1_s_2::RSh1
Constant(value=[0, 0]) -&gt; SliceSlicePattern_init7_s1_0_start
Constant(value=[30, 30]) -&gt; SliceSlicePattern_init7_s1_30_end
Constant(value=[0, 1]) -&gt; SliceSlicePattern_init7_s1_1_axis
  Slice(mask, SliceSlicePattern_init7_s1_0_start, SliceSlicePattern_init7_s1_30_end, SliceSlicePattern_init7_s1_1_axis) -&gt; slice_2
  Equal(slice_2, init1_s_2::RSh1) -&gt; eq
MatMul(norm_1, weight::T102) -&gt; key
  Transpose(key, perm=[0,2,1]) -&gt; transpose
    MatMul(query, transpose) -&gt; matmul
  Mul(matmul, init1_s_::RSh1) -&gt; _onx_mul_matmul
  Where(eq, init1_s1_, _onx_mul_matmul) -&gt; masked_fill
    Softmax(masked_fill, axis=-1) -&gt; softmax
MatMul(norm_1, weight::T103) -&gt; value
  MatMul(softmax, value) -&gt; attention_0
Constant(value=[-inf]) -&gt; init1_s1_2
Constant(value=[0.25]) -&gt; init1_s_::RSh12
Constant(value=[0.0]) -&gt; init1_s_2::RSh12
Constant(value=[0, 0]) -&gt; SliceSlicePattern_init7_s1_0_start2
Constant(value=[30, 30]) -&gt; SliceSlicePattern_init7_s1_30_end2
Constant(value=[0, 1]) -&gt; SliceSlicePattern_init7_s1_1_axis2
  Slice(mask2, SliceSlicePattern_init7_s1_0_start2, SliceSlicePattern_init7_s1_30_end2, SliceSlicePattern_init7_s1_1_axis2) -&gt; slice_22
  Equal(slice_22, init1_s_2::RSh12) -&gt; eq2
MatMul(norm_1, weight::T104) -&gt; query2
MatMul(norm_1, weight::T1022) -&gt; key2
  Transpose(key2, perm=[0,2,1]) -&gt; transpose2
  MatMul(query2, transpose2) -&gt; matmul2
  Mul(matmul2, init1_s_::RSh12) -&gt; _onx_mul_matmul2
  Where(eq2, init1_s1_2, _onx_mul_matmul2) -&gt; masked_fill2
    Softmax(masked_fill2, axis=-1) -&gt; softmax2
MatMul(norm_1, weight::T1032) -&gt; value2
  MatMul(softmax2, value2) -&gt; attention_1
    Concat(attention_0, attention_1, axis=-1) -&gt; cat
      MatMul(cat, weight::T105) -&gt; _onx_matmul_cat
Constant(value=[-0.157050...) -&gt; bias
  Add(_onx_matmul_cat, bias) -&gt; attention
    Add(attention, embedding) -&gt; add_1
Constant(value=[1.0, 1.0,...) -&gt; init1_s16_3
Constant(value=[0.0, 0.0,...) -&gt; init1_s16_22
  LayerNormalization(add_1, init1_s16_3, init1_s16_22, axis=-1, epsilon=0.00, stash_type=1) -&gt; norm_2
    MatMul(norm_2, weight::T106) -&gt; _onx_matmul_layer_norm_1
      Add(_onx_matmul_layer_norm_1, decoder.feed_forward.linear_1.bias) -&gt; linear_1
        Relu(linear_1) -&gt; relu
          MatMul(relu, weight::T1023) -&gt; _onx_matmul_relu
Constant(value=[0.0367000...) -&gt; bias2
  Add(_onx_matmul_relu, bias2) -&gt; feed_forward
    Add(feed_forward, add_1) -&gt; output_0
output: name=&#39;output_0&#39; type=dtype(&#39;float32&#39;) shape=[1, 30, 16]
</pre></div>
</div>
<p>We check again there is no new discrepancies.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession" title="onnxruntime.capi.onnxruntime_inference_collection.InferenceSession" class="sphx-glr-backref-module-onnxruntime-capi-onnxruntime_inference_collection sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession" title="onnxruntime.capi.onnxruntime_inference_collection.InferenceSession" class="sphx-glr-backref-module-onnxruntime-capi-onnxruntime_inference_collection sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession" title="onnxruntime.capi.onnxruntime_inference_collection.InferenceSession" class="sphx-glr-backref-module-onnxruntime-capi-onnxruntime_inference_collection sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sess</span></a></a></a> <span class="o">=</span> <a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession" title="onnxruntime.capi.onnxruntime_inference_collection.InferenceSession" class="sphx-glr-backref-module-onnxruntime-capi-onnxruntime_inference_collection sphx-glr-backref-type-py-class"><a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession" title="onnxruntime.capi.onnxruntime_inference_collection.InferenceSession" class="sphx-glr-backref-module-onnxruntime-capi-onnxruntime_inference_collection sphx-glr-backref-type-py-class"><a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession" title="onnxruntime.capi.onnxruntime_inference_collection.InferenceSession" class="sphx-glr-backref-module-onnxruntime-capi-onnxruntime_inference_collection sphx-glr-backref-type-py-class"><span class="n">InferenceSession</span></a></a></a><span class="p">(</span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx_module</span></a></a></a><span class="o">.</span><span class="n">SerializeToString</span><span class="p">(),</span> <span class="n">providers</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;CPUExecutionProvider&quot;</span><span class="p">])</span>
<a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">feeds</span></a></a></a> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_ids</span></a></a></a><span class="o">=</span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_ids</span></a></a></a><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
<a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">got</span></a></a></a> <span class="o">=</span> <a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession.run" title="onnxruntime.InferenceSession.run" class="sphx-glr-backref-module-onnxruntime sphx-glr-backref-type-py-method"><a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession.run" title="onnxruntime.InferenceSession.run" class="sphx-glr-backref-module-onnxruntime sphx-glr-backref-type-py-method"><a href="https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession.run" title="onnxruntime.InferenceSession.run" class="sphx-glr-backref-module-onnxruntime sphx-glr-backref-type-py-method"><span class="n">sess</span><span class="o">.</span><span class="n">run</span></a></a></a><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">feeds</span></a></a></a><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

<a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">diff</span></a></a></a> <span class="o">=</span> <a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/index.html#onnx_diagnostic.helpers.max_diff" title="onnx_diagnostic.helpers.max_diff" class="sphx-glr-backref-module-onnx_diagnostic-helpers sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/index.html#onnx_diagnostic.helpers.max_diff" title="onnx_diagnostic.helpers.max_diff" class="sphx-glr-backref-module-onnx_diagnostic-helpers sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/index.html#onnx_diagnostic.helpers.max_diff" title="onnx_diagnostic.helpers.max_diff" class="sphx-glr-backref-module-onnx_diagnostic-helpers sphx-glr-backref-type-py-function"><span class="n">max_diff</span></a></a></a><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">y</span></a></a></a><span class="p">,</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">got</span></a></a></a><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;output: shape=</span><span class="si">{</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">got</span><span class="o">.</span><span class="n">shape</span></a></a></a><span class="si">}</span><span class="s2">, min=</span><span class="si">{</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">got</span></a></a></a><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="si">}</span><span class="s2">, max=</span><span class="si">{</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">got</span></a></a></a><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;max discrepancy=</span><span class="si">{</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">diff</span></a></a></a><span class="p">[</span><span class="s1">&#39;abs&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>output: shape=(1, 30, 16), min=-4.500553607940674, max=5.789700508117676
max discrepancy=4.76837158203125e-07
</pre></div>
</div>
<p>Lets save the ONNX model.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">onnx</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx_module</span></a></a></a><span class="p">,</span> <span class="s2">&quot;plot_exporter_recipes_c_modules.module.onnx&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>And visually.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://sdpython.github.io/doc/onnx-array-api/dev/api/plotting.html#onnx_array_api.plotting.graphviz_helper.plot_dot" title="onnx_array_api.plotting.graphviz_helper.plot_dot" class="sphx-glr-backref-module-onnx_array_api-plotting-graphviz_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-array-api/dev/api/plotting.html#onnx_array_api.plotting.graphviz_helper.plot_dot" title="onnx_array_api.plotting.graphviz_helper.plot_dot" class="sphx-glr-backref-module-onnx_array_api-plotting-graphviz_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-array-api/dev/api/plotting.html#onnx_array_api.plotting.graphviz_helper.plot_dot" title="onnx_array_api.plotting.graphviz_helper.plot_dot" class="sphx-glr-backref-module-onnx_array_api-plotting-graphviz_helper sphx-glr-backref-type-py-function"><span class="n">plot_dot</span></a></a></a><span class="p">(</span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx_module</span></a></a></a><span class="p">)</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_plot_exporter_recipes_c_modules_001.png" srcset="../_images/sphx_glr_plot_exporter_recipes_c_modules_001.png" alt="plot exporter recipes c modules" class = "sphx-glr-single-img"/></section>
<section id="inlining">
<h2>Inlining<a class="headerlink" href="#inlining" title="Link to this heading"></a></h2>
<p>The ONNX graph can still be inline after this.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx_inlined</span></a></a></a> <span class="o">=</span> <a href="https://onnx.ai/onnx/api/inliner.html#onnx.inliner.inline_local_functions" title="onnx.inliner.inline_local_functions" class="sphx-glr-backref-module-onnx-inliner sphx-glr-backref-type-py-function"><a href="https://onnx.ai/onnx/api/inliner.html#onnx.inliner.inline_local_functions" title="onnx.inliner.inline_local_functions" class="sphx-glr-backref-module-onnx-inliner sphx-glr-backref-type-py-function"><a href="https://onnx.ai/onnx/api/inliner.html#onnx.inliner.inline_local_functions" title="onnx.inliner.inline_local_functions" class="sphx-glr-backref-module-onnx-inliner sphx-glr-backref-type-py-function"><span class="n">inline_local_functions</span></a></a></a><span class="p">(</span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx_module</span></a></a></a><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><span class="n">pretty_onnx</span></a></a></a><span class="p">(</span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx_inlined</span></a></a></a><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>opset: domain=&#39;&#39; version=18
opset: domain=&#39;aten_local_function&#39; version=1
input: name=&#39;input_ids&#39; type=dtype(&#39;int64&#39;) shape=[1, 30]
init: name=&#39;embedding.embedding.weight&#39; type=float32 shape=(1024, 16) -- GraphBuilder.make_local_function/from(embedding.embedding.weight)
init: name=&#39;embedding.pe.weight&#39; type=float32 shape=(1024, 16)        -- GraphBuilder.make_local_function/from(embedding.pe.weight)
init: name=&#39;mask&#39; type=float32 shape=(256, 256)                       -- GraphBuilder.make_local_function/from(mask)
init: name=&#39;weight::T10&#39; type=float32 shape=(16, 16)                  -- GraphBuilder.make_local_function/from(weight::T10)
init: name=&#39;weight::T102&#39; type=float32 shape=(16, 16)                 -- GraphBuilder.make_local_function/from(weight::T102)
init: name=&#39;weight::T103&#39; type=float32 shape=(16, 16)                 -- GraphBuilder.make_local_function/from(weight::T103)
init: name=&#39;mask2&#39; type=float32 shape=(256, 256)                      -- GraphBuilder.make_local_function/from(mask2)
init: name=&#39;weight::T104&#39; type=float32 shape=(16, 16)                 -- GraphBuilder.make_local_function/from(weight::T104)
init: name=&#39;weight::T1022&#39; type=float32 shape=(16, 16)                -- GraphBuilder.make_local_function/from(weight::T1022)
init: name=&#39;weight::T1032&#39; type=float32 shape=(16, 16)                -- GraphBuilder.make_local_function/from(weight::T1032)
init: name=&#39;weight::T105&#39; type=float32 shape=(32, 16)                 -- GraphBuilder.make_local_function/from(weight::T105)
init: name=&#39;decoder.feed_forward.linear_1.bias&#39; type=float32 shape=(128,)-- GraphBuilder.make_local_function/from(decoder.feed_forward.linear_1.bias)
init: name=&#39;weight::T106&#39; type=float32 shape=(16, 128)                -- GraphBuilder.make_local_function/from(weight::T106)
init: name=&#39;weight::T1023&#39; type=float32 shape=(128, 16)               -- GraphBuilder.make_local_function/from(weight::T1023)
Constant(value=[1.0, 1.0,...) -&gt; init1_s16_
Gather(embedding.embedding.weight, input_ids) -&gt; embedding2
Gather(embedding.pe.weight, input_ids) -&gt; pe
  Add(embedding2, pe) -&gt; embedding
Constant(value=[0.0, 0.0,...) -&gt; init1_s16_2
  LayerNormalization(embedding, init1_s16_, init1_s16_2, axis=-1, epsilon=0.00, stash_type=1) -&gt; norm_1
    MatMul(norm_1, weight::T10) -&gt; query
Constant(value=[-inf]) -&gt; init1_s1_
Constant(value=[0.25]) -&gt; init1_s_::RSh1
Constant(value=[0.0]) -&gt; init1_s_2::RSh1
Constant(value=[0, 0]) -&gt; SliceSlicePattern_init7_s1_0_start
Constant(value=[30, 30]) -&gt; SliceSlicePattern_init7_s1_30_end
Constant(value=[0, 1]) -&gt; SliceSlicePattern_init7_s1_1_axis
  Slice(mask, SliceSlicePattern_init7_s1_0_start, SliceSlicePattern_init7_s1_30_end, SliceSlicePattern_init7_s1_1_axis) -&gt; slice_2
  Equal(slice_2, init1_s_2::RSh1) -&gt; eq
MatMul(norm_1, weight::T102) -&gt; key
  Transpose(key, perm=[0,2,1]) -&gt; transpose
    MatMul(query, transpose) -&gt; matmul
  Mul(matmul, init1_s_::RSh1) -&gt; _onx_mul_matmul
  Where(eq, init1_s1_, _onx_mul_matmul) -&gt; masked_fill
    Softmax(masked_fill, axis=-1) -&gt; softmax
MatMul(norm_1, weight::T103) -&gt; value
  MatMul(softmax, value) -&gt; attention_0
Constant(value=[-inf]) -&gt; init1_s1_2
Constant(value=[0.25]) -&gt; init1_s_::RSh12
Constant(value=[0.0]) -&gt; init1_s_2::RSh12
Constant(value=[0, 0]) -&gt; SliceSlicePattern_init7_s1_0_start2
Constant(value=[30, 30]) -&gt; SliceSlicePattern_init7_s1_30_end2
Constant(value=[0, 1]) -&gt; SliceSlicePattern_init7_s1_1_axis2
  Slice(mask2, SliceSlicePattern_init7_s1_0_start2, SliceSlicePattern_init7_s1_30_end2, SliceSlicePattern_init7_s1_1_axis2) -&gt; slice_22
  Equal(slice_22, init1_s_2::RSh12) -&gt; eq2
MatMul(norm_1, weight::T104) -&gt; query2
MatMul(norm_1, weight::T1022) -&gt; key2
  Transpose(key2, perm=[0,2,1]) -&gt; transpose2
  MatMul(query2, transpose2) -&gt; matmul2
  Mul(matmul2, init1_s_::RSh12) -&gt; _onx_mul_matmul2
  Where(eq2, init1_s1_2, _onx_mul_matmul2) -&gt; masked_fill2
    Softmax(masked_fill2, axis=-1) -&gt; softmax2
MatMul(norm_1, weight::T1032) -&gt; value2
  MatMul(softmax2, value2) -&gt; attention_1
    Concat(attention_0, attention_1, axis=-1) -&gt; cat
      MatMul(cat, weight::T105) -&gt; _onx_matmul_cat
Constant(value=[-0.157050...) -&gt; bias
  Add(_onx_matmul_cat, bias) -&gt; attention
    Add(attention, embedding) -&gt; add_1
Constant(value=[1.0, 1.0,...) -&gt; init1_s16_3
Constant(value=[0.0, 0.0,...) -&gt; init1_s16_22
  LayerNormalization(add_1, init1_s16_3, init1_s16_22, axis=-1, epsilon=0.00, stash_type=1) -&gt; norm_2
    MatMul(norm_2, weight::T106) -&gt; _onx_matmul_layer_norm_1
      Add(_onx_matmul_layer_norm_1, decoder.feed_forward.linear_1.bias) -&gt; linear_1
        Relu(linear_1) -&gt; relu
          MatMul(relu, weight::T1023) -&gt; _onx_matmul_relu
Constant(value=[0.0367000...) -&gt; bias2
  Add(_onx_matmul_relu, bias2) -&gt; feed_forward
    Add(feed_forward, add_1) -&gt; output_0
output: name=&#39;output_0&#39; type=dtype(&#39;float32&#39;) shape=[1, 30, 16]
</pre></div>
</div>
</section>
<section id="optimizations">
<h2>Optimizations<a class="headerlink" href="#optimizations" title="Link to this heading"></a></h2>
<p>The ONNX graph produced by the exporter without any optimization is very verbose
and less efficient. Thats why some optimizations are made to the model by default.
It is also possible to introduce kernels implemented in <a class="reference external" href="https://onnxruntime.ai/">onnxruntime</a>.
Lets how it goes.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx_optimized</span></a></a></a> <span class="o">=</span> <a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter sphx-glr-backref-type-py-function"><span class="n">to_onnx</span></a></a></a><span class="p">(</span>
    <span class="n">llm</span><span class="p">,</span>
    <span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_ids</span></a></a></a><span class="p">,),</span>
    <span class="n">options</span><span class="o">=</span><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/xbuilder/index.html#experimental_experiment.xbuilder.OptimizationOptions" title="experimental_experiment.xbuilder.OptimizationOptions" class="sphx-glr-backref-module-experimental_experiment-xbuilder sphx-glr-backref-type-py-class"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/xbuilder/index.html#experimental_experiment.xbuilder.OptimizationOptions" title="experimental_experiment.xbuilder.OptimizationOptions" class="sphx-glr-backref-module-experimental_experiment-xbuilder sphx-glr-backref-type-py-class"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/xbuilder/index.html#experimental_experiment.xbuilder.OptimizationOptions" title="experimental_experiment.xbuilder.OptimizationOptions" class="sphx-glr-backref-module-experimental_experiment-xbuilder sphx-glr-backref-type-py-class"><span class="n">OptimizationOptions</span></a></a></a><span class="p">(</span><span class="n">patterns</span><span class="o">=</span><span class="s2">&quot;default+onnxruntime&quot;</span><span class="p">,</span> <span class="n">constant_folding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><span class="n">pretty_onnx</span></a></a></a><span class="p">(</span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx_optimized</span></a></a></a><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[GraphBuilder-ACU.optimize] start with 73 nodes
[GraphBuilder-ACU.optimize] #patterns=102
[GraphBuilder-ACU.remove_unused] remove_initializer 1:1/47:embedding.embedding.weight:torch.float32[torch.Size([1024, 16])]
[GraphBuilder-ACU.remove_unused] remove_initializer 2:3/47:embedding.pe.weight:torch.float32[torch.Size([1024, 16])]
[GraphBuilder-ACU.remove_unused] remove_initializer 3:5/47:decoder.attention.attention.0.query.weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-ACU.remove_unused] remove_initializer 4:7/47:decoder.attention.attention.0.key.weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-ACU.remove_unused] remove_initializer 5:9/47:decoder.attention.attention.0.value.weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-ACU.remove_unused] remove_initializer 6:11/47:decoder.attention.attention.1.query.weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-ACU.remove_unused] remove_initializer 7:13/47:decoder.attention.attention.1.key.weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-ACU.remove_unused] remove_initializer 8:15/47:decoder.attention.attention.1.value.weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-ACU.remove_unused] remove_initializer 9:17/47:decoder.attention.linear.weight:torch.float32[torch.Size([16, 32])]
[GraphBuilder-ACU.remove_unused] remove_initializer 10:19/47:decoder.attention.linear.bias:torch.float32[torch.Size([16])]
[GraphBuilder-ACU.remove_unused] remove_initializer 11:21/47:decoder.feed_forward.linear_1.weight:torch.float32[torch.Size([128, 16])]
[GraphBuilder-ACU.remove_unused] remove_initializer 12:23/47:decoder.feed_forward.linear_1.bias:torch.float32[torch.Size([128])]
[GraphBuilder-ACU.remove_unused] remove_initializer 13:25/47:decoder.feed_forward.linear_2.weight:torch.float32[torch.Size([16, 128])]
[GraphBuilder-ACU.remove_unused] remove_initializer 14:27/47:decoder.feed_forward.linear_2.bias:torch.float32[torch.Size([16])]
[GraphBuilder-ACU.remove_unused] remove_initializer 15:29/47:decoder.norm_1.weight:torch.float32[torch.Size([16])]
[GraphBuilder-ACU.remove_unused] remove_initializer 16:31/47:decoder.norm_1.bias:torch.float32[torch.Size([16])]
[GraphBuilder-ACU.remove_unused] remove_initializer 17:33/47:decoder.norm_2.weight:torch.float32[torch.Size([16])]
[GraphBuilder-ACU.remove_unused] remove_initializer 18:35/47:decoder.norm_2.bias:torch.float32[torch.Size([16])]
[GraphBuilder-ACU.remove_unused] remove_initializer 1:2/46:p_decoder_attention_attention_0_query_weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-ACU.remove_unused] remove_initializer 2:3/46:p_decoder_attention_attention_0_key_weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-ACU.remove_unused] remove_initializer 3:4/46:p_decoder_attention_attention_0_value_weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-ACU.remove_unused] remove_initializer 4:5/46:p_decoder_attention_attention_1_query_weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-ACU.remove_unused] remove_initializer 5:6/46:p_decoder_attention_attention_1_key_weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-ACU.remove_unused] remove_initializer 6:7/46:p_decoder_attention_attention_1_value_weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-ACU.remove_unused] remove_initializer 7:8/46:p_decoder_attention_linear_weight:torch.float32[torch.Size([16, 32])]
[GraphBuilder-ACU.remove_unused] remove_initializer 8:10/46:p_decoder_feed_forward_linear_1_weight:torch.float32[torch.Size([128, 16])]
[GraphBuilder-ACU.remove_unused] remove_initializer 9:12/46:p_decoder_feed_forward_linear_2_weight:torch.float32[torch.Size([16, 128])]
[GraphBuilder-ACU.remove_unused] remove_initializer 10:18/46:b_decoder_attention_attention_0_mask:torch.float32[torch.Size([256, 256])]
[GraphBuilder-ACU.remove_unused] remove_initializer 11:19/46:b_decoder_attention_attention_1_mask:torch.float32[torch.Size([256, 256])]
[GraphBuilder-ACU.remove_unused] remove_initializer 12:23/46:init1_s_:float32[()]
[GraphBuilder-ACU.remove_unused] remove_initializer 13:24/46:init7_s1_1:int64[(1,)]
[GraphBuilder-ACU.remove_unused] remove_initializer 14:25/46:init7_s1_0:int64[(1,)]
[GraphBuilder-ACU.remove_unused] remove_initializer 15:26/46:init7_s1_30:int64[(1,)]
[GraphBuilder-ACU.remove_unused] remove_initializer 16:27/46:init1_s_2:float32[()]
[GraphBuilder-ACU.remove_unused] remove_initializer 17:33/46:slice_1:torch.float32[torch.Size([30, 256])]
[GraphBuilder-ACU.remove_unused] remove_initializer 18:40/46:slice_3:torch.float32[torch.Size([30, 256])]
[GraphBuilderPatternOptimization-ACU.optimize] start with 53 nodes, 28 initializers, 102 patterns, priorities=[0, 1, 2, 3], max_iter=212
[GraphBuilderPatternOptimization-ACU.optimize] use pattern   1/102 - P0 - BatchNormalizationPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern   2/102 - P0 - BatchNormalizationTrainingPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern   3/102 - P0 - CastCastPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern   4/102 - P0 - CastPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern   5/102 - P0 - ConcatGatherPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern   6/102 - P0 - ConcatReshapePattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern   7/102 - P0 - ConvBiasNullPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern   8/102 - P0 - ExpandPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern   9/102 - P0 - FunctionAttentionPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  10/102 - P0 - GeluErfPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  11/102 - P0 - GeluOrtPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  12/102 - P0 - GeluPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  13/102 - P0 - IdentityPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  14/102 - P0 - LeakyReluPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  15/102 - P0 - ReshapePattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  16/102 - P0 - ReshapeReshapePattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  17/102 - P0 - SameChildrenFromInputPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  18/102 - P0 - SameChildrenPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  19/102 - P0 - ShapeBasedEditDistanceReshapePattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  20/102 - P0 - ShapeBasedIdentityPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  21/102 - P0 - ShapeBasedReshapeIsSqueezePattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  22/102 - P0 - ShapeBasedSameChildrenPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  23/102 - P0 - ShapeBasedShapeShapeAddPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  24/102 - P0 - ShapeBasedStaticExpandPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  25/102 - P0 - ShapedBasedReshapePattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  26/102 - P0 - SoftmaxCrossEntropyLossCastPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  27/102 - P0 - SqueezeAddPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  28/102 - P0 - SqueezeBinaryUnsqueezePattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  29/102 - P0 - SqueezeUnsqueezePattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  30/102 - P0 - StaticConcatReshapePattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  31/102 - P0 - SwapExpandReshapePattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  32/102 - P0 - TransposeReshapeTransposePattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  33/102 - P0 - TransposeTransposePattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  34/102 - P0 - UnsqueezeReshapePattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  35/102 - P0 - UnsqueezeUnsqueezePattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  36/102 - P1 - BiasGeluPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  37/102 - P1 - BiasSoftmaxPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  38/102 - P1 - CastCastBinaryPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  39/102 - P1 - CastLayerNormalizationCastPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  40/102 - P1 - CastOpCastPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  41/102 - P1 - ClipClipPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  42/102 - P1 - ComputationCastOpCastPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  43/102 - P1 - ConcatEmptyPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  44/102 - P1 - ConcatTwiceUnaryPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  45/102 - P1 - ContribRotaryEmbedding3DPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  46/102 - P1 - DropoutPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  47/102 - P1 - ExpandBroadcastPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  48/102 - P1 - ExpandSwapPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  49/102 - P1 - FastGeluPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  50/102 - P1 - FunctionCausalMaskMulAddPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  51/102 - P1 - FunctionCausalMaskPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  52/102 - P1 - FunctionCosSinCachePattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  53/102 - P1 - FunctionHalfRotaryEmbeddingPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  54/102 - P1 - GemmTransposePattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  55/102 - P1 - LayerNormalizationPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  56/102 - P1 - LayerNormalizationScalePattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  57/102 - P1 - MatMulReshape2Of3Pattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  58/102 - P1 - MulMulMatMulPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  59/102 - P1 - MulMulMulScalarPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  60/102 - P1 - MultiHeadAttention3DPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  61/102 - P1 - OrtBatchNormalizationTrainingPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  62/102 - P1 - QuickGeluPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  63/102 - P1 - RMSNormalizationPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  64/102 - P1 - ReduceReshapePattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  65/102 - P1 - ReduceSumNormalizePattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  66/102 - P1 - Reshape2Of3Pattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  67/102 - P1 - ReshapeMatMulReshapePattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  68/102 - P1 - ReshapeReshapeBinaryPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  69/102 - P1 - RotaryConcatPartPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  70/102 - P1 - RotaryEmbeddingPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  71/102 - P1 - SequenceConstructAtPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  72/102 - P1 - ShapeBasedConcatExpandPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  73/102 - P1 - ShapeBasedExpandBroadcastMatMulPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  74/102 - P1 - ShapeBasedExpandBroadcastPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  75/102 - P1 - ShapeBasedExpandCastWhereSwapPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  76/102 - P1 - ShapeBasedExpandSwapPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  77/102 - P1 - ShapeBasedMatMulToMulPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  78/102 - P1 - SimplifiedLayerNormalizationMulPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  79/102 - P1 - SimplifiedLayerNormalizationPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  80/102 - P1 - SkipLayerNormalizationPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  81/102 - P1 - SkipSimplifiedLayerNormalizationMulPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  82/102 - P1 - SkipSimplifiedLayerNormalizationPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  83/102 - P1 - SliceSlicePattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  84/102 - P1 - SlicesSplitPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  85/102 - P1 - SoftmaxGradPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  86/102 - P1 - SplitConcatPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  87/102 - P1 - Sub1MulPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  88/102 - P1 - SwitchOrderBinaryPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  89/102 - P1 - SwitchReshapeActivationPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  90/102 - P1 - TransposeEqualReshapePattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  91/102 - P1 - TransposeMatMulPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  92/102 - P1 - TransposeReshapeMatMulPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  93/102 - P1 - UnsqueezeEqualPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  94/102 - P2 - ContribRotaryEmbeddingPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  95/102 - P2 - FusedConvPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  96/102 - P2 - FusedMatMulDivPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  97/102 - P2 - FusedMatMulPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  98/102 - P3 - FusedMatMulTransposePattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern  99/102 - P3 - FusedMatMulx2Pattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern 100/102 - P3 - MatMulAddPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern 101/102 - P3 - ReshapeGemmPattern()
[GraphBuilderPatternOptimization-ACU.optimize] use pattern 102/102 - P3 - TransposeFusedMatMulBPattern()
[GraphBuilderPatternOptimization-ACU.optimize] same children={&#39;SameChildrenFromInputPattern&#39;, &#39;SameChildrenPattern&#39;}
[GraphBuilderPatternOptimization-ACU.optimize] iteration 0: 53 nodes, priority=0
[GraphBuilderPatternOptimization-ACU.optimize] applies 6 matches, 2*CastPattern, 4*IdentityPattern - time=0.009 | max_time=GeluErfPattern:0.002
[GraphBuilder-ACU.remove_unused] remove_initializer 1:5/28:p_decoder_norm_1_weight:torch.float32[torch.Size([16])]
[GraphBuilder-ACU.remove_unused] remove_initializer 2:6/28:p_decoder_norm_1_bias:torch.float32[torch.Size([16])]
[GraphBuilder-ACU.remove_unused] remove_initializer 3:7/28:p_decoder_norm_2_weight:torch.float32[torch.Size([16])]
[GraphBuilder-ACU.remove_unused] remove_initializer 4:8/28:p_decoder_norm_2_bias:torch.float32[torch.Size([16])]
[GraphBuilderPatternOptimization-ACU.optimize] iteration 1: 47 nodes, priority=0
[GraphBuilderPatternOptimization-ACU.optimize] increase priority to 1
[GraphBuilderPatternOptimization-ACU.optimize] iteration 2: 47 nodes, priority=1
[GraphBuilderPatternOptimization-ACU.optimize] applies 2 matches, 2*LayerNormalizationPattern - time=0.005 | max_time=IdentityPattern:0.000
[GraphBuilder-ACU.remove_unused] remove_initializer 1:5/26:init7_s1_-1:int64[(1,)]
[GraphBuilder-ACU.remove_unused] remove_initializer 2:6/26:init1_s1_:float32[(1,)]
[GraphBuilder-ACU.remove_unused] remove_initializer 3:7/26:init1_s1_2:float32[(1,)]
[GraphBuilderPatternOptimization-ACU.optimize] iteration 3: 35 nodes, priority=1
[GraphBuilderPatternOptimization-ACU.optimize] applies 2 matches, 2*SkipLayerNormalizationPattern - time=0.003 | max_time=IdentityPattern:0.000
[GraphBuilderPatternOptimization-ACU.optimize] iteration 4: 33 nodes, priority=1
[GraphBuilderPatternOptimization-ACU.optimize] increase priority to 2
[GraphBuilderPatternOptimization-ACU.optimize] iteration 5: 33 nodes, priority=2
[GraphBuilderPatternOptimization-ACU.optimize] applies 2 matches, 2*FusedMatMulPattern - time=0.004 | max_time=IdentityPattern:0.000
[GraphBuilder-ACU.remove_unused] remove_initializer 1:9/23:init1_s_::RSh1:float32[(1,)]
[GraphBuilder-ACU.remove_unused] remove_initializer 2:15/23:init1_s_::RSh12:float32[(1,)]
[GraphBuilderPatternOptimization-ACU.optimize] iteration 6: 29 nodes, priority=2
[GraphBuilderPatternOptimization-ACU.optimize] increase priority to 3
[GraphBuilderPatternOptimization-ACU.optimize] iteration 7: 29 nodes, priority=3
[GraphBuilderPatternOptimization-ACU.optimize] stops current_priority_index=4, priorities=[0, 1, 2, 3]
[GraphBuilderPatternOptimization-ACU.optimize] done after 8 iterations with 29 nodes in 0.052
    STAT apply_CastPattern +2 -2 #it=1 maxmatch=1 i=2 - time=0.0001885939964267891
    STAT apply_FusedMatMulPattern +2 -6 #it=1 maxmatch=1 i=2 - time=0.0006855690007796511
    STAT apply_IdentityPattern +4 -4 #it=1 maxmatch=5 i=4 - time=0.00027474399757920764
    STAT apply_LayerNormalizationPattern +2 -14 #it=1 maxmatch=1 i=2 - time=0.0004809579986613244
    STAT apply_SkipLayerNormalizationPattern +2 -4 #it=1 maxmatch=1 i=2 - time=0.00019513599909259938
    STAT build_graph_for_pattern +0 -0 #it=8 maxmatch=0 i=0 - time=0.0012872370025434066
    STAT check_pattern_00 +0 -0 #it=1 maxmatch=0 i=0 - time=0.0002791379993141163
    STAT check_pattern_A0 +0 -0 #it=4 maxmatch=0 i=0 - time=0.0012117680016672239
    STAT check_pattern_B0 +0 -0 #it=8 maxmatch=0 i=0 - time=0.002238924993434921
    STAT insert_and_remove_nodes +0 -0 #it=0 maxmatch=0 i=0 - time=0.0008783430021139793
    STAT match_BatchNormalizationPattern +0 -0 #it=8 maxmatch=0 i=0 - time=0.00032548400122323073
    STAT match_BatchNormalizationTrainingPattern +0 -0 #it=8 maxmatch=0 i=0 - time=0.00023920000239741057
    STAT match_BiasGeluPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0001557649993628729
    STAT match_BiasSoftmaxPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0001429980002285447
    STAT match_CastCastBinaryPattern +0 -0 #it=6 maxmatch=0 i=0 - time=0.00040759900366538204
    STAT match_CastCastPattern +0 -0 #it=8 maxmatch=2 i=0 - time=0.0002480109942553099
    STAT match_CastLayerNormalizationCastPattern +0 -0 #it=6 maxmatch=0 i=0 - time=0.0001963299982890021
    STAT match_CastOpCastPattern +0 -0 #it=6 maxmatch=0 i=0 - time=0.000386555002478417
    STAT match_CastPattern +0 -0 #it=8 maxmatch=2 i=2 - time=0.0002735839952947572
    STAT match_ClipClipPattern +0 -0 #it=6 maxmatch=0 i=0 - time=0.00016561099982936867
    STAT match_ComputationCastOpCastPattern +0 -0 #it=6 maxmatch=0 i=0 - time=0.00024530199880246073
    STAT match_ConcatEmptyPattern +0 -0 #it=6 maxmatch=0 i=0 - time=0.00021343499247450382
    STAT match_ConcatGatherPattern +0 -0 #it=8 maxmatch=2 i=0 - time=0.0002852400066331029
    STAT match_ConcatReshapePattern +0 -0 #it=8 maxmatch=2 i=0 - time=0.000235641000472242
    STAT match_ConcatTwiceUnaryPattern +0 -0 #it=6 maxmatch=0 i=0 - time=0.00016231399786192924
    STAT match_ContribRotaryEmbedding3DPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00018237400581710972
    STAT match_ContribRotaryEmbeddingPattern +0 -0 #it=3 maxmatch=0 i=0 - time=7.715200263191946e-05
    STAT match_ConvBiasNullPattern +0 -0 #it=8 maxmatch=2 i=0 - time=0.0002506000018911436
    STAT match_DropoutPattern +0 -0 #it=6 maxmatch=0 i=0 - time=0.00012828500257455744
    STAT match_ExpandBroadcastPattern +0 -0 #it=6 maxmatch=0 i=0 - time=0.00013850899995304644
    STAT match_ExpandPattern +0 -0 #it=8 maxmatch=2 i=0 - time=0.00023278001026483253
    STAT match_ExpandSwapPattern +0 -0 #it=6 maxmatch=0 i=0 - time=0.00013484400187735446
    STAT match_FastGeluPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0001536089985165745
    STAT match_FunctionAttentionPattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.0002734360059548635
    STAT match_FunctionCausalMaskMulAddPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00020203999520163052
    STAT match_FunctionCausalMaskPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00015536100181634538
    STAT match_FunctionCosSinCachePattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00014732499403180555
    STAT match_FunctionHalfRotaryEmbeddingPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00014243700570659712
    STAT match_FusedConvPattern +0 -0 #it=3 maxmatch=0 i=0 - time=7.495099634979852e-05
    STAT match_FusedMatMulDivPattern +0 -0 #it=3 maxmatch=2 i=0 - time=0.00017691700486466289
    STAT match_FusedMatMulPattern +0 -0 #it=3 maxmatch=2 i=2 - time=0.0003985959992860444
    STAT match_FusedMatMulTransposePattern +0 -0 #it=1 maxmatch=0 i=0 - time=6.717699943692423e-05
    STAT match_FusedMatMulx2Pattern +0 -0 #it=1 maxmatch=0 i=0 - time=9.748000229592435e-05
    STAT match_GeluErfPattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.003968451001128415
    STAT match_GeluOrtPattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.003076731001783628
    STAT match_GeluPattern +0 -0 #it=8 maxmatch=2 i=0 - time=9.348001185571775e-06
    STAT match_GemmTransposePattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0001622300005692523
    STAT match_IdentityPattern +0 -0 #it=8 maxmatch=6 i=4 - time=0.002988143991387915
    STAT match_LayerNormalizationPattern +0 -0 #it=6 maxmatch=2 i=2 - time=0.0003055179950024467
    STAT match_LayerNormalizationScalePattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00015324100604630075
    STAT match_LeakyReluPattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.0027481260076456238
    STAT match_MatMulAddPattern +0 -0 #it=1 maxmatch=0 i=0 - time=6.798499816795811e-05
    STAT match_MatMulReshape2Of3Pattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0006229889986570925
    STAT match_MulMulMatMulPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00035041399678448215
    STAT match_MulMulMulScalarPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0001853159956226591
    STAT match_MultiHeadAttention3DPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0001838730022427626
    STAT match_OrtBatchNormalizationTrainingPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00024746000053710304
    STAT match_QuickGeluPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0001475650024076458
    STAT match_RMSNormalizationPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0001459219965909142
    STAT match_ReduceReshapePattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.000195075997908134
    STAT match_ReduceSumNormalizePattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00015325699496315792
    STAT match_Reshape2Of3Pattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00040715599971008487
    STAT match_ReshapeGemmPattern +0 -0 #it=1 maxmatch=0 i=0 - time=2.4444001610390842e-05
    STAT match_ReshapeMatMulReshapePattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0003118599961453583
    STAT match_ReshapePattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.00019957200129283592
    STAT match_ReshapeReshapeBinaryPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00027001500347978435
    STAT match_ReshapeReshapePattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.00020701099856523797
    STAT match_RotaryConcatPartPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00021032499716966413
    STAT match_RotaryEmbeddingPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00013525900067179464
    STAT match_SameChildrenFromInputPattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.0004365900058473926
    STAT match_SameChildrenPattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.0007758529936836567
    STAT match_SequenceConstructAtPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00014961900160415098
    STAT match_ShapeBasedConcatExpandPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0001554280024720356
    STAT match_ShapeBasedEditDistanceReshapePattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.0001990289965760894
    STAT match_ShapeBasedExpandBroadcastMatMulPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00042491499698371626
    STAT match_ShapeBasedExpandBroadcastPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00038390200279536657
    STAT match_ShapeBasedExpandCastWhereSwapPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0001709300049697049
    STAT match_ShapeBasedExpandSwapPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00035198799741920084
    STAT match_ShapeBasedIdentityPattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.000231715999689186
    STAT match_ShapeBasedMatMulToMulPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0004037630023958627
    STAT match_ShapeBasedReshapeIsSqueezePattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.00023134499497245997
    STAT match_ShapeBasedSameChildrenPattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.0002103160004480742
    STAT match_ShapeBasedShapeShapeAddPattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.00027045201204600744
    STAT match_ShapeBasedStaticExpandPattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.00022192699543666095
    STAT match_ShapedBasedReshapePattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.0002024099994741846
    STAT match_SimplifiedLayerNormalizationMulPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00018851600179914385
    STAT match_SimplifiedLayerNormalizationPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00027797399525297806
    STAT match_SkipLayerNormalizationPattern +0 -0 #it=6 maxmatch=2 i=2 - time=0.0002057369965768885
    STAT match_SkipSimplifiedLayerNormalizationMulPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00017509899771539494
    STAT match_SkipSimplifiedLayerNormalizationPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00016801800302346237
    STAT match_SliceSlicePattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0001340469971182756
    STAT match_SlicesSplitPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0001463980006519705
    STAT match_SoftmaxCrossEntropyLossCastPattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.0035700940061360598
    STAT match_SoftmaxGradPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0001478870071878191
    STAT match_SplitConcatPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00014370800272445194
    STAT match_SqueezeAddPattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.000372420996427536
    STAT match_SqueezeBinaryUnsqueezePattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.0002093600014632102
    STAT match_SqueezeUnsqueezePattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.0002429120104352478
    STAT match_StaticConcatReshapePattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.00020865000260528177
    STAT match_Sub1MulPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0001644320072955452
    STAT match_SwapExpandReshapePattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.00020195399702060968
    STAT match_SwitchOrderBinaryPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00045169399891165085
    STAT match_SwitchReshapeActivationPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00022703899230691604
    STAT match_TransposeEqualReshapePattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0002247320044261869
    STAT match_TransposeFusedMatMulBPattern +0 -0 #it=1 maxmatch=0 i=0 - time=0.00010796599963214248
    STAT match_TransposeMatMulPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00034367300395388156
    STAT match_TransposeReshapeMatMulPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0003635969951574225
    STAT match_TransposeReshapeTransposePattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.0002534320046834182
    STAT match_TransposeTransposePattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.00023189300554804504
    STAT match_UnsqueezeEqualPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0002838100008375477
    STAT match_UnsqueezeReshapePattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.00023653299649595283
    STAT match_UnsqueezeUnsqueezePattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.00021943000319879502
    STAT remove_duplicated_shape +0 -0 #it=8 maxmatch=0 i=0 - time=5.1017999794567004e-05
    STAT remove_identity_nodes +9 -15 #it=8 maxmatch=0 i=0 - time=0.0019527340009517502
    STAT remove_unused +0 -0 #it=8 maxmatch=0 i=0 - time=0.002112569003656972
--MODEL: 29 nodes, 1 inputs, 1 outputs, 21 initializers--
         INPUT:   1 x 7t
     INPUT-SEQ:   1 x Falset
        OUTPUT:   1 x 1t
    OUTPUT-SEQ:   1 x Falset
          INIT:  21 x 1t
          NODE:   4 x Add
          NODE:   1 x Concat
          NODE:   2 x Equal
          NODE:   2 x Gather
          NODE:  11 x MatMul
          NODE:   1 x Relu
          NODE:   2 x Softmax
          NODE:   2 x Where
          NODE:   2 x com.microsoft.FusedMatMul
          NODE:   2 x com.microsoft.SkipLayerNormalization
--MODEL: 29 nodes, 1 inputs, 1 outputs, 21 initializers--DETAILED--
     INPUT:   1 x 7t[1x30]
    OUTPUT:   1 x 1t[1x30x16]
      INIT:   2 x 1t[1024x16]
      INIT:   1 x 1t[128]
      INIT:   1 x 1t[128x16]
      INIT:   4 x 1t[16]
      INIT:   1 x 1t[16x128]
      INIT:   6 x 1t[16x16]
      INIT:   3 x 1t[1]
      INIT:   2 x 1t[30x30]
      INIT:   1 x 1t[32x16]
      NODE:   1 x Add -SIG- 1t[1x30x128], 1t[128]
      NODE:   2 x Add -SIG- 1t[1x30x16], 1t[16]
      NODE:   1 x Add -SIG- 1t[1x30x16], 1t[1x30x16]
      NODE:   1 x Concat -SIG- 1t[1x30x16], 1t[1x30x16]
      NODE:   2 x Equal -SIG- 1t[30x30], 1t[1]
      NODE:   2 x Gather -SIG- 1t[1024x16], 7t[1x30]
      NODE:   1 x MatMul -SIG- 1t[1x30x128], 1t[128x16]
      NODE:   1 x MatMul -SIG- 1t[1x30x16], 1t[16x128]
      NODE:   6 x MatMul -SIG- 1t[1x30x16], 1t[16x16]
      NODE:   2 x MatMul -SIG- 1t[1x30x30], 1t[1x30x16]
      NODE:   1 x MatMul -SIG- 1t[1x30x32], 1t[32x16]
      NODE:   1 x Relu -SIG- 1t[1x30x128]
      NODE:   2 x Softmax -SIG- 1t[1x30x30]
      NODE:   2 x Where -SIG- 9t[30x30], 1t[1], 1t[1x30x30]
      NODE:   2 x com.microsoft.FusedMatMul -SIG- 1t[1x30x16], 1t[1x30x16]
      NODE:   2 x com.microsoft.SkipLayerNormalization -SIG- 1t[1x30x16], 1t[1x30x16], 1t[16], 1t[16]
[GraphBuilder-ACU.remove_unused] remove_initializer 1:15/21:init1_s_2::RSh12:float32[(1,)]
[GraphBuilder-ACU.optimize] done with 29 nodes in 0.064
opset: domain=&#39;&#39; version=18
opset: domain=&#39;com.microsoft&#39; version=1
input: name=&#39;input_ids&#39; type=dtype(&#39;int64&#39;) shape=[1, 30]
init: name=&#39;init1_s1_3&#39; type=float32 shape=(1,) -- array([-inf], dtype=float32)-- Opset.make_node.1/Small##Opset.make_node.1/Small
init: name=&#39;p_decoder_attention_attention_0_query_weight::T10&#39; type=float32 shape=(16, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_attention_attention_0_query_weight)##p_decoder_attention_attention_0_query_weight/DynamoInterpret.placeholder.1/P(decoder.attention.attention.0.query.weight)
init: name=&#39;p_decoder_attention_attention_0_key_weight::T10&#39; type=float32 shape=(16, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_attention_attention_0_key_weight)##p_decoder_attention_attention_0_key_weight/DynamoInterpret.placeholder.1/P(decoder.attention.attention.0.key.weight)
init: name=&#39;p_decoder_attention_attention_0_value_weight::T10&#39; type=float32 shape=(16, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_attention_attention_0_value_weight)##p_decoder_attention_attention_0_value_weight/DynamoInterpret.placeholder.1/P(decoder.attention.attention.0.value.weight)
init: name=&#39;slice_2&#39; type=float32 shape=(30, 30)                      -- GraphBuilder.constant_folding.from/fold(init7_s1_0,init7_s1_1,init7_s1_30,slice_1)##slice_1/GraphBuilder.constant_folding.from/fold(b_decoder_attention_attention_0_mask,init7_s1_0,init7_s1_30)##b_decoder_attention_attention_0_mask/DynamoInterpret.placeholder.0##init7_s1_0/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##init7_s1_30/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##init7_s1_0/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##init7_s1_30/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##init7_s1_1/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape
init: name=&#39;init1_s_2::RSh1&#39; type=float32 shape=(1,) -- array([0.], dtype=float32)-- GraphBuilder.constant_folding.from/fold(init1_s_2,init7_s1_1)##init1_s_2/shape_type_compute._cast_inputs.0##shape_type_compute._cast_inputs.0##init7_s1_1/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape
init: name=&#39;p_decoder_attention_attention_1_query_weight::T10&#39; type=float32 shape=(16, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_attention_attention_1_query_weight)##p_decoder_attention_attention_1_query_weight/DynamoInterpret.placeholder.1/P(decoder.attention.attention.1.query.weight)
init: name=&#39;p_decoder_attention_attention_1_key_weight::T10&#39; type=float32 shape=(16, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_attention_attention_1_key_weight)##p_decoder_attention_attention_1_key_weight/DynamoInterpret.placeholder.1/P(decoder.attention.attention.1.key.weight)
init: name=&#39;p_decoder_attention_attention_1_value_weight::T10&#39; type=float32 shape=(16, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_attention_attention_1_value_weight)##p_decoder_attention_attention_1_value_weight/DynamoInterpret.placeholder.1/P(decoder.attention.attention.1.value.weight)
init: name=&#39;slice_4&#39; type=float32 shape=(30, 30)                      -- GraphBuilder.constant_folding.from/fold(init7_s1_0,init7_s1_1,init7_s1_30,slice_3)##slice_3/GraphBuilder.constant_folding.from/fold(b_decoder_attention_attention_1_mask,init7_s1_0,init7_s1_30)##b_decoder_attention_attention_1_mask/DynamoInterpret.placeholder.0##init7_s1_0/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##init7_s1_30/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##init7_s1_0/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##init7_s1_30/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##init7_s1_1/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape
init: name=&#39;p_decoder_attention_linear_weight::T10&#39; type=float32 shape=(32, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_attention_linear_weight)##p_decoder_attention_linear_weight/DynamoInterpret.placeholder.1/P(decoder.attention.linear.weight)
init: name=&#39;p_decoder_feed_forward_linear_1_weight::T10&#39; type=float32 shape=(16, 128)-- GraphBuilder.constant_folding.from/fold(p_decoder_feed_forward_linear_1_weight)##p_decoder_feed_forward_linear_1_weight/DynamoInterpret.placeholder.1/P(decoder.feed_forward.linear_1.weight)
init: name=&#39;p_decoder_feed_forward_linear_2_weight::T10&#39; type=float32 shape=(128, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_feed_forward_linear_2_weight)##p_decoder_feed_forward_linear_2_weight/DynamoInterpret.placeholder.1/P(decoder.feed_forward.linear_2.weight)
init: name=&#39;init1_s16_&#39; type=float32 shape=(16,)                      -- LayerNormalizationPattern.apply.scale##LayerNormalizationPattern.apply.scale
init: name=&#39;init1_s16_2&#39; type=float32 shape=(16,)                     -- LayerNormalizationPattern.apply.bias##LayerNormalizationPattern.apply.bias
init: name=&#39;embedding.embedding.weight&#39; type=float32 shape=(1024, 16) -- DynamoInterpret.placeholder.1/P(embedding.embedding.weight)
init: name=&#39;embedding.pe.weight&#39; type=float32 shape=(1024, 16)        -- DynamoInterpret.placeholder.1/P(embedding.pe.weight)
init: name=&#39;decoder.attention.linear.bias&#39; type=float32 shape=(16,)   -- DynamoInterpret.placeholder.1/P(decoder.attention.linear.bias)
init: name=&#39;decoder.feed_forward.linear_1.bias&#39; type=float32 shape=(128,)-- DynamoInterpret.placeholder.1/P(decoder.feed_forward.linear_1.bias)
init: name=&#39;decoder.feed_forward.linear_2.bias&#39; type=float32 shape=(16,)-- DynamoInterpret.placeholder.1/P(decoder.feed_forward.linear_2.bias)
Equal(slice_2, init1_s_2::RSh1) -&gt; eq
Gather(embedding.embedding.weight, input_ids) -&gt; embedding
Gather(embedding.pe.weight, input_ids) -&gt; embedding_1
  SkipLayerNormalization[com.microsoft](embedding, embedding_1, init1_s16_, init1_s16_2, epsilon=0.00) -&gt; _onx_div_sub_add, unused, unused2, add
    MatMul(_onx_div_sub_add, p_decoder_attention_attention_0_query_weight::T10) -&gt; linear
MatMul(_onx_div_sub_add, p_decoder_attention_attention_0_key_weight::T10) -&gt; linear_1
  FusedMatMul[com.microsoft](linear, linear_1, alpha=0.25, transA=0, transB=1, transBatchA=0, transBatchB=0) -&gt; _onx_mul_matmul
  Where(eq, init1_s1_3, _onx_mul_matmul) -&gt; masked_fill
    Softmax(masked_fill, axis=-1) -&gt; softmax
MatMul(_onx_div_sub_add, p_decoder_attention_attention_0_value_weight::T10) -&gt; linear_2
  MatMul(softmax, linear_2) -&gt; matmul_1
MatMul(_onx_div_sub_add, p_decoder_attention_attention_1_query_weight::T10) -&gt; linear_3
MatMul(_onx_div_sub_add, p_decoder_attention_attention_1_key_weight::T10) -&gt; linear_4
  FusedMatMul[com.microsoft](linear_3, linear_4, alpha=0.25, transA=0, transB=1, transBatchA=0, transBatchB=0) -&gt; _onx_mul_matmul_2
MatMul(_onx_div_sub_add, p_decoder_attention_attention_1_value_weight::T10) -&gt; linear_5
Equal(slice_4, init1_s_2::RSh1) -&gt; eq_1
  Where(eq_1, init1_s1_3, _onx_mul_matmul_2) -&gt; masked_fill_1
    Softmax(masked_fill_1, axis=-1) -&gt; softmax_1
  MatMul(softmax_1, linear_5) -&gt; matmul_3
    Concat(matmul_1, matmul_3, axis=-1) -&gt; cat
      MatMul(cat, p_decoder_attention_linear_weight::T10) -&gt; _onx_matmul_cat
        Add(_onx_matmul_cat, decoder.attention.linear.bias) -&gt; linear_6
    SkipLayerNormalization[com.microsoft](linear_6, add, init1_s16_, init1_s16_2, epsilon=0.00) -&gt; _onx_div_sub_add_1, unused3, unused4, add_1
      MatMul(_onx_div_sub_add_1, p_decoder_feed_forward_linear_1_weight::T10) -&gt; _onx_matmul_layer_norm_1
        Add(_onx_matmul_layer_norm_1, decoder.feed_forward.linear_1.bias) -&gt; linear_7
          Relu(linear_7) -&gt; relu
            MatMul(relu, p_decoder_feed_forward_linear_2_weight::T10) -&gt; _onx_matmul_relu
              Add(_onx_matmul_relu, decoder.feed_forward.linear_2.bias) -&gt; linear_8
      Add(linear_8, add_1) -&gt; output_0
output: name=&#39;output_0&#39; type=dtype(&#39;float32&#39;) shape=[1, 30, 16]
</pre></div>
</div>
<p>This shows a kernel <code class="docutils literal notranslate"><span class="pre">FusedMatMul[com.microsoft]</span></code> which implement a kernel equivalent Gemm
but working for any tensors, not only 2D.
How does it work on the model which keeps exports the moduels as local functions?
The optimizer optimizes every local function independantly.
We reduce the verbosity</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx_module_optimized</span></a></a></a> <span class="o">=</span> <a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter sphx-glr-backref-type-py-function"><span class="n">to_onnx</span></a></a></a><span class="p">(</span>
    <span class="n">llm</span><span class="p">,</span>
    <span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_ids</span></a></a></a><span class="p">,),</span>
    <span class="n">options</span><span class="o">=</span><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/xbuilder/index.html#experimental_experiment.xbuilder.OptimizationOptions" title="experimental_experiment.xbuilder.OptimizationOptions" class="sphx-glr-backref-module-experimental_experiment-xbuilder sphx-glr-backref-type-py-class"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/xbuilder/index.html#experimental_experiment.xbuilder.OptimizationOptions" title="experimental_experiment.xbuilder.OptimizationOptions" class="sphx-glr-backref-module-experimental_experiment-xbuilder sphx-glr-backref-type-py-class"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/xbuilder/index.html#experimental_experiment.xbuilder.OptimizationOptions" title="experimental_experiment.xbuilder.OptimizationOptions" class="sphx-glr-backref-module-experimental_experiment-xbuilder sphx-glr-backref-type-py-class"><span class="n">OptimizationOptions</span></a></a></a><span class="p">(</span><span class="n">patterns</span><span class="o">=</span><span class="s2">&quot;default+onnxruntime&quot;</span><span class="p">,</span> <span class="n">constant_folding</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <span class="n">export_modules_as_functions</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><span class="n">pretty_onnx</span></a></a></a><span class="p">(</span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx_module_optimized</span></a></a></a><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>/usr/lib/python3.12/copyreg.py:99: FutureWarning: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.
  return cls.__new__(cls, *args)
opset: domain=&#39;&#39; version=18
opset: domain=&#39;aten_local_function&#39; version=1
opset: domain=&#39;com.microsoft&#39; version=1
input: name=&#39;input_ids&#39; type=dtype(&#39;int64&#39;) shape=[1, 30]
init: name=&#39;embedding.embedding.weight&#39; type=float32 shape=(1024, 16) -- GraphBuilder.make_local_function/from(embedding.embedding.weight)
init: name=&#39;embedding.pe.weight&#39; type=float32 shape=(1024, 16)        -- GraphBuilder.make_local_function/from(embedding.pe.weight)
init: name=&#39;weight::T10&#39; type=float32 shape=(16, 16)                  -- GraphBuilder.make_local_function/from(weight::T10)
init: name=&#39;weight::T102&#39; type=float32 shape=(16, 16)                 -- GraphBuilder.make_local_function/from(weight::T102)
init: name=&#39;weight::T103&#39; type=float32 shape=(16, 16)                 -- GraphBuilder.make_local_function/from(weight::T103)
init: name=&#39;slice_2&#39; type=float32 shape=(30, 30)                      -- GraphBuilder.make_local_function/from(slice_2)
init: name=&#39;weight::T104&#39; type=float32 shape=(16, 16)                 -- GraphBuilder.make_local_function/from(weight::T104)
init: name=&#39;weight::T1022&#39; type=float32 shape=(16, 16)                -- GraphBuilder.make_local_function/from(weight::T1022)
init: name=&#39;weight::T1032&#39; type=float32 shape=(16, 16)                -- GraphBuilder.make_local_function/from(weight::T1032)
init: name=&#39;slice_4&#39; type=float32 shape=(30, 30)                      -- GraphBuilder.make_local_function/from(slice_4)
init: name=&#39;weight::T105&#39; type=float32 shape=(32, 16)                 -- GraphBuilder.make_local_function/from(weight::T105)
init: name=&#39;decoder.feed_forward.linear_1.bias&#39; type=float32 shape=(128,)-- GraphBuilder.make_local_function/from(decoder.feed_forward.linear_1.bias)
init: name=&#39;weight::T106&#39; type=float32 shape=(16, 128)                -- GraphBuilder.make_local_function/from(weight::T106)
init: name=&#39;weight::T1023&#39; type=float32 shape=(128, 16)               -- GraphBuilder.make_local_function/from(weight::T1023)
init: name=&#39;init1_s16_3&#39; type=float32 shape=(16,)                     -- GraphBuilder.constant_folding.from/fold()
init: name=&#39;init1_s16_22&#39; type=float32 shape=(16,)                    -- GraphBuilder.constant_folding.from/fold()
init: name=&#39;bias2&#39; type=float32 shape=(16,)                           -- GraphBuilder.constant_folding.from/fold()
init: name=&#39;bias&#39; type=float32 shape=(16,)                            -- GraphBuilder.constant_folding.from/fold()
init: name=&#39;init1_s1_2&#39; type=float32 shape=(1,) -- array([-inf], dtype=float32)-- GraphBuilder.constant_folding.from/fold()
init: name=&#39;init1_s_2::RSh12&#39; type=float32 shape=(1,) -- array([0.], dtype=float32)-- GraphBuilder.constant_folding.from/fold()
Equal(slice_2, init1_s_2::RSh12) -&gt; eq
Gather(embedding.embedding.weight, input_ids) -&gt; embedding2
Gather(embedding.pe.weight, input_ids) -&gt; pe
  SkipLayerNormalization[com.microsoft](embedding2, pe, init1_s16_3, init1_s16_22, epsilon=0.00) -&gt; norm_1, unused, unused2, embedding
    MatMul(norm_1, weight::T10) -&gt; query
MatMul(norm_1, weight::T102) -&gt; key
  FusedMatMul[com.microsoft](query, key, alpha=0.25, transA=0, transB=1, transBatchA=0, transBatchB=0) -&gt; _onx_mul_matmul
  Where(eq, init1_s1_2, _onx_mul_matmul) -&gt; masked_fill
    Softmax(masked_fill, axis=-1) -&gt; softmax
MatMul(norm_1, weight::T103) -&gt; value
  MatMul(softmax, value) -&gt; attention_0
MatMul(norm_1, weight::T104) -&gt; query2
MatMul(norm_1, weight::T1022) -&gt; key2
  FusedMatMul[com.microsoft](query2, key2, alpha=0.25, transA=0, transB=1, transBatchA=0, transBatchB=0) -&gt; _onx_mul_matmul2
MatMul(norm_1, weight::T1032) -&gt; value2
Equal(slice_4, init1_s_2::RSh12) -&gt; eq2
  Where(eq2, init1_s1_2, _onx_mul_matmul2) -&gt; masked_fill2
    Softmax(masked_fill2, axis=-1) -&gt; softmax2
  MatMul(softmax2, value2) -&gt; attention_1
    Concat(attention_0, attention_1, axis=-1) -&gt; cat
      MatMul(cat, weight::T105) -&gt; _onx_matmul_cat
        Add(_onx_matmul_cat, bias) -&gt; attention
    SkipLayerNormalization[com.microsoft](attention, embedding, init1_s16_3, init1_s16_22, epsilon=0.00) -&gt; norm_2, unused3, unused4, add_1
      MatMul(norm_2, weight::T106) -&gt; _onx_matmul_layer_norm_1
        Add(_onx_matmul_layer_norm_1, decoder.feed_forward.linear_1.bias) -&gt; linear_1
          Relu(linear_1) -&gt; relu
            MatMul(relu, weight::T1023) -&gt; _onx_matmul_relu
              Add(_onx_matmul_relu, bias2) -&gt; feed_forward
      Add(feed_forward, add_1) -&gt; output_0
output: name=&#39;output_0&#39; type=dtype(&#39;float32&#39;) shape=[1, 30, 16]
</pre></div>
</div>
<p>It seems to be working as well on this simple case even though the optimizers were
not tested on such models. However, keeping the submodule information might be useful
to implement optimizer for a fmaily of models sharing the same components.</p>
</section>
<section id="optimizations-for-cuda">
<h2>Optimizations for CUDA<a class="headerlink" href="#optimizations-for-cuda" title="Link to this heading"></a></h2>
<p>The optimizer may have a different behaviour knowning the model is running on CUDA.
It may use different kernels and do different optimization if needed.
That may not be the good place to do it as the runtime may choose to run one kernel on CPU,
another one on CUDA. The current optimization does not know that and
is not able to decide which provider would be more useful for some kernels.
This coudl even be decided at runtime.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx_cuda_optimized</span></a></a></a> <span class="o">=</span> <a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/torch_interpreter/index.html#experimental_experiment.torch_interpreter.to_onnx" title="experimental_experiment.torch_interpreter.to_onnx" class="sphx-glr-backref-module-experimental_experiment-torch_interpreter sphx-glr-backref-type-py-function"><span class="n">to_onnx</span></a></a></a><span class="p">(</span>
    <span class="n">llm</span><span class="p">,</span>
    <span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_ids</span></a></a></a><span class="p">,),</span>
    <span class="n">options</span><span class="o">=</span><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/xbuilder/index.html#experimental_experiment.xbuilder.OptimizationOptions" title="experimental_experiment.xbuilder.OptimizationOptions" class="sphx-glr-backref-module-experimental_experiment-xbuilder sphx-glr-backref-type-py-class"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/xbuilder/index.html#experimental_experiment.xbuilder.OptimizationOptions" title="experimental_experiment.xbuilder.OptimizationOptions" class="sphx-glr-backref-module-experimental_experiment-xbuilder sphx-glr-backref-type-py-class"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/xbuilder/index.html#experimental_experiment.xbuilder.OptimizationOptions" title="experimental_experiment.xbuilder.OptimizationOptions" class="sphx-glr-backref-module-experimental_experiment-xbuilder sphx-glr-backref-type-py-class"><span class="n">OptimizationOptions</span></a></a></a><span class="p">(</span>
        <span class="n">patterns</span><span class="o">=</span><span class="s2">&quot;default+onnxruntime&quot;</span><span class="p">,</span> <span class="n">constant_folding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">processor</span><span class="o">=</span><span class="s2">&quot;CUDA&quot;</span>
    <span class="p">),</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-diagnostic/dev/api/helpers/onnx_helper.html#onnx_diagnostic.helpers.onnx_helper.pretty_onnx" title="onnx_diagnostic.helpers.onnx_helper.pretty_onnx" class="sphx-glr-backref-module-onnx_diagnostic-helpers-onnx_helper sphx-glr-backref-type-py-function"><span class="n">pretty_onnx</span></a></a></a><span class="p">(</span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx_cuda_optimized</span></a></a></a><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[GraphBuilder-MNW.optimize] start with 73 nodes
[GraphBuilder-MNW.optimize] #patterns=102
[GraphBuilder-MNW.remove_unused] remove_initializer 1:1/47:embedding.embedding.weight:torch.float32[torch.Size([1024, 16])]
[GraphBuilder-MNW.remove_unused] remove_initializer 2:3/47:embedding.pe.weight:torch.float32[torch.Size([1024, 16])]
[GraphBuilder-MNW.remove_unused] remove_initializer 3:5/47:decoder.attention.attention.0.query.weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-MNW.remove_unused] remove_initializer 4:7/47:decoder.attention.attention.0.key.weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-MNW.remove_unused] remove_initializer 5:9/47:decoder.attention.attention.0.value.weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-MNW.remove_unused] remove_initializer 6:11/47:decoder.attention.attention.1.query.weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-MNW.remove_unused] remove_initializer 7:13/47:decoder.attention.attention.1.key.weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-MNW.remove_unused] remove_initializer 8:15/47:decoder.attention.attention.1.value.weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-MNW.remove_unused] remove_initializer 9:17/47:decoder.attention.linear.weight:torch.float32[torch.Size([16, 32])]
[GraphBuilder-MNW.remove_unused] remove_initializer 10:19/47:decoder.attention.linear.bias:torch.float32[torch.Size([16])]
[GraphBuilder-MNW.remove_unused] remove_initializer 11:21/47:decoder.feed_forward.linear_1.weight:torch.float32[torch.Size([128, 16])]
[GraphBuilder-MNW.remove_unused] remove_initializer 12:23/47:decoder.feed_forward.linear_1.bias:torch.float32[torch.Size([128])]
[GraphBuilder-MNW.remove_unused] remove_initializer 13:25/47:decoder.feed_forward.linear_2.weight:torch.float32[torch.Size([16, 128])]
[GraphBuilder-MNW.remove_unused] remove_initializer 14:27/47:decoder.feed_forward.linear_2.bias:torch.float32[torch.Size([16])]
[GraphBuilder-MNW.remove_unused] remove_initializer 15:29/47:decoder.norm_1.weight:torch.float32[torch.Size([16])]
[GraphBuilder-MNW.remove_unused] remove_initializer 16:31/47:decoder.norm_1.bias:torch.float32[torch.Size([16])]
[GraphBuilder-MNW.remove_unused] remove_initializer 17:33/47:decoder.norm_2.weight:torch.float32[torch.Size([16])]
[GraphBuilder-MNW.remove_unused] remove_initializer 18:35/47:decoder.norm_2.bias:torch.float32[torch.Size([16])]
[GraphBuilder-MNW.remove_unused] remove_initializer 1:2/46:p_decoder_attention_attention_0_query_weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-MNW.remove_unused] remove_initializer 2:3/46:p_decoder_attention_attention_0_key_weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-MNW.remove_unused] remove_initializer 3:4/46:p_decoder_attention_attention_0_value_weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-MNW.remove_unused] remove_initializer 4:5/46:p_decoder_attention_attention_1_query_weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-MNW.remove_unused] remove_initializer 5:6/46:p_decoder_attention_attention_1_key_weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-MNW.remove_unused] remove_initializer 6:7/46:p_decoder_attention_attention_1_value_weight:torch.float32[torch.Size([16, 16])]
[GraphBuilder-MNW.remove_unused] remove_initializer 7:8/46:p_decoder_attention_linear_weight:torch.float32[torch.Size([16, 32])]
[GraphBuilder-MNW.remove_unused] remove_initializer 8:10/46:p_decoder_feed_forward_linear_1_weight:torch.float32[torch.Size([128, 16])]
[GraphBuilder-MNW.remove_unused] remove_initializer 9:12/46:p_decoder_feed_forward_linear_2_weight:torch.float32[torch.Size([16, 128])]
[GraphBuilder-MNW.remove_unused] remove_initializer 10:18/46:b_decoder_attention_attention_0_mask:torch.float32[torch.Size([256, 256])]
[GraphBuilder-MNW.remove_unused] remove_initializer 11:19/46:b_decoder_attention_attention_1_mask:torch.float32[torch.Size([256, 256])]
[GraphBuilder-MNW.remove_unused] remove_initializer 12:23/46:init1_s_:float32[()]
[GraphBuilder-MNW.remove_unused] remove_initializer 13:24/46:init7_s1_1:int64[(1,)]
[GraphBuilder-MNW.remove_unused] remove_initializer 14:25/46:init7_s1_0:int64[(1,)]
[GraphBuilder-MNW.remove_unused] remove_initializer 15:26/46:init7_s1_30:int64[(1,)]
[GraphBuilder-MNW.remove_unused] remove_initializer 16:27/46:init1_s_2:float32[()]
[GraphBuilder-MNW.remove_unused] remove_initializer 17:33/46:slice_1:torch.float32[torch.Size([30, 256])]
[GraphBuilder-MNW.remove_unused] remove_initializer 18:40/46:slice_3:torch.float32[torch.Size([30, 256])]
[GraphBuilderPatternOptimization-MNW.optimize] start with 53 nodes, 28 initializers, 102 patterns, priorities=[0, 1, 2, 3], max_iter=212
[GraphBuilderPatternOptimization-MNW.optimize] use pattern   1/102 - P0 - BatchNormalizationPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern   2/102 - P0 - BatchNormalizationTrainingPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern   3/102 - P0 - CastCastPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern   4/102 - P0 - CastPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern   5/102 - P0 - ConcatGatherPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern   6/102 - P0 - ConcatReshapePattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern   7/102 - P0 - ConvBiasNullPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern   8/102 - P0 - ExpandPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern   9/102 - P0 - FunctionAttentionPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  10/102 - P0 - GeluErfPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  11/102 - P0 - GeluOrtPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  12/102 - P0 - GeluPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  13/102 - P0 - IdentityPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  14/102 - P0 - LeakyReluPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  15/102 - P0 - ReshapePattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  16/102 - P0 - ReshapeReshapePattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  17/102 - P0 - SameChildrenFromInputPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  18/102 - P0 - SameChildrenPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  19/102 - P0 - ShapeBasedEditDistanceReshapePattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  20/102 - P0 - ShapeBasedIdentityPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  21/102 - P0 - ShapeBasedReshapeIsSqueezePattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  22/102 - P0 - ShapeBasedSameChildrenPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  23/102 - P0 - ShapeBasedShapeShapeAddPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  24/102 - P0 - ShapeBasedStaticExpandPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  25/102 - P0 - ShapedBasedReshapePattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  26/102 - P0 - SoftmaxCrossEntropyLossCastPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  27/102 - P0 - SqueezeAddPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  28/102 - P0 - SqueezeBinaryUnsqueezePattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  29/102 - P0 - SqueezeUnsqueezePattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  30/102 - P0 - StaticConcatReshapePattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  31/102 - P0 - SwapExpandReshapePattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  32/102 - P0 - TransposeReshapeTransposePattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  33/102 - P0 - TransposeTransposePattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  34/102 - P0 - UnsqueezeReshapePattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  35/102 - P0 - UnsqueezeUnsqueezePattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  36/102 - P1 - BiasGeluPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  37/102 - P1 - BiasSoftmaxPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  38/102 - P1 - CastCastBinaryPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  39/102 - P1 - CastLayerNormalizationCastPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  40/102 - P1 - CastOpCastPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  41/102 - P1 - ClipClipPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  42/102 - P1 - ComputationCastOpCastPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  43/102 - P1 - ConcatEmptyPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  44/102 - P1 - ConcatTwiceUnaryPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  45/102 - P1 - ContribRotaryEmbedding3DPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  46/102 - P1 - DropoutPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  47/102 - P1 - ExpandBroadcastPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  48/102 - P1 - ExpandSwapPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  49/102 - P1 - FastGeluPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  50/102 - P1 - FunctionCausalMaskMulAddPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  51/102 - P1 - FunctionCausalMaskPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  52/102 - P1 - FunctionCosSinCachePattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  53/102 - P1 - FunctionHalfRotaryEmbeddingPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  54/102 - P1 - GemmTransposePattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  55/102 - P1 - LayerNormalizationPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  56/102 - P1 - LayerNormalizationScalePattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  57/102 - P1 - MatMulReshape2Of3Pattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  58/102 - P1 - MulMulMatMulPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  59/102 - P1 - MulMulMulScalarPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  60/102 - P1 - MultiHeadAttention3DPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  61/102 - P1 - OrtBatchNormalizationTrainingPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  62/102 - P1 - QuickGeluPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  63/102 - P1 - RMSNormalizationPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  64/102 - P1 - ReduceReshapePattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  65/102 - P1 - ReduceSumNormalizePattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  66/102 - P1 - Reshape2Of3Pattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  67/102 - P1 - ReshapeMatMulReshapePattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  68/102 - P1 - ReshapeReshapeBinaryPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  69/102 - P1 - RotaryConcatPartPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  70/102 - P1 - RotaryEmbeddingPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  71/102 - P1 - SequenceConstructAtPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  72/102 - P1 - ShapeBasedConcatExpandPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  73/102 - P1 - ShapeBasedExpandBroadcastMatMulPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  74/102 - P1 - ShapeBasedExpandBroadcastPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  75/102 - P1 - ShapeBasedExpandCastWhereSwapPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  76/102 - P1 - ShapeBasedExpandSwapPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  77/102 - P1 - ShapeBasedMatMulToMulPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  78/102 - P1 - SimplifiedLayerNormalizationMulPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  79/102 - P1 - SimplifiedLayerNormalizationPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  80/102 - P1 - SkipLayerNormalizationPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  81/102 - P1 - SkipSimplifiedLayerNormalizationMulPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  82/102 - P1 - SkipSimplifiedLayerNormalizationPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  83/102 - P1 - SliceSlicePattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  84/102 - P1 - SlicesSplitPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  85/102 - P1 - SoftmaxGradPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  86/102 - P1 - SplitConcatPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  87/102 - P1 - Sub1MulPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  88/102 - P1 - SwitchOrderBinaryPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  89/102 - P1 - SwitchReshapeActivationPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  90/102 - P1 - TransposeEqualReshapePattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  91/102 - P1 - TransposeMatMulPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  92/102 - P1 - TransposeReshapeMatMulPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  93/102 - P1 - UnsqueezeEqualPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  94/102 - P2 - ContribRotaryEmbeddingPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  95/102 - P2 - FusedConvPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  96/102 - P2 - FusedMatMulDivPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  97/102 - P2 - FusedMatMulPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  98/102 - P3 - FusedMatMulTransposePattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern  99/102 - P3 - FusedMatMulx2Pattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern 100/102 - P3 - MatMulAddPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern 101/102 - P3 - ReshapeGemmPattern()
[GraphBuilderPatternOptimization-MNW.optimize] use pattern 102/102 - P3 - TransposeFusedMatMulBPattern()
[GraphBuilderPatternOptimization-MNW.optimize] same children={&#39;SameChildrenFromInputPattern&#39;, &#39;SameChildrenPattern&#39;}
[GraphBuilderPatternOptimization-MNW.optimize] iteration 0: 53 nodes, priority=0
[GraphBuilderPatternOptimization-MNW.optimize] applies 6 matches, 2*CastPattern, 4*IdentityPattern - time=0.006 | max_time=SoftmaxCrossEntropyLossCastPattern:0.002
[GraphBuilder-MNW.remove_unused] remove_initializer 1:5/28:p_decoder_norm_1_weight:torch.float32[torch.Size([16])]
[GraphBuilder-MNW.remove_unused] remove_initializer 2:6/28:p_decoder_norm_1_bias:torch.float32[torch.Size([16])]
[GraphBuilder-MNW.remove_unused] remove_initializer 3:7/28:p_decoder_norm_2_weight:torch.float32[torch.Size([16])]
[GraphBuilder-MNW.remove_unused] remove_initializer 4:8/28:p_decoder_norm_2_bias:torch.float32[torch.Size([16])]
[GraphBuilderPatternOptimization-MNW.optimize] iteration 1: 47 nodes, priority=0
[GraphBuilderPatternOptimization-MNW.optimize] increase priority to 1
[GraphBuilderPatternOptimization-MNW.optimize] iteration 2: 47 nodes, priority=1
[GraphBuilderPatternOptimization-MNW.optimize] applies 2 matches, 2*LayerNormalizationPattern - time=0.005 | max_time=IdentityPattern:0.000
[GraphBuilder-MNW.remove_unused] remove_initializer 1:5/26:init7_s1_-1:int64[(1,)]
[GraphBuilder-MNW.remove_unused] remove_initializer 2:6/26:init1_s1_:float32[(1,)]
[GraphBuilder-MNW.remove_unused] remove_initializer 3:7/26:init1_s1_2:float32[(1,)]
[GraphBuilderPatternOptimization-MNW.optimize] iteration 3: 35 nodes, priority=1
[GraphBuilderPatternOptimization-MNW.optimize] applies 2 matches, 2*SkipLayerNormalizationPattern - time=0.003 | max_time=IdentityPattern:0.000
[GraphBuilderPatternOptimization-MNW.optimize] iteration 4: 33 nodes, priority=1
[GraphBuilderPatternOptimization-MNW.optimize] increase priority to 2
[GraphBuilderPatternOptimization-MNW.optimize] iteration 5: 33 nodes, priority=2
[GraphBuilderPatternOptimization-MNW.optimize] applies 2 matches, 2*FusedMatMulPattern - time=0.003 | max_time=GeluOrtPattern:0.000
[GraphBuilder-MNW.remove_unused] remove_initializer 1:9/23:init1_s_::RSh1:float32[(1,)]
[GraphBuilder-MNW.remove_unused] remove_initializer 2:15/23:init1_s_::RSh12:float32[(1,)]
[GraphBuilderPatternOptimization-MNW.optimize] iteration 6: 29 nodes, priority=2
[GraphBuilderPatternOptimization-MNW.optimize] increase priority to 3
[GraphBuilderPatternOptimization-MNW.optimize] iteration 7: 29 nodes, priority=3
[GraphBuilderPatternOptimization-MNW.optimize] stops current_priority_index=4, priorities=[0, 1, 2, 3]
[GraphBuilderPatternOptimization-MNW.optimize] done after 8 iterations with 29 nodes in 0.042
    STAT apply_CastPattern +2 -2 #it=1 maxmatch=1 i=2 - time=0.00016328200217685662
    STAT apply_FusedMatMulPattern +2 -6 #it=1 maxmatch=1 i=2 - time=0.00047822000124142505
    STAT apply_IdentityPattern +4 -4 #it=1 maxmatch=5 i=4 - time=0.00023145399609347805
    STAT apply_LayerNormalizationPattern +2 -14 #it=1 maxmatch=1 i=2 - time=0.00045434599815052934
    STAT apply_SkipLayerNormalizationPattern +2 -4 #it=1 maxmatch=1 i=2 - time=0.00017654499970376492
    STAT build_graph_for_pattern +0 -0 #it=8 maxmatch=0 i=0 - time=0.0010946979964501224
    STAT check_pattern_00 +0 -0 #it=1 maxmatch=0 i=0 - time=0.00013521099754143506
    STAT check_pattern_A0 +0 -0 #it=4 maxmatch=0 i=0 - time=0.001169749997643521
    STAT check_pattern_B0 +0 -0 #it=8 maxmatch=0 i=0 - time=0.0019305630194139667
    STAT insert_and_remove_nodes +0 -0 #it=0 maxmatch=0 i=0 - time=0.0007083319978846703
    STAT match_BatchNormalizationPattern +0 -0 #it=8 maxmatch=0 i=0 - time=0.0002275240076414775
    STAT match_BatchNormalizationTrainingPattern +0 -0 #it=8 maxmatch=0 i=0 - time=0.00018863400691770948
    STAT match_BiasGeluPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0001218450051965192
    STAT match_BiasSoftmaxPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00031873700572759844
    STAT match_CastCastBinaryPattern +0 -0 #it=6 maxmatch=0 i=0 - time=0.0003499200029182248
    STAT match_CastCastPattern +0 -0 #it=8 maxmatch=2 i=0 - time=0.00018547300351201557
    STAT match_CastLayerNormalizationCastPattern +0 -0 #it=6 maxmatch=0 i=0 - time=0.00015791699479450472
    STAT match_CastOpCastPattern +0 -0 #it=6 maxmatch=0 i=0 - time=0.00032358399766962975
    STAT match_CastPattern +0 -0 #it=8 maxmatch=2 i=2 - time=0.0002001369939534925
    STAT match_ClipClipPattern +0 -0 #it=6 maxmatch=0 i=0 - time=0.00012561300536617637
    STAT match_ComputationCastOpCastPattern +0 -0 #it=6 maxmatch=0 i=0 - time=0.00021212500359979458
    STAT match_ConcatEmptyPattern +0 -0 #it=6 maxmatch=0 i=0 - time=0.0001941499976965133
    STAT match_ConcatGatherPattern +0 -0 #it=8 maxmatch=2 i=0 - time=0.000229769000725355
    STAT match_ConcatReshapePattern +0 -0 #it=8 maxmatch=2 i=0 - time=0.0001786030043149367
    STAT match_ConcatTwiceUnaryPattern +0 -0 #it=6 maxmatch=0 i=0 - time=0.0001349199992546346
    STAT match_ContribRotaryEmbedding3DPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0001189299946418032
    STAT match_ContribRotaryEmbeddingPattern +0 -0 #it=3 maxmatch=0 i=0 - time=5.9319001593394205e-05
    STAT match_ConvBiasNullPattern +0 -0 #it=8 maxmatch=2 i=0 - time=0.00017198299974552356
    STAT match_DropoutPattern +0 -0 #it=6 maxmatch=0 i=0 - time=0.00010795799971674569
    STAT match_ExpandBroadcastPattern +0 -0 #it=6 maxmatch=0 i=0 - time=0.00011969699698965997
    STAT match_ExpandPattern +0 -0 #it=8 maxmatch=2 i=0 - time=0.00017331599519820884
    STAT match_ExpandSwapPattern +0 -0 #it=6 maxmatch=0 i=0 - time=0.00011628199717961252
    STAT match_FastGeluPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00012374400466796942
    STAT match_FunctionAttentionPattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.0002522550021240022
    STAT match_FunctionCausalMaskMulAddPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00016782300372142345
    STAT match_FunctionCausalMaskPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0001566600039950572
    STAT match_FunctionCosSinCachePattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0002141069999197498
    STAT match_FunctionHalfRotaryEmbeddingPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00017531200137455016
    STAT match_FusedConvPattern +0 -0 #it=3 maxmatch=0 i=0 - time=5.47620038560126e-05
    STAT match_FusedMatMulDivPattern +0 -0 #it=3 maxmatch=2 i=0 - time=0.0001260919962078333
    STAT match_FusedMatMulPattern +0 -0 #it=3 maxmatch=2 i=2 - time=0.00031501900230068713
    STAT match_FusedMatMulTransposePattern +0 -0 #it=1 maxmatch=0 i=0 - time=4.688600165536627e-05
    STAT match_FusedMatMulx2Pattern +0 -0 #it=1 maxmatch=0 i=0 - time=5.38929998583626e-05
    STAT match_GeluErfPattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.0018943459981528576
    STAT match_GeluOrtPattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.0024612349916424137
    STAT match_GeluPattern +0 -0 #it=8 maxmatch=2 i=0 - time=6.03299486101605e-06
    STAT match_GemmTransposePattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00012359100219327956
    STAT match_IdentityPattern +0 -0 #it=8 maxmatch=6 i=4 - time=0.002273370006150799
    STAT match_LayerNormalizationPattern +0 -0 #it=6 maxmatch=2 i=2 - time=0.00026916200295090675
    STAT match_LayerNormalizationScalePattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00014736500088474713
    STAT match_LeakyReluPattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.002310866995685501
    STAT match_MatMulAddPattern +0 -0 #it=1 maxmatch=0 i=0 - time=5.314900045050308e-05
    STAT match_MatMulReshape2Of3Pattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.000530122997588478
    STAT match_MulMulMatMulPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0003056379973713774
    STAT match_MulMulMulScalarPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00016327000412275083
    STAT match_MultiHeadAttention3DPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00014574200031347573
    STAT match_OrtBatchNormalizationTrainingPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00021547900178120472
    STAT match_QuickGeluPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00012218900155858137
    STAT match_RMSNormalizationPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00011870099842781201
    STAT match_ReduceReshapePattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0001674599916441366
    STAT match_ReduceSumNormalizePattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00011974699737038463
    STAT match_Reshape2Of3Pattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0003544819956005085
    STAT match_ReshapeGemmPattern +0 -0 #it=1 maxmatch=0 i=0 - time=1.9148999854223803e-05
    STAT match_ReshapeMatMulReshapePattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0002711950037337374
    STAT match_ReshapePattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.00023376999524771236
    STAT match_ReshapeReshapeBinaryPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00028334099260973744
    STAT match_ReshapeReshapePattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.00017636999473324977
    STAT match_RotaryConcatPartPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0001679860033618752
    STAT match_RotaryEmbeddingPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00011106900274171494
    STAT match_SameChildrenFromInputPattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.0003943030060327146
    STAT match_SameChildrenPattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.0006762810044165235
    STAT match_SequenceConstructAtPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00018846100283553824
    STAT match_ShapeBasedConcatExpandPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00012490400331444107
    STAT match_ShapeBasedEditDistanceReshapePattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.00016698700346751139
    STAT match_ShapeBasedExpandBroadcastMatMulPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0003718980005942285
    STAT match_ShapeBasedExpandBroadcastPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0003586149941838812
    STAT match_ShapeBasedExpandCastWhereSwapPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00014622800154029392
    STAT match_ShapeBasedExpandSwapPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00030972699823905714
    STAT match_ShapeBasedIdentityPattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.00020080499598407187
    STAT match_ShapeBasedMatMulToMulPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.000330789993313374
    STAT match_ShapeBasedReshapeIsSqueezePattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.00019694200091180392
    STAT match_ShapeBasedSameChildrenPattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.00018088100114255212
    STAT match_ShapeBasedShapeShapeAddPattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.00025431899848626927
    STAT match_ShapeBasedStaticExpandPattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.00017006999769364484
    STAT match_ShapedBasedReshapePattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.00017395400209352374
    STAT match_SimplifiedLayerNormalizationMulPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0001540119992569089
    STAT match_SimplifiedLayerNormalizationPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0002338640006200876
    STAT match_SkipLayerNormalizationPattern +0 -0 #it=6 maxmatch=2 i=2 - time=0.00014351000572787598
    STAT match_SkipSimplifiedLayerNormalizationMulPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0001363239971396979
    STAT match_SkipSimplifiedLayerNormalizationPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00011566499961190857
    STAT match_SliceSlicePattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00012057999992975965
    STAT match_SlicesSplitPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00012339699969743378
    STAT match_SoftmaxCrossEntropyLossCastPattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.003189224993548123
    STAT match_SoftmaxGradPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00012112699550925754
    STAT match_SplitConcatPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00012160499682067893
    STAT match_SqueezeAddPattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.0002801240007102024
    STAT match_SqueezeBinaryUnsqueezePattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.0001843350000854116
    STAT match_SqueezeUnsqueezePattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.00018335199638386257
    STAT match_StaticConcatReshapePattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.00016874099674168974
    STAT match_Sub1MulPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00013352900714380667
    STAT match_SwapExpandReshapePattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.00016670000695739873
    STAT match_SwitchOrderBinaryPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.0003891580090567004
    STAT match_SwitchReshapeActivationPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00018675999672268517
    STAT match_TransposeEqualReshapePattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00018497000201023184
    STAT match_TransposeFusedMatMulBPattern +0 -0 #it=1 maxmatch=0 i=0 - time=6.95550006639678e-05
    STAT match_TransposeMatMulPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00030761999732931145
    STAT match_TransposeReshapeMatMulPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00028330699569778517
    STAT match_TransposeReshapeTransposePattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.00019186899589840323
    STAT match_TransposeTransposePattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.00019036600133404136
    STAT match_UnsqueezeEqualPattern +0 -0 #it=6 maxmatch=2 i=0 - time=0.00025403100153198466
    STAT match_UnsqueezeReshapePattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.00017220400332007557
    STAT match_UnsqueezeUnsqueezePattern +0 -0 #it=8 maxmatch=6 i=0 - time=0.00016572999811614864
    STAT remove_duplicated_shape +0 -0 #it=8 maxmatch=0 i=0 - time=4.362199979368597e-05
    STAT remove_identity_nodes +9 -15 #it=8 maxmatch=0 i=0 - time=0.001662053993641166
    STAT remove_unused +0 -0 #it=8 maxmatch=0 i=0 - time=0.0018001399985223543
--MODEL: 29 nodes, 1 inputs, 1 outputs, 21 initializers--
         INPUT:   1 x 7t
     INPUT-SEQ:   1 x Falset
        OUTPUT:   1 x 1t
    OUTPUT-SEQ:   1 x Falset
          INIT:  21 x 1t
          NODE:   4 x Add
          NODE:   1 x Concat
          NODE:   2 x Equal
          NODE:   2 x Gather
          NODE:  11 x MatMul
          NODE:   1 x Relu
          NODE:   2 x Softmax
          NODE:   2 x Where
          NODE:   2 x com.microsoft.FusedMatMul
          NODE:   2 x com.microsoft.SkipLayerNormalization
--MODEL: 29 nodes, 1 inputs, 1 outputs, 21 initializers--DETAILED--
     INPUT:   1 x 7t[1x30]
    OUTPUT:   1 x 1t[1x30x16]
      INIT:   2 x 1t[1024x16]
      INIT:   1 x 1t[128]
      INIT:   1 x 1t[128x16]
      INIT:   4 x 1t[16]
      INIT:   1 x 1t[16x128]
      INIT:   6 x 1t[16x16]
      INIT:   3 x 1t[1]
      INIT:   2 x 1t[30x30]
      INIT:   1 x 1t[32x16]
      NODE:   1 x Add -SIG- 1t[1x30x128], 1t[128]
      NODE:   2 x Add -SIG- 1t[1x30x16], 1t[16]
      NODE:   1 x Add -SIG- 1t[1x30x16], 1t[1x30x16]
      NODE:   1 x Concat -SIG- 1t[1x30x16], 1t[1x30x16]
      NODE:   2 x Equal -SIG- 1t[30x30], 1t[1]
      NODE:   2 x Gather -SIG- 1t[1024x16], 7t[1x30]
      NODE:   1 x MatMul -SIG- 1t[1x30x128], 1t[128x16]
      NODE:   1 x MatMul -SIG- 1t[1x30x16], 1t[16x128]
      NODE:   6 x MatMul -SIG- 1t[1x30x16], 1t[16x16]
      NODE:   2 x MatMul -SIG- 1t[1x30x30], 1t[1x30x16]
      NODE:   1 x MatMul -SIG- 1t[1x30x32], 1t[32x16]
      NODE:   1 x Relu -SIG- 1t[1x30x128]
      NODE:   2 x Softmax -SIG- 1t[1x30x30]
      NODE:   2 x Where -SIG- 9t[30x30], 1t[1], 1t[1x30x30]
      NODE:   2 x com.microsoft.FusedMatMul -SIG- 1t[1x30x16], 1t[1x30x16]
      NODE:   2 x com.microsoft.SkipLayerNormalization -SIG- 1t[1x30x16], 1t[1x30x16], 1t[16], 1t[16]
[GraphBuilder-MNW.remove_unused] remove_initializer 1:15/21:init1_s_2::RSh12:float32[(1,)]
[GraphBuilder-MNW.optimize] done with 29 nodes in 0.052
opset: domain=&#39;&#39; version=18
opset: domain=&#39;com.microsoft&#39; version=1
input: name=&#39;input_ids&#39; type=dtype(&#39;int64&#39;) shape=[1, 30]
init: name=&#39;init1_s1_3&#39; type=float32 shape=(1,) -- array([-inf], dtype=float32)-- Opset.make_node.1/Small##Opset.make_node.1/Small
init: name=&#39;p_decoder_attention_attention_0_query_weight::T10&#39; type=float32 shape=(16, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_attention_attention_0_query_weight)##p_decoder_attention_attention_0_query_weight/DynamoInterpret.placeholder.1/P(decoder.attention.attention.0.query.weight)
init: name=&#39;p_decoder_attention_attention_0_key_weight::T10&#39; type=float32 shape=(16, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_attention_attention_0_key_weight)##p_decoder_attention_attention_0_key_weight/DynamoInterpret.placeholder.1/P(decoder.attention.attention.0.key.weight)
init: name=&#39;p_decoder_attention_attention_0_value_weight::T10&#39; type=float32 shape=(16, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_attention_attention_0_value_weight)##p_decoder_attention_attention_0_value_weight/DynamoInterpret.placeholder.1/P(decoder.attention.attention.0.value.weight)
init: name=&#39;slice_2&#39; type=float32 shape=(30, 30)                      -- GraphBuilder.constant_folding.from/fold(init7_s1_0,init7_s1_1,init7_s1_30,slice_1)##slice_1/GraphBuilder.constant_folding.from/fold(b_decoder_attention_attention_0_mask,init7_s1_0,init7_s1_30)##b_decoder_attention_attention_0_mask/DynamoInterpret.placeholder.0##init7_s1_0/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##init7_s1_30/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##init7_s1_0/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##init7_s1_30/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##init7_s1_1/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape
init: name=&#39;init1_s_2::RSh1&#39; type=float32 shape=(1,) -- array([0.], dtype=float32)-- GraphBuilder.constant_folding.from/fold(init1_s_2,init7_s1_1)##init1_s_2/shape_type_compute._cast_inputs.0##shape_type_compute._cast_inputs.0##init7_s1_1/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape
init: name=&#39;p_decoder_attention_attention_1_query_weight::T10&#39; type=float32 shape=(16, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_attention_attention_1_query_weight)##p_decoder_attention_attention_1_query_weight/DynamoInterpret.placeholder.1/P(decoder.attention.attention.1.query.weight)
init: name=&#39;p_decoder_attention_attention_1_key_weight::T10&#39; type=float32 shape=(16, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_attention_attention_1_key_weight)##p_decoder_attention_attention_1_key_weight/DynamoInterpret.placeholder.1/P(decoder.attention.attention.1.key.weight)
init: name=&#39;p_decoder_attention_attention_1_value_weight::T10&#39; type=float32 shape=(16, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_attention_attention_1_value_weight)##p_decoder_attention_attention_1_value_weight/DynamoInterpret.placeholder.1/P(decoder.attention.attention.1.value.weight)
init: name=&#39;slice_4&#39; type=float32 shape=(30, 30)                      -- GraphBuilder.constant_folding.from/fold(init7_s1_0,init7_s1_1,init7_s1_30,slice_3)##slice_3/GraphBuilder.constant_folding.from/fold(b_decoder_attention_attention_1_mask,init7_s1_0,init7_s1_30)##b_decoder_attention_attention_1_mask/DynamoInterpret.placeholder.0##init7_s1_0/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##init7_s1_30/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##init7_s1_0/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##init7_s1_30/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##init7_s1_1/Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape##Opset.make_node.1/Shape
init: name=&#39;p_decoder_attention_linear_weight::T10&#39; type=float32 shape=(32, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_attention_linear_weight)##p_decoder_attention_linear_weight/DynamoInterpret.placeholder.1/P(decoder.attention.linear.weight)
init: name=&#39;p_decoder_feed_forward_linear_1_weight::T10&#39; type=float32 shape=(16, 128)-- GraphBuilder.constant_folding.from/fold(p_decoder_feed_forward_linear_1_weight)##p_decoder_feed_forward_linear_1_weight/DynamoInterpret.placeholder.1/P(decoder.feed_forward.linear_1.weight)
init: name=&#39;p_decoder_feed_forward_linear_2_weight::T10&#39; type=float32 shape=(128, 16)-- GraphBuilder.constant_folding.from/fold(p_decoder_feed_forward_linear_2_weight)##p_decoder_feed_forward_linear_2_weight/DynamoInterpret.placeholder.1/P(decoder.feed_forward.linear_2.weight)
init: name=&#39;init1_s16_&#39; type=float32 shape=(16,)                      -- LayerNormalizationPattern.apply.scale##LayerNormalizationPattern.apply.scale
init: name=&#39;init1_s16_2&#39; type=float32 shape=(16,)                     -- LayerNormalizationPattern.apply.bias##LayerNormalizationPattern.apply.bias
init: name=&#39;embedding.embedding.weight&#39; type=float32 shape=(1024, 16) -- DynamoInterpret.placeholder.1/P(embedding.embedding.weight)
init: name=&#39;embedding.pe.weight&#39; type=float32 shape=(1024, 16)        -- DynamoInterpret.placeholder.1/P(embedding.pe.weight)
init: name=&#39;decoder.attention.linear.bias&#39; type=float32 shape=(16,)   -- DynamoInterpret.placeholder.1/P(decoder.attention.linear.bias)
init: name=&#39;decoder.feed_forward.linear_1.bias&#39; type=float32 shape=(128,)-- DynamoInterpret.placeholder.1/P(decoder.feed_forward.linear_1.bias)
init: name=&#39;decoder.feed_forward.linear_2.bias&#39; type=float32 shape=(16,)-- DynamoInterpret.placeholder.1/P(decoder.feed_forward.linear_2.bias)
Equal(slice_2, init1_s_2::RSh1) -&gt; eq
Gather(embedding.embedding.weight, input_ids) -&gt; embedding
Gather(embedding.pe.weight, input_ids) -&gt; embedding_1
  SkipLayerNormalization[com.microsoft](embedding, embedding_1, init1_s16_, init1_s16_2, epsilon=0.00) -&gt; _onx_div_sub_add, unused, unused2, add
    MatMul(_onx_div_sub_add, p_decoder_attention_attention_0_query_weight::T10) -&gt; linear
MatMul(_onx_div_sub_add, p_decoder_attention_attention_0_key_weight::T10) -&gt; linear_1
  FusedMatMul[com.microsoft](linear, linear_1, alpha=0.25, transA=0, transB=1, transBatchA=0, transBatchB=0) -&gt; _onx_mul_matmul
  Where(eq, init1_s1_3, _onx_mul_matmul) -&gt; masked_fill
    Softmax(masked_fill, axis=-1) -&gt; softmax
MatMul(_onx_div_sub_add, p_decoder_attention_attention_0_value_weight::T10) -&gt; linear_2
  MatMul(softmax, linear_2) -&gt; matmul_1
MatMul(_onx_div_sub_add, p_decoder_attention_attention_1_query_weight::T10) -&gt; linear_3
MatMul(_onx_div_sub_add, p_decoder_attention_attention_1_key_weight::T10) -&gt; linear_4
  FusedMatMul[com.microsoft](linear_3, linear_4, alpha=0.25, transA=0, transB=1, transBatchA=0, transBatchB=0) -&gt; _onx_mul_matmul_2
MatMul(_onx_div_sub_add, p_decoder_attention_attention_1_value_weight::T10) -&gt; linear_5
Equal(slice_4, init1_s_2::RSh1) -&gt; eq_1
  Where(eq_1, init1_s1_3, _onx_mul_matmul_2) -&gt; masked_fill_1
    Softmax(masked_fill_1, axis=-1) -&gt; softmax_1
  MatMul(softmax_1, linear_5) -&gt; matmul_3
    Concat(matmul_1, matmul_3, axis=-1) -&gt; cat
      MatMul(cat, p_decoder_attention_linear_weight::T10) -&gt; _onx_matmul_cat
        Add(_onx_matmul_cat, decoder.attention.linear.bias) -&gt; linear_6
    SkipLayerNormalization[com.microsoft](linear_6, add, init1_s16_, init1_s16_2, epsilon=0.00) -&gt; _onx_div_sub_add_1, unused3, unused4, add_1
      MatMul(_onx_div_sub_add_1, p_decoder_feed_forward_linear_1_weight::T10) -&gt; _onx_matmul_layer_norm_1
        Add(_onx_matmul_layer_norm_1, decoder.feed_forward.linear_1.bias) -&gt; linear_7
          Relu(linear_7) -&gt; relu
            MatMul(relu, p_decoder_feed_forward_linear_2_weight::T10) -&gt; _onx_matmul_relu
              Add(_onx_matmul_relu, decoder.feed_forward.linear_2.bias) -&gt; linear_8
      Add(linear_8, add_1) -&gt; output_0
output: name=&#39;output_0&#39; type=dtype(&#39;float32&#39;) shape=[1, 30, 16]
</pre></div>
</div>
</section>
<section id="comparison-optimized-and-not-optimized">
<h2>Comparison optimized and not optimized?<a class="headerlink" href="#comparison-optimized-and-not-optimized" title="Link to this heading"></a></h2>
<p>The following tools is trying to match the node and shape inference
from two models. If they are not too different, the functions
is able to find out the differences. We can use to see
which operators were fused into bigger ones only implemented by
<a class="reference external" href="https://onnxruntime.ai/">onnxruntime</a>.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">res1</span></a></a></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">res2</span></a></a></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">align</span></a></a></a><span class="p">,</span> <a href="https://sdpython.github.io/doc/onnx-array-api/dev/api/reference.html#onnx_array_api.reference.DistanceExecution" title="onnx_array_api.reference.DistanceExecution" class="sphx-glr-backref-module-onnx_array_api-reference sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://sdpython.github.io/doc/onnx-array-api/dev/api/reference.html#onnx_array_api.reference.DistanceExecution" title="onnx_array_api.reference.DistanceExecution" class="sphx-glr-backref-module-onnx_array_api-reference sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://sdpython.github.io/doc/onnx-array-api/dev/api/reference.html#onnx_array_api.reference.DistanceExecution" title="onnx_array_api.reference.DistanceExecution" class="sphx-glr-backref-module-onnx_array_api-reference sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dc</span></a></a></a> <span class="o">=</span> <a href="https://sdpython.github.io/doc/onnx-array-api/dev/api/reference.html#onnx_array_api.reference.compare_onnx_execution" title="onnx_array_api.reference.compare_onnx_execution" class="sphx-glr-backref-module-onnx_array_api-reference sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-array-api/dev/api/reference.html#onnx_array_api.reference.compare_onnx_execution" title="onnx_array_api.reference.compare_onnx_execution" class="sphx-glr-backref-module-onnx_array_api-reference sphx-glr-backref-type-py-function"><a href="https://sdpython.github.io/doc/onnx-array-api/dev/api/reference.html#onnx_array_api.reference.compare_onnx_execution" title="onnx_array_api.reference.compare_onnx_execution" class="sphx-glr-backref-module-onnx_array_api-reference sphx-glr-backref-type-py-function"><span class="n">compare_onnx_execution</span></a></a></a><span class="p">(</span>
    <a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx</span></a></a></a><span class="p">,</span> <a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx_optimized</span></a></a></a><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="bp">cls</span><span class="o">=</span><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/reference/index.html#experimental_experiment.reference.ExtendedReferenceEvaluator" title="experimental_experiment.reference.ExtendedReferenceEvaluator" class="sphx-glr-backref-module-experimental_experiment-reference sphx-glr-backref-type-py-class"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/reference/index.html#experimental_experiment.reference.ExtendedReferenceEvaluator" title="experimental_experiment.reference.ExtendedReferenceEvaluator" class="sphx-glr-backref-module-experimental_experiment-reference sphx-glr-backref-type-py-class"><a href="https://sdpython.github.io/doc/experimental-experiment/dev/api/reference/index.html#experimental_experiment.reference.ExtendedReferenceEvaluator" title="experimental_experiment.reference.ExtendedReferenceEvaluator" class="sphx-glr-backref-module-experimental_experiment-reference sphx-glr-backref-type-py-class"><span class="n">ExtendedReferenceEvaluator</span></a></a></a>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------&quot;</span><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">text</span></a></a></a> <span class="o">=</span> <a href="https://sdpython.github.io/doc/onnx-array-api/dev/api/reference.html#onnx_array_api.reference.DistanceExecution.to_str" title="onnx_array_api.reference.DistanceExecution.to_str" class="sphx-glr-backref-module-onnx_array_api-reference sphx-glr-backref-type-py-method"><a href="https://sdpython.github.io/doc/onnx-array-api/dev/api/reference.html#onnx_array_api.reference.DistanceExecution.to_str" title="onnx_array_api.reference.DistanceExecution.to_str" class="sphx-glr-backref-module-onnx_array_api-reference sphx-glr-backref-type-py-method"><a href="https://sdpython.github.io/doc/onnx-array-api/dev/api/reference.html#onnx_array_api.reference.DistanceExecution.to_str" title="onnx_array_api.reference.DistanceExecution.to_str" class="sphx-glr-backref-module-onnx_array_api-reference sphx-glr-backref-type-py-method"><span class="n">dc</span><span class="o">.</span><span class="n">to_str</span></a></a></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">res1</span></a></a></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">res2</span></a></a></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">align</span></a></a></a><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">text</span></a></a></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[compare_onnx_execution] generate inputs
[compare_onnx_execution] execute with 1 inputs
[compare_onnx_execution] execute first model
[compare_onnx_execution] got 66 results
[compare_onnx_execution] execute second model
[compare_onnx_execution] got 66 results (first model)
[compare_onnx_execution] got 57 results (second model)
[compare_onnx_execution] compute edit distance
[compare_onnx_execution] got 66 pairs
[compare_onnx_execution] done
------------
001 ~ | INITIA float32  2:256x256            AOCQ                 b_ | INITIA float32  1:1                  ?AAA                 in
002 - | INITIA float32  2:256x256            AOCQ                 b_ |
003 - | INITIA int64    1:1                  BAAA                 in |
004 - | INITIA int64    1:1                  AAAA                 in |
005 - | INITIA int64    1:1                  EAAA                 in |
006 ~ | INITIA float32  1:1                  ?AAA                 in | INITIA float32  2:16x16              AAAA                 p_
007 ~ | INITIA float32  2:16x16              AAAA                 p_ | INITIA float32  2:16x16              AAAZ                 p_
008 ~ | INITIA float32  2:16x16              AAAZ                 p_ | INITIA float32  2:16x16              AAAA                 p_
009 ~ | INITIA float32  2:16x16              AAAA                 p_ | INITIA float32  2:30x30              KGSP                 sl
010 = | INITIA float32  1:1                  AAAA                 in | INITIA float32  1:1                  AAAA                 in
011 ~ | INITIA float32  1:1                  AAAA                 in | INITIA float32  2:16x16              AAAA                 p_
012 ~ | INITIA float32  2:16x16              AAAA                 p_ | INITIA float32  2:16x16              AABA                 p_
013 ~ | INITIA float32  2:16x16              AABA                 p_ | INITIA float32  2:16x16              AACB                 p_
014 ~ | INITIA float32  2:16x16              AACB                 p_ | INITIA float32  2:30x30              KGSP                 sl
015 = | INITIA float32  2:32x16              AAAA                 p_ | INITIA float32  2:32x16              AAAA                 p_
016 = | INITIA float32  2:16x128             VYBV                 p_ | INITIA float32  2:16x128             VYBV                 p_
017 = | INITIA float32  2:128x16             CABZ                 p_ | INITIA float32  2:128x16             CABZ                 p_
018 = | INITIA float32  1:16                 EEEE                 in | INITIA float32  1:16                 EEEE                 in
019 = | INITIA float32  1:16                 AAAA                 in | INITIA float32  1:16                 AAAA                 in
020 = | INITIA float32  2:1024x16            ACSE                 em | INITIA float32  2:1024x16            ACSE                 em
021 = | INITIA float32  2:1024x16            VYQK                 em | INITIA float32  2:1024x16            VYQK                 em
022 = | INITIA float32  1:16                 AAAA                 de | INITIA float32  1:16                 AAAA                 de
023 = | INITIA float32  1:128                BAAZ                 de | INITIA float32  1:128                BAAZ                 de
024 = | INITIA float32  1:16                 AAAA                 de | INITIA float32  1:16                 AAAA                 de
025 = | INPUT  int64    2:1x30               COAD                 in | INPUT  int64    2:1x30               COAD                 in
026 - | RESULT int64    1:2                  ABAA Concat          Sl |
027 - | RESULT int64    1:2                  EEAA Concat          Sl |
028 - | RESULT int64    1:2                  AAAA Concat          Sl |
029 = | RESULT float32  3:1x30x16            OIOQ Gather          em | RESULT float32  3:1x30x16            OIOQ Gather          em
030 = | RESULT float32  3:1x30x16            OQQE Gather          em | RESULT float32  3:1x30x16            OQQE Gather          em
031 ~ | RESULT float32  3:1x30x16            CZEU Add             ad | RESULT float32  3:1x30x16            BZDX SkipLayerNormal _o
032 ~ | RESULT float32  3:1x30x16            BZDX LayerNormalizat _o | RESULT float32  3:1x30x1             ZABA SkipLayerNormal un
033 ~ | RESULT float32  3:1x30x16            SQRW MatMul          li | RESULT float32  3:1x30x1             GFFE SkipLayerNormal un
034 ~ | RESULT float32  3:1x30x16            WDXZ MatMul          li | RESULT float32  3:1x30x16            CZEU SkipLayerNormal ad
035 ~ | RESULT float32  3:1x30x16            BEQG MatMul          li | RESULT float32  3:1x30x16            SQRW MatMul          li
036 ~ | RESULT float32  3:1x16x30            GWZT Transpose       tr | RESULT float32  3:1x30x16            WDXZ MatMul          li
037 ~ | RESULT float32  3:1x30x30            WTFV MatMul          ma | RESULT float32  3:1x30x30            TEBF FusedMatMul     _o
038 ~ | RESULT float32  3:1x30x30            TEBF Mul             _o | RESULT float32  3:1x30x16            BEQG MatMul          li
039 - | RESULT float32  2:30x30              KGSP Slice           sl |
040 = | RESULT bool     2:30x30              HLZC Equal           eq | RESULT bool     2:30x30              HLZC Equal           eq
041 = | RESULT float32  3:1x30x30            ???? Where           ma | RESULT float32  3:1x30x30            ???? Where           ma
042 = | RESULT float32  3:1x30x30            IHHH Softmax         so | RESULT float32  3:1x30x30            IHHH Softmax         so
043 = | RESULT float32  3:1x30x16            BBZA MatMul          ma | RESULT float32  3:1x30x16            BBZA MatMul          ma
044 = | RESULT float32  3:1x30x16            XAIF MatMul          li | RESULT float32  3:1x30x16            XAIF MatMul          li
045 = | RESULT float32  3:1x30x16            HCAA MatMul          li | RESULT float32  3:1x30x16            HCAA MatMul          li
046 ~ | RESULT float32  3:1x30x16            AXIB MatMul          li | RESULT float32  3:1x30x30            FUYA FusedMatMul     _o
047 ~ | RESULT float32  3:1x16x30            AIYD Transpose       tr | RESULT float32  3:1x30x16            AXIB MatMul          li
048 ~ | RESULT float32  3:1x30x30            VASB MatMul          ma | RESULT bool     2:30x30              HLZC Equal           eq
049 ~ | RESULT float32  3:1x30x30            FUYA Mul             _o | RESULT float32  3:1x30x30            ???? Where           ma
050 ~ | RESULT float32  2:30x30              KGSP Slice           sl | RESULT float32  3:1x30x30            IGHH Softmax         so
051 - | RESULT bool     2:30x30              HLZC Equal           eq |
052 ~ | RESULT float32  3:1x30x30            ???? Where           ma | RESULT float32  3:1x30x16            IZBB MatMul          ma
053 ~ | RESULT float32  3:1x30x30            IGHH Softmax         so | RESULT float32  3:1x30x32            JAAB Concat          ca
054 ~ | RESULT float32  3:1x30x16            IZBB MatMul          ma | RESULT float32  3:1x30x16            AACB MatMul          _o
055 ~ | RESULT float32  3:1x30x32            JAAB Concat          ca | RESULT float32  3:1x30x16            WVZY Add             li
056 ~ | RESULT float32  3:1x30x16            AACB MatMul          _o | RESULT float32  3:1x30x16            CYDX SkipLayerNormal _o
057 ~ | RESULT float32  3:1x30x16            WVZY Add             li | RESULT float32  3:1x30x1             ZABA SkipLayerNormal un
058 ~ | RESULT float32  3:1x30x16            XUCS Add             ad | RESULT float32  3:1x30x1             HFFE SkipLayerNormal un
059 ~ | RESULT float32  3:1x30x16            CYDX LayerNormalizat _o | RESULT float32  3:1x30x16            XUCS SkipLayerNormal ad
060 = | RESULT float32  3:1x30x128           UZFK MatMul          _o | RESULT float32  3:1x30x128           UZFK MatMul          _o
061 = | RESULT float32  3:1x30x128           CEMP Add             li | RESULT float32  3:1x30x128           CEMP Add             li
062 = | RESULT float32  3:1x30x128           GDME Relu            re | RESULT float32  3:1x30x128           GDME Relu            re
063 = | RESULT float32  3:1x30x16            DFDG MatMul          _o | RESULT float32  3:1x30x16            DFDG MatMul          _o
064 = | RESULT float32  3:1x30x16            FGFI Add             li | RESULT float32  3:1x30x16            FGFI Add             li
065 = | RESULT float32  3:1x30x16            CAHA Add             ou | RESULT float32  3:1x30x16            CAHA Add             ou
066 = | OUTPUT float32  3:1x30x16            CAHA                 ou | OUTPUT float32  3:1x30x16            CAHA                 ou
</pre></div>
</div>
<p>The conversion should handle dynamic shapes as well as the input sequence
can be of any length. But thats a topic for another example.</p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (0 minutes 1.917 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-recipes-plot-exporter-recipes-c-modules-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/cb5ea34f3427dcee1ab63090ed6a2e2b/plot_exporter_recipes_c_modules.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_exporter_recipes_c_modules.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/ef2c9223bf91adc2ae05ba5115daa19e/plot_exporter_recipes_c_modules.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_exporter_recipes_c_modules.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../_downloads/4a095e9b122b9cb32142c72045f9a49c/plot_exporter_recipes_c_modules.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">plot_exporter_recipes_c_modules.zip</span></code></a></p>
</div>
</div>
<p class="rubric">Related examples</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="torch.export.export often breaks on big models because there are control flows or instructions breaking the propagation of dynamic shapes (see ...). The function usually gives an indication where the model implementation can be fixed but in case, that is not possible, we can try to export the model piece by piece: every module is converted separately from its submodule. A model can be exported even if one of its submodules cannot."><img alt="" src="../_images/sphx_glr_plot_exporter_exporter_phi35_piece_thumb.png" />
<p><a class="reference internal" href="plot_exporter_exporter_phi35_piece.html#sphx-glr-auto-recipes-plot-exporter-exporter-phi35-piece-py"><span class="std std-ref">Export Phi-3.5-mini-instruct piece by piece</span></a></p>
  <div class="sphx-glr-thumbnail-title">Export Phi-3.5-mini-instruct piece by piece</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to convert a custom operator as defined in the tutorial Python Custom Operators."><img alt="" src="../_images/sphx_glr_plot_exporter_recipes_c_custom_ops_inplace_thumb.png" />
<p><a class="reference internal" href="plot_exporter_recipes_c_custom_ops_inplace.html#sphx-glr-auto-recipes-plot-exporter-recipes-c-custom-ops-inplace-py"><span class="std std-ref">to_onnx and a custom operator inplace</span></a></p>
  <div class="sphx-glr-thumbnail-title">to_onnx and a custom operator inplace</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This is a frequent task which does not play well with dynamic shapes. Let&#x27;s see how to avoid using torch.cond."><img alt="" src="../_images/sphx_glr_plot_exporter_recipes_c_dynpad_thumb.png" />
<p><a class="reference internal" href="plot_exporter_recipes_c_dynpad.html#sphx-glr-auto-recipes-plot-exporter-recipes-c-dynpad-py"><span class="std std-ref">to_onnx and padding one dimension to a mulitple of a constant</span></a></p>
  <div class="sphx-glr-thumbnail-title">to_onnx and padding one dimension to a mulitple of a constant</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Every conversion task must be tested on a large scale. One huge source of model is HuggingFace. We focus on the model Tiny-LLM. To avoid downloading any weigths, we write a function creating a random model based on the same architecture."><img alt="" src="../_images/sphx_glr_plot_exporter_exporter_untrained_tinyllm_thumb.png" />
<p><a class="reference internal" href="plot_exporter_exporter_untrained_tinyllm.html#sphx-glr-auto-recipes-plot-exporter-exporter-untrained-tinyllm-py"><span class="std std-ref">Check the exporter on a dummy from HuggingFace</span></a></p>
  <div class="sphx-glr-thumbnail-title">Check the exporter on a dummy from HuggingFace</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to convert a custom operator, inspired from Python Custom Operators."><img alt="" src="../_images/sphx_glr_plot_exporter_recipes_c_custom_ops_fct_thumb.png" />
<p><a class="reference internal" href="plot_exporter_recipes_c_custom_ops_fct.html#sphx-glr-auto-recipes-plot-exporter-recipes-c-custom-ops-fct-py"><span class="std std-ref">to_onnx and a custom operator registered with a function</span></a></p>
  <div class="sphx-glr-thumbnail-title">to_onnx and a custom operator registered with a function</div>
</div></div><p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="../command_lines.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Command Lines</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="plot_exporter_recipes_c_dynpad.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">to_onnx and padding one dimension to a mulitple of a constant</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2023-2024
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">to_onnx and submodules from LLMs</a><ul>
<li><a class="reference internal" href="#a-simple-llm">A simple LLM</a></li>
<li><a class="reference internal" href="#first-conversion-to-onnx">First conversion to ONNX</a></li>
<li><a class="reference internal" href="#onnx-with-submodules">ONNX with submodules</a></li>
<li><a class="reference internal" href="#inlining">Inlining</a></li>
<li><a class="reference internal" href="#optimizations">Optimizations</a></li>
<li><a class="reference internal" href="#optimizations-for-cuda">Optimizations for CUDA</a></li>
<li><a class="reference internal" href="#comparison-optimized-and-not-optimized">Comparison optimized and not optimized?</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../_static/documentation_options.js?v=1a9ffd16"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/furo.js?v=46bd48cc"></script>
    </body>
</html>