<!doctype html>
<html class="no-js" lang="en" data-content_root="">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="Change Logs" href="../CHANGELOGS.html" /><link rel="prev" title="Example gallery" href="index.html" />

    <!-- Generated with Sphinx 7.1.2 and Furo 2023.09.10 -->
        <title>Evaluate different ways to export a torch model to ONNX - experimental-experiment 0.1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=135e06be" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css?v=7f9a90b1" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css?v=eafc0fe6" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=61a4c737" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=36a5483c" />
    
    


<style>
  body {
    --color-code-background: #eeffcc;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">experimental-experiment 0.1.0 documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="../_static/logo.png" alt="Logo"/>
  </div>
  
  <span class="sidebar-brand-text">experimental-experiment 0.1.0 documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Contents</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../tutorial/index.html">Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/index.html">API</a></li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="index.html">Example gallery</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of Example gallery</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2 current current-page"><a class="current reference internal" href="#">Evaluate different ways to export a torch model to ONNX</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">More</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../CHANGELOGS.html">Change Logs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-auto-examples-plot-torch-export-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code</p>
</div>
<section class="sphx-glr-example-title" id="evaluate-different-ways-to-export-a-torch-model-to-onnx">
<span id="sphx-glr-auto-examples-plot-torch-export-py"></span><h1>Evaluate different ways to export a torch model to ONNX<a class="headerlink" href="#evaluate-different-ways-to-export-a-torch-model-to-onnx" title="Permalink to this heading">#</a></h1>
<p>The example evaluates the performance of onnxruntime of a simple
torch model after it was converted into ONNX through different processes:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://pytorch.org/docs/stable/onnx.html#torchscript-based-onnx-exporter">TorchScript-based ONNX Exporter</a>,
let’s call it <strong>script</strong></p></li>
<li><p><a class="reference external" href="https://pytorch.org/docs/stable/onnx.html#torchdynamo-based-onnx-exporter">TorchDynamo-based ONNX Exporter</a>,
let’s call it <strong>dynamo</strong></p></li>
<li><p>if available, the previous model but optimized, <strong>dynopt</strong></p></li>
<li><p>a custom exporter <strong>cus_p0</strong>, this exporter supports a very limited
set of models, as <strong>dynamo</strong>, it relies on
<a class="reference external" href="https://pytorch.org/docs/stable/fx.html">torch.fx</a> but the design is closer to
what tensorflow-onnx does.</p></li>
<li><p>the same exporter but unused nodes were removed, <strong>cus_p1</strong></p></li>
<li><p>the same exporter but constant where folded, <strong>cus_p2</strong></p></li>
</ul>
<section id="some-helpers">
<h2>Some helpers<a class="headerlink" href="#some-helpers" title="Permalink to this heading">#</a></h2>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">platform</span>
<span class="kn">import</span> <span class="nn">pprint</span>
<span class="kn">import</span> <span class="nn">multiprocessing</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">cProfile</span>
<span class="kn">import</span> <span class="nn">pstats</span>
<span class="kn">import</span> <span class="nn">io</span>
<span class="kn">from</span> <span class="nn">pstats</span> <span class="kn">import</span> <span class="n">SortKey</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">pandas</span>
<span class="kn">import</span> <span class="nn">onnx</span>
<span class="kn">from</span> <span class="nn">onnx_extended.ext_test_case</span> <span class="kn">import</span> <span class="n">measure_time</span>
<span class="kn">from</span> <span class="nn">onnx_array_api.plotting.text_plot</span> <span class="kn">import</span> <span class="n">onnx_simple_text_plot</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">experimental_experiment</span>
<span class="kn">from</span> <span class="nn">experimental_experiment.torch_exp.onnx_export</span> <span class="kn">import</span> <span class="n">to_onnx</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>


<span class="k">def</span> <span class="nf">system_info</span><span class="p">():</span>
    <span class="n">obs</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">obs</span><span class="p">[</span><span class="s2">&quot;processor&quot;</span><span class="p">]</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/platform.html#platform.processor" title="platform.processor" class="sphx-glr-backref-module-platform sphx-glr-backref-type-py-function"><span class="n">platform</span><span class="o">.</span><span class="n">processor</span></a><span class="p">()</span>
    <span class="n">obs</span><span class="p">[</span><span class="s2">&quot;cores&quot;</span><span class="p">]</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/multiprocessing.html#multiprocessing.cpu_count" title="multiprocessing.cpu_count" class="sphx-glr-backref-module-multiprocessing sphx-glr-backref-type-py-function"><span class="n">multiprocessing</span><span class="o">.</span><span class="n">cpu_count</span></a><span class="p">()</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">obs</span><span class="p">[</span><span class="s2">&quot;cuda&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <a href="https://pytorch.org/docs/stable/generated/torch.cuda.is_available.html#torch.cuda.is_available" title="torch.cuda.is_available" class="sphx-glr-backref-module-torch-cuda sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span></a><span class="p">()</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="n">obs</span><span class="p">[</span><span class="s2">&quot;cuda_count&quot;</span><span class="p">]</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.cuda.device_count.html#torch.cuda.device_count" title="torch.cuda.device_count" class="sphx-glr-backref-module-torch-cuda sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span></a><span class="p">()</span>
        <span class="n">obs</span><span class="p">[</span><span class="s2">&quot;cuda_name&quot;</span><span class="p">]</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.cuda.get_device_name.html#torch.cuda.get_device_name" title="torch.cuda.get_device_name" class="sphx-glr-backref-module-torch-cuda sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_name</span></a><span class="p">()</span>
        <span class="n">obs</span><span class="p">[</span><span class="s2">&quot;cuda_capa&quot;</span><span class="p">]</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.cuda.get_device_capability.html#torch.cuda.get_device_capability" title="torch.cuda.get_device_capability" class="sphx-glr-backref-module-torch-cuda sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_capability</span></a><span class="p">()</span>
    <span class="k">except</span> <span class="ne">RuntimeError</span><span class="p">:</span>
        <span class="c1"># no cuda</span>
        <span class="k">pass</span>
    <span class="k">return</span> <span class="n">obs</span>


<a href="https://docs.python.org/3/library/pprint.html#pprint.pprint" title="pprint.pprint" class="sphx-glr-backref-module-pprint sphx-glr-backref-type-py-function"><span class="n">pprint</span><span class="o">.</span><span class="n">pprint</span></a><span class="p">(</span><span class="n">system_info</span><span class="p">())</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>{&#39;cores&#39;: 8,
 &#39;cuda&#39;: 1,
 &#39;cuda_capa&#39;: (6, 1),
 &#39;cuda_count&#39;: 1,
 &#39;cuda_name&#39;: &#39;NVIDIA GeForce GTX 1060&#39;,
 &#39;processor&#39;: &#39;x86_64&#39;}
</pre></div>
</div>
</section>
<section id="the-model">
<h2>The model<a class="headerlink" href="#the-model" title="Permalink to this heading">#</a></h2>
<p>A simple model to convert.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MyModel</span><span class="p">(</span><a href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><a href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">MyModel</span></a><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d" title="torch.nn.Conv2d" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span></a><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d" title="torch.nn.Conv2d" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span></a><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">13456</span><span class="p">,</span> <span class="mi">1024</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.nn.functional.max_pool2d.html#torch.nn.functional.max_pool2d" title="torch.nn.functional.max_pool2d" class="sphx-glr-backref-module-torch-nn-functional sphx-glr-backref-type-py-function"><span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span></a><span class="p">(</span><a href="https://pytorch.org/docs/stable/generated/torch.nn.functional.relu.html#torch.nn.functional.relu" title="torch.nn.functional.relu" class="sphx-glr-backref-module-torch-nn-functional sphx-glr-backref-type-py-function"><span class="n">F</span><span class="o">.</span><span class="n">relu</span></a><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.nn.functional.max_pool2d.html#torch.nn.functional.max_pool2d" title="torch.nn.functional.max_pool2d" class="sphx-glr-backref-module-torch-nn-functional sphx-glr-backref-type-py-function"><span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span></a><span class="p">(</span><a href="https://pytorch.org/docs/stable/generated/torch.nn.functional.relu.html#torch.nn.functional.relu" title="torch.nn.functional.relu" class="sphx-glr-backref-module-torch-nn-functional sphx-glr-backref-type-py-function"><span class="n">F</span><span class="o">.</span><span class="n">relu</span></a><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)),</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.flatten.html#torch.flatten" title="torch.flatten" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">flatten</span></a><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.nn.functional.relu.html#torch.nn.functional.relu" title="torch.nn.functional.relu" class="sphx-glr-backref-module-torch-nn-functional sphx-glr-backref-type-py-function"><span class="n">F</span><span class="o">.</span><span class="n">relu</span></a><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.nn.functional.relu.html#torch.nn.functional.relu" title="torch.nn.functional.relu" class="sphx-glr-backref-module-torch-nn-functional sphx-glr-backref-type-py-function"><span class="n">F</span><span class="o">.</span><span class="n">relu</span></a><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</section>
<section id="the-exporters">
<h2>The exporters<a class="headerlink" href="#the-exporters" title="Permalink to this heading">#</a></h2>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">export_script</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">filename</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
    <a href="https://pytorch.org/docs/stable/onnx_torchscript.html#torch.onnx.export" title="torch.onnx.export" class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">export</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">filename</span></a><span class="p">,</span> <span class="n">input_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;input&quot;</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">export_dynamo</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">filename</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
    <span class="n">export_output</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.dynamo_export" title="torch.onnx.dynamo_export" class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">dynamo_export</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span>
    <span class="n">export_output</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">filename</span></a><span class="p">)</span>


<span class="k">def</span> <span class="nf">export_dynopt</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">filename</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
    <span class="n">export_output</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.dynamo_export" title="torch.onnx.dynamo_export" class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">dynamo_export</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span>
    <span class="n">export_output</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">filename</span></a><span class="p">)</span>
    <span class="n">model_onnx</span> <span class="o">=</span> <a href="https://onnx.ai/onnx/api/serialization.html#onnx.load" title="onnx.load" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-function"><span class="n">onnx</span><span class="o">.</span><span class="n">load</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">filename</span></a><span class="p">)</span>

    <span class="kn">from</span> <span class="nn">onnxrewriter.optimizer</span> <span class="kn">import</span> <span class="n">optimize</span>

    <span class="n">optimized_model</span> <span class="o">=</span> <span class="n">optimize</span><span class="p">(</span><span class="n">model_onnx</span><span class="p">)</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">filename</span></a><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">optimized_model</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">())</span>


<span class="k">def</span> <span class="nf">export_cus_p0</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">filename</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
    <a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx</span></a> <span class="o">=</span> <span class="n">to_onnx</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a><span class="p">,</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">args</span><span class="p">),</span> <span class="n">input_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;input&quot;</span><span class="p">])</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">filename</span></a><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx</span></a><span class="o">.</span><span class="n">SerializeToString</span><span class="p">())</span>


<span class="k">def</span> <span class="nf">export_cus_p1</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">filename</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
    <a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx</span></a> <span class="o">=</span> <span class="n">to_onnx</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a><span class="p">,</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">args</span><span class="p">),</span> <span class="n">input_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;input&quot;</span><span class="p">],</span> <span class="n">remove_unused</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">filename</span></a><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx</span></a><span class="o">.</span><span class="n">SerializeToString</span><span class="p">())</span>


<span class="k">def</span> <span class="nf">export_cus_p2</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">filename</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
    <a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx</span></a> <span class="o">=</span> <span class="n">to_onnx</span><span class="p">(</span>
        <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a><span class="p">,</span>
        <span class="nb">tuple</span><span class="p">(</span><span class="n">args</span><span class="p">),</span>
        <span class="n">input_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;input&quot;</span><span class="p">],</span>
        <span class="n">remove_unused</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">constant_folding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">filename</span></a><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx</span></a><span class="o">.</span><span class="n">SerializeToString</span><span class="p">())</span>
</pre></div>
</div>
<p>Let’s check they are working.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">export_functions</span></a> <span class="o">=</span> <span class="p">[</span>
    <span class="n">export_script</span><span class="p">,</span>
    <span class="n">export_dynamo</span><span class="p">,</span>
    <span class="n">export_dynopt</span><span class="p">,</span>
    <span class="n">export_cus_p0</span><span class="p">,</span>
    <span class="n">export_cus_p1</span><span class="p">,</span>
    <span class="n">export_cus_p2</span><span class="p">,</span>
<span class="p">]</span>

<a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">exporters</span></a> <span class="o">=</span> <span class="p">{</span><span class="n">f</span><span class="o">.</span><span class="vm">__name__</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;export_&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">):</span> <span class="n">f</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">export_functions</span></a><span class="p">}</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">shape</span></a> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">]</span>
<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_tensor</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.rand.html#torch.rand" title="torch.rand" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">rand</span></a><span class="p">(</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">shape</span></a><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><a href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch</span><span class="o">.</span><span class="n">float32</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">MyModel</span></a><span class="p">()</span>

<a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">supported_exporters</span></a> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">k</span></a><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">exporters</span></a><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;run exporter </span><span class="si">{</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">k</span></a><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">filename</span></a> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;plot_torch_export_</span><span class="si">{</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">k</span></a><span class="si">}</span><span class="s2">.onnx&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">v</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">filename</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a><span class="p">,</span> <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_tensor</span></a><span class="p">)</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;skipped due to </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">continue</span>
    <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">supported_exporters</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">k</span></a><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;done.&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>run exporter script
[2023-12-05 14:03:15,850] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
done.
run exporter dynamo
/home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/exporter.py:130: UserWarning: torch.onnx.dynamo_export only implements opset version 18 for now. If you need to use a different opset version, please register them with register_custom_op.
  warnings.warn(
done.
run exporter dynopt
/home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/exporter.py:130: UserWarning: torch.onnx.dynamo_export only implements opset version 18 for now. If you need to use a different opset version, please register them with register_custom_op.
  warnings.warn(
WARNING:onnxrewriter.optimizer.constant_folding:Skip storing constant folded nvalue result_1 due to large size 55115776.
WARNING:onnxrewriter.optimizer.constant_folding:Skip storing constant folded nvalue t due to large size 55115776.
WARNING:onnxrewriter.optimizer.constant_folding:Skip storing constant folded nvalue result_1 due to large size 55115776.
WARNING:onnxrewriter.optimizer.constant_folding:Skip storing constant folded nvalue t due to large size 55115776.
done.
run exporter cus_p0
done.
run exporter cus_p1
done.
run exporter cus_p2
done.
</pre></div>
</div>
</section>
<section id="exporter-speed">
<h2>Exporter speed<a class="headerlink" href="#exporter-speed" title="Permalink to this heading">#</a></h2>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data</span></a> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">k</span></a><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">supported_exporters</span></a><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;run exporter </span><span class="si">{</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">k</span></a><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">filename</span></a> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;plot_torch_export_</span><span class="si">{</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">k</span></a><span class="si">}</span><span class="s2">.onnx&quot;</span>
    <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">times</span></a> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i</span></a> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
        <a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">begin</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/time.html#time.perf_counter" title="time.perf_counter" class="sphx-glr-backref-module-time sphx-glr-backref-type-py-function"><span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span></a><span class="p">()</span>
        <span class="n">v</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">filename</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a><span class="p">,</span> <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_tensor</span></a><span class="p">)</span>
        <a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">duration</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/time.html#time.perf_counter" title="time.perf_counter" class="sphx-glr-backref-module-time sphx-glr-backref-type-py-function"><span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span></a><span class="p">()</span> <span class="o">-</span> <a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">begin</span></a>
        <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">times</span></a><span class="o">.</span><span class="n">append</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">duration</span></a><span class="p">)</span>
    <a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx</span></a> <span class="o">=</span> <a href="https://onnx.ai/onnx/api/serialization.html#onnx.load" title="onnx.load" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-function"><span class="n">onnx</span><span class="o">.</span><span class="n">load</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">filename</span></a><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;done.&quot;</span><span class="p">)</span>
    <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data</span></a><span class="o">.</span><span class="n">append</span><span class="p">(</span>
        <span class="nb">dict</span><span class="p">(</span>
            <span class="n">export</span><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">k</span></a><span class="p">,</span>
            <span class="n">time</span><span class="o">=</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.mean.html#numpy.mean" title="numpy.mean" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">mean</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">duration</span></a><span class="p">),</span>
            <span class="nb">min</span><span class="o">=</span><span class="nb">min</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">times</span></a><span class="p">),</span>
            <span class="nb">max</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">times</span></a><span class="p">),</span>
            <span class="n">first</span><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">times</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="n">last</span><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">times</span></a><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
            <span class="n">std</span><span class="o">=</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.std.html#numpy.std" title="numpy.std" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">std</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">times</span></a><span class="p">),</span>
            <span class="n">nodes</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx</span></a><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="p">),</span>
        <span class="p">)</span>
    <span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>run exporter script
done.
run exporter dynamo
/home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/exporter.py:130: UserWarning: torch.onnx.dynamo_export only implements opset version 18 for now. If you need to use a different opset version, please register them with register_custom_op.
  warnings.warn(
/home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/exporter.py:130: UserWarning: torch.onnx.dynamo_export only implements opset version 18 for now. If you need to use a different opset version, please register them with register_custom_op.
  warnings.warn(
/home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/exporter.py:130: UserWarning: torch.onnx.dynamo_export only implements opset version 18 for now. If you need to use a different opset version, please register them with register_custom_op.
  warnings.warn(
/home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/exporter.py:130: UserWarning: torch.onnx.dynamo_export only implements opset version 18 for now. If you need to use a different opset version, please register them with register_custom_op.
  warnings.warn(
/home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/exporter.py:130: UserWarning: torch.onnx.dynamo_export only implements opset version 18 for now. If you need to use a different opset version, please register them with register_custom_op.
  warnings.warn(
done.
run exporter dynopt
/home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/exporter.py:130: UserWarning: torch.onnx.dynamo_export only implements opset version 18 for now. If you need to use a different opset version, please register them with register_custom_op.
  warnings.warn(
WARNING:onnxrewriter.optimizer.constant_folding:Skip storing constant folded nvalue result_1 due to large size 55115776.
WARNING:onnxrewriter.optimizer.constant_folding:Skip storing constant folded nvalue t due to large size 55115776.
WARNING:onnxrewriter.optimizer.constant_folding:Skip storing constant folded nvalue result_1 due to large size 55115776.
WARNING:onnxrewriter.optimizer.constant_folding:Skip storing constant folded nvalue t due to large size 55115776.
/home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/exporter.py:130: UserWarning: torch.onnx.dynamo_export only implements opset version 18 for now. If you need to use a different opset version, please register them with register_custom_op.
  warnings.warn(
WARNING:onnxrewriter.optimizer.constant_folding:Skip storing constant folded nvalue result_1 due to large size 55115776.
WARNING:onnxrewriter.optimizer.constant_folding:Skip storing constant folded nvalue t due to large size 55115776.
WARNING:onnxrewriter.optimizer.constant_folding:Skip storing constant folded nvalue result_1 due to large size 55115776.
WARNING:onnxrewriter.optimizer.constant_folding:Skip storing constant folded nvalue t due to large size 55115776.
/home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/exporter.py:130: UserWarning: torch.onnx.dynamo_export only implements opset version 18 for now. If you need to use a different opset version, please register them with register_custom_op.
  warnings.warn(
WARNING:onnxrewriter.optimizer.constant_folding:Skip storing constant folded nvalue result_1 due to large size 55115776.
WARNING:onnxrewriter.optimizer.constant_folding:Skip storing constant folded nvalue t due to large size 55115776.
WARNING:onnxrewriter.optimizer.constant_folding:Skip storing constant folded nvalue result_1 due to large size 55115776.
WARNING:onnxrewriter.optimizer.constant_folding:Skip storing constant folded nvalue t due to large size 55115776.
/home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/exporter.py:130: UserWarning: torch.onnx.dynamo_export only implements opset version 18 for now. If you need to use a different opset version, please register them with register_custom_op.
  warnings.warn(
WARNING:onnxrewriter.optimizer.constant_folding:Skip storing constant folded nvalue result_1 due to large size 55115776.
WARNING:onnxrewriter.optimizer.constant_folding:Skip storing constant folded nvalue t due to large size 55115776.
WARNING:onnxrewriter.optimizer.constant_folding:Skip storing constant folded nvalue result_1 due to large size 55115776.
WARNING:onnxrewriter.optimizer.constant_folding:Skip storing constant folded nvalue t due to large size 55115776.
/home/xadupre/.local/lib/python3.10/site-packages/torch/onnx/_internal/exporter.py:130: UserWarning: torch.onnx.dynamo_export only implements opset version 18 for now. If you need to use a different opset version, please register them with register_custom_op.
  warnings.warn(
WARNING:onnxrewriter.optimizer.constant_folding:Skip storing constant folded nvalue result_1 due to large size 55115776.
WARNING:onnxrewriter.optimizer.constant_folding:Skip storing constant folded nvalue t due to large size 55115776.
WARNING:onnxrewriter.optimizer.constant_folding:Skip storing constant folded nvalue result_1 due to large size 55115776.
WARNING:onnxrewriter.optimizer.constant_folding:Skip storing constant folded nvalue t due to large size 55115776.
done.
run exporter cus_p0
done.
run exporter cus_p1
done.
run exporter cus_p2
done.
</pre></div>
</div>
<p>The last export to measure time torch spends in export the model
before any other export can begin the translation
except the first one.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">begin</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/time.html#time.perf_counter" title="time.perf_counter" class="sphx-glr-backref-module-time sphx-glr-backref-type-py-function"><span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span></a><span class="p">()</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i</span></a> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <a href="https://pytorch.org/docs/stable/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">exported_mod</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/export.html#torch.export.export" title="torch.export.export" class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">export</span><span class="o">.</span><span class="n">export</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a><span class="p">,</span> <span class="p">(</span><a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_tensor</span></a><span class="p">,))</span>
<a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">duration</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/time.html#time.perf_counter" title="time.perf_counter" class="sphx-glr-backref-module-time sphx-glr-backref-type-py-function"><span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span></a><span class="p">()</span> <span class="o">-</span> <a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">begin</span></a>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data</span></a><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">export</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">time</span><span class="o">=</span><a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">duration</span></a> <span class="o">/</span> <span class="mi">5</span><span class="p">))</span>
</pre></div>
</div>
<p>The result.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df1</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class"><span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data</span></a><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df1</span></a><span class="p">)</span>

<a href="https://matplotlib.org/stable/api/figure_api.html#matplotlib.figure.Figure" title="matplotlib.figure.Figure" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fig</span></a><span class="p">,</span> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.html#matplotlib.axes.Axes" title="matplotlib.axes.Axes" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span></a> <span class="o">=</span> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="matplotlib.pyplot.subplots" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dfi</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df1</span></a><span class="p">[[</span><span class="s2">&quot;export&quot;</span><span class="p">,</span> <span class="s2">&quot;time&quot;</span><span class="p">,</span> <span class="s2">&quot;std&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s2">&quot;export&quot;</span><span class="p">)</span>
<a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dfi</span></a><span class="p">[</span><span class="s2">&quot;time&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.html#matplotlib.axes.Axes" title="matplotlib.axes.Axes" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span></a><span class="o">=</span><a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.html#matplotlib.axes.Axes" title="matplotlib.axes.Axes" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span></a><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Export time&quot;</span><span class="p">,</span> <span class="n">yerr</span><span class="o">=</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dfi</span></a><span class="p">[</span><span class="s2">&quot;std&quot;</span><span class="p">])</span>
<a href="https://matplotlib.org/stable/api/figure_api.html#matplotlib.figure.Figure.tight_layout" title="matplotlib.figure.Figure.tight_layout" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-method"><span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span></a><span class="p">()</span>
<a href="https://matplotlib.org/stable/api/figure_api.html#matplotlib.figure.Figure.savefig" title="matplotlib.figure.Figure.savefig" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-method"><span class="n">fig</span><span class="o">.</span><span class="n">savefig</span></a><span class="p">(</span><span class="s2">&quot;plot_torch_export.png&quot;</span><span class="p">)</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_plot_torch_export_001.png" srcset="../_images/sphx_glr_plot_torch_export_001.png" alt="Export time" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>   export      time       min       max     first      last       std  nodes
0  script  0.195931  0.183295  0.257570  0.210905  0.195931  0.025777   12.0
1  dynamo  0.625513  0.488551  0.786897  0.656923  0.625513  0.109937   13.0
2  dynopt  0.858001  0.814010  0.936153  0.885437  0.858001  0.039646   13.0
3  cus_p0  0.460740  0.360371  0.460740  0.360371  0.460740  0.037929   27.0
4  cus_p1  0.350459  0.350459  0.452602  0.362487  0.350459  0.039809   15.0
5  cus_p2  0.459033  0.396157  0.486254  0.416429  0.459033  0.032243   12.0
6   torch  0.214853       NaN       NaN       NaN       NaN       NaN    NaN
</pre></div>
</div>
</section>
<section id="profiling">
<h2>Profiling<a class="headerlink" href="#profiling" title="Permalink to this heading">#</a></h2>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">pr</span> <span class="o">=</span> <span class="n">cProfile</span><span class="o">.</span><span class="n">Profile</span><span class="p">()</span>
<span class="n">pr</span><span class="o">.</span><span class="n">enable</span><span class="p">()</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i</span></a> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">export_cus_p0</span><span class="p">(</span><span class="s2">&quot;dummy.onnx&quot;</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a><span class="p">,</span> <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_tensor</span></a><span class="p">)</span>
<span class="n">pr</span><span class="o">.</span><span class="n">disable</span><span class="p">()</span>
<a href="https://docs.python.org/3/library/io.html#io.StringIO" title="io.StringIO" class="sphx-glr-backref-module-io sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">s</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/io.html#io.StringIO" title="io.StringIO" class="sphx-glr-backref-module-io sphx-glr-backref-type-py-class"><span class="n">io</span><span class="o">.</span><span class="n">StringIO</span></a><span class="p">()</span>
<span class="n">sortby</span> <span class="o">=</span> <span class="n">SortKey</span><span class="o">.</span><span class="n">CUMULATIVE</span>
<a href="https://docs.python.org/3/library/profile.html#pstats.Stats" title="pstats.Stats" class="sphx-glr-backref-module-pstats sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ps</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/profile.html#pstats.Stats" title="pstats.Stats" class="sphx-glr-backref-module-pstats sphx-glr-backref-type-py-class"><span class="n">pstats</span><span class="o">.</span><span class="n">Stats</span></a><span class="p">(</span><span class="n">pr</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><a href="https://docs.python.org/3/library/io.html#io.StringIO" title="io.StringIO" class="sphx-glr-backref-module-io sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">s</span></a><span class="p">)</span><span class="o">.</span><span class="n">sort_stats</span><span class="p">(</span><span class="n">sortby</span><span class="p">)</span>
<a href="https://docs.python.org/3/library/profile.html#pstats.Stats.print_stats" title="pstats.Stats.print_stats" class="sphx-glr-backref-module-pstats sphx-glr-backref-type-py-method"><span class="n">ps</span><span class="o">.</span><span class="n">print_stats</span></a><span class="p">()</span>


<span class="k">def</span> <span class="nf">clean_text</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">text</span></a><span class="p">):</span>
    <span class="n">pathes</span> <span class="o">=</span> <span class="p">[</span>
        <a href="https://docs.python.org/3/library/os.path.html#os.path.abspath" title="os.path.abspath" class="sphx-glr-backref-module-os-path sphx-glr-backref-type-py-function"><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span></a><span class="p">(</span>
            <a href="https://docs.python.org/3/library/os.path.html#os.path.normpath" title="os.path.normpath" class="sphx-glr-backref-module-os-path sphx-glr-backref-type-py-function"><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">normpath</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/os.path.html#os.path.join" title="os.path.join" class="sphx-glr-backref-module-os-path sphx-glr-backref-type-py-function"><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/os.path.html#os.path.dirname" title="os.path.dirname" class="sphx-glr-backref-module-os-path sphx-glr-backref-type-py-function"><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span></a><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="vm">__file__</span><span class="p">),</span> <span class="s2">&quot;..&quot;</span><span class="p">))</span>
        <span class="p">),</span>
        <a href="https://docs.python.org/3/library/os.path.html#os.path.abspath" title="os.path.abspath" class="sphx-glr-backref-module-os-path sphx-glr-backref-type-py-function"><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span></a><span class="p">(</span>
            <a href="https://docs.python.org/3/library/os.path.html#os.path.normpath" title="os.path.normpath" class="sphx-glr-backref-module-os-path sphx-glr-backref-type-py-function"><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">normpath</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/os.path.html#os.path.join" title="os.path.join" class="sphx-glr-backref-module-os-path sphx-glr-backref-type-py-function"><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/os.path.html#os.path.dirname" title="os.path.dirname" class="sphx-glr-backref-module-os-path sphx-glr-backref-type-py-function"><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span></a><span class="p">(</span><span class="n">onnx</span><span class="o">.</span><span class="vm">__file__</span><span class="p">),</span> <span class="s2">&quot;..&quot;</span><span class="p">))</span>
        <span class="p">),</span>
        <a href="https://docs.python.org/3/library/os.path.html#os.path.abspath" title="os.path.abspath" class="sphx-glr-backref-module-os-path sphx-glr-backref-type-py-function"><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span></a><span class="p">(</span>
            <a href="https://docs.python.org/3/library/os.path.html#os.path.normpath" title="os.path.normpath" class="sphx-glr-backref-module-os-path sphx-glr-backref-type-py-function"><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">normpath</span></a><span class="p">(</span>
                <a href="https://docs.python.org/3/library/os.path.html#os.path.join" title="os.path.join" class="sphx-glr-backref-module-os-path sphx-glr-backref-type-py-function"><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/os.path.html#os.path.dirname" title="os.path.dirname" class="sphx-glr-backref-module-os-path sphx-glr-backref-type-py-function"><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span></a><span class="p">(</span><span class="n">experimental_experiment</span><span class="o">.</span><span class="vm">__file__</span><span class="p">),</span> <span class="s2">&quot;..&quot;</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="p">),</span>
    <span class="p">]</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">pathes</span><span class="p">:</span>
        <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">text</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">text</span></a><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
    <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">text</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">text</span></a><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;experimental_experiment&quot;</span><span class="p">,</span> <span class="s2">&quot;experimental_experiment&quot;</span><span class="o">.</span><span class="n">upper</span><span class="p">())</span>
    <span class="k">return</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">text</span></a>


<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">text</span></a> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><a href="https://docs.python.org/3/library/io.html#io.StringIO" title="io.StringIO" class="sphx-glr-backref-module-io sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">s</span></a><span class="o">.</span><span class="n">getvalue</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)[:</span><span class="mi">200</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">clean_text</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">text</span></a><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>         1782086 function calls (1681746 primitive calls) in 4.993 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        5    0.002    0.000    5.138    1.028 /_doc/examples/plot_torch_export.py:119(export_cus_p0)
        5    0.003    0.001    4.799    0.960 /EXPERIMENTAL_EXPERIMENT/torch_exp/onnx_export.py:8(to_onnx)
        5    0.000    0.000    3.930    0.786 /torch/export/__init__.py:930(export)
        5    0.002    0.000    3.930    0.786 /torch/_export/__init__.py:212(export)
    15/10    0.001    0.000    2.819    0.282 /torch/_dynamo/utils.py:182(time_wrapper)
    20/10    0.000    0.000    2.732    0.273 /torch/_dynamo/eval_frame.py:307(_fn)
3520/1655    0.012    0.000    2.595    0.002 /torch/utils/_stats.py:15(wrapper)
   115/55    0.001    0.000    2.482    0.045 /torch/nn/modules/module.py:1514(_wrapped_call_impl)
   115/55    0.001    0.000    2.482    0.045 /torch/nn/modules/module.py:1520(_call_impl)
2910/1810    0.018    0.000    2.121    0.001 /torch/_subclasses/fake_tensor.py:1246(__torch_dispatch__)
2910/1810    0.137    0.000    2.088    0.001 /torch/_subclasses/fake_tensor.py:1270(dispatch)
        5    0.001    0.000    1.692    0.338 /torch/_dynamo/eval_frame.py:1028(inner)
       20    0.004    0.000    1.691    0.085 /torch/fx/interpreter.py:99(run)
      355    0.004    0.000    1.670    0.005 /torch/fx/interpreter.py:177(run_node)
        5    0.000    0.000    1.590    0.318 /torch/_functorch/aot_autograd.py:3914(aot_export_module)
        5    0.000    0.000    1.586    0.317 /torch/_functorch/aot_autograd.py:4164(_aot_export_function)
        5    0.001    0.000    1.583    0.317 /torch/_functorch/aot_autograd.py:3277(create_aot_dispatcher_function)
    15/10    0.000    0.000    1.491    0.149 /torch/_dynamo/external_utils.py:15(inner)
       10    0.000    0.000    1.243    0.124 /torch/_functorch/aot_autograd.py:3519(flat_fn)
       10    0.001    0.000    1.241    0.124 /torch/_functorch/aot_autograd.py:3486(functional_call)
        5    0.000    0.000    1.240    0.248 /torch/_dynamo/eval_frame.py:456(catch_errors)
        5    0.000    0.000    1.240    0.248 /torch/_dynamo/convert_frame.py:122(_fn)
        5    0.000    0.000    1.237    0.247 /torch/_dynamo/convert_frame.py:249(_convert_frame_assert)
        5    0.000    0.000    1.236    0.247 /torch/_dynamo/convert_frame.py:414(_compile)
        5    0.000    0.000    1.234    0.247 /torch/_dynamo/convert_frame.py:481(compile_inner)
        5    0.000    0.000    1.160    0.232 /torch/_functorch/aot_autograd.py:2182(aot_wrapper_dedupe)
        5    0.000    0.000    1.160    0.232 /torch/_functorch/aot_autograd.py:2375(aot_wrapper_synthetic_base)
        5    0.000    0.000    1.159    0.232 /torch/_functorch/aot_autograd.py:1518(aot_dispatch_base_graph)
        5    0.000    0.000    1.121    0.224 /torch/_functorch/aot_autograd.py:1349(create_functionalized_graph)
        5    0.000    0.000    1.121    0.224 /torch/fx/experimental/proxy_tensor.py:721(wrapped)
2590/1295    0.007    0.000    1.118    0.001 /torch/_ops.py:447(__call__)
        5    0.000    0.000    1.114    0.223 /torch/_compile.py:20(inner)
        5    0.000    0.000    1.113    0.223 /torch/fx/experimental/proxy_tensor.py:462(dispatch_trace)
45710/11325    0.224    0.000    1.094    0.000 /torch/utils/_pytree.py:230(tree_flatten)
        5    0.000    0.000    1.085    0.217 /torch/fx/_symbolic_trace.py:695(trace)
        5    0.000    0.000    1.058    0.212 /torch/fx/experimental/proxy_tensor.py:477(wrapped)
        5    0.000    0.000    1.046    0.209 /torch/_dynamo/bytecode_transformation.py:1020(transform_code_object)
        5    0.000    0.000    1.038    0.208 /torch/_dynamo/convert_frame.py:439(transform)
        5    0.000    0.000    1.000    0.200 /torch/_dynamo/symbolic_convert.py:2068(run)
        5    0.001    0.000    1.000    0.200 /torch/_dynamo/symbolic_convert.py:712(run)
      265    0.005    0.000    0.998    0.004 /torch/_dynamo/symbolic_convert.py:617(step)
        5    0.000    0.000    0.920    0.184 /torch/_functorch/aot_autograd.py:1411(fwd_helper)
        5    0.000    0.000    0.920    0.184 /torch/_functorch/aot_autograd.py:1357(functionalized_f_helper)
  600/175    0.003    0.000    0.911    0.005 /torch/_prims_common/wrappers.py:221(_fn)
        5    0.000    0.000    0.908    0.182 /torch/_functorch/aot_autograd.py:1164(inner_fn)
       60    0.001    0.000    0.890    0.015 /torch/nn/modules/linear.py:113(forward)
       60    0.013    0.000    0.889    0.015 {built-in method torch._C._nn.linear}
  410/380    0.003    0.000    0.884    0.002 /torch/fx/experimental/proxy_tensor.py:552(__torch_dispatch__)
5660/3350    0.022    0.000    0.879    0.000 /torch/utils/_pytree.py:281(tree_map)
  410/380    0.001    0.000    0.871    0.002 /torch/fx/experimental/proxy_tensor.py:573(inner_torch_dispatch)
       50    0.000    0.000    0.867    0.017 /torch/fx/interpreter.py:291(call_module)
   105/75    0.006    0.000    0.860    0.011 /torch/fx/experimental/proxy_tensor.py:243(proxy_call)
        5    0.000    0.000    0.838    0.168 /EXPERIMENTAL_EXPERIMENT/torch_exp/graph_builder.py:325(to_onnx)
       60    0.000    0.000    0.838    0.014 /torch/_dynamo/symbolic_convert.py:384(wrapper)
       60    0.000    0.000    0.832    0.014 /torch/_dynamo/symbolic_convert.py:1106(CALL_FUNCTION)
       60    0.001    0.000    0.830    0.014 /torch/_dynamo/symbolic_convert.py:537(call_function)
       65    0.000    0.000    0.797    0.012 /torch/_dynamo/variables/builder.py:1190(wrap_fx_proxy)
       65    0.004    0.000    0.796    0.012 /torch/_dynamo/variables/builder.py:1240(wrap_fx_proxy_cls)
       75    0.002    0.000    0.761    0.010 /torch/_decomp/decompositions.py:48(inner)
       60    0.003    0.000    0.711    0.012 /torch/_dynamo/utils.py:1291(get_fake_value)
       90    0.000    0.000    0.699    0.008 /torch/_dynamo/utils.py:914(wrap_fake_exception)
       25    0.000    0.000    0.632    0.025 /torch/fx/_symbolic_trace.py:785(module_call_wrapper)
       25    0.000    0.000    0.630    0.025 /torch/fx/experimental/proxy_tensor.py:422(call_module)
       25    0.000    0.000    0.630    0.025 /torch/fx/_symbolic_trace.py:787(forward)
      155    0.001    0.000    0.621    0.004 /torch/fx/interpreter.py:249(call_function)
       25    0.001    0.000    0.619    0.025 /torch/_dynamo/variables/nn_module.py:243(call_function)
       10    0.000    0.000    0.590    0.059 /torch/export/__init__.py:395(_transform)
5660/3350    0.013    0.000    0.547    0.000 /torch/utils/_pytree.py:283(&lt;listcomp&gt;)
       10    0.000    0.000    0.525    0.052 /torch/fx/passes/infra/pass_manager.py:242(__call__)
       75    0.008    0.000    0.498    0.007 /torch/_decomp/decompositions.py:1222(addmm)
       10    0.000    0.000    0.483    0.048 /torch/fx/passes/infra/pass_base.py:34(__call__)
        5    0.000    0.000    0.482    0.096 /torch/_export/passes/add_runtime_assertions_for_constraints_pass.py:138(call)
        5    0.000    0.000    0.476    0.095 /torch/_export/pass_base.py:400(call)
        5    0.000    0.000    0.475    0.095 /torch/_export/pass_base.py:376(call_submodule)
     4410    0.012    0.000    0.475    0.000 /torch/_subclasses/fake_tensor.py:207(tree_flatten_only)
  310/260    0.010    0.000    0.440    0.002 {method &#39;detach&#39; of &#39;torch._C._TensorBase&#39; objects}
     1920    0.009    0.000    0.440    0.000 /torch/utils/_pytree.py:352(tree_map_only)
       40    0.000    0.000    0.434    0.011 /torch/nn/modules/conv.py:459(forward)
       40    0.000    0.000    0.433    0.011 /torch/nn/modules/conv.py:451(_conv_forward)
      145    0.001    0.000    0.433    0.003 /torch/_export/pass_base.py:230(run_node)
       40    0.007    0.000    0.433    0.011 {built-in method torch.conv2d}
       90    0.002    0.000    0.387    0.004 /torch/_export/pass_base.py:244(_fx)
       85    0.001    0.000    0.387    0.005 /torch/_export/pass_base.py:173(call_function)
        5    0.002    0.000    0.380    0.076 /EXPERIMENTAL_EXPERIMENT/torch_exp/graph_builder.py:305(_build_initializers)
        5    0.001    0.000    0.378    0.076 /torch/_dynamo/eval_frame.py:1075(result_capturing_wrapper)
       50    0.149    0.003    0.378    0.008 /EXPERIMENTAL_EXPERIMENT/torch_exp/graph_builder.py:270(from_array)
       75    0.001    0.000    0.376    0.005 /torch/_export/passes/add_runtime_assertions_for_constraints_pass.py:84(call_operator)
       75    0.000    0.000    0.374    0.005 /torch/_export/pass_base.py:312(call_operator)
    20520    0.258    0.000    0.371    0.000 /torch/utils/_pytree.py:223(__init__)
       60    0.000    0.000    0.368    0.006 /torch/_dynamo/utils.py:1338(&lt;lambda&gt;)
       60    0.000    0.000    0.368    0.006 /torch/_dynamo/utils.py:1379(run_node)
       80    0.000    0.000    0.351    0.004 /torch/nn/functional.py:1460(relu)
       80    0.008    0.000    0.351    0.004 {built-in method torch.relu}
        5    0.001    0.000    0.343    0.069 /torch/_functorch/aot_autograd.py:742(inner)
        5    0.000    0.000    0.343    0.069 /torch/_functorch/functional_call.py:10(functional_call)
        5    0.000    0.000    0.343    0.069 /torch/nn/utils/stateless.py:230(_functional_call)
        5    0.000    0.000    0.340    0.068 /torch/fx/graph_module.py:677(call_wrapped)
        5    0.000    0.000    0.340    0.068 /torch/fx/graph_module.py:269(__call__)
  655/250    0.003    0.000    0.333    0.001 /usr/lib/python3.10/copy.py:259(_reconstruct)
  2405/70    0.012    0.000    0.332    0.005 /usr/lib/python3.10/copy.py:128(deepcopy)
   105/45    0.002    0.000    0.327    0.007 /usr/lib/python3.10/copy.py:227(_deepcopy_dict)
       25    0.000    0.000    0.325    0.013 /torch/_dynamo/utils.py:925(deepcopy_to_fake_tensor)
       25    0.000    0.000    0.324    0.013 /torch/_dynamo/utils.py:927(&lt;lambda&gt;)
     1430    0.004    0.000    0.315    0.000 /torch/_subclasses/fake_tensor.py:1569(validate_and_convert_non_fake_tensors)
       50    0.002    0.000    0.302    0.006 /torch/nn/parameter.py:54(__deepcopy__)
      250    0.002    0.000    0.297    0.001 /torch/_subclasses/fake_tensor.py:1799(__torch_function__)
     1005    0.006    0.000    0.296    0.000 /torch/_subclasses/fake_tensor.py:1604(wrap_meta_outputs_with_default_device_logic)
        5    0.000    0.000    0.292    0.058 /onnx/helper.py:278(make_model)
       15    0.000    0.000    0.292    0.019 /google/protobuf/message.py:118(CopyFrom)
       15    0.291    0.019    0.291    0.019 {method &#39;MergeFrom&#39; of &#39;google._upb._message.Message&#39; objects}
  525/325    0.011    0.000    0.289    0.001 /torch/_prims_common/wrappers.py:110(_fn)
       80    0.000    0.000    0.288    0.004 /torch/fx/experimental/proxy_tensor.py:182(track_tensor_tree)
   155/80    0.001    0.000    0.287    0.004 /torch/fx/experimental/proxy_tensor.py:183(wrap_with_proxy)
      150    0.001    0.000    0.267    0.002 /torch/fx/experimental/proxy_tensor.py:144(set_meta)
  170/150    0.001    0.000    0.262    0.002 /torch/fx/experimental/proxy_tensor.py:117(extract_val)
      160    0.000    0.000    0.261    0.002 /torch/fx/experimental/proxy_tensor.py:114(snapshot_fake)
  200/150    0.003    0.000    0.254    0.002 /torch/_subclasses/fake_tensor.py:1059(__torch_dispatch__)
     1055    0.009    0.000    0.252    0.000 /torch/_subclasses/fake_tensor.py:1620(wrap)
      180    0.001    0.000    0.247    0.001 /torch/utils/_pytree.py:375(tree_all_only)
       70    0.001    0.000    0.240    0.003 /torch/fx/graph_module.py:649(recompile)
    70900    0.091    0.000    0.237    0.000 /torch/utils/_pytree.py:186(_get_node_type)
      400    0.010    0.000    0.233    0.001 {method &#39;to&#39; of &#39;torch._C._TensorBase&#39; objects}
    45710    0.062    0.000    0.218    0.000 /torch/utils/_pytree.py:192(_is_leaf)
       70    0.001    0.000    0.215    0.003 /torch/fx/graph.py:1208(python_code)
       35    0.005    0.000    0.208    0.006 /torch/_dynamo/variables/torch.py:208(call_function)
       70    0.001    0.000    0.202    0.003 /torch/fx/graph.py:1270(_python_code)
       70    0.012    0.000    0.202    0.003 /torch/fx/graph.py:326(_gen_python_code)
265050/258585    0.171    0.000    0.200    0.000 {built-in method builtins.isinstance}
  290/240    0.074    0.000    0.189    0.001 {method &#39;clone&#39; of &#39;torch._C._TensorBase&#39; objects}
        5    0.001    0.000    0.186    0.037 /torch/_dynamo/guards.py:879(__init__)
       50    0.000    0.000    0.181    0.004 /torch/nn/parameter.py:33(__new__)
       40    0.000    0.000    0.174    0.004 /torch/_jit_internal.py:478(fn)
       40    0.001    0.000    0.174    0.004 /torch/nn/functional.py:769(_max_pool2d)
       40    0.005    0.000    0.173    0.004 {built-in method torch.max_pool2d}
      155    0.166    0.001    0.172    0.001 {method &#39;extend&#39; of &#39;google._upb._message.RepeatedCompositeContainer&#39; objects}
        5    0.172    0.034    0.172    0.034 {method &#39;write&#39; of &#39;_io.BufferedWriter&#39; objects}
    45715    0.104    0.000    0.170    0.000 /torch/utils/_pytree.py:207(__post_init__)
      225    0.001    0.000    0.169    0.001 /torch/_decomp/decompositions.py:58(increase_prec)
        5    0.000    0.000    0.165    0.033 /onnx/helper.py:191(make_graph)
      420    0.003    0.000    0.165    0.000 /torch/fx/proxy.py:170(create_proxy)
     1430    0.006    0.000    0.165    0.000 /torch/_subclasses/fake_tensor.py:1557(check_for_subclass)
       55    0.159    0.003    0.159    0.003 {method &#39;tobytes&#39; of &#39;numpy.ndarray&#39; objects}
       45    0.002    0.000    0.158    0.004 /torch/fx/graph_module.py:318(__init__)
  490/400    0.004    0.000    0.154    0.000 /torch/nn/modules/module.py:1697(__setattr__)
        5    0.001    0.000    0.152    0.030 /torch/_dynamo/guards.py:943(compile_check_fn)
     1005    0.006    0.000    0.151    0.000 /torch/_subclasses/fake_tensor.py:1115(_find_common_device)
      100    0.001    0.000    0.150    0.002 /torch/_refs/nn/functional/__init__.py:134(_fn)
       45    0.000    0.000    0.148    0.003 /torch/fx/graph_module.py:416(graph)
        5    0.001    0.000    0.147    0.029 /torch/_dynamo/guards.py:1162(build_guard_function)
    70900    0.105    0.000    0.146    0.000 /torch/utils/_pytree.py:176(_is_namedtuple_instance)
     6670    0.014    0.000    0.141    0.000 /torch/fx/node.py:632(map_arg)
17415/5695    0.085    0.000    0.134    0.000 /torch/utils/_pytree.py:252(tree_unflatten)
      100    0.001    0.000    0.130    0.001 /torch/_refs/nn/functional/__init__.py:246(relu)
14150/6675    0.057    0.000    0.123    0.000 /torch/fx/node.py:640(map_aggregate)
       35    0.118    0.003    0.118    0.003 {method &#39;SerializeToString&#39; of &#39;google._upb._message.Message&#39; objects}
 5390/330    0.013    0.000    0.116    0.000 /usr/lib/python3.10/ast.py:414(visit)
      225    0.001    0.000    0.110    0.000 /torch/_subclasses/fake_tensor.py:358(__call__)
      225    0.002    0.000    0.109    0.000 /torch/_subclasses/fake_tensor.py:283(from_real_tensor)
      165    0.006    0.000    0.100    0.001 /torch/_subclasses/meta_utils.py:494(__call__)
15445/14455    0.019    0.000    0.096    0.000 {built-in method builtins.next}
      430    0.006    0.000    0.096    0.000 /torch/fx/proxy.py:114(create_node)
      165    0.011    0.000    0.093    0.001 /torch/_subclasses/meta_utils.py:177(meta_tensor)
       60    0.000    0.000    0.092    0.002 /torch/_refs/__init__.py:4265(t)
       60    0.001    0.000    0.092    0.002 {built-in method torch.transpose}
       75    0.002    0.000    0.091    0.001 {built-in method torch.mm}
      250    0.003    0.000    0.089    0.000 /torch/_refs/__init__.py:957(_ref)
     1450    0.012    0.000    0.088    0.000 /torch/fx/graph.py:482(emit_node)
       60    0.001    0.000    0.087    0.001 /torch/_refs/__init__.py:4301(transpose)
       60    0.001    0.000    0.087    0.001 /torch/_dynamo/symbolic_convert.py:1184(LOAD_ATTR)
       60    0.001    0.000    0.086    0.001 {built-in method torch.permute}
     1055    0.010    0.000    0.086    0.000 /torch/_subclasses/fake_tensor.py:341(from_meta_and_device)
        1    0.000    0.000    0.083    0.083 &lt;eval_with_key&gt;.518:4(forward)
8925/8365    0.010    0.000    0.080    0.000 /torch/fx/node.py:646(&lt;genexpr&gt;)
      440    0.005    0.000    0.079    0.000 /torch/fx/graph.py:805(create_node)
      165    0.001    0.000    0.077    0.000 /torch/_subclasses/fake_tensor.py:1702(from_tensor)
      425    0.009    0.000    0.076    0.000 /torch/_prims/__init__.py:331(_elementwise_meta)
 1080/480    0.007    0.000    0.075    0.000 /torch/_dynamo/variables/base.py:95(__call__)
    70/50    0.005    0.000    0.074    0.001 {built-in method torch._ops.aten.}
        1    0.000    0.000    0.072    0.072 &lt;eval_with_key&gt;.490:4(forward)
        1    0.000    0.000    0.072    0.072 &lt;eval_with_key&gt;.546:4(forward)
       15    0.000    0.000    0.071    0.005 /torch/export/__init__.py:232(__init__)
      670    0.002    0.000    0.071    0.000 /torch/_dynamo/guards.py:128(_ast_unparse)
       15    0.000    0.000    0.071    0.005 /torch/_export/exported_program.py:230(_create_graph_module_for_export)
       10    0.001    0.000    0.070    0.007 /torch/_decomp/decompositions_for_rng.py:129(reset)
      110    0.000    0.000    0.070    0.001 /torch/_dynamo/guards.py:1169(replace)
      110    0.001    0.000    0.069    0.001 /torch/_dynamo/guards.py:862(replace)
      670    0.002    0.000    0.069    0.000 /usr/lib/python3.10/ast.py:1679(unparse)
       50    0.003    0.000    0.068    0.001 /torch/_subclasses/fake_tensor.py:653(conv)
 3685/310    0.027    0.000    0.068    0.000 /torch/_dynamo/variables/base.py:141(apply)
       30    0.000    0.000    0.068    0.002 /torch/_decomp/decompositions_for_rng.py:71(__init__)
       30    0.000    0.000    0.068    0.002 /torch/_decomp/decompositions_for_rng.py:74(reset)
       60    0.004    0.000    0.067    0.001 {built-in method torch.tensor}
 1080/480    0.002    0.000    0.067    0.000 /torch/_dynamo/variables/base.py:346(__post_init__)
      670    0.002    0.000    0.066    0.000 /usr/lib/python3.10/ast.py:811(visit)
110035/109870    0.065    0.000    0.065    0.000 {built-in method builtins.len}
</pre></div>
</div>
<p>The following display helps to understand.
Most of the tiume added by the custom converter is used to
converter the initializer and build the onnx model once the conversion
is complete.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># from onnx_array_api.profiling import profile2graph</span>
<span class="c1"># root, nodes = profile2graph(ps, clean_text=clean_text)</span>
<span class="c1"># text = root.to_text()</span>
<span class="c1"># print(text)</span>
</pre></div>
</div>
</section>
<section id="benchmark">
<h2>Benchmark<a class="headerlink" href="#benchmark" title="Permalink to this heading">#</a></h2>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">benchmark</span><span class="p">():</span>
    <span class="kn">from</span> <span class="nn">onnxruntime</span> <span class="kn">import</span> <span class="n">InferenceSession</span><span class="p">,</span> <span class="n">SessionOptions</span><span class="p">,</span> <span class="n">GraphOptimizationLevel</span>

    <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">shape</span></a> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">]</span>
    <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data</span></a> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">confs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
        <a href="https://docs.python.org/3/library/itertools.html#itertools.product" title="itertools.product" class="sphx-glr-backref-module-itertools sphx-glr-backref-type-py-function"><span class="n">itertools</span><span class="o">.</span><span class="n">product</span></a><span class="p">(</span>
            <span class="p">[</span><span class="n">_</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <a href="https://docs.python.org/3/library/os.html#os.listdir" title="os.listdir" class="sphx-glr-backref-module-os sphx-glr-backref-type-py-function"><span class="n">os</span><span class="o">.</span><span class="n">listdir</span></a><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="s2">&quot;.onnx&quot;</span> <span class="ow">in</span> <span class="n">_</span> <span class="ow">and</span> <span class="n">_</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;plot_torch&quot;</span><span class="p">)],</span>
            <span class="p">[</span>
                <span class="p">[</span><span class="s2">&quot;CPUExecutionProvider&quot;</span><span class="p">],</span>
                <span class="p">[</span><span class="s2">&quot;CUDAExecutionProvider&quot;</span><span class="p">,</span> <span class="s2">&quot;CPUExecutionProvider&quot;</span><span class="p">],</span>
            <span class="p">],</span>
            <span class="p">[</span><span class="s2">&quot;0&quot;</span><span class="p">,</span> <span class="s2">&quot;1&quot;</span><span class="p">],</span>
        <span class="p">)</span>
    <span class="p">)</span>
    <span class="n">loop</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">confs</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;number of experiments: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">loop</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <a href="https://docs.python.org/3/library/profile.html#pstats.Stats" title="pstats.Stats" class="sphx-glr-backref-module-pstats sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ps</span></a><span class="p">,</span> <span class="n">aot</span> <span class="ow">in</span> <span class="n">loop</span><span class="p">:</span>
        <span class="n">root</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/os.path.html#os.path.split" title="os.path.split" class="sphx-glr-backref-module-os-path sphx-glr-backref-type-py-function"><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">split</span></a><span class="p">(</span><span class="n">name</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">ext</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/os.path.html#os.path.splitext" title="os.path.splitext" class="sphx-glr-backref-module-os-path sphx-glr-backref-type-py-function"><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">splitext</span></a><span class="p">(</span><span class="n">root</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">ext</span> <span class="o">!=</span> <span class="s2">&quot;.onnx&quot;</span><span class="p">:</span>
            <span class="k">continue</span>

        <span class="n">obs</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># system_info()</span>
        <span class="n">obs</span><span class="p">[</span><span class="s2">&quot;name&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">name</span>
        <span class="n">obs</span><span class="p">[</span><span class="s2">&quot;providers&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;,&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><a href="https://docs.python.org/3/library/profile.html#pstats.Stats" title="pstats.Stats" class="sphx-glr-backref-module-pstats sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ps</span></a><span class="p">)</span>
        <span class="n">p</span> <span class="o">=</span> <span class="s2">&quot;CUDA&quot;</span> <span class="k">if</span> <span class="s2">&quot;CUDA&quot;</span> <span class="ow">in</span> <span class="n">obs</span><span class="p">[</span><span class="s2">&quot;providers&quot;</span><span class="p">]</span> <span class="k">else</span> <span class="s2">&quot;CPU&quot;</span>
        <span class="n">obs</span><span class="p">[</span><span class="s2">&quot;compute&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">p</span>
        <span class="n">obs</span><span class="p">[</span><span class="s2">&quot;aot&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">aot</span> <span class="o">==</span> <span class="s2">&quot;0&quot;</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="n">obs</span><span class="p">[</span><span class="s2">&quot;export&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;plot_torch_export_&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;.onnx&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>

        <a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx</span></a> <span class="o">=</span> <a href="https://onnx.ai/onnx/api/serialization.html#onnx.load" title="onnx.load" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-function"><span class="n">onnx</span><span class="o">.</span><span class="n">load</span></a><span class="p">(</span><span class="n">name</span><span class="p">)</span>
        <span class="n">obs</span><span class="p">[</span><span class="s2">&quot;n_nodes&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx</span></a><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="p">)</span>
        <span class="n">obs</span><span class="p">[</span><span class="s2">&quot;n_function&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx</span></a><span class="o">.</span><span class="n">functions</span> <span class="ow">or</span> <span class="p">[])</span>
        <span class="n">obs</span><span class="p">[</span><span class="s2">&quot;n_sub&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">([</span><span class="n">n</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx</span></a><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">node</span> <span class="k">if</span> <span class="n">n</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Sub&quot;</span><span class="p">])</span>

        <span class="n">opts</span> <span class="o">=</span> <span class="n">SessionOptions</span><span class="p">()</span>
        <span class="n">opts</span><span class="o">.</span><span class="n">add_session_config_entry</span><span class="p">(</span><span class="s2">&quot;session.disable_aot_function_inlining&quot;</span><span class="p">,</span> <span class="n">aot</span><span class="p">)</span>
        <span class="n">opts</span><span class="o">.</span><span class="n">graph_optimization_level</span> <span class="o">=</span> <span class="n">GraphOptimizationLevel</span><span class="o">.</span><span class="n">ORT_ENABLE_ALL</span>
        <span class="n">opts</span><span class="o">.</span><span class="n">optimized_model_filepath</span> <span class="o">=</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;ort-</span><span class="si">{</span><span class="n">name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;.onnx&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="n">p</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="si">}</span><span class="s2">-aot</span><span class="si">{</span><span class="n">aot</span><span class="si">}</span><span class="s2">.onnx&quot;</span>
        <span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">sess</span> <span class="o">=</span> <span class="n">InferenceSession</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">opts</span><span class="p">,</span> <span class="n">providers</span><span class="o">=</span><a href="https://docs.python.org/3/library/profile.html#pstats.Stats" title="pstats.Stats" class="sphx-glr-backref-module-pstats sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ps</span></a><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">loop</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ERROR-load: </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">obs</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;error&quot;</span><span class="p">:</span> <span class="n">e</span><span class="p">,</span> <span class="s2">&quot;step&quot;</span><span class="p">:</span> <span class="s2">&quot;run&quot;</span><span class="p">})</span>
            <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data</span></a><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span>
            <span class="k">continue</span>

        <span class="n">input_name</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">get_inputs</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span>
        <span class="n">feeds</span> <span class="o">=</span> <span class="p">{</span><span class="n">input_name</span><span class="p">:</span> <a href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.rand.html#numpy.random.rand" title="numpy.random.rand" class="sphx-glr-backref-module-numpy-random sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span></a><span class="p">(</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">shape</span></a><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float32" title="numpy.float32" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"><span class="n">np</span><span class="o">.</span><span class="n">float32</span></a><span class="p">)}</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i</span></a> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">):</span>
                <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">feeds</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">loop</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ERROR-run: </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">obs</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;error&quot;</span><span class="p">:</span> <span class="n">e</span><span class="p">,</span> <span class="s2">&quot;step&quot;</span><span class="p">:</span> <span class="s2">&quot;load&quot;</span><span class="p">})</span>
            <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data</span></a><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span>
            <span class="k">continue</span>
        <span class="n">obs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">measure_time</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">feeds</span><span class="p">),</span> <span class="n">max_time</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

        <span class="n">loop</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">obs</span><span class="p">[</span><span class="s1">&#39;average&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><a href="https://docs.python.org/3/library/profile.html#pstats.Stats" title="pstats.Stats" class="sphx-glr-backref-module-pstats sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ps</span></a><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data</span></a><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span>

    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class"><span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data</span></a><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html#pandas.DataFrame.to_csv" title="pandas.DataFrame.to_csv" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">to_csv</span></a><span class="p">(</span><span class="s2">&quot;benchmark.csv&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_excel.html#pandas.DataFrame.to_excel" title="pandas.DataFrame.to_excel" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">to_excel</span></a><span class="p">(</span><span class="s2">&quot;benchmark.xlsx&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">return</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a>


<a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <span class="n">benchmark</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>  0%|          | 0/24 [00:00&lt;?, ?it/s]number of experiments: 24

0.012920297619053773 plot_torch_export_cus_p1.onnx [&#39;CPUExecutionProvider&#39;]:   0%|          | 0/24 [00:01&lt;?, ?it/s]
0.012920297619053773 plot_torch_export_cus_p1.onnx [&#39;CPUExecutionProvider&#39;]:   4%|▍         | 1/24 [00:01&lt;00:33,  1.47s/it]
0.013763085057470217 plot_torch_export_cus_p1.onnx [&#39;CPUExecutionProvider&#39;]:   4%|▍         | 1/24 [00:03&lt;00:33,  1.47s/it]
0.013763085057470217 plot_torch_export_cus_p1.onnx [&#39;CPUExecutionProvider&#39;]:   8%|▊         | 2/24 [00:03&lt;00:35,  1.62s/it]
0.001620969485291461 plot_torch_export_cus_p1.onnx [&#39;CUDAExecutionProvider&#39;, &#39;CPUExecutionProvider&#39;]:   8%|▊         | 2/24 [00:28&lt;00:35,  1.62s/it]
0.001620969485291461 plot_torch_export_cus_p1.onnx [&#39;CUDAExecutionProvider&#39;, &#39;CPUExecutionProvider&#39;]:  12%|█▎        | 3/24 [00:28&lt;04:23, 12.56s/it]
0.001593664592593861 plot_torch_export_cus_p1.onnx [&#39;CUDAExecutionProvider&#39;, &#39;CPUExecutionProvider&#39;]:  12%|█▎        | 3/24 [00:30&lt;04:23, 12.56s/it]
0.001593664592593861 plot_torch_export_cus_p1.onnx [&#39;CUDAExecutionProvider&#39;, &#39;CPUExecutionProvider&#39;]:  17%|█▋        | 4/24 [00:30&lt;02:47,  8.37s/it]
0.014656697101441829 plot_torch_export_cus_p2.onnx [&#39;CPUExecutionProvider&#39;]:  17%|█▋        | 4/24 [00:32&lt;02:47,  8.37s/it]
0.014656697101441829 plot_torch_export_cus_p2.onnx [&#39;CPUExecutionProvider&#39;]:  21%|██        | 5/24 [00:32&lt;01:51,  5.87s/it]
0.013667482666666425 plot_torch_export_cus_p2.onnx [&#39;CPUExecutionProvider&#39;]:  21%|██        | 5/24 [00:33&lt;01:51,  5.87s/it]
0.013667482666666425 plot_torch_export_cus_p2.onnx [&#39;CPUExecutionProvider&#39;]:  25%|██▌       | 6/24 [00:33&lt;01:18,  4.36s/it]
0.0017512387878813377 plot_torch_export_cus_p2.onnx [&#39;CUDAExecutionProvider&#39;, &#39;CPUExecutionProvider&#39;]:  25%|██▌       | 6/24 [00:35&lt;01:18,  4.36s/it]
0.0017512387878813377 plot_torch_export_cus_p2.onnx [&#39;CUDAExecutionProvider&#39;, &#39;CPUExecutionProvider&#39;]:  29%|██▉       | 7/24 [00:35&lt;00:58,  3.41s/it]
0.00160631751151929 plot_torch_export_cus_p2.onnx [&#39;CUDAExecutionProvider&#39;, &#39;CPUExecutionProvider&#39;]:  29%|██▉       | 7/24 [00:36&lt;00:58,  3.41s/it]
0.00160631751151929 plot_torch_export_cus_p2.onnx [&#39;CUDAExecutionProvider&#39;, &#39;CPUExecutionProvider&#39;]:  33%|███▎      | 8/24 [00:36&lt;00:44,  2.76s/it]
0.008168666433569222 plot_torch_export_script.onnx [&#39;CPUExecutionProvider&#39;]:  33%|███▎      | 8/24 [00:38&lt;00:44,  2.76s/it]
0.008168666433569222 plot_torch_export_script.onnx [&#39;CPUExecutionProvider&#39;]:  38%|███▊      | 9/24 [00:38&lt;00:36,  2.42s/it]
0.009028141666673643 plot_torch_export_script.onnx [&#39;CPUExecutionProvider&#39;]:  38%|███▊      | 9/24 [00:40&lt;00:36,  2.42s/it]
0.009028141666673643 plot_torch_export_script.onnx [&#39;CPUExecutionProvider&#39;]:  42%|████▏     | 10/24 [00:40&lt;00:32,  2.35s/it]
0.0015296807017556714 plot_torch_export_script.onnx [&#39;CUDAExecutionProvider&#39;, &#39;CPUExecutionProvider&#39;]:  42%|████▏     | 10/24 [00:41&lt;00:32,  2.35s/it]
0.0015296807017556714 plot_torch_export_script.onnx [&#39;CUDAExecutionProvider&#39;, &#39;CPUExecutionProvider&#39;]:  46%|████▌     | 11/24 [00:41&lt;00:27,  2.15s/it]
0.001618982296651428 plot_torch_export_script.onnx [&#39;CUDAExecutionProvider&#39;, &#39;CPUExecutionProvider&#39;]:  46%|████▌     | 11/24 [00:43&lt;00:27,  2.15s/it]
0.001618982296651428 plot_torch_export_script.onnx [&#39;CUDAExecutionProvider&#39;, &#39;CPUExecutionProvider&#39;]:  50%|█████     | 12/24 [00:43&lt;00:23,  1.94s/it]
0.02053954901966077 plot_torch_export_cus_p0.onnx [&#39;CPUExecutionProvider&#39;]:  50%|█████     | 12/24 [00:45&lt;00:23,  1.94s/it]
0.02053954901966077 plot_torch_export_cus_p0.onnx [&#39;CPUExecutionProvider&#39;]:  54%|█████▍    | 13/24 [00:45&lt;00:23,  2.11s/it]
0.019018220895576185 plot_torch_export_cus_p0.onnx [&#39;CPUExecutionProvider&#39;]:  54%|█████▍    | 13/24 [00:48&lt;00:23,  2.11s/it]
0.019018220895576185 plot_torch_export_cus_p0.onnx [&#39;CPUExecutionProvider&#39;]:  58%|█████▊    | 14/24 [00:48&lt;00:21,  2.15s/it]
0.002281675793653001 plot_torch_export_cus_p0.onnx [&#39;CUDAExecutionProvider&#39;, &#39;CPUExecutionProvider&#39;]:  58%|█████▊    | 14/24 [00:49&lt;00:21,  2.15s/it]
0.002281675793653001 plot_torch_export_cus_p0.onnx [&#39;CUDAExecutionProvider&#39;, &#39;CPUExecutionProvider&#39;]:  62%|██████▎   | 15/24 [00:49&lt;00:17,  1.96s/it]
0.0022854861261261215 plot_torch_export_cus_p0.onnx [&#39;CUDAExecutionProvider&#39;, &#39;CPUExecutionProvider&#39;]:  62%|██████▎   | 15/24 [00:51&lt;00:17,  1.96s/it]
0.0022854861261261215 plot_torch_export_cus_p0.onnx [&#39;CUDAExecutionProvider&#39;, &#39;CPUExecutionProvider&#39;]:  67%|██████▋   | 16/24 [00:51&lt;00:14,  1.85s/it]
0.025161007142872092 plot_torch_export_dynopt.onnx [&#39;CPUExecutionProvider&#39;]:  67%|██████▋   | 16/24 [00:53&lt;00:14,  1.85s/it]
0.025161007142872092 plot_torch_export_dynopt.onnx [&#39;CPUExecutionProvider&#39;]:  71%|███████   | 17/24 [00:53&lt;00:13,  1.92s/it]
0.044606683333389206 plot_torch_export_dynopt.onnx [&#39;CPUExecutionProvider&#39;]:  71%|███████   | 17/24 [00:55&lt;00:13,  1.92s/it]
0.044606683333389206 plot_torch_export_dynopt.onnx [&#39;CPUExecutionProvider&#39;]:  75%|███████▌  | 18/24 [00:55&lt;00:12,  2.04s/it]
0.0023448135881035787 plot_torch_export_dynopt.onnx [&#39;CUDAExecutionProvider&#39;, &#39;CPUExecutionProvider&#39;]:  75%|███████▌  | 18/24 [00:57&lt;00:12,  2.04s/it]
0.0023448135881035787 plot_torch_export_dynopt.onnx [&#39;CUDAExecutionProvider&#39;, &#39;CPUExecutionProvider&#39;]:  79%|███████▉  | 19/24 [00:57&lt;00:09,  1.90s/it]
0.004259221544710205 plot_torch_export_dynopt.onnx [&#39;CUDAExecutionProvider&#39;, &#39;CPUExecutionProvider&#39;]:  79%|███████▉  | 19/24 [00:58&lt;00:09,  1.90s/it]
0.004259221544710205 plot_torch_export_dynopt.onnx [&#39;CUDAExecutionProvider&#39;, &#39;CPUExecutionProvider&#39;]:  83%|████████▎ | 20/24 [00:58&lt;00:07,  1.78s/it]
0.020721249206337868 plot_torch_export_dynamo.onnx [&#39;CPUExecutionProvider&#39;]:  83%|████████▎ | 20/24 [01:01&lt;00:07,  1.78s/it]
0.020721249206337868 plot_torch_export_dynamo.onnx [&#39;CPUExecutionProvider&#39;]:  88%|████████▊ | 21/24 [01:01&lt;00:05,  1.95s/it]
0.04156973030297773 plot_torch_export_dynamo.onnx [&#39;CPUExecutionProvider&#39;]:  88%|████████▊ | 21/24 [01:03&lt;00:05,  1.95s/it]
0.04156973030297773 plot_torch_export_dynamo.onnx [&#39;CPUExecutionProvider&#39;]:  92%|█████████▏| 22/24 [01:03&lt;00:03,  1.93s/it]
0.0022504826235135514 plot_torch_export_dynamo.onnx [&#39;CUDAExecutionProvider&#39;, &#39;CPUExecutionProvider&#39;]:  92%|█████████▏| 22/24 [01:04&lt;00:03,  1.93s/it]
0.0022504826235135514 plot_torch_export_dynamo.onnx [&#39;CUDAExecutionProvider&#39;, &#39;CPUExecutionProvider&#39;]:  96%|█████████▌| 23/24 [01:04&lt;00:01,  1.95s/it]
0.005023675980398776 plot_torch_export_dynamo.onnx [&#39;CUDAExecutionProvider&#39;, &#39;CPUExecutionProvider&#39;]:  96%|█████████▌| 23/24 [01:06&lt;00:01,  1.95s/it]
0.005023675980398776 plot_torch_export_dynamo.onnx [&#39;CUDAExecutionProvider&#39;, &#39;CPUExecutionProvider&#39;]: 100%|██████████| 24/24 [01:06&lt;00:00,  1.79s/it]
0.005023675980398776 plot_torch_export_dynamo.onnx [&#39;CUDAExecutionProvider&#39;, &#39;CPUExecutionProvider&#39;]: 100%|██████████| 24/24 [01:06&lt;00:00,  2.77s/it]
                             name                                   providers compute  aot  export  n_nodes  n_function  n_sub   average  deviation  min_exec  max_exec  repeat  number     ttime  context_size  warmup_time
0   plot_torch_export_cus_p1.onnx                        CPUExecutionProvider     CPU    1  cus_p1       15           0      0  0.012920   0.000795  0.011773  0.013512       1    84.0  1.085305            64     0.011963
1   plot_torch_export_cus_p1.onnx                        CPUExecutionProvider     CPU    0  cus_p1       15           0      0  0.013763   0.000693  0.012633  0.014831       1    87.0  1.197388            64     0.013315
2   plot_torch_export_cus_p1.onnx  CUDAExecutionProvider,CPUExecutionProvider    CUDA    1  cus_p1       15           0      0  0.001621   0.000454  0.001512  0.008372       1   816.0  1.322711            64     0.008215
3   plot_torch_export_cus_p1.onnx  CUDAExecutionProvider,CPUExecutionProvider    CUDA    0  cus_p1       15           0      0  0.001594   0.000011  0.001447  0.001599       1   675.0  1.075724            64     0.001626
4   plot_torch_export_cus_p2.onnx                        CPUExecutionProvider     CPU    1  cus_p2       12           0      0  0.014657   0.000546  0.013585  0.015057       1    69.0  1.011312            64     0.013433
5   plot_torch_export_cus_p2.onnx                        CPUExecutionProvider     CPU    0  cus_p2       12           0      0  0.013667   0.000541  0.012986  0.014449       1    75.0  1.025061            64     0.013617
6   plot_torch_export_cus_p2.onnx  CUDAExecutionProvider,CPUExecutionProvider    CUDA    1  cus_p2       12           0      0  0.001751   0.000028  0.001479  0.001769       1   660.0  1.155818            64     0.001579
7   plot_torch_export_cus_p2.onnx  CUDAExecutionProvider,CPUExecutionProvider    CUDA    0  cus_p2       12           0      0  0.001606   0.000011  0.001515  0.001620       1   651.0  1.045713            64     0.001455
8   plot_torch_export_script.onnx                        CPUExecutionProvider     CPU    1  script       12           0      0  0.008169   0.000392  0.007682  0.010543       1   143.0  1.168119            64     0.007879
9   plot_torch_export_script.onnx                        CPUExecutionProvider     CPU    0  script       12           0      0  0.009028   0.000598  0.008200  0.009886       1   120.0  1.083377            64     0.007946
10  plot_torch_export_script.onnx  CUDAExecutionProvider,CPUExecutionProvider    CUDA    1  script       12           0      0  0.001530   0.000032  0.001487  0.001564       1   855.0  1.307877            64     0.001788
11  plot_torch_export_script.onnx  CUDAExecutionProvider,CPUExecutionProvider    CUDA    0  script       12           0      0  0.001619   0.000071  0.001570  0.002383       1   627.0  1.015102            64     0.001484
12  plot_torch_export_cus_p0.onnx                        CPUExecutionProvider     CPU    1  cus_p0       27           0      2  0.020540   0.001648  0.019366  0.022974       1    51.0  1.047517            64     0.020749
13  plot_torch_export_cus_p0.onnx                        CPUExecutionProvider     CPU    0  cus_p0       27           0      2  0.019018   0.000640  0.018166  0.020004       1    67.0  1.274221            64     0.018788
14  plot_torch_export_cus_p0.onnx  CUDAExecutionProvider,CPUExecutionProvider    CUDA    1  cus_p0       27           0      2  0.002282   0.000025  0.001874  0.002289       1   504.0  1.149965            64     0.001880
15  plot_torch_export_cus_p0.onnx  CUDAExecutionProvider,CPUExecutionProvider    CUDA    0  cus_p0       27           0      2  0.002285   0.000028  0.002110  0.002538       1   555.0  1.268445            64     0.002031
16  plot_torch_export_dynopt.onnx                        CPUExecutionProvider     CPU    1  dynopt       13          21      0  0.025161   0.002672  0.020189  0.027220       1    42.0  1.056762            64     0.022742
17  plot_torch_export_dynopt.onnx                        CPUExecutionProvider     CPU    0  dynopt       13          21      0  0.044607   0.002668  0.038980  0.048468       1    24.0  1.070560            64     0.046328
18  plot_torch_export_dynopt.onnx  CUDAExecutionProvider,CPUExecutionProvider    CUDA    1  dynopt       13          21      0  0.002345   0.000068  0.002119  0.002393       1   471.0  1.104407            64     0.002019
19  plot_torch_export_dynopt.onnx  CUDAExecutionProvider,CPUExecutionProvider    CUDA    0  dynopt       13          21      0  0.004259   0.000037  0.003758  0.004286       1   246.0  1.047768            64     0.003568
20  plot_torch_export_dynamo.onnx                        CPUExecutionProvider     CPU    1  dynamo       13          13      0  0.020721   0.001366  0.018397  0.021614       1    63.0  1.305439            64     0.019942
21  plot_torch_export_dynamo.onnx                        CPUExecutionProvider     CPU    0  dynamo       13          13      0  0.041570   0.003044  0.039782  0.053197       1    33.0  1.371801            64     0.044708
22  plot_torch_export_dynamo.onnx  CUDAExecutionProvider,CPUExecutionProvider    CUDA    1  dynamo       13          13      0  0.002250   0.000011  0.002240  0.002270       1   587.0  1.321033            64     0.002417
23  plot_torch_export_dynamo.onnx  CUDAExecutionProvider,CPUExecutionProvider    CUDA    0  dynamo       13          13      0  0.005024   0.000028  0.004635  0.005029       1   204.0  1.024830            64     0.004803
</pre></div>
</div>
<p>Other view</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">piv</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.pivot_table.html#pandas.pivot_table" title="pandas.pivot_table" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-function"><span class="n">pandas</span><span class="o">.</span><span class="n">pivot_table</span></a><span class="p">(</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="s2">&quot;export&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;compute&quot;</span><span class="p">,</span> <span class="s2">&quot;aot&quot;</span><span class="p">],</span> <span class="n">values</span><span class="o">=</span><span class="s2">&quot;average&quot;</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">piv</span></a><span class="p">)</span>

<a href="https://matplotlib.org/stable/api/figure_api.html#matplotlib.figure.Figure" title="matplotlib.figure.Figure" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fig</span></a><span class="p">,</span> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.html#matplotlib.axes.Axes" title="matplotlib.axes.Axes" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span></a> <span class="o">=</span> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="matplotlib.pyplot.subplots" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">()</span>
<a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">piv</span></a><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.html#matplotlib.axes.Axes" title="matplotlib.axes.Axes" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span></a><span class="o">=</span><a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.html#matplotlib.axes.Axes" title="matplotlib.axes.Axes" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span></a><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Compares onnxruntime time on exported models&quot;</span><span class="p">)</span>
<a href="https://matplotlib.org/stable/api/figure_api.html#matplotlib.figure.Figure.tight_layout" title="matplotlib.figure.Figure.tight_layout" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-method"><span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span></a><span class="p">()</span>
<a href="https://matplotlib.org/stable/api/figure_api.html#matplotlib.figure.Figure.savefig" title="matplotlib.figure.Figure.savefig" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-method"><span class="n">fig</span><span class="o">.</span><span class="n">savefig</span></a><span class="p">(</span><span class="s2">&quot;plot_torch_export_ort.png&quot;</span><span class="p">)</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_plot_torch_export_002.png" srcset="../_images/sphx_glr_plot_torch_export_002.png" alt="Compares onnxruntime time on exported models" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>compute       CPU                CUDA
aot             0         1         0         1
export
cus_p0   0.019018  0.020540  0.002285  0.002282
cus_p1   0.013763  0.012920  0.001594  0.001621
cus_p2   0.013667  0.014657  0.001606  0.001751
dynamo   0.041570  0.020721  0.005024  0.002250
dynopt   0.044607  0.025161  0.004259  0.002345
script   0.009028  0.008169  0.001619  0.001530
</pre></div>
</div>
</section>
<section id="show-the-interesting-models">
<h2>Show the interesting models<a class="headerlink" href="#show-the-interesting-models" title="Permalink to this heading">#</a></h2>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">models</span></a> <span class="o">=</span> <span class="p">[</span>
    <span class="n">_</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <a href="https://docs.python.org/3/library/os.html#os.listdir" title="os.listdir" class="sphx-glr-backref-module-os sphx-glr-backref-type-py-function"><span class="n">os</span><span class="o">.</span><span class="n">listdir</span></a><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="s2">&quot;.onnx&quot;</span> <span class="ow">in</span> <span class="n">_</span> <span class="ow">and</span> <span class="n">_</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;ort-plot_torch_export&quot;</span><span class="p">)</span>
<span class="p">]</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a> <span class="ow">in</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">models</span></a><span class="p">:</span>
    <span class="k">if</span> <span class="p">(</span>
        <span class="s2">&quot;cpu&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a>
        <span class="ow">and</span> <span class="s2">&quot;cuda&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a>
        <span class="ow">or</span> <span class="s2">&quot;aot&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a>
        <span class="ow">or</span> <span class="s2">&quot;cus_p0&quot;</span> <span class="ow">in</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a>
        <span class="ow">or</span> <span class="s2">&quot;cus_p1&quot;</span> <span class="ow">in</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a>
    <span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;skip1&quot;</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a><span class="p">)</span>
        <span class="k">continue</span>
    <span class="k">if</span> <span class="p">(</span><span class="s2">&quot;dynamo&quot;</span> <span class="ow">in</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a> <span class="ow">or</span> <span class="s2">&quot;dynopt&quot;</span> <span class="ow">in</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a><span class="p">)</span> <span class="ow">and</span> <span class="s2">&quot;aot0&quot;</span> <span class="ow">in</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;skip2&quot;</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a><span class="p">)</span>
        <span class="k">continue</span>
    <span class="k">if</span> <span class="s2">&quot;aot1&quot;</span> <span class="ow">in</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a> <span class="ow">and</span> <span class="p">(</span><span class="s2">&quot;dynamo&quot;</span> <span class="ow">in</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a> <span class="ow">or</span> <span class="s2">&quot;dynopt&quot;</span> <span class="ow">in</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;skip3&quot;</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a><span class="p">)</span>
        <span class="k">continue</span>
    <span class="nb">print</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;#################################################&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;#################################################&quot;</span><span class="p">)</span>
    <a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx</span></a> <span class="o">=</span> <a href="https://onnx.ai/onnx/api/serialization.html#onnx.load" title="onnx.load" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-function"><span class="n">onnx</span><span class="o">.</span><span class="n">load</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">onnx_simple_text_plot</span><span class="p">(</span><a href="https://onnx.ai/onnx/api/serialization.html#onnx.ModelProto" title="onnx.ModelProto" class="sphx-glr-backref-module-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">onx</span></a><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;done.&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>skip1 ort-plot_torch_export_cus_p0-cpu-aot1.onnx
skip1 ort-plot_torch_export_cus_p0-cpu-aot0.onnx

#################################################
ort-plot_torch_export_cus_p2-cuda-aot1.onnx
#################################################
opset: domain=&#39;&#39; version=18
opset: domain=&#39;ai.onnx.ml&#39; version=4
opset: domain=&#39;ai.onnx.training&#39; version=1
opset: domain=&#39;ai.onnx.preview.training&#39; version=1
opset: domain=&#39;com.microsoft&#39; version=1
opset: domain=&#39;com.microsoft.experimental&#39; version=1
opset: domain=&#39;com.microsoft.nchwc&#39; version=1
opset: domain=&#39;org.pytorch.aten&#39; version=1
input: name=&#39;input&#39; type=dtype(&#39;float32&#39;) shape=[1, 1, 128, 128]
init: name=&#39;arg0_1&#39; type=dtype(&#39;float32&#39;) shape=(128, 1, 5, 5)
init: name=&#39;arg1_1&#39; type=dtype(&#39;float32&#39;) shape=(128,)
init: name=&#39;arg2_1&#39; type=dtype(&#39;float32&#39;) shape=(16, 128, 5, 5)
init: name=&#39;arg3_1&#39; type=dtype(&#39;float32&#39;) shape=(16,)
init: name=&#39;arg5_1&#39; type=dtype(&#39;float32&#39;) shape=(1024,)
init: name=&#39;arg7_1&#39; type=dtype(&#39;float32&#39;) shape=(128,)
init: name=&#39;arg9_1&#39; type=dtype(&#39;float32&#39;) shape=(10,)
init: name=&#39;ortshared_7_1_2_0_token_8&#39; type=dtype(&#39;int64&#39;) shape=(2,) -- array([    1, 13456])
init: name=&#39;permute&#39; type=dtype(&#39;float32&#39;) shape=(13456, 1024)
init: name=&#39;permute_1&#39; type=dtype(&#39;float32&#39;) shape=(1024, 128)
init: name=&#39;permute_2&#39; type=dtype(&#39;float32&#39;) shape=(128, 10)
FusedConv[com.microsoft](input, arg0_1, arg1_1, activation=b&#39;Relu&#39;, dilations=[1,1], group=1, strides=[1,1], pads=[0,0,0,0], auto_pad=b&#39;NOTSET&#39;) -&gt; relu
  MaxPool(relu, storage_order=0, auto_pad=b&#39;NOTSET&#39;, ceil_mode=0, dilations=[1,1], kernel_shape=[2,2], pads=[0,0,0,0], strides=[2,2]) -&gt; _onx_maxpool0, _onx_maxpool1
    FusedConv[com.microsoft](_onx_maxpool0, arg2_1, arg3_1, activation=b&#39;Relu&#39;, dilations=[1,1], group=1, strides=[1,1], pads=[0,0,0,0], auto_pad=b&#39;NOTSET&#39;) -&gt; relu_1
      MaxPool(relu_1, storage_order=0, auto_pad=b&#39;NOTSET&#39;, ceil_mode=0, dilations=[1,1], kernel_shape=[2,2], pads=[0,0,0,0], strides=[2,2]) -&gt; _onx_maxpool03, _onx_maxpool13
        Reshape(_onx_maxpool03, ortshared_7_1_2_0_token_8, allowzero=0) -&gt; view
          Gemm(view, permute, arg5_1, transB=0, transA=0, alpha=1.00, beta=1.00) -&gt; addmm
            Relu(addmm) -&gt; relu_2
              Gemm(relu_2, permute_1, arg7_1, transB=0, transA=0, alpha=1.00, beta=1.00) -&gt; addmm_1
                Relu(addmm_1) -&gt; relu_3
                  Gemm(relu_3, permute_2, arg9_1, transB=0, transA=0, alpha=1.00, beta=1.00) -&gt; output
output: name=&#39;output&#39; type=dtype(&#39;float32&#39;) shape=[1, 10]
skip1 ort-plot_torch_export_cus_p1-cpu-aot0.onnx

#################################################
ort-plot_torch_export_cus_p2-cpu-aot1.onnx
#################################################
opset: domain=&#39;&#39; version=18
opset: domain=&#39;ai.onnx.ml&#39; version=4
opset: domain=&#39;ai.onnx.training&#39; version=1
opset: domain=&#39;ai.onnx.preview.training&#39; version=1
opset: domain=&#39;com.microsoft&#39; version=1
opset: domain=&#39;com.microsoft.experimental&#39; version=1
opset: domain=&#39;com.microsoft.nchwc&#39; version=1
opset: domain=&#39;org.pytorch.aten&#39; version=1
input: name=&#39;input&#39; type=dtype(&#39;float32&#39;) shape=[1, 1, 128, 128]
init: name=&#39;reorder&#39; type=dtype(&#39;float32&#39;) shape=(128, 1, 5, 5)
init: name=&#39;arg1_1&#39; type=dtype(&#39;float32&#39;) shape=(128,)
init: name=&#39;reorder_token_11&#39; type=dtype(&#39;float32&#39;) shape=(16, 128, 5, 5)
init: name=&#39;arg3_1&#39; type=dtype(&#39;float32&#39;) shape=(16,)
init: name=&#39;arg5_1&#39; type=dtype(&#39;float32&#39;) shape=(1024,)
init: name=&#39;arg7_1&#39; type=dtype(&#39;float32&#39;) shape=(128,)
init: name=&#39;arg9_1&#39; type=dtype(&#39;float32&#39;) shape=(10,)
init: name=&#39;ortshared_7_1_2_0_token_8&#39; type=dtype(&#39;int64&#39;) shape=(2,) -- array([    1, 13456])
init: name=&#39;permute&#39; type=dtype(&#39;float32&#39;) shape=(13456, 1024)
init: name=&#39;permute_1&#39; type=dtype(&#39;float32&#39;) shape=(1024, 128)
init: name=&#39;permute_2&#39; type=dtype(&#39;float32&#39;) shape=(128, 10)
Conv[com.microsoft.nchwc](input, reorder, arg1_1, activation=b&#39;Relu&#39;, dilations=[1,1], group=1, strides=[1,1], pads=[0,0,0,0], auto_pad=b&#39;NOTSET&#39;) -&gt; reorder_token_10
  ReorderOutput[com.microsoft.nchwc](reorder_token_10, channels_last=0, channels=128) -&gt; relu
    MaxPool(relu, storage_order=0, auto_pad=b&#39;NOTSET&#39;, ceil_mode=0, dilations=[1,1], kernel_shape=[2,2], pads=[0,0,0,0], strides=[2,2]) -&gt; _onx_maxpool0, _onx_maxpool1
      ReorderInput[com.microsoft.nchwc](_onx_maxpool0, channels_last=0) -&gt; reorder_token_12
        Conv[com.microsoft.nchwc](reorder_token_12, reorder_token_11, arg3_1, activation=b&#39;Relu&#39;, dilations=[1,1], group=1, strides=[1,1], pads=[0,0,0,0], auto_pad=b&#39;NOTSET&#39;) -&gt; reorder_token_13
          ReorderOutput[com.microsoft.nchwc](reorder_token_13, channels_last=0, channels=16) -&gt; relu_1
            MaxPool(relu_1, storage_order=0, auto_pad=b&#39;NOTSET&#39;, ceil_mode=0, dilations=[1,1], kernel_shape=[2,2], pads=[0,0,0,0], strides=[2,2]) -&gt; _onx_maxpool03, _onx_maxpool13
              Reshape(_onx_maxpool03, ortshared_7_1_2_0_token_8, allowzero=0) -&gt; view
                FusedGemm[com.microsoft](view, permute, arg5_1, activation=b&#39;Relu&#39;, transB=0, transA=0, alpha=1.00, beta=1.00) -&gt; relu_2
                  FusedGemm[com.microsoft](relu_2, permute_1, arg7_1, activation=b&#39;Relu&#39;, transB=0, transA=0, alpha=1.00, beta=1.00) -&gt; relu_3
                    Gemm(relu_3, permute_2, arg9_1, transB=0, transA=0, alpha=1.00, beta=1.00) -&gt; output
output: name=&#39;output&#39; type=dtype(&#39;float32&#39;) shape=[1, 10]
skip1 ort-plot_torch_export_cus_p1-cpu-aot1.onnx
skip1 ort-plot_torch_export_cus_p1-cuda-aot0.onnx

#################################################
ort-plot_torch_export_script-cpu-aot0.onnx
#################################################
opset: domain=&#39;&#39; version=17
opset: domain=&#39;ai.onnx.ml&#39; version=4
opset: domain=&#39;ai.onnx.training&#39; version=1
opset: domain=&#39;ai.onnx.preview.training&#39; version=1
opset: domain=&#39;com.microsoft&#39; version=1
opset: domain=&#39;com.microsoft.experimental&#39; version=1
opset: domain=&#39;com.microsoft.nchwc&#39; version=1
opset: domain=&#39;org.pytorch.aten&#39; version=1
input: name=&#39;input&#39; type=dtype(&#39;float32&#39;) shape=[1, 1, 128, 128]
init: name=&#39;reorder&#39; type=dtype(&#39;float32&#39;) shape=(128, 1, 5, 5)
init: name=&#39;conv1.bias&#39; type=dtype(&#39;float32&#39;) shape=(128,)
init: name=&#39;reorder_token_2&#39; type=dtype(&#39;float32&#39;) shape=(16, 128, 5, 5)
init: name=&#39;conv2.bias&#39; type=dtype(&#39;float32&#39;) shape=(16,)
init: name=&#39;fc1.weight&#39; type=dtype(&#39;float32&#39;) shape=(1024, 13456)
init: name=&#39;fc1.bias&#39; type=dtype(&#39;float32&#39;) shape=(1024,)
init: name=&#39;fc2.weight&#39; type=dtype(&#39;float32&#39;) shape=(128, 1024)
init: name=&#39;fc2.bias&#39; type=dtype(&#39;float32&#39;) shape=(128,)
init: name=&#39;fc3.weight&#39; type=dtype(&#39;float32&#39;) shape=(10, 128)
init: name=&#39;fc3.bias&#39; type=dtype(&#39;float32&#39;) shape=(10,)
Conv[com.microsoft.nchwc](input, reorder, conv1.bias, activation=b&#39;Relu&#39;, auto_pad=b&#39;NOTSET&#39;, dilations=[1,1], group=1, strides=[1,1], kernel_shape=[5,5], pads=[0,0,0,0]) -&gt; reorder_token_0
  MaxPool[com.microsoft.nchwc](reorder_token_0, storage_order=0, ceil_mode=0, kernel_shape=[2,2], pads=[0,0,0,0], auto_pad=b&#39;NOTSET&#39;, strides=[2,2]) -&gt; reorder_token_1
    Conv[com.microsoft.nchwc](reorder_token_1, reorder_token_2, conv2.bias, activation=b&#39;Relu&#39;, auto_pad=b&#39;NOTSET&#39;, dilations=[1,1], group=1, strides=[1,1], kernel_shape=[5,5], pads=[0,0,0,0]) -&gt; reorder_token_3
      MaxPool[com.microsoft.nchwc](reorder_token_3, storage_order=0, ceil_mode=0, kernel_shape=[2,2], pads=[0,0,0,0], auto_pad=b&#39;NOTSET&#39;, strides=[2,2]) -&gt; reorder_token_4
        ReorderOutput[com.microsoft.nchwc](reorder_token_4, channels_last=0, channels=16) -&gt; /MaxPool_1_output_0
          Flatten(/MaxPool_1_output_0, axis=1) -&gt; /Flatten_output_0
            FusedGemm[com.microsoft](/Flatten_output_0, fc1.weight, fc1.bias, activation=b&#39;Relu&#39;, alpha=1.00, beta=1.00, transA=0, transB=1) -&gt; /Relu_2_output_0
              FusedGemm[com.microsoft](/Relu_2_output_0, fc2.weight, fc2.bias, activation=b&#39;Relu&#39;, alpha=1.00, beta=1.00, transA=0, transB=1) -&gt; /Relu_3_output_0
                Gemm(/Relu_3_output_0, fc3.weight, fc3.bias, alpha=1.00, beta=1.00, transA=0, transB=1) -&gt; 22
output: name=&#39;22&#39; type=dtype(&#39;float32&#39;) shape=[1, 10]
skip1 ort-plot_torch_export_cus_p0-cuda-aot0.onnx
skip3 ort-plot_torch_export_dynopt-cpu-aot1.onnx
skip2 ort-plot_torch_export_dynamo-cpu-aot0.onnx

#################################################
ort-plot_torch_export_cus_p2-cpu-aot0.onnx
#################################################
opset: domain=&#39;&#39; version=18
opset: domain=&#39;ai.onnx.ml&#39; version=4
opset: domain=&#39;ai.onnx.training&#39; version=1
opset: domain=&#39;ai.onnx.preview.training&#39; version=1
opset: domain=&#39;com.microsoft&#39; version=1
opset: domain=&#39;com.microsoft.experimental&#39; version=1
opset: domain=&#39;com.microsoft.nchwc&#39; version=1
opset: domain=&#39;org.pytorch.aten&#39; version=1
input: name=&#39;input&#39; type=dtype(&#39;float32&#39;) shape=[1, 1, 128, 128]
init: name=&#39;reorder&#39; type=dtype(&#39;float32&#39;) shape=(128, 1, 5, 5)
init: name=&#39;arg1_1&#39; type=dtype(&#39;float32&#39;) shape=(128,)
init: name=&#39;reorder_token_11&#39; type=dtype(&#39;float32&#39;) shape=(16, 128, 5, 5)
init: name=&#39;arg3_1&#39; type=dtype(&#39;float32&#39;) shape=(16,)
init: name=&#39;arg5_1&#39; type=dtype(&#39;float32&#39;) shape=(1024,)
init: name=&#39;arg7_1&#39; type=dtype(&#39;float32&#39;) shape=(128,)
init: name=&#39;arg9_1&#39; type=dtype(&#39;float32&#39;) shape=(10,)
init: name=&#39;ortshared_7_1_2_0_token_8&#39; type=dtype(&#39;int64&#39;) shape=(2,) -- array([    1, 13456])
init: name=&#39;permute&#39; type=dtype(&#39;float32&#39;) shape=(13456, 1024)
init: name=&#39;permute_1&#39; type=dtype(&#39;float32&#39;) shape=(1024, 128)
init: name=&#39;permute_2&#39; type=dtype(&#39;float32&#39;) shape=(128, 10)
Conv[com.microsoft.nchwc](input, reorder, arg1_1, activation=b&#39;Relu&#39;, dilations=[1,1], group=1, strides=[1,1], pads=[0,0,0,0], auto_pad=b&#39;NOTSET&#39;) -&gt; reorder_token_10
  ReorderOutput[com.microsoft.nchwc](reorder_token_10, channels_last=0, channels=128) -&gt; relu
    MaxPool(relu, storage_order=0, auto_pad=b&#39;NOTSET&#39;, ceil_mode=0, dilations=[1,1], kernel_shape=[2,2], pads=[0,0,0,0], strides=[2,2]) -&gt; _onx_maxpool0, _onx_maxpool1
      ReorderInput[com.microsoft.nchwc](_onx_maxpool0, channels_last=0) -&gt; reorder_token_12
        Conv[com.microsoft.nchwc](reorder_token_12, reorder_token_11, arg3_1, activation=b&#39;Relu&#39;, dilations=[1,1], group=1, strides=[1,1], pads=[0,0,0,0], auto_pad=b&#39;NOTSET&#39;) -&gt; reorder_token_13
          ReorderOutput[com.microsoft.nchwc](reorder_token_13, channels_last=0, channels=16) -&gt; relu_1
            MaxPool(relu_1, storage_order=0, auto_pad=b&#39;NOTSET&#39;, ceil_mode=0, dilations=[1,1], kernel_shape=[2,2], pads=[0,0,0,0], strides=[2,2]) -&gt; _onx_maxpool03, _onx_maxpool13
              Reshape(_onx_maxpool03, ortshared_7_1_2_0_token_8, allowzero=0) -&gt; view
                FusedGemm[com.microsoft](view, permute, arg5_1, activation=b&#39;Relu&#39;, transB=0, transA=0, alpha=1.00, beta=1.00) -&gt; relu_2
                  FusedGemm[com.microsoft](relu_2, permute_1, arg7_1, activation=b&#39;Relu&#39;, transB=0, transA=0, alpha=1.00, beta=1.00) -&gt; relu_3
                    Gemm(relu_3, permute_2, arg9_1, transB=0, transA=0, alpha=1.00, beta=1.00) -&gt; output
output: name=&#39;output&#39; type=dtype(&#39;float32&#39;) shape=[1, 10]
skip3 ort-plot_torch_export_dynamo-cuda-aot1.onnx
skip1 ort-plot_torch_export_cus_p1-cuda-aot1.onnx
skip3 ort-plot_torch_export_dynopt-cuda-aot1.onnx

#################################################
ort-plot_torch_export_script-cuda-aot0.onnx
#################################################
opset: domain=&#39;&#39; version=17
opset: domain=&#39;ai.onnx.ml&#39; version=4
opset: domain=&#39;ai.onnx.training&#39; version=1
opset: domain=&#39;ai.onnx.preview.training&#39; version=1
opset: domain=&#39;com.microsoft&#39; version=1
opset: domain=&#39;com.microsoft.experimental&#39; version=1
opset: domain=&#39;com.microsoft.nchwc&#39; version=1
opset: domain=&#39;org.pytorch.aten&#39; version=1
input: name=&#39;input&#39; type=dtype(&#39;float32&#39;) shape=[1, 1, 128, 128]
init: name=&#39;conv1.weight&#39; type=dtype(&#39;float32&#39;) shape=(128, 1, 5, 5)
init: name=&#39;conv1.bias&#39; type=dtype(&#39;float32&#39;) shape=(128,)
init: name=&#39;conv2.weight&#39; type=dtype(&#39;float32&#39;) shape=(16, 128, 5, 5)
init: name=&#39;conv2.bias&#39; type=dtype(&#39;float32&#39;) shape=(16,)
init: name=&#39;fc1.weight&#39; type=dtype(&#39;float32&#39;) shape=(1024, 13456)
init: name=&#39;fc1.bias&#39; type=dtype(&#39;float32&#39;) shape=(1024,)
init: name=&#39;fc2.weight&#39; type=dtype(&#39;float32&#39;) shape=(128, 1024)
init: name=&#39;fc2.bias&#39; type=dtype(&#39;float32&#39;) shape=(128,)
init: name=&#39;fc3.weight&#39; type=dtype(&#39;float32&#39;) shape=(10, 128)
init: name=&#39;fc3.bias&#39; type=dtype(&#39;float32&#39;) shape=(10,)
FusedConv[com.microsoft](input, conv1.weight, conv1.bias, activation=b&#39;Relu&#39;, auto_pad=b&#39;NOTSET&#39;, dilations=[1,1], group=1, strides=[1,1], kernel_shape=[5,5], pads=[0,0,0,0]) -&gt; /Relu_output_0
  MaxPool(/Relu_output_0, storage_order=0, ceil_mode=0, kernel_shape=[2,2], pads=[0,0,0,0], auto_pad=b&#39;NOTSET&#39;, strides=[2,2]) -&gt; /MaxPool_output_0
    FusedConv[com.microsoft](/MaxPool_output_0, conv2.weight, conv2.bias, activation=b&#39;Relu&#39;, auto_pad=b&#39;NOTSET&#39;, dilations=[1,1], group=1, strides=[1,1], kernel_shape=[5,5], pads=[0,0,0,0]) -&gt; /Relu_1_output_0
      MaxPool(/Relu_1_output_0, storage_order=0, ceil_mode=0, kernel_shape=[2,2], pads=[0,0,0,0], auto_pad=b&#39;NOTSET&#39;, strides=[2,2]) -&gt; /MaxPool_1_output_0
        Flatten(/MaxPool_1_output_0, axis=1) -&gt; /Flatten_output_0
          Gemm(/Flatten_output_0, fc1.weight, fc1.bias, alpha=1.00, beta=1.00, transA=0, transB=1) -&gt; /fc1/Gemm_output_0
            Relu(/fc1/Gemm_output_0) -&gt; /Relu_2_output_0
              Gemm(/Relu_2_output_0, fc2.weight, fc2.bias, alpha=1.00, beta=1.00, transA=0, transB=1) -&gt; /fc2/Gemm_output_0
                Relu(/fc2/Gemm_output_0) -&gt; /Relu_3_output_0
                  Gemm(/Relu_3_output_0, fc3.weight, fc3.bias, alpha=1.00, beta=1.00, transA=0, transB=1) -&gt; 22
output: name=&#39;22&#39; type=dtype(&#39;float32&#39;) shape=[1, 10]
skip2 ort-plot_torch_export_dynamo-cuda-aot0.onnx
skip2 ort-plot_torch_export_dynopt-cpu-aot0.onnx

#################################################
ort-plot_torch_export_cus_p2-cuda-aot0.onnx
#################################################
opset: domain=&#39;&#39; version=18
opset: domain=&#39;ai.onnx.ml&#39; version=4
opset: domain=&#39;ai.onnx.training&#39; version=1
opset: domain=&#39;ai.onnx.preview.training&#39; version=1
opset: domain=&#39;com.microsoft&#39; version=1
opset: domain=&#39;com.microsoft.experimental&#39; version=1
opset: domain=&#39;com.microsoft.nchwc&#39; version=1
opset: domain=&#39;org.pytorch.aten&#39; version=1
input: name=&#39;input&#39; type=dtype(&#39;float32&#39;) shape=[1, 1, 128, 128]
init: name=&#39;arg0_1&#39; type=dtype(&#39;float32&#39;) shape=(128, 1, 5, 5)
init: name=&#39;arg1_1&#39; type=dtype(&#39;float32&#39;) shape=(128,)
init: name=&#39;arg2_1&#39; type=dtype(&#39;float32&#39;) shape=(16, 128, 5, 5)
init: name=&#39;arg3_1&#39; type=dtype(&#39;float32&#39;) shape=(16,)
init: name=&#39;arg5_1&#39; type=dtype(&#39;float32&#39;) shape=(1024,)
init: name=&#39;arg7_1&#39; type=dtype(&#39;float32&#39;) shape=(128,)
init: name=&#39;arg9_1&#39; type=dtype(&#39;float32&#39;) shape=(10,)
init: name=&#39;ortshared_7_1_2_0_token_8&#39; type=dtype(&#39;int64&#39;) shape=(2,) -- array([    1, 13456])
init: name=&#39;permute&#39; type=dtype(&#39;float32&#39;) shape=(13456, 1024)
init: name=&#39;permute_1&#39; type=dtype(&#39;float32&#39;) shape=(1024, 128)
init: name=&#39;permute_2&#39; type=dtype(&#39;float32&#39;) shape=(128, 10)
FusedConv[com.microsoft](input, arg0_1, arg1_1, activation=b&#39;Relu&#39;, dilations=[1,1], group=1, strides=[1,1], pads=[0,0,0,0], auto_pad=b&#39;NOTSET&#39;) -&gt; relu
  MaxPool(relu, storage_order=0, auto_pad=b&#39;NOTSET&#39;, ceil_mode=0, dilations=[1,1], kernel_shape=[2,2], pads=[0,0,0,0], strides=[2,2]) -&gt; _onx_maxpool0, _onx_maxpool1
    FusedConv[com.microsoft](_onx_maxpool0, arg2_1, arg3_1, activation=b&#39;Relu&#39;, dilations=[1,1], group=1, strides=[1,1], pads=[0,0,0,0], auto_pad=b&#39;NOTSET&#39;) -&gt; relu_1
      MaxPool(relu_1, storage_order=0, auto_pad=b&#39;NOTSET&#39;, ceil_mode=0, dilations=[1,1], kernel_shape=[2,2], pads=[0,0,0,0], strides=[2,2]) -&gt; _onx_maxpool03, _onx_maxpool13
        Reshape(_onx_maxpool03, ortshared_7_1_2_0_token_8, allowzero=0) -&gt; view
          Gemm(view, permute, arg5_1, transB=0, transA=0, alpha=1.00, beta=1.00) -&gt; addmm
            Relu(addmm) -&gt; relu_2
              Gemm(relu_2, permute_1, arg7_1, transB=0, transA=0, alpha=1.00, beta=1.00) -&gt; addmm_1
                Relu(addmm_1) -&gt; relu_3
                  Gemm(relu_3, permute_2, arg9_1, transB=0, transA=0, alpha=1.00, beta=1.00) -&gt; output
output: name=&#39;output&#39; type=dtype(&#39;float32&#39;) shape=[1, 10]
skip2 ort-plot_torch_export_dynopt-cuda-aot0.onnx
skip3 ort-plot_torch_export_dynamo-cpu-aot1.onnx

#################################################
ort-plot_torch_export_script-cuda-aot1.onnx
#################################################
opset: domain=&#39;&#39; version=17
opset: domain=&#39;ai.onnx.ml&#39; version=4
opset: domain=&#39;ai.onnx.training&#39; version=1
opset: domain=&#39;ai.onnx.preview.training&#39; version=1
opset: domain=&#39;com.microsoft&#39; version=1
opset: domain=&#39;com.microsoft.experimental&#39; version=1
opset: domain=&#39;com.microsoft.nchwc&#39; version=1
opset: domain=&#39;org.pytorch.aten&#39; version=1
input: name=&#39;input&#39; type=dtype(&#39;float32&#39;) shape=[1, 1, 128, 128]
init: name=&#39;conv1.weight&#39; type=dtype(&#39;float32&#39;) shape=(128, 1, 5, 5)
init: name=&#39;conv1.bias&#39; type=dtype(&#39;float32&#39;) shape=(128,)
init: name=&#39;conv2.weight&#39; type=dtype(&#39;float32&#39;) shape=(16, 128, 5, 5)
init: name=&#39;conv2.bias&#39; type=dtype(&#39;float32&#39;) shape=(16,)
init: name=&#39;fc1.weight&#39; type=dtype(&#39;float32&#39;) shape=(1024, 13456)
init: name=&#39;fc1.bias&#39; type=dtype(&#39;float32&#39;) shape=(1024,)
init: name=&#39;fc2.weight&#39; type=dtype(&#39;float32&#39;) shape=(128, 1024)
init: name=&#39;fc2.bias&#39; type=dtype(&#39;float32&#39;) shape=(128,)
init: name=&#39;fc3.weight&#39; type=dtype(&#39;float32&#39;) shape=(10, 128)
init: name=&#39;fc3.bias&#39; type=dtype(&#39;float32&#39;) shape=(10,)
FusedConv[com.microsoft](input, conv1.weight, conv1.bias, activation=b&#39;Relu&#39;, auto_pad=b&#39;NOTSET&#39;, dilations=[1,1], group=1, strides=[1,1], kernel_shape=[5,5], pads=[0,0,0,0]) -&gt; /Relu_output_0
  MaxPool(/Relu_output_0, storage_order=0, ceil_mode=0, kernel_shape=[2,2], pads=[0,0,0,0], auto_pad=b&#39;NOTSET&#39;, strides=[2,2]) -&gt; /MaxPool_output_0
    FusedConv[com.microsoft](/MaxPool_output_0, conv2.weight, conv2.bias, activation=b&#39;Relu&#39;, auto_pad=b&#39;NOTSET&#39;, dilations=[1,1], group=1, strides=[1,1], kernel_shape=[5,5], pads=[0,0,0,0]) -&gt; /Relu_1_output_0
      MaxPool(/Relu_1_output_0, storage_order=0, ceil_mode=0, kernel_shape=[2,2], pads=[0,0,0,0], auto_pad=b&#39;NOTSET&#39;, strides=[2,2]) -&gt; /MaxPool_1_output_0
        Flatten(/MaxPool_1_output_0, axis=1) -&gt; /Flatten_output_0
          Gemm(/Flatten_output_0, fc1.weight, fc1.bias, alpha=1.00, beta=1.00, transA=0, transB=1) -&gt; /fc1/Gemm_output_0
            Relu(/fc1/Gemm_output_0) -&gt; /Relu_2_output_0
              Gemm(/Relu_2_output_0, fc2.weight, fc2.bias, alpha=1.00, beta=1.00, transA=0, transB=1) -&gt; /fc2/Gemm_output_0
                Relu(/fc2/Gemm_output_0) -&gt; /Relu_3_output_0
                  Gemm(/Relu_3_output_0, fc3.weight, fc3.bias, alpha=1.00, beta=1.00, transA=0, transB=1) -&gt; 22
output: name=&#39;22&#39; type=dtype(&#39;float32&#39;) shape=[1, 10]
skip1 ort-plot_torch_export_cus_p0-cuda-aot1.onnx

#################################################
ort-plot_torch_export_script-cpu-aot1.onnx
#################################################
opset: domain=&#39;&#39; version=17
opset: domain=&#39;ai.onnx.ml&#39; version=4
opset: domain=&#39;ai.onnx.training&#39; version=1
opset: domain=&#39;ai.onnx.preview.training&#39; version=1
opset: domain=&#39;com.microsoft&#39; version=1
opset: domain=&#39;com.microsoft.experimental&#39; version=1
opset: domain=&#39;com.microsoft.nchwc&#39; version=1
opset: domain=&#39;org.pytorch.aten&#39; version=1
input: name=&#39;input&#39; type=dtype(&#39;float32&#39;) shape=[1, 1, 128, 128]
init: name=&#39;reorder&#39; type=dtype(&#39;float32&#39;) shape=(128, 1, 5, 5)
init: name=&#39;conv1.bias&#39; type=dtype(&#39;float32&#39;) shape=(128,)
init: name=&#39;reorder_token_2&#39; type=dtype(&#39;float32&#39;) shape=(16, 128, 5, 5)
init: name=&#39;conv2.bias&#39; type=dtype(&#39;float32&#39;) shape=(16,)
init: name=&#39;fc1.weight&#39; type=dtype(&#39;float32&#39;) shape=(1024, 13456)
init: name=&#39;fc1.bias&#39; type=dtype(&#39;float32&#39;) shape=(1024,)
init: name=&#39;fc2.weight&#39; type=dtype(&#39;float32&#39;) shape=(128, 1024)
init: name=&#39;fc2.bias&#39; type=dtype(&#39;float32&#39;) shape=(128,)
init: name=&#39;fc3.weight&#39; type=dtype(&#39;float32&#39;) shape=(10, 128)
init: name=&#39;fc3.bias&#39; type=dtype(&#39;float32&#39;) shape=(10,)
Conv[com.microsoft.nchwc](input, reorder, conv1.bias, activation=b&#39;Relu&#39;, auto_pad=b&#39;NOTSET&#39;, dilations=[1,1], group=1, strides=[1,1], kernel_shape=[5,5], pads=[0,0,0,0]) -&gt; reorder_token_0
  MaxPool[com.microsoft.nchwc](reorder_token_0, storage_order=0, ceil_mode=0, kernel_shape=[2,2], pads=[0,0,0,0], auto_pad=b&#39;NOTSET&#39;, strides=[2,2]) -&gt; reorder_token_1
    Conv[com.microsoft.nchwc](reorder_token_1, reorder_token_2, conv2.bias, activation=b&#39;Relu&#39;, auto_pad=b&#39;NOTSET&#39;, dilations=[1,1], group=1, strides=[1,1], kernel_shape=[5,5], pads=[0,0,0,0]) -&gt; reorder_token_3
      MaxPool[com.microsoft.nchwc](reorder_token_3, storage_order=0, ceil_mode=0, kernel_shape=[2,2], pads=[0,0,0,0], auto_pad=b&#39;NOTSET&#39;, strides=[2,2]) -&gt; reorder_token_4
        ReorderOutput[com.microsoft.nchwc](reorder_token_4, channels_last=0, channels=16) -&gt; /MaxPool_1_output_0
          Flatten(/MaxPool_1_output_0, axis=1) -&gt; /Flatten_output_0
            FusedGemm[com.microsoft](/Flatten_output_0, fc1.weight, fc1.bias, activation=b&#39;Relu&#39;, alpha=1.00, beta=1.00, transA=0, transB=1) -&gt; /Relu_2_output_0
              FusedGemm[com.microsoft](/Relu_2_output_0, fc2.weight, fc2.bias, activation=b&#39;Relu&#39;, alpha=1.00, beta=1.00, transA=0, transB=1) -&gt; /Relu_3_output_0
                Gemm(/Relu_3_output_0, fc3.weight, fc3.bias, alpha=1.00, beta=1.00, transA=0, transB=1) -&gt; 22
output: name=&#39;22&#39; type=dtype(&#39;float32&#39;) shape=[1, 10]
done.
</pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (1 minutes 45.965 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-plot-torch-export-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/0534a82190ecce5d98ccd3b019bd1c7a/plot_torch_export.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_torch_export.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/5ea159170a8b6e6d090b561d7986469d/plot_torch_export.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_torch_export.py</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="../CHANGELOGS.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Change Logs</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="index.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Example gallery</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2023, Xavier Dupré
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Evaluate different ways to export a torch model to ONNX</a><ul>
<li><a class="reference internal" href="#some-helpers">Some helpers</a></li>
<li><a class="reference internal" href="#the-model">The model</a></li>
<li><a class="reference internal" href="#the-exporters">The exporters</a></li>
<li><a class="reference internal" href="#exporter-speed">Exporter speed</a></li>
<li><a class="reference internal" href="#profiling">Profiling</a></li>
<li><a class="reference internal" href="#benchmark">Benchmark</a></li>
<li><a class="reference internal" href="#show-the-interesting-models">Show the interesting models</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js?v=c88f2e48"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=4825356b"></script>
    <script src="../_static/scripts/furo.js?v=32e29ea5"></script>
    </body>
</html>