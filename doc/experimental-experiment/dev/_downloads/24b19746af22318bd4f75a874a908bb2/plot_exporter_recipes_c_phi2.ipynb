{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# to_onnx and Phi-2\n\nExports model [Phi-2](https://huggingface.co/microsoft/phi-2).\nWe use a dummy model. The main difficulty is to set the dynamic shapes properly.\nIf there is an issue, you can go to the following line:\n[torch/fx/experimental/symbolic_shapes.py#L5965](https://github.com/pytorch/pytorch/blob/main/torch/fx/experimental/symbolic_shapes.py#L5965)\nand look for ``log.info(\"set_replacement %s = %s (%s) %s\", a, tgt, msg, tgt_bound)`` and add\nbefore or after, something like:\n\n::\n\n    if isinstance(tgt, int):\n        raise AssertionError(\n            f\"dynamic shape becomes a constant \"\n            f\"{[a, tgt, type(tgt), msg, tgt_bound]}\"\n        )\n\nAdding ``TORCH_LOGS=\"+dynamo\" TORCHDYNAMO_VERBOSE=1`` prints out more information\nabout dynamic shapes.\n\n## Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import copy\nfrom typing import Any, Dict\nimport onnx\nimport torch\nimport transformers\nfrom onnx_array_api.plotting.graphviz_helper import plot_dot\nfrom experimental_experiment.helpers import string_type\nfrom experimental_experiment.xbuilder import GraphBuilder, InferShapesOptions\nfrom experimental_experiment.torch_interpreter import to_onnx, ExportOptions\n\n\ndef get_phi2_untrained(batch_size: int = 2, **kwargs) -> Dict[str, Any]:\n    \"\"\"\n    Gets a non initialized model with its inputs\n\n    :param batch_size: batch size\n    :param kwargs: to overwrite the configuration, example ``num_hidden_layers=1``\n    :return: dictionary\n\n    See `Phi-2/config.json\n    <https://huggingface.co/microsoft/phi-2/blob/main/config.json>`_.\n    \"\"\"\n    config = {\n        \"_name_or_path\": \"microsoft/phi-2\",\n        \"architectures\": [\"PhiForCausalLM\"],\n        \"attention_dropout\": 0.0,\n        \"bos_token_id\": 50256,\n        \"embd_pdrop\": 0.0,\n        \"eos_token_id\": 50256,\n        \"hidden_act\": \"gelu_new\",\n        \"hidden_size\": 2560,\n        \"initializer_range\": 0.02,\n        \"intermediate_size\": 10240,\n        \"layer_norm_eps\": 1e-05,\n        \"max_position_embeddings\": 2048,\n        \"model_type\": \"phi\",\n        \"num_attention_heads\": 32,\n        \"num_hidden_layers\": 32,\n        \"num_key_value_heads\": 32,\n        \"partial_rotary_factor\": 0.4,\n        \"qk_layernorm\": False,\n        \"resid_pdrop\": 0.1,\n        \"rope_scaling\": None,\n        \"rope_theta\": 10000.0,\n        \"tie_word_embeddings\": False,\n        \"torch_dtype\": \"float16\",\n        \"transformers_version\": \"4.37.0\",\n        \"use_cache\": True,\n        \"vocab_size\": 51200,\n    }\n    config.update(**kwargs)\n    conf = transformers.PhiConfig(**config)\n    model = transformers.PhiForCausalLM(conf)\n    model.eval()\n\n    batch = torch.export.Dim(\"batch\")\n    seq_length = torch.export.Dim(\"seq_length\")\n    shapes = {}\n\n    cache = transformers.cache_utils.DynamicCache(config[\"num_hidden_layers\"])\n    for i in range(config[\"num_hidden_layers\"]):\n        cache.update(\n            torch.randn(batch_size, 32, 30, 80), torch.randn(batch_size, 32, 30, 80), i\n        )\n    cache2 = transformers.cache_utils.DynamicCache(config[\"num_hidden_layers\"])\n    for i in range(config[\"num_hidden_layers\"]):\n        cache2.update(\n            torch.randn(batch_size + 1, 32, 31, 80),\n            torch.randn(batch_size + 1, 32, 31, 80),\n            i,\n        )\n\n    inputs = dict(\n        input_ids=torch.randint(0, 50285, (batch_size, 3)).to(torch.int64),\n        attention_mask=torch.ones((batch_size, 33)).to(torch.int64),\n        past_key_values=cache,\n    )\n    inputs2 = dict(\n        input_ids=torch.randint(0, 50285, (batch_size + 1, 4)).to(torch.int64),\n        attention_mask=torch.ones((batch_size + 1, 35)).to(torch.int64),\n        past_key_values=cache2,\n    )\n    n = len(cache.key_cache)\n    cache_length = torch.export.Dim(\"cache_length\")\n    shapes.update(\n        {\n            \"input_ids\": {0: batch, 1: seq_length},\n            \"attention_mask\": {\n                0: batch,\n                1: torch.export.Dim.DYNAMIC,  # cache_length + seq_length\n            },\n            \"past_key_values\": [\n                [{0: batch, 2: cache_length} for _ in range(n)],  # 0: batch,\n                [{0: batch, 2: cache_length} for _ in range(n)],  # 0: batch,\n            ],\n        }\n    )\n\n    return dict(inputs=inputs, model=model, dynamic_shapes=shapes, inputs2=inputs2)\n\n\ndata = get_phi2_untrained(num_hidden_layers=2)\nmodel = data[\"model\"]\ninputs = data[\"inputs\"]\ndynamic_shapes = data[\"dynamic_shapes\"]\n\nprint(\"inputs\", string_type(inputs, with_shape=True))\nprint(\"dynamic_shapes\", dynamic_shapes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's check it is working.\nWe need to copy the input before calling the model\nbecause it modified the inputs and they are not properly\nset up when the export starts.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model(**copy.deepcopy(inputs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export\n\nWe try to export with :func:`experimental_experiment.torch_interpreter.to_onnx`.\n\n``to_onnx(model, (), kwargs=copy.deepcopy(inputs), dynamic_shapes=dynamic_shapes)``\n\nThis fails because of dynamic shapes issues.\n\n::\n\n  Constraints violated (batch, seq_length)! For more information,\n  run with TORCH_LOGS=\"+dynamic\".\n  Cannot associate shape\n      [[{0: <class '__main__.batch'>, 2: <class '__main__.cache_length'>},\n        {0: <class '__main__.batch'>, 2: <class '__main__.cache_length'>}],\n       [{0: <class '__main__.batch'>, 2: <class '__main__.cache_length'>},\n        {0: <class '__main__.batch'>, 2: <class '__main__.cache_length'>}]]\n      specified at `dynamic_shapes['past_key_values']`\n          to non-tensor type <class 'transformers.cache_utils.DynamicCache'>\n          at `inputs['past_key_values']` (expected None)\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The export fails for a couple of reason but it is possible to patch the\ncode to make it work. All those modifications are put in place by\n:func:`onnx_export_errors <experimental_experiment.torch_interpreter.onnx_export_errors>`\nand reverted after the export is done. Among other things, this function registers\nserialization functions as shown in example\n`l-plot-torch-export-with-dynamic-cache-201`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from experimental_experiment.torch_interpreter.onnx_export_errors import (\n    bypass_export_some_errors,\n)\n\nwith bypass_export_some_errors(\n    patch_transformers=True, replace_dynamic_cache=True, verbose=1\n) as modificator:\n    print(\"inputs before\", string_type(inputs, with_shape=True))\n    inputs = modificator(inputs)\n    print(\"inputs after\", string_type(inputs, with_shape=True))\n    # ep = torch.export.export(model, (), inputs, dynamic_shapes=dynamic_shapes, strict=False)\n    large_onx = to_onnx(\n        model,\n        (),\n        inputs,\n        dynamic_shapes=dynamic_shapes,\n        export_options=ExportOptions(strict=False),\n        large_model=True,\n    )\n    large_onx.save(\"plot_exporter_recipes_c_phi2.onnx\", all_tensors_to_one_file=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's display the model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "onx = onnx.load(\"plot_exporter_recipes_c_phi2.onnx\")\ngr = GraphBuilder(onx, infer_shapes_options=InferShapesOptions.NONE)\nprint(gr.pretty_text())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visually.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot_dot(onx)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}