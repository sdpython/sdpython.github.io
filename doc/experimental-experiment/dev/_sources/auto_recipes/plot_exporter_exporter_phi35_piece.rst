
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_recipes/plot_exporter_exporter_phi35_piece.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_recipes_plot_exporter_exporter_phi35_piece.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_recipes_plot_exporter_exporter_phi35_piece.py:


.. _l-plot-exporter-exporter-phi35-piece:

Export Phi-3.5-mini-instruct piece by piece
===========================================

:func:`torch.export.export` often breaks on big models because there
are control flows or instructions breaking the propagation of
dynamic shapes (see ...). The function usually gives an indication where
the model implementation can be fixed but in case, that is not possible,
we can try to export the model piece by piece: every module
is converted separately from its submodule. A model can be exported even
if one of its submodules cannot.

Model
+++++

.. GENERATED FROM PYTHON SOURCE LINES 18-213

.. code-block:: Python


    import pprint
    from typing import Any, Dict
    import torch
    import torch._export.tools
    import transformers
    from onnx_diagnostic.helpers.cache_helper import make_dynamic_cache
    from experimental_experiment.helpers import string_type
    from experimental_experiment.torch_interpreter.piece_by_piece import (
        trace_execution_piece_by_piece,
    )


    def get_phi35_untrained(batch_size: int = 2, **kwargs) -> Dict[str, Any]:
        """
        Gets a non initialized model with two sets of inputs and different shapes.

        :param batch_size: batch size
        :param kwargs: to overwrite the configuration, example ``num_hidden_layers=1``
        :return: dictionary

        See `Phi-3.5-mini-instruct/config.json
        <https://huggingface.co/microsoft/Phi-3.5-mini-instruct/blob/main/config.json>`_.
        """
        config = {
            "_name_or_path": "Phi-3.5-mini-instruct",
            "architectures": ["Phi3ForCausalLM"],
            "attention_dropout": 0.0,
            "auto_map": {
                "AutoConfig": "configuration_phi3.Phi3Config",
                "AutoModelForCausalLM": "modeling_phi3.Phi3ForCausalLM",
            },
            "bos_token_id": 1,
            "embd_pdrop": 0.0,
            "eos_token_id": 32000,
            "hidden_act": "silu",
            "hidden_size": 3072,
            "initializer_range": 0.02,
            "intermediate_size": 8192,
            "max_position_embeddings": 131072,
            "model_type": "phi3",
            "num_attention_heads": 32,
            "num_hidden_layers": 32,
            "num_key_value_heads": 32,
            "original_max_position_embeddings": 4096,
            "pad_token_id": 32000,
            "resid_pdrop": 0.0,
            "rms_norm_eps": 1e-05,
            "rope_scaling": {
                "long_factor": [
                    1.0800000429153442,
                    1.1100000143051147,
                    1.1399999856948853,
                    1.340000033378601,
                    1.5899999141693115,
                    1.600000023841858,
                    1.6200000047683716,
                    2.620000123977661,
                    3.2300000190734863,
                    3.2300000190734863,
                    4.789999961853027,
                    7.400000095367432,
                    7.700000286102295,
                    9.09000015258789,
                    12.199999809265137,
                    17.670000076293945,
                    24.46000099182129,
                    28.57000160217285,
                    30.420001983642578,
                    30.840002059936523,
                    32.590003967285156,
                    32.93000411987305,
                    42.320003509521484,
                    44.96000289916992,
                    50.340003967285156,
                    50.45000457763672,
                    57.55000305175781,
                    57.93000411987305,
                    58.21000289916992,
                    60.1400032043457,
                    62.61000442504883,
                    62.62000274658203,
                    62.71000289916992,
                    63.1400032043457,
                    63.1400032043457,
                    63.77000427246094,
                    63.93000411987305,
                    63.96000289916992,
                    63.970001220703125,
                    64.02999877929688,
                    64.06999969482422,
                    64.08000183105469,
                    64.12000274658203,
                    64.41000366210938,
                    64.4800033569336,
                    64.51000213623047,
                    64.52999877929688,
                    64.83999633789062,
                ],
                "short_factor": [
                    1.0,
                    1.0199999809265137,
                    1.0299999713897705,
                    1.0299999713897705,
                    1.0499999523162842,
                    1.0499999523162842,
                    1.0499999523162842,
                    1.0499999523162842,
                    1.0499999523162842,
                    1.0699999332427979,
                    1.0999999046325684,
                    1.1099998950958252,
                    1.1599998474121094,
                    1.1599998474121094,
                    1.1699998378753662,
                    1.2899998426437378,
                    1.339999794960022,
                    1.679999828338623,
                    1.7899998426437378,
                    1.8199998140335083,
                    1.8499997854232788,
                    1.8799997568130493,
                    1.9099997282028198,
                    1.9399996995925903,
                    1.9899996519088745,
                    2.0199997425079346,
                    2.0199997425079346,
                    2.0199997425079346,
                    2.0199997425079346,
                    2.0199997425079346,
                    2.0199997425079346,
                    2.0299997329711914,
                    2.0299997329711914,
                    2.0299997329711914,
                    2.0299997329711914,
                    2.0299997329711914,
                    2.0299997329711914,
                    2.0299997329711914,
                    2.0299997329711914,
                    2.0299997329711914,
                    2.0799996852874756,
                    2.0899996757507324,
                    2.189999580383301,
                    2.2199995517730713,
                    2.5899994373321533,
                    2.729999542236328,
                    2.749999523162842,
                    2.8399994373321533,
                ],
                "type": "longrope",
            },
            "rope_theta": 10000.0,
            "sliding_window": 262144,
            "tie_word_embeddings": False,
            "torch_dtype": "bfloat16",
            "use_cache": True,
            "attention_bias": False,
            "vocab_size": 32064,
        }
        config.update(**kwargs)
        conf = transformers.Phi3Config(**config)
        model = transformers.Phi3ForCausalLM(conf)
        model.eval()

        cache = make_dynamic_cache(
            [
                (torch.randn(batch_size, 32, 30, 96), torch.randn(batch_size, 32, 30, 96))
                for i in range(config["num_hidden_layers"])
            ]
        )
        cache2 = make_dynamic_cache(
            [
                (torch.randn(batch_size + 1, 32, 31, 96), torch.randn(batch_size + 1, 32, 31, 96))
                for i in range(config["num_hidden_layers"])
            ]
        )

        inputs = dict(
            input_ids=torch.randint(0, 32064, (batch_size, 3)).to(torch.int64),
            attention_mask=torch.ones((batch_size, 33)).to(torch.int64),
            past_key_values=cache,
        )
        inputs2 = dict(
            input_ids=torch.randint(0, 32064, (batch_size + 1, 4)).to(torch.int64),
            attention_mask=torch.ones((batch_size + 1, 35)).to(torch.int64),
            past_key_values=cache2,
        )
        return dict(inputs=inputs, model=model, inputs2=inputs2)


    data = get_phi35_untrained(num_hidden_layers=2)
    model, inputs, inputs2 = data["model"], data["inputs"], data["inputs2"]

    print(string_type(inputs, with_shape=True))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    dict(input_ids:T7s2x3,attention_mask:T7s2x33,past_key_values:DynamicCache(key_cache=#2[T1s2x32x30x96,T1s2x32x30x96], value_cache=#2[T1s2x32x30x96,T1s2x32x30x96]))




.. GENERATED FROM PYTHON SOURCE LINES 214-221

Dynamic Shapes
++++++++++++++

We want to infer the dynamic shapes from the two sets of inputs we gave.
For that, we use a function to trace the execution of the model
including its submodules. It is going to execute the model twice
with the two sets of inputs and stores every intermediate input and output.

.. GENERATED FROM PYTHON SOURCE LINES 221-224

.. code-block:: Python


    diag = trace_execution_piece_by_piece(model, [inputs, inputs2], verbose=2)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [_trace_forward_execution] -trace-  M:__main__-Phi3ForCausalLM.forward
    [_trace_forward_execution] -trace- .. M:model-Phi3Model.forward
    [_trace_forward_execution] -trace- .... M:embed_tokens-Embedding.forward
    [_trace_forward_execution] -trace- .... M:layers[0]-Phi3DecoderLayer.forward
    [_trace_forward_execution] -trace- ...... M:self_attn-Phi3Attention.forward
    [_trace_forward_execution] -trace- ........ M:o_proj-Linear.forward
    [_trace_forward_execution] -trace- ........ M:qkv_proj-Linear.forward
    [_trace_forward_execution] -trace- ...... M:mlp-Phi3MLP.forward
    [_trace_forward_execution] -trace- ........ M:gate_up_proj-Linear.forward
    [_trace_forward_execution] -trace- ........ M:down_proj-Linear.forward
    [_trace_forward_execution] -trace- ........ M:activation_fn-SiLUActivation.forward
    [_trace_forward_execution] -trace- ...... M:input_layernorm-Phi3RMSNorm.forward
    [_trace_forward_execution] -trace- ...... M:post_attention_layernorm-Phi3RMSNorm.forward
    [_trace_forward_execution] -trace- ...... M:resid_attn_dropout-Dropout.forward
    [_trace_forward_execution] -trace- ...... M:resid_mlp_dropout-Dropout.forward
    [_trace_forward_execution] -trace- .... M:layers[1]-Phi3DecoderLayer.forward
    [_trace_forward_execution] -trace- ...... M:self_attn-Phi3Attention.forward
    [_trace_forward_execution] -trace- ........ M:o_proj-Linear.forward
    [_trace_forward_execution] -trace- ........ M:qkv_proj-Linear.forward
    [_trace_forward_execution] -trace- ...... M:mlp-Phi3MLP.forward
    [_trace_forward_execution] -trace- ........ M:gate_up_proj-Linear.forward
    [_trace_forward_execution] -trace- ........ M:down_proj-Linear.forward
    [_trace_forward_execution] -trace- ........ M:activation_fn-SiLUActivation.forward
    [_trace_forward_execution] -trace- ...... M:input_layernorm-Phi3RMSNorm.forward
    [_trace_forward_execution] -trace- ...... M:post_attention_layernorm-Phi3RMSNorm.forward
    [_trace_forward_execution] -trace- ...... M:resid_attn_dropout-Dropout.forward
    [_trace_forward_execution] -trace- ...... M:resid_mlp_dropout-Dropout.forward
    [_trace_forward_execution] -trace- .... M:norm-Phi3RMSNorm.forward
    [_trace_forward_execution] -trace- .... M:rotary_emb-Phi3RotaryEmbedding.forward
    [_trace_forward_execution] -trace- .. M:lm_head-Linear.forward
    [trace_execution_piece_by_piece] run with dict(args:(),kwargs:dict(input_ids:T7s2x3,attention_mask:T7s2x33,past_key_values:DynamicCache(key_cache=#2[T1s2x32x30x96,T1s2x32x30x96], value_cache=#2[T1s2x32x30x96,T1s2x32x30x96])))
    [__main__:Phi3ForCausalLM] > **dict(input_ids:T7r2,attention_mask:T7r2,past_key_values:DynamicCache(key_cache=#2[T1r4,T1r4], value_cache=#2[T1r4,T1r4]))
    [model:Phi3Model]   > **dict(input_ids:T7r2,attention_mask:T7r2,position_ids:None,past_key_values:DynamicCache(key_cache=#2[T1r4,T1r4], value_cache=#2[T1r4,T1r4]),inputs_embeds:None,use_cache:None,cache_position:None)
    [embed_tokens:Embedding]     > T7r2
    [embed_tokens:Embedding]     < T1r3
    [rotary_emb:Phi3RotaryEmbedding]     > *(T1r3,), **dict(position_ids:T7r2)
    [rotary_emb:Phi3RotaryEmbedding]     < *(T1r3,T1r3)
    [layers[0]:Phi3DecoderLayer]     > *(T1r3,), **dict(attention_mask:T9r4,position_ids:T7r2,past_key_values:DynamicCache(key_cache=#2[T1r4,T1r4], value_cache=#2[T1r4,T1r4]),use_cache:bool,cache_position:T7r1,position_embeddings:(T1r3,T1r3))
    [input_layernorm:Phi3RMSNorm]       > T1r3
    [input_layernorm:Phi3RMSNorm]       < T1r3
    [self_attn:Phi3Attention]       > **dict(hidden_states:T1r3,attention_mask:T9r4,position_ids:T7r2,past_key_values:DynamicCache(key_cache=#2[T1r4,T1r4], value_cache=#2[T1r4,T1r4]),use_cache:bool,cache_position:T7r1,position_embeddings:(T1r3,T1r3))
    [qkv_proj:Linear]         > T1r3
    [qkv_proj:Linear]         < T1r3
    [o_proj:Linear]         > T1r3
    [o_proj:Linear]         < T1r3
    [self_attn:Phi3Attention]       < *(T1r3,None)
    [resid_attn_dropout:Dropout]       > T1r3
    [resid_attn_dropout:Dropout]       < T1r3
    [post_attention_layernorm:Phi3RMSNorm]       > T1r3
    [post_attention_layernorm:Phi3RMSNorm]       < T1r3
    [mlp:Phi3MLP]       > T1r3
    [gate_up_proj:Linear]         > T1r3
    [gate_up_proj:Linear]         < T1r3
    [activation_fn:SiLUActivation]         > T1r3
    [activation_fn:SiLUActivation]         < T1r3
    [down_proj:Linear]         > T1r3
    [down_proj:Linear]         < T1r3
    [mlp:Phi3MLP]       < T1r3
    [resid_mlp_dropout:Dropout]       > T1r3
    [resid_mlp_dropout:Dropout]       < T1r3
    [layers[0]:Phi3DecoderLayer]     < T1r3
    [layers[1]:Phi3DecoderLayer]     > *(T1r3,), **dict(attention_mask:T9r4,position_ids:T7r2,past_key_values:DynamicCache(key_cache=#2[T1r4,T1r4], value_cache=#2[T1r4,T1r4]),use_cache:bool,cache_position:T7r1,position_embeddings:(T1r3,T1r3))
    [input_layernorm:Phi3RMSNorm]       > T1r3
    [input_layernorm:Phi3RMSNorm]       < T1r3
    [self_attn:Phi3Attention]       > **dict(hidden_states:T1r3,attention_mask:T9r4,position_ids:T7r2,past_key_values:DynamicCache(key_cache=#2[T1r4,T1r4], value_cache=#2[T1r4,T1r4]),use_cache:bool,cache_position:T7r1,position_embeddings:(T1r3,T1r3))
    [qkv_proj:Linear]         > T1r3
    [qkv_proj:Linear]         < T1r3
    [o_proj:Linear]         > T1r3
    [o_proj:Linear]         < T1r3
    [self_attn:Phi3Attention]       < *(T1r3,None)
    [resid_attn_dropout:Dropout]       > T1r3
    [resid_attn_dropout:Dropout]       < T1r3
    [post_attention_layernorm:Phi3RMSNorm]       > T1r3
    [post_attention_layernorm:Phi3RMSNorm]       < T1r3
    [mlp:Phi3MLP]       > T1r3
    [gate_up_proj:Linear]         > T1r3
    [gate_up_proj:Linear]         < T1r3
    [activation_fn:SiLUActivation]         > T1r3
    [activation_fn:SiLUActivation]         < T1r3
    [down_proj:Linear]         > T1r3
    [down_proj:Linear]         < T1r3
    [mlp:Phi3MLP]       < T1r3
    [resid_mlp_dropout:Dropout]       > T1r3
    [resid_mlp_dropout:Dropout]       < T1r3
    [layers[1]:Phi3DecoderLayer]     < T1r3
    [norm:Phi3RMSNorm]     > T1r3
    [norm:Phi3RMSNorm]     < T1r3
    [model:Phi3Model]   < *BaseModelOutputWithPast(last_hidden_state:T1r3,past_key_values:DynamicCache(key_cache=#2[T1r4,T1r4], value_cache=#2[T1r4,T1r4]))
    [lm_head:Linear]   > T1r3
    [lm_head:Linear]   < T1r3
    [__main__:Phi3ForCausalLM] < *CausalLMOutputWithPast(logits:T1r3,past_key_values:DynamicCache(key_cache=#2[T1r4,T1r4], value_cache=#2[T1r4,T1r4]))
    [trace_execution_piece_by_piece] run with dict(args:(),kwargs:dict(input_ids:T7s3x4,attention_mask:T7s3x35,past_key_values:DynamicCache(key_cache=#2[T1s3x32x31x96,T1s3x32x31x96], value_cache=#2[T1s3x32x31x96,T1s3x32x31x96])))
    [__main__:Phi3ForCausalLM] > **dict(input_ids:T7r2,attention_mask:T7r2,past_key_values:DynamicCache(key_cache=#2[T1r4,T1r4], value_cache=#2[T1r4,T1r4]))
    [model:Phi3Model]   > **dict(input_ids:T7r2,attention_mask:T7r2,position_ids:None,past_key_values:DynamicCache(key_cache=#2[T1r4,T1r4], value_cache=#2[T1r4,T1r4]),inputs_embeds:None,use_cache:None,cache_position:None)
    [embed_tokens:Embedding]     > T7r2
    [embed_tokens:Embedding]     < T1r3
    [rotary_emb:Phi3RotaryEmbedding]     > *(T1r3,), **dict(position_ids:T7r2)
    [rotary_emb:Phi3RotaryEmbedding]     < *(T1r3,T1r3)
    [layers[0]:Phi3DecoderLayer]     > *(T1r3,), **dict(attention_mask:T9r4,position_ids:T7r2,past_key_values:DynamicCache(key_cache=#2[T1r4,T1r4], value_cache=#2[T1r4,T1r4]),use_cache:bool,cache_position:T7r1,position_embeddings:(T1r3,T1r3))
    [input_layernorm:Phi3RMSNorm]       > T1r3
    [input_layernorm:Phi3RMSNorm]       < T1r3
    [self_attn:Phi3Attention]       > **dict(hidden_states:T1r3,attention_mask:T9r4,position_ids:T7r2,past_key_values:DynamicCache(key_cache=#2[T1r4,T1r4], value_cache=#2[T1r4,T1r4]),use_cache:bool,cache_position:T7r1,position_embeddings:(T1r3,T1r3))
    [qkv_proj:Linear]         > T1r3
    [qkv_proj:Linear]         < T1r3
    [o_proj:Linear]         > T1r3
    [o_proj:Linear]         < T1r3
    [self_attn:Phi3Attention]       < *(T1r3,None)
    [resid_attn_dropout:Dropout]       > T1r3
    [resid_attn_dropout:Dropout]       < T1r3
    [post_attention_layernorm:Phi3RMSNorm]       > T1r3
    [post_attention_layernorm:Phi3RMSNorm]       < T1r3
    [mlp:Phi3MLP]       > T1r3
    [gate_up_proj:Linear]         > T1r3
    [gate_up_proj:Linear]         < T1r3
    [activation_fn:SiLUActivation]         > T1r3
    [activation_fn:SiLUActivation]         < T1r3
    [down_proj:Linear]         > T1r3
    [down_proj:Linear]         < T1r3
    [mlp:Phi3MLP]       < T1r3
    [resid_mlp_dropout:Dropout]       > T1r3
    [resid_mlp_dropout:Dropout]       < T1r3
    [layers[0]:Phi3DecoderLayer]     < T1r3
    [layers[1]:Phi3DecoderLayer]     > *(T1r3,), **dict(attention_mask:T9r4,position_ids:T7r2,past_key_values:DynamicCache(key_cache=#2[T1r4,T1r4], value_cache=#2[T1r4,T1r4]),use_cache:bool,cache_position:T7r1,position_embeddings:(T1r3,T1r3))
    [input_layernorm:Phi3RMSNorm]       > T1r3
    [input_layernorm:Phi3RMSNorm]       < T1r3
    [self_attn:Phi3Attention]       > **dict(hidden_states:T1r3,attention_mask:T9r4,position_ids:T7r2,past_key_values:DynamicCache(key_cache=#2[T1r4,T1r4], value_cache=#2[T1r4,T1r4]),use_cache:bool,cache_position:T7r1,position_embeddings:(T1r3,T1r3))
    [qkv_proj:Linear]         > T1r3
    [qkv_proj:Linear]         < T1r3
    [o_proj:Linear]         > T1r3
    [o_proj:Linear]         < T1r3
    [self_attn:Phi3Attention]       < *(T1r3,None)
    [resid_attn_dropout:Dropout]       > T1r3
    [resid_attn_dropout:Dropout]       < T1r3
    [post_attention_layernorm:Phi3RMSNorm]       > T1r3
    [post_attention_layernorm:Phi3RMSNorm]       < T1r3
    [mlp:Phi3MLP]       > T1r3
    [gate_up_proj:Linear]         > T1r3
    [gate_up_proj:Linear]         < T1r3
    [activation_fn:SiLUActivation]         > T1r3
    [activation_fn:SiLUActivation]         < T1r3
    [down_proj:Linear]         > T1r3
    [down_proj:Linear]         < T1r3
    [mlp:Phi3MLP]       < T1r3
    [resid_mlp_dropout:Dropout]       > T1r3
    [resid_mlp_dropout:Dropout]       < T1r3
    [layers[1]:Phi3DecoderLayer]     < T1r3
    [norm:Phi3RMSNorm]     > T1r3
    [norm:Phi3RMSNorm]     < T1r3
    [model:Phi3Model]   < *BaseModelOutputWithPast(last_hidden_state:T1r3,past_key_values:DynamicCache(key_cache=#2[T1r4,T1r4], value_cache=#2[T1r4,T1r4]))
    [lm_head:Linear]   > T1r3
    [lm_head:Linear]   < T1r3
    [__main__:Phi3ForCausalLM] < *CausalLMOutputWithPast(logits:T1r3,past_key_values:DynamicCache(key_cache=#2[T1r4,T1r4], value_cache=#2[T1r4,T1r4]))
    [trace_forward_execution] traced execution of model Phi3ForCausalLM
    >>> __main__: Phi3ForCausalLM
      > ((),dict(input_ids:CT7s2x3[2362,19849:A9927.0],attention_mask:CT7s2x33[1,1:A1.0],past_key_values:DynamicCache(key_cache=#2[CT1s2x32x30x96[-4.4372687339782715,4.9389166831970215:A-0.0018145969465168518],CT1s2x32x30x96[-4.307009220123291,4.684481143951416:A-6.06859164521424e-05]], value_cache=#2[CT1s2x32x30x96[-4.653428554534912,4.33624792098999:A0.0037828923996646186],CT1s2x32x30x96[-4.381317615509033,4.224946022033691:A-0.0016259470875989261]])))
      > ((),dict(input_ids:CT7s3x4[2638,25821:A11206.25],attention_mask:CT7s3x35[1,1:A1.0],past_key_values:DynamicCache(key_cache=#2[CT1s3x32x31x96[-4.666959285736084,4.36474609375:A-0.0005669254036047338],CT1s3x32x31x96[-5.348014831542969,4.368123531341553:A0.0016996543330539782]], value_cache=#2[CT1s3x32x31x96[-4.478281021118164,5.405029773712158:A-0.0015320026912303557],CT1s3x32x31x96[-4.481750011444092,4.899826526641846:A0.001329172336241602]])))
        >>> model: Phi3Model
          > ((),dict(input_ids:CT7s2x3[2362,19849:A9927.0],attention_mask:CT7s2x33[1,1:A1.0],position_ids:None,past_key_values:DynamicCache(key_cache=#2[CT1s2x32x30x96[-4.4372687339782715,4.9389166831970215:A-0.0018145969465168518],CT1s2x32x30x96[-4.307009220123291,4.684481143951416:A-6.06859164521424e-05]], value_cache=#2[CT1s2x32x30x96[-4.653428554534912,4.33624792098999:A0.0037828923996646186],CT1s2x32x30x96[-4.381317615509033,4.224946022033691:A-0.0016259470875989261]]),inputs_embeds:None,use_cache:None,cache_position:None))
          > ((),dict(input_ids:CT7s3x4[2638,25821:A11206.25],attention_mask:CT7s3x35[1,1:A1.0],position_ids:None,past_key_values:DynamicCache(key_cache=#2[CT1s3x32x31x96[-4.666959285736084,4.36474609375:A-0.0005669254036047338],CT1s3x32x31x96[-5.348014831542969,4.368123531341553:A0.0016996543330539782]], value_cache=#2[CT1s3x32x31x96[-4.478281021118164,5.405029773712158:A-0.0015320026912303557],CT1s3x32x31x96[-4.481750011444092,4.899826526641846:A0.001329172336241602]]),inputs_embeds:None,use_cache:None,cache_position:None))
            >>> embed_tokens: Embedding
              > ((CT7s2x3[2362,19849:A9927.0],),{})
              > ((CT7s3x4[2638,25821:A11206.25],),{})
              < (CT1s2x3x3072[-0.07376911491155624,0.07879423350095749:A-4.1887485139631884e-05],)
              < (CT1s3x4x3072[-0.08714857697486877,0.07588315010070801:A4.5155108760684524e-05],)
            <<<
            >>> layers[0]: Phi3DecoderLayer
              > ((CT1s2x3x3072[-0.07376911491155624,0.07879423350095749:A-4.1887485139631884e-05],),dict(attention_mask:CT9s2x1x3x33[False,True:A0.9696969696969697],position_ids:CT7s1x3[30,32:A31.0],past_key_values:DynamicCache(key_cache=#2[CT1s2x32x30x96[-4.4372687339782715,4.9389166831970215:A-0.0018145969465168518],CT1s2x32x30x96[-4.307009220123291,4.684481143951416:A-6.06859164521424e-05]], value_cache=#2[CT1s2x32x30x96[-4.653428554534912,4.33624792098999:A0.0037828923996646186],CT1s2x32x30x96[-4.381317615509033,4.224946022033691:A-0.0016259470875989261]]),use_cache:bool=True,cache_position:CT7s3[30,32:A31.0],position_embeddings:(CT1s1x3x96[-1.1855769157409668,1.1902371644973755:A0.746652018013669],CT1s1x3x96[-1.1887905597686768,1.190193772315979:A0.1589894221542636])))
              > ((CT1s3x4x3072[-0.08714857697486877,0.07588315010070801:A4.5155108760684524e-05],),dict(attention_mask:CT9s3x1x4x35[False,True:A0.9571428571428572],position_ids:CT7s1x4[31,34:A32.5],past_key_values:DynamicCache(key_cache=#2[CT1s3x32x31x96[-4.666959285736084,4.36474609375:A-0.0005669254036047338],CT1s3x32x31x96[-5.348014831542969,4.368123531341553:A0.0016996543330539782]], value_cache=#2[CT1s3x32x31x96[-4.478281021118164,5.405029773712158:A-0.0015320026912303557],CT1s3x32x31x96[-4.481750011444092,4.899826526641846:A0.001329172336241602]]),use_cache:bool=True,cache_position:CT7s4[31,34:A32.5],position_embeddings:(CT1s1x4x96[-1.1855769157409668,1.190237045288086:A0.7129333875218435],CT1s1x4x96[-1.1719439029693604,1.1902378797531128:A0.18296290554159592])))
                >>> self_attn: Phi3Attention
                  > ((),dict(hidden_states:CT1s2x3x3072[-3.5838396549224854,3.9394724369049072:A-0.0019140506855666534],attention_mask:CT9s2x1x3x33[False,True:A0.9696969696969697],position_ids:CT7s1x3[30,32:A31.0],past_key_values:DynamicCache(key_cache=#2[CT1s2x32x30x96[-4.4372687339782715,4.9389166831970215:A-0.0018145969465168518],CT1s2x32x30x96[-4.307009220123291,4.684481143951416:A-6.06859164521424e-05]], value_cache=#2[CT1s2x32x30x96[-4.653428554534912,4.33624792098999:A0.0037828923996646186],CT1s2x32x30x96[-4.381317615509033,4.224946022033691:A-0.0016259470875989261]]),use_cache:bool=True,cache_position:CT7s3[30,32:A31.0],position_embeddings:(CT1s1x3x96[-1.1855769157409668,1.1902371644973755:A0.746652018013669],CT1s1x3x96[-1.1887905597686768,1.190193772315979:A0.1589894221542636])))
                  > ((),dict(hidden_states:CT1s3x4x3072[-4.286052227020264,3.7994778156280518:A0.00223767950507181],attention_mask:CT9s3x1x4x35[False,True:A0.9571428571428572],position_ids:CT7s1x4[31,34:A32.5],past_key_values:DynamicCache(key_cache=#2[CT1s3x32x31x96[-4.666959285736084,4.36474609375:A-0.0005669254036047338],CT1s3x32x31x96[-5.348014831542969,4.368123531341553:A0.0016996543330539782]], value_cache=#2[CT1s3x32x31x96[-4.478281021118164,5.405029773712158:A-0.0015320026912303557],CT1s3x32x31x96[-4.481750011444092,4.899826526641846:A0.001329172336241602]]),use_cache:bool=True,cache_position:CT7s4[31,34:A32.5],position_embeddings:(CT1s1x4x96[-1.1855769157409668,1.190237045288086:A0.7129333875218435],CT1s1x4x96[-1.1719439029693604,1.1902378797531128:A0.18296290554159592])))
                    >>> o_proj: Linear
                      > ((CT1s2x3x3072[-1.7982155084609985,1.5562021732330322:A0.005110508281258758],),{})
                      > ((CT1s3x4x3072[-2.0415515899658203,2.0737204551696777:A-0.0008414809059943776],),{})
                      < (CT1s2x3x3072[-1.8279160261154175,1.4507904052734375:A-0.0008396338007135758],)
                      < (CT1s3x4x3072[-1.9243743419647217,1.7442429065704346:A-0.001205723278606759],)
                    <<<
                    >>> qkv_proj: Linear
                      > ((CT1s2x3x3072[-3.5838396549224854,3.9394724369049072:A-0.0019140506855666534],),{})
                      > ((CT1s3x4x3072[-4.286052227020264,3.7994778156280518:A0.00223767950507181],),{})
                      < (CT1s2x3x9216[-4.587186336517334,4.292729377746582:A0.007473712318685515],)
                      < (CT1s3x4x9216[-4.700593948364258,4.975395202636719:A-0.005646158394060624],)
                    <<<
                  < (CT1s2x3x3072[-1.8279160261154175,1.4507904052734375:A-0.0008396338007135758],None)
                  < (CT1s3x4x3072[-1.9243743419647217,1.7442429065704346:A-0.001205723278606759],None)
                <<<
                >>> mlp: Phi3MLP
                  > ((CT1s2x3x3072[-4.625214099884033,3.9082841873168945:A-0.0025625945843975716],),{})
                  > ((CT1s3x4x3072[-4.834957122802734,4.3198089599609375:A-0.003181357021565301],),{})
                    >>> gate_up_proj: Linear
                      > ((CT1s2x3x3072[-4.625214099884033,3.9082841873168945:A-0.0025625945843975716],),{})
                      > ((CT1s3x4x3072[-4.834957122802734,4.3198089599609375:A-0.003181357021565301],),{})
                      < (CT1s2x3x16384[-4.861887454986572,4.448859691619873:A-0.002939468152601895],)
                      < (CT1s3x4x16384[-5.807982921600342,4.96391487121582:A-0.007495159157847671],)
                    <<<
                    >>> down_proj: Linear
                      > ((CT1s2x3x8192[-9.830395698547363,9.824663162231445:A0.0016648271212688266],),{})
                      > ((CT1s3x4x8192[-8.675286293029785,9.960387229919434:A0.0007451121837550966],),{})
                      < (CT1s2x3x3072[-5.607044219970703,5.26134729385376:A-0.0029576658751137882],)
                      < (CT1s3x4x3072[-5.735095500946045,6.008514881134033:A0.0005367050955998012],)
                    <<<
                    >>> activation_fn: SiLUActivation
                      > ((CT1s2x3x8192[-4.861887454986572,4.393069267272949:A0.004347703658316012],),{})
                      > ((CT1s3x4x8192[-4.904458522796631,4.508429527282715:A-0.0034831209142941097],),{})
                      < (CT1s2x3x8192[-0.27846455574035645,4.339422225952148:A0.24792149335454552],)
                      < (CT1s3x4x8192[-0.27846455574035645,4.459306716918945:A0.2423858982331506],)
                    <<<
                  < (CT1s2x3x3072[-5.607044219970703,5.26134729385376:A-0.0029576658751137882],)
                  < (CT1s3x4x3072[-5.735095500946045,6.008514881134033:A0.0005367050955998012],)
                <<<
                >>> input_layernorm: Phi3RMSNorm
                  > ((CT1s2x3x3072[-0.07376911491155624,0.07879423350095749:A-4.1887485139631884e-05],),{})
                  > ((CT1s3x4x3072[-0.08714857697486877,0.07588315010070801:A4.5155108760684524e-05],),{})
                  < (CT1s2x3x3072[-3.5838396549224854,3.9394724369049072:A-0.0019140506855666534],)
                  < (CT1s3x4x3072[-4.286052227020264,3.7994778156280518:A0.00223767950507181],)
                <<<
                >>> post_attention_layernorm: Phi3RMSNorm
                  > ((CT1s2x3x3072[-1.8303141593933105,1.4518355131149292:A-0.000881521285227412],),{})
                  > ((CT1s3x4x3072[-1.9323235750198364,1.7264411449432373:A-0.0011605681411298956],),{})
                  < (CT1s2x3x3072[-4.625214099884033,3.9082841873168945:A-0.0025625945843975716],)
                  < (CT1s3x4x3072[-4.834957122802734,4.3198089599609375:A-0.003181357021565301],)
                <<<
                >>> resid_attn_dropout: Dropout
                  > ((CT1s2x3x3072[-1.8279160261154175,1.4507904052734375:A-0.0008396338007135758],),{})
                  > ((CT1s3x4x3072[-1.9243743419647217,1.7442429065704346:A-0.001205723278606759],),{})
                  < (CT1s2x3x3072[-1.8279160261154175,1.4507904052734375:A-0.0008396338007135758],)
                  < (CT1s3x4x3072[-1.9243743419647217,1.7442429065704346:A-0.001205723278606759],)
                <<<
                >>> resid_mlp_dropout: Dropout
                  > ((CT1s2x3x3072[-5.607044219970703,5.26134729385376:A-0.0029576658751137882],),{})
                  > ((CT1s3x4x3072[-5.735095500946045,6.008514881134033:A0.0005367050955998012],),{})
                  < (CT1s2x3x3072[-5.607044219970703,5.26134729385376:A-0.0029576658751137882],)
                  < (CT1s3x4x3072[-5.735095500946045,6.008514881134033:A0.0005367050955998012],)
                <<<
              < (CT1s2x3x3072[-5.3211469650268555,5.16252326965332:A-0.0038391876845101556],)
              < (CT1s3x4x3072[-5.867830276489258,5.941324710845947:A-0.0006238630239497272],)
            <<<
            >>> layers[1]: Phi3DecoderLayer
              > ((CT1s2x3x3072[-5.3211469650268555,5.16252326965332:A-0.0038391876845101556],),dict(attention_mask:CT9s2x1x3x33[False,True:A0.9696969696969697],position_ids:CT7s1x3[30,32:A31.0],past_key_values:DynamicCache(key_cache=#2[CT1s2x32x33x96[-5.45668888092041,5.061878681182861:A-1.9015148069905276e-06],CT1s2x32x30x96[-4.307009220123291,4.684481143951416:A-6.06859164521424e-05]], value_cache=#2[CT1s2x32x33x96[-4.653428554534912,4.33624792098999:A0.003731328124832182],CT1s2x32x30x96[-4.381317615509033,4.224946022033691:A-0.0016259470875989261]]),use_cache:bool=True,cache_position:CT7s3[30,32:A31.0],position_embeddings:(CT1s1x3x96[-1.1855769157409668,1.1902371644973755:A0.746652018013669],CT1s1x3x96[-1.1887905597686768,1.190193772315979:A0.1589894221542636])))
              > ((CT1s3x4x3072[-5.867830276489258,5.941324710845947:A-0.0006238630239497272],),dict(attention_mask:CT9s3x1x4x35[False,True:A0.9571428571428572],position_ids:CT7s1x4[31,34:A32.5],past_key_values:DynamicCache(key_cache=#2[CT1s3x32x35x96[-5.892448425292969,5.922724723815918:A-0.0014520613828399344],CT1s3x32x31x96[-5.348014831542969,4.368123531341553:A0.0016996543330539782]], value_cache=#2[CT1s3x32x35x96[-4.478281021118164,5.405029773712158:A-0.0013515191728212593],CT1s3x32x31x96[-4.481750011444092,4.899826526641846:A0.001329172336241602]]),use_cache:bool=True,cache_position:CT7s4[31,34:A32.5],position_embeddings:(CT1s1x4x96[-1.1855769157409668,1.190237045288086:A0.7129333875218435],CT1s1x4x96[-1.1719439029693604,1.1902378797531128:A0.18296290554159592])))
                >>> self_attn: Phi3Attention
                  > ((),dict(hidden_states:CT1s2x3x3072[-3.732288122177124,3.7007057666778564:A-0.0027576641566727667],attention_mask:CT9s2x1x3x33[False,True:A0.9696969696969697],position_ids:CT7s1x3[30,32:A31.0],past_key_values:DynamicCache(key_cache=#2[CT1s2x32x33x96[-5.45668888092041,5.061878681182861:A-1.9015148069905276e-06],CT1s2x32x30x96[-4.307009220123291,4.684481143951416:A-6.06859164521424e-05]], value_cache=#2[CT1s2x32x33x96[-4.653428554534912,4.33624792098999:A0.003731328124832182],CT1s2x32x30x96[-4.381317615509033,4.224946022033691:A-0.0016259470875989261]]),use_cache:bool=True,cache_position:CT7s3[30,32:A31.0],position_embeddings:(CT1s1x3x96[-1.1855769157409668,1.1902371644973755:A0.746652018013669],CT1s1x3x96[-1.1887905597686768,1.190193772315979:A0.1589894221542636])))
                  > ((),dict(hidden_states:CT1s3x4x3072[-4.143612861633301,4.394371509552002:A-0.0004325411176276075],attention_mask:CT9s3x1x4x35[False,True:A0.9571428571428572],position_ids:CT7s1x4[31,34:A32.5],past_key_values:DynamicCache(key_cache=#2[CT1s3x32x35x96[-5.892448425292969,5.922724723815918:A-0.0014520613828399344],CT1s3x32x31x96[-5.348014831542969,4.368123531341553:A0.0016996543330539782]], value_cache=#2[CT1s3x32x35x96[-4.478281021118164,5.405029773712158:A-0.0013515191728212593],CT1s3x32x31x96[-4.481750011444092,4.899826526641846:A0.001329172336241602]]),use_cache:bool=True,cache_position:CT7s4[31,34:A32.5],position_embeddings:(CT1s1x4x96[-1.1855769157409668,1.190237045288086:A0.7129333875218435],CT1s1x4x96[-1.1719439029693604,1.1902378797531128:A0.18296290554159592])))
                    >>> o_proj: Linear
                      > ((CT1s2x3x3072[-2.196047782897949,3.491006851196289:A0.0010470968606750687],),{})
                      > ((CT1s3x4x3072[-2.2303245067596436,3.1470181941986084:A0.0019257652728554276],),{})
                      < (CT1s2x3x3072[-1.6340974569320679,1.4639941453933716:A0.009091115853894709],)
                      < (CT1s3x4x3072[-1.7076345682144165,1.594178318977356:A-0.0006970665916712607],)
                    <<<
                    >>> qkv_proj: Linear
                      > ((CT1s2x3x3072[-3.732288122177124,3.7007057666778564:A-0.0027576641566727667],),{})
                      > ((CT1s3x4x3072[-4.143612861633301,4.394371509552002:A-0.0004325411176276075],),{})
                      < (CT1s2x3x9216[-4.686030387878418,5.232321739196777:A-0.007595571796819648],)
                      < (CT1s3x4x9216[-4.747264862060547,4.846535682678223:A0.006878406574714889],)
                    <<<
                  < (CT1s2x3x3072[-1.6340974569320679,1.4639941453933716:A0.009091115853894709],None)
                  < (CT1s3x4x3072[-1.7076345682144165,1.594178318977356:A-0.0006970665916712607],None)
                <<<
                >>> mlp: Phi3MLP
                  > ((CT1s2x3x3072[-3.8420677185058594,3.825016498565674:A0.003660252361635388],),{})
                  > ((CT1s3x4x3072[-4.3753790855407715,4.6400532722473145:A-0.0009089054335977349],),{})
                    >>> gate_up_proj: Linear
                      > ((CT1s2x3x3072[-3.8420677185058594,3.825016498565674:A0.003660252361635388],),{})
                      > ((CT1s3x4x3072[-4.3753790855407715,4.6400532722473145:A-0.0009089054335977349],),{})
                      < (CT1s2x3x16384[-4.505943298339844,4.743088722229004:A-0.0011835947237723115],)
                      < (CT1s3x4x16384[-4.810391426086426,5.156411170959473:A0.0017788842293716318],)
                    <<<
                    >>> down_proj: Linear
                      > ((CT1s2x3x8192[-8.877033233642578,9.58362102508545:A-0.0017682261852222751],),{})
                      > ((CT1s3x4x8192[-9.506426811218262,9.895496368408203:A-0.0007792048849036259],),{})
                      < (CT1s2x3x3072[-4.93414831161499,5.361568450927734:A-0.011077598914880582],)
                      < (CT1s3x4x3072[-5.495031356811523,6.2018890380859375:A-0.01374426155741225],)
                    <<<
                    >>> activation_fn: SiLUActivation
                      > ((CT1s2x3x8192[-4.288691520690918,4.743088722229004:A0.0037829975197638532],),{})
                      > ((CT1s3x4x8192[-4.810391426086426,4.749007225036621:A0.001125319845272088],),{})
                      < (CT1s2x3x8192[-0.27846455574035645,4.702125072479248:A0.24757450217875318],)
                      < (CT1s3x4x8192[-0.27846455574035645,4.708232402801514:A0.24683770229472768],)
                    <<<
                  < (CT1s2x3x3072[-4.93414831161499,5.361568450927734:A-0.011077598914880582],)
                  < (CT1s3x4x3072[-5.495031356811523,6.2018890380859375:A-0.01374426155741225],)
                <<<
                >>> input_layernorm: Phi3RMSNorm
                  > ((CT1s2x3x3072[-5.3211469650268555,5.16252326965332:A-0.0038391876845101556],),{})
                  > ((CT1s3x4x3072[-5.867830276489258,5.941324710845947:A-0.0006238630239497272],),{})
                  < (CT1s2x3x3072[-3.732288122177124,3.7007057666778564:A-0.0027576641566727667],)
                  < (CT1s3x4x3072[-4.143612861633301,4.394371509552002:A-0.0004325411176276075],)
                <<<
                >>> post_attention_layernorm: Phi3RMSNorm
                  > ((CT1s2x3x3072[-5.592419624328613,5.567600250244141:A0.005251927939601349],),{})
                  > ((CT1s3x4x3072[-6.4618000984191895,6.491318225860596:A-0.0013209298003415723],),{})
                  < (CT1s2x3x3072[-3.8420677185058594,3.825016498565674:A0.003660252361635388],)
                  < (CT1s3x4x3072[-4.3753790855407715,4.6400532722473145:A-0.0009089054335977349],)
                <<<
                >>> resid_attn_dropout: Dropout
                  > ((CT1s2x3x3072[-1.6340974569320679,1.4639941453933716:A0.009091115853894709],),{})
                  > ((CT1s3x4x3072[-1.7076345682144165,1.594178318977356:A-0.0006970665916712607],),{})
                  < (CT1s2x3x3072[-1.6340974569320679,1.4639941453933716:A0.009091115853894709],)
                  < (CT1s3x4x3072[-1.7076345682144165,1.594178318977356:A-0.0006970665916712607],)
                <<<
                >>> resid_mlp_dropout: Dropout
                  > ((CT1s2x3x3072[-4.93414831161499,5.361568450927734:A-0.011077598914880582],),{})
                  > ((CT1s3x4x3072[-5.495031356811523,6.2018890380859375:A-0.01374426155741225],),{})
                  < (CT1s2x3x3072[-4.93414831161499,5.361568450927734:A-0.011077598914880582],)
                  < (CT1s3x4x3072[-5.495031356811523,6.2018890380859375:A-0.01374426155741225],)
                <<<
              < (CT1s2x3x3072[-7.256673812866211,8.507494926452637:A-0.0058256708042689655],)
              < (CT1s3x4x3072[-8.208396911621094,7.302861213684082:A-0.015065191307308446],)
            <<<
            >>> norm: Phi3RMSNorm
              > ((CT1s2x3x3072[-7.256673812866211,8.507494926452637:A-0.0058256708042689655],),{})
              > ((CT1s3x4x3072[-8.208396911621094,7.302861213684082:A-0.015065191307308446],),{})
              < (CT1s2x3x3072[-3.7511699199676514,4.354421615600586:A-0.0029114874530221536],)
              < (CT1s3x4x3072[-4.0881123542785645,3.7902109622955322:A-0.007392428970230205],)
            <<<
            >>> rotary_emb: Phi3RotaryEmbedding
              > ((CT1s2x3x3072[-0.07376911491155624,0.07879423350095749:A-4.1887485139631884e-05],),dict(position_ids:CT7s1x3[30,32:A31.0]))
              > ((CT1s3x4x3072[-0.08714857697486877,0.07588315010070801:A4.5155108760684524e-05],),dict(position_ids:CT7s1x4[31,34:A32.5]))
              < (CT1s1x3x96[-1.1855769157409668,1.1902371644973755:A0.746652018013669],CT1s1x3x96[-1.1887905597686768,1.190193772315979:A0.1589894221542636])
              < (CT1s1x4x96[-1.1855769157409668,1.190237045288086:A0.7129333875218435],CT1s1x4x96[-1.1719439029693604,1.1902378797531128:A0.18296290554159592])
            <<<
          < (dict(last_hidden_state:CT1s2x3x3072[-3.7511699199676514,4.354421615600586:A-0.0029114874530221536],past_key_values:DynamicCache(key_cache=#2[CT1s2x32x33x96[-5.45668888092041,5.061878681182861:A-1.9015148069905276e-06],CT1s2x32x33x96[-5.21619987487793,5.736476421356201:A0.0004283623140302432]], value_cache=#2[CT1s2x32x33x96[-4.653428554534912,4.33624792098999:A0.003731328124832182],CT1s2x32x33x96[-4.381317615509033,4.224946022033691:A-0.002159246555065681]])),)
          < (dict(last_hidden_state:CT1s3x4x3072[-4.0881123542785645,3.7902109622955322:A-0.007392428970230205],past_key_values:DynamicCache(key_cache=#2[CT1s3x32x35x96[-5.892448425292969,5.922724723815918:A-0.0014520613828399344],CT1s3x32x35x96[-5.673103332519531,5.6023125648498535:A0.0033009962427847485]], value_cache=#2[CT1s3x32x35x96[-4.478281021118164,5.405029773712158:A-0.0013515191728212593],CT1s3x32x35x96[-4.567196369171143,4.899826526641846:A0.002020652803907956]])),)
        <<<
        >>> lm_head: Linear
          > ((CT1s2x3x3072[-3.7511699199676514,4.354421615600586:A-0.0029114874530221536],),{})
          > ((CT1s3x4x3072[-4.0881123542785645,3.7902109622955322:A-0.007392428970230205],),{})
          < (CT1s2x3x32064[-5.220239162445068,4.913861274719238:A0.0015322401525973096],)
          < (CT1s3x4x32064[-5.743113994598389,6.3348002433776855:A0.001989656881118981],)
        <<<
      < (dict(logits:CT1s2x3x32064[-5.220239162445068,4.913861274719238:A0.0015322401525973096],past_key_values:DynamicCache(key_cache=#2[CT1s2x32x33x96[-5.45668888092041,5.061878681182861:A-1.9015148069905276e-06],CT1s2x32x33x96[-5.21619987487793,5.736476421356201:A0.0004283623140302432]], value_cache=#2[CT1s2x32x33x96[-4.653428554534912,4.33624792098999:A0.003731328124832182],CT1s2x32x33x96[-4.381317615509033,4.224946022033691:A-0.002159246555065681]])),)
      < (dict(logits:CT1s3x4x32064[-5.743113994598389,6.3348002433776855:A0.001989656881118981],past_key_values:DynamicCache(key_cache=#2[CT1s3x32x35x96[-5.892448425292969,5.922724723815918:A-0.0014520613828399344],CT1s3x32x35x96[-5.673103332519531,5.6023125648498535:A0.0033009962427847485]], value_cache=#2[CT1s3x32x35x96[-4.478281021118164,5.405029773712158:A-0.0013515191728212593],CT1s3x32x35x96[-4.567196369171143,4.899826526641846:A0.002020652803907956]])),)
    <<<
    [_untrace_forward_execution]  M:__main__-Phi3ForCausalLM
    [_untrace_forward_execution] .. M:model-Phi3Model
    [_untrace_forward_execution] .... M:embed_tokens-Embedding
    [_untrace_forward_execution] .... M:layers[0]-Phi3DecoderLayer
    [_untrace_forward_execution] ...... M:self_attn-Phi3Attention
    [_untrace_forward_execution] ........ M:o_proj-Linear
    [_untrace_forward_execution] ........ M:qkv_proj-Linear
    [_untrace_forward_execution] ...... M:mlp-Phi3MLP
    [_untrace_forward_execution] ........ M:gate_up_proj-Linear
    [_untrace_forward_execution] ........ M:down_proj-Linear
    [_untrace_forward_execution] ........ M:activation_fn-SiLUActivation
    [_untrace_forward_execution] ...... M:input_layernorm-Phi3RMSNorm
    [_untrace_forward_execution] ...... M:post_attention_layernorm-Phi3RMSNorm
    [_untrace_forward_execution] ...... M:resid_attn_dropout-Dropout
    [_untrace_forward_execution] ...... M:resid_mlp_dropout-Dropout
    [_untrace_forward_execution] .... M:layers[1]-Phi3DecoderLayer
    [_untrace_forward_execution] ...... M:self_attn-Phi3Attention
    [_untrace_forward_execution] ........ M:o_proj-Linear
    [_untrace_forward_execution] ........ M:qkv_proj-Linear
    [_untrace_forward_execution] ...... M:mlp-Phi3MLP
    [_untrace_forward_execution] ........ M:gate_up_proj-Linear
    [_untrace_forward_execution] ........ M:down_proj-Linear
    [_untrace_forward_execution] ........ M:activation_fn-SiLUActivation
    [_untrace_forward_execution] ...... M:input_layernorm-Phi3RMSNorm
    [_untrace_forward_execution] ...... M:post_attention_layernorm-Phi3RMSNorm
    [_untrace_forward_execution] ...... M:resid_attn_dropout-Dropout
    [_untrace_forward_execution] ...... M:resid_mlp_dropout-Dropout
    [_untrace_forward_execution] .... M:norm-Phi3RMSNorm
    [_untrace_forward_execution] .... M:rotary_emb-Phi3RotaryEmbedding
    [_untrace_forward_execution] .. M:lm_head-Linear




.. GENERATED FROM PYTHON SOURCE LINES 225-228

Now we keep in memory every input/output for the submodules,
we can guess the dynamic shapes for every of them.
The final ones:

.. GENERATED FROM PYTHON SOURCE LINES 228-232

.. code-block:: Python

    dynamic_shapes = diag.guess_dynamic_shapes()
    print("The dynamic shapes are:")
    pprint.pprint(dynamic_shapes)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    The dynamic shapes are:
    ((),
     {'attention_mask': {0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},
      'input_ids': {0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},
      'past_key_values': [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)},
                          {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)},
                          {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)},
                          {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}]})




.. GENERATED FROM PYTHON SOURCE LINES 233-234

And all the dynamic shapes all along the traced submodules.

.. GENERATED FROM PYTHON SOURCE LINES 234-244

.. code-block:: Python

    print(
        diag.pretty_text(
            with_dynamic_shape=True,
            with_shape=False,
            with_min_max=False,
            with_device=False,
            with_inputs=False,
        ).replace("<_DimHint.DYNAMIC: 3>", "DYN")
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    >>> __main__: Phi3ForCausalLM
      DS=((), {'attention_mask': {0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)}, 'input_ids': {0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)}, 'past_key_values': [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}]})
        >>> model: Phi3Model
          DS=((), {'attention_mask': {0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)}, 'cache_position': None, 'input_ids': {0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)}, 'inputs_embeds': None, 'past_key_values': [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}], 'position_ids': None, 'use_cache': None})
            >>> embed_tokens: Embedding: DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {}) <<<
            >>> layers[0]: Phi3DecoderLayer
              DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {'attention_mask': {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC), 3: DimHint(DYNAMIC)}, 'cache_position': {0: DimHint(DYNAMIC)}, 'past_key_values': [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}], 'position_embeddings': ({1: DimHint(DYNAMIC)}, {1: DimHint(DYNAMIC)}), 'position_ids': {1: DimHint(DYNAMIC)}, 'use_cache': None})
                >>> self_attn: Phi3Attention
                  DS=((), {'attention_mask': {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC), 3: DimHint(DYNAMIC)}, 'cache_position': {0: DimHint(DYNAMIC)}, 'hidden_states': {0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)}, 'past_key_values': [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}], 'position_embeddings': ({1: DimHint(DYNAMIC)}, {1: DimHint(DYNAMIC)}), 'position_ids': {1: DimHint(DYNAMIC)}, 'use_cache': None})
                    >>> o_proj: Linear: DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {}) <<<
                    >>> qkv_proj: Linear: DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {}) <<<
                <<<
                >>> mlp: Phi3MLP
                  DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {})
                    >>> gate_up_proj: Linear: DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {}) <<<
                    >>> down_proj: Linear: DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {}) <<<
                    >>> activation_fn: SiLUActivation: DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {}) <<<
                <<<
                >>> input_layernorm: Phi3RMSNorm: DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {}) <<<
                >>> post_attention_layernorm: Phi3RMSNorm: DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {}) <<<
                >>> resid_attn_dropout: Dropout: DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {}) <<<
                >>> resid_mlp_dropout: Dropout: DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {}) <<<
            <<<
            >>> layers[1]: Phi3DecoderLayer
              DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {'attention_mask': {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC), 3: DimHint(DYNAMIC)}, 'cache_position': {0: DimHint(DYNAMIC)}, 'past_key_values': [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}], 'position_embeddings': ({1: DimHint(DYNAMIC)}, {1: DimHint(DYNAMIC)}), 'position_ids': {1: DimHint(DYNAMIC)}, 'use_cache': None})
                >>> self_attn: Phi3Attention
                  DS=((), {'attention_mask': {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC), 3: DimHint(DYNAMIC)}, 'cache_position': {0: DimHint(DYNAMIC)}, 'hidden_states': {0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)}, 'past_key_values': [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}], 'position_embeddings': ({1: DimHint(DYNAMIC)}, {1: DimHint(DYNAMIC)}), 'position_ids': {1: DimHint(DYNAMIC)}, 'use_cache': None})
                    >>> o_proj: Linear: DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {}) <<<
                    >>> qkv_proj: Linear: DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {}) <<<
                <<<
                >>> mlp: Phi3MLP
                  DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {})
                    >>> gate_up_proj: Linear: DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {}) <<<
                    >>> down_proj: Linear: DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {}) <<<
                    >>> activation_fn: SiLUActivation: DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {}) <<<
                <<<
                >>> input_layernorm: Phi3RMSNorm: DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {}) <<<
                >>> post_attention_layernorm: Phi3RMSNorm: DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {}) <<<
                >>> resid_attn_dropout: Dropout: DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {}) <<<
                >>> resid_mlp_dropout: Dropout: DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {}) <<<
            <<<
            >>> norm: Phi3RMSNorm: DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {}) <<<
            >>> rotary_emb: Phi3RotaryEmbedding: DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {'position_ids': {1: DimHint(DYNAMIC)}}) <<<
        <<<
        >>> lm_head: Linear: DS=(({0: DimHint(DYNAMIC), 1: DimHint(DYNAMIC)},), {}) <<<
    <<<




.. GENERATED FROM PYTHON SOURCE LINES 245-255

Evaluate the export
+++++++++++++++++++

In many cases, the export (to :class:`torch.fx.Graph`, to ONNX)
does not work on the first try. We need a way to understand
how much the model can be exported. It can be used to evaluate
the how much code needs to be rewritten or patched to be exportable.
The verbosity can be increase to show dynamic shapes, results
of the discrepancies.
Let's display the module and its submodule first.

.. GENERATED FROM PYTHON SOURCE LINES 255-266

.. code-block:: Python


    print(
        diag.pretty_text(
            with_dynamic_shape=False,
            with_shape=False,
            with_min_max=False,
            with_device=False,
            with_inputs=False,
        )
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    >>> __main__: Phi3ForCausalLM
        >>> model: Phi3Model
            >>> embed_tokens: Embedding <<<
            >>> layers[0]: Phi3DecoderLayer
                >>> self_attn: Phi3Attention
                    >>> o_proj: Linear <<<
                    >>> qkv_proj: Linear <<<
                <<<
                >>> mlp: Phi3MLP
                    >>> gate_up_proj: Linear <<<
                    >>> down_proj: Linear <<<
                    >>> activation_fn: SiLUActivation <<<
                <<<
                >>> input_layernorm: Phi3RMSNorm <<<
                >>> post_attention_layernorm: Phi3RMSNorm <<<
                >>> resid_attn_dropout: Dropout <<<
                >>> resid_mlp_dropout: Dropout <<<
            <<<
            >>> layers[1]: Phi3DecoderLayer
                >>> self_attn: Phi3Attention
                    >>> o_proj: Linear <<<
                    >>> qkv_proj: Linear <<<
                <<<
                >>> mlp: Phi3MLP
                    >>> gate_up_proj: Linear <<<
                    >>> down_proj: Linear <<<
                    >>> activation_fn: SiLUActivation <<<
                <<<
                >>> input_layernorm: Phi3RMSNorm <<<
                >>> post_attention_layernorm: Phi3RMSNorm <<<
                >>> resid_attn_dropout: Dropout <<<
                >>> resid_mlp_dropout: Dropout <<<
            <<<
            >>> norm: Phi3RMSNorm <<<
            >>> rotary_emb: Phi3RotaryEmbedding <<<
        <<<
        >>> lm_head: Linear <<<
    <<<




.. GENERATED FROM PYTHON SOURCE LINES 267-270

The we try to export to see the submodule failing the whole model.
We can pickle the failing model and restore it to speedup
the refactoring to make it work.

.. GENERATED FROM PYTHON SOURCE LINES 270-278

.. code-block:: Python

    print("----------------------")
    ep = diag.try_export(
        exporter="fx",
        use_dynamic_shapes=True,
        exporter_kwargs=dict(strict=False),
        verbose=1,
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    ----------------------

    [torch_export] export starts with backed_size_oblivious=False
    [try_export-FX]  M:__main__-Phi3ForCausalLM --- FAIL, step=EXPORT, reason=Cannot associate shape [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}] specified at `dynamic_shapes['past_key_values']` to non-tensor type <class 'transformers.cache_utils.DynamicCache'> at `inputs['past_key_values']` (expected None) --- For more information about this error, see: https://pytorch.org/docs/main/generated/exportdb/index.html#dynamic-shapes-validation ---  --- The error above occurred when calling torch.export.export. If you would like to view some more information about this error, and get a list of all other errors that may occur in your export call, you can replace your `export()` call with `draft_export()`.['Traceback (most recent call last):\n', '  File "/home/xadupre/github/experimental-experiment/experimental_experiment/torch_interpreter/piece_by_piece.py", line 1573, in _try_export_no_bypass_export\n    ep = torch_export(\n         ^^^^^^^^^^^^^\n', '  File "/home/xadupre/github/experimental-experiment/experimental_experiment/export_helpers.py", line 164, in torch_export\n    return torch.export.export(\n           ^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/__init__.py", line 205, in export\n    raise e\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/__init__.py", line 171, in export\n    return _export(\n           ^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 1343, in wrapper\n    raise e\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 1309, in wrapper\n    ep = fn(*args, **kwargs)\n         ^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/exported_program.py", line 124, in wrapper\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 2507, in _export\n    ep = _export_for_training(\n         ^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 1343, in wrapper\n    raise e\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 1309, in wrapper\n    ep = fn(*args, **kwargs)\n         ^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/exported_program.py", line 124, in wrapper\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 2296, in _export_for_training\n    export_artifact = export_func(\n                      ^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 2178, in _non_strict_export\n    ) = make_fake_inputs(\n        ^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/_export/non_strict_utils.py", line 419, in make_fake_inputs\n    _check_dynamic_shapes(combined_args, dynamic_shapes)\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py", line 1079, in _check_dynamic_shapes\n    _tree_map_with_path(check_shape, combined_args, dynamic_shapes, tree_name="inputs")\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py", line 639, in _tree_map_with_path\n    return tree_map_with_path(f, tree, *dynamic_shapes, is_leaf=is_leaf)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/utils/_pytree.py", line 2207, in tree_map_with_path\n    return treespec.unflatten(func(*xs) for xs in zip(*all_keypath_leaves, strict=True))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/utils/_pytree.py", line 1280, in unflatten\n    leaves = list(leaves)\n             ^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/utils/_pytree.py", line 2207, in <genexpr>\n    return treespec.unflatten(func(*xs) for xs in zip(*all_keypath_leaves, strict=True))\n                              ^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py", line 636, in f\n    return func(path, t, *dynamic_shapes)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py", line 1072, in check_shape\n    raise UserError(\n', "torch._dynamo.exc.UserError: Cannot associate shape [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}] specified at `dynamic_shapes['past_key_values']` to non-tensor type <class 'transformers.cache_utils.DynamicCache'> at `inputs['past_key_values']` (expected None)\nFor more information about this error, see: https://pytorch.org/docs/main/generated/exportdb/index.html#dynamic-shapes-validation\n\nThe error above occurred when calling torch.export.export. If you would like to view some more information about this error, and get a list of all other errors that may occur in your export call, you can replace your `export()` call with `draft_export()`.\n"]
    [torch_export] export starts with backed_size_oblivious=False
    [try_export-FX] .. M:model-Phi3Model --- FAIL, step=EXPORT, reason=Cannot associate shape [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}] specified at `dynamic_shapes['past_key_values']` to non-tensor type <class 'transformers.cache_utils.DynamicCache'> at `inputs['past_key_values']` (expected None) --- For more information about this error, see: https://pytorch.org/docs/main/generated/exportdb/index.html#dynamic-shapes-validation ---  --- The error above occurred when calling torch.export.export. If you would like to view some more information about this error, and get a list of all other errors that may occur in your export call, you can replace your `export()` call with `draft_export()`.['Traceback (most recent call last):\n', '  File "/home/xadupre/github/experimental-experiment/experimental_experiment/torch_interpreter/piece_by_piece.py", line 1573, in _try_export_no_bypass_export\n    ep = torch_export(\n         ^^^^^^^^^^^^^\n', '  File "/home/xadupre/github/experimental-experiment/experimental_experiment/export_helpers.py", line 164, in torch_export\n    return torch.export.export(\n           ^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/__init__.py", line 205, in export\n    raise e\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/__init__.py", line 171, in export\n    return _export(\n           ^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 1343, in wrapper\n    raise e\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 1309, in wrapper\n    ep = fn(*args, **kwargs)\n         ^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/exported_program.py", line 124, in wrapper\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 2507, in _export\n    ep = _export_for_training(\n         ^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 1343, in wrapper\n    raise e\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 1309, in wrapper\n    ep = fn(*args, **kwargs)\n         ^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/exported_program.py", line 124, in wrapper\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 2296, in _export_for_training\n    export_artifact = export_func(\n                      ^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 2178, in _non_strict_export\n    ) = make_fake_inputs(\n        ^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/_export/non_strict_utils.py", line 419, in make_fake_inputs\n    _check_dynamic_shapes(combined_args, dynamic_shapes)\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py", line 1079, in _check_dynamic_shapes\n    _tree_map_with_path(check_shape, combined_args, dynamic_shapes, tree_name="inputs")\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py", line 639, in _tree_map_with_path\n    return tree_map_with_path(f, tree, *dynamic_shapes, is_leaf=is_leaf)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/utils/_pytree.py", line 2207, in tree_map_with_path\n    return treespec.unflatten(func(*xs) for xs in zip(*all_keypath_leaves, strict=True))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/utils/_pytree.py", line 1280, in unflatten\n    leaves = list(leaves)\n             ^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/utils/_pytree.py", line 2207, in <genexpr>\n    return treespec.unflatten(func(*xs) for xs in zip(*all_keypath_leaves, strict=True))\n                              ^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py", line 636, in f\n    return func(path, t, *dynamic_shapes)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py", line 1072, in check_shape\n    raise UserError(\n', "torch._dynamo.exc.UserError: Cannot associate shape [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}] specified at `dynamic_shapes['past_key_values']` to non-tensor type <class 'transformers.cache_utils.DynamicCache'> at `inputs['past_key_values']` (expected None)\nFor more information about this error, see: https://pytorch.org/docs/main/generated/exportdb/index.html#dynamic-shapes-validation\n\nThe error above occurred when calling torch.export.export. If you would like to view some more information about this error, and get a list of all other errors that may occur in your export call, you can replace your `export()` call with `draft_export()`.\n"]
    [torch_export] export starts with backed_size_oblivious=False
    [try_export-FX] .... M:embed_tokens-Embedding --- OK: 
    [torch_export] export starts with backed_size_oblivious=False
    [try_export-FX] .... M:layers[0]-Phi3DecoderLayer --- FAIL, step=EXPORT, reason=Cannot associate shape [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}] specified at `dynamic_shapes['past_key_values']` to non-tensor type <class 'transformers.cache_utils.DynamicCache'> at `inputs['past_key_values']` (expected None) --- For more information about this error, see: https://pytorch.org/docs/main/generated/exportdb/index.html#dynamic-shapes-validation ---  --- The error above occurred when calling torch.export.export. If you would like to view some more information about this error, and get a list of all other errors that may occur in your export call, you can replace your `export()` call with `draft_export()`.['Traceback (most recent call last):\n', '  File "/home/xadupre/github/experimental-experiment/experimental_experiment/torch_interpreter/piece_by_piece.py", line 1573, in _try_export_no_bypass_export\n    ep = torch_export(\n         ^^^^^^^^^^^^^\n', '  File "/home/xadupre/github/experimental-experiment/experimental_experiment/export_helpers.py", line 164, in torch_export\n    return torch.export.export(\n           ^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/__init__.py", line 205, in export\n    raise e\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/__init__.py", line 171, in export\n    return _export(\n           ^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 1343, in wrapper\n    raise e\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 1309, in wrapper\n    ep = fn(*args, **kwargs)\n         ^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/exported_program.py", line 124, in wrapper\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 2507, in _export\n    ep = _export_for_training(\n         ^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 1343, in wrapper\n    raise e\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 1309, in wrapper\n    ep = fn(*args, **kwargs)\n         ^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/exported_program.py", line 124, in wrapper\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 2296, in _export_for_training\n    export_artifact = export_func(\n                      ^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 2178, in _non_strict_export\n    ) = make_fake_inputs(\n        ^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/_export/non_strict_utils.py", line 419, in make_fake_inputs\n    _check_dynamic_shapes(combined_args, dynamic_shapes)\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py", line 1079, in _check_dynamic_shapes\n    _tree_map_with_path(check_shape, combined_args, dynamic_shapes, tree_name="inputs")\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py", line 639, in _tree_map_with_path\n    return tree_map_with_path(f, tree, *dynamic_shapes, is_leaf=is_leaf)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/utils/_pytree.py", line 2207, in tree_map_with_path\n    return treespec.unflatten(func(*xs) for xs in zip(*all_keypath_leaves, strict=True))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/utils/_pytree.py", line 1280, in unflatten\n    leaves = list(leaves)\n             ^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/utils/_pytree.py", line 2207, in <genexpr>\n    return treespec.unflatten(func(*xs) for xs in zip(*all_keypath_leaves, strict=True))\n                              ^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py", line 636, in f\n    return func(path, t, *dynamic_shapes)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py", line 1072, in check_shape\n    raise UserError(\n', "torch._dynamo.exc.UserError: Cannot associate shape [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}] specified at `dynamic_shapes['past_key_values']` to non-tensor type <class 'transformers.cache_utils.DynamicCache'> at `inputs['past_key_values']` (expected None)\nFor more information about this error, see: https://pytorch.org/docs/main/generated/exportdb/index.html#dynamic-shapes-validation\n\nThe error above occurred when calling torch.export.export. If you would like to view some more information about this error, and get a list of all other errors that may occur in your export call, you can replace your `export()` call with `draft_export()`.\n"]
    [torch_export] export starts with backed_size_oblivious=False
    [try_export-FX] ...... M:self_attn-Phi3Attention --- FAIL, step=EXPORT, reason=Cannot associate shape [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}] specified at `dynamic_shapes['past_key_values']` to non-tensor type <class 'transformers.cache_utils.DynamicCache'> at `inputs['past_key_values']` (expected None) --- For more information about this error, see: https://pytorch.org/docs/main/generated/exportdb/index.html#dynamic-shapes-validation ---  --- The error above occurred when calling torch.export.export. If you would like to view some more information about this error, and get a list of all other errors that may occur in your export call, you can replace your `export()` call with `draft_export()`.['Traceback (most recent call last):\n', '  File "/home/xadupre/github/experimental-experiment/experimental_experiment/torch_interpreter/piece_by_piece.py", line 1573, in _try_export_no_bypass_export\n    ep = torch_export(\n         ^^^^^^^^^^^^^\n', '  File "/home/xadupre/github/experimental-experiment/experimental_experiment/export_helpers.py", line 164, in torch_export\n    return torch.export.export(\n           ^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/__init__.py", line 205, in export\n    raise e\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/__init__.py", line 171, in export\n    return _export(\n           ^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 1343, in wrapper\n    raise e\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 1309, in wrapper\n    ep = fn(*args, **kwargs)\n         ^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/exported_program.py", line 124, in wrapper\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 2507, in _export\n    ep = _export_for_training(\n         ^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 1343, in wrapper\n    raise e\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 1309, in wrapper\n    ep = fn(*args, **kwargs)\n         ^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/exported_program.py", line 124, in wrapper\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 2296, in _export_for_training\n    export_artifact = export_func(\n                      ^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 2178, in _non_strict_export\n    ) = make_fake_inputs(\n        ^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/_export/non_strict_utils.py", line 419, in make_fake_inputs\n    _check_dynamic_shapes(combined_args, dynamic_shapes)\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py", line 1079, in _check_dynamic_shapes\n    _tree_map_with_path(check_shape, combined_args, dynamic_shapes, tree_name="inputs")\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py", line 639, in _tree_map_with_path\n    return tree_map_with_path(f, tree, *dynamic_shapes, is_leaf=is_leaf)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/utils/_pytree.py", line 2207, in tree_map_with_path\n    return treespec.unflatten(func(*xs) for xs in zip(*all_keypath_leaves, strict=True))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/utils/_pytree.py", line 1280, in unflatten\n    leaves = list(leaves)\n             ^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/utils/_pytree.py", line 2207, in <genexpr>\n    return treespec.unflatten(func(*xs) for xs in zip(*all_keypath_leaves, strict=True))\n                              ^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py", line 636, in f\n    return func(path, t, *dynamic_shapes)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py", line 1072, in check_shape\n    raise UserError(\n', "torch._dynamo.exc.UserError: Cannot associate shape [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}] specified at `dynamic_shapes['past_key_values']` to non-tensor type <class 'transformers.cache_utils.DynamicCache'> at `inputs['past_key_values']` (expected None)\nFor more information about this error, see: https://pytorch.org/docs/main/generated/exportdb/index.html#dynamic-shapes-validation\n\nThe error above occurred when calling torch.export.export. If you would like to view some more information about this error, and get a list of all other errors that may occur in your export call, you can replace your `export()` call with `draft_export()`.\n"]
    [torch_export] export starts with backed_size_oblivious=False
    [try_export-FX] ........ M:o_proj-Linear --- OK: 
    [torch_export] export starts with backed_size_oblivious=False
    [try_export-FX] ........ M:qkv_proj-Linear --- OK: 
    [torch_export] export starts with backed_size_oblivious=False
    [try_export-FX] ...... M:mlp-Phi3MLP --- OK: 
    [torch_export] export starts with backed_size_oblivious=False
    [try_export-FX] ...... M:input_layernorm-Phi3RMSNorm --- OK: 
    [torch_export] export starts with backed_size_oblivious=False
    [try_export-FX] ...... M:post_attention_layernorm-Phi3RMSNorm --- OK: 
    [torch_export] export starts with backed_size_oblivious=False
    [try_export-FX] ...... M:resid_attn_dropout-Dropout --- OK: 
    [torch_export] export starts with backed_size_oblivious=False
    [try_export-FX] ...... M:resid_mlp_dropout-Dropout --- OK: 
    [torch_export] export starts with backed_size_oblivious=False
    [try_export-FX] .... M:layers[1]-Phi3DecoderLayer --- FAIL, step=EXPORT, reason=Cannot associate shape [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}] specified at `dynamic_shapes['past_key_values']` to non-tensor type <class 'transformers.cache_utils.DynamicCache'> at `inputs['past_key_values']` (expected None) --- For more information about this error, see: https://pytorch.org/docs/main/generated/exportdb/index.html#dynamic-shapes-validation ---  --- The error above occurred when calling torch.export.export. If you would like to view some more information about this error, and get a list of all other errors that may occur in your export call, you can replace your `export()` call with `draft_export()`.['Traceback (most recent call last):\n', '  File "/home/xadupre/github/experimental-experiment/experimental_experiment/torch_interpreter/piece_by_piece.py", line 1573, in _try_export_no_bypass_export\n    ep = torch_export(\n         ^^^^^^^^^^^^^\n', '  File "/home/xadupre/github/experimental-experiment/experimental_experiment/export_helpers.py", line 164, in torch_export\n    return torch.export.export(\n           ^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/__init__.py", line 205, in export\n    raise e\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/__init__.py", line 171, in export\n    return _export(\n           ^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 1343, in wrapper\n    raise e\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 1309, in wrapper\n    ep = fn(*args, **kwargs)\n         ^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/exported_program.py", line 124, in wrapper\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 2507, in _export\n    ep = _export_for_training(\n         ^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 1343, in wrapper\n    raise e\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 1309, in wrapper\n    ep = fn(*args, **kwargs)\n         ^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/exported_program.py", line 124, in wrapper\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 2296, in _export_for_training\n    export_artifact = export_func(\n                      ^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 2178, in _non_strict_export\n    ) = make_fake_inputs(\n        ^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/_export/non_strict_utils.py", line 419, in make_fake_inputs\n    _check_dynamic_shapes(combined_args, dynamic_shapes)\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py", line 1079, in _check_dynamic_shapes\n    _tree_map_with_path(check_shape, combined_args, dynamic_shapes, tree_name="inputs")\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py", line 639, in _tree_map_with_path\n    return tree_map_with_path(f, tree, *dynamic_shapes, is_leaf=is_leaf)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/utils/_pytree.py", line 2207, in tree_map_with_path\n    return treespec.unflatten(func(*xs) for xs in zip(*all_keypath_leaves, strict=True))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/utils/_pytree.py", line 1280, in unflatten\n    leaves = list(leaves)\n             ^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/utils/_pytree.py", line 2207, in <genexpr>\n    return treespec.unflatten(func(*xs) for xs in zip(*all_keypath_leaves, strict=True))\n                              ^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py", line 636, in f\n    return func(path, t, *dynamic_shapes)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py", line 1072, in check_shape\n    raise UserError(\n', "torch._dynamo.exc.UserError: Cannot associate shape [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}] specified at `dynamic_shapes['past_key_values']` to non-tensor type <class 'transformers.cache_utils.DynamicCache'> at `inputs['past_key_values']` (expected None)\nFor more information about this error, see: https://pytorch.org/docs/main/generated/exportdb/index.html#dynamic-shapes-validation\n\nThe error above occurred when calling torch.export.export. If you would like to view some more information about this error, and get a list of all other errors that may occur in your export call, you can replace your `export()` call with `draft_export()`.\n"]
    [torch_export] export starts with backed_size_oblivious=False
    [try_export-FX] ...... M:self_attn-Phi3Attention --- FAIL, step=EXPORT, reason=Cannot associate shape [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}] specified at `dynamic_shapes['past_key_values']` to non-tensor type <class 'transformers.cache_utils.DynamicCache'> at `inputs['past_key_values']` (expected None) --- For more information about this error, see: https://pytorch.org/docs/main/generated/exportdb/index.html#dynamic-shapes-validation ---  --- The error above occurred when calling torch.export.export. If you would like to view some more information about this error, and get a list of all other errors that may occur in your export call, you can replace your `export()` call with `draft_export()`.['Traceback (most recent call last):\n', '  File "/home/xadupre/github/experimental-experiment/experimental_experiment/torch_interpreter/piece_by_piece.py", line 1573, in _try_export_no_bypass_export\n    ep = torch_export(\n         ^^^^^^^^^^^^^\n', '  File "/home/xadupre/github/experimental-experiment/experimental_experiment/export_helpers.py", line 164, in torch_export\n    return torch.export.export(\n           ^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/__init__.py", line 205, in export\n    raise e\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/__init__.py", line 171, in export\n    return _export(\n           ^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 1343, in wrapper\n    raise e\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 1309, in wrapper\n    ep = fn(*args, **kwargs)\n         ^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/exported_program.py", line 124, in wrapper\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 2507, in _export\n    ep = _export_for_training(\n         ^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 1343, in wrapper\n    raise e\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 1309, in wrapper\n    ep = fn(*args, **kwargs)\n         ^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/exported_program.py", line 124, in wrapper\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 2296, in _export_for_training\n    export_artifact = export_func(\n                      ^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 2178, in _non_strict_export\n    ) = make_fake_inputs(\n        ^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/_export/non_strict_utils.py", line 419, in make_fake_inputs\n    _check_dynamic_shapes(combined_args, dynamic_shapes)\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py", line 1079, in _check_dynamic_shapes\n    _tree_map_with_path(check_shape, combined_args, dynamic_shapes, tree_name="inputs")\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py", line 639, in _tree_map_with_path\n    return tree_map_with_path(f, tree, *dynamic_shapes, is_leaf=is_leaf)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/utils/_pytree.py", line 2207, in tree_map_with_path\n    return treespec.unflatten(func(*xs) for xs in zip(*all_keypath_leaves, strict=True))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/utils/_pytree.py", line 1280, in unflatten\n    leaves = list(leaves)\n             ^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/utils/_pytree.py", line 2207, in <genexpr>\n    return treespec.unflatten(func(*xs) for xs in zip(*all_keypath_leaves, strict=True))\n                              ^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py", line 636, in f\n    return func(path, t, *dynamic_shapes)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/dynamic_shapes.py", line 1072, in check_shape\n    raise UserError(\n', "torch._dynamo.exc.UserError: Cannot associate shape [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}] specified at `dynamic_shapes['past_key_values']` to non-tensor type <class 'transformers.cache_utils.DynamicCache'> at `inputs['past_key_values']` (expected None)\nFor more information about this error, see: https://pytorch.org/docs/main/generated/exportdb/index.html#dynamic-shapes-validation\n\nThe error above occurred when calling torch.export.export. If you would like to view some more information about this error, and get a list of all other errors that may occur in your export call, you can replace your `export()` call with `draft_export()`.\n"]
    [torch_export] export starts with backed_size_oblivious=False
    [try_export-FX] ........ M:o_proj-Linear --- OK: 
    [torch_export] export starts with backed_size_oblivious=False
    [try_export-FX] ........ M:qkv_proj-Linear --- OK: 
    [torch_export] export starts with backed_size_oblivious=False
    [try_export-FX] ...... M:mlp-Phi3MLP --- OK: 
    [torch_export] export starts with backed_size_oblivious=False
    [try_export-FX] ...... M:input_layernorm-Phi3RMSNorm --- OK: 
    [torch_export] export starts with backed_size_oblivious=False
    [try_export-FX] ...... M:post_attention_layernorm-Phi3RMSNorm --- OK: 
    [torch_export] export starts with backed_size_oblivious=False
    [try_export-FX] ...... M:resid_attn_dropout-Dropout --- OK: 
    [torch_export] export starts with backed_size_oblivious=False
    [try_export-FX] ...... M:resid_mlp_dropout-Dropout --- OK: 
    [torch_export] export starts with backed_size_oblivious=False
    [try_export-FX] .... M:norm-Phi3RMSNorm --- OK: 
    [torch_export] export starts with backed_size_oblivious=False



    def forward(self, arg0_1: "f32[48]", arg1_1: "f32[48]", arg2_1: "f32[s77, s27, 3072]", arg3_1: "i64[1, s9]"):
        # No stacktrace found for following nodes
        _set_grad_enabled = torch._C._set_grad_enabled(False);  _set_grad_enabled = None
        max_1: "i64[]" = torch.ops.aten.max.default(arg3_1);  arg3_1 = None
        add: "i64[]" = torch.ops.aten.add.Tensor(max_1, 1);  max_1 = None
        gt: "b8[]" = torch.ops.aten.gt.Scalar(add, 4096);  add = None
        ne: "b8[]" = torch.ops.aten.ne.Scalar(gt, 0);  gt = None
        item: "Sym(Eq(u0, 1))" = torch.ops.aten.item.default(ne);  ne = item = None
        _set_grad_enabled_1 = torch._C._set_grad_enabled(True);  _set_grad_enabled_1 = None
    



    def forward(self, arg0_1: "f32[48]", arg1_1: "f32[48]", arg2_1: "f32[s77, s27, 3072]", arg3_1: "i64[1, s9]"):
        # No stacktrace found for following nodes
        _set_grad_enabled = torch._C._set_grad_enabled(False);  _set_grad_enabled = None
        max_1: "i64[]" = torch.ops.aten.max.default(arg3_1);  arg3_1 = None
        add: "i64[]" = torch.ops.aten.add.Tensor(max_1, 1);  max_1 = None
        gt: "b8[]" = torch.ops.aten.gt.Scalar(add, 4096);  add = None
        ne: "b8[]" = torch.ops.aten.ne.Scalar(gt, 0);  gt = None
        item: "Sym(Eq(u0, 1))" = torch.ops.aten.item.default(ne);  ne = item = None
        _set_grad_enabled_1 = torch._C._set_grad_enabled(True);  _set_grad_enabled_1 = None
    
    [try_export-FX] .... M:rotary_emb-Phi3RotaryEmbedding --- FAIL, step=EXPORT, reason=Could not guard on data-dependent expression Eq(u0, 1) (unhinted: Eq(u0, 1)).  (Size-like symbols: none) ---  --- consider using data-dependent friendly APIs such as guard_or_false, guard_or_true and statically_known_true. --- Caused by: (_export/non_strict_utils.py:1159 in __torch_function__) --- For more information, run with TORCH_LOGS="dynamic" --- For extended logs when we create symbols, also add TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL="u0" --- If you suspect the guard was triggered from C++, add TORCHDYNAMO_EXTENDED_DEBUG_CPP=1 --- For more debugging help, see https://docs.google.com/document/d/1HSuTTVvYH1pTew89Rtpeu84Ht3nQEFTYhAX3Ypa_xJs/edit?usp=sharing ---  --- For C++ stack trace, run with TORCHDYNAMO_EXTENDED_DEBUG_CPP=1 ---  --- The following call raised this error: ---   File "/home/xadupre/github/transformers/src/transformers/modeling_rope_utils.py", line 63, in longrope_frequency_update ---     if seq_len > original_max_position_embeddings: ---  ---  --- The error above occurred when calling torch.export.export. If you would like to view some more information about this error, and get a list of all other errors that may occur in your export call, you can replace your `export()` call with `draft_export()`.['Traceback (most recent call last):\n', '  File "/home/xadupre/github/experimental-experiment/experimental_experiment/torch_interpreter/piece_by_piece.py", line 1573, in _try_export_no_bypass_export\n    ep = torch_export(\n         ^^^^^^^^^^^^^\n', '  File "/home/xadupre/github/experimental-experiment/experimental_experiment/export_helpers.py", line 164, in torch_export\n    return torch.export.export(\n           ^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/__init__.py", line 205, in export\n    raise e\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/__init__.py", line 171, in export\n    return _export(\n           ^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 1343, in wrapper\n    raise e\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 1309, in wrapper\n    ep = fn(*args, **kwargs)\n         ^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/exported_program.py", line 124, in wrapper\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 2507, in _export\n    ep = _export_for_training(\n         ^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 1343, in wrapper\n    raise e\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 1309, in wrapper\n    ep = fn(*args, **kwargs)\n         ^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/exported_program.py", line 124, in wrapper\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 2296, in _export_for_training\n    export_artifact = export_func(\n                      ^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 2225, in _non_strict_export\n    aten_export_artifact = _to_aten_func(\n                           ^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 2002, in _export_to_aten_ir_make_fx\n    gm, graph_signature = transform(_make_fx_helper)(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 2132, in _aot_export_non_strict\n    gm, sig = aot_export(stack, wrapped_mod, args, kwargs=kwargs, **flags)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 1910, in _make_fx_helper\n    gm = make_fx(\n         ^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py", line 2824, in wrapped\n    return make_fx_tracer.trace(f, *args)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py", line 2725, in trace\n    return self._trace_inner(f, *args)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py", line 2686, in _trace_inner\n    t = dispatch_trace(\n        ^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/_compile.py", line 54, in inner\n    return disable_fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 1241, in _fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py", line 1533, in dispatch_trace\n    graph = tracer.trace(root, concrete_args)  # type: ignore[arg-type]\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py", line 2264, in trace\n    res = super().trace(root, concrete_args)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 1241, in _fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/fx/_symbolic_trace.py", line 890, in trace\n    (self.create_arg(fn(*args)),),\n                     ^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py", line 1603, in wrapped\n    out = f(*tensors)  # type:ignore[call-arg]\n          ^^^^^^^^^^^\n', '  File "<string>", line 1, in <lambda>\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 1794, in wrapped_fn\n    return tuple(flat_fn(*args))\n                 ^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/utils.py", line 204, in flat_fn\n    tree_out = fn(*args, **kwargs)\n               ^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/graph_capture_wrappers.py", line 1496, in functional_call\n    out = mod(*args[params_len:], **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/fx/_symbolic_trace.py", line 864, in module_call_wrapper\n    return self.call_module(mod, forward, args, kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py", line 2353, in call_module\n    return Tracer.call_module(self, m, forward, args, kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/fx/_symbolic_trace.py", line 572, in call_module\n    ret_val = forward(*args, **kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/fx/_symbolic_trace.py", line 857, in forward\n    return _orig_module_call(mod, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1779, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1790, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/export/_trace.py", line 2116, in forward\n    tree_out = mod(*args, **kwargs)\n               ^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/fx/_symbolic_trace.py", line 864, in module_call_wrapper\n    return self.call_module(mod, forward, args, kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py", line 2353, in call_module\n    return Tracer.call_module(self, m, forward, args, kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/fx/_symbolic_trace.py", line 572, in call_module\n    ret_val = forward(*args, **kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/fx/_symbolic_trace.py", line 857, in forward\n    return _orig_module_call(mod, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1779, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1790, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 124, in decorate_context\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/github/transformers/src/transformers/modeling_rope_utils.py", line 126, in wrapper\n    longrope_frequency_update(self, position_ids, device=x.device, **kwargs)\n', '  File "/home/xadupre/github/transformers/src/transformers/modeling_rope_utils.py", line 63, in longrope_frequency_update\n    if seq_len > original_max_position_embeddings:\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py", line 1654, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py", line 1725, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/_export/non_strict_utils.py", line 1159, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py", line 546, in guard_bool\n    r = self.evaluate()\n        ^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py", line 520, in evaluate\n    return self.shape_env.evaluate_sym_node(self, size_oblivious)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py", line 7479, in evaluate_sym_node\n    return self.evaluate_expr(\n           ^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py", line 7575, in evaluate_expr\n    return self._inner_evaluate_expr(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/fx/experimental/recording.py", line 285, in wrapper\n    return retlog(fn(*args, **kwargs))\n                  ^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py", line 7598, in _inner_evaluate_expr\n    return self._evaluate_expr(\n           ^^^^^^^^^^^^^^^^^^^^\n', '  File "/home/xadupre/vv/this312/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py", line 7793, in _evaluate_expr\n    raise self._make_data_dependent_error(\n', 'torch.fx.experimental.symbolic_shapes.GuardOnDataDependentSymNode: Could not guard on data-dependent expression Eq(u0, 1) (unhinted: Eq(u0, 1)).  (Size-like symbols: none)\n\nconsider using data-dependent friendly APIs such as guard_or_false, guard_or_true and statically_known_true.\nCaused by: (_export/non_strict_utils.py:1159 in __torch_function__)\nFor more information, run with TORCH_LOGS="dynamic"\nFor extended logs when we create symbols, also add TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL="u0"\nIf you suspect the guard was triggered from C++, add TORCHDYNAMO_EXTENDED_DEBUG_CPP=1\nFor more debugging help, see https://docs.google.com/document/d/1HSuTTVvYH1pTew89Rtpeu84Ht3nQEFTYhAX3Ypa_xJs/edit?usp=sharing\n\nFor C++ stack trace, run with TORCHDYNAMO_EXTENDED_DEBUG_CPP=1\n\nThe following call raised this error:\n  File "/home/xadupre/github/transformers/src/transformers/modeling_rope_utils.py", line 63, in longrope_frequency_update\n    if seq_len > original_max_position_embeddings:\n\n\nThe error above occurred when calling torch.export.export. If you would like to view some more information about this error, and get a list of all other errors that may occur in your export call, you can replace your `export()` call with `draft_export()`.\n']
    [try_export-FX] .... M:rotary_emb-Phi3RotaryEmbedding --- FAIL: Could not guard on data-depend...
    [torch_export] export starts with backed_size_oblivious=False
    [try_export-FX] .. M:lm_head-Linear --- OK: 




.. GENERATED FROM PYTHON SOURCE LINES 279-280

Let's display a report.

.. GENERATED FROM PYTHON SOURCE LINES 280-283

.. code-block:: Python

    print(f"success: {ep.status}")
    print(diag.get_export_report())





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    success: 2
    __main__                         Phi3ForCausalLM       FAIL -- step=EXPORT, reason='Cannot associate shape [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint...'
    ..model                          Phi3Model             FAIL -- step=EXPORT, reason='Cannot associate shape [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint...'
    ....embed_tokens                 Embedding             OK -- ExportedProgram
    ....layers[0]                    Phi3DecoderLayer      FAIL -- step=EXPORT, reason='Cannot associate shape [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint...'
    ......self_attn                  Phi3Attention         FAIL -- step=EXPORT, reason='Cannot associate shape [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint...'
    ........o_proj                   Linear                OK -- ExportedProgram
    ........qkv_proj                 Linear                OK -- ExportedProgram
    ......mlp                        Phi3MLP               OK -- ExportedProgram
    ........gate_up_proj             Linear                <OK-2i-0>
    ........down_proj                Linear                <OK-2i-0>
    ........activation_fn            SiLUActivation        <OK-2i-0>
    ......input_layernorm            Phi3RMSNorm           OK -- ExportedProgram
    ......post_attention_layernorm   Phi3RMSNorm           OK -- ExportedProgram
    ......resid_attn_dropout         Dropout               OK -- ExportedProgram
    ......resid_mlp_dropout          Dropout               OK -- ExportedProgram
    ....layers[1]                    Phi3DecoderLayer      FAIL -- step=EXPORT, reason='Cannot associate shape [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint...'
    ......self_attn                  Phi3Attention         FAIL -- step=EXPORT, reason='Cannot associate shape [{0: DimHint(DYNAMIC), 2: DimHint(DYNAMIC)}, {0: DimHint(DYNAMIC), 2: DimHint...'
    ........o_proj                   Linear                OK -- ExportedProgram
    ........qkv_proj                 Linear                OK -- ExportedProgram
    ......mlp                        Phi3MLP               OK -- ExportedProgram
    ........gate_up_proj             Linear                <OK-2i-0>
    ........down_proj                Linear                <OK-2i-0>
    ........activation_fn            SiLUActivation        <OK-2i-0>
    ......input_layernorm            Phi3RMSNorm           OK -- ExportedProgram
    ......post_attention_layernorm   Phi3RMSNorm           OK -- ExportedProgram
    ......resid_attn_dropout         Dropout               OK -- ExportedProgram
    ......resid_mlp_dropout          Dropout               OK -- ExportedProgram
    ....norm                         Phi3RMSNorm           OK -- ExportedProgram
    ....rotary_emb                   Phi3RotaryEmbedding   FAIL -- step=EXPORT, reason='Could not guard on data-dependent expression Eq(u0, 1) (unhinted: Eq(u0, 1)).  (Size-like symbols: n...'
    ..lm_head                        Linear                OK -- ExportedProgram




.. GENERATED FROM PYTHON SOURCE LINES 284-291

Replace the failing module by a custom op
+++++++++++++++++++++++++++++++++++++++++

The main module is not exportable because one piece cannot be exported.
But maybe if we assume it works, maybe everything else is working.
So let's try to replace this class by a custom op.
This will be something for another example.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 7.553 seconds)


.. _sphx_glr_download_auto_recipes_plot_exporter_exporter_phi35_piece.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_exporter_exporter_phi35_piece.ipynb <plot_exporter_exporter_phi35_piece.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_exporter_exporter_phi35_piece.py <plot_exporter_exporter_phi35_piece.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_exporter_exporter_phi35_piece.zip <plot_exporter_exporter_phi35_piece.zip>`


.. include:: plot_exporter_exporter_phi35_piece.recommendations


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
