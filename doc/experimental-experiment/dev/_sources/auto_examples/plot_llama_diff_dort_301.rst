
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_llama_diff_dort_301.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_plot_llama_diff_dort_301.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_llama_diff_dort_301.py:


.. _l-plot-onnxrt-diff:

301: Compares LLAMA exporters for onnxrt backend
================================================

The script compares exported models in :epkg:`pytorch`
using :epkg:`onnxrt backend`. It tries to do a side by side
of the execution of both models.

To run the script:

::

    python _doc/examples/plot_llama_diff_dort --help


The following example compares the forward step for mixed precision on cuda
and produces all the intermediate onnx graphs.

::

    python _doc/examples/plot_llama_diff_dort.py --part model --ortopt 1 \
            --cuda 1 --backward 0 --mixed 1

You may use ``--mixed=1`` to compare the backward graphs.

Some helpers
++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 31-96

.. code-block:: Python


    from experimental_experiment.args import get_parsed_args

    script_args = get_parsed_args(
        "plot_llama_diff_export",
        description=__doc__,
        part=("model", "one value among model, ..."),
        ortopt=(1, "run onnxruntime optimization"),
        backward=(0, "does one operator for backward"),
        cuda=(0, "use cuda or not"),
        mixed=(0, "use miwed precision"),
        opset=(18, "onnx opset"),
        expose="part,exporter,ortopt,cuda,mixed,opset",
    )


    import copy
    import os
    import warnings
    import logging

    try:
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            import onnxruntime

            has_cuda = "CUDAExecutionProvider" in onnxruntime.get_available_providers()
    except ImportError:
        print("onnxruntime not available.")
        import sys

        sys.exit(0)

    import onnx
    from onnx_array_api.reference import compare_onnx_execution, ExtendedReferenceEvaluator
    import torch
    from torch._dynamo.backends.common import aot_autograd
    from experimental_experiment.ext_test_case import unit_test_going
    from experimental_experiment.convert.convert_helper import (
        ort_optimize,
        optimize_model_proto_oxs,
    )
    from experimental_experiment.torch_models.llama_helper import get_llama_model
    from experimental_experiment.torch_models.dump_helper import (
        assert_all_close,
        dump_onnx,
        reorder_functions_in_proto,
        inputs_from_onnx_model,
        build_matching_inputs,
        results_to_string,
    )
    from experimental_experiment.torch_models.training_helper import (
        train_loop,
        make_aot_ort,
    )
    from experimental_experiment.torch_dynamo import (
        onnx_debug_backend,
        get_decomposition_table,
    )

    has_cuda = has_cuda and torch.cuda.is_available()
    logging.disable(logging.ERROR)
    provider = "cuda" if has_cuda else "cpu"









.. GENERATED FROM PYTHON SOURCE LINES 97-99

The exporting functions
+++++++++++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 99-112

.. code-block:: Python


    print(f"part={script_args.part}")
    ortopt = script_args.ortopt in (1, "1")
    print(f"ortopt={ortopt}")
    backward = script_args.backward in (1, "1")
    print(f"backward={backward}")
    use_cuda = script_args.cuda in (1, "1")
    print(f"cuda={use_cuda}")
    use_mixed = script_args.mixed in (1, "1")
    print(f"mixed={use_mixed}")
    opset = int(script_args.opset)
    print(f"opset={opset}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    part=model
    ortopt=True
    backward=False
    cuda=False
    mixed=False
    opset=18




.. GENERATED FROM PYTHON SOURCE LINES 113-115

Model and data
++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 115-165

.. code-block:: Python


    if unit_test_going():
        kwargs = dict(input_dims=[(2, 1024)] * 2)
    else:
        kwargs = dict(
            input_dims=[(2, 1024)] * 2,
            _attn_implementation="eager",
            num_hidden_layers=1,
            hidden_size=512,
            vocab_size=4000,
            intermediate_size=2000,
            max_position_embeddings=2048,
            num_attention_heads=8,
        )

    if script_args.part == "model":
        model, inputs = get_llama_model(**kwargs)
    else:
        raise RuntimeError(f"Unexpected value for part={script_args.part!r}")

    if use_cuda:
        model = model.to("cuda")
        inputs = [[i.to("cuda") for i in inp] for inp in inputs]

    print(f"simple run with {len(inputs)} inputs")
    if backward:
        if use_mixed:
            assert use_cuda, "mixed precision only works with cuda"
            with torch.autocast(device_type="cuda", dtype=torch.float16):
                torch.cuda.synchronize()
                expected = train_loop(copy.deepcopy(model), *inputs[0])
                torch.cuda.synchronize()
        else:
            expected = train_loop(copy.deepcopy(model), *inputs[0])
        print(
            f"-- eager mode worked, {len(expected)} gradients, first one is "
            f"{expected[0].shape}, {expected[0].dtype}"
        )
    else:
        if use_mixed:
            assert use_cuda, "mixed precision only works with cuda"
            with torch.autocast(device_type="cuda", dtype=torch.float16):
                torch.cuda.synchronize()
                expected = model(*inputs[0])
                torch.cuda.synchronize()
        else:
            expected = model(*inputs[0])
        print(results_to_string(expected))






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    simple run with 2 inputs
    1 results
      torch.float32 (2, 1024, 512) [sum=3.34e+03]




.. GENERATED FROM PYTHON SOURCE LINES 166-168

Exporting
+++++++++

.. GENERATED FROM PYTHON SOURCE LINES 168-263

.. code-block:: Python


    if hasattr(torch._dynamo.variables.misc, "LoggingLoggerVariable"):
        # A tweak to make torch.export.export work.
        torch._dynamo.variables.misc.LoggingLoggerVariable.call_method = lambda *_, **__: None


    folder = "dump_models"
    storage = {}

    if backward:
        # onnxrt backend
        local_aot_ort, _ = make_aot_ort(dynamic=False, rewrite=True)

        optimized_mod = torch.compile(
            copy.deepcopy(model), backend=local_aot_ort, dynamic=False, fullgraph=True
        )

        with dump_onnx("llama_onnxrt", folder=folder, clean=True):
            if use_mixed:
                with torch.autocast(device_type="cuda", dtype=torch.float16):
                    torch.cuda.synchronize()
                    expected_onnxrt = train_loop(optimized_mod, *inputs[0])
                    torch.cuda.synchronize()
            else:
                expected_onnxrt = train_loop(optimized_mod, *inputs[0])
        assert_all_close(expected[0], expected_onnxrt[0], atol=1e-3)
        print(
            f"-- onnxrt backend worked, {len(expected_onnxrt)} gradients, first one is "
            f"{expected_onnxrt[0].shape}, {expected_onnxrt[0].dtype}"
        )

        # debugging backend
        aot_compiler = aot_autograd(
            fw_compiler=lambda *args, **kwargs: onnx_debug_backend(
                *args,
                dump_prefix=os.path.join(folder, "llama_debug"),
                target_opset=opset,
                storage=storage,
                **kwargs,
            ),
            decompositions=get_decomposition_table(),
        )
        onnx_mod = torch.compile(copy.deepcopy(model), backend=aot_compiler, fullgraph=True)

        if use_mixed:
            with torch.autocast(device_type="cuda", dtype=torch.float16):
                torch.cuda.synchronize()
                got = train_loop(onnx_mod, *inputs[0])
                torch.cuda.synchronize()
        else:
            got = train_loop(onnx_mod, *inputs[0])
        assert_all_close(expected[0], got[0], atol=1e-2 if use_mixed else 1e-4)
        print(
            f"-- debug backend worked, {len(got)} gradients, first one is "
            f"{got[0].shape}, {got[0].dtype}"
        )

    else:
        # onnxrt backend
        local_aot_ort, _ = make_aot_ort(dynamic=True, rewrite=True)
        optimized_mod = torch.compile(model, backend=local_aot_ort, fullgraph=True)
        with dump_onnx("llama_onnxrt", folder=folder, clean=True):
            if use_mixed:
                with torch.autocast(device_type="cuda", dtype=torch.float16):
                    torch.cuda.synchronize()
                    expected_onnxrt = optimized_mod(*inputs[0])
                    torch.cuda.synchronize()
            else:
                expected_onnxrt = optimized_mod(*inputs[0])
        assert_all_close(expected, expected_onnxrt, atol=1e-2)

        # debugging backend
        aot_compiler = aot_autograd(
            fw_compiler=lambda *args, **kwargs: onnx_debug_backend(
                *args,
                dump_prefix=os.path.join(folder, "llama_debug"),
                target_opset=17,
                storage=storage,
                **kwargs,
            )
        )

        onnx_mod = torch.compile(model, backend=aot_compiler, fullgraph=True)
        if use_mixed:
            with torch.autocast(device_type="cuda", dtype=torch.float16):
                got = onnx_mod(*inputs[0])
        else:
            try:
                got = onnx_mod(*inputs[0])
            except Exception as e:
                print(f"ERROR: {e}")
                got = None
        if got is not None:
            assert_all_close(expected, got, atol=1 if use_mixed else 1e-3)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /home/xadupre/vv/this312/lib/python3.12/site-packages/torch/onnx/_internal/_exporter_legacy.py:107: UserWarning: torch.onnx.dynamo_export only implements opset version 18 for now. If you need to use a different opset version, please register them with register_custom_op.
      warnings.warn(
    Applied 17 of general pattern rewrite rules.
    Applied 1 of general pattern rewrite rules.




.. GENERATED FROM PYTHON SOURCE LINES 264-267

For forward, there are two files, one onnx model and the graph module
printed in a txt file. For backward, there are two onnx models.
Then it is multiplied by the number of backends.

.. GENERATED FROM PYTHON SOURCE LINES 267-271

.. code-block:: Python


    models = os.listdir(folder)
    print(f"exported models: {models}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    exported models: ['llama_debug_0.onnx', 'llama_onnxrt_0.txt', 'llama_debug_0.txt', 'llama_onnxrt_0.onnx']




.. GENERATED FROM PYTHON SOURCE LINES 272-273

Inputs used by the debug backend

.. GENERATED FROM PYTHON SOURCE LINES 273-279

.. code-block:: Python


    if "instance" in storage:
        feeds = storage["instance"][0]["inputs"][0]
        for k, v in feeds.items():
            print(f"-- {k} {v.dtype} {v.shape}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    -- input0 int64 (2, 1024)
    -- input1 float32 (4000, 512)
    -- input2 float32 (2, 1024)
    -- input3 float32 (32,)
    -- input4 float32 (512,)
    -- input5 float32 (512, 512)
    -- input6 float32 (512, 512)
    -- input7 float32 (512, 512)
    -- input8 float32 (512, 512)
    -- input9 float32 (512,)
    -- input10 float32 (2000, 512)
    -- input11 float32 (2000, 512)
    -- input12 float32 (512, 2000)
    -- input13 float32 (512,)




.. GENERATED FROM PYTHON SOURCE LINES 280-281

Let's the first line of the graph module

.. GENERATED FROM PYTHON SOURCE LINES 281-287

.. code-block:: Python


    if "instance" in storage:
        graph_module = storage["instance"][0]["graph_module"]
        print("\n".join(str(graph_module.graph).split("\n")[:10]))






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    graph():
        %primals_1 : [num_users=2] = placeholder[target=primals_1]
        %primals_2 : [num_users=1] = placeholder[target=primals_2]
        %primals_3 : [num_users=1] = placeholder[target=primals_3]
        %primals_4 : [num_users=1] = placeholder[target=primals_4]
        %primals_5 : [num_users=2] = placeholder[target=primals_5]
        %primals_6 : [num_users=1] = placeholder[target=primals_6]
        %primals_7 : [num_users=1] = placeholder[target=primals_7]
        %primals_8 : [num_users=1] = placeholder[target=primals_8]
        %primals_9 : [num_users=1] = placeholder[target=primals_9]




.. GENERATED FROM PYTHON SOURCE LINES 288-290

Comparison and execution
++++++++++++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 290-319

.. code-block:: Python


    if "instance" in storage:
        if backward:
            print(f"-- {len(storage['instance'])} onnx models were creates")
            for i, inst in enumerate(storage["instance"]):
                print(f"  model {i}: {len(inst['inputs'])} runs")

            # deal with backward
            onnx_models = list(sorted([m for m in models if m.endswith(".onnx")]))
            assert len(onnx_models) == 4, f"unexpected value {onnx_models}"
            onnx_models = list(sorted([m for m in models if m.endswith(".onnx") and "_1" in m]))
            assert len(onnx_models) == 2, f"unexpected value {onnx_models}"
            model_onnxrt = os.path.join(folder, onnx_models[1])
            model_debug = os.path.join(folder, onnx_models[0])
        else:
            onnx_models = list(sorted([m for m in models if m.endswith(".onnx")]))
            if len(onnx_models) == 2:
                model_onnxrt = os.path.join(folder, onnx_models[1])
                model_debug = os.path.join(folder, onnx_models[0])
            else:
                model_debug = os.path.join(folder, onnx_models[0])
                # the following error may appear:
                # Node type 'Rank' from domain 'pkg.onnxscript.torch_lib.common' is unknown
                print(f"One model is missing, onnx_models={onnx_models}")
                model_onnxrt = model_debug

        print(f"model_onnxrt={model_onnxrt}")
        print(f"model_debug={model_debug}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    model_onnxrt=dump_models/llama_onnxrt_0.onnx
    model_debug=dump_models/llama_debug_0.onnx




.. GENERATED FROM PYTHON SOURCE LINES 320-321

The inputs of both models

.. GENERATED FROM PYTHON SOURCE LINES 321-326

.. code-block:: Python


    if "instance" in storage:
        print("onnxrt:", inputs_from_onnx_model(model_onnxrt))
        print("debug:", inputs_from_onnx_model(model_debug))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    onnxrt: [('INPUT', 'primals_2', 1, (4000, 512)), ('INPUT', 'primals_1', 7, (2, 1024)), ('INPUT', 'primals_3', 1, (2, 1024)), ('INPUT', 'primals_4', 1, (32,)), ('INPUT', 'primals_6', 1, (512, 512)), ('INPUT', 'primals_7', 1, (512, 512)), ('INPUT', 'primals_8', 1, (512, 512)), ('INPUT', 'primals_9', 1, (512, 512)), ('INPUT', 'primals_11', 1, (2000, 512)), ('INPUT', 'primals_12', 1, (2000, 512)), ('INPUT', 'primals_13', 1, (512, 2000)), ('INPUT', 'primals_5', 1, (512,)), ('INPUT', 'primals_10', 1, (512,)), ('INPUT', 'primals_14', 1, (512,))]
    debug: [('INPUT', 'input0', 7, (2, 1024)), ('INPUT', 'input1', 1, (4000, 512)), ('INPUT', 'input2', 1, (2, 1024)), ('INPUT', 'input3', 1, (32,)), ('INPUT', 'input4', 1, (512,)), ('INPUT', 'input5', 1, (512, 512)), ('INPUT', 'input6', 1, (512, 512)), ('INPUT', 'input7', 1, (512, 512)), ('INPUT', 'input8', 1, (512, 512)), ('INPUT', 'input9', 1, (512,)), ('INPUT', 'input10', 1, (2000, 512)), ('INPUT', 'input11', 1, (2000, 512)), ('INPUT', 'input12', 1, (512, 2000)), ('INPUT', 'input13', 1, (512,))]




.. GENERATED FROM PYTHON SOURCE LINES 327-329

Inputs are not the same. The first model has more and some inputs were
moved into the initializer list into for `model_debug`.

.. GENERATED FROM PYTHON SOURCE LINES 329-333

.. code-block:: Python


    if "instance" in storage:
        print("debug:", inputs_from_onnx_model(model_debug, init=True))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    debug: [('INPUT', 'input0', 7, (2, 1024)), ('INPUT', 'input1', 1, (4000, 512)), ('INPUT', 'input2', 1, (2, 1024)), ('INPUT', 'input3', 1, (32,)), ('INPUT', 'input4', 1, (512,)), ('INPUT', 'input5', 1, (512, 512)), ('INPUT', 'input6', 1, (512, 512)), ('INPUT', 'input7', 1, (512, 512)), ('INPUT', 'input8', 1, (512, 512)), ('INPUT', 'input9', 1, (512,)), ('INPUT', 'input10', 1, (2000, 512)), ('INPUT', 'input11', 1, (2000, 512)), ('INPUT', 'input12', 1, (512, 2000)), ('INPUT', 'input13', 1, (512,)), ('INIT', 'init7_s_0', 7, ()), ('INIT', 'init7_s_1024', 7, ()), ('INIT', 'init7_s_1', 7, ()), ('INIT', 'init7_s2_1024_1024', 7, (2,)), ('INIT', 'init7_s2_-1_1', 7, (2,)), ('INIT', 'init7_s1_1', 7, (1,)), ('INIT', 'init7_s4_2_1_1024_1024', 7, (4,)), ('INIT', 'init1_s_', 1, ()), ('INIT', 'init1_s1_', 1, (1,)), ('INIT', 'init1_s_2', 1, ()), ('INIT', 'init1_s1_2', 1, (1,)), ('INIT', 'init1_s_3', 1, ()), ('INIT', 'init7_s2_2048_512', 7, (2,)), ('INIT', 'init7_s3_2_1024_512', 7, (3,)), ('INIT', 'init7_s4_2_1024_-1_64', 7, (4,)), ('INIT', 'init7_s3_16_1024_64', 7, (3,)), ('INIT', 'init7_s3_16_64_1024', 7, (3,)), ('INIT', 'init1_s_4', 1, ()), ('INIT', 'init7_s3_16_1024_1024', 7, (3,)), ('INIT', 'init7_s3_2_1024_2000', 7, (3,)), ('INIT', 'init7_s2_2048_2000', 7, (2,)), ('INIT', 'init7_s2_0_1', 7, (2,)), ('INIT', 'init7_s2_1_2', 7, (2,)), ('INIT', 'init7_s2_0_2', 7, (2,)), ('INIT', 'init7_s2_32_32', 7, (2,))]




.. GENERATED FROM PYTHON SOURCE LINES 334-343

Optimization and Verification
+++++++++++++++++++++++++++++

Let's try the model with a python backend (reference implementation).
First step, onnxscript uses many functions. The reference evaluation expects
every function to be defined so the order of functions in the model matters.
No recursivity is allowed by this runtime.
We need to reorder as function Rank is usually placed
at the end of the model.

.. GENERATED FROM PYTHON SOURCE LINES 343-347

.. code-block:: Python


    if "instance" in storage:
        reorder_functions_in_proto(model_onnxrt)








.. GENERATED FROM PYTHON SOURCE LINES 348-349

Let's load the model and optimize them.

.. GENERATED FROM PYTHON SOURCE LINES 349-358

.. code-block:: Python


    if "instance" in storage:
        debug = onnx.load(model_debug)
        try:
            onnxrt = optimize_model_proto_oxs(onnx.load(model_onnxrt))
        except ImportError as e:
            print("missing library", e)
            onnxrt = debug








.. GENERATED FROM PYTHON SOURCE LINES 359-360

Let's apply onnxruntime optimization

.. GENERATED FROM PYTHON SOURCE LINES 360-379

.. code-block:: Python


    if "instance" in storage and ortopt:
        providers = (
            [("CUDAExecutionProvider", {}), ("CPUExecutionProvider", {})]
            if use_cuda
            else ["CPUExecutionProvider"]
        )
        with open(model_onnxrt.replace(".onnx", ".before.opt.onnx"), "wb") as f:
            f.write(onnxrt.SerializeToString())
        print(f"run onnxruntime optimization on {model_onnxrt}")
        optimized = model_onnxrt.replace(".onnx", ".opt.onnx")
        ort_optimize(onnxrt, output=optimized, providers=providers)
        onnxrt = onnx.load(optimized)

        print(f"run onnxruntime optimization on {model_debug}")
        optimized = model_debug.replace(".onnx", ".opt.onnx")
        ort_optimize(debug, output=optimized, disable_aot=True, providers=providers)
        debug = onnx.load(optimized)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    run onnxruntime optimization on dump_models/llama_onnxrt_0.onnx
    run onnxruntime optimization on dump_models/llama_debug_0.onnx




.. GENERATED FROM PYTHON SOURCE LINES 380-381

For what's following, we need to build two lists of matching inputs.

.. GENERATED FROM PYTHON SOURCE LINES 381-388

.. code-block:: Python


    if "instance" in storage:
        print("build_matching_inputs")
        feedsrt = build_matching_inputs(model_debug, feeds, model_onnxrt)
        print("done")






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    build_matching_inputs
    done




.. GENERATED FROM PYTHON SOURCE LINES 389-390

We check both models are running.

.. GENERATED FROM PYTHON SOURCE LINES 390-399

.. code-block:: Python


    if "instance" in storage:
        out_onnxrt = ExtendedReferenceEvaluator(onnxrt).run(None, feedsrt)
        out_debug = ExtendedReferenceEvaluator(debug).run(None, feeds)
        assert out_onnxrt
        assert out_debug

    # assert_all_close(out_onnxrt, out_debug)








.. GENERATED FROM PYTHON SOURCE LINES 400-401

Side by side

.. GENERATED FROM PYTHON SOURCE LINES 401-413

.. code-block:: Python



    if "instance" in storage:
        res1, res2, align, dc = compare_onnx_execution(
            onnxrt,
            debug,
            verbose=1,
            raise_exc=True,
            inputs=(feedsrt, feeds),
        )
        text = dc.to_str(res1, res2, align, column_size=90)
        print(text)




.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [compare_onnx_execution] execute with 2 inputs
    [compare_onnx_execution] execute first model
    [compare_onnx_execution] got 167 results
    [compare_onnx_execution] execute second model
    [compare_onnx_execution] got 167 results (first model)
    [compare_onnx_execution] got 171 results (second model)
    [compare_onnx_execution] compute edit distance
    [compare_onnx_execution] got 205 pairs
    [compare_onnx_execution] done
    001 ~ | INITIA int64    1:4                  CIKK                 _val_503                         | INITIA float32  1:1                  AAAA                 _reshape_init1_s_0              
    002 - | INITIA float32  4:2x1x1024x1024      ????                 expand_1                         |                                                                                           
    003 - | INITIA int64                         AAAA                 aten_unsqueeze_184_dim_0         |                                                                                           
    004 ~ | INITIA int64    1:2                  UYAA                 _val_581                         | INITIA float32  1:1                  AAAA                 _reshape_init1_s_303            
    005 ~ | INITIA int64                         BAAA                 aten_triu_198_diagonal           | INITIA float32  3:1x1x1024           KAQG                 _to_copy                        
    006 = | INITIA int64    1:3                  QKKA                 _val_533                         | INITIA int64    1:3                  QKKA                 init7_s3_16_1024_1024           
    007 + |                                                                                            | INITIA float32  4:2x1x1024x1024      ????                 expand_1                         
    008 - | INITIA float32                       AAAA                 _val_560                         |                                                                                           
    009 ~ | INITIA int64    1:2                  GGAA                 splits_token_15                  | INITIA int64    1:1                  BAAA                 init7_s1_1                      
    010 ~ | INITIA int64                         CAAA                 aten_unsqueeze_246_dim_0         | INITIA int64    1:2                  ACAA                 init7_s2_0_2                    
    011 - | INITIA float32                       AAAA                 _val_522                         |                                                                                           
    012 ~ | INITIA int64    1:3                  QMKA                 _val_464                         | INITIA int64    1:2                  GGAA                 init7_s2_32_32                  
    013 ~ | INITIA int64    1:4                  CIKM                 _val_539                         | INITIA float32  1:1                  ?AAA                 init1_s1_                       
    014 ~ | INITIA int64    1:1                  ZAAA                 _val_592                         | INITIA int64    1:2                  BCAA                 init7_s2_1_2                    
    015 ~ | INITIA int64    1:3                  CKSA                 _val_585                         | INITIA float32  1:1                  CAAA                 init1_s1_2                      
    016 ~ | INITIA int64    1:3                  QKMA                 _val_377                         | INITIA int64    1:2                  UYAA                 init7_s2_2048_2000              
    017 = | INITIA int64    1:2                  USAA                 _val_188                         | INITIA int64    1:2                  USAA                 init7_s2_2048_512               
    018 - | INITIA float32  3:1x1x1024           KAQG                 view_2                           |                                                                                           
    019 ~ | INITIA int64    1:2                  GGAA                 splits                           | INITIA int64    1:3                  CKSA                 init7_s3_2_1024_512             
    020 ~ | INITIA float32                       AAAA                 scalar_tensor_default            | INITIA int64    1:4                  CKZM                 init7_s4_2_1024_-1_64           
    021 - | INITIA float32                       ?AAA                 _val_389                         |                                                                                           
    022 ~ | INITIA int64    1:3                  CKZA                 _val_544                         | INITIA int64    1:3                  QKMA                 init7_s3_16_1024_64             
    023 ~ | INITIA int64    1:3                  CKYA                 _val_572                         | INITIA int64    1:3                  QMKA                 init7_s3_16_64_1024             
    024 ~ | INITIA int64    1:4                  CKZM                 _val_233                         | INITIA int64    1:3                  CKYA                 init7_s3_2_1024_2000            
    025 + |                                                                                            | INPUT  int64    2:2x1024             PYHI                 input0                           
    026 = | INPUT  float32  2:4000x512           CUBH                 primals_2                        | INPUT  float32  2:4000x512           CUBH                 input1                          
    027 - | INPUT  int64    2:2x1024             PYHI                 primals_1                        |                                                                                           
    028 = | INPUT  float32  2:2x1024             BACA                 primals_3                        | INPUT  float32  2:2x1024             BACA                 input2                          
    029 = | INPUT  float32  1:32                 DAAA                 primals_4                        | INPUT  float32  1:32                 DAAA                 input3                          
    030 + |                                                                                            | INPUT  float32  1:512                YYYY                 input4                           
    031 = | INPUT  float32  2:512x512            AVBZ                 primals_6                        | INPUT  float32  2:512x512            AVBZ                 input5                          
    032 = | INPUT  float32  2:512x512            AAAY                 primals_7                        | INPUT  float32  2:512x512            AAAY                 input6                          
    033 = | INPUT  float32  2:512x512            DAUZ                 primals_8                        | INPUT  float32  2:512x512            DAUZ                 input7                          
    034 = | INPUT  float32  2:512x512            HDBV                 primals_9                        | INPUT  float32  2:512x512            HDBV                 input8                          
    035 + |                                                                                            | INPUT  float32  1:512                YYYY                 input9                           
    036 = | INPUT  float32  2:2000x512           GYWO                 primals_11                       | INPUT  float32  2:2000x512           GYWO                 input10                         
    037 = | INPUT  float32  2:2000x512           SPPI                 primals_12                       | INPUT  float32  2:2000x512           SPPI                 input11                         
    038 = | INPUT  float32  2:512x2000           VVTO                 primals_13                       | INPUT  float32  2:512x2000           VVTO                 input12                         
    039 = | INPUT  float32  1:512                YYYY                 primals_5                        | INPUT  float32  1:512                YYYY                 input13                         
    040 ~ | INPUT  float32  1:512                YYYY                 primals_10                       | RESULT float32  1:512                YYYY Identity        output_4                        
    041 ~ | INPUT  float32  1:512                YYYY                 primals_14                       | RESULT float32  1:512                YYYY Identity        output_3                        
    042 - | RESULT float32  2:512x512            AVBZ Identity        t_33                             |                                                                                           
    043 - | RESULT float32  2:512x512            AAAY Identity        t_29                             |                                                                                           
    044 - | RESULT float32  2:512x512            DAUZ Identity        t_25                             |                                                                                           
    045 - | RESULT float32  2:512x512            HDBV Identity        t_21                             |                                                                                           
    046 - | RESULT float32  2:2000x512           GYWO Identity        t_17                             |                                                                                           
    047 - | RESULT float32  2:2000x512           SPPI Identity        t_13                             |                                                                                           
    048 - | RESULT float32  2:512x2000           VVTO Identity        t_9                              |                                                                                           
    049 ~ | RESULT float32  2:1x32               DAAA Unsqueeze       unsqueeze_7                      | RESULT float32  1:512                YYYY Identity        output_2                        
    050 + |                                                                                            | RESULT int64    2:2x1024             PYHI Identity        output_1                         
    051 = | RESULT float32  3:1x32x1             DAAA Unsqueeze       unsqueeze_8                      | RESULT float32  3:1x32x1             DAAA Unsqueeze       unsqueeze_8                     
    052 + |                                                                                            | RESULT float32  3:1x32x1024          EFXM MatMul          bmm                              
    053 - | RESULT float32  3:1x1024x32          XCHM FusedMatMul     transpose                        |                                                                                           
    054 - | RESULT float32  3:1x1024x64          VFPY Concat          cat                              |                                                                                           
    055 ~ | RESULT float32  3:1x1024x64          GSEC Sin             sin                              | RESULT float32  3:1x64x1024          JKJK Concat          cat_token_5                     
    056 ~ | RESULT float32  4:1x1x1024x64        GSEC Unsqueeze       unsqueeze_11                     | RESULT float32  3:1x64x1024          RMRM Sin             sin_token_7                     
    057 + |                                                                                            | RESULT float32  4:1x1x64x1024        RMRM Unsqueeze       unsqueeze10                      
    058 = | RESULT float32  4:1x1024x1x64        GSEC Transpose       Transpose_token_4_out0           | RESULT float32  4:1x1024x1x64        GSEC Transpose       Transpose_token_10_out0         
    059 = | RESULT float32  3:2x1024x512         BXDM Gather          embedding                        | RESULT float32  3:2x1024x512         BXDM Gather          output_5                        
    060 = | RESULT float32  3:2x1024x512         BBBA Pow             pow_1                            | RESULT float32  3:2x1024x512         BBBA Pow             pow_1                           
    061 = | RESULT float32  3:2x1024x1           AAAA ReduceMean      mean                             | RESULT float32  3:2x1024x1           AAAA ReduceMean      mean                            
    062 = | RESULT float32  3:2x1024x1           AAAA Add             add_1                            | RESULT float32  3:2x1024x1           AAAA Add             add_1                           
    063 = | RESULT float32  3:2x1024x1           KKKK Sqrt            _val_139                         | RESULT float32  3:2x1024x1           KKKK Sqrt            _onx_sqrt_add_10                
    064 = | RESULT float32  3:2x1024x1           NGKS Reciprocal      rsqrt                            | RESULT float32  3:2x1024x1           NGKS Reciprocal      output_6                        
    065 = | RESULT float32  3:2x1024x512         ELIE Mul             mul_3                            | RESULT float32  3:2x1024x512         ELIE Mul             output_7                        
    066 = | RESULT float32  3:2x1024x512         ELIE Mul             mul_4                            | RESULT float32  3:2x1024x512         ELIE Mul             mul_4                           
    067 = | RESULT float32  2:2048x512           ELIE Reshape         view_4                           | RESULT float32  2:2048x512           ELIE Reshape         output_9                        
    068 ~ | RESULT float32  2:2048x512           YQEG FusedMatMul     mm_1                             | RESULT float32  2:2048x512           YQEG Gemm            mm_1                            
    069 - | RESULT float32  3:2x1024x512         YQEG Reshape         _unsafe_view_1                   |                                                                                           
    070 = | RESULT float32  4:2x1024x8x64        YQEG Reshape         view_7                           | RESULT float32  4:2x1024x8x64        YQEG Reshape         view_7                          
    071 = | RESULT float32  4:2x1024x8x32        SDHE Split           Slice_460                        | RESULT float32  4:2x1024x8x32        SDHE Split           SlicesSplitPattern--slice_Tensor
    072 = | RESULT float32  4:2x1024x8x32        FOWC Split           Slice_477                        | RESULT float32  4:2x1024x8x32        FOWC Split           SlicesSplitPattern--slice_Tensor
    073 = | RESULT float32  4:2x1024x8x32        VMEY Neg             Neg_500                          | RESULT float32  4:2x1024x8x32        VMEY Neg             neg2                            
    074 = | RESULT float32  4:2x1024x8x64        NOLD Concat          Concat_508                       | RESULT float32  4:2x1024x8x64        NOLD Concat          cat3                            
    075 = | RESULT float32  4:2x1024x8x64        YARN Mul             Mul_521                          | RESULT float32  4:2x1024x8x64        YARN Mul             mul_Tensor15                    
    076 + |                                                                                            | RESULT float32  3:1x64x1024          NHNH Cos             cos_token_13                     
    077 ~ | RESULT float32  3:1x1024x64          CJYF Cos             cos                              | RESULT float32  4:1x1x64x1024        NHNH Unsqueeze       unsqueeze9                      
    078 - | RESULT float32  4:1x1x1024x64        CJYF Unsqueeze       unsqueeze_10                     |                                                                                           
    079 = | RESULT float32  4:1x1024x1x64        CJYF Transpose       Transpose_token_6_out0           | RESULT float32  4:1x1024x1x64        CJYF Transpose       Transpose_token_16_out0         
    080 = | RESULT float32  4:2x1024x8x64        ZCMZ Mul             Mul_519                          | RESULT float32  4:2x1024x8x64        ZCMZ Mul             mul_Tensor14                    
    081 = | RESULT float32  4:2x1024x8x64        YBDL Add             Add_526                          | RESULT float32  4:2x1024x8x64        YBDL Add             add_Tensor4                     
    082 = | RESULT float32  4:2x8x64x1024        PKVT Transpose       transpose_4                      | RESULT float32  4:2x8x64x1024        PKVT Transpose       transpose_4                     
    083 + |                                                                                            | RESULT float32  4:1x1x1024x64        GSEC Transpose       output_15                        
    084 - | RESULT float32  3:16x64x1024         PKVT Reshape         _unsafe_view_4                   |                                                                                           
    085 ~ | RESULT float32  2:2048x512           PYOP FusedMatMul     mm                               | RESULT float32  2:2048x512           PYOP Gemm            mm                              
    086 - | RESULT float32  3:2x1024x512         PYOP Reshape         _unsafe_view                     |                                                                                           
    087 = | RESULT float32  4:2x1024x8x64        PYOP Reshape         view_5                           | RESULT float32  4:2x1024x8x64        PYOP Reshape         view_5                          
    088 = | RESULT float32  4:2x8x1024x64        XREA Transpose       transpose_1                      | RESULT float32  4:2x8x1024x64        XREA Transpose       transpose_1                     
    089 = | RESULT float32  4:2x8x1024x32        SCEL Split           slice_24                         | RESULT float32  4:2x8x1024x32        SCEL Split           slice_24                        
    090 = | RESULT float32  4:2x8x1024x32        FPZQ Split           slice_25                         | RESULT float32  4:2x8x1024x32        FPZQ Split           slice_25                        
    091 = | RESULT float32  4:2x8x1024x32        VLBK Neg             neg                              | RESULT float32  4:2x8x1024x32        VLBK Neg             neg                             
    092 = | RESULT float32  4:2x8x1024x64        MMGV Concat          cat_1                            | RESULT float32  4:2x8x1024x64        MMGV Concat          cat_1                           
    093 = | RESULT float32  4:2x8x1024x64        VHNI Mul             mul_6                            | RESULT float32  4:2x8x1024x64        VHNI Mul             mul_6                           
    094 + |                                                                                            | RESULT float32  4:1x1x1024x64        CJYF Transpose       output_14                        
    095 = | RESULT float32  4:2x8x1024x64        QLKE Mul             mul_5                            | RESULT float32  4:2x8x1024x64        QLKE Mul             mul_5                           
    096 = | RESULT float32  4:2x8x1024x64        LTWM Add             add_2                            | RESULT float32  4:2x8x1024x64        LTWM Add             add_2                           
    097 - | RESULT float32  3:16x1024x64         LTWM Reshape         _unsafe_view_3                   |                                                                                           
    098 - | RESULT float32  3:16x1024x1024       QIHN MatMul          bmm_1                            |                                                                                           
    099 - | RESULT float32  4:2x8x1024x1024      QIHN Reshape         view_10                          |                                                                                           
    100 ~ | RESULT float32  4:2x8x1024x1024      GBRB Mul             mul_9                            | RESULT float32  4:2x8x1024x1024      GBRB FusedMatMul     _onx_mul_view_100               
    101 - | RESULT float32  3:2x1x1024           BACA Unsqueeze       unsqueeze_5                      |                                                                                           
    102 = | RESULT float32  4:2x1x1x1024         BACA Unsqueeze       unsqueeze_6                      | RESULT float32  4:2x1x1x1024         BACA Unsqueeze       unsqueeze_6                     
    103 = | RESULT float32  4:2x1x1024x1024      ???? Add             add                              | RESULT float32  4:2x1x1024x1024      ???? Add             add                             
    104 = | RESULT bool     4:2x1x1024x1024      KWTE Equal           eq                               | RESULT bool     4:2x1x1024x1024      KWTE Equal           eq                              
    105 = | RESULT float32  4:2x1x1024x1024      ???? Where           masked_fill                      | RESULT float32  4:2x1x1024x1024      ???? Where           masked_fill                     
    106 = | RESULT float32  4:2x8x1024x1024      ???? Add             add_4                            | RESULT float32  4:2x8x1024x1024      ???? Add             add_4                           
    107 = | RESULT float32  4:2x8x1024x1024      OOON Softmax         _softmax                         | RESULT float32  4:2x8x1024x1024      OOON Softmax         output_18                       
    108 - | RESULT float32  3:16x1024x1024       OOON Reshape         view_11                          |                                                                                           
    109 ~ | RESULT float32  2:2048x512           HNET FusedMatMul     mm_2                             | RESULT float32  2:2048x512           HNET Gemm            mm_2                            
    110 - | RESULT float32  3:2x1024x512         HNET Reshape         _unsafe_view_2                   |                                                                                           
    111 = | RESULT float32  4:2x1024x8x64        HNET Reshape         view_9                           | RESULT float32  4:2x1024x8x64        HNET Reshape         view_9                          
    112 = | RESULT float32  4:2x8x1024x64        HMTE Transpose       transpose_3                      | RESULT float32  4:2x8x1024x64        HMTE Transpose       transpose_3                     
    113 - | RESULT float32  3:16x1024x64         HMTE Reshape         _unsafe_view_5                   |                                                                                           
    114 - | RESULT float32  3:16x1024x64         IOQW MatMul          bmm_2                            |                                                                                           
    115 ~ | RESULT float32  4:2x8x1024x64        IOQW Reshape         view_12                          | RESULT float32  4:2x8x1024x64        IOQW MatMul          view_12                         
    116 = | RESULT float32  4:2x1024x8x64        LLWP Transpose       transpose_5                      | RESULT float32  4:2x1024x8x64        LLWP Transpose       transpose_5                     
    117 - | RESULT float32  3:2x1024x512         LLWP Reshape         view_13                          |                                                                                           
    118 = | RESULT float32  2:2048x512           LLWP Reshape         view_14                          | RESULT float32  2:2048x512           LLWP Reshape         output_22                       
    119 ~ | RESULT float32  2:2048x512           KKYD FusedMatMul     mm_3                             | RESULT float32  2:2048x512           KKYD Gemm            mm_3                            
    120 = | RESULT float32  3:2x1024x512         KKYD Reshape         _unsafe_view_6                   | RESULT float32  3:2x1024x512         KKYD Reshape         _unsafe_view_6                  
    121 = | RESULT float32  3:2x1024x512         MGBP Add             add_5                            | RESULT float32  3:2x1024x512         MGBP Add             output_23                       
    122 = | RESULT float32  3:2x1024x512         QSZS Pow             pow_2                            | RESULT float32  3:2x1024x512         QSZS Pow             pow_2                           
    123 = | RESULT float32  3:2x1024x1           WWLL ReduceMean      mean_1                           | RESULT float32  3:2x1024x1           WWLL ReduceMean      mean_1                          
    124 = | RESULT float32  3:2x1024x1           WWLL Add             add_6                            | RESULT float32  3:2x1024x1           WWLL Add             add_6                           
    125 = | RESULT float32  3:2x1024x1           EEYY Sqrt            _val_562                         | RESULT float32  3:2x1024x1           EEYY Sqrt            _onx_sqrt_add_60                
    126 = | RESULT float32  3:2x1024x1           GGIJ Reciprocal      rsqrt_1                          | RESULT float32  3:2x1024x1           GGIJ Reciprocal      output_24                       
    127 = | RESULT float32  3:2x1024x512         YZJA Mul             mul_10                           | RESULT float32  3:2x1024x512         YZJA Mul             output_25                       
    128 = | RESULT float32  3:2x1024x512         YZJA Mul             mul_11                           | RESULT float32  3:2x1024x512         YZJA Mul             mul_11                          
    129 = | RESULT float32  2:2048x512           YZJA Reshape         view_15                          | RESULT float32  2:2048x512           YZJA Reshape         output_27                       
    130 ~ | RESULT float32  2:2048x2000          IRWC FusedMatMul     mm_4                             | RESULT float32  2:2048x2000          IRWC Gemm            mm_4                            
    131 = | RESULT float32  3:2x1024x2000        IRWC Reshape         _unsafe_view_7                   | RESULT float32  3:2x1024x2000        IRWC Reshape         output_28                       
    132 ~ | RESULT float32  3:2x1024x2000        AOHJ QuickGelu       silu                             | RESULT float32  3:2x1024x2000        KNVS Sigmoid         _onx_sigmoid__unsafe_view_70    
    133 ~ | RESULT float32  2:2048x2000          YSOM FusedMatMul     mm_5                             | RESULT float32  2:2048x2000          KNVS Reshape         Reshape2Of3PatternR__onx_sigmoid
    134 ~ | RESULT float32  3:2x1024x2000        YSOM Reshape         _unsafe_view_8                   | RESULT float32  2:2048x2000          AOHJ Mul             Reshape2Of3PatternL_output_29   
    135 ~ | RESULT float32  3:2x1024x2000        ZPRE Mul             mul_12                           | RESULT float32  2:2048x2000          YSOM Gemm            mm_5                            
    136 ~ | RESULT float32  2:2048x2000          ZPRE Reshape         view_17                          | RESULT float32  2:2048x2000          ZPRE Mul             output_34                       
    137 ~ | RESULT float32  2:2048x512           TIAC FusedMatMul     mm_6                             | RESULT float32  2:2048x512           TIAC Gemm            mm_6                            
    138 = | RESULT float32  3:2x1024x512         TIAC Reshape         _unsafe_view_9                   | RESULT float32  3:2x1024x512         TIAC Reshape         _unsafe_view_9                  
    139 = | RESULT float32  3:2x1024x512         FPBS Add             add_7                            | RESULT float32  3:2x1024x512         FPBS Add             output_35                       
    140 = | RESULT float32  3:2x1024x512         WEUY Pow             pow_3                            | RESULT float32  3:2x1024x512         WEUY Pow             pow_3                           
    141 = | RESULT float32  3:2x1024x1           DDPP ReduceMean      mean_2                           | RESULT float32  3:2x1024x1           DDPP ReduceMean      mean_2                          
    142 = | RESULT float32  3:2x1024x1           DDPP Add             add_8                            | RESULT float32  3:2x1024x1           DDPP Add             add_8                           
    143 = | RESULT float32  3:2x1024x1           TTLL Sqrt            _val_596                         | RESULT float32  3:2x1024x1           TTLL Sqrt            _onx_sqrt_add_80                
    144 = | RESULT float32  3:2x1024x1           XWDG Reciprocal      rsqrt_2                          | RESULT float32  3:2x1024x1           XWDG Reciprocal      output_36                       
    145 = | RESULT float32  3:2x1024x512         FOTY Mul             mul_13                           | RESULT float32  3:2x1024x512         FOTY Mul             output_37                       
    146 = | RESULT float32  3:2x1024x512         FOTY Mul             mul_14                           | RESULT float32  3:2x1024x512         FOTY Mul             output_0                        
    147 + |                                                                                            | RESULT float32  3:2x1024x2000        YSOM Reshape         output_32                        
    148 + |                                                                                            | RESULT float32  3:2x1024x2000        AOHJ Reshape         output_29                        
    149 + |                                                                                            | RESULT float32  2:2048x512           YZJA Identity        output_31                        
    150 ~ | RESULT float32  3:16x1024x1024       OOON Transpose       transpose_7                      | RESULT float32  3:16x1024x1024       OOON Reshape         output_19                       
    151 + |                                                                                            | RESULT float32  3:16x64x1024         PKVT Reshape         output_17                        
    152 - | RESULT float32  4:2x8x1024x1024      OOON Identity        detach_13                        |                                                                                           
    153 ~ | RESULT float32  3:16x1024x64         PKVT Transpose       transpose_10                     | RESULT float32  3:16x1024x64         LTWM Reshape         output_16                       
    154 + |                                                                                            | RESULT float32  3:16x1024x64         HMTE Reshape         output_20                        
    155 ~ | RESULT float32  3:16x64x1024         LTWM Transpose       transpose_9                      | RESULT float32  2:2048x512           ELIE Identity        output_11                       
    156 ~ | RESULT float32  3:16x64x1024         HMTE Transpose       transpose_8                      | RESULT float32  2:2048x512           ELIE Identity        output_13                       
    157 - | OUTPUT float32  3:2x1024x512         BXDM                 embedding                        |                                                                                           
    158 ~ | OUTPUT float32  2:512x512            AVBZ                 t_33                             | RESULT float32  2:512x512            YQAG Transpose       output_8                        
    159 ~ | OUTPUT float32  2:512x512            AAAY                 t_29                             | RESULT float32  2:512x512            CBYY Transpose       output_10                       
    160 ~ | OUTPUT float32  2:512x512            DAUZ                 t_25                             | RESULT float32  2:512x512            ZDBS Transpose       output_12                       
    161 ~ | OUTPUT float32  2:512x512            HDBV                 t_21                             | RESULT float32  2:512x512            DACB Transpose       output_21                       
    162 + |                                                                                            | RESULT float32  2:512x2000           YJHZ Transpose       output_26                        
    163 + |                                                                                            | RESULT float32  2:512x2000           NJOV Transpose       output_30                        
    164 - | OUTPUT float32  2:2000x512           GYWO                 t_17                             |                                                                                           
    165 ~ | OUTPUT float32  2:2000x512           SPPI                 t_13                             | RESULT float32  2:2000x512           VNOA Transpose       output_33                       
    166 + |                                                                                            | OUTPUT float32  3:2x1024x512         FOTY                 output_0                         
    167 + |                                                                                            | OUTPUT int64    2:2x1024             PYHI                 output_1                         
    168 + |                                                                                            | OUTPUT float32  1:512                YYYY                 output_2                         
    169 + |                                                                                            | OUTPUT float32  1:512                YYYY                 output_3                         
    170 + |                                                                                            | OUTPUT float32  1:512                YYYY                 output_4                         
    171 + |                                                                                            | OUTPUT float32  3:2x1024x512         BXDM                 output_5                         
    172 - | OUTPUT float32  2:512x2000           VVTO                 t_9                              |                                                                                           
    173 = | OUTPUT float32  3:2x1024x1           NGKS                 rsqrt                            | OUTPUT float32  3:2x1024x1           NGKS                 output_6                        
    174 + |                                                                                            | OUTPUT float32  3:2x1024x512         ELIE                 output_7                         
    175 + |                                                                                            | OUTPUT float32  2:512x512            YQAG                 output_8                         
    176 = | OUTPUT float32  2:2048x512           ELIE                 view_4                           | OUTPUT float32  2:2048x512           ELIE                 output_9                        
    177 + |                                                                                            | OUTPUT float32  2:512x512            CBYY                 output_10                        
    178 - | OUTPUT float32  3:1x1024x64          VFPY                 cat                              |                                                                                           
    179 ~ | OUTPUT float32  3:16x64x1024         HMTE                 transpose_8                      | OUTPUT float32  2:2048x512           ELIE                 output_11                       
    180 + |                                                                                            | OUTPUT float32  2:512x512            ZDBS                 output_12                        
    181 ~ | OUTPUT float32  3:16x64x1024         LTWM                 transpose_9                      | OUTPUT float32  2:2048x512           ELIE                 output_13                       
    182 + |                                                                                            | OUTPUT float32  4:1x1x1024x64        CJYF                 output_14                        
    183 + |                                                                                            | OUTPUT float32  4:1x1x1024x64        GSEC                 output_15                        
    184 ~ | OUTPUT float32  3:16x1024x64         PKVT                 transpose_10                     | OUTPUT float32  3:16x1024x64         LTWM                 output_16                       
    185 + |                                                                                            | OUTPUT float32  3:16x64x1024         PKVT                 output_17                        
    186 = | OUTPUT float32  4:2x8x1024x1024      OOON                 detach_13                        | OUTPUT float32  4:2x8x1024x1024      OOON                 output_18                       
    187 = | OUTPUT float32  3:16x1024x1024       OOON                 transpose_7                      | OUTPUT float32  3:16x1024x1024       OOON                 output_19                       
    188 ~ | OUTPUT float32  2:2048x512           LLWP                 view_14                          | OUTPUT float32  3:16x1024x64         HMTE                 output_20                       
    189 + |                                                                                            | OUTPUT float32  2:512x512            DACB                 output_21                        
    190 ~ | OUTPUT float32  2:2048x512           KKYD                 mm_3                             | OUTPUT float32  2:2048x512           LLWP                 output_22                       
    191 + |                                                                                            | OUTPUT float32  3:2x1024x512         MGBP                 output_23                        
    192 = | OUTPUT float32  3:2x1024x1           GGIJ                 rsqrt_1                          | OUTPUT float32  3:2x1024x1           GGIJ                 output_24                       
    193 + |                                                                                            | OUTPUT float32  3:2x1024x512         YZJA                 output_25                        
    194 + |                                                                                            | OUTPUT float32  2:512x2000           YJHZ                 output_26                        
    195 = | OUTPUT float32  2:2048x512           YZJA                 view_15                          | OUTPUT float32  2:2048x512           YZJA                 output_27                       
    196 ~ | OUTPUT float32  2:2048x2000          IRWC                 mm_4                             | OUTPUT float32  3:2x1024x2000        IRWC                 output_28                       
    197 + |                                                                                            | OUTPUT float32  3:2x1024x2000        AOHJ                 output_29                        
    198 + |                                                                                            | OUTPUT float32  2:512x2000           NJOV                 output_30                        
    199 + |                                                                                            | OUTPUT float32  2:2048x512           YZJA                 output_31                        
    200 ~ | OUTPUT float32  2:2048x2000          YSOM                 mm_5                             | OUTPUT float32  3:2x1024x2000        YSOM                 output_32                       
    201 + |                                                                                            | OUTPUT float32  2:2000x512           VNOA                 output_33                        
    202 = | OUTPUT float32  2:2048x2000          ZPRE                 view_17                          | OUTPUT float32  2:2048x2000          ZPRE                 output_34                       
    203 = | OUTPUT float32  3:2x1024x512         FPBS                 add_7                            | OUTPUT float32  3:2x1024x512         FPBS                 output_35                       
    204 = | OUTPUT float32  3:2x1024x1           XWDG                 rsqrt_2                          | OUTPUT float32  3:2x1024x1           XWDG                 output_36                       
    205 = | OUTPUT float32  3:2x1024x512         FOTY                 mul_14                           | OUTPUT float32  3:2x1024x512         FOTY                 output_37                       





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 40.478 seconds)


.. _sphx_glr_download_auto_examples_plot_llama_diff_dort_301.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_llama_diff_dort_301.ipynb <plot_llama_diff_dort_301.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_llama_diff_dort_301.py <plot_llama_diff_dort_301.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_llama_diff_dort_301.zip <plot_llama_diff_dort_301.zip>`


.. include:: plot_llama_diff_dort_301.recommendations


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
