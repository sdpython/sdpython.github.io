
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_torch_export_201.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_plot_torch_export_201.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_torch_export_201.py:


.. _l-plot-torch-export-201:

201: Evaluate different ways to export a torch model to ONNX
============================================================

The example evaluates the performance of onnxruntime of a simple
torch model after it was converted into ONNX through different processes:

* `TorchScript-based ONNX Exporter
  <https://pytorch.org/docs/stable/onnx.html#torchscript-based-onnx-exporter>`_,
  let's call it **script**
* `TorchDynamo-based ONNX Exporter
  <https://pytorch.org/docs/stable/onnx.html#torchdynamo-based-onnx-exporter>`_,
  let's call it **dynamo**
* if available, the previous model but optimized, **dynopt**
* a custom exporter **cus_p0**, this exporter supports a very limited
  set of models, as **dynamo**, it relies on
  `torch.fx <https://pytorch.org/docs/stable/fx.html>`_ but the design is closer to
  what tensorflow-onnx does.
* the same exporter but unused nodes were removed and constants were folded, **cus_p2**

To run the script:

::

    python _doc/examples/plot_torch_export --help

The script takes around 12 minutes with a larger models.

Some helpers
++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 34-122

.. code-block:: Python


    from experimental_experiment.args import get_parsed_args


    script_args = get_parsed_args(
        "plot_torch_export",
        description=__doc__,
        scenarios={
            "small": "small model to test",
            "middle": "55Mb model",
            "large": "1Gb model",
        },
        warmup=5,
        repeat=5,
        maxtime=(
            2,
            "maximum time to run a model to measure the computation time, "
            "it is 0.1 when scenario is small",
        ),
        expose="scenarios,repeat,warmup",
    )


    import contextlib
    import itertools
    import os
    import platform
    import pprint
    import multiprocessing
    import time
    import cProfile
    import pstats
    import io
    import warnings
    import logging
    from pstats import SortKey

    try:
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            import onnxruntime

            has_cuda = "CUDAExecutionProvider" in onnxruntime.get_available_providers()
    except ImportError:
        print("onnxruntime not available.")
        import sys

        sys.exit(0)

    import numpy as np
    import matplotlib.pyplot as plt
    import pandas
    import onnx
    from onnx_array_api.profiling import profile2graph
    import torch
    from torch import nn
    import torch.nn.functional as F
    import experimental_experiment
    from experimental_experiment.torch_interpreter import to_onnx
    from experimental_experiment.xbuilder import OptimizationOptions
    from experimental_experiment.plotting.memory import memory_peak_plot
    from experimental_experiment.ext_test_case import measure_time, get_figure
    from experimental_experiment.memory_peak import start_spying_on
    from experimental_experiment.ext_test_case import unit_test_going
    from experimental_experiment.helpers import pretty_onnx
    from tqdm import tqdm

    has_cuda = has_cuda and torch.cuda.is_available()
    logging.disable(logging.ERROR)


    def system_info():
        obs = {}
        obs["processor"] = platform.processor()
        obs["cores"] = multiprocessing.cpu_count()
        try:
            obs["cuda"] = 1 if torch.cuda.is_available() else 0
            obs["cuda_count"] = torch.cuda.device_count()
            obs["cuda_name"] = torch.cuda.get_device_name()
            obs["cuda_capa"] = torch.cuda.get_device_capability()
        except (RuntimeError, AssertionError):
            # no cuda
            pass
        return obs


    pprint.pprint(system_info())





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    {'cores': 20,
     'cuda': 1,
     'cuda_capa': (8, 9),
     'cuda_count': 1,
     'cuda_name': 'NVIDIA GeForce RTX 4060 Laptop GPU',
     'processor': 'x86_64'}




.. GENERATED FROM PYTHON SOURCE LINES 123-124

Scripts arguments

.. GENERATED FROM PYTHON SOURCE LINES 124-140

.. code-block:: Python



    if script_args.scenario in (None, "small"):
        script_args.maxtime = 0.1

    if unit_test_going():
        script_args.warmup = 1
        script_args.repeat = 1
        script_args.maxtime = 0.1
        script_args.scenario = "small"

    print(f"scenario={script_args.scenario or 'small'}")
    print(f"warmup={script_args.warmup}")
    print(f"repeat={script_args.repeat}")
    print(f"maxtime={script_args.maxtime}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    scenario=small
    warmup=5
    repeat=5
    maxtime=0.1




.. GENERATED FROM PYTHON SOURCE LINES 141-145

The model
+++++++++

A simple model to convert.

.. GENERATED FROM PYTHON SOURCE LINES 145-244

.. code-block:: Python



    class MyModelClass(nn.Module):
        def __init__(self, scenario=script_args.scenario):
            super().__init__()
            if scenario == "middle":
                self.large = False
                self.conv1 = nn.Conv2d(1, 128, 5)
                self.conv2 = nn.Conv2d(128, 16, 5)
                self.fc1 = nn.Linear(13456, 1024)
                self.fcs = []
                self.fc2 = nn.Linear(1024, 128)
                self.fc3 = nn.Linear(128, 10)
            elif scenario in (None, "small"):
                self.large = False
                self.conv1 = nn.Conv2d(1, 16, 5)
                self.conv2 = nn.Conv2d(16, 16, 5)
                self.fc1 = nn.Linear(16, 512)
                self.fcs = []
                self.fc2 = nn.Linear(512, 128)
                self.fc3 = nn.Linear(128, 10)
            elif scenario in (None, "large"):
                self.large = True
                self.conv1 = nn.Conv2d(1, 128, 5)
                self.conv2 = nn.Conv2d(128, 16, 5)
                self.fc1 = nn.Linear(13456, 4096)
                # torch script does not support loops.
                self.fca = nn.Linear(4096, 4096)
                self.fcb = nn.Linear(4096, 4096)
                self.fcc = nn.Linear(4096, 4096)
                self.fcd = nn.Linear(4096, 4096)
                self.fce = nn.Linear(4096, 4096)
                self.fcf = nn.Linear(4096, 4096)
                self.fcg = nn.Linear(4096, 4096)
                self.fch = nn.Linear(4096, 4096)
                self.fci = nn.Linear(4096, 4096)
                self.fck = nn.Linear(4096, 4096)
                self.fcl = nn.Linear(4096, 4096)
                self.fcm = nn.Linear(4096, 4096)
                self.fcn = nn.Linear(4096, 4096)
                # end of the unfolded loop.
                self.fc2 = nn.Linear(4096, 128)
                self.fc3 = nn.Linear(128, 10)
            else:
                raise ValueError(f"Unsupported scenario={scenario!r}.")

        def forward(self, x):
            x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))
            x = F.max_pool2d(F.relu(self.conv2(x)), 2)
            x = torch.flatten(x, 1)
            x = F.relu(self.fc1(x))
            if self.large:
                # loop
                x = F.relu(self.fca(x))
                x = F.relu(self.fcb(x))
                x = F.relu(self.fcc(x))
                x = F.relu(self.fcd(x))
                x = F.relu(self.fce(x))
                x = F.relu(self.fcf(x))
                x = F.relu(self.fcg(x))
                x = F.relu(self.fch(x))
                x = F.relu(self.fci(x))
                x = F.relu(self.fck(x))
                x = F.relu(self.fcl(x))
                x = F.relu(self.fcm(x))
                x = F.relu(self.fcn(x))
                # end of the loop
            x = F.relu(self.fc2(x))
            x = self.fc3(x)
            return x


    def create_model_and_input(scenario=script_args.scenario):
        if scenario == "middle":
            shape = [1, 1, 128, 128]
        elif scenario in (None, "small"):
            shape = [1, 1, 16, 16]
        elif scenario == "large":
            shape = [1, 1, 128, 128]
        else:
            raise ValueError(f"Unsupported scenario={scenario!r}.")
        input_tensor = torch.rand(*shape).to(torch.float32)
        model = MyModelClass(scenario=scenario)
        assert model(input_tensor) is not None
        return model, input_tensor


    def torch_model_size(model):
        size_model = 0
        for param in model.parameters():
            size = param.numel() * torch.finfo(param.data.dtype).bits / 8
            size_model += size
        return size_model


    model, input_tensor = create_model_and_input()
    model_size = torch_model_size(model)
    print(f"model size={model_size / 2 ** 20} Mb")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    model size=0.31467437744140625 Mb




.. GENERATED FROM PYTHON SOURCE LINES 245-247

The exporters
+++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 247-301

.. code-block:: Python



    def export_script(filename, model, *args):
        with contextlib.redirect_stdout(io.StringIO()):
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                torch.onnx.export(model, *args, filename, input_names=["input"])


    def export_dynamo(filename, model, *args):
        with contextlib.redirect_stdout(io.StringIO()):
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                export_output = torch.onnx.export(model, args, dynamo=True)
                export_output.save(filename)


    def export_dynopt(filename, model, *args):
        with contextlib.redirect_stdout(io.StringIO()):
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                export_output = torch.onnx.export(model, args, dynamo=True)
                model_onnx = export_output.model_proto

                from experimental_experiment.convert.convert_helper import (
                    optimize_model_proto_oxs,
                )

                optimized_model = optimize_model_proto_oxs(model_onnx)

                with open(filename, "wb") as f:
                    f.write(optimized_model.SerializeToString())


    def export_cus_p0(filename, model, *args):
        onx = to_onnx(model, tuple(args), input_names=["input"])
        with open(filename, "wb") as f:
            f.write(onx.SerializeToString())


    def export_cus_p2(filename, model, *args):
        onx = to_onnx(
            model,
            tuple(args),
            input_names=["input"],
            options=OptimizationOptions(
                remove_unused=True,
                constant_folding=True,
            ),
        )
        with open(filename, "wb") as f:
            f.write(onx.SerializeToString())









.. GENERATED FROM PYTHON SOURCE LINES 302-303

Let's check they are working.

.. GENERATED FROM PYTHON SOURCE LINES 303-327

.. code-block:: Python


    export_functions = [
        export_script,
        export_dynamo,
        export_dynopt,
        export_cus_p0,
        export_cus_p2,
    ]

    exporters = {f.__name__.replace("export_", ""): f for f in export_functions}

    supported_exporters = {}
    for k, v in exporters.items():
        print(f"run exporter {k}")
        filename = f"plot_torch_export_{k}.onnx"
        try:
            v(filename, model, input_tensor)
        except Exception as e:
            print(f"skipped due to {str(e)[:1000]}")
            continue
        supported_exporters[k] = v
        print(f"done. size={os.stat(filename).st_size / 2 ** 20:1.0f} Mb")






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    run exporter script
    done. size=0 Mb
    run exporter dynamo
    done. size=0 Mb
    run exporter dynopt
    done. size=0 Mb
    run exporter cus_p0
    done. size=0 Mb
    run exporter cus_p2
    done. size=0 Mb




.. GENERATED FROM PYTHON SOURCE LINES 328-330

Exporter memory
+++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 330-362

.. code-block:: Python



    def flatten(ps):
        obs = ps["cpu"].to_dict(unit=2**20)
        if "gpus" in ps:
            for i, g in enumerate(ps["gpus"]):
                for k, v in g.to_dict(unit=2**20).items():
                    obs[f"gpu{i}_{k}"] = v
        return obs


    data = []

    for k, v in supported_exporters.items():
        print(f"run exporter for memory {k}")
        filename = f"plot_torch_export_{k}.onnx"
        if has_cuda:
            torch.cuda.set_device(0)
        stat = start_spying_on(cuda=1 if has_cuda else 0)
        v(filename, model, input_tensor)
        obs = flatten(stat.stop())
        print("done.")
        onx = onnx.load(filename)
        obs.update(dict(nodes=len(onx.graph.node), export=k))
        data.append(obs)

    stat = start_spying_on(cuda=1 if has_cuda else 0)
    exported_mod = torch.export.export(model, (input_tensor,))
    obs = flatten(stat.stop())
    obs.update(dict(export="torch.fx"))
    data.append(obs)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    run exporter for memory script
    done.
    run exporter for memory dynamo
    done.
    run exporter for memory dynopt
    done.
    run exporter for memory cus_p0
    done.
    run exporter for memory cus_p2
    done.




.. GENERATED FROM PYTHON SOURCE LINES 363-364

The result.

.. GENERATED FROM PYTHON SOURCE LINES 364-376

.. code-block:: Python

    df1 = pandas.DataFrame(data)
    df1.to_csv("plot_torch_export_memory.csv", index=False)
    df1.to_excel("plot_torch_export_memory.xlsx", index=False)
    print(df1)

    ax = memory_peak_plot(
        data,
        bars=[model_size * i / 2**20 for i in range(1, 5)],
        suptitle=f"Memory Consumption of the Export\nmodel size={model_size / 2**20:1.0f} Mb",
    )
    get_figure(ax).savefig("plot_torch_export_memory.png")




.. image-sg:: /auto_examples/images/sphx_glr_plot_torch_export_201_001.png
   :alt: Memory Consumption of the Export model size=0 Mb, Memory peak (Mb), Memory peak - memory begin (Mb), Memory average - memory begin (Mb), GPU Memory peak (Mb), GPU Memory peak - memory begin (Mb), GPU Memory average - memory begin (Mb)
   :srcset: /auto_examples/images/sphx_glr_plot_torch_export_201_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

              peak         mean   n        begin          end    gpu0_peak    gpu0_mean  gpu0_n   gpu0_begin     gpu0_end  nodes    export
    0  6642.589844  6642.583984   6  6642.589844  6642.585938  1883.617188  1883.617188       6  1883.617188  1883.617188   12.0    script
    1  6643.394531  6642.745959  58  6642.585938  6643.394531  1883.617188  1883.617188      58  1883.617188  1883.617188   17.0    dynamo
    2  6643.429688  6643.395137  58  6643.394531  6643.429688  1883.617188  1883.617188      58  1883.617188  1883.617188   16.0    dynopt
    3  6643.429688  6643.429688  15  6643.429688  6643.429688  1883.617188  1883.617188      15  1883.617188  1883.617188   15.0    cus_p0
    4  6643.433594  6643.430664  16  6643.429688  6643.433594  1883.617188  1883.617188      16  1883.617188  1883.617188   12.0    cus_p2
    5  6643.433594  6643.433594  16  6643.433594  6643.433594  1883.617188  1883.617188      16  1883.617188  1883.617188    NaN  torch.fx




.. GENERATED FROM PYTHON SOURCE LINES 377-379

Exporter speed
++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 379-407

.. code-block:: Python


    data = []

    for k, v in supported_exporters.items():
        print(f"run exporter {k}")
        filename = f"plot_torch_export_{k}.onnx"
        times = []
        for _ in range(script_args.repeat):
            begin = time.perf_counter()
            v(filename, model, input_tensor)
            duration = time.perf_counter() - begin
            times.append(duration)
        onx = onnx.load(filename)
        print("done.")
        data.append(
            dict(
                export=k,
                time=np.mean(times),
                min=min(times),
                max=max(times),
                first=times[0],
                last=times[-1],
                std=np.std(times),
                nodes=len(onx.graph.node),
            )
        )






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    run exporter script
    done.
    run exporter dynamo
    done.
    run exporter dynopt
    done.
    run exporter cus_p0
    done.
    run exporter cus_p2
    done.




.. GENERATED FROM PYTHON SOURCE LINES 408-411

The last export to measure time torch spends in export the model
before any other export can begin the translation
except the first one.

.. GENERATED FROM PYTHON SOURCE LINES 411-431

.. code-block:: Python


    times = []
    for _ in range(script_args.repeat):
        begin = time.perf_counter()
        exported_mod = torch.export.export(model, (input_tensor,))
        duration = time.perf_counter() - begin
        times.append(duration)
    data.append(
        dict(
            export="torch.fx",
            time=np.mean(times),
            min=min(times),
            max=max(times),
            first=times[0],
            last=times[-1],
            std=np.std(times),
            nodes=len(onx.graph.node),
        )
    )








.. GENERATED FROM PYTHON SOURCE LINES 432-433

The result.

.. GENERATED FROM PYTHON SOURCE LINES 433-444

.. code-block:: Python

    df1 = pandas.DataFrame(data)
    df1.to_csv("plot_torch_export_time.csv", index=False)
    df1.to_excel("plot_torch_export_time.xlsx", index=False)
    print(df1)

    fig, ax = plt.subplots(1, 1)
    dfi = df1[["export", "time", "std"]].set_index("export")
    dfi["time"].plot.bar(ax=ax, title="Export time", yerr=dfi["std"], rot=30)
    fig.tight_layout()
    fig.savefig("plot_torch_export_time.png")




.. image-sg:: /auto_examples/images/sphx_glr_plot_torch_export_201_002.png
   :alt: Export time
   :srcset: /auto_examples/images/sphx_glr_plot_torch_export_201_002.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

         export      time       min       max     first      last       std  nodes
    0    script  0.050720  0.020475  0.084030  0.053975  0.020475  0.024156     12
    1    dynamo  0.546456  0.444285  0.897654  0.897654  0.481192  0.176025     17
    2    dynopt  0.550420  0.449514  0.852314  0.852314  0.449514  0.153759     16
    3    cus_p0  0.099774  0.087176  0.119119  0.099311  0.119119  0.010769     15
    4    cus_p2  0.091772  0.081538  0.107795  0.087403  0.081538  0.009740     12
    5  torch.fx  0.072886  0.069259  0.078131  0.078131  0.072545  0.003305     12




.. GENERATED FROM PYTHON SOURCE LINES 445-447

Exporter Profiling
++++++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 447-495

.. code-block:: Python



    def clean_text(text):
        pathes = [
            os.path.abspath(os.path.normpath(os.path.join(os.path.dirname(torch.__file__), ".."))),
            os.path.abspath(os.path.normpath(os.path.join(os.path.dirname(onnx.__file__), ".."))),
            os.path.abspath(
                os.path.normpath(
                    os.path.join(os.path.dirname(experimental_experiment.__file__), "..")
                )
            ),
        ]
        for p in pathes:
            text = text.replace(p, "")
        text = text.replace("experimental_experiment", "experimental_experiment".upper())
        return text


    def profile_function(name, export_function, verbose=False):
        print(f"profile {name}: {export_function}")
        pr = cProfile.Profile()
        pr.enable()
        for _ in range(script_args.repeat):
            export_function("dummyc.onnx", model, input_tensor)
        pr.disable()
        s = io.StringIO()
        sortby = SortKey.CUMULATIVE
        ps = pstats.Stats(pr, stream=s).sort_stats(sortby)
        ps.print_stats()

        raw = s.getvalue()
        text = "\n".join(raw.split("\n")[:200])
        if verbose:
            print(text)
        with open(f"plot_torch_export_profile_{name}.txt", "w") as f:
            f.write(raw)

        root, nodes = profile2graph(ps, clean_text=clean_text)
        text = root.to_text()
        with open(f"plot_torch_export_profile_{name}_h.txt", "w") as f:
            f.write(text)
        print("done.")


    profile_function("custom0", export_cus_p0, True)
    profile_function("custom2", export_cus_p2)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    profile custom0: <function export_cus_p0 at 0x7f8dd2126200>
             1045423 function calls (1017508 primitive calls) in 1.300 seconds

       Ordered by: cumulative time

       ncalls  tottime  percall  cumtime  percall filename:lineno(function)
            5    0.001    0.000    1.315    0.263 /home/xadupre/github/experimental-experiment/_doc/examples/plot_torch_export_201.py:281(export_cus_p0)
            5    0.000    0.000    1.307    0.261 /home/xadupre/github/experimental-experiment/experimental_experiment/torch_interpreter/onnx_export.py:703(to_onnx)
            5    0.000    0.000    1.109    0.222 /home/xadupre/github/experimental-experiment/experimental_experiment/torch_interpreter/onnx_export.py:356(_make_builder_interpreter)
            5    0.000    0.000    1.107    0.221 /home/xadupre/github/experimental-experiment/experimental_experiment/torch_interpreter/export_options.py:150(export)
            5    0.000    0.000    1.107    0.221 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/export/__init__.py:263(export)
         10/5    0.000    0.000    1.107    0.221 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/export/_trace.py:999(wrapper)
         10/5    0.000    0.000    1.107    0.221 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/export/exported_program.py:124(wrapper)
            5    0.000    0.000    1.107    0.221 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/export/_trace.py:1888(_export)
            5    0.000    0.000    1.106    0.221 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/export/_trace.py:1797(_export_for_training)
            5    0.001    0.000    1.089    0.218 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/export/_trace.py:1266(_strict_export_lower_to_aten_ir)
            5    0.004    0.001    0.867    0.173 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/export/_trace.py:624(_export_to_torch_ir)
            5    0.000    0.000    0.861    0.172 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:1433(inner)
        95/30    0.000    0.000    0.857    0.029 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/nn/modules/module.py:1735(_wrapped_call_impl)
        95/30    0.001    0.000    0.857    0.029 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/nn/modules/module.py:1743(_call_impl)
            5    0.000    0.000    0.821    0.164 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:539(_fn)
            5    0.000    0.000    0.767    0.153 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:1311(__call__)
            5    0.000    0.000    0.766    0.153 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:449(__call__)
            5    0.001    0.000    0.765    0.153 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:599(_compile)
            5    0.000    0.000    0.739    0.148 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:696(compile_inner)
            5    0.000    0.000    0.737    0.147 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_utils_internal.py:89(wrapper_function)
            5    0.000    0.000    0.737    0.147 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:719(_compile_inner)
            5    0.000    0.000    0.678    0.136 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py:1353(transform_code_object)
            5    0.001    0.000    0.418    0.084 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py:1414(cleaned_instructions)
          800    0.412    0.001    0.413    0.001 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py:71(convert_instruction)
            5    0.000    0.000    0.259    0.052 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:204(_fn)
            5    0.000    0.000    0.257    0.051 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:635(transform)
            5    0.000    0.000    0.232    0.046 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:2863(run)
            5    0.000    0.000    0.232    0.046 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:1049(run)
          280    0.001    0.000    0.231    0.001 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:935(step)
     1080/690    0.002    0.000    0.199    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/utils/_stats.py:16(wrapper)
            5    0.000    0.000    0.196    0.039 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/export/_trace.py:1416(_export_to_aten_ir_make_fx)
           60    0.000    0.000    0.189    0.003 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:653(wrapper)
           60    0.000    0.000    0.188    0.003 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:1655(CALL_FUNCTION)
           60    0.001    0.000    0.187    0.003 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:878(call_function)
        15/10    0.000    0.000    0.183    0.018 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:737(_fn)
           65    0.000    0.000    0.168    0.003 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/variables/builder.py:2120(wrap_fx_proxy)
           65    0.000    0.000    0.168    0.003 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/variables/builder.py:2193(wrap_fx_proxy_cls)
           60    0.001    0.000    0.166    0.003 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/variables/builder.py:2277(_wrap_fx_proxy)
            5    0.001    0.000    0.157    0.031 /home/xadupre/github/experimental-experiment/experimental_experiment/xbuilder/graph_builder.py:4562(to_onnx)
           60    0.001    0.000    0.156    0.003 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/utils.py:2371(get_fake_value)
           90    0.000    0.000    0.155    0.002 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/utils.py:1975(wrap_fake_exception)
          870    0.002    0.000    0.149    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:1257(__torch_dispatch__)
          870    0.005    0.000    0.147    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:1781(dispatch)
            5    0.000    0.000    0.141    0.028 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/export/_trace.py:1434(_make_fx_helper)
           25    0.000    0.000    0.139    0.006 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/variables/nn_module.py:342(call_function)
          485    0.003    0.000    0.139    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:1341(_cached_dispatch_impl)
            5    0.000    0.000    0.137    0.027 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:2194(wrapped)
            5    0.000    0.000    0.137    0.027 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:2132(trace)
            5    0.000    0.000    0.134    0.027 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:2016(_trace_inner)
            5    0.000    0.000    0.130    0.026 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_compile.py:22(inner)
            5    0.000    0.000    0.130    0.026 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:1132(dispatch_trace)
            5    0.000    0.000    0.118    0.024 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:1691(trace)
            5    0.000    0.000    0.118    0.024 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/_symbolic_trace.py:711(trace)
    3830/1885    0.005    0.000    0.109    0.000 /usr/lib/python3.10/copy.py:128(deepcopy)
      465/165    0.001    0.000    0.106    0.001 /usr/lib/python3.10/copy.py:259(_reconstruct)
           25    0.000    0.000    0.106    0.004 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/utils.py:1986(deepcopy_to_fake_tensor)
           25    0.000    0.000    0.106    0.004 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/utils.py:1988(<lambda>)
       135/60    0.001    0.000    0.104    0.002 /usr/lib/python3.10/copy.py:227(_deepcopy_dict)
            5    0.000    0.000    0.104    0.021 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:1182(wrapped)
      435/325    0.000    0.000    0.100    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_ops.py:722(__call__)
           50    0.001    0.000    0.099    0.002 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/nn/parameter.py:63(__deepcopy__)
           60    0.001    0.000    0.098    0.002 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/graph_module.py:792(recompile)
      160/110    0.055    0.000    0.098    0.001 {method 'clone' of 'torch._C.TensorBase' objects}
          250    0.001    0.000    0.096    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:2687(__torch_function__)
           10    0.001    0.000    0.096    0.010 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/interpreter.py:117(run)
          140    0.001    0.000    0.091    0.001 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/interpreter.py:210(run_node)
            5    0.000    0.000    0.088    0.018 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/export/_trace.py:1463(wrapped_fn)
            5    0.000    0.000    0.088    0.018 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py:178(flat_fn)
           65    0.000    0.000    0.088    0.001 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/graph.py:1568(python_code)
            5    0.000    0.000    0.088    0.018 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py:864(functional_call)
           70    0.000    0.000    0.084    0.001 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/experimental/symbolic_shapes.py:6633(run_node)
            5    0.000    0.000    0.083    0.017 /home/xadupre/github/experimental-experiment/experimental_experiment/xbuilder/graph_builder.py:4948(optimize)
         1260    0.002    0.000    0.081    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:1231(__torch_function__)
            5    0.000    0.000    0.079    0.016 /home/xadupre/github/experimental-experiment/experimental_experiment/xbuilder/graph_builder.py:5227(optimize_with_patterns)
            5    0.005    0.001    0.079    0.016 /home/xadupre/github/experimental-experiment/experimental_experiment/xoptim/graph_builder_optim.py:1027(optimize)
         1260    0.001    0.000    0.077    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:1260(__torch_function__)
           60    0.000    0.000    0.074    0.001 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_ops.py:830(handler)
           65    0.001    0.000    0.072    0.001 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/graph.py:1645(_python_code)
           65    0.009    0.000    0.072    0.001 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/graph.py:408(_gen_python_code)
          485    0.001    0.000    0.071    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:1715(_output_from_cache_entry)
           60    0.000    0.000    0.070    0.001 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_library/utils.py:280(handle_dispatch_mode)
          150    0.002    0.000    0.070    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:758(__torch_dispatch__)
          515    0.008    0.000    0.070    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:1649(_get_output_tensor_from_cache_entry)
           60    0.000    0.000    0.067    0.001 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:1329(__torch_dispatch__)
           60    0.002    0.000    0.066    0.001 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:762(proxy_call)
          485    0.002    0.000    0.062    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:1384(_cache_key)
            5    0.001    0.000    0.061    0.012 /home/xadupre/github/experimental-experiment/experimental_experiment/xbuilder/graph_builder.py:4050(_build_initializers)
            5    0.000    0.000    0.059    0.012 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/guards.py:2229(__init__)
    7400/7110    0.004    0.000    0.059    0.000 {built-in method builtins.next}
           50    0.002    0.000    0.058    0.001 /home/xadupre/github/experimental-experiment/experimental_experiment/mini_onnx_builder.py:104(proto_from_array)
       120/90    0.000    0.000    0.057    0.001 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_guards.py:291(create)
     2070/535    0.008    0.000    0.056    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:1460(_prep_args_for_hash)
         1030    0.013    0.000    0.055    0.000 /home/xadupre/github/experimental-experiment/experimental_experiment/xoptim/patterns_api.py:115(enumerate_matches)
            5    0.000    0.000    0.053    0.011 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:1484(result_capturing_wrapper)
            5    0.000    0.000    0.053    0.011 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/export/_trace.py:411(_produce_aten_artifact)
           50    0.000    0.000    0.053    0.001 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/nn/parameter.py:40(__new__)
      175/125    0.002    0.000    0.053    0.000 {method 'detach' of 'torch._C.TensorBase' objects}
       100/60    0.000    0.000    0.049    0.001 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/nn/functional.py:1693(relu)
           60    0.003    0.000    0.048    0.001 {built-in method torch.relu}
           35    0.001    0.000    0.046    0.001 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/variables/torch.py:876(call_function)
           60    0.000    0.000    0.044    0.001 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/utils.py:2432(<lambda>)
           60    0.000    0.000    0.044    0.001 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/utils.py:2522(run_node)
           45    0.000    0.000    0.043    0.001 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/nn/modules/linear.py:124(forward)
        75/45    0.003    0.000    0.043    0.001 {built-in method torch._C._nn.linear}
           35    0.000    0.000    0.042    0.001 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/interpreter.py:288(call_function)
          165    0.000    0.000    0.041    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:2586(from_tensor)
          165    0.001    0.000    0.041    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:331(from_real_tensor)
           50    0.000    0.000    0.041    0.001 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/_symbolic_trace.py:490(call_module)
            5    0.000    0.000    0.039    0.008 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_functorch/functional_call.py:11(functional_call)
            5    0.000    0.000    0.039    0.008 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/nn/utils/stateless.py:264(_functional_call)
          105    0.002    0.000    0.038    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_subclasses/meta_utils.py:1721(__call__)
           25    0.000    0.000    0.038    0.002 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/interpreter.py:334(call_module)
           25    0.000    0.000    0.038    0.002 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/_symbolic_trace.py:811(module_call_wrapper)
            5    0.000    0.000    0.038    0.008 /home/xadupre/github/experimental-experiment/experimental_experiment/xbuilder/graph_builder.py:4473(process)
            5    0.000    0.000    0.037    0.007 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/_lazy_graph_module.py:115(_lazy_forward)
           25    0.000    0.000    0.037    0.001 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:1741(call_module)
    3535/3390    0.002    0.000    0.036    0.000 /usr/lib/python3.10/contextlib.py:130(__enter__)
          120    0.001    0.000    0.036    0.000 /home/xadupre/github/experimental-experiment/experimental_experiment/torch_interpreter/interpreter.py:165(run_node)
           25    0.000    0.000    0.036    0.001 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/_symbolic_trace.py:813(forward)
        60/30    0.000    0.000    0.036    0.001 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/overrides.py:1668(handle_torch_function)
          110    0.000    0.000    0.034    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/variables/base.py:458(build)
           25    0.001    0.000    0.034    0.001 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/graph_module.py:437(__init__)
      575/505    0.002    0.000    0.034    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/nn/modules/module.py:1934(__setattr__)
         1260    0.005    0.000    0.033    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/graph.py:634(emit_node)
          110    0.001    0.000    0.032    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/variables/builder.py:375(__call__)
    194625/192135    0.026    0.000    0.032    0.000 {built-in method builtins.isinstance}
            5    0.000    0.000    0.031    0.006 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/graph_module.py:821(call_wrapped)
            5    0.000    0.000    0.031    0.006 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/graph_module.py:382(__call__)
           25    0.000    0.000    0.030    0.001 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/graph_module.py:548(graph)
          240    0.001    0.000    0.030    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/proxy.py:209(create_proxy)
           65    0.003    0.000    0.030    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/variables/builder.py:540(_wrap)
            5    0.000    0.000    0.028    0.006 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/guards.py:1820(SHAPE_ENV)
           30    0.000    0.000    0.028    0.001 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/nn/modules/conv.py:553(forward)
           30    0.000    0.000    0.028    0.001 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/nn/modules/conv.py:536(_conv_forward)
           60    0.001    0.000    0.028    0.000 /home/xadupre/github/experimental-experiment/experimental_experiment/torch_interpreter/interpreter.py:1262(call_function)
        50/30    0.003    0.000    0.028    0.001 {built-in method torch.conv2d}
            5    0.000    0.000    0.027    0.005 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:1153(rewrite_signature)
    3535/3390    0.003    0.000    0.027    0.000 /usr/lib/python3.10/contextlib.py:139(__exit__)
          190    0.001    0.000    0.025    0.000 /home/xadupre/github/experimental-experiment/experimental_experiment/xbuilder/graph_builder_opset.py:113(make_node)
          220    0.004    0.000    0.025    0.000 /home/xadupre/github/experimental-experiment/experimental_experiment/xbuilder/graph_builder.py:3411(make_node)
           10    0.000    0.000    0.025    0.003 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_export/passes/replace_with_hop_pass_util.py:152(_replace_with_hop_pass_helper)
          635    0.009    0.000    0.025    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:948(_flatten_into)
            5    0.000    0.000    0.024    0.005 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:2681(__init__)
          735    0.008    0.000    0.023    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:672(__new__)
          635    0.007    0.000    0.023    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:968(extract_tensor_metadata)
            5    0.000    0.000    0.023    0.005 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/guards.py:1248(add_python_lambda_leaf_guard_to_root)
           90    0.001    0.000    0.022    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/guards.py:1424(ID_MATCH)
        50/30    0.000    0.000    0.022    0.001 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_jit_internal.py:614(fn)
        50/30    0.000    0.000    0.022    0.001 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/nn/functional.py:807(_max_pool2d)
          250    0.002    0.000    0.022    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/proxy.py:143(create_node)
            5    0.000    0.000    0.021    0.004 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/guards.py:2553(build_guard_function)
           65    0.000    0.000    0.021    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:594(track_tensor_tree)
           30    0.002    0.000    0.021    0.001 {built-in method torch.max_pool2d}
       120/65    0.000    0.000    0.020    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:616(wrap_with_proxy)
          105    0.003    0.000    0.020    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_subclasses/meta_utils.py:755(meta_tensor)
         4770    0.007    0.000    0.019    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/node.py:855(__setattr__)
         4340    0.003    0.000    0.019    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/node.py:875(map_arg)
            5    0.000    0.000    0.019    0.004 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/metrics_context.py:37(__exit__)
            5    0.000    0.000    0.019    0.004 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/utils.py:966(record_compilation_metrics)
            5    0.000    0.000    0.018    0.004 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:1094(transform)
            5    0.000    0.000    0.018    0.004 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/interpreter.py:563(transform)
            5    0.001    0.000    0.018    0.004 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/utils.py:925(_scrubbed_inductor_config_for_logging)
           65    0.000    0.000    0.018    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:1796(LOAD_ATTR)
           65    0.000    0.000    0.018    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:1789(_load_attr)
          260    0.002    0.000    0.018    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/graph.py:1110(create_node)
    8260/4895    0.008    0.000    0.018    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/node.py:884(map_aggregate)
          960    0.001    0.000    0.018    0.000 /home/xadupre/github/experimental-experiment/experimental_experiment/xoptim/patterns_api.py:815(match)
           15    0.000    0.000    0.017    0.001 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/_lazy_graph_module.py:57(_make_graph_module)
           30    0.000    0.000    0.017    0.001 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/guards.py:1641(NN_MODULE)
         55/5    0.000    0.000    0.017    0.003 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/variables/lazy.py:104(realize_all)
            5    0.000    0.000    0.017    0.003 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/variables/lazy.py:136(<dictcomp>)
     2920/135    0.002    0.000    0.017    0.000 /usr/lib/python3.10/ast.py:414(visit)
           10    0.000    0.000    0.017    0.002 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/variables/lazy.py:61(realize)
           10    0.000    0.000    0.017    0.002 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/variables/lazy.py:20(realize)
           65    0.000    0.000    0.017    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/variables/builtin.py:987(call_function)
          960    0.001    0.000    0.016    0.000 /home/xadupre/github/experimental-experiment/experimental_experiment/xoptim/patterns_api.py:328(_get_match_pattern)
           65    0.000    0.000    0.016    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/variables/builtin.py:850(builtin_dispatch)
           65    0.000    0.000    0.016    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/variables/builtin.py:770(call_self_handler)
            5    0.000    0.000    0.016    0.003 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:3043(RETURN_VALUE)
            5    0.000    0.000    0.016    0.003 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:3015(_return)
           65    0.001    0.000    0.016    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/variables/builtin.py:1620(call_getattr)
            5    0.000    0.000    0.016    0.003 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/output_graph.py:945(compile_subgraph)
    1655/1585    0.006    0.000    0.015    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/experimental/recording.py:238(wrapper)
         4365    0.003    0.000    0.015    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_subclasses/meta_utils.py:165(is_sparse_any)
           10    0.000    0.000    0.015    0.001 /home/xadupre/github/experimental-experiment/experimental_experiment/xoptim/patterns_api.py:278(_build_pattern)
         3685    0.002    0.000    0.014    0.000 /usr/lib/python3.10/re.py:197(search)
         1570    0.001    0.000    0.014    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/experimental/symbolic_shapes.py:2948(_suppress_guards)
           65    0.002    0.000    0.014    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/output_graph.py:1927(create_proxy)
          105    0.004    0.000    0.014    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_subclasses/meta_utils.py:248(describe_tensor)
           60    0.000    0.000    0.014    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/graph_module.py:91(_forward_from_src)
           60    0.000    0.000    0.014    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/graph_module.py:97(_method_from_src)
          115    0.001    0.000    0.014    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:487(set_meta)
           60    0.000    0.000    0.014    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/graph_module.py:86(_exec_with_source)
          130    0.002    0.000    0.014    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/graph.py:1622(override_node_repr)
          150    0.014    0.000    0.014    0.000 {built-in method builtins.compile}
    done.
    profile custom2: <function export_cus_p2 at 0x7f8dd2126170>
    done.




.. GENERATED FROM PYTHON SOURCE LINES 496-497

Same with dynamo-exporter.

.. GENERATED FROM PYTHON SOURCE LINES 497-503

.. code-block:: Python


    profile_function("dynamo", export_dynamo, verbose=True)
    if "dynopt" in supported_exporters:
        profile_function("dynopt", export_dynopt)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    profile dynamo: <function export_dynamo at 0x7f8dd21265f0>
             7015430 function calls (6899300 primitive calls) in 4.623 seconds

       Ordered by: cumulative time

       ncalls  tottime  percall  cumtime  percall filename:lineno(function)
            5    0.000    0.000    4.715    0.943 /home/xadupre/github/experimental-experiment/_doc/examples/plot_torch_export_201.py:256(export_dynamo)
            5    0.002    0.000    4.697    0.939 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/onnx/__init__.py:129(export)
            5    0.001    0.000    4.696    0.939 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/onnx/_internal/exporter/_compat.py:221(export_compat)
            5    0.000    0.000    2.728    0.546 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/onnx/_internal/exporter/_core.py:1167(export)
            5    0.001    0.000    2.396    0.479 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/onnx/_internal/exporter/_core.py:884(_prepare_exported_program_for_export)
            5    0.001    0.000    2.325    0.465 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/onnx/_internal/exporter/_fx_passes.py:11(decompose_with_registry)
        15/10    0.000    0.000    2.111    0.211 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/export/exported_program.py:124(wrapper)
            5    0.026    0.005    1.967    0.393 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/onnx/_internal/exporter/_registration.py:123(from_torchlib)
            5    0.000    0.000    1.844    0.369 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/export/exported_program.py:1203(run_decompositions)
            5    0.000    0.000    1.397    0.279 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/export/exported_program.py:732(_decompose_exported_program)
            5    0.001    0.000    1.380    0.276 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/export/exported_program.py:354(_decompose_and_get_gm_with_new_signature_constants)
            5    0.026    0.005    1.251    0.250 /home/xadupre/github/onnxscript/onnxscript/_framework_apis/torch_2_5.py:99(get_torchlib_ops)
          920    0.007    0.000    1.220    0.001 /home/xadupre/github/onnxscript/onnxscript/values.py:640(function_ir)
    10405/9325    0.006    0.000    0.872    0.000 {built-in method builtins.next}
    4975/4440    0.003    0.000    0.825    0.000 /usr/lib/python3.10/contextlib.py:130(__enter__)
          920    0.005    0.000    0.815    0.001 /home/xadupre/github/onnxscript/onnxscript/_internal/ast_utils.py:16(get_src_and_ast)
           20    0.097    0.005    0.792    0.040 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/export/exported_program.py:194(_override_composite_implicit_decomp)
           10    0.001    0.000    0.769    0.077 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_export/utils.py:1087(_collect_all_valid_cia_ops)
          250    0.010    0.000    0.768    0.003 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_export/utils.py:1070(_collect_all_valid_cia_ops_for_namespace)
          250    0.286    0.001    0.682    0.003 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_export/utils.py:1005(_materialize_cpp_cia_ops)
          920    0.001    0.000    0.671    0.001 /usr/lib/python3.10/inspect.py:1133(getsource)
          920    0.018    0.000    0.669    0.001 /usr/lib/python3.10/inspect.py:1112(getsourcelines)
         2905    0.059    0.000    0.656    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/onnx/_internal/exporter/_schemas.py:431(from_function)
          920    0.097    0.000    0.600    0.001 /usr/lib/python3.10/inspect.py:1101(getblock)
            5    0.000    0.000    0.474    0.095 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/export/_trace.py:693(_export_to_aten_ir)
       133875    0.263    0.000    0.455    0.000 /usr/lib/python3.10/tokenize.py:431(_tokenize)
            5    0.005    0.001    0.447    0.089 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/export/exported_program.py:301(_split_decomp_table_to_cia_and_python_decomp)
            5    0.000    0.000    0.443    0.089 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py:1141(aot_export_module)
            5    0.000    0.000    0.441    0.088 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py:1448(_aot_export_function)
            5    0.000    0.000    0.440    0.088 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py:519(create_aot_dispatcher_function)
            5    0.001    0.000    0.435    0.087 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py:532(_create_aot_dispatcher_function)
        35700    0.428    0.000    0.428    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_higher_order_ops/utils.py:62(autograd_not_implemented)
            5    0.005    0.001    0.422    0.084 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/onnx/_internal/exporter/_decomp.py:42(create_onnx_friendly_decomposition_table)
           10    0.000    0.000    0.417    0.042 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/export/exported_program.py:286(_override_decomp_aten_to_variants)
            5    0.000    0.000    0.386    0.077 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/export/decomp_utils.py:125(items)
            5    0.000    0.000    0.386    0.077 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/export/decomp_utils.py:142(_materialize_if_needed)
            5    0.001    0.000    0.386    0.077 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/export/decomp_utils.py:129(materialize)
           10    0.000    0.000    0.382    0.038 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:2194(wrapped)
           10    0.000    0.000    0.382    0.038 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:2132(trace)
           10    0.000    0.000    0.380    0.038 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:2016(_trace_inner)
           10    0.000    0.000    0.374    0.037 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_compile.py:22(inner)
        20/10    0.000    0.000    0.374    0.037 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:737(_fn)
           10    0.000    0.000    0.374    0.037 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:1132(dispatch_trace)
          920    0.002    0.000    0.371    0.000 /home/xadupre/github/onnxscript/onnxscript/converter.py:1463(translate_function_signature)
          920    0.027    0.000    0.366    0.000 /home/xadupre/github/onnxscript/onnxscript/converter.py:1378(_translate_function_signature_common)
           10    0.000    0.000    0.348    0.035 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:1691(trace)
           10    0.000    0.000    0.348    0.035 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/_symbolic_trace.py:711(trace)
           10    0.000    0.000    0.315    0.032 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:1182(wrapped)
    2600/1735    0.003    0.000    0.304    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/utils/_stats.py:16(wrapper)
           15    0.000    0.000    0.302    0.020 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py:178(flat_fn)
           15    0.000    0.000    0.301    0.020 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py:864(functional_call)
            5    0.000    0.000    0.269    0.054 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/onnx/_internal/exporter/_capture_strategies.py:99(__call__)
            5    0.000    0.000    0.267    0.053 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/onnx/_internal/exporter/_capture_strategies.py:182(_capture)
            5    0.000    0.000    0.267    0.053 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/export/__init__.py:263(export)
         10/5    0.000    0.000    0.267    0.053 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/export/_trace.py:999(wrapper)
            5    0.000    0.000    0.267    0.053 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/export/_trace.py:1888(_export)
            5    0.000    0.000    0.266    0.053 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/export/_trace.py:1797(_export_for_training)
    2295/1030    0.002    0.000    0.265    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_ops.py:722(__call__)
            5    0.000    0.000    0.261    0.052 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:98(aot_dispatch_export)
            5    0.000    0.000    0.260    0.052 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:73(aot_dispatch_base_graph)
            5    0.000    0.000    0.251    0.050 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/export/_trace.py:1636(_non_strict_export)
      720/660    0.019    0.000    0.246    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_subclasses/functional_tensor.py:352(__torch_dispatch__)
         3340    0.005    0.000    0.239    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:1231(__torch_function__)
           15    0.002    0.000    0.237    0.016 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/interpreter.py:117(run)
    28025/5185    0.063    0.000    0.229    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/onnx/_internal/exporter/_schemas.py:267(_get_allowed_types_from_type_annotation)
            5    0.000    0.000    0.227    0.045 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/export/_trace.py:1416(_export_to_aten_ir_make_fx)
        64955    0.187    0.000    0.226    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_ops.py:106(inner)
    37845/9080    0.042    0.000    0.225    0.000 /home/xadupre/github/onnxscript/onnxscript/type_annotation.py:131(is_value_type)
        18640    0.224    0.000    0.224    0.000 {built-in method builtins.compile}
            5    0.000    0.000    0.216    0.043 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:46(_create_graph)
       794320    0.212    0.000    0.214    0.000 {built-in method builtins.getattr}
          375    0.001    0.000    0.214    0.001 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/interpreter.py:210(run_node)
         2905    0.031    0.000    0.209    0.000 /usr/lib/python3.10/typing.py:1773(get_type_hints)
          195    0.000    0.000    0.201    0.001 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/interpreter.py:288(call_function)
         1915    0.003    0.000    0.190    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:1257(__torch_dispatch__)
         1915    0.009    0.000    0.186    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:1781(dispatch)
          240    0.001    0.000    0.179    0.001 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/experimental/symbolic_shapes.py:6633(run_node)
            5    0.000    0.000    0.178    0.036 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/export/_trace.py:1659(_aot_export_non_strict)
          685    0.002    0.000    0.173    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:1329(__torch_dispatch__)
            5    0.000    0.000    0.172    0.034 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py:663(inner_fn)
            5    0.000    0.000    0.172    0.034 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py:396(_functionalized_f_helper)
            5    0.000    0.000    0.171    0.034 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/export/_trace.py:1434(_make_fx_helper)
     1680/600    0.004    0.000    0.171    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/utils/_pytree.py:923(tree_map)
          525    0.003    0.000    0.170    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:1341(_cached_dispatch_impl)
    1053675/1047820    0.129    0.000    0.166    0.000 {built-in method builtins.isinstance}
     6410/865    0.013    0.000    0.166    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/utils/_pytree.py:801(unflatten)
           85    0.001    0.000    0.159    0.002 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/graph_module.py:792(recompile)
          135    0.004    0.000    0.157    0.001 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:762(proxy_call)
         5110    0.003    0.000    0.146    0.000 /home/xadupre/github/onnxscript/onnxscript/type_annotation.py:172(is_valid_type)
           85    0.001    0.000    0.132    0.002 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/graph.py:1568(python_code)
            5    0.001    0.000    0.128    0.026 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/collect_metadata_analysis.py:171(inner)
    4475/3995    0.008    0.000    0.123    0.000 /home/xadupre/github/onnxscript/onnxscript/type_annotation.py:150(<listcomp>)
       126275    0.122    0.000    0.122    0.000 {method 'match' of 're.Pattern' objects}
          250    0.116    0.000    0.116    0.000 {built-in method torch._C._dispatch_get_registrations_for_dispatch_key}
            5    0.000    0.000    0.114    0.023 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py:76(inner_fn)
          920    0.001    0.000    0.113    0.000 /usr/lib/python3.10/ast.py:33(parse)
            5    0.000    0.000    0.113    0.023 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/export/_trace.py:1463(wrapped_fn)
         35/5    0.000    0.000    0.112    0.022 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/_symbolic_trace.py:811(module_call_wrapper)
         7255    0.004    0.000    0.112    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_export/utils.py:991(_is_preservable_cia_op)
         35/5    0.000    0.000    0.111    0.022 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:1741(call_module)
         35/5    0.000    0.000    0.111    0.022 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/_symbolic_trace.py:490(call_module)
         1260    0.002    0.000    0.111    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:1260(__torch_function__)
         35/5    0.000    0.000    0.111    0.022 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/_symbolic_trace.py:813(forward)
         35/5    0.000    0.000    0.111    0.022 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/nn/modules/module.py:1735(_wrapped_call_impl)
         35/5    0.000    0.000    0.111    0.022 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/nn/modules/module.py:1743(_call_impl)
            5    0.000    0.000    0.111    0.022 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/export/_trace.py:1667(forward)
           70    0.000    0.000    0.111    0.002 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_higher_order_ops/utils.py:63(inner)
           70    0.001    0.000    0.111    0.002 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_higher_order_ops/utils.py:20(autograd_not_implemented_inner)
            5    0.000    0.000    0.110    0.022 /home/xadupre/github/experimental-experiment/_doc/examples/plot_torch_export_201.py:191(forward)
         1670    0.002    0.000    0.109    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_export/non_strict_utils.py:540(__torch_function__)
         2945    0.002    0.000    0.107    0.000 /usr/lib/python3.10/inspect.py:3252(signature)
           85    0.001    0.000    0.106    0.001 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/graph.py:1645(_python_code)
           85    0.013    0.000    0.106    0.001 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/graph.py:408(_gen_python_code)
         2945    0.002    0.000    0.105    0.000 /usr/lib/python3.10/inspect.py:2998(from_callable)
          110    0.000    0.000    0.104    0.001 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/functional_utils.py:35(to_fun)
          110    0.001    0.000    0.104    0.001 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_subclasses/functional_tensor.py:208(to_functional)
           60    0.000    0.000    0.103    0.002 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_ops.py:830(handler)
    2975/2945    0.018    0.000    0.103    0.000 /usr/lib/python3.10/inspect.py:2375(_signature_from_callable)
         1425    0.003    0.000    0.101    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/utils/_pytree.py:1130(tree_map_only)
           60    0.000    0.000    0.100    0.002 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_library/utils.py:280(handle_dispatch_mode)
    44065/44015    0.017    0.000    0.099    0.000 {built-in method builtins.repr}
         7255    0.037    0.000    0.092    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_export/utils.py:1039(_check_valid_to_preserve)
        34115    0.014    0.000    0.091    0.000 /home/xadupre/github/onnxscript/onnxscript/ir/_core.py:1417(__hash__)
    24000/10750    0.014    0.000    0.090    0.000 /usr/lib/python3.10/typing.py:320(_eval_type)
        37845    0.028    0.000    0.089    0.000 /home/xadupre/github/onnxscript/onnxscript/type_annotation.py:123(_is_tensor_type)
         3970    0.002    0.000    0.083    0.000 /home/xadupre/github/onnxscript/onnxscript/type_annotation.py:168(is_attr_type)
        10750    0.022    0.000    0.082    0.000 /usr/lib/python3.10/typing.py:679(_evaluate)
           10    0.000    0.000    0.074    0.007 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/export/_trace.py:411(_produce_aten_artifact)
       468130    0.068    0.000    0.068    0.000 {method 'split' of 'str' objects}
          170    0.002    0.000    0.068    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:331(from_real_tensor)
         2945    0.026    0.000    0.067    0.000 /usr/lib/python3.10/inspect.py:2280(_signature_from_function)
         6885    0.010    0.000    0.065    0.000 /home/xadupre/github/onnxscript/onnxscript/converter.py:451(_eval_constant_expr)
          170    0.003    0.000    0.064    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_subclasses/meta_utils.py:1721(__call__)
        70950    0.039    0.000    0.063    0.000 /usr/lib/python3.10/typing.py:1902(get_origin)
        40225    0.021    0.000    0.063    0.000 /home/xadupre/github/onnxscript/onnxscript/type_annotation.py:70(_remove_annotation)
          450    0.001    0.000    0.063    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:1715(_output_from_cache_entry)
            5    0.001    0.000    0.062    0.012 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/onnx/_internal/exporter/_core.py:929(_exported_program_to_onnx_program)
      265/175    0.001    0.000    0.062    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_ops.py:757(decompose)
        10750    0.009    0.000    0.062    0.000 /usr/lib/python3.10/typing.py:664(__init__)
            5    0.000    0.000    0.062    0.012 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/export/exported_program.py:1175(module)
           30    0.001    0.000    0.062    0.002 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/graph_module.py:437(__init__)
        37140    0.028    0.000    0.061    0.000 /home/xadupre/github/onnxscript/onnxscript/ir/_core.py:1425(__repr__)
            5    0.000    0.000    0.061    0.012 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/export/_unlift.py:368(_unlift_exported_program_lifted_states)
          525    0.002    0.000    0.061    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:1384(_cache_key)
          470    0.007    0.000    0.061    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:1649(_get_output_tensor_from_cache_entry)
            5    0.000    0.000    0.061    0.012 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/onnx/_internal/exporter/_fx_passes.py:23(insert_type_promotion_nodes)
           40    0.000    0.000    0.061    0.002 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_export/utils.py:1123(_special_op_to_decompose_cia)
      655/555    0.002    0.000    0.060    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/nn/modules/module.py:1934(__setattr__)
          110    0.002    0.000    0.059    0.001 {built-in method torch._to_functional_tensor}
            5    0.013    0.003    0.057    0.011 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/onnx/_internal/exporter/_decomp.py:15(get_onnx_implemented_overloads)
           30    0.000    0.000    0.056    0.002 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/graph_module.py:548(graph)
     1965/525    0.008    0.000    0.056    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:1460(_prep_args_for_hash)
        140/5    0.002    0.000    0.056    0.011 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py:66(wrapper)
            5    0.000    0.000    0.056    0.011 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/onnx/_internal/fx/_pass.py:240(run)
          245    0.001    0.000    0.056    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/proxy.py:209(create_proxy)
            5    0.000    0.000    0.056    0.011 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py:1696(_run)
            5    0.001    0.000    0.056    0.011 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/onnx/_internal/exporter/_core.py:658(_translate_fx_graph)
           75    0.001    0.000    0.053    0.001 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/onnx/_internal/exporter/_core.py:448(_handle_call_function_node_with_lowering)
    4975/4440    0.004    0.000    0.053    0.000 /usr/lib/python3.10/contextlib.py:139(__exit__)
        90/30    0.000    0.000    0.052    0.002 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/overrides.py:1668(handle_torch_function)
         2145    0.007    0.000    0.050    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/graph.py:634(emit_node)
           55    0.000    0.000    0.048    0.001 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/collect_metadata_analysis.py:161(_to_fun)
    670335/670100    0.047    0.000    0.047    0.000 {built-in method builtins.len}
       132955    0.047    0.000    0.047    0.000 /usr/lib/python3.10/inspect.py:1058(tokeneater)
          135    0.001    0.000    0.047    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py:1601(run_node)
          920    0.008    0.000    0.047    0.000 /usr/lib/python3.10/inspect.py:932(findsource)
          255    0.002    0.000    0.047    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:1777(create_node)
         2065    0.002    0.000    0.046    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/utils/_pytree.py:866(tree_flatten)
    7175/2065    0.011    0.000    0.045    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/utils/_pytree.py:845(_tree_flatten_helper)
           65    0.004    0.000    0.044    0.001 {built-in method torch.tensor}
          145    0.000    0.000    0.044    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:594(track_tensor_tree)
      255/145    0.001    0.000    0.042    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py:616(wrap_with_proxy)
           10    0.000    0.000    0.042    0.004 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_decomp/decompositions_for_rng.py:132(reset)
           30    0.000    0.000    0.041    0.001 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_decomp/decompositions_for_rng.py:74(__init__)
           30    0.000    0.000    0.041    0.001 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_decomp/decompositions_for_rng.py:77(reset)
          105    0.000    0.000    0.041    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:2586(from_tensor)
           75    0.002    0.000    0.040    0.001 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:1967(_dispatch_impl)
         1635    0.001    0.000    0.038    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/utils/_pytree.py:1079(wrapped)
           10    0.000    0.000    0.037    0.004 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/export/_trace.py:787(_fakify_params_buffers)
        89904    0.026    0.000    0.036    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_ops.py:730(__hash__)
       146820    0.025    0.000    0.036    0.000 {built-in method builtins.hasattr}
          410    0.007    0.000    0.035    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/onnx/_internal/exporter/_schemas.py:273(<setcomp>)
          170    0.006    0.000    0.035    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_subclasses/meta_utils.py:755(meta_tensor)
        85/80    0.000    0.000    0.035    0.000 /home/xadupre/github/onnxscript/onnxscript/values.py:295(__call__)
        80/20    0.000    0.000    0.035    0.002 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/nn/functional.py:1693(relu)
        85/80    0.000    0.000    0.034    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/onnx/_internal/exporter/_building.py:558(eval)
         8525    0.005    0.000    0.034    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/node.py:875(map_arg)
        17655    0.025    0.000    0.034    0.000 {built-in method builtins.eval}
           20    0.000    0.000    0.034    0.002 {built-in method torch.relu}
         8185    0.011    0.000    0.032    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/node.py:855(__setattr__)
    15995/9735    0.015    0.000    0.032    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/node.py:884(map_aggregate)
          260    0.004    0.000    0.031    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_subclasses/functional_tensor.py:97(__new__)
        14990    0.004    0.000    0.031    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/onnx/_internal/exporter/_registration.py:269(is_registered)
          885    0.009    0.000    0.031    0.000 /home/xadupre/vv/this/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:672(__new__)
        10750    0.019    0.000    0.030    0.000 /usr/lib/python3.10/typing.py:146(_type_check)
    done.
    profile dynopt: <function export_dynopt at 0x7f8dd2126560>
    done.




.. GENERATED FROM PYTHON SOURCE LINES 504-506

Benchmark exported models with ORT
++++++++++++++++++++++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 506-652

.. code-block:: Python



    def benchmark(shape):
        from onnxruntime import InferenceSession, SessionOptions, GraphOptimizationLevel

        data = []
        data1 = []
        data_mem_load = []
        data_mem_first_run = []
        data_mem_run = []
        confs = list(
            itertools.product(
                [_ for _ in os.listdir(".") if ".onnx" in _ and _.startswith("plot_torch")],
                [
                    ["CPUExecutionProvider"],
                    ["CUDAExecutionProvider", "CPUExecutionProvider"],
                ],
                ["0", "1"],
            )
        )
        loop = tqdm(confs)
        print(f"number of experiments: {len(loop)}")
        for name, ps, aot in loop:
            root = os.path.split(name)[-1]
            _, ext = os.path.splitext(root)
            if ext != ".onnx":
                continue

            obs = {}  # system_info()
            obs["name"] = name
            obs["providers"] = ",".join(ps)
            p = "CUDA" if "CUDA" in obs["providers"] else "CPU"
            obs["compute"] = p
            obs["aot"] = 1 if aot == "0" else 0
            obs["export"] = name.replace("plot_torch_export_", "").replace(".onnx", "")

            if not has_cuda and p == "CUDA":
                continue

            onx = onnx.load(name)
            obs["n_nodes"] = len(onx.graph.node)
            obs["n_function"] = len(onx.functions or [])
            obs["n_sub"] = len([n for n in onx.graph.node if n.op_type == "Sub"])
            obs1 = obs.copy()
            short_obs = dict(
                name=obs["name"],
                aot=obs["aot"],
                providers=obs["providers"],
                export=obs["export"],
                compute=obs["compute"],
            )

            opts = SessionOptions()
            opts.add_session_config_entry("session.disable_aot_function_inlining", aot)
            opts.graph_optimization_level = GraphOptimizationLevel.ORT_ENABLE_ALL
            opts.optimized_model_filepath = (
                f"ort-{name.replace('.onnx', '')}-{p.lower()}-aot{1 if aot == '0' else 0}.onnx"
            )

            try:
                InferenceSession(name, opts, providers=ps)
            except Exception as e:
                loop.set_description(f"ERROR-load: {name} {e}")
                obs.update({"error": e, "step": "run"})
                data.append(obs)
                continue

            opts = SessionOptions()
            opts.add_session_config_entry("session.disable_aot_function_inlining", aot)
            opts.graph_optimization_level = GraphOptimizationLevel.ORT_ENABLE_ALL
            stat = start_spying_on(cuda=1 if has_cuda else 0)
            sess = InferenceSession(name, opts, providers=ps)
            memobs = flatten(stat.stop())
            memobs.update(short_obs)
            data_mem_load.append(memobs)

            input_name = sess.get_inputs()[0].name
            feeds = {input_name: np.random.rand(*shape).astype(np.float32)}

            stat = start_spying_on(cuda=1 if has_cuda else 0)
            try:
                sess.run(None, feeds)
            except Exception as e:
                loop.set_description(f"ERROR-run: {name} {e}")
                obs.update({"error": e, "step": "load"})
                data.append(obs)
                stat.stop()
                continue
            memobs = flatten(stat.stop())
            memobs.update(short_obs)
            data_mem_first_run.append(memobs)

            # memory consumption
            stat = start_spying_on(cuda=1 if has_cuda else 0)
            for _ in range(0, script_args.warmup):
                sess.run(None, feeds)
            memobs = flatten(stat.stop())
            memobs.update(short_obs)
            data_mem_run.append(memobs)

            obs.update(
                measure_time(
                    lambda sess=sess, feeds=feeds: sess.run(None, feeds),
                    max_time=script_args.maxtime,
                    repeat=script_args.repeat,
                    number=1,
                )
            )

            loop.set_description(f"{obs['average']} {name} {ps}")
            data.append(obs)

            # check first run
            obs1.update(
                measure_time(
                    lambda name=name, opts=opts, ps=ps, feeds=feeds: InferenceSession(
                        name, opts, providers=ps
                    ).run(None, feeds),
                    max_time=script_args.maxtime,
                    repeat=max(1, script_args.repeat // 2),
                    number=1,
                )
            )
            data1.append(obs1)

        df = pandas.DataFrame(data)
        df.to_csv("plot_torch_export_ort_time.csv", index=False)
        df.to_excel("plot_torch_export_ort_time.xlsx", index=False)
        df1 = pandas.DataFrame(data1)
        df1.to_csv("plot_torch_export_ort_time1_init.csv", index=False)
        df1.to_excel("plot_torch_export_ort_time1_init.xlsx", index=False)
        dfmem = pandas.DataFrame(data_mem_load)
        dfmem.to_csv("plot_torch_export_ort_load_mem.csv", index=False)
        dfmem.to_excel("plot_torch_export_ort_load_mem.xlsx", index=False)
        dfmemr = pandas.DataFrame(data_mem_run)
        dfmemr.to_csv("plot_torch_export_ort_run_mem.csv", index=False)
        dfmemr.to_excel("plot_torch_export_ort_run_mem.xlsx", index=False)
        dfmemfr = pandas.DataFrame(data_mem_first_run)
        dfmemfr.to_csv("plot_torch_export_ort_first_run_mem.csv", index=False)
        dfmemfr.to_excel("plot_torch_export_ort_first_run_mem.xlsx", index=False)
        return df, df1, dfmem, dfmemfr, dfmemr


    df, df_init, dfmem, dfmemfr, dfmemr = benchmark(list(input_tensor.shape))
    print(df)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

      0%|          | 0/20 [00:00<?, ?it/s]number of experiments: 20
    6.483880551022816e-05 plot_torch_export_cus_p2.onnx ['CPUExecutionProvider']:   0%|          | 0/20 [00:00<?, ?it/s]    6.483880551022816e-05 plot_torch_export_cus_p2.onnx ['CPUExecutionProvider']:   5%|▌         | 1/20 [00:00<00:16,  1.13it/s]    5.542607990037235e-05 plot_torch_export_cus_p2.onnx ['CPUExecutionProvider']:   5%|▌         | 1/20 [00:01<00:16,  1.13it/s]    5.542607990037235e-05 plot_torch_export_cus_p2.onnx ['CPUExecutionProvider']:  10%|█         | 2/20 [00:01<00:16,  1.10it/s]    0.0006697205223930207 plot_torch_export_cus_p2.onnx ['CUDAExecutionProvider', 'CPUExecutionProvider']:  10%|█         | 2/20 [00:02<00:16,  1.10it/s]    0.0006697205223930207 plot_torch_export_cus_p2.onnx ['CUDAExecutionProvider', 'CPUExecutionProvider']:  15%|█▌        | 3/20 [00:02<00:15,  1.11it/s]    0.0006617759874254559 plot_torch_export_cus_p2.onnx ['CUDAExecutionProvider', 'CPUExecutionProvider']:  15%|█▌        | 3/20 [00:03<00:15,  1.11it/s]    0.0006617759874254559 plot_torch_export_cus_p2.onnx ['CUDAExecutionProvider', 'CPUExecutionProvider']:  20%|██        | 4/20 [00:03<00:13,  1.17it/s]    4.989830666513305e-05 plot_torch_export_dynopt.onnx ['CPUExecutionProvider']:  20%|██        | 4/20 [00:04<00:13,  1.17it/s]                             4.989830666513305e-05 plot_torch_export_dynopt.onnx ['CPUExecutionProvider']:  25%|██▌       | 5/20 [00:04<00:12,  1.19it/s]    5.4981575758555755e-05 plot_torch_export_dynopt.onnx ['CPUExecutionProvider']:  25%|██▌       | 5/20 [00:05<00:12,  1.19it/s]    5.4981575758555755e-05 plot_torch_export_dynopt.onnx ['CPUExecutionProvider']:  30%|███       | 6/20 [00:05<00:12,  1.15it/s]    0.000749330761576833 plot_torch_export_dynopt.onnx ['CUDAExecutionProvider', 'CPUExecutionProvider']:  30%|███       | 6/20 [00:06<00:12,  1.15it/s]    0.000749330761576833 plot_torch_export_dynopt.onnx ['CUDAExecutionProvider', 'CPUExecutionProvider']:  35%|███▌      | 7/20 [00:06<00:12,  1.01it/s]    0.00056971850695676 plot_torch_export_dynopt.onnx ['CUDAExecutionProvider', 'CPUExecutionProvider']:  35%|███▌      | 7/20 [00:07<00:12,  1.01it/s]     0.00056971850695676 plot_torch_export_dynopt.onnx ['CUDAExecutionProvider', 'CPUExecutionProvider']:  40%|████      | 8/20 [00:07<00:11,  1.05it/s]    0.00011999101257661439 plot_torch_export_dynamo.onnx ['CPUExecutionProvider']:  40%|████      | 8/20 [00:08<00:11,  1.05it/s]                          0.00011999101257661439 plot_torch_export_dynamo.onnx ['CPUExecutionProvider']:  45%|████▌     | 9/20 [00:08<00:10,  1.05it/s]    0.00011013189522384177 plot_torch_export_dynamo.onnx ['CPUExecutionProvider']:  45%|████▌     | 9/20 [00:09<00:10,  1.05it/s]    0.00011013189522384177 plot_torch_export_dynamo.onnx ['CPUExecutionProvider']:  50%|█████     | 10/20 [00:09<00:09,  1.05it/s]    0.0007421003096462828 plot_torch_export_dynamo.onnx ['CUDAExecutionProvider', 'CPUExecutionProvider']:  50%|█████     | 10/20 [00:09<00:09,  1.05it/s]    0.0007421003096462828 plot_torch_export_dynamo.onnx ['CUDAExecutionProvider', 'CPUExecutionProvider']:  55%|█████▌    | 11/20 [00:10<00:08,  1.07it/s]    0.0006763151004509395 plot_torch_export_dynamo.onnx ['CUDAExecutionProvider', 'CPUExecutionProvider']:  55%|█████▌    | 11/20 [00:10<00:08,  1.07it/s]    0.0006763151004509395 plot_torch_export_dynamo.onnx ['CUDAExecutionProvider', 'CPUExecutionProvider']:  60%|██████    | 12/20 [00:11<00:07,  1.07it/s]    5.828093656232976e-05 plot_torch_export_script.onnx ['CPUExecutionProvider']:  60%|██████    | 12/20 [00:11<00:07,  1.07it/s]                             5.828093656232976e-05 plot_torch_export_script.onnx ['CPUExecutionProvider']:  65%|██████▌   | 13/20 [00:11<00:06,  1.08it/s]    0.00013688182641415997 plot_torch_export_script.onnx ['CPUExecutionProvider']:  65%|██████▌   | 13/20 [00:12<00:06,  1.08it/s]    0.00013688182641415997 plot_torch_export_script.onnx ['CPUExecutionProvider']:  70%|███████   | 14/20 [00:12<00:05,  1.08it/s]    0.0006785470503007147 plot_torch_export_script.onnx ['CUDAExecutionProvider', 'CPUExecutionProvider']:  70%|███████   | 14/20 [00:13<00:05,  1.08it/s]    0.0006785470503007147 plot_torch_export_script.onnx ['CUDAExecutionProvider', 'CPUExecutionProvider']:  75%|███████▌  | 15/20 [00:13<00:04,  1.14it/s]    0.0006188644245961179 plot_torch_export_script.onnx ['CUDAExecutionProvider', 'CPUExecutionProvider']:  75%|███████▌  | 15/20 [00:14<00:04,  1.14it/s]    0.0006188644245961179 plot_torch_export_script.onnx ['CUDAExecutionProvider', 'CPUExecutionProvider']:  80%|████████  | 16/20 [00:14<00:03,  1.15it/s]    0.00013321774967783756 plot_torch_export_cus_p0.onnx ['CPUExecutionProvider']:  80%|████████  | 16/20 [00:15<00:03,  1.15it/s]                            0.00013321774967783756 plot_torch_export_cus_p0.onnx ['CPUExecutionProvider']:  85%|████████▌ | 17/20 [00:15<00:02,  1.16it/s]    0.000126562590948543 plot_torch_export_cus_p0.onnx ['CPUExecutionProvider']:  85%|████████▌ | 17/20 [00:16<00:02,  1.16it/s]      0.000126562590948543 plot_torch_export_cus_p0.onnx ['CPUExecutionProvider']:  90%|█████████ | 18/20 [00:16<00:01,  1.15it/s]    0.0006541280049554985 plot_torch_export_cus_p0.onnx ['CUDAExecutionProvider', 'CPUExecutionProvider']:  90%|█████████ | 18/20 [00:17<00:01,  1.15it/s]    0.0006541280049554985 plot_torch_export_cus_p0.onnx ['CUDAExecutionProvider', 'CPUExecutionProvider']:  95%|█████████▌| 19/20 [00:17<00:00,  1.14it/s]    0.0006785564030213942 plot_torch_export_cus_p0.onnx ['CUDAExecutionProvider', 'CPUExecutionProvider']:  95%|█████████▌| 19/20 [00:17<00:00,  1.14it/s]    0.0006785564030213942 plot_torch_export_cus_p0.onnx ['CUDAExecutionProvider', 'CPUExecutionProvider']: 100%|██████████| 20/20 [00:18<00:00,  1.14it/s]    0.0006785564030213942 plot_torch_export_cus_p0.onnx ['CUDAExecutionProvider', 'CPUExecutionProvider']: 100%|██████████| 20/20 [00:18<00:00,  1.11it/s]
                                 name                                   providers compute  aot  export  n_nodes  n_function  n_sub   average  deviation  min_exec  max_exec  repeat  number     ttime  context_size  warmup_time
    0   plot_torch_export_cus_p2.onnx                        CPUExecutionProvider     CPU    1  cus_p2       12           0      0  0.000065   0.000045  0.000044  0.000318       1  1635.0  0.106011            64     0.000934
    1   plot_torch_export_cus_p2.onnx                        CPUExecutionProvider     CPU    0  cus_p2       12           0      0  0.000055   0.000016  0.000046  0.000156       1  2403.0  0.133189            64     0.000264
    2   plot_torch_export_cus_p2.onnx  CUDAExecutionProvider,CPUExecutionProvider    CUDA    1  cus_p2       12           0      0  0.000670   0.000054  0.000618  0.001012       1   201.0  0.134614            64     0.001846
    3   plot_torch_export_cus_p2.onnx  CUDAExecutionProvider,CPUExecutionProvider    CUDA    0  cus_p2       12           0      0  0.000662   0.000015  0.000591  0.000679       1   159.0  0.105222            64     0.001335
    4   plot_torch_export_dynopt.onnx                        CPUExecutionProvider     CPU    1  dynopt       16           0      0  0.000050   0.000005  0.000043  0.000081       1  2475.0  0.123498            64     0.000305
    5   plot_torch_export_dynopt.onnx                        CPUExecutionProvider     CPU    0  dynopt       16           0      0  0.000055   0.000019  0.000045  0.000146       1  1914.0  0.105235            64     0.000535
    6   plot_torch_export_dynopt.onnx  CUDAExecutionProvider,CPUExecutionProvider    CUDA    1  dynopt       16           0      0  0.000749   0.000139  0.000650  0.001009       1   151.0  0.113149            64     0.001955
    7   plot_torch_export_dynopt.onnx  CUDAExecutionProvider,CPUExecutionProvider    CUDA    0  dynopt       16           0      0  0.000570   0.000062  0.000531  0.000702       1   215.0  0.122489            64     0.001587
    8   plot_torch_export_dynamo.onnx                        CPUExecutionProvider     CPU    1  dynamo       17           2      0  0.000120   0.000056  0.000066  0.000199       1  1272.0  0.152629            64     0.000671
    9   plot_torch_export_dynamo.onnx                        CPUExecutionProvider     CPU    0  dynamo       17           2      0  0.000110   0.000005  0.000050  0.000117       1  1842.0  0.202863            64     0.000288
    10  plot_torch_export_dynamo.onnx  CUDAExecutionProvider,CPUExecutionProvider    CUDA    1  dynamo       17           2      0  0.000742   0.000090  0.000672  0.000895       1   155.0  0.115026            64     0.001923
    11  plot_torch_export_dynamo.onnx  CUDAExecutionProvider,CPUExecutionProvider    CUDA    0  dynamo       17           2      0  0.000676   0.000034  0.000628  0.000990       1   219.0  0.148113            64     0.001898
    12  plot_torch_export_script.onnx                        CPUExecutionProvider     CPU    1  script       12           0      0  0.000058   0.000038  0.000044  0.000643       1  1860.0  0.108403            64     0.000372
    13  plot_torch_export_script.onnx                        CPUExecutionProvider     CPU    0  script       12           0      0  0.000137   0.000075  0.000050  0.000290       1   795.0  0.108821            64     0.001180
    14  plot_torch_export_script.onnx  CUDAExecutionProvider,CPUExecutionProvider    CUDA    1  script       12           0      0  0.000679   0.000060  0.000622  0.000895       1   159.0  0.107889            64     0.001856
    15  plot_torch_export_script.onnx  CUDAExecutionProvider,CPUExecutionProvider    CUDA    0  script       12           0      0  0.000619   0.000025  0.000606  0.000843       1   179.0  0.110777            64     0.001888
    16  plot_torch_export_cus_p0.onnx                        CPUExecutionProvider     CPU    1  cus_p0       15           0      0  0.000133   0.000063  0.000053  0.000335       1   783.0  0.104309            64     0.000850
    17  plot_torch_export_cus_p0.onnx                        CPUExecutionProvider     CPU    0  cus_p0       15           0      0  0.000127   0.000039  0.000082  0.000363       1  1017.0  0.128714            64     0.001341
    18  plot_torch_export_cus_p0.onnx  CUDAExecutionProvider,CPUExecutionProvider    CUDA    1  cus_p0       15           0      0  0.000654   0.000078  0.000596  0.001214       1   201.0  0.131480            64     0.002156
    19  plot_torch_export_cus_p0.onnx  CUDAExecutionProvider,CPUExecutionProvider    CUDA    0  cus_p0       15           0      0  0.000679   0.000047  0.000617  0.001065       1   201.0  0.136390            64     0.001991




.. GENERATED FROM PYTHON SOURCE LINES 653-654

Other view

.. GENERATED FROM PYTHON SOURCE LINES 654-689

.. code-block:: Python



    def view_time(df, title, suffix="time"):
        piv = pandas.pivot_table(df, index="export", columns=["compute", "aot"], values="average")
        print(piv)
        piv.to_csv(f"plot_torch_export_ort_{suffix}_compute.csv")
        piv.to_excel(f"plot_torch_export_ort_{suffix}_compute.xlsx")

        piv_cpu = pandas.pivot_table(
            df[df.compute == "CPU"],
            index="export",
            columns=["compute", "aot"],
            values="average",
        )

        fig, ax = plt.subplots(1, 2, figsize=(12, 4))
        fig.suptitle(title)
        piv_cpu.plot.barh(ax=ax[0], title="CPU")

        if has_cuda:
            piv_gpu = pandas.pivot_table(
                df[df.compute == "CUDA"],
                index="export",
                columns=["compute", "aot"],
                values="average",
            )
            piv_gpu.plot.barh(ax=ax[1], title="CUDA")

        fig.tight_layout()
        fig.savefig(f"plot_torch_export_ort_{suffix}.png")
        return ax


    view_time(df, "Compares onnxruntime time on exported models")




.. image-sg:: /auto_examples/images/sphx_glr_plot_torch_export_201_003.png
   :alt: Compares onnxruntime time on exported models, CPU, CUDA
   :srcset: /auto_examples/images/sphx_glr_plot_torch_export_201_003.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    compute       CPU                CUDA          
    aot             0         1         0         1
    export                                         
    cus_p0   0.000127  0.000133  0.000679  0.000654
    cus_p2   0.000055  0.000065  0.000662  0.000670
    dynamo   0.000110  0.000120  0.000676  0.000742
    dynopt   0.000055  0.000050  0.000570  0.000749
    script   0.000137  0.000058  0.000619  0.000679

    array([<Axes: title={'center': 'CPU'}, ylabel='export'>,
           <Axes: title={'center': 'CUDA'}, ylabel='export'>], dtype=object)



.. GENERATED FROM PYTHON SOURCE LINES 690-691

New graph without the very long times.

.. GENERATED FROM PYTHON SOURCE LINES 691-719

.. code-block:: Python


    piv_cpu = pandas.pivot_table(
        df[
            (df.compute == "CPU")
            & ((df.aot == 1) | ((df.export != "dynamo") & (df.export != "dynopt")))
        ],
        index="export",
        columns=["compute", "aot"],
        values="average",
    )

    fig, ax = plt.subplots(1, 2, figsize=(12, 4))
    fig.suptitle("Compares onnxruntime time on exported models\nHide dynamo without AOT")
    piv_cpu.plot.barh(ax=ax[0], title="CPU")

    if has_cuda:
        piv_gpu = pandas.pivot_table(
            df[df.compute == "CUDA"],
            index="export",
            columns=["compute", "aot"],
            values="average",
        )
        piv_gpu.plot.barh(ax=ax[1], title="CUDA")

    fig.tight_layout()
    fig.savefig("plot_torch_export_ort_time_2.png")





.. image-sg:: /auto_examples/images/sphx_glr_plot_torch_export_201_004.png
   :alt: Compares onnxruntime time on exported models Hide dynamo without AOT, CPU, CUDA
   :srcset: /auto_examples/images/sphx_glr_plot_torch_export_201_004.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 720-721

Let's do the same with the loading time + the first run.

.. GENERATED FROM PYTHON SOURCE LINES 721-729

.. code-block:: Python


    view_time(
        df_init,
        "Compares onnxruntime loading time and first run on exported models",
        suffix="time1_init",
    )





.. image-sg:: /auto_examples/images/sphx_glr_plot_torch_export_201_005.png
   :alt: Compares onnxruntime loading time and first run on exported models, CPU, CUDA
   :srcset: /auto_examples/images/sphx_glr_plot_torch_export_201_005.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    compute       CPU                CUDA          
    aot             0         1         0         1
    export                                         
    cus_p0   0.007672  0.007547  0.039553  0.042411
    cus_p2   0.007657  0.010460  0.029390  0.028335
    dynamo   0.008768  0.007736  0.030956  0.025820
    dynopt   0.007163  0.007586  0.036962  0.037953
    script   0.006722  0.006567  0.039189  0.038493

    array([<Axes: title={'center': 'CPU'}, ylabel='export'>,
           <Axes: title={'center': 'CUDA'}, ylabel='export'>], dtype=object)



.. GENERATED FROM PYTHON SOURCE LINES 730-732

Memory Loading Time (ORT)
+++++++++++++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 732-745

.. code-block:: Python


    for compute in ["CPU", "CUDA"]:
        if not has_cuda and compute == "CUDA":
            continue
        ax = memory_peak_plot(
            dfmem[dfmem.compute == compute],
            ("export", "aot"),
            suptitle=f"Memory Consumption of onnxruntime loading time\nrunning on {compute}",
            bars=[model_size * i / 2**20 for i in range(1, 3)],
            figsize=(18, 6),
        )
        get_figure(ax).savefig(f"plot_torch_export_ort_load_mem_{compute}.png")




.. rst-class:: sphx-glr-horizontal


    *

      .. image-sg:: /auto_examples/images/sphx_glr_plot_torch_export_201_006.png
         :alt: Memory Consumption of onnxruntime loading time running on CPU, Memory peak (Mb), Memory peak - memory begin (Mb), Memory average - memory begin (Mb), GPU Memory peak (Mb), GPU Memory peak - memory begin (Mb), GPU Memory average - memory begin (Mb)
         :srcset: /auto_examples/images/sphx_glr_plot_torch_export_201_006.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/images/sphx_glr_plot_torch_export_201_007.png
         :alt: Memory Consumption of onnxruntime loading time running on CUDA, Memory peak (Mb), Memory peak - memory begin (Mb), Memory average - memory begin (Mb), GPU Memory peak (Mb), GPU Memory peak - memory begin (Mb), GPU Memory average - memory begin (Mb)
         :srcset: /auto_examples/images/sphx_glr_plot_torch_export_201_007.png
         :class: sphx-glr-multi-img





.. GENERATED FROM PYTHON SOURCE LINES 746-748

Memory First Running Time (ORT)
+++++++++++++++++++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 748-762

.. code-block:: Python


    for compute in ["CPU", "CUDA"]:
        if not has_cuda and compute == "CUDA":
            continue
        ax = memory_peak_plot(
            dfmemfr[dfmemfr.compute == compute],
            ("export", "aot"),
            suptitle=f"Memory Consumption of onnxruntime first running time"
            f"\nrunning on {compute}",
            bars=[model_size * i / 2**20 for i in range(1, 3)],
            figsize=(18, 6),
        )
        get_figure(ax).savefig(f"plot_torch_export_ort_first_run_mem_{compute}.png")




.. rst-class:: sphx-glr-horizontal


    *

      .. image-sg:: /auto_examples/images/sphx_glr_plot_torch_export_201_008.png
         :alt: Memory Consumption of onnxruntime first running time running on CPU, Memory peak (Mb), Memory peak - memory begin (Mb), Memory average - memory begin (Mb), GPU Memory peak (Mb), GPU Memory peak - memory begin (Mb), GPU Memory average - memory begin (Mb)
         :srcset: /auto_examples/images/sphx_glr_plot_torch_export_201_008.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/images/sphx_glr_plot_torch_export_201_009.png
         :alt: Memory Consumption of onnxruntime first running time running on CUDA, Memory peak (Mb), Memory peak - memory begin (Mb), Memory average - memory begin (Mb), GPU Memory peak (Mb), GPU Memory peak - memory begin (Mb), GPU Memory average - memory begin (Mb)
         :srcset: /auto_examples/images/sphx_glr_plot_torch_export_201_009.png
         :class: sphx-glr-multi-img





.. GENERATED FROM PYTHON SOURCE LINES 763-765

Memory Running Time (ORT)
+++++++++++++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 765-779

.. code-block:: Python


    for compute in ["CPU", "CUDA"]:
        if not has_cuda and compute == "CUDA":
            continue
        ax = memory_peak_plot(
            dfmemr[dfmemr.compute == compute],
            ("export", "aot"),
            suptitle=f"Memory Consumption of onnxruntime running time\nrunning on {compute}",
            bars=[model_size * i / 2**20 for i in range(1, 3)],
            figsize=(18, 6),
        )
        get_figure(ax).savefig(f"plot_torch_export_ort_run_mem_{compute}.png")





.. rst-class:: sphx-glr-horizontal


    *

      .. image-sg:: /auto_examples/images/sphx_glr_plot_torch_export_201_010.png
         :alt: Memory Consumption of onnxruntime running time running on CPU, Memory peak (Mb), Memory peak - memory begin (Mb), Memory average - memory begin (Mb), GPU Memory peak (Mb), GPU Memory peak - memory begin (Mb), GPU Memory average - memory begin (Mb)
         :srcset: /auto_examples/images/sphx_glr_plot_torch_export_201_010.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/images/sphx_glr_plot_torch_export_201_011.png
         :alt: Memory Consumption of onnxruntime running time running on CUDA, Memory peak (Mb), Memory peak - memory begin (Mb), Memory average - memory begin (Mb), GPU Memory peak (Mb), GPU Memory peak - memory begin (Mb), GPU Memory average - memory begin (Mb)
         :srcset: /auto_examples/images/sphx_glr_plot_torch_export_201_011.png
         :class: sphx-glr-multi-img





.. GENERATED FROM PYTHON SOURCE LINES 780-785

Show the interesting models for CPU
+++++++++++++++++++++++++++++++++++

script
~~~~~~

.. GENERATED FROM PYTHON SOURCE LINES 785-790

.. code-block:: Python


    model = "ort-plot_torch_export_cus_p2-cpu-aot0.onnx"
    if os.path.exists(model):
        print(pretty_onnx(onnx.load(model)))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    opset: domain='' version=18
    opset: domain='ai.onnx.ml' version=5
    opset: domain='ai.onnx.training' version=1
    opset: domain='ai.onnx.preview.training' version=1
    opset: domain='com.microsoft' version=1
    opset: domain='com.microsoft.experimental' version=1
    opset: domain='com.microsoft.nchwc' version=1
    opset: domain='org.pytorch.aten' version=1
    doc_string: large_model=False, inline=False, external_threshold=102...
    input: name='input' type=dtype('float32') shape=[1, 1, 16, 16]
    init: name='_onx_concat0' type=int64 shape=(2,) -- array([ 1, -1])    -- GraphBuilder.constant_folding.from/fold(_onx_gatherelements0,init7_s1_-1)##_onx_gatherelements0/GraphBuilder.constant_folding.from/fold(_onx_shape0,init7_s1_0)##_onx_shape0/##init7_s1_0/Opset.make_node.1/Shape##init7_s1_-1/Opset.make_node.1/Shape
    init: name='GemmTransposePattern--_onx_transpose0' type=float32 shape=(512, 16)-- GraphBuilder.constant_folding.from/fold(_onx_transpose0)##_onx_transpose0/GraphBuilder.constant_folding.from/fold(p_fc1_weight)##p_fc1_weight/DynamoInterpret.placeholder.1/P(fc1.weight)
    init: name='GemmTransposePattern--_onx_transpose02' type=float32 shape=(128, 512)-- GraphBuilder.constant_folding.from/fold(_onx_transpose02)##_onx_transpose02/GraphBuilder.constant_folding.from/fold(p_fc2_weight)##p_fc2_weight/DynamoInterpret.placeholder.1/P(fc2.weight)
    init: name='GemmTransposePattern--_onx_transpose03' type=float32 shape=(10, 128)-- GraphBuilder.constant_folding.from/fold(_onx_transpose03)##_onx_transpose03/GraphBuilder.constant_folding.from/fold(p_fc3_weight)##p_fc3_weight/DynamoInterpret.placeholder.1/P(fc3.weight)
    init: name='reorder' type=float32 shape=(16, 1, 5, 5)
    init: name='conv1.bias' type=float32 shape=(16,)                      -- DynamoInterpret.placeholder.1/P(conv1.bias)
    init: name='reorder_token_1' type=float32 shape=(16, 16, 5, 5)
    init: name='conv2.bias' type=float32 shape=(16,)                      -- DynamoInterpret.placeholder.1/P(conv2.bias)
    init: name='fc1.bias' type=float32 shape=(512,)                       -- DynamoInterpret.placeholder.1/P(fc1.bias)
    init: name='fc2.bias' type=float32 shape=(128,)                       -- DynamoInterpret.placeholder.1/P(fc2.bias)
    init: name='fc3.bias' type=float32 shape=(10,)                        -- DynamoInterpret.placeholder.1/P(fc3.bias)
    Conv[com.microsoft.nchwc](input, reorder, conv1.bias, activation=b'Relu', dilations=[1,1], group=1, strides=[1,1], pads=[0,0,0,0], auto_pad=b'NOTSET') -> reorder_token_0
      ReorderOutput[com.microsoft.nchwc](reorder_token_0, channels_last=0, channels=16) -> relu
        MaxPool(relu, storage_order=0, auto_pad=b'NOTSET', ceil_mode=0, dilations=[1,1], kernel_shape=[2,2], pads=[0,0,0,0], strides=[2,2]) -> _onx_maxpool0, _onx_maxpool1
          ReorderInput[com.microsoft.nchwc](_onx_maxpool0, channels_last=0) -> reorder_token_2
            Conv[com.microsoft.nchwc](reorder_token_2, reorder_token_1, conv2.bias, activation=b'Relu', dilations=[1,1], group=1, strides=[1,1], pads=[0,0,0,0], auto_pad=b'NOTSET') -> reorder_token_3
              ReorderOutput[com.microsoft.nchwc](reorder_token_3, channels_last=0, channels=16) -> relu_1
                MaxPool(relu_1, storage_order=0, auto_pad=b'NOTSET', ceil_mode=0, dilations=[1,1], kernel_shape=[2,2], pads=[0,0,0,0], strides=[2,2]) -> _onx_maxpool02, _onx_maxpool12
                  Reshape(_onx_maxpool02, _onx_concat0, allowzero=0) -> flatten
                    FusedGemm[com.microsoft](flatten, GemmTransposePattern--_onx_transpose0, fc1.bias, transA=0, beta=1.00, activation=b'Relu', transB=1, alpha=1.00) -> relu_2
                      FusedGemm[com.microsoft](relu_2, GemmTransposePattern--_onx_transpose02, fc2.bias, transA=0, beta=1.00, activation=b'Relu', transB=1, alpha=1.00) -> relu_3
                        Gemm(relu_3, GemmTransposePattern--_onx_transpose03, fc3.bias, transA=0, beta=1.00, transB=1, alpha=1.00) -> output_0
    output: name='output_0' type=dtype('float32') shape=[1, 10]




.. GENERATED FROM PYTHON SOURCE LINES 791-793

cus_p2
~~~~~~

.. GENERATED FROM PYTHON SOURCE LINES 793-798

.. code-block:: Python


    model = "ort-plot_torch_export_cus_p2-cpu-aot0.onnx"
    if os.path.exists(model):
        print(pretty_onnx(onnx.load(model)))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    opset: domain='' version=18
    opset: domain='ai.onnx.ml' version=5
    opset: domain='ai.onnx.training' version=1
    opset: domain='ai.onnx.preview.training' version=1
    opset: domain='com.microsoft' version=1
    opset: domain='com.microsoft.experimental' version=1
    opset: domain='com.microsoft.nchwc' version=1
    opset: domain='org.pytorch.aten' version=1
    doc_string: large_model=False, inline=False, external_threshold=102...
    input: name='input' type=dtype('float32') shape=[1, 1, 16, 16]
    init: name='_onx_concat0' type=int64 shape=(2,) -- array([ 1, -1])    -- GraphBuilder.constant_folding.from/fold(_onx_gatherelements0,init7_s1_-1)##_onx_gatherelements0/GraphBuilder.constant_folding.from/fold(_onx_shape0,init7_s1_0)##_onx_shape0/##init7_s1_0/Opset.make_node.1/Shape##init7_s1_-1/Opset.make_node.1/Shape
    init: name='GemmTransposePattern--_onx_transpose0' type=float32 shape=(512, 16)-- GraphBuilder.constant_folding.from/fold(_onx_transpose0)##_onx_transpose0/GraphBuilder.constant_folding.from/fold(p_fc1_weight)##p_fc1_weight/DynamoInterpret.placeholder.1/P(fc1.weight)
    init: name='GemmTransposePattern--_onx_transpose02' type=float32 shape=(128, 512)-- GraphBuilder.constant_folding.from/fold(_onx_transpose02)##_onx_transpose02/GraphBuilder.constant_folding.from/fold(p_fc2_weight)##p_fc2_weight/DynamoInterpret.placeholder.1/P(fc2.weight)
    init: name='GemmTransposePattern--_onx_transpose03' type=float32 shape=(10, 128)-- GraphBuilder.constant_folding.from/fold(_onx_transpose03)##_onx_transpose03/GraphBuilder.constant_folding.from/fold(p_fc3_weight)##p_fc3_weight/DynamoInterpret.placeholder.1/P(fc3.weight)
    init: name='reorder' type=float32 shape=(16, 1, 5, 5)
    init: name='conv1.bias' type=float32 shape=(16,)                      -- DynamoInterpret.placeholder.1/P(conv1.bias)
    init: name='reorder_token_1' type=float32 shape=(16, 16, 5, 5)
    init: name='conv2.bias' type=float32 shape=(16,)                      -- DynamoInterpret.placeholder.1/P(conv2.bias)
    init: name='fc1.bias' type=float32 shape=(512,)                       -- DynamoInterpret.placeholder.1/P(fc1.bias)
    init: name='fc2.bias' type=float32 shape=(128,)                       -- DynamoInterpret.placeholder.1/P(fc2.bias)
    init: name='fc3.bias' type=float32 shape=(10,)                        -- DynamoInterpret.placeholder.1/P(fc3.bias)
    Conv[com.microsoft.nchwc](input, reorder, conv1.bias, activation=b'Relu', dilations=[1,1], group=1, strides=[1,1], pads=[0,0,0,0], auto_pad=b'NOTSET') -> reorder_token_0
      ReorderOutput[com.microsoft.nchwc](reorder_token_0, channels_last=0, channels=16) -> relu
        MaxPool(relu, storage_order=0, auto_pad=b'NOTSET', ceil_mode=0, dilations=[1,1], kernel_shape=[2,2], pads=[0,0,0,0], strides=[2,2]) -> _onx_maxpool0, _onx_maxpool1
          ReorderInput[com.microsoft.nchwc](_onx_maxpool0, channels_last=0) -> reorder_token_2
            Conv[com.microsoft.nchwc](reorder_token_2, reorder_token_1, conv2.bias, activation=b'Relu', dilations=[1,1], group=1, strides=[1,1], pads=[0,0,0,0], auto_pad=b'NOTSET') -> reorder_token_3
              ReorderOutput[com.microsoft.nchwc](reorder_token_3, channels_last=0, channels=16) -> relu_1
                MaxPool(relu_1, storage_order=0, auto_pad=b'NOTSET', ceil_mode=0, dilations=[1,1], kernel_shape=[2,2], pads=[0,0,0,0], strides=[2,2]) -> _onx_maxpool02, _onx_maxpool12
                  Reshape(_onx_maxpool02, _onx_concat0, allowzero=0) -> flatten
                    FusedGemm[com.microsoft](flatten, GemmTransposePattern--_onx_transpose0, fc1.bias, transA=0, beta=1.00, activation=b'Relu', transB=1, alpha=1.00) -> relu_2
                      FusedGemm[com.microsoft](relu_2, GemmTransposePattern--_onx_transpose02, fc2.bias, transA=0, beta=1.00, activation=b'Relu', transB=1, alpha=1.00) -> relu_3
                        Gemm(relu_3, GemmTransposePattern--_onx_transpose03, fc3.bias, transA=0, beta=1.00, transB=1, alpha=1.00) -> output_0
    output: name='output_0' type=dtype('float32') shape=[1, 10]




.. GENERATED FROM PYTHON SOURCE LINES 799-801

dynopt
~~~~~~

.. GENERATED FROM PYTHON SOURCE LINES 801-806

.. code-block:: Python


    model = "ort-plot_torch_export_dynopt-cpu-aot1.onnx"
    if os.path.exists(model):
        print(pretty_onnx(onnx.load(model)))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    opset: domain='pkg.onnxscript.torch_lib.common' version=1
    opset: domain='' version=18
    opset: domain='ai.onnx.ml' version=5
    opset: domain='ai.onnx.training' version=1
    opset: domain='ai.onnx.preview.training' version=1
    opset: domain='com.microsoft' version=1
    opset: domain='com.microsoft.experimental' version=1
    opset: domain='com.microsoft.nchwc' version=1
    opset: domain='org.pytorch.aten' version=1
    input: name='x' type=dtype('float32') shape=[1, 1, 16, 16]
    init: name='reorder' type=float32 shape=(16, 1, 5, 5)
    init: name='conv1.bias' type=float32 shape=(16,)
    init: name='reorder_token_2' type=float32 shape=(16, 16, 5, 5)
    init: name='conv2.bias' type=float32 shape=(16,)
    init: name='fc1.bias' type=float32 shape=(512,)
    init: name='fc2.bias' type=float32 shape=(128,)
    init: name='fc3.bias' type=float32 shape=(10,)
    init: name='val_3' type=int64 shape=(2,) -- array([ 1, 16])
    init: name='t' type=float32 shape=(16, 512)
    init: name='t_1' type=float32 shape=(512, 128)
    init: name='t_2' type=float32 shape=(128, 10)
    Conv[com.microsoft.nchwc](x, reorder, conv1.bias, activation=b'Relu', group=1, strides=[1,1], pads=[0,0,0,0], auto_pad=b'NOTSET', dilations=[1,1]) -> reorder_token_0
      MaxPool[com.microsoft.nchwc](reorder_token_0, pads=[0,0,0,0], kernel_shape=[2,2], ceil_mode=0, auto_pad=b'NOTSET', dilations=[1,1], strides=[2,2], storage_order=0) -> reorder_token_1
        Conv[com.microsoft.nchwc](reorder_token_1, reorder_token_2, conv2.bias, activation=b'Relu', group=1, strides=[1,1], pads=[0,0,0,0], auto_pad=b'NOTSET', dilations=[1,1]) -> reorder_token_3
          MaxPool[com.microsoft.nchwc](reorder_token_3, pads=[0,0,0,0], kernel_shape=[2,2], ceil_mode=0, auto_pad=b'NOTSET', dilations=[1,1], strides=[2,2], storage_order=0) -> reorder_token_4
            ReorderOutput[com.microsoft.nchwc](reorder_token_4, channels_last=0, channels=16) -> max_pool2d_1
              Reshape(max_pool2d_1, val_3, allowzero=0) -> view
                FusedGemm[com.microsoft](view, t, fc1.bias, transA=0, alpha=1.00, activation=b'Relu', transB=0, beta=1.00) -> relu_2
                  FusedGemm[com.microsoft](relu_2, t_1, fc2.bias, transA=0, alpha=1.00, activation=b'Relu', transB=0, beta=1.00) -> relu_3
                    Gemm(relu_3, t_2, fc3.bias, transA=0, alpha=1.00, transB=0, beta=1.00) -> addmm_2
    output: name='addmm_2' type=dtype('float32') shape=[1, 10]




.. GENERATED FROM PYTHON SOURCE LINES 807-809

dynamo
~~~~~~

.. GENERATED FROM PYTHON SOURCE LINES 809-815

.. code-block:: Python


    model = "ort-plot_torch_export_dynamo-cpu-aot1.onnx"
    if os.path.exists(model):
        print(pretty_onnx(onnx.load(model)))






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    opset: domain='pkg.onnxscript.torch_lib.common' version=1
    opset: domain='' version=18
    opset: domain='ai.onnx.ml' version=5
    opset: domain='ai.onnx.training' version=1
    opset: domain='ai.onnx.preview.training' version=1
    opset: domain='com.microsoft' version=1
    opset: domain='com.microsoft.experimental' version=1
    opset: domain='com.microsoft.nchwc' version=1
    opset: domain='org.pytorch.aten' version=1
    input: name='x' type=dtype('float32') shape=[1, 1, 16, 16]
    init: name='reorder' type=float32 shape=(16, 1, 5, 5)
    init: name='conv1.bias' type=float32 shape=(16,)
    init: name='reorder_token_1' type=float32 shape=(16, 16, 5, 5)
    init: name='conv2.bias' type=float32 shape=(16,)
    init: name='fc1.weight' type=float32 shape=(512, 16)
    init: name='fc1.bias' type=float32 shape=(512,)
    init: name='fc2.weight' type=float32 shape=(128, 512)
    init: name='fc2.bias' type=float32 shape=(128,)
    init: name='fc3.weight' type=float32 shape=(10, 128)
    init: name='fc3.bias' type=float32 shape=(10,)
    init: name='val_2' type=int64 shape=(2,) -- array([ 1, 16])
    Conv[com.microsoft.nchwc](x, reorder, conv1.bias, activation=b'Relu', group=1, strides=[1,1], pads=[0,0,0,0], auto_pad=b'NOTSET', dilations=[1,1]) -> reorder_token_0
      ReorderOutput[com.microsoft.nchwc](reorder_token_0, channels_last=0, channels=16) -> relu
        MaxPool(relu, pads=[0,0,0,0], kernel_shape=[2,2], ceil_mode=0, auto_pad=b'NOTSET', dilations=[1,1], strides=[2,2], storage_order=0) -> max_pool2d, val_0
          ReorderInput[com.microsoft.nchwc](max_pool2d, channels_last=0) -> reorder_token_2
            Conv[com.microsoft.nchwc](reorder_token_2, reorder_token_1, conv2.bias, activation=b'Relu', group=1, strides=[1,1], pads=[0,0,0,0], auto_pad=b'NOTSET', dilations=[1,1]) -> reorder_token_3
              ReorderOutput[com.microsoft.nchwc](reorder_token_3, channels_last=0, channels=16) -> relu_1
                MaxPool(relu_1, pads=[0,0,0,0], kernel_shape=[2,2], ceil_mode=0, auto_pad=b'NOTSET', dilations=[1,1], strides=[2,2], storage_order=0) -> max_pool2d_1, val_1
                  Reshape(max_pool2d_1, val_2, allowzero=0) -> view
                    FusedGemm[com.microsoft](view, fc1.weight, fc1.bias, activation=b'Relu', beta=1.00, transB=1, alpha=1.00, transA=0) -> relu_2
                      FusedGemm[com.microsoft](relu_2, fc2.weight, fc2.bias, activation=b'Relu', beta=1.00, transB=1, alpha=1.00, transA=0) -> relu_3
                        Gemm(relu_3, fc3.weight, fc3.bias, beta=1.00, transB=1, alpha=1.00, transA=0) -> addmm_2
    output: name='addmm_2' type=dtype('float32') shape=[1, 10]




.. GENERATED FROM PYTHON SOURCE LINES 816-821

Show the interesting models for CUDA
++++++++++++++++++++++++++++++++++++

script
~~~~~~

.. GENERATED FROM PYTHON SOURCE LINES 821-826

.. code-block:: Python


    model = "ort-plot_torch_export_cus_p2-cuda-aot0.onnx"
    if os.path.exists(model):
        print(pretty_onnx(onnx.load(model)))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    opset: domain='' version=18
    opset: domain='ai.onnx.ml' version=5
    opset: domain='ai.onnx.training' version=1
    opset: domain='ai.onnx.preview.training' version=1
    opset: domain='com.microsoft' version=1
    opset: domain='com.microsoft.experimental' version=1
    opset: domain='com.microsoft.nchwc' version=1
    opset: domain='org.pytorch.aten' version=1
    doc_string: large_model=False, inline=False, external_threshold=102...
    input: name='input' type=dtype('float32') shape=[1, 1, 16, 16]
    init: name='_onx_concat0' type=int64 shape=(2,) -- array([ 1, -1])    -- GraphBuilder.constant_folding.from/fold(_onx_gatherelements0,init7_s1_-1)##_onx_gatherelements0/GraphBuilder.constant_folding.from/fold(_onx_shape0,init7_s1_0)##_onx_shape0/##init7_s1_0/Opset.make_node.1/Shape##init7_s1_-1/Opset.make_node.1/Shape
    init: name='GemmTransposePattern--_onx_transpose0' type=float32 shape=(512, 16)-- GraphBuilder.constant_folding.from/fold(_onx_transpose0)##_onx_transpose0/GraphBuilder.constant_folding.from/fold(p_fc1_weight)##p_fc1_weight/DynamoInterpret.placeholder.1/P(fc1.weight)
    init: name='GemmTransposePattern--_onx_transpose02' type=float32 shape=(128, 512)-- GraphBuilder.constant_folding.from/fold(_onx_transpose02)##_onx_transpose02/GraphBuilder.constant_folding.from/fold(p_fc2_weight)##p_fc2_weight/DynamoInterpret.placeholder.1/P(fc2.weight)
    init: name='GemmTransposePattern--_onx_transpose03' type=float32 shape=(10, 128)-- GraphBuilder.constant_folding.from/fold(_onx_transpose03)##_onx_transpose03/GraphBuilder.constant_folding.from/fold(p_fc3_weight)##p_fc3_weight/DynamoInterpret.placeholder.1/P(fc3.weight)
    init: name='conv1.weight' type=float32 shape=(16, 1, 5, 5)            -- DynamoInterpret.placeholder.1/P(conv1.weight)
    init: name='conv1.bias' type=float32 shape=(16,)                      -- DynamoInterpret.placeholder.1/P(conv1.bias)
    init: name='conv2.weight' type=float32 shape=(16, 16, 5, 5)           -- DynamoInterpret.placeholder.1/P(conv2.weight)
    init: name='conv2.bias' type=float32 shape=(16,)                      -- DynamoInterpret.placeholder.1/P(conv2.bias)
    init: name='fc1.bias' type=float32 shape=(512,)                       -- DynamoInterpret.placeholder.1/P(fc1.bias)
    init: name='fc2.bias' type=float32 shape=(128,)                       -- DynamoInterpret.placeholder.1/P(fc2.bias)
    init: name='fc3.bias' type=float32 shape=(10,)                        -- DynamoInterpret.placeholder.1/P(fc3.bias)
    Conv(input, conv1.weight, conv1.bias, dilations=[1,1], group=1, pads=[0,0,0,0], strides=[1,1]) -> conv2d
      Relu(conv2d) -> relu
        MaxPool(relu, ceil_mode=0, dilations=[1,1], kernel_shape=[2,2], pads=[0,0,0,0], strides=[2,2]) -> _onx_maxpool0, _onx_maxpool1
          Conv(_onx_maxpool0, conv2.weight, conv2.bias, dilations=[1,1], group=1, pads=[0,0,0,0], strides=[1,1]) -> conv2d_1
            Relu(conv2d_1) -> relu_1
              MaxPool(relu_1, ceil_mode=0, dilations=[1,1], kernel_shape=[2,2], pads=[0,0,0,0], strides=[2,2]) -> _onx_maxpool02, _onx_maxpool12
                Reshape(_onx_maxpool02, _onx_concat0) -> flatten
                  Gemm(flatten, GemmTransposePattern--_onx_transpose0, fc1.bias, transB=1) -> linear
                    Relu(linear) -> relu_2
                      Gemm(relu_2, GemmTransposePattern--_onx_transpose02, fc2.bias, transB=1) -> linear_1
                        Relu(linear_1) -> relu_3
                          Gemm(relu_3, GemmTransposePattern--_onx_transpose03, fc3.bias, transB=1) -> output_0
    output: name='output_0' type=dtype('float32') shape=[1, 10]




.. GENERATED FROM PYTHON SOURCE LINES 827-829

cus_p2
~~~~~~

.. GENERATED FROM PYTHON SOURCE LINES 829-834

.. code-block:: Python


    model = "ort-plot_torch_export_cus_p2-cuda-aot0.onnx"
    if os.path.exists(model):
        print(pretty_onnx(onnx.load(model)))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    opset: domain='' version=18
    opset: domain='ai.onnx.ml' version=5
    opset: domain='ai.onnx.training' version=1
    opset: domain='ai.onnx.preview.training' version=1
    opset: domain='com.microsoft' version=1
    opset: domain='com.microsoft.experimental' version=1
    opset: domain='com.microsoft.nchwc' version=1
    opset: domain='org.pytorch.aten' version=1
    doc_string: large_model=False, inline=False, external_threshold=102...
    input: name='input' type=dtype('float32') shape=[1, 1, 16, 16]
    init: name='_onx_concat0' type=int64 shape=(2,) -- array([ 1, -1])    -- GraphBuilder.constant_folding.from/fold(_onx_gatherelements0,init7_s1_-1)##_onx_gatherelements0/GraphBuilder.constant_folding.from/fold(_onx_shape0,init7_s1_0)##_onx_shape0/##init7_s1_0/Opset.make_node.1/Shape##init7_s1_-1/Opset.make_node.1/Shape
    init: name='GemmTransposePattern--_onx_transpose0' type=float32 shape=(512, 16)-- GraphBuilder.constant_folding.from/fold(_onx_transpose0)##_onx_transpose0/GraphBuilder.constant_folding.from/fold(p_fc1_weight)##p_fc1_weight/DynamoInterpret.placeholder.1/P(fc1.weight)
    init: name='GemmTransposePattern--_onx_transpose02' type=float32 shape=(128, 512)-- GraphBuilder.constant_folding.from/fold(_onx_transpose02)##_onx_transpose02/GraphBuilder.constant_folding.from/fold(p_fc2_weight)##p_fc2_weight/DynamoInterpret.placeholder.1/P(fc2.weight)
    init: name='GemmTransposePattern--_onx_transpose03' type=float32 shape=(10, 128)-- GraphBuilder.constant_folding.from/fold(_onx_transpose03)##_onx_transpose03/GraphBuilder.constant_folding.from/fold(p_fc3_weight)##p_fc3_weight/DynamoInterpret.placeholder.1/P(fc3.weight)
    init: name='conv1.weight' type=float32 shape=(16, 1, 5, 5)            -- DynamoInterpret.placeholder.1/P(conv1.weight)
    init: name='conv1.bias' type=float32 shape=(16,)                      -- DynamoInterpret.placeholder.1/P(conv1.bias)
    init: name='conv2.weight' type=float32 shape=(16, 16, 5, 5)           -- DynamoInterpret.placeholder.1/P(conv2.weight)
    init: name='conv2.bias' type=float32 shape=(16,)                      -- DynamoInterpret.placeholder.1/P(conv2.bias)
    init: name='fc1.bias' type=float32 shape=(512,)                       -- DynamoInterpret.placeholder.1/P(fc1.bias)
    init: name='fc2.bias' type=float32 shape=(128,)                       -- DynamoInterpret.placeholder.1/P(fc2.bias)
    init: name='fc3.bias' type=float32 shape=(10,)                        -- DynamoInterpret.placeholder.1/P(fc3.bias)
    Conv(input, conv1.weight, conv1.bias, dilations=[1,1], group=1, pads=[0,0,0,0], strides=[1,1]) -> conv2d
      Relu(conv2d) -> relu
        MaxPool(relu, ceil_mode=0, dilations=[1,1], kernel_shape=[2,2], pads=[0,0,0,0], strides=[2,2]) -> _onx_maxpool0, _onx_maxpool1
          Conv(_onx_maxpool0, conv2.weight, conv2.bias, dilations=[1,1], group=1, pads=[0,0,0,0], strides=[1,1]) -> conv2d_1
            Relu(conv2d_1) -> relu_1
              MaxPool(relu_1, ceil_mode=0, dilations=[1,1], kernel_shape=[2,2], pads=[0,0,0,0], strides=[2,2]) -> _onx_maxpool02, _onx_maxpool12
                Reshape(_onx_maxpool02, _onx_concat0) -> flatten
                  Gemm(flatten, GemmTransposePattern--_onx_transpose0, fc1.bias, transB=1) -> linear
                    Relu(linear) -> relu_2
                      Gemm(relu_2, GemmTransposePattern--_onx_transpose02, fc2.bias, transB=1) -> linear_1
                        Relu(linear_1) -> relu_3
                          Gemm(relu_3, GemmTransposePattern--_onx_transpose03, fc3.bias, transB=1) -> output_0
    output: name='output_0' type=dtype('float32') shape=[1, 10]




.. GENERATED FROM PYTHON SOURCE LINES 835-837

dynopt
~~~~~~

.. GENERATED FROM PYTHON SOURCE LINES 837-842

.. code-block:: Python


    model = "ort-plot_torch_export_dynopt-cuda-aot1.onnx"
    if os.path.exists(model):
        print(pretty_onnx(onnx.load(model)))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    opset: domain='pkg.onnxscript.torch_lib.common' version=1
    opset: domain='' version=18
    opset: domain='ai.onnx.ml' version=5
    opset: domain='ai.onnx.training' version=1
    opset: domain='ai.onnx.preview.training' version=1
    opset: domain='com.microsoft' version=1
    opset: domain='com.microsoft.experimental' version=1
    opset: domain='com.microsoft.nchwc' version=1
    opset: domain='org.pytorch.aten' version=1
    input: name='x' type=dtype('float32') shape=[1, 1, 16, 16]
    init: name='conv1.weight' type=float32 shape=(16, 1, 5, 5)
    init: name='conv1.bias' type=float32 shape=(16,)
    init: name='conv2.weight' type=float32 shape=(16, 16, 5, 5)
    init: name='conv2.bias' type=float32 shape=(16,)
    init: name='fc1.bias' type=float32 shape=(512,)
    init: name='fc2.bias' type=float32 shape=(128,)
    init: name='fc3.bias' type=float32 shape=(10,)
    init: name='val_3' type=int64 shape=(2,) -- array([ 1, 16])
    init: name='t' type=float32 shape=(16, 512)
    init: name='t_1' type=float32 shape=(512, 128)
    init: name='t_2' type=float32 shape=(128, 10)
    Conv(x, conv1.weight, conv1.bias, group=1, pads=[0,0,0,0], auto_pad=b'NOTSET', strides=[1,1], dilations=[1,1]) -> conv2d
      Relu(conv2d) -> relu
        MaxPool(relu, storage_order=0, dilations=[1,1], ceil_mode=0, pads=[0,0,0,0], auto_pad=b'NOTSET', strides=[2,2], kernel_shape=[2,2]) -> max_pool2d
          Conv(max_pool2d, conv2.weight, conv2.bias, group=1, pads=[0,0,0,0], auto_pad=b'NOTSET', strides=[1,1], dilations=[1,1]) -> conv2d_1
            Relu(conv2d_1) -> relu_1
              MaxPool(relu_1, storage_order=0, dilations=[1,1], ceil_mode=0, pads=[0,0,0,0], auto_pad=b'NOTSET', strides=[2,2], kernel_shape=[2,2]) -> max_pool2d_1
                Reshape(max_pool2d_1, val_3, allowzero=0) -> view
                  Gemm(view, t, fc1.bias, beta=1.00, transB=0, alpha=1.00, transA=0) -> addmm
                    Relu(addmm) -> relu_2
                      Gemm(relu_2, t_1, fc2.bias, beta=1.00, transB=0, alpha=1.00, transA=0) -> addmm_1
                        Relu(addmm_1) -> relu_3
                          Gemm(relu_3, t_2, fc3.bias, beta=1.00, transB=0, alpha=1.00, transA=0) -> addmm_2
    output: name='addmm_2' type=dtype('float32') shape=[1, 10]




.. GENERATED FROM PYTHON SOURCE LINES 843-845

dynamo
~~~~~~

.. GENERATED FROM PYTHON SOURCE LINES 845-849

.. code-block:: Python


    model = "ort-plot_torch_export_dynamo-cuda-aot1.onnx"
    if os.path.exists(model):
        print(pretty_onnx(onnx.load(model)))




.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    opset: domain='pkg.onnxscript.torch_lib.common' version=1
    opset: domain='' version=18
    opset: domain='ai.onnx.ml' version=5
    opset: domain='ai.onnx.training' version=1
    opset: domain='ai.onnx.preview.training' version=1
    opset: domain='com.microsoft' version=1
    opset: domain='com.microsoft.experimental' version=1
    opset: domain='com.microsoft.nchwc' version=1
    opset: domain='org.pytorch.aten' version=1
    input: name='x' type=dtype('float32') shape=[1, 1, 16, 16]
    init: name='conv1.weight' type=float32 shape=(16, 1, 5, 5)
    init: name='conv1.bias' type=float32 shape=(16,)
    init: name='conv2.weight' type=float32 shape=(16, 16, 5, 5)
    init: name='conv2.bias' type=float32 shape=(16,)
    init: name='fc1.weight' type=float32 shape=(512, 16)
    init: name='fc1.bias' type=float32 shape=(512,)
    init: name='fc2.weight' type=float32 shape=(128, 512)
    init: name='fc2.bias' type=float32 shape=(128,)
    init: name='fc3.weight' type=float32 shape=(10, 128)
    init: name='fc3.bias' type=float32 shape=(10,)
    init: name='val_2' type=int64 shape=(2,) -- array([ 1, 16])
    Conv(x, conv1.weight, conv1.bias, dilations=[1,1], auto_pad=b'NOTSET', pads=[0,0,0,0], strides=[1,1], group=1) -> conv2d
      Relu(conv2d) -> relu
        MaxPool(relu, pads=[0,0,0,0], kernel_shape=[2,2], ceil_mode=0, auto_pad=b'NOTSET', dilations=[1,1], strides=[2,2], storage_order=0) -> max_pool2d, val_0
          Conv(max_pool2d, conv2.weight, conv2.bias, dilations=[1,1], auto_pad=b'NOTSET', pads=[0,0,0,0], strides=[1,1], group=1) -> conv2d_1
            Relu(conv2d_1) -> relu_1
              MaxPool(relu_1, pads=[0,0,0,0], kernel_shape=[2,2], ceil_mode=0, auto_pad=b'NOTSET', dilations=[1,1], strides=[2,2], storage_order=0) -> max_pool2d_1, val_1
                Reshape(max_pool2d_1, val_2, allowzero=0) -> view
                  Gemm(view, fc1.weight, fc1.bias, beta=1.00, transB=1, alpha=1.00, transA=0) -> addmm
                    Relu(addmm) -> relu_2
                      Gemm(relu_2, fc2.weight, fc2.bias, beta=1.00, transB=1, alpha=1.00, transA=0) -> addmm_1
                        Relu(addmm_1) -> relu_3
                          Gemm(relu_3, fc3.weight, fc3.bias, beta=1.00, transB=1, alpha=1.00, transA=0) -> addmm_2
    output: name='addmm_2' type=dtype('float32') shape=[1, 10]





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 49.538 seconds)


.. _sphx_glr_download_auto_examples_plot_torch_export_201.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_torch_export_201.ipynb <plot_torch_export_201.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_torch_export_201.py <plot_torch_export_201.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_torch_export_201.zip <plot_torch_export_201.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
