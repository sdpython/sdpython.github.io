
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_exporter_recipes_oe_cond.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_plot_exporter_recipes_oe_cond.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_exporter_recipes_oe_cond.py:


.. _l-plot-exporter-recipes-onnx-exporter-cond:

torch.onnx.export and a model with a test
=========================================

Control flow cannot be exported with a change.
The code of the model can be changed or patched
to introduce function :func:`torch.cond`.

A model with a test
+++++++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 14-19

.. code-block:: Python


    from onnx.printer import to_text
    import torch









.. GENERATED FROM PYTHON SOURCE LINES 20-21

We define a model with a control flow (-> graph break)

.. GENERATED FROM PYTHON SOURCE LINES 21-46

.. code-block:: Python



    class ModuleWithControlFlow(torch.nn.Module):
        def forward(self, x):
            if x.sum():
                return x * 2
            return -x


    class ModelWithControlFlow(torch.nn.Module):
        def __init__(self):
            super().__init__()
            self.mlp = torch.nn.Sequential(
                torch.nn.Linear(3, 2),
                torch.nn.Linear(2, 1),
                ModuleWithControlFlow(),
            )

        def forward(self, x):
            out = self.mlp(x)
            return out


    model = ModelWithControlFlow()








.. GENERATED FROM PYTHON SOURCE LINES 47-48

Let's check it runs.

.. GENERATED FROM PYTHON SOURCE LINES 48-51

.. code-block:: Python

    x = torch.randn(3)
    model(x)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    tensor([-0.4584], grad_fn=<MulBackward0>)



.. GENERATED FROM PYTHON SOURCE LINES 52-53

As expected, it does not export.

.. GENERATED FROM PYTHON SOURCE LINES 53-59

.. code-block:: Python

    try:
        torch.export.export(model, (x,))
        raise AssertionError("This export should failed unless pytorch now supports this model.")
    except Exception as e:
        print(e)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Dynamic control flow is not supported at the moment. Please use functorch.experimental.control_flow.cond to explicitly capture the control flow. For more information about this error, see: https://pytorch.org/docs/main/generated/exportdb/index.html#cond-operands

    from user code:
       File "/home/xadupre/github/experimental-experiment/_doc/examples/plot_exporter_recipes_oe_cond.py", line 40, in forward
        out = self.mlp(x)
      File "/home/xadupre/vv/this/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
        return forward_call(*args, **kwargs)
      File "/home/xadupre/github/experimental-experiment/_doc/examples/plot_exporter_recipes_oe_cond.py", line 25, in forward
        if x.sum():

    Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information





.. GENERATED FROM PYTHON SOURCE LINES 60-62

It does export with torch.onnx.export because it uses JIT to trace the execution.
But the model is not exactly the same as the initial model.

.. GENERATED FROM PYTHON SOURCE LINES 62-66

.. code-block:: Python

    ep = torch.onnx.export(model, (x,), dynamo=True)
    print(to_text(ep.model_proto))






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [torch.onnx] Obtain model graph for `ModelWithControlFlow([...]` with `torch.export.export`...
    [torch.onnx] Obtain model graph for `ModelWithControlFlow([...]` with `torch.export.export`... ❌
    [torch.onnx] Obtain model graph for `ModelWithControlFlow([...]` with `torch.export.export(..., strict=False)`...
    [torch.onnx] Obtain model graph for `ModelWithControlFlow([...]` with `torch.export.export(..., strict=False)`... ❌
    [torch.onnx] Obtain model graph for `ModelWithControlFlow([...]` with Torch Script...
    /home/xadupre/github/experimental-experiment/_doc/examples/plot_exporter_recipes_oe_cond.py:25: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
      if x.sum():
    [torch.onnx] Obtain model graph for `ModelWithControlFlow([...]` with Torch Script... ✅
    [torch.onnx] Translate the graph into ONNX...
    /home/xadupre/vv/this/lib/python3.10/site-packages/torch/export/_unlift.py:63: UserWarning: Attempted to insert a get_attr Node with no underlying reference in the owning GraphModule! Call GraphModule.add_submodule to add the necessary submodule, GraphModule.add_parameter to add the necessary Parameter, or nn.Module.register_buffer to add the necessary buffer
      getattr_node = gm.graph.get_attr(lifted_node)
    /home/xadupre/vv/this/lib/python3.10/site-packages/torch/fx/graph.py:1794: UserWarning: Node lifted_tensor_6 target lifted_tensor_6 lifted_tensor_6 of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target
      warnings.warn(
    [torch.onnx] Translate the graph into ONNX... ✅
    <
       ir_version: 9,
       opset_import: ["" : 18, "pkg.onnxscript.torch_lib.common" : 1],
       producer_name: "pytorch",
       producer_version: "2.6.0.dev20241027+cu121"
    >
    main_graph (float[3] input_1) => (float[1] mul) 
       <float[2] "model.mlp.0.bias" =  {0.181673,0.33226}, float[2,3] "model.mlp.0.weight" =  {0.144064,-0.451293,0.00360129,0.261578,0.317026,-0.442908}, float[1] "model.mlp.1.bias" =  {-0.090658}, float[1,2] "model.mlp.1.weight" =  {-0.100761,0.248413}, float[1,3] view, float[3,2] t, float[1,2] addmm, float[2] view_1, float[1,2] view_2, float[2,1] t_1, float[1,1] addmm_1, float[1] view_3, float scalar_tensor_default>
    {
       [node_Constant_0] val_0 = Constant <value: tensor = int64[2] {1,3}> ()
       [node_Cast_1] val_1 = Cast <to: int = 7> (val_0)
       [node_Reshape_2] view = Reshape <allowzero: int = 0> (input_1, val_1)
       [node_Transpose_3] t = Transpose <perm: ints = [1, 0]> ("model.mlp.0.weight")
       [node_Gemm_4] addmm = Gemm <beta: float = 1, transB: int = 0, alpha: float = 1, transA: int = 0> (view, t, "model.mlp.0.bias")
       [node_Constant_5] val_2 = Constant <value: tensor = int64[1] {2}> ()
       [node_Cast_6] val_3 = Cast <to: int = 7> (val_2)
       [node_Reshape_7] view_1 = Reshape <allowzero: int = 0> (addmm, val_3)
       [node_Constant_8] val_4 = Constant <value: tensor = int64[2] {1,2}> ()
       [node_Cast_9] val_5 = Cast <to: int = 7> (val_4)
       [node_Reshape_10] view_2 = Reshape <allowzero: int = 0> (view_1, val_5)
       [node_Transpose_11] t_1 = Transpose <perm: ints = [1, 0]> ("model.mlp.1.weight")
       [node_Gemm_12] addmm_1 = Gemm <beta: float = 1, transB: int = 0, alpha: float = 1, transA: int = 0> (view_2, t_1, "model.mlp.1.bias")
       [node_Constant_13] val_6 = Constant <value: tensor = int64[1] {1}> ()
       [node_Cast_14] val_7 = Cast <to: int = 7> (val_6)
       [node_Reshape_15] view_3 = Reshape <allowzero: int = 0> (addmm_1, val_7)
       [node_Constant_16] val_8 = Constant <value: tensor = int64 {2}> ()
       [node_Cast_17] scalar_tensor_default = Cast <to: int = 1> (val_8)
       [node_Mul_18] mul = Mul (view_3, scalar_tensor_default)
    }
    <
      domain: "pkg.onnxscript.torch_lib.common",
      opset_import: ["" : 18]
    >
    Rank (input) => (return_val)
    {
       [n0] tmp = Shape (input)
       [n1] return_val = Size (tmp)
    }
    <
      domain: "pkg.onnxscript.torch_lib.common",
      opset_import: ["" : 18]
    >
    IsScalar (input) => (return_val)
    {
       [n0] tmp = Shape (input)
       [n1] tmp_0 = Size (tmp)
       [n2] tmp_1 = Constant <value_int: int = 0> ()
       [n3] return_val = Equal (tmp_0, tmp_1)
    }




.. GENERATED FROM PYTHON SOURCE LINES 67-71

Suggested Patch
+++++++++++++++

Let's avoid the graph break by replacing the forward.

.. GENERATED FROM PYTHON SOURCE LINES 71-89

.. code-block:: Python



    def new_forward(x):
        def identity2(x):
            return x * 2

        def neg(x):
            return -x

        return torch.cond(x.sum() > 0, identity2, neg, (x,))


    print("the list of submodules")
    for name, mod in model.named_modules():
        print(name, type(mod))
        if isinstance(mod, ModuleWithControlFlow):
            mod.forward = new_forward





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    the list of submodules
     <class '__main__.ModelWithControlFlow'>
    mlp <class 'torch.nn.modules.container.Sequential'>
    mlp.0 <class 'torch.nn.modules.linear.Linear'>
    mlp.1 <class 'torch.nn.modules.linear.Linear'>
    mlp.2 <class '__main__.ModuleWithControlFlow'>




.. GENERATED FROM PYTHON SOURCE LINES 90-91

Let's export again.

.. GENERATED FROM PYTHON SOURCE LINES 91-96

.. code-block:: Python


    ep = torch.onnx.export(model, (x,), dynamo=True)
    print(to_text(ep.model_proto))






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [torch.onnx] Obtain model graph for `ModelWithControlFlow([...]` with `torch.export.export`...
    [torch.onnx] Obtain model graph for `ModelWithControlFlow([...]` with `torch.export.export`... ✅
    [torch.onnx] Translate the graph into ONNX...
    [torch.onnx] Obtain model graph for `<lambda>()` with `torch.export.export`...
    [torch.onnx] Obtain model graph for `<lambda>()` with `torch.export.export`... ✅
    [torch.onnx] Translate the graph into ONNX...
    [torch.onnx] Translate the graph into ONNX... ✅
    [torch.onnx] Obtain model graph for `<lambda>()` with `torch.export.export`...
    [torch.onnx] Obtain model graph for `<lambda>()` with `torch.export.export`... ✅
    [torch.onnx] Translate the graph into ONNX...
    [torch.onnx] Translate the graph into ONNX... ✅
    [torch.onnx] Translate the graph into ONNX... ✅
    <
       ir_version: 9,
       opset_import: ["" : 18, "pkg.onnxscript.torch_lib" : 1, "local_onnx_dynamo_function" : 1, "pkg.onnxscript.torch_lib.common" : 1],
       producer_name: "pytorch",
       producer_version: "2.6.0.dev20241027+cu121"
    >
    main_graph (float[3] x) => (float[1] getitem) 
       <float[2,3] "mlp.0.weight" =  {0.144064,-0.451293,0.00360129,0.261578,0.317026,-0.442908}, float[2] "mlp.0.bias" =  {0.181673,0.33226}, float[1,2] "mlp.1.weight" =  {-0.100761,0.248413}, float[1] "mlp.1.bias" =  {-0.090658}, float[1,3] view, float[3,2] t, float[1,2] addmm, float[2] view_1, float[1,2] view_2, float[2,1] t_1, float[1,1] addmm_1, float[1] view_3, float sum_1, float scalar_tensor_default, bool gt, float[1] "local_onnx_dynamo_function::true_graph_0/view_3", float "local_onnx_dynamo_function::true_graph_0/scalar_tensor_default", float[1] "local_onnx_dynamo_function::true_graph_0/mul", float[1] "local_onnx_dynamo_function::false_graph_0/view_3", float[1] "local_onnx_dynamo_function::false_graph_0/neg">
    {
       [node_Constant_0] val_0 = Constant <value: tensor = int64[2] {1,3}> ()
       [node_Cast_1] val_1 = Cast <to: int = 7> (val_0)
       [node_Reshape_2] view = Reshape <allowzero: int = 0> (x, val_1)
       [node_Transpose_3] t = Transpose <perm: ints = [1, 0]> ("mlp.0.weight")
       [node_Gemm_4] addmm = Gemm <beta: float = 1, transB: int = 0, alpha: float = 1, transA: int = 0> (view, t, "mlp.0.bias")
       [node_Constant_5] val_2 = Constant <value: tensor = int64[1] {2}> ()
       [node_Cast_6] val_3 = Cast <to: int = 7> (val_2)
       [node_Reshape_7] view_1 = Reshape <allowzero: int = 0> (addmm, val_3)
       [node_Constant_8] val_4 = Constant <value: tensor = int64[2] {1,2}> ()
       [node_Cast_9] val_5 = Cast <to: int = 7> (val_4)
       [node_Reshape_10] view_2 = Reshape <allowzero: int = 0> (view_1, val_5)
       [node_Transpose_11] t_1 = Transpose <perm: ints = [1, 0]> ("mlp.1.weight")
       [node_Gemm_12] addmm_1 = Gemm <beta: float = 1, transB: int = 0, alpha: float = 1, transA: int = 0> (view_2, t_1, "mlp.1.bias")
       [node_Constant_13] val_6 = Constant <value: tensor = int64[1] {1}> ()
       [node_Cast_14] val_7 = Cast <to: int = 7> (val_6)
       [node_Reshape_15] view_3 = Reshape <allowzero: int = 0> (addmm_1, val_7)
       [node__aten_sum_dim_none_16] sum_1 = pkg.onnxscript.torch_lib._aten_sum_dim_none <keepdim: int = 0> (view_3)
       [node_Constant_17] val_8 = Constant <value: tensor = int64 {0}> ()
       [node_Cast_18] scalar_tensor_default = Cast <to: int = 1> (val_8)
       [node_aten_gt_19] gt = pkg.onnxscript.torch_lib.aten_gt (sum_1, scalar_tensor_default)
       [node_If_20] getitem = If (gt) <then_branch: graph = then_graph () => ( cond) {
          [node_true_graph_0_0] cond = local_onnx_dynamo_function.true_graph_0 (view_3)
       }, else_branch: graph = else_graph () => ( cond) {
          [node_false_graph_0_0] cond = local_onnx_dynamo_function.false_graph_0 (view_3)
       }>
    }
    <
      domain: "pkg.onnxscript.torch_lib",
      opset_import: ["pkg.onnxscript.torch_lib.common" : 1,"" : 18]
    >
    _aten_sum_dim_none (self) => (result_5)
    {
       [n0] self_is_scalar = pkg.onnxscript.torch_lib.common.IsScalar (self)
       [n1] self_2 = If (self_is_scalar) <then_branch: graph = thenGraph_4 () => ( self_0) {
          [n0] tmp = Constant <value_ints: ints = [-1]> ()
          [n1] self_0 = Reshape (self, tmp)
       }, else_branch: graph = elseGraph_4 () => ( self_1) {
          [n0] self_1 = Identity (self)
       }>
       [n2] result = ReduceSum <keepdims: int = @keepdim> (self_2)
       [n3] result_5 = If (self_is_scalar) <then_branch: graph = thenGraph_9 () => ( result_3) {
          [n0] result_3 = Squeeze (result)
       }, else_branch: graph = elseGraph_9 () => ( result_4) {
          [n0] result_4 = Identity (result)
       }>
    }
    <
      domain: "pkg.onnxscript.torch_lib",
      opset_import: ["" : 18]
    >
    aten_gt (self, other) => (return_val)
    {
       [n0] return_val = Greater (self, other)
    }
    <
      domain: "local_onnx_dynamo_function",
      opset_import: ["" : 18,"pkg.onnxscript.torch_lib.common" : 1]
    >
    true_graph_0 (view_3) => (mul)
    {
       [node_Constant_0] val_0 = Constant <value: tensor = int64 {2}> ()
       [node_Cast_1] scalar_tensor_default = Cast <to: int = 1> (val_0)
       [node_Mul_2] mul = Mul (view_3, scalar_tensor_default)
    }
    <
      domain: "local_onnx_dynamo_function",
      opset_import: ["" : 18,"pkg.onnxscript.torch_lib" : 1,"pkg.onnxscript.torch_lib.common" : 1]
    >
    false_graph_0 (view_3) => (neg)
    {
       [node_aten_neg_0] neg = pkg.onnxscript.torch_lib.aten_neg (view_3)
    }
    <
      domain: "pkg.onnxscript.torch_lib.common",
      opset_import: ["" : 18]
    >
    Rank (input) => (return_val)
    {
       [n0] tmp = Shape (input)
       [n1] return_val = Size (tmp)
    }
    <
      domain: "pkg.onnxscript.torch_lib.common",
      opset_import: ["" : 18]
    >
    IsScalar (input) => (return_val)
    {
       [n0] tmp = Shape (input)
       [n1] tmp_0 = Size (tmp)
       [n2] tmp_1 = Constant <value_int: int = 0> ()
       [n3] return_val = Equal (tmp_0, tmp_1)
    }




.. GENERATED FROM PYTHON SOURCE LINES 97-98

Let's optimize to see a small model.

.. GENERATED FROM PYTHON SOURCE LINES 98-102

.. code-block:: Python


    ep = torch.onnx.export(model, (x,), dynamo=True)
    ep.optimize()
    print(to_text(ep.model_proto))




.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [torch.onnx] Obtain model graph for `ModelWithControlFlow([...]` with `torch.export.export`...
    [torch.onnx] Obtain model graph for `ModelWithControlFlow([...]` with `torch.export.export`... ✅
    [torch.onnx] Translate the graph into ONNX...
    [torch.onnx] Obtain model graph for `<lambda>()` with `torch.export.export`...
    [torch.onnx] Obtain model graph for `<lambda>()` with `torch.export.export`... ✅
    [torch.onnx] Translate the graph into ONNX...
    [torch.onnx] Translate the graph into ONNX... ✅
    [torch.onnx] Obtain model graph for `<lambda>()` with `torch.export.export`...
    [torch.onnx] Obtain model graph for `<lambda>()` with `torch.export.export`... ✅
    [torch.onnx] Translate the graph into ONNX...
    [torch.onnx] Translate the graph into ONNX... ✅
    [torch.onnx] Translate the graph into ONNX... ✅
    Applied 2 of general pattern rewrite rules.
    <
       ir_version: 9,
       opset_import: ["" : 18, "pkg.onnxscript.torch_lib" : 1, "local_onnx_dynamo_function" : 1, "pkg.onnxscript.torch_lib.common" : 1],
       producer_name: "pytorch",
       producer_version: "2.6.0.dev20241027+cu121"
    >
    main_graph (float[3] x) => (float[1] getitem) 
       <float[2] "mlp.0.bias" =  {0.181673,0.33226}, float[1] "mlp.1.bias" =  {-0.090658}, float[3,2] t, float[2] val_9, float[2] view_1, float[2,1] t_1, float[1] val_10, float[1] view_3, float node__aten_sum_dim_none_16_result>
    {
       [node_Constant_22] t = Constant <value: tensor = float[3,2] t {0.144064,0.261578,-0.451293,0.317026,0.00360129,-0.442908}> ()
       [node_MatMul_31] val_9 = MatMul (x, t)
       [node_Add_32] view_1 = Add (val_9, "mlp.0.bias")
       [node_Constant_25] t_1 = Constant <value: tensor = float[2,1] t_1 {-0.100761,0.248413}> ()
       [node_MatMul_33] val_10 = MatMul (view_1, t_1)
       [node_Add_34] view_3 = Add (val_10, "mlp.1.bias")
       [node__aten_sum_dim_none_16_n2] node__aten_sum_dim_none_16_result = ReduceSum <keepdims: int = 0> (view_3)
       [node_If_20] getitem = If (gt) <then_branch: graph = then_graph () => (float[1] cond) 
          <float node_true_graph_0_0_scalar_tensor_default>
    {
          [node_Constant_1] node_true_graph_0_0_scalar_tensor_default = Constant <value: tensor = float node_true_graph_0_0_scalar_tensor_default {2}> ()
          [node_true_graph_0_0_node_Mul_2] cond = Mul (view_3, node_true_graph_0_0_scalar_tensor_default)
       }, else_branch: graph = else_graph () => ( cond) {
          [node_false_graph_0_0_node_aten_neg_0] cond = pkg.onnxscript.torch_lib.aten_neg (view_3)
       }>
    }





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 3.318 seconds)


.. _sphx_glr_download_auto_examples_plot_exporter_recipes_oe_cond.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_exporter_recipes_oe_cond.ipynb <plot_exporter_recipes_oe_cond.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_exporter_recipes_oe_cond.py <plot_exporter_recipes_oe_cond.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_exporter_recipes_oe_cond.zip <plot_exporter_recipes_oe_cond.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
