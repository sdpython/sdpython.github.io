
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_torch_export_101.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_plot_torch_export_101.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_torch_export_101.py:


.. _l-plot-torch-export-101:

101: Some dummy examples with torch.export.export
=================================================

Easy Case
+++++++++

.. GENERATED FROM PYTHON SOURCE LINES 10-27

.. code-block:: Python


    import torch


    class Neuron(torch.nn.Module):
        def __init__(self, n_dims: int = 5, n_targets: int = 3):
            super().__init__()
            self.linear = torch.nn.Linear(n_dims, n_targets)

        def forward(self, x):
            z = self.linear(x)
            return torch.sigmoid(z)


    exported_program = torch.export.export(Neuron(), (torch.randn(1, 5),))
    print(exported_program.graph)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    graph():
        %p_linear_weight : [num_users=1] = placeholder[target=p_linear_weight]
        %p_linear_bias : [num_users=1] = placeholder[target=p_linear_bias]
        %x : [num_users=1] = placeholder[target=x]
        %linear : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%x, %p_linear_weight, %p_linear_bias), kwargs = {})
        %sigmoid : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%linear,), kwargs = {})
        return (sigmoid,)




.. GENERATED FROM PYTHON SOURCE LINES 28-35

With an integer as input
++++++++++++++++++++++++

As `torch.export.export <https://pytorch.org/docs/stable/export.html>`_
documentation, integer do not show up on the graph.
An exporter based on :func:`torch.export.export` cannot consider
the integer as an input.

.. GENERATED FROM PYTHON SOURCE LINES 35-50

.. code-block:: Python



    class NeuronIInt(torch.nn.Module):
        def __init__(self, n_dims: int = 5, n_targets: int = 3):
            super().__init__()
            self.linear = torch.nn.Linear(n_dims, n_targets)

        def forward(self, x: torch.Tensor, i_input: int):
            z = self.linear(x)
            return torch.sigmoid(z)[:, i_input]


    exported_program = torch.export.export(NeuronIInt(), (torch.randn(1, 5), 2))
    print(exported_program.graph)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    graph():
        %p_linear_weight : [num_users=1] = placeholder[target=p_linear_weight]
        %p_linear_bias : [num_users=1] = placeholder[target=p_linear_bias]
        %x : [num_users=1] = placeholder[target=x]
        %i_input : [num_users=0] = placeholder[target=i_input]
        %linear : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%x, %p_linear_weight, %p_linear_bias), kwargs = {})
        %sigmoid : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%linear,), kwargs = {})
        %slice_1 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%sigmoid, 0, 0, 9223372036854775807), kwargs = {})
        %select : [num_users=1] = call_function[target=torch.ops.aten.select.int](args = (%slice_1, 1, 2), kwargs = {})
        return (select,)




.. GENERATED FROM PYTHON SOURCE LINES 51-55

With an integer as input
++++++++++++++++++++++++

But if the integer is wrapped into a Tensor, it works.

.. GENERATED FROM PYTHON SOURCE LINES 55-73

.. code-block:: Python



    class NeuronIInt(torch.nn.Module):
        def __init__(self, n_dims: int = 5, n_targets: int = 3):
            super().__init__()
            self.linear = torch.nn.Linear(n_dims, n_targets)

        def forward(self, x: torch.Tensor, i_input):
            z = self.linear(x)
            return torch.sigmoid(z)[:, i_input]


    exported_program = torch.export.export(
        NeuronIInt(), (torch.randn(1, 5), torch.Tensor([2]).to(torch.int32))
    )
    print(exported_program.graph)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    graph():
        %p_linear_weight : [num_users=1] = placeholder[target=p_linear_weight]
        %p_linear_bias : [num_users=1] = placeholder[target=p_linear_bias]
        %x : [num_users=1] = placeholder[target=x]
        %i_input : [num_users=1] = placeholder[target=i_input]
        %linear : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%x, %p_linear_weight, %p_linear_bias), kwargs = {})
        %sigmoid : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%linear,), kwargs = {})
        %slice_1 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%sigmoid, 0, 0, 9223372036854775807), kwargs = {})
        %index : [num_users=1] = call_function[target=torch.ops.aten.index.Tensor](args = (%slice_1, [None, %i_input]), kwargs = {})
        return (index,)




.. GENERATED FROM PYTHON SOURCE LINES 74-78

Wrapped
+++++++

Wrapped, it continues to work.

.. GENERATED FROM PYTHON SOURCE LINES 78-95

.. code-block:: Python



    class WrappedNeuronIInt(torch.nn.Module):
        def __init__(self, model):
            super().__init__()
            self.model = model

        def forward(self, *args, **kwargs):
            return self.model.forward(*args, **kwargs)


    exported_program = torch.export.export(
        WrappedNeuronIInt(NeuronIInt()), (torch.randn(1, 5), torch.Tensor([2]).to(torch.int32))
    )
    print(exported_program.graph)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    graph():
        %p_model_linear_weight : [num_users=1] = placeholder[target=p_model_linear_weight]
        %p_model_linear_bias : [num_users=1] = placeholder[target=p_model_linear_bias]
        %args_0 : [num_users=1] = placeholder[target=args_0]
        %args_1 : [num_users=1] = placeholder[target=args_1]
        %linear : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%args_0, %p_model_linear_weight, %p_model_linear_bias), kwargs = {})
        %sigmoid : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%linear,), kwargs = {})
        %slice_1 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%sigmoid, 0, 0, 9223372036854775807), kwargs = {})
        %index : [num_users=1] = call_function[target=torch.ops.aten.index.Tensor](args = (%slice_1, [None, %args_1]), kwargs = {})
        return (index,)




.. GENERATED FROM PYTHON SOURCE LINES 96-101

List
++++

The last one does not export. An exporter based on
:func:`torch.export.export` cannot work.

.. GENERATED FROM PYTHON SOURCE LINES 101-128

.. code-block:: Python



    class NeuronNoneListInt(torch.nn.Module):
        def __init__(self, n_dims: int = 5, n_targets: int = 3):
            super().__init__()
            self.linear = torch.nn.Linear(n_dims, n_targets)

        def forward(self, x, yz, i_input):
            z = self.linear(x + yz[0] * yz[3])
            return torch.sigmoid(z)[:i_input]


    try:
        exported_program = torch.export.export(
            NeuronNoneListInt(),
            (
                torch.randn(1, 5),
                [torch.randn(1, 5), None, None, torch.randn(1, 5)],
                torch.Tensor([2]).to(torch.int32),
            ),
        )
        print(exported_program.graph)
    except torch._dynamo.exc.Unsupported as e:
        print("-- an error occured:")
        print(e)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    -- an error occured:
    Dynamic slicing on data-dependent value is not supported

    from user code:
       File "/home/xadupre/github/experimental-experiment/_doc/examples/plot_torch_export_101.py", line 110, in forward
        return torch.sigmoid(z)[:i_input]

    Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information





.. GENERATED FROM PYTHON SOURCE LINES 129-133

Loops
+++++

Loops are not captured.

.. GENERATED FROM PYTHON SOURCE LINES 133-155

.. code-block:: Python



    class NeuronLoop(torch.nn.Module):
        def __init__(self, n_dims: int = 5, n_targets: int = 3):
            super().__init__()
            self.linear = torch.nn.Linear(n_dims, n_targets)

        def forward(self, x, xs):
            z = self.linear(x)
            for i in range(len(xs)):
                x += xs[i] * (i + 1)
            return z


    exported_program = torch.export.export(
        NeuronLoop(),
        (
            torch.randn(1, 5),
            [torch.randn(1, 5), torch.randn(1, 5)],
        ),
    )
    print(exported_program.graph)




.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    graph():
        %p_linear_weight : [num_users=1] = placeholder[target=p_linear_weight]
        %p_linear_bias : [num_users=1] = placeholder[target=p_linear_bias]
        %x : [num_users=2] = placeholder[target=x]
        %xs_0 : [num_users=1] = placeholder[target=xs_0]
        %xs_1 : [num_users=1] = placeholder[target=xs_1]
        %linear : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%x, %p_linear_weight, %p_linear_bias), kwargs = {})
        %mul : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%xs_0, 1), kwargs = {})
        %add : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%x, %mul), kwargs = {})
        %mul_1 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%xs_1, 2), kwargs = {})
        %add_1 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add, %mul_1), kwargs = {})
        return (add_1, linear)





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 7.917 seconds)


.. _sphx_glr_download_auto_examples_plot_torch_export_101.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_torch_export_101.ipynb <plot_torch_export_101.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_torch_export_101.py <plot_torch_export_101.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_torch_export_101.zip <plot_torch_export_101.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
