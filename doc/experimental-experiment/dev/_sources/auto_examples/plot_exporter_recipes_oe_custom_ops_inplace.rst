
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_exporter_recipes_oe_custom_ops_inplace.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_plot_exporter_recipes_oe_custom_ops_inplace.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_exporter_recipes_oe_custom_ops_inplace.py:


.. _l-plot-exporter-recipes-onnx-exporter-custom-ops-inplace:

torch.onnx.export and a custom operator inplace
===============================================

This example shows how to convert a custom operator as defined
in the tutorial `Python Custom Operators
<https://pytorch.org/tutorials/advanced/python_custom_ops.html#python-custom-ops-tutorial>`_.

Inplace modification are not supported by onnx.

A model with a custom ops
+++++++++++++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 16-23

.. code-block:: Python


    import numpy as np
    from onnx.printer import to_text
    import onnxscript
    import torch









.. GENERATED FROM PYTHON SOURCE LINES 24-25

We define a model with a custom operator.

.. GENERATED FROM PYTHON SOURCE LINES 25-45

.. code-block:: Python



    @torch.library.custom_op("mylib::numpy_sin", mutates_args={"output"}, device_types="cpu")
    def numpy_sin(x: torch.Tensor, output: torch.Tensor) -> None:
        assert x.device == output.device
        assert x.device.type == "cpu"
        x_np = x.numpy()
        output_np = output.numpy()
        np.sin(x_np, out=output_np)


    class ModuleWithACustomOperator(torch.nn.Module):
        def forward(self, x):
            out = torch.zeros(x.shape)
            numpy_sin(x, out)
            return out


    model = ModuleWithACustomOperator()








.. GENERATED FROM PYTHON SOURCE LINES 46-47

Let's check it runs.

.. GENERATED FROM PYTHON SOURCE LINES 47-50

.. code-block:: Python

    x = torch.randn(1, 3)
    model(x)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    tensor([[-0.9488, -0.7051,  0.8754]])



.. GENERATED FROM PYTHON SOURCE LINES 51-52

As expected, it does not export.

.. GENERATED FROM PYTHON SOURCE LINES 52-58

.. code-block:: Python

    try:
        torch.export.export(model, (x,))
        raise AssertionError("This export should failed unless pytorch now supports this model.")
    except Exception as e:
        print(e)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    This export should failed unless pytorch now supports this model.




.. GENERATED FROM PYTHON SOURCE LINES 59-60

The exporter fails with the same eror as it expects torch.export.export to work.

.. GENERATED FROM PYTHON SOURCE LINES 60-67

.. code-block:: Python


    try:
        torch.onnx.export(model, (x,), dynamo=True)
    except Exception as e:
        print(e)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /home/xadupre/github/onnxscript/onnxscript/converter.py:820: FutureWarning: 'onnxscript.values.Op.param_schemas' is deprecated in version 0.1 and will be removed in the future. Please use '.op_signature' instead.
      param_schemas = callee.param_schemas()
    /home/xadupre/github/onnxscript/onnxscript/converter.py:820: FutureWarning: 'onnxscript.values.OnnxFunction.param_schemas' is deprecated in version 0.1 and will be removed in the future. Please use '.op_signature' instead.
      param_schemas = callee.param_schemas()
    [torch.onnx] Obtain model graph for `ModuleWithACustomOperator()` with `torch.export.export`...
    [torch.onnx] Obtain model graph for `ModuleWithACustomOperator()` with `torch.export.export`... ‚úÖ
    [torch.onnx] Translate the graph into ONNX...
    [torch.onnx] Translate the graph into ONNX... ‚ùå
    Failed to convert the exported program to an ONNX model. This is step 2/2 of exporting the model to ONNX. Next steps:
    - If there is a missing ONNX function, implement it and register it to the registry.
    - If there is an internal error during ONNX conversion, debug the error and summit a PR to PyTorch.
    - Save the ExportedProgram as a pt2 file and create an error report with `export(..., report=True)`. Create an issue in the PyTorch GitHub repository against the *onnx* component. Attach the pt2 model and the error report.

    ## Exception summary

    <class 'torch.onnx._internal.exporter._errors.DispatchError'>: No ONNX function found for <torch._higher_order_ops.auto_functionalize.AutoFunctionalized object at 0x7fbe5836b310>. Failure message: No decompositions registered for the real-valued input
    ‚¨ÜÔ∏è
    <class 'torch.onnx._internal.exporter._errors.ConversionError'>: Error when translating node %auto_functionalized : [num_users=1] = call_function[target=torch.ops.higher_order.auto_functionalized](args = (mylib.numpy_sin.default,), kwargs = {x: %x, output: %zeros}). See the stack trace for more information.

    (Refer to the full stack trace above for more information.)




.. GENERATED FROM PYTHON SOURCE LINES 68-75

Registration
++++++++++++

The exporter how to convert the new exporter into ONNX.
This must be defined. The first piece is to tell the exporter
that the shape of the output is the same as x.
input names must be the same.

.. GENERATED FROM PYTHON SOURCE LINES 75-82

.. code-block:: Python



    @numpy_sin.register_fake
    def numpy_sin_shape(x, output):
        pass









.. GENERATED FROM PYTHON SOURCE LINES 83-84

Next is the conversion to onnx.

.. GENERATED FROM PYTHON SOURCE LINES 84-89

.. code-block:: Python

    T = str  # a tensor name


    op = onnxscript.opset18








.. GENERATED FROM PYTHON SOURCE LINES 90-91

Let's convert the custom op into onnx.

.. GENERATED FROM PYTHON SOURCE LINES 91-98

.. code-block:: Python



    @onnxscript.script()
    def numpy_sin_to_onnx(x):
        return op.Sin(x)









.. GENERATED FROM PYTHON SOURCE LINES 99-100

And we convert again.

.. GENERATED FROM PYTHON SOURCE LINES 100-108

.. code-block:: Python


    ep = torch.onnx.export(
        model,
        (x,),
        custom_translation_table={torch.ops.mylib.numpy_sin: numpy_sin_to_onnx},
        dynamo=True,
    )
    print(to_text(ep.model_proto))


.. rst-class:: sphx-glr-script-out

.. code-block:: pytb

    Traceback (most recent call last):
      File "/home/xadupre/github/experimental-experiment/_doc/examples/plot_exporter_recipes_oe_custom_ops_inplace.py", line 101, in <module>
        ep = torch.onnx.export(
      File "/home/xadupre/vv/this/lib/python3.10/site-packages/torch/onnx/__init__.py", line 350, in export
        return _compat.export_compat(
      File "/home/xadupre/vv/this/lib/python3.10/site-packages/torch/onnx/_internal/exporter/_compat.py", line 174, in export_compat
        onnx_program = _core.export(
      File "/home/xadupre/vv/this/lib/python3.10/site-packages/torch/onnx/_internal/exporter/_core.py", line 1255, in export
        raise _errors.ConversionError(
    torch.onnx._internal.exporter._errors.ConversionError: Failed to convert the exported program to an ONNX model. [96mThis is step 2/2[0m of exporting the model to ONNX. Next steps:
    - If there is a missing ONNX function, implement it and register it to the registry.
    - If there is an internal error during ONNX conversion, debug the error and summit a PR to PyTorch.
    - Save the ExportedProgram as a pt2 file and create an error report with `export(..., report=True)`. Create an issue in the PyTorch GitHub repository against the [96m*onnx*[0m component. Attach the pt2 model and the error report.

    ## Exception summary

    <class 'torch.onnx._internal.exporter._errors.DispatchError'>: No ONNX function found for <torch._higher_order_ops.auto_functionalize.AutoFunctionalized object at 0x7fbe5836b310>. Failure message: No decompositions registered for the real-valued input
    ‚¨ÜÔ∏è
    <class 'torch.onnx._internal.exporter._errors.ConversionError'>: Error when translating node %auto_functionalized : [num_users=1] = call_function[target=torch.ops.higher_order.auto_functionalized](args = (mylib.numpy_sin.default,), kwargs = {x: %x, output: %zeros}). See the stack trace for more information.

    (Refer to the full stack trace above for more information.)





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 11.948 seconds)


.. _sphx_glr_download_auto_examples_plot_exporter_recipes_oe_custom_ops_inplace.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_exporter_recipes_oe_custom_ops_inplace.ipynb <plot_exporter_recipes_oe_custom_ops_inplace.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_exporter_recipes_oe_custom_ops_inplace.py <plot_exporter_recipes_oe_custom_ops_inplace.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_exporter_recipes_oe_custom_ops_inplace.zip <plot_exporter_recipes_oe_custom_ops_inplace.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
