{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# 201: Use torch to export a scikit-learn model into ONNX\n\nWhen :epkg:`sklearn-onnx` is missing a converter, :epkg:`torch` can be used\nto write it. We use :class:`sklearn.impute.KNNImputer` as an example.\nThe first step is to rewrite the scikit-learn model with torch functions.\nThe code is then refactored and split into submodules to be able\nto bypass some pieces :func:`torch.export.export` cannot process.\n\n## torch implementation of nan_euclidean_distances\n\nLet's start with a simple case, a pairwise distance.\nSee :func:`sklearn.metrics.nan_euclidean_distances`.\n\n### Module\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import contextlib\nimport io\nimport logging\nimport math\nimport numbers\nimport warnings\nimport numpy as np\nimport onnx\nimport sklearn\nimport torch\nimport onnxruntime\nfrom onnx_diagnostic.helpers import max_diff\nfrom onnx_diagnostic.helpers.onnx_helper import pretty_onnx\nfrom experimental_experiment.reference import ExtendedReferenceEvaluator\nfrom experimental_experiment.skl.helpers import flatnonzero, _get_weights\nfrom experimental_experiment.torch_interpreter import make_undefined_dimension\nfrom onnx_diagnostic.torch_export_patches import torch_export_patches\nfrom experimental_experiment.torch_interpreter.piece_by_piece import (\n    trace_execution_piece_by_piece,\n    CustomOpStrategy,\n)\nfrom experimental_experiment.xbuilder.reverse_graph_builder import to_graph_builder_code\n\n\nclass NanEuclidean(torch.nn.Module):\n    \"\"\"Implements :func:`sklearn.metrics.nan_euclidean_distances`.\"\"\"\n\n    def __init__(self, squared=False, copy=True):\n        super().__init__()\n        self.squared = squared\n        self.copy = copy\n\n    def forward(self, X, Y):\n        X = X.clone()\n        Y = Y.to(X.dtype).clone()\n\n        missing_X = torch.isnan(X)\n        missing_Y = torch.isnan(Y)\n\n        # set missing values to zero\n        X[missing_X] = 0\n        Y[missing_Y] = 0\n\n        # Adjust distances for missing values\n        XX = X * X\n        YY = Y * Y\n\n        distances = -2 * X @ Y.T + XX.sum(1, keepdim=True) + YY.sum(1, keepdim=True).T\n\n        distances -= XX @ missing_Y.to(X.dtype).T\n        distances -= missing_X.to(X.dtype) @ YY.T\n\n        distances = torch.clip(distances, 0, None)\n\n        present_X = 1 - missing_X.to(X.dtype)\n        present_Y = ~missing_Y\n        present_count = present_X @ present_Y.to(X.dtype).T\n        distances[present_count == 0] = torch.nan\n        # avoid divide by zero\n        present_count = torch.maximum(\n            torch.tensor([1], dtype=present_count.dtype), present_count\n        )\n        distances /= present_count\n        distances *= X.shape[1]\n\n        if not self.squared:\n            distances = distances.sqrt()\n\n        return distances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Validation\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def get_xy(sizex=5, sizey=3, col=3, n_nans=None):\n    X = torch.randn((sizex, col))\n    Y = torch.randn((sizey, col))\n    i_nans = 0\n    for i in range(sizex):\n        X[i, i % X.shape[1]] = torch.nan\n        i_nans += 1\n        if n_nans and n_nans >= i_nans:\n            break\n        X[i, (i + 1) % X.shape[1]] = torch.nan\n        i_nans += 1\n        if n_nans and n_nans >= i_nans:\n            break\n    i_nans = 0\n    for i in range(sizey):\n        Y[(i + 1) % sizey, i % Y.shape[1]] = torch.nan\n        i_nans += 1\n        if n_nans and n_nans >= i_nans:\n            break\n        Y[(i + 1) % sizey, (i + 1) % Y.shape[1]] = torch.nan\n        i_nans += 1\n        if n_nans and n_nans >= i_nans:\n            break\n    return X, Y\n\n\nX, Y = get_xy()\nmodel = NanEuclidean()\n\n\nd1 = sklearn.metrics.nan_euclidean_distances(X.numpy(), Y.numpy())\nd2 = model(X, Y)\nprint(f\"discrepancies: {max_diff(d1, d2)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## torch implementation of KNNImputer\n\nSee :class:`sklearn.impute.KNNImputer`.\nThe code is split into several :class:`torch.nn.Module`\nand refactored to avoid control flow.\n\n### Module and sub modules\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def _get_mask(X, value_to_mask):\n    return (\n        torch.isnan(X)\n        if (  # sklearn.utils._missing.is_scalar_nan(value_to_mask)\n            not isinstance(value_to_mask, numbers.Integral)\n            and isinstance(value_to_mask, numbers.Real)\n            and math.isnan(value_to_mask)\n        )\n        else (value_to_mask == X)\n    )\n\n\nclass SubWeightMatrix(torch.nn.Module):\n    def __init__(self, weights):\n        super().__init__()\n        self.weights = weights\n\n    def forward(self, donors_dist):\n        weight_matrix = _get_weights(donors_dist, self.weights)\n        if weight_matrix is not None:\n            weight_matrix = weight_matrix.clone()\n            weight_matrix[torch.isnan(weight_matrix)] = 0.0\n        else:\n            weight_matrix = torch.ones_like(donors_dist)\n            weight_matrix[torch.isnan(donors_dist)] = 0.0\n        return weight_matrix\n\n\nclass SubDonorsIdx(torch.nn.Module):\n    def forward(self, dist_pot_donors, n_neighbors):\n        xn = torch.nan_to_num(dist_pot_donors, nan=1.0e10)\n        tk = torch.topk(xn, n_neighbors, dim=1, largest=False, sorted=True)\n        return tk.indices, tk.values\n\n\nclass MakeNewWeights(torch.nn.Module):\n    def forward(self, donors_mask, donors, weight_matrix):\n        return donors_mask.to(donors.dtype) * weight_matrix.to(donors.dtype)\n\n\nclass CalcImpute(torch.nn.Module):\n    \"\"\"Implements :meth:`sklearn.impute.KNNImputer._calc_impute`.\"\"\"\n\n    def __init__(self, weights):\n        super().__init__()\n        self._weights = SubWeightMatrix(weights)\n        self._donors_idx = SubDonorsIdx()\n        self._make_new_neights = MakeNewWeights()\n\n    def _calc_impute(self, dist_pot_donors, n_neighbors, fit_X_col, mask_fit_X_col):\n        donors_idx, donors_dist = self._donors_idx(dist_pot_donors, n_neighbors)\n        weight_matrix = self._weights(donors_dist)\n        # Retrieve donor values and calculate kNN average\n        donors = fit_X_col.take(donors_idx)\n        donors_mask = torch.tensor([1], dtype=donors_idx.dtype) - (\n            mask_fit_X_col.take(donors_idx)\n        ).to(donors_idx.dtype)\n\n        new_weights = self._make_new_neights(donors_mask, donors, weight_matrix)\n\n        weights_sum = new_weights.sum(axis=1, keepdim=True)\n        div = torch.where(\n            weights_sum == 0, torch.tensor([1], dtype=weights_sum.dtype), weights_sum\n        )\n        res = (donors * new_weights).sum(axis=1, keepdim=True) / div\n        return res.squeeze(dim=1).to(dist_pot_donors.dtype)\n\n    def forward(self, dist_pot_donors, n_neighbors, fit_X_col, mask_fit_X_col):\n        return self._calc_impute(dist_pot_donors, n_neighbors, fit_X_col, mask_fit_X_col)\n\n\nclass ColProcessorAllNan(torch.nn.Module):\n    def __init__(self, col: int):\n        super().__init__()\n        self.col = col\n\n    def forward(\n        self,\n        X,\n        dist_subset,\n        mask_fit_X,\n        _fit_X,\n        receivers_idx,\n        all_nan_receivers_idx,\n        all_nan_dist_mask,\n        dist_chunk,\n        dist_idx_map,\n        potential_donors_idx,\n    ):\n        col = self.col\n        X = X.clone()\n        mask_ = (~mask_fit_X[:, col]).to(_fit_X.dtype)\n        mask_sum = mask_.to(X.dtype).sum()\n\n        col_sum = (_fit_X[mask_ == 1, col]).sum().to(X.dtype)\n        div = torch.where(mask_sum > 0, mask_sum, torch.tensor([1], dtype=mask_sum.dtype))\n        X[all_nan_receivers_idx, col] = col_sum / div\n\n        # receivers with at least one defined distance\n        receivers_idx = receivers_idx[~all_nan_dist_mask]\n        dist_subset = dist_chunk[dist_idx_map[receivers_idx]][:, potential_donors_idx]\n        return X, dist_subset, receivers_idx\n\n\nclass ColProcessorIdentity(torch.nn.Module):\n    def forward(\n        self,\n        X,\n        dist_subset,\n        mask_fit_X,\n        _fit_X,\n        receivers_idx,\n        all_nan_receivers_idx,\n        all_nan_dist_mask,\n        dist_chunk,\n        dist_idx_map,\n        potential_donors_idx,\n    ):\n        # .clone() not efficient but torch.cond does not like simple return\n        return (\n            X.contiguous(),\n            dist_subset.contiguous(),\n            receivers_idx.contiguous(),\n        )\n\n\nclass ColProcessorCond(torch.nn.Module):\n    def __init__(self, col: int):\n        super().__init__()\n        self.col = col\n        self._all_nan = ColProcessorAllNan(col)\n        self._identity = ColProcessorIdentity()\n\n    def forward(\n        self,\n        X,\n        dist_subset,\n        mask_fit_X,\n        _fit_X,\n        receivers_idx,\n        all_nan_receivers_idx,\n        all_nan_dist_mask,\n        dist_chunk,\n        dist_idx_map,\n        potential_donors_idx,\n    ):\n        X, dist_subset, receivers_idx = torch.cond(\n            all_nan_receivers_idx.numel() > 0,\n            self._all_nan,\n            self._identity,\n            [\n                X,\n                dist_subset,\n                mask_fit_X,\n                _fit_X,\n                receivers_idx,\n                all_nan_receivers_idx,\n                all_nan_dist_mask,\n                dist_chunk,\n                dist_idx_map,\n                potential_donors_idx,\n            ],\n        )\n        return X.contiguous(), dist_subset.contiguous(), receivers_idx.contiguous()\n\n\nclass ColProcessor(torch.nn.Module):\n    \"\"\"Processes one column (= one feature).\"\"\"\n\n    def __init__(self, col, n_neighbors, weights):\n        super().__init__()\n        self._calc_impute = CalcImpute(weights)\n        self._col_cond = ColProcessorCond(col)\n        self.col = col\n        self.n_neighbors = n_neighbors\n\n    def process_one_col(\n        self,\n        X,\n        dist_chunk,\n        non_missing_fix_X,\n        mask_fit_X,\n        dist_idx_map,\n        mask,\n        row_missing_idx,\n        _fit_X,\n    ):\n        col = self.col\n        X = X.clone()\n        row_missing_chunk = row_missing_idx\n        col_mask = mask[row_missing_chunk, col]\n\n        potential_donors_idx = torch.nonzero(non_missing_fix_X[:, col], as_tuple=True)[0]\n\n        # receivers_idx are indices in X\n        receivers_idx = row_missing_chunk[flatnonzero(col_mask)]\n\n        # distances for samples that needed imputation for column\n        dist_subset = dist_chunk[dist_idx_map[receivers_idx]][:, potential_donors_idx]\n\n        # receivers with all nan distances impute with mean\n        all_nan_dist_mask = torch.isnan(dist_subset).all(axis=1)\n        all_nan_receivers_idx = receivers_idx[all_nan_dist_mask]\n\n        # when all_nan_receivers_idx is not empty (training set is small)\n        # ... if all_nan_receivers_idx.size > 0:\n        #    # onnxruntime does not like this part when it is empty\n        #    mask_ = (~mask_fit_X[:, col]).to(_fit_X.dtype)\n        #    mask_sum = mask_.to(X.dtype).sum()\n        #\n        #    col_sum = (_fit_X[mask_ == 1, col]).sum().to(X.dtype)\n        #    div = torch.where(mask_sum > 0, mask_sum, torch.tensor([1], dtype=mask_sum.dtype))\n        #    X[all_nan_receivers_idx, col] = col_sum / div\n        #\n        #     # receivers with at least one defined distance\n        #     receivers_idx = receivers_idx[~all_nan_dist_mask]\n        #     dist_subset = dist_chunk[dist_idx_map[receivers_idx]][:, potential_donors_idx]\n        # else\n        #     ... identity\n        X, dist_subset, receivers_idx = self._col_cond(\n            X,\n            dist_subset,\n            mask_fit_X,\n            _fit_X,\n            receivers_idx,\n            all_nan_receivers_idx,\n            all_nan_dist_mask,\n            dist_chunk,\n            dist_idx_map,\n            potential_donors_idx,\n        )\n\n        # when all_nan_receivers_idx is not empty (training set is big)\n        tn = torch.tensor(self.n_neighbors)\n        n_neighbors = torch.where(\n            tn < potential_donors_idx.shape[0], tn, potential_donors_idx.shape[0]\n        )\n        # to make sure n_neighbors > 0\n        n_neighbors = torch.where(\n            n_neighbors <= 0, torch.tensor([1], dtype=n_neighbors.dtype), n_neighbors\n        )\n        value = self._calc_impute(\n            dist_subset,\n            n_neighbors,\n            _fit_X[potential_donors_idx, col],\n            mask_fit_X[potential_donors_idx, col],\n        )\n        X[receivers_idx, col] = value.to(X.dtype)\n        return X\n\n    def forward(\n        self,\n        X,\n        dist_chunk,\n        non_missing_fix_X,\n        mask_fit_X,\n        dist_idx_map,\n        mask,\n        row_missing_idx,\n        _fit_X,\n    ):\n        return self.process_one_col(\n            X,\n            dist_chunk,\n            non_missing_fix_X,\n            mask_fit_X,\n            dist_idx_map,\n            mask,\n            row_missing_idx,\n            _fit_X,\n        )\n\n\nclass MakeDictIdxMap(torch.nn.Module):\n    def forward(self, X, row_missing_idx):\n        dist_idx_map = torch.zeros(X.shape[0], dtype=int)\n        dist_idx_map[row_missing_idx] = torch.arange(row_missing_idx.shape[0])\n        return dist_idx_map\n\n\nclass TorchKNNImputer(torch.nn.Module):\n    def __init__(self, knn_imputer):\n        super().__init__()\n        assert (\n            knn_imputer.metric == \"nan_euclidean\"\n        ), f\"Not implemented for metric={knn_imputer.metric!r}\"\n        self.dist = NanEuclidean()\n        cols = []\n        for col in range(knn_imputer._fit_X.shape[1]):\n            cols.append(ColProcessor(col, knn_imputer.n_neighbors, knn_imputer.weights))\n        self.columns = torch.nn.ModuleList(cols)\n        # refactoring\n        self._make_dict_idx_map = MakeDictIdxMap()\n        # knn imputer\n        self.missing_values = knn_imputer.missing_values\n        self.n_neighbors = knn_imputer.n_neighbors\n        self.weights = knn_imputer.weights\n        self.metric = knn_imputer.metric\n        self.keep_empty_features = knn_imputer.keep_empty_features\n        self.add_indicator = knn_imputer.add_indicator\n        # results of fitting\n        self.indicator_ = knn_imputer.indicator_\n        # The training results.\n        # self._fit_X = torch.from_numpy(knn_imputer._fit_X.astype(np.float32))\n        # self._mask_fit_X = torch.from_numpy(knn_imputer._mask_fit_X)\n        # self._valid_mask = torch.from_numpy(knn_imputer._valid_mask)\n\n    def _transform_indicator(self, X):\n        if self.add_indicator:\n            if not hasattr(self, \"indicator_\"):\n                raise ValueError(\n                    \"Make sure to call _fit_indicator before _transform_indicator\"\n                )\n            raise NotImplementedError(type(self.indicator_))\n            # return self.indicator_.transform(X)\n        return None\n\n    def _concatenate_indicator(self, X_imputed, X_indicator):\n        if not self.add_indicator:\n            return X_imputed\n        if X_indicator is None:\n            raise ValueError(\n                \"Data from the missing indicator are not provided. Call \"\n                \"_fit_indicator and _transform_indicator in the imputer \"\n                \"implementation.\"\n            )\n        return torch.cat([X_imputed, X_indicator], dim=0)\n\n    def transform(self, mask_fit_X, _valid_mask, _fit_X, X):\n        X = X.clone()\n        mask = _get_mask(X, self.missing_values)\n\n        X_indicator = self._transform_indicator(mask)\n\n        row_missing_idx = flatnonzero(mask[:, _valid_mask].any(axis=1))\n        non_missing_fix_X = torch.logical_not(mask_fit_X)\n\n        # Maps from indices from X to indices in dist matrix\n        dist_idx_map = self._make_dict_idx_map(X, row_missing_idx)\n\n        # process in fixed-memory chunks\n        pairwise_distances = self.dist(X[row_missing_idx, :], _fit_X)\n\n        # The export unfold the loop as it depends on the number of features.\n        # Fixed in this case.\n        for col_processor in self.columns:\n            X = col_processor(\n                X,\n                pairwise_distances,\n                non_missing_fix_X,\n                mask_fit_X,\n                dist_idx_map,\n                mask,\n                row_missing_idx,\n                _fit_X,\n            )\n\n        if self.keep_empty_features:\n            Xc = X.clone()\n            Xc[:, ~_valid_mask] = 0\n        else:\n            Xc = X[:, _valid_mask]\n\n        return self._concatenate_indicator(Xc, X_indicator)\n\n    def forward(self, _mask_fit_X, _valid_mask, _fit_X, X):\n        return self.transform(_mask_fit_X, _valid_mask, _fit_X, X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Validation\n\nWe need to do that with different sizes of training set.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def validate(size, sizey, col=3, n_nans=None):\n    X, Y = get_xy(size, sizey, col, n_nans)\n    knn_imputer = sklearn.impute.KNNImputer(n_neighbors=3)\n    knn_imputer.fit(X)\n\n    model = TorchKNNImputer(knn_imputer)\n\n    p1 = knn_imputer.transform(Y)\n    p2 = model.transform(\n        torch.from_numpy(knn_imputer._mask_fit_X),\n        torch.from_numpy(knn_imputer._valid_mask),\n        torch.from_numpy(knn_imputer._fit_X.astype(np.float32)),\n        Y,\n    )\n    d = max_diff(p1, p2)\n    assert d[\"abs\"] < 1e-5, f\"Discrepancies for size={size} and sizey={sizey}, d={d}\"\n    print(f\"knn discrepancies for size={size}: {d}\")\n\n    p1 = knn_imputer.transform(Y[1:2])\n    p2 = model.transform(\n        torch.from_numpy(knn_imputer._mask_fit_X),\n        torch.from_numpy(knn_imputer._valid_mask),\n        torch.from_numpy(knn_imputer._fit_X.astype(np.float32)),\n        Y[1:2],\n    )\n    d = max_diff(p1, p2)\n    assert d[\"abs\"] < 1e-5, f\"Discrepancies for size={size} and sizey={sizey}, d={d}\"\n    print(f\"knn discrepancies for size={size}: {d}\")\n    return knn_imputer, Y\n\n\nknn5, Y10 = validate(5, 10)\nknn50, Y40 = validate(50, 40)\nknn1, Y1 = validate(10, 10, n_nans=1)\nknn11, Y11 = validate(11, 11, n_nans=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export to ONNX\n\nThe module cannot be exported as is because one operator :func:`torch.topk`\nexpects a fixed number of neighbour but the model makes it variable.\nThis is case not supported by :func:`torch.export.export`.\nWe need to isolate that part before exporting the model.\nIt is done by replacing it with a custom op.\nThis is automatically done by function :func:`trace_execution_piece_by_piece`.\n\nFirst step, we create two sets of inputs. A function will use this\nto infer the dynamic shapes.\n\n### First step: tracing intermediate outputs\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "used = [(knn50, Y40), (knn5, Y10), (knn1, Y1), (knn11, Y11)]\ninputs = [\n    (\n        (\n            torch.from_numpy(knn._mask_fit_X),\n            torch.from_numpy(knn._valid_mask),\n            torch.from_numpy(knn._fit_X.astype(np.float32)),\n            y,\n        ),\n        {},\n    )\n    for knn, y in used\n]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we trace the execution to capture every input and output of every submodule.\nThe model implementation was refactored to introduce many tiny one and get\na fine-grained evaluation of the exportability.\nWe track messages such as ``-needs-more-inputs`` or ``-no-input``.\nIf any, we must provide the tracer more input to make sure\nevery submodule receives enough data to guess dynamic shapes and export.\nWhen the model has control flow, we need more data to make sure every\npiece is used.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trace = trace_execution_piece_by_piece(TorchKNNImputer(knn5), inputs, verbose=0)\npretty = trace.get_export_report()\nprint(pretty)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We need more so let's add more.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def rotate(inputs, col=3):\n    if isinstance(inputs, torch.Tensor):\n        if len(inputs.shape) == 2 and inputs.shape[1] == 3:\n            return torch.cat([inputs[:, 1:], inputs[:, :1]], axis=1)\n        if len(inputs.shape) == 1 and inputs.shape[0] == 3:\n            return torch.cat([inputs[1:], inputs[:1]], axis=0)\n        return inputs\n    if isinstance(inputs, tuple):\n        return tuple(rotate(i, col=col) for i in inputs)\n    if isinstance(inputs, list):\n        return [rotate(i, col=col) for i in inputs]\n    if isinstance(inputs, dict):\n        return {k: rotate(v, col=col) for k, v in inputs.items()}\n    raise TypeError(f\"Unexpected type {type(inputs)}\")\n\n\ninputs = [*inputs, *rotate(inputs), *rotate(rotate(inputs))]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's try again.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"---------\")\ntrace = trace_execution_piece_by_piece(TorchKNNImputer(knn5), inputs, verbose=0)\npretty = trace.get_export_report()\nprint(pretty)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The dynamic shapes for the whole model:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"dynamic shapes:\")\nprint(trace.guess_dynamic_shapes())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The method ``try_export`` cannot infer all links between input shapes and output shapes\nfor every submodule. The following function fills this gap.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "shape_functions = {\n    \"NanEuclidean\": {\n        0: lambda *args, **kwargs: torch.empty(\n            (args[0].shape[0], args[1].shape[0]), dtype=args[0].dtype\n        )\n    },\n    \"CalcImpute\": {\n        0: lambda *args, **kwargs: torch.empty((args[0].shape[0],), dtype=args[0].dtype)\n    },\n    \"SubDonorsIdx\": {\n        0: lambda *args, **kwargs: torch.empty(\n            (\n                make_undefined_dimension(111111),  # args[0].shape[0]),\n                make_undefined_dimension(min(args[0].shape[1], knn5.n_neighbors)),\n            ),\n            dtype=args[0].dtype,\n        ),\n        1: lambda *args, **kwargs: torch.empty(\n            (\n                make_undefined_dimension(111111),  # args[0].shape[0]),\n                make_undefined_dimension(min(args[0].shape[1], knn5.n_neighbors)),\n            ),\n            dtype=torch.float32,\n        ),\n    },\n    \"MakeDictIdxMap\": {\n        0: lambda *args, **kwargs: torch.empty((args[0].shape[0],), dtype=args[1].dtype),\n    },\n    \"ColProcessorCond\": {\n        0: lambda *args, **kwargs: torch.empty(args[0], dtype=args[0].dtype),\n        1: lambda *args, **kwargs: torch.empty(\n            make_undefined_dimension(0), args[1].shape[1], dtype=args[0].dtype\n        ),\n        2: lambda *args, **kwargs: torch.empty(\n            (make_undefined_dimension(0),), dtype=args[0].dtype\n        ),\n    },\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we we try to export piece by piece.\nWe capture the standard output to avoid being overwhelmed\nand we use function\n:func:`onnx_diagnostic.torch_export_patches.torch_export_patches`\nto skip some errors with shape checking made by :mod:`torch`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "logging.disable(logging.CRITICAL)\n\nwith contextlib.redirect_stderr(io.StringIO()), torch_export_patches():\n    ep = trace.try_export(\n        exporter=\"fx\",\n        use_dynamic_shapes=True,\n        exporter_kwargs=dict(strict=False),\n        replace_by_custom_op=CustomOpStrategy.LOCAL,\n        verbose=0,\n        shape_functions=shape_functions,\n        quiet=1,\n    )\n\nassert ep.status in (\n    ep.status.OK,\n    ep.status.OK_CHILDC,\n), f\"FAIL: {ep}\\n-- report --\\n{trace.get_export_report()}\"\nprint(trace.get_export_report())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``OK`` means the module is exportable. ``OK_CHILDC`` means the module\ncan be exported after its submodules are replaced by custom ops.\nIt works except for the topk function. ``FAIL`` means\nthe submodule cannot be exported at all but that\nmodule is simple enough and its ONNX conversion can be provided.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Final step\n\nWe first start by running the decompositions on every exported program.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "with warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n\n    for t in trace:\n        if t.exporter_status.exported is None:\n            print(f\"[run_decompositions] {t.dot_name} - skipped\")\n            continue\n        print(f\"[run_decompositions] {t.dot_name}\")\n        t.exporter_status.exported = t.exporter_status.exported.run_decompositions({})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's run the conversion. We also check the conversion into ONNX\nis accurate. It is doable because every intermediate results\nwere previously traced.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "try:\n    onx = trace.to_onnx_local(\n        verbose=1,\n        check_conversion_cls=dict(cls=ExtendedReferenceEvaluator, atol=1e-5, rtol=1e-5),\n        inline=False,\n    )\nexcept Exception as e:\n    print(f\"The example is broken: {e}\")\n    onx = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's save it.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if onx:\n    onnx.save(onx, \"plot_torch_sklearn_201.onnx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also print it.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if onx:\n    print(pretty_onnx(onx))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Validation again\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def validate_onnx(size, sizey, onx, verbose: int = 1, use_ort: bool = False, col: int = 3):\n    X, Y = get_xy(size, sizey, col=col)\n\n    knn_imputer = sklearn.impute.KNNImputer(n_neighbors=3)\n    knn_imputer.fit(X)\n\n    model = TorchKNNImputer(knn_imputer)\n\n    expected = p1 = knn_imputer.transform(Y)\n\n    model_inputs = (\n        torch.from_numpy(knn_imputer._mask_fit_X),\n        torch.from_numpy(knn_imputer._valid_mask),\n        torch.from_numpy(knn_imputer._fit_X.astype(np.float32)),\n        Y,\n    )\n    p2 = model.transform(*model_inputs)\n    d = max_diff(p1, p2)\n    assert d[\"abs\"] < 1e-5, f\"Discrepancies for size={size} and sizey={sizey}, d={d}\"\n    if verbose:\n        print(f\"Torch Discrepancies for size={size} and sizey={sizey}, d={d}\")\n\n    input_names = [i.name for i in onx.graph.input]\n    feeds = feeds0 = dict(zip(input_names, [t.numpy() for t in model_inputs]))\n\n    if verbose:\n        print(\"python: loading the model...\")\n    sess = ExtendedReferenceEvaluator(onx, verbose=0)\n    if verbose:\n        print(\"python: running the model...\")\n    got = sess.run(None, feeds)\n    d = max_diff(p1, got[0])\n    assert d[\"abs\"] < 1e-5, f\"ONNX Discrepancies for size={size} and sizey={sizey}, d={d}\"\n    if verbose:\n        print(f\"ONNX Discrepancies for size={size} and sizey={sizey}, d={d}\")\n\n    if use_ort:\n        if verbose:\n            print(\"onnxruntime: loading the model...\")\n        opts = onnxruntime.SessionOptions()\n        opts.optimized_model_filepath = \"plot_torch_sklearn_201.ort.onnx\"\n        opts.log_severity_level = 0\n        opts.log_verbosity_level = 0\n        sess = onnxruntime.InferenceSession(\n            onx.SerializeToString(), opts, providers=[\"CPUExecutionProvider\"]\n        )\n        if verbose:\n            print(\"onnxruntime: running the model...\")\n        got = sess.run(None, feeds)\n        d = max_diff(p1, got[0])\n        assert d[\"abs\"] < 1e-5, f\"ONNX Discrepancies for size={size} and sizey={sizey}, d={d}\"\n        if verbose:\n            print(f\"ONNX Discrepancies for size={size} and sizey={sizey}, d={d}\")\n\n    model_inputs = (\n        torch.from_numpy(knn_imputer._mask_fit_X),\n        torch.from_numpy(knn_imputer._valid_mask),\n        torch.from_numpy(knn_imputer._fit_X.astype(np.float32)),\n        Y[1:2],\n    )\n    p1 = knn_imputer.transform(Y[1:2])\n    p2 = model.transform(*model_inputs)\n    d = max_diff(p1, p2)\n    assert d[\"abs\"] < 1e-5, f\"Discrepancies for size={size} and sizey={sizey}, d={d}\"\n    feeds = dict(zip(input_names, [t.numpy() for t in model_inputs]))\n    if verbose:\n        print(\"ReferenceEvaluator: running the model...\")\n    got = sess.run(None, feeds)\n    d = max_diff(p1, got[0])\n    assert d[\"abs\"] < 1e-5, f\"ONNX Discrepancies for size={size} and sizey={sizey}, d={d}\"\n    if verbose:\n        print(\"done\")\n    return feeds0, expected"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This does not work yet.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if onx:\n    feeds, expected = validate_onnx(5, 10, onx)\n    validate_onnx(50, 40, onx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ModelProto to python Code\n\nWe finally call function :func:`to_graph_builder_code\n<experimental_experiment.xbuilder.reverse_graph_builder.to_graph_builder_code>`\nto convert the onnx model into pseudo code if that helps moving that code\nto a converter library (:epkg:`sklearn-onnx`).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if onx:\n    code = to_graph_builder_code(onx)\n    addition = (\n        f\"\"\"\n\n    feeds = {feeds!r}\n    expected = {expected!r}\n    ref = ExtendedReferenceEvaluator(model)\n    got = ref.run(None, feeds)\n    print(\"disrepancies:\", max_diff(expected, got[0]))\n    \"\"\".replace(\n            \"nan\", \"np.nan\"\n        )\n        .replace(\"array\", \"np.array\")\n        .replace(\"float32\", \"np.float32\")\n    )\n    code = f\"\"\"\n    from experimental_experiment.reference import ExtendedReferenceEvaluator\n    from experimental_experiment.helpers import max_diff\n    {code}\n    {addition}\n    \"\"\"\n    print(code)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's finally check it produces the same results.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if onx:\n    with open(\"_plot_torch_sklearn_201_knnpy.py\", \"w\") as f:\n        f.write(code)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's run it...\nIt can be run this way.\n\n``subprocess.run([sys.executable, \"_plot_torch_sklearn_201_knnpy.py\"])``\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}