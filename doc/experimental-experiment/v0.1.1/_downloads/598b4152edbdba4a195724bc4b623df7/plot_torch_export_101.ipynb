{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# 101: Some dummy examples with torch.export.export\n\n:func:`torch.export.export` behaviour in various situations.\n\n## Easy Case\n\nA simple model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\n\n\nclass Neuron(torch.nn.Module):\n    def __init__(self, n_dims: int = 5, n_targets: int = 3):\n        super().__init__()\n        self.linear = torch.nn.Linear(n_dims, n_targets)\n\n    def forward(self, x):\n        z = self.linear(x)\n        return torch.sigmoid(z)\n\n\nexported_program = torch.export.export(Neuron(), (torch.randn(1, 5),))\nprint(exported_program.graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### With an integer as input\n\nAs [torch.export.export](https://docs.pytorch.org/docs/stable/export.html)\ndocumentation, integer do not show up on the graph.\nAn exporter based on :func:`torch.export.export` cannot consider\nthe integer as an input.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class NeuronIInt(torch.nn.Module):\n    def __init__(self, n_dims: int = 5, n_targets: int = 3):\n        super().__init__()\n        self.linear = torch.nn.Linear(n_dims, n_targets)\n\n    def forward(self, x: torch.Tensor, i_input: int):\n        z = self.linear(x)\n        return torch.sigmoid(z)[:, i_input]\n\n\nexported_program = torch.export.export(NeuronIInt(), (torch.randn(1, 5), 2))\nprint(exported_program.graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### With an integer as input\n\nBut if the integer is wrapped into a Tensor, it works.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class NeuronIInt(torch.nn.Module):\n    def __init__(self, n_dims: int = 5, n_targets: int = 3):\n        super().__init__()\n        self.linear = torch.nn.Linear(n_dims, n_targets)\n\n    def forward(self, x: torch.Tensor, i_input):\n        z = self.linear(x)\n        return torch.sigmoid(z)[:, i_input]\n\n\nexported_program = torch.export.export(\n    NeuronIInt(), (torch.randn(1, 5), torch.Tensor([2]).to(torch.int32))\n)\nprint(exported_program.graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Wrapped\n\nWrapped, it continues to work.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class WrappedNeuronIInt(torch.nn.Module):\n    def __init__(self, model):\n        super().__init__()\n        self.model = model\n\n    def forward(self, *args, **kwargs):\n        return self.model.forward(*args, **kwargs)\n\n\nexported_program = torch.export.export(\n    WrappedNeuronIInt(NeuronIInt()), (torch.randn(1, 5), torch.Tensor([2]).to(torch.int32))\n)\nprint(exported_program.graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### List\n\nThe last one does not export. An exporter based on\n:func:`torch.export.export` cannot work.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class NeuronNoneListInt(torch.nn.Module):\n    def __init__(self, n_dims: int = 5, n_targets: int = 3):\n        super().__init__()\n        self.linear = torch.nn.Linear(n_dims, n_targets)\n\n    def forward(self, x, yz, i_input):\n        z = self.linear(x + yz[0] * yz[3])\n        return torch.sigmoid(z)[:i_input]\n\n\ntry:\n    exported_program = torch.export.export(\n        NeuronNoneListInt(),\n        (\n            torch.randn(1, 5),\n            [torch.randn(1, 5), None, None, torch.randn(1, 5)],\n            torch.Tensor([2]).to(torch.int32),\n        ),\n    )\n    print(exported_program.graph)\nexcept (torch._dynamo.exc.Unsupported, RuntimeError) as e:\n    print(f\"-- an error {type(e)} occured:\")\n    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loops\n\nLoops are not captured.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class NeuronLoop(torch.nn.Module):\n    def __init__(self, n_dims: int = 5, n_targets: int = 3):\n        super().__init__()\n        self.linear = torch.nn.Linear(n_dims, n_targets)\n\n    def forward(self, x, xs):\n        z = self.linear(x)\n        for i in range(len(xs)):\n            x += xs[i] * (i + 1)\n        return z\n\n\nexported_program = torch.export.export(\n    NeuronLoop(),\n    (\n        torch.randn(1, 5),\n        [torch.randn(1, 5), torch.randn(1, 5)],\n    ),\n)\nprint(exported_program.graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Export for training\n\nIn that case, the weights are exported as inputs.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class Neuron(torch.nn.Module):\n    def __init__(self, n_dims: int = 5, n_targets: int = 3):\n        super().__init__()\n        self.linear = torch.nn.Linear(n_dims, n_targets)\n\n    def forward(self, x):\n        z = self.linear(x)\n        return torch.sigmoid(z)\n\n\nprint(\"-- training\")\nmod = Neuron()\nmod.train()\nexported_program = torch.export.export_for_training(mod, (torch.randn(1, 5),))\nprint(exported_program.graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preserve Modules\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class Neuron(torch.nn.Module):\n    def __init__(self, n_dims: int = 5, n_targets: int = 3):\n        super().__init__()\n        self.linear = torch.nn.Linear(n_dims, n_targets)\n\n    def forward(self, x):\n        z = self.linear(x)\n        return torch.sigmoid(z)\n\n\nclass NeuronNeuron(torch.nn.Module):\n    def __init__(self, n_dims: int = 5, n_targets: int = 3):\n        super().__init__()\n        self.my_neuron = Neuron(n_dims, n_targets)\n\n    def forward(self, x):\n        z = self.my_neuron(x)\n        return -z"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The list of the modules.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mod = NeuronNeuron()\nfor item in mod.named_modules():\n    print(item)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The exported module did not change.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"-- preserved?\")\nexported_program = torch.export.export(\n    mod, (torch.randn(1, 5),), preserve_module_call_signature=(\"my_neuron\",)\n)\nprint(exported_program.graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And now?\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch.export._swap\n\nswapped_gm = torch.export._swap._swap_modules(exported_program, {\"my_neuron\": Neuron()})\n\nprint(\"-- preserved?\")\nprint(swapped_gm.graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Unfortunately this approach does not work well on big models\nand it is a provite API.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}