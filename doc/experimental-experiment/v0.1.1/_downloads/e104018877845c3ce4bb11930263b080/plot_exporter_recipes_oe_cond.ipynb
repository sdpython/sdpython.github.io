{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# torch.onnx.export and a model with a test\n\nTests cannot be exported into ONNX unless they refactored\nto use :func:`torch.cond`.\n\n## A model with a test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from onnx.printer import to_text\nimport torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We define a model with a control flow (-> graph break)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class ForwardWithControlFlowTest(torch.nn.Module):\n    def forward(self, x):\n        if x.sum():\n            return x * 2\n        return -x\n\n\nclass ModelWithControlFlowTest(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.mlp = torch.nn.Sequential(\n            torch.nn.Linear(3, 2),\n            torch.nn.Linear(2, 1),\n            ForwardWithControlFlowTest(),\n        )\n\n    def forward(self, x):\n        out = self.mlp(x)\n        return out\n\n\nmodel = ModelWithControlFlowTest()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's check it runs.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x = torch.randn(3)\nmodel(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As expected, it does not export.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "try:\n    torch.export.export(model, (x,))\n    raise AssertionError(\"This export should failed unless pytorch now supports this model.\")\nexcept Exception as e:\n    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It does export with :func:`torch.onnx.export` because\nit uses JIT to trace the execution.\nBut the model is not exactly the same as the initial model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ep = torch.onnx.export(model, (x,), dynamo=True)\nprint(to_text(ep.model_proto))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Suggested Patch\n\nLet's avoid the graph break by replacing the forward.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def new_forward(x):\n    def identity2(x):\n        return x * 2\n\n    def neg(x):\n        return -x\n\n    return torch.cond(x.sum() > 0, identity2, neg, (x,))\n\n\nprint(\"the list of submodules\")\nfor name, mod in model.named_modules():\n    print(name, type(mod))\n    if isinstance(mod, ForwardWithControlFlowTest):\n        mod.forward = new_forward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's see what the fx graph looks like.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(torch.export.export(model, (x,)).graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's export again.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ep = torch.onnx.export(model, (x,), dynamo=True)\nprint(to_text(ep.model_proto))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's optimize to see a small model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ep = torch.onnx.export(model, (x,), dynamo=True)\nep.optimize()\nprint(to_text(ep.model_proto))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}