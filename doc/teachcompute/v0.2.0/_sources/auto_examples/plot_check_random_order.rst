
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_check_random_order.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_plot_check_random_order.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_check_random_order.py:


Random order for a sum
======================

Parallelization usually means a summation is done with a random order.
That may lead to different values if the computation is made many times
even though the result should be the same. This example compares
summation of random permutation of the same array of values.

Setup
+++++

.. GENERATED FROM PYTHON SOURCE LINES 13-33

.. code-block:: Python


    from tqdm import tqdm
    import numpy as np
    import pandas

    unique_values = np.array(
        [2.1102535724639893, 0.5986238718032837, -0.49545818567276], dtype=np.float32
    )
    random_index = np.random.randint(0, 3, 2000)
    assert set(random_index) == {0, 1, 2}
    values = unique_values[random_index]

    s0 = values.sum()
    s1 = np.array(0, dtype=np.float32)
    for n in values:
        s1 += n

    delta = s1 - s0
    print(f"reduced sum={s0}, iterative sum={s1}, delta={delta}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    reduced sum=1488.9971923828125, iterative sum=1488.9810791015625, delta=-0.01611328125




.. GENERATED FROM PYTHON SOURCE LINES 34-41

There are discrepancies.

Random order
++++++++++++

Let's go further and check the sum of random permutation of the same set.
Let's compare the result with the same sum done with a higher precision (double).

.. GENERATED FROM PYTHON SOURCE LINES 41-78

.. code-block:: Python



    def check_orders(values, n=200, bias=0):
        double_sums = []
        sums = []
        reduced_sums = []
        reduced_dsums = []
        for i in tqdm(range(n)):
            permuted_values = np.random.permutation(values)
            s = np.array(bias, dtype=np.float32)
            sd = np.array(bias, dtype=np.float64)
            for n in permuted_values:
                s += n
                sd += n
            sums.append(s)
            double_sums.append(sd)
            reduced_sums.append(permuted_values.sum() + bias)
            reduced_dsums.append(permuted_values.astype(np.float64).sum() + bias)

        data = []
        mi, ma = min(sums), max(sums)
        data.append(dict(name="seq_fp32", min=mi, max=ma, bias=bias))
        print(f"min={mi} max={ma} delta={ma-mi}")
        mi, ma = min(double_sums), max(double_sums)
        data.append(dict(name="seq_fp64", min=mi, max=ma, bias=bias))
        print(f"min={mi} max={ma} delta={ma-mi} (double)")
        mi, ma = min(reduced_sums), max(reduced_sums)
        data.append(dict(name="red_f32", min=mi, max=ma, bias=bias))
        print(f"min={mi} max={ma} delta={ma-mi} (reduced)")
        mi, ma = min(reduced_dsums), max(reduced_dsums)
        data.append(dict(name="red_f64", min=mi, max=ma, bias=bias))
        print(f"min={mi} max={ma} delta={ma-mi} (reduced)")
        return data


    data1 = check_orders(values)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

      0%|          | 0/200 [00:00<?, ?it/s]     10%|█         | 20/200 [00:00<00:00, 194.10it/s]     20%|██        | 40/200 [00:00<00:00, 186.07it/s]     30%|██▉       | 59/200 [00:00<00:00, 177.45it/s]     39%|███▉      | 78/200 [00:00<00:00, 179.85it/s]     48%|████▊     | 97/200 [00:00<00:00, 182.56it/s]     58%|█████▊    | 117/200 [00:00<00:00, 186.98it/s]     68%|██████▊   | 136/200 [00:00<00:00, 183.86it/s]     78%|███████▊  | 156/200 [00:00<00:00, 186.38it/s]     88%|████████▊ | 176/200 [00:00<00:00, 187.99it/s]     98%|█████████▊| 196/200 [00:01<00:00, 189.86it/s]    100%|██████████| 200/200 [00:01<00:00, 186.19it/s]
    min=1488.9796142578125 max=1488.9837646484375 delta=0.004150390625
    min=1488.9972762465477 max=1488.9972762465477 delta=0.0 (double)
    min=1488.9970703125 max=1488.997314453125 delta=0.000244140625 (reduced)
    min=1488.9972762465477 max=1488.9972762465477 delta=0.0 (reduced)




.. GENERATED FROM PYTHON SOURCE LINES 79-91

This example clearly shows the order has an impact.
It is usually unavoidable but it could reduced if the sum
it close to zero. In that case, the sum would be of the same
order of magnitude of the add values.

Removing the average
++++++++++++++++++++

Computing the average of the values requires to compute the sum.
However if we have an estimator of this average, not necessarily
the exact value, we would help the summation to keep the same order
of magnitude than the values it adds.

.. GENERATED FROM PYTHON SOURCE LINES 91-96

.. code-block:: Python


    mean = unique_values.mean()
    values -= mean
    data2 = check_orders(values, bias=len(values) * mean)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

      0%|          | 0/200 [00:00<?, ?it/s]      8%|▊         | 16/200 [00:00<00:01, 156.40it/s]     16%|█▋        | 33/200 [00:00<00:01, 160.01it/s]     25%|██▌       | 50/200 [00:00<00:00, 161.57it/s]     34%|███▍      | 68/200 [00:00<00:00, 166.75it/s]     43%|████▎     | 86/200 [00:00<00:00, 168.73it/s]     52%|█████▏    | 103/200 [00:00<00:00, 166.96it/s]     60%|██████    | 120/200 [00:00<00:00, 164.98it/s]     69%|██████▉   | 138/200 [00:00<00:00, 169.47it/s]     78%|███████▊  | 157/200 [00:00<00:00, 173.92it/s]     88%|████████▊ | 177/200 [00:01<00:00, 180.58it/s]     98%|█████████▊| 197/200 [00:01<00:00, 183.94it/s]    100%|██████████| 200/200 [00:01<00:00, 173.22it/s]
    min=1488.99658203125 max=1488.99658203125 delta=0.0
    min=1488.9972355365753 max=1488.9972355365753 delta=0.0 (double)
    min=1488.9972372055054 max=1488.9972705841064 delta=3.337860107421875e-05 (reduced)
    min=1488.9972355365753 max=1488.9972355365753 delta=0.0 (reduced)




.. GENERATED FROM PYTHON SOURCE LINES 97-98

The differences are clearly lower.

.. GENERATED FROM PYTHON SOURCE LINES 98-104

.. code-block:: Python


    df = pandas.DataFrame(data1 + data2)
    df["delta"] = df["max"] - df["min"]
    piv = df.pivot(index="name", columns="bias", values="delta")
    print(piv)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    bias     0.000000    1475.612998
    name                            
    red_f32     0.000244    0.000033
    red_f64          0.0         0.0
    seq_fp32     0.00415         0.0
    seq_fp64         0.0         0.0




.. GENERATED FROM PYTHON SOURCE LINES 105-106

Plots.

.. GENERATED FROM PYTHON SOURCE LINES 106-111

.. code-block:: Python


    ax = piv.plot.barh()
    ax.set_title("max(sum) - min(sum) over random orders")
    ax.get_figure().tight_layout()
    ax.get_figure().savefig("plot_check_random_order.png")



.. image-sg:: /auto_examples/images/sphx_glr_plot_check_random_order_001.png
   :alt: max(sum) - min(sum) over random orders
   :srcset: /auto_examples/images/sphx_glr_plot_check_random_order_001.png
   :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 2.374 seconds)


.. _sphx_glr_download_auto_examples_plot_check_random_order.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_check_random_order.ipynb <plot_check_random_order.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_check_random_order.py <plot_check_random_order.py>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
