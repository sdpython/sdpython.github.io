{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Measuring CUDA performance with a vector sum\n\nThe objective is to measure the summation of all elements from a tensor.\n\n::\n\n    nsys profile python _doc/examples/plot_bench_cuda_vector_sum.py\n\n## Vector Add\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\nimport numpy\nimport matplotlib.pyplot as plt\nfrom pandas import DataFrame\nfrom teachcompute.ext_test_case import measure_time, unit_test_going\nimport torch\n\nhas_cuda = torch.cuda.is_available()\n\ntry:\n    from teachcompute.validation.cuda.cuda_example_py import (\n        vector_sum0,\n        vector_sum_atomic,\n        vector_sum6,\n    )\nexcept ImportError:\n    has_cuda = False\n\n\ndef wrap_cuda_call(f, values):\n    torch.cuda.nvtx.range_push(f\"CUDA f={f.__name__} dim={values.size}\")\n    res = f(values)\n    torch.cuda.nvtx.range_pop()\n    return res\n\n\nobs = []\ndims = [2**10, 2**15, 2**20, 2**25, 2**28]\nif unit_test_going():\n    dims = [10, 20, 30]\nfor dim in tqdm(dims):\n    values = numpy.ones((dim,), dtype=numpy.float32).ravel()\n\n    if has_cuda:\n        for f in [vector_sum0, vector_sum_atomic, vector_sum6]:\n            if f == vector_sum_atomic and dim > 2**20:\n                continue\n            diff = numpy.abs(wrap_cuda_call(f, values) - (values.sum()))\n            res = measure_time(lambda: wrap_cuda_call(f, values), max_time=0.5)\n\n            obs.append(\n                dict(\n                    dim=dim,\n                    size=values.size,\n                    time=res[\"average\"],\n                    fct=f\"CUDA-{f.__name__}\",\n                    time_per_element=res[\"average\"] / dim,\n                    diff=diff,\n                )\n            )\n\n    diff = 0\n    res = measure_time(lambda: values.sum(), max_time=0.5)\n\n    obs.append(\n        dict(\n            dim=dim,\n            size=values.size,\n            time=res[\"average\"],\n            fct=\"numpy\",\n            time_per_element=res[\"average\"] / dim,\n            diff=0,\n        )\n    )\n\n\ndf = DataFrame(obs)\npiv = df.pivot(index=\"dim\", columns=\"fct\", values=\"time_per_element\")\nprint(piv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plots\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "piv_diff = df.pivot(index=\"dim\", columns=\"fct\", values=\"diff\")\npiv_time = df.pivot(index=\"dim\", columns=\"fct\", values=\"time\")\n\nfig, ax = plt.subplots(1, 3, figsize=(12, 6))\npiv.plot(ax=ax[0], logx=True, title=\"Comparison between two summation\")\npiv_diff.plot(ax=ax[1], logx=True, logy=True, title=\"Summation errors\")\npiv_time.plot(ax=ax[2], logx=True, logy=True, title=\"Total time\")\nfig.tight_layout()\nfig.savefig(\"plot_bench_cuda_vector_sum.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "CUDA seems very slow but in fact, all the time is spent\nin moving the data from the CPU memory (Host) to the GPU memory (device).\n\n<img src=\"file://../images/nsight_vector_sum.png\">\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}