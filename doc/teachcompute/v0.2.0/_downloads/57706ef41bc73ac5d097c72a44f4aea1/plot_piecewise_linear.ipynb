{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Compares implementations for a Piecewise Linear\n\nA piecewise linear function is implemented and trained\nfollowing the tutorial :epkg:`Custom C++ and CUDA Extensions`.\n\n## Piecewise linear regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import time\nimport pandas\nimport matplotlib.pyplot as plt\nimport torch\nfrom teachcompute.torch_extensions.piecewise_linear import (\n    PiecewiseLinearFunction,\n    PiecewiseLinearFunctionC,\n    PiecewiseLinearFunctionCBetter,\n)\n\n\ndef train_piecewise_linear(x, y, device, cls, max_iter=400, learning_rate=1e-4):\n\n    alpha_pos = torch.tensor([1], dtype=torch.float32).to(device)\n    alpha_neg = torch.tensor([0.5], dtype=torch.float32).to(device)\n    alpha_pos.requires_grad_()\n    alpha_neg.requires_grad_()\n\n    losses = []\n    fct = cls.apply\n\n    for _t in range(max_iter):\n\n        y_pred = fct(x, alpha_neg, alpha_pos)\n        loss = (y_pred - y).pow(2).sum()\n        loss.backward()\n        losses.append(loss)\n\n        with torch.no_grad():\n            alpha_pos -= learning_rate * alpha_pos.grad\n            alpha_neg -= learning_rate * alpha_neg.grad\n\n            # Manually zero the gradients after updating weights\n            alpha_pos.grad.zero_()\n            alpha_neg.grad.zero_()\n\n    return losses, alpha_neg, alpha_pos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Python implementation\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\nprint(\"device:\", device)\nx = torch.randn(100, 1, dtype=torch.float32)\ny = x * 0.2 + (x > 0).to(torch.float32) * x * 1.5 + torch.randn(100, 1) / 5\nx = x.to(device).requires_grad_()\ny = y.to(device).requires_grad_()\n\nbegin = time.perf_counter()\nlosses, alpha_neg, alpha_pos = train_piecewise_linear(\n    x, y, device, PiecewiseLinearFunction\n)\nend = time.perf_counter()\nprint(f\"duration={end - begin}, alpha_neg={alpha_neg} alpha_pos={alpha_pos}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## C++ implementation\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "begin = time.perf_counter()\nlosses, alpha_neg, alpha_pos = train_piecewise_linear(\n    x, y, device, PiecewiseLinearFunctionC\n)\nend = time.perf_counter()\nprint(f\"duration={end - begin}, alpha_neg={alpha_neg} alpha_pos={alpha_pos}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## C++ implementation, second try\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "begin = time.perf_counter()\nlosses, alpha_neg, alpha_pos = train_piecewise_linear(\n    x, y, device, PiecewiseLinearFunctionCBetter\n)\nend = time.perf_counter()\nprint(f\"duration={end - begin}, alpha_neg={alpha_neg} alpha_pos={alpha_pos}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The C++ implementation is very close to the python code.\nThe second implementation in C++ is faster because\nit reuses created tensors.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Graphs\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df = pandas.DataFrame()\ndf[\"x\"] = x.cpu().detach().numpy().ravel()\ndf[\"y\"] = y.cpu().detach().numpy().ravel()\ndf[\"yp\"] = PiecewiseLinearFunction.apply(x, alpha_neg, alpha_pos).cpu().detach().numpy()\n\nfig, ax = plt.subplots(1, 2, figsize=(10, 4))\ndf.plot.scatter(x=\"x\", y=\"y\", label=\"y\", color=\"blue\", ax=ax[0])\ndf.plot.scatter(x=\"x\", y=\"yp\", ax=ax[0], label=\"yp\", color=\"orange\")\nax[1].plot([float(lo.detach()) for lo in losses], label=\"loss\")\nax[1].legend()\n\n\n# plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}