
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_benchmark_dot_mul.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_plot_benchmark_dot_mul.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_benchmark_dot_mul.py:


Compares matrix multiplication implementations
==============================================

:epkg:`numpy` has a very fast implementation of
matrix multiplication. There are many ways to be slower.

Compared implementations:

* :func:`dmul_cython_omp <teachcompute.validation.cython.mul_cython_omp.dmul_cython_omp>`
  `code <https://github.com/sdpython/teachcompute/blob/main/
  teachcompute/validation/cython/mul_cython_omp.pyx#L171>`_

.. GENERATED FROM PYTHON SOURCE LINES 15-30

.. code-block:: Python


    import pprint
    import numpy
    from numpy.testing import assert_almost_equal
    import matplotlib.pyplot as plt
    from pandas import DataFrame, concat
    from teachcompute.validation.cython.mul_cython_omp import dmul_cython_omp
    from teachcompute.ext_test_case import measure_time_dim, unit_test_going

    dfs = []
    if unit_test_going():
        sets = [2, 4, 6]
    else:
        sets = list(range(2, 145, 20))








.. GENERATED FROM PYTHON SOURCE LINES 31-34

numpy mul
+++++++++


.. GENERATED FROM PYTHON SOURCE LINES 34-51

.. code-block:: Python


    ctxs = [
        dict(
            va=numpy.random.randn(n, n).astype(numpy.float64),
            vb=numpy.random.randn(n, n).astype(numpy.float64),
            mul=lambda x, y: x @ y,
            x_name=n,
        )
        for n in sets
    ]

    res = list(measure_time_dim("mul(va, vb)", ctxs, verbose=1))
    dfs.append(DataFrame(res))
    dfs[-1]["fct"] = "numpy"
    pprint.pprint(dfs[-1].tail(n=2))






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

      0%|          | 0/8 [00:00<?, ?it/s]     88%|████████▊ | 7/8 [00:00<00:00, 58.08it/s]    100%|██████████| 8/8 [00:00<00:00, 47.61it/s]
        average     deviation  min_exec  max_exec  repeat  number     ttime  context_size  warmup_time  x_name    fct
    6  0.000097  1.951100e-06  0.000093  0.000099      10      50  0.000967           184     0.000118     122  numpy
    7  0.000094  4.998209e-07  0.000093  0.000094      10      50  0.000935           184     0.000124     142  numpy




.. GENERATED FROM PYTHON SOURCE LINES 52-55

Simple multiplication
+++++++++++++++++++++


.. GENERATED FROM PYTHON SOURCE LINES 55-70

.. code-block:: Python


    ctxs = [
        dict(
            va=numpy.random.randn(n, n).astype(numpy.float64),
            vb=numpy.random.randn(n, n).astype(numpy.float64),
            mul=dmul_cython_omp,
            x_name=n,
        )
        for n in sets
    ]

    res = list(measure_time_dim("mul(va, vb)", ctxs, verbose=1))
    pprint.pprint(res[-1])






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

      0%|          | 0/8 [00:00<?, ?it/s]     50%|█████     | 4/8 [00:00<00:00, 22.28it/s]     88%|████████▊ | 7/8 [00:02<00:00,  2.76it/s]    100%|██████████| 8/8 [00:03<00:00,  2.28it/s]
    {'average': 0.0027063118629157548,
     'context_size': 184,
     'deviation': 0.00017595801149480333,
     'max_exec': 0.0031397583708167075,
     'min_exec': 0.002544899322092533,
     'number': 50,
     'repeat': 10,
     'ttime': 0.027063118629157546,
     'warmup_time': 0.002733813598752022,
     'x_name': 142}




.. GENERATED FROM PYTHON SOURCE LINES 71-77

Other scenarios
+++++++++++++++

3 differents algorithms, each of them parallelized.
See :func:`dmul_cython_omp
<teachcompute.validation.cython.mul_cython_omp.dmul_cython_omp>`.

.. GENERATED FROM PYTHON SOURCE LINES 77-96

.. code-block:: Python


    for algo in range(0, 2):
        for parallel in (0, 1):
            print("algo=%d parallel=%d" % (algo, parallel))
            ctxs = [
                dict(
                    va=numpy.random.randn(n, n).astype(numpy.float64),
                    vb=numpy.random.randn(n, n).astype(numpy.float64),
                    mul=lambda x, y: dmul_cython_omp(x, y, algo=algo, parallel=parallel),
                    x_name=n,
                )
                for n in sets
            ]

            res = list(measure_time_dim("mul(va, vb)", ctxs, verbose=1))
            dfs.append(DataFrame(res))
            dfs[-1]["fct"] = "a=%d-p=%d" % (algo, parallel)
            pprint.pprint(dfs[-1].tail(n=2))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    algo=0 parallel=0
      0%|          | 0/8 [00:00<?, ?it/s]     50%|█████     | 4/8 [00:00<00:00, 33.68it/s]    100%|██████████| 8/8 [00:03<00:00,  2.22it/s]    100%|██████████| 8/8 [00:03<00:00,  2.58it/s]
        average  deviation  min_exec  max_exec  repeat  number     ttime  context_size  warmup_time  x_name      fct
    6  0.001691   0.000090  0.001552  0.001819      10      50  0.016914           184     0.001775     122  a=0-p=0
    7  0.002835   0.000218  0.002550  0.003338      10      50  0.028353           184     0.002695     142  a=0-p=0
    algo=0 parallel=1
      0%|          | 0/8 [00:00<?, ?it/s]     12%|█▎        | 1/8 [00:00<00:02,  2.37it/s]     25%|██▌       | 2/8 [00:01<00:03,  1.60it/s]     38%|███▊      | 3/8 [00:01<00:03,  1.48it/s]     50%|█████     | 4/8 [00:02<00:02,  1.35it/s]     62%|██████▎   | 5/8 [00:03<00:02,  1.42it/s]     75%|███████▌  | 6/8 [00:04<00:01,  1.43it/s]     88%|████████▊ | 7/8 [00:04<00:00,  1.43it/s]    100%|██████████| 8/8 [00:05<00:00,  1.32it/s]    100%|██████████| 8/8 [00:05<00:00,  1.41it/s]
        average  deviation  min_exec  max_exec  repeat  number     ttime  context_size  warmup_time  x_name      fct
    6  0.001386   0.000320  0.000839  0.001796      10      50  0.013860           184     0.000753     122  a=0-p=1
    7  0.001743   0.000253  0.001247  0.002272      10      50  0.017431           184     0.001224     142  a=0-p=1
    algo=1 parallel=0
      0%|          | 0/8 [00:00<?, ?it/s]     50%|█████     | 4/8 [00:00<00:00, 21.97it/s]     88%|████████▊ | 7/8 [00:02<00:00,  2.53it/s]    100%|██████████| 8/8 [00:03<00:00,  1.71it/s]    100%|██████████| 8/8 [00:03<00:00,  2.16it/s]
        average  deviation  min_exec  max_exec  repeat  number     ttime  context_size  warmup_time  x_name      fct
    6  0.002336   0.000044  0.002307  0.002436      10      50  0.023364           184     0.002378     122  a=1-p=0
    7  0.002698   0.000192  0.002541  0.003169      10      50  0.026977           184     0.004061     142  a=1-p=0
    algo=1 parallel=1
      0%|          | 0/8 [00:00<?, ?it/s]     12%|█▎        | 1/8 [00:00<00:04,  1.71it/s]     25%|██▌       | 2/8 [00:01<00:04,  1.48it/s]     38%|███▊      | 3/8 [00:02<00:03,  1.43it/s]     50%|█████     | 4/8 [00:02<00:02,  1.48it/s]     62%|██████▎   | 5/8 [00:03<00:02,  1.43it/s]     75%|███████▌  | 6/8 [00:04<00:01,  1.31it/s]     88%|████████▊ | 7/8 [00:05<00:00,  1.27it/s]    100%|██████████| 8/8 [00:06<00:00,  1.22it/s]    100%|██████████| 8/8 [00:06<00:00,  1.32it/s]
        average  deviation  min_exec  max_exec  repeat  number     ttime  context_size  warmup_time  x_name      fct
    6  0.001660   0.000242  0.001330  0.002188      10      50  0.016595           184     0.000885     122  a=1-p=1
    7  0.001789   0.000465  0.001035  0.002787      10      50  0.017889           184     0.002669     142  a=1-p=1




.. GENERATED FROM PYTHON SOURCE LINES 97-102

One left issue
++++++++++++++

Will you find it in :func:`dmul_cython_omp
<teachcompute.validation.cython.mul_cython_omp.dmul_cython_omp>`.

.. GENERATED FROM PYTHON SOURCE LINES 102-118

.. code-block:: Python



    va = numpy.random.randn(3, 4).astype(numpy.float64)
    vb = numpy.random.randn(4, 5).astype(numpy.float64)
    numpy_mul = va @ vb

    try:
        for a in range(0, 50):
            wrong_mul = dmul_cython_omp(va, vb, algo=2, parallel=1)
            assert_almost_equal(numpy_mul, wrong_mul)
            print("Iteration %d is Ok" % a)
        print("All iterations are unexpectedly Ok. Don't push your luck.")
    except AssertionError as e:
        print(e)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    Arrays are not almost equal to 7 decimals

    Mismatched elements: 3 / 15 (20%)
    Max absolute difference: 1.95960206
    Max relative difference: 2.8622679e-16
     x: array([[ 3.5026014,  1.1843984,  3.3666019, -3.6713302,  1.9596021],
           [ 0.1630768,  0.7299838,  2.7027151, -0.9078025, -0.1672389],
           [ 2.3259059,  2.5907322,  1.7346457, -0.3878823,  1.2806922]])
     y: array([[ 3.5026014,  1.1843984,  3.3666019, -3.6713302,  0.       ],
           [ 0.1630768,  0.7299838,  2.7027151, -0.9078025,  0.       ],
           [ 2.3259059,  2.5907322,  1.7346457, -0.3878823,  0.       ]])




.. GENERATED FROM PYTHON SOURCE LINES 119-124

Other scenarios but transposed
++++++++++++++++++++++++++++++

Same differents algorithms but the second matrix
is transposed first: ``b_trans=1``.

.. GENERATED FROM PYTHON SOURCE LINES 124-147

.. code-block:: Python



    for algo in range(0, 2):
        for parallel in (0, 1):
            print("algo=%d parallel=%d transposed" % (algo, parallel))
            ctxs = [
                dict(
                    va=numpy.random.randn(n, n).astype(numpy.float64),
                    vb=numpy.random.randn(n, n).astype(numpy.float64),
                    mul=lambda x, y: dmul_cython_omp(
                        x, y, algo=algo, parallel=parallel, b_trans=1
                    ),
                    x_name=n,
                )
                for n in sets
            ]

            res = list(measure_time_dim("mul(va, vb)", ctxs, verbose=2))
            dfs.append(DataFrame(res))
            dfs[-1]["fct"] = "a=%d-p=%d-T" % (algo, parallel)
            pprint.pprint(dfs[-1].tail(n=2))






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    algo=0 parallel=0 transposed
      0%|          | 0/8 [00:00<?, ?it/s]     62%|██████▎   | 5/8 [00:00<00:00, 21.00it/s]    100%|██████████| 8/8 [00:01<00:00,  3.40it/s]    100%|██████████| 8/8 [00:01<00:00,  4.04it/s]
        average  deviation  min_exec  max_exec  repeat  number     ttime  context_size  warmup_time  x_name        fct
    6  0.001094   0.000028  0.001080  0.001179      10      50  0.010941           184     0.001217     122  a=0-p=0-T
    7  0.001743   0.000040  0.001726  0.001863      10      50  0.017434           184     0.001793     142  a=0-p=0-T
    algo=0 parallel=1 transposed
      0%|          | 0/8 [00:00<?, ?it/s]     62%|██████▎   | 5/8 [00:00<00:00, 44.05it/s]    100%|██████████| 8/8 [00:00<00:00, 19.34it/s]
        average  deviation  min_exec  max_exec  repeat  number     ttime  context_size  warmup_time  x_name        fct
    6  0.000200   0.000304  0.000091  0.001109      10      50  0.001998           184     0.000121     122  a=0-p=1-T
    7  0.000225   0.000304  0.000109  0.001136      10      50  0.002247           184     0.000147     142  a=0-p=1-T
    algo=1 parallel=0 transposed
      0%|          | 0/8 [00:00<?, ?it/s]     62%|██████▎   | 5/8 [00:00<00:00, 20.91it/s]    100%|██████████| 8/8 [00:01<00:00,  3.39it/s]    100%|██████████| 8/8 [00:01<00:00,  4.02it/s]
        average  deviation  min_exec  max_exec  repeat  number     ttime  context_size  warmup_time  x_name        fct
    6  0.001108   0.000008  0.001096  0.001122      10      50  0.011084           184     0.001110     122  a=1-p=0-T
    7  0.001742   0.000016  0.001727  0.001778      10      50  0.017424           184     0.001898     142  a=1-p=0-T
    algo=1 parallel=1 transposed
      0%|          | 0/8 [00:00<?, ?it/s]     38%|███▊      | 3/8 [00:00<00:00, 29.13it/s]     75%|███████▌  | 6/8 [00:00<00:00, 13.77it/s]    100%|██████████| 8/8 [00:00<00:00,  9.71it/s]    100%|██████████| 8/8 [00:00<00:00, 11.17it/s]
        average  deviation  min_exec  max_exec  repeat  number     ttime  context_size  warmup_time  x_name        fct
    6  0.000250   0.000297  0.000149  0.001141      10      50  0.002498           184     0.000161     122  a=1-p=1-T
    7  0.000377   0.000398  0.000173  0.001179      10      50  0.003771           184     0.000163     142  a=1-p=1-T




.. GENERATED FROM PYTHON SOURCE LINES 148-150

Let's display the results
+++++++++++++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 150-178

.. code-block:: Python


    cc = concat(dfs)
    cc["N"] = cc["x_name"]

    fig, ax = plt.subplots(3, 2, figsize=(10, 8), sharex=True, sharey=True)
    ccnp = cc.fct == "numpy"
    cct = cc.fct.str.contains("-T")
    cca0 = cc.fct.str.contains("a=0")
    cc[ccnp | (~cct & cca0)].pivot(index="N", columns="fct", values="average").plot(
        logy=True, logx=True, ax=ax[0, 0]
    )
    cc[ccnp | (~cct & ~cca0)].pivot(index="N", columns="fct", values="average").plot(
        logy=True, logx=True, ax=ax[0, 1]
    )
    cc[ccnp | (cct & cca0)].pivot(index="N", columns="fct", values="average").plot(
        logy=True, logx=True, ax=ax[1, 0]
    )
    cc[ccnp | (~cct & ~cca0)].pivot(index="N", columns="fct", values="average").plot(
        logy=True, logx=True, ax=ax[1, 1]
    )
    cc[ccnp | cca0].pivot(index="N", columns="fct", values="average").plot(
        logy=True, logx=True, ax=ax[2, 0]
    )
    cc[ccnp | ~cca0].pivot(index="N", columns="fct", values="average").plot(
        logy=True, logx=True, ax=ax[2, 1]
    )
    fig.suptitle("Comparison of matrix multiplication implementations")




.. image-sg:: /auto_examples/images/sphx_glr_plot_benchmark_dot_mul_001.png
   :alt: Comparison of matrix multiplication implementations
   :srcset: /auto_examples/images/sphx_glr_plot_benchmark_dot_mul_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    Text(0.5, 0.98, 'Comparison of matrix multiplication implementations')



.. GENERATED FROM PYTHON SOURCE LINES 179-182

The results depends on the machine, its
number of cores, the compilation settings
of :epkg:`numpy` or this module.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 28.942 seconds)


.. _sphx_glr_download_auto_examples_plot_benchmark_dot_mul.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_benchmark_dot_mul.ipynb <plot_benchmark_dot_mul.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_benchmark_dot_mul.py <plot_benchmark_dot_mul.py>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
