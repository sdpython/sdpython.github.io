{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Random order for a sum\n\nParallelization usually means a summation is done with a random order.\nThat may lead to different values if the computation is made many times\neven though the result should be the same. This example compares\nsummation of random permutation of the same array of values.\n\n## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\nimport numpy as np\nimport pandas\n\nunique_values = np.array(\n    [2.1102535724639893, 0.5986238718032837, -0.49545818567276], dtype=np.float32\n)\nrandom_index = np.random.randint(0, 3, 2000)\nassert set(random_index) == {0, 1, 2}\nvalues = unique_values[random_index]\n\ns0 = values.sum()\ns1 = np.array(0, dtype=np.float32)\nfor n in values:\n    s1 += n\n\ndelta = s1 - s0\nprint(f\"reduced sum={s0}, iterative sum={s1}, delta={delta}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are discrepancies.\n\n## Random order\n\nLet's go further and check the sum of random permutation of the same set.\nLet's compare the result with the same sum done with a higher precision (double).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def check_orders(values, n=200, bias=0):\n    double_sums = []\n    sums = []\n    reduced_sums = []\n    reduced_dsums = []\n    for i in tqdm(range(n)):\n        permuted_values = np.random.permutation(values)\n        s = np.array(bias, dtype=np.float32)\n        sd = np.array(bias, dtype=np.float64)\n        for n in permuted_values:\n            s += n\n            sd += n\n        sums.append(s)\n        double_sums.append(sd)\n        reduced_sums.append(permuted_values.sum() + bias)\n        reduced_dsums.append(permuted_values.astype(np.float64).sum() + bias)\n\n    data = []\n    mi, ma = min(sums), max(sums)\n    data.append(dict(name=\"seq_fp32\", min=mi, max=ma, bias=bias))\n    print(f\"min={mi} max={ma} delta={ma-mi}\")\n    mi, ma = min(double_sums), max(double_sums)\n    data.append(dict(name=\"seq_fp64\", min=mi, max=ma, bias=bias))\n    print(f\"min={mi} max={ma} delta={ma-mi} (double)\")\n    mi, ma = min(reduced_sums), max(reduced_sums)\n    data.append(dict(name=\"red_f32\", min=mi, max=ma, bias=bias))\n    print(f\"min={mi} max={ma} delta={ma-mi} (reduced)\")\n    mi, ma = min(reduced_dsums), max(reduced_dsums)\n    data.append(dict(name=\"red_f64\", min=mi, max=ma, bias=bias))\n    print(f\"min={mi} max={ma} delta={ma-mi} (reduced)\")\n    return data\n\n\ndata1 = check_orders(values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This example clearly shows the order has an impact.\nIt is usually unavoidable but it could reduced if the sum\nit close to zero. In that case, the sum would be of the same\norder of magnitude of the add values.\n\n## Removing the average\n\nComputing the average of the values requires to compute the sum.\nHowever if we have an estimator of this average, not necessarily\nthe exact value, we would help the summation to keep the same order\nof magnitude than the values it adds.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mean = unique_values.mean()\nvalues -= mean\ndata2 = check_orders(values, bias=len(values) * mean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The differences are clearly lower.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df = pandas.DataFrame(data1 + data2)\ndf[\"delta\"] = df[\"max\"] - df[\"min\"]\npiv = df.pivot(index=\"name\", columns=\"bias\", values=\"delta\")\nprint(piv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plots.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ax = piv.plot.barh()\nax.set_title(\"max(sum) - min(sum) over random orders\")\nax.get_figure().tight_layout()\nax.get_figure().savefig(\"plot_check_random_order.png\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}