{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Measuring CUDA performance with a vector addition\n\nMeasure the time between two additions, one with CUDA, one with\n:epkg:`numpy`. The script can be profiled with\n:epkg:`Nsight`.\n\n::\n\n    nsys profile python _doc/examples/plot_bench_cuda_vector_add.py\n\n## Vector Add\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\nimport numpy\nimport matplotlib.pyplot as plt\nfrom pandas import DataFrame\nfrom teachcompute.ext_test_case import measure_time, unit_test_going\nimport torch\n\nhas_cuda = torch.cuda.is_available()\n\ntry:\n    from teachcompute.validation.cuda.cuda_example_py import vector_add\nexcept ImportError:\n    has_cuda = False\n\n\ndef cuda_vector_add(values):\n    torch.cuda.nvtx.range_push(f\"CUDA dim={values.size}\")\n    res = vector_add(values, values, 0)\n    torch.cuda.nvtx.range_pop()\n    return res\n\n\nobs = []\ndims = [2**10, 2**15, 2**20, 2**25]\nif unit_test_going():\n    dims = [10, 20, 30]\nfor dim in tqdm(dims):\n    values = numpy.ones((dim,), dtype=numpy.float32).ravel()\n\n    if has_cuda:\n        diff = numpy.abs(vector_add(values, values, 0) - (values + values)).max()\n        res = measure_time(lambda values=values: cuda_vector_add(values), max_time=0.5)\n\n        obs.append(\n            dict(\n                dim=dim,\n                size=values.size,\n                time=res[\"average\"],\n                fct=\"CUDA\",\n                time_per_element=res[\"average\"] / dim,\n                diff=diff,\n            )\n        )\n\n    diff = 0\n    res = measure_time(lambda values=values: values + values, max_time=0.5)\n\n    obs.append(\n        dict(\n            dim=dim,\n            size=values.size,\n            time=res[\"average\"],\n            fct=\"numpy\",\n            time_per_element=res[\"average\"] / dim,\n            diff=0,\n        )\n    )\n\n\ndf = DataFrame(obs)\npiv = df.pivot(index=\"dim\", columns=\"fct\", values=\"time_per_element\")\nprint(piv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plots\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "piv_diff = df.pivot(index=\"dim\", columns=\"fct\", values=\"diff\")\npiv_time = df.pivot(index=\"dim\", columns=\"fct\", values=\"time\")\n\nfig, ax = plt.subplots(1, 3, figsize=(12, 6))\npiv.plot(ax=ax[0], logx=True, title=\"Comparison between two summation\")\npiv_diff.plot(ax=ax[1], logx=True, logy=True, title=\"Summation errors\")\npiv_time.plot(ax=ax[2], logx=True, logy=True, title=\"Total time\")\nfig.tight_layout()\nfig.savefig(\"plot_bench_cuda_vector_add.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "CUDA seems very slow but in fact, all the time is spent\nin moving the data from the CPU memory (Host) to the GPU memory (device).\n\n<img src=\"file://../images/nsight_vector_add.png\">\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}