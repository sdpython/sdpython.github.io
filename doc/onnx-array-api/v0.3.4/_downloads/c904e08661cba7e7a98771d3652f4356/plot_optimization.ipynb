{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Optimization with onnxruntime\n\n*onnxruntime* optimizes the onnx graph by default before running\nthe inference. It modifies, fuses or add new operators.\nSome of them are standard onnx operators, some of them\nare implemented in onnxruntime (see [Supported Operators](https://github.com/microsoft/onnxruntime/blob/main/docs/OperatorKernels.md)).\nThis example looks into the differences of two models.\n\n## Optimize a model with onnxruntime\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nfrom pprint import pprint\nimport numpy\nfrom pandas import DataFrame\nimport matplotlib.pyplot as plt\nfrom onnx import load\nfrom onnx_array_api.ext_test_case import example_path\nfrom onnx_array_api.plotting.text_plot import onnx_simple_text_plot\nfrom onnx_array_api.validation.diff import text_diff, html_diff\nfrom onnxruntime import GraphOptimizationLevel, InferenceSession, SessionOptions\nfrom onnx_array_api.ext_test_case import measure_time\nfrom onnx_array_api.ort.ort_optimizers import ort_optimized_model\n\n\nfilename = example_path(\"data/small.onnx\")\noptimized = filename + \".optimized.onnx\"\n\nif not os.path.exists(optimized):\n    ort_optimized_model(filename, output=optimized)\nprint(optimized)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Output comparison\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "so = SessionOptions()\nso.graph_optimization_level = GraphOptimizationLevel.ORT_ENABLE_ALL\nimg = numpy.random.random((1, 3, 112, 112)).astype(numpy.float32)\n\nsess = InferenceSession(filename, so, providers=[\"CPUExecutionProvider\"])\nsess_opt = InferenceSession(optimized, so, providers=[\"CPUExecutionProvider\"])\ninput_name = sess.get_inputs()[0].name\nout = sess.run(None, {input_name: img})[0]\nout_opt = sess_opt.run(None, {input_name: img})[0]\nif out.shape != out_opt.shape:\n    print(\"ERROR shape are different {out.shape} != {out_opt.shape}\")\ndiff = numpy.abs(out - out_opt).max()\nprint(f\"Differences: {diff}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Difference\n\nUnoptimized model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "with open(filename, \"rb\") as f:\n    model = load(f)\nprint(\"first model to text...\")\ntext1 = onnx_simple_text_plot(model, indent=False)\nprint(text1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Optimized model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "with open(optimized, \"rb\") as f:\n    model = load(f)\nprint(\"second model to text...\")\ntext2 = onnx_simple_text_plot(model, indent=False)\nprint(text2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Differences\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"differences...\")\nprint(text_diff(text1, text2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "HTML version.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"html differences...\")\noutput = html_diff(text1, text2)\nwith open(\"diff_html.html\", \"w\", encoding=\"utf-8\") as f:\n    f.write(output)\nprint(\"done.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Benchmark\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "img = numpy.random.random((1, 3, 112, 112)).astype(numpy.float32)\n\nt1 = measure_time(lambda: sess.run(None, {input_name: img}), repeat=25, number=25)\nt1[\"name\"] = \"original\"\nprint(\"Original model\")\npprint(t1)\n\nt2 = measure_time(lambda: sess_opt.run(None, {input_name: img}), repeat=25, number=25)\nt2[\"name\"] = \"optimized\"\nprint(\"Optimized\")\npprint(t2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plots\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(12, 4))\n\ndf = DataFrame([t1, t2]).set_index(\"name\")\ndf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And the graph is:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ax.bar(df.index, df[\"average\"].values, yerr=df[\"deviation\"].values, capsize=6)\nax.set_title(\"Measure performance of optimized model\\nlower is better\")\nplt.grid()\nfig.savefig(\"plot_optimization.png\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}