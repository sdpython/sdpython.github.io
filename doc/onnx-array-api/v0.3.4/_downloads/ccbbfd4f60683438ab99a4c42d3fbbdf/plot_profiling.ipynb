{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Profiling with onnxruntime\n\n*onnxruntime* optimizes the onnx graph by default before running\nthe inference. It modifies, fuses or add new operators.\nSome of them are standard onnx operators, some of them\nare implemented in onnxruntime (see [Supported Operators](https://github.com/microsoft/onnxruntime/blob/main/docs/OperatorKernels.md)).\nThis example profiles the two models.\n\n## Optimize a model with onnxruntime\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport numpy\nimport matplotlib.pyplot as plt\nfrom onnxruntime import get_available_providers\nfrom onnx_array_api.ext_test_case import example_path\nfrom onnx_array_api.ort.ort_optimizers import ort_optimized_model\nfrom onnx_array_api.ort.ort_profile import ort_profile, merge_ort_profile\nfrom onnx_array_api.plotting.stat_plot import plot_ort_profile\n\n\nsuffix = \"\"\nfilename = example_path(f\"data/small{suffix}.onnx\")\noptimized = filename + \".optimized.onnx\"\nprint(f\"model={filename!r}\")\n\nif not os.path.exists(optimized):\n    ort_optimized_model(filename, output=optimized)\nprint(f\"optimized={optimized!r}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n## Profiling\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "feeds = {\"input\": numpy.random.random((1, 3, 112, 112)).astype(numpy.float32)}\nprof_base = ort_profile(\n    filename,\n    feeds,\n    repeat=6,\n    disable_optimization=True,\n    providers=[\"CPUExecutionProvider\"],\n)\nprof_base.to_excel(f\"prof_base{suffix}.xlsx\", index=False)\nprof_base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And the optimized model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "prof_opti = ort_profile(\n    optimized,\n    feeds,\n    repeat=6,\n    disable_optimization=True,\n    providers=[\"CPUExecutionProvider\"],\n)\nprof_opti.to_excel(f\"prof_opti{suffix}.xlsx\", index=False)\nprof_opti"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And the graph is:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "unique_op = set(prof_base[\"args_op_name\"])\nfig, ax = plt.subplots(2, 2, figsize=(10, len(unique_op)), sharex=\"col\")\nplot_ort_profile(prof_base, ax[0, 0], ax[0, 1], title=\"baseline\")\nplot_ort_profile(prof_opti, ax[1, 0], ax[1, 1], title=\"optimized\")\nfig.tight_layout()\nfig.savefig(f\"plot_profiling{suffix}.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Merging profiles\n\nLet's try to compare both profiles assuming every iteration\nprocess the same image and the input and output size are the\nsame at every iteration.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "merge, gr = merge_ort_profile(prof_base, prof_opti)\nmerge.to_excel(f\"plot_profiling_merged{suffix}.xlsx\", index=False)\nmerge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "More detailed\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gr.to_excel(f\"plot_profiling_merged_details{suffix}.xlsx\", index=False)\ngr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Final plot\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# let's filter out unsignificant operator.\ngrmax = gr[\"durbase\"] + gr[\"duropti\"]\ntotal = grmax.sum()\ngrmax /= total\ngr = gr[grmax >= 0.01]\n\n\nfig, ax = plt.subplots(1, 2, figsize=(14, min(gr.shape[0], 500)), sharey=True)\ngr[[\"durbase\", \"duropti\"]].plot.barh(ax=ax[0])\nax[0].set_title(\"Side by side duration\")\ngr = gr.copy()\ngr[[\"countbase\", \"countopti\"]].plot.barh(ax=ax[1])\nax[1].set_title(\"Side by side count\")\nfig.tight_layout()\nfig.savefig(f\"plot_profiling_side_by_side{suffix}.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## On CUDA\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if \"CUDAExecutionProvider\" in get_available_providers():\n    print(\"Profiling on CUDA\")\n    prof_base = ort_profile(\n        filename,\n        feeds,\n        repeat=6,\n        disable_optimization=True,\n        providers=[\"CUDAExecutionProvider\"],\n    )\n    prof_base.to_excel(f\"prof_cuda_base{suffix}.xlsx\", index=False)\n\n    prof_opti = ort_profile(\n        optimized,\n        feeds,\n        repeat=6,\n        disable_optimization=True,\n        providers=[\"CUDAExecutionProvider\", \"CPUExecutionProvider\"],\n    )\n    prof_opti.to_excel(f\"prof_cuda_opti{suffix}.xlsx\", index=False)\n\n    unique_op = set(prof_base[\"args_op_name\"])\n    fig, ax = plt.subplots(2, 2, figsize=(10, len(unique_op)), sharex=\"col\")\n    plot_ort_profile(prof_base, ax[0, 0], ax[0, 1], title=\"baseline\")\n    plot_ort_profile(prof_opti, ax[1, 0], ax[1, 1], title=\"optimized\")\n    fig.tight_layout()\n    fig.savefig(f\"plot_profiling_cuda{suffix}.png\")\n\n    merge, gr = merge_ort_profile(prof_base, prof_opti)\n    merge.to_excel(f\"plot_profiling_merged{suffix}.xlsx\", index=False)\n    gr.to_excel(f\"plot_profiling_merged_details{suffix}.xlsx\", index=False)\n\n    grmax = gr[\"durbase\"] + gr[\"duropti\"]\n    total = grmax.sum()\n    grmax /= total\n    gr = gr[grmax >= 0.01]\n\n    fig, ax = plt.subplots(1, 2, figsize=(14, min(gr.shape[0], 500)), sharey=True)\n    gr[[\"durbase\", \"duropti\"]].plot.barh(ax=ax[0])\n    ax[0].set_title(\"Side by side duration\")\n    gr = gr.copy()\n    gr[[\"countbase\", \"countopti\"]].plot.barh(ax=ax[1])\n    ax[1].set_title(\"Side by side count\")\n    fig.tight_layout()\n    fig.savefig(f\"plot_profiling_side_by_side_cuda{suffix}.png\")\n\nelse:\n    print(f\"CUDA not available in {get_available_providers()}.\")\n    fig, ax = None, None\n\nax"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}