{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Profiling with onnxruntime\n\n*onnxruntime* optimizes the onnx graph by default before running\nthe inference. It modifies, fuses or add new operators.\nSome of them are standard onnx operators, some of them\nare implemented in onnxruntime (see [Supported Operators](https://github.com/microsoft/onnxruntime/blob/main/docs/OperatorKernels.md)).\nThis example profiles the two models.\n\n## Optimize a model with onnxruntime\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport numpy\nimport matplotlib.pyplot as plt\nfrom onnxruntime import get_available_providers\nfrom onnx_array_api.ext_test_case import example_path\nfrom onnx_array_api.ort.ort_optimizers import ort_optimized_model\nfrom onnx_array_api.ort.ort_profile import ort_profile\n\n\nfilename = example_path(\"data/small.onnx\")\noptimized = filename + \".optimized.onnx\"\n\nif not os.path.exists(optimized):\n    ort_optimized_model(filename, output=optimized)\nprint(optimized)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Profiling\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "feeds = {\"input\": numpy.random.random((1, 3, 112, 112)).astype(numpy.float32)}\nprof_base = ort_profile(filename, feeds, repeat=6, disable_optimization=True)\nprof_base.to_excel(\"prof_base.xlsx\", index=False)\nprof_base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And the optimized model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "prof_opt = ort_profile(optimized, feeds, repeat=6, disable_optimization=True)\nprof_opt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And the graph is:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_profile(df, ax0, ax1=None, title=None):\n    gr_dur = (\n        df[[\"dur\", \"args_op_name\"]].groupby(\"args_op_name\").sum().sort_values(\"dur\")\n    )\n    gr_dur.plot.barh(ax=ax0)\n    if title is not None:\n        ax0.set_title(title)\n    if ax1 is not None:\n        gr_n = (\n            df[[\"dur\", \"args_op_name\"]]\n            .groupby(\"args_op_name\")\n            .count()\n            .sort_values(\"dur\")\n        )\n        gr_n = gr_n.loc[gr_dur.index, :]\n        gr_n.plot.barh(ax=ax1)\n        ax1.set_title(\"n occurences\")\n\n\nunique_op = set(prof_base[\"args_op_name\"])\nfig, ax = plt.subplots(2, 2, figsize=(10, len(unique_op)), sharex=\"col\")\nplot_profile(prof_base, ax[0, 0], ax[0, 1], title=\"baseline\")\nplot_profile(prof_opt, ax[1, 0], ax[1, 1], title=\"optimized\")\n\nfig.savefig(\"plot_profiling.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Merging profiles\n\nLet's try to compare both profiles assuming every iteration\nprocess the same image and the input and output size are the\nsame at every iteration.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def preprocess(df):\n    groupkey = [\n        \"args_op_name\",\n        \"args_output_type_shape\",\n        \"args_input_type_shape\",\n        \"args_provider\",\n    ]\n\n    def _idx(row):\n        \"\"\"\n        There may be multiple node with the same\n        input/output types and shapes.\n        This function gives every instance a distinct id.\n        First unique op with same I/O receives the index 0.\n        The counter restart when the session goes to the\n        next image.\n        \"\"\"\n        if row[\"cat\"] == \"Session\":\n            occurences[0] = {}\n            return -1\n        assert \"idx\" not in groupkey\n        vals = [row[k] for k in groupkey]\n        key = tuple(map(str, vals))\n        if key not in occurences[0]:\n            occurences[0][key] = 0\n        else:\n            occurences[0][key] += 1\n        return occurences[0][key]\n\n    df = df.copy()\n    occurences = [{}]\n    df[\"idx\"] = df.apply(_idx, axis=1)\n    df = df[(df[\"cat\"] == \"Node\") & df[\"name\"].str.contains(\"kernel_time\")]\n    groupkey.append(\"idx\")\n    for c in groupkey:\n        if c != \"idx\":\n            df[c] = df[c].apply(str)\n    gr = df[groupkey + [\"dur\"]].groupby(groupkey)\n    return gr.sum()\n\n\nbase = preprocess(prof_base)\nopti = preprocess(prof_opt)\nmerge = base.merge(\n    opti, how=\"outer\", suffixes=(\"base\", \"opti\"), left_index=True, right_index=True\n)\nmerge = merge.reset_index(drop=False)\nmerge.to_excel(\"plot_profiling_merged.xlsx\", index=False)\nmerge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Aggregation\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def classify(row):\n    if numpy.isnan(row[\"duropti\"]):\n        return \"-\"\n    if numpy.isnan(row[\"durbase\"]):\n        return \"+\"\n    return \"=\"\n\n\nkeys = {\"float\": \"f\"}\n\n\ndef process_shape(s):\n    value = eval(s)\n    ns = []\n    for v in value:\n        if len(v) != 1:\n            raise NotImplementedError(f\"Unexpected value {v} in {s!r}.\")\n        k, v = list(v.items())[0]\n        n = \"-\".join([keys[k], \"x\".join(map(str, v))])\n        ns.append(n)\n    return \",\".join(ns)\n\n\ndef label(row):\n    name = row[\"args_op_name\"]\n    inshape = process_shape(row[\"args_input_type_shape\"])\n    outshape = process_shape(row[\"args_output_type_shape\"])\n    side = row[\"side\"][0]\n    prov = row[\"args_provider\"][:3]\n    idx = row[\"idx\"]\n    return f\"[{side}{prov}]{name}({inshape})->{outshape}[{idx}]\"\n\n\ndf = merge.copy()\ndf[\"side\"] = df.apply(classify, axis=1)\ndf[\"label\"] = df.apply(label, axis=1)\ngr = (\n    df[[\"label\", \"durbase\", \"duropti\", \"idx\"]]\n    .groupby(\"label\")\n    .agg({\"durbase\": numpy.sum, \"duropti\": numpy.sum, \"idx\": max})\n)\ngr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Final plot\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# let's filter out unsignificant operator.\ngrmax = gr[\"durbase\"] + gr[\"duropti\"]\ntotal = grmax.sum()\ngrmax /= total\ngr = gr[grmax >= 0.01]\n\n\nfig, ax = plt.subplots(1, 2, figsize=(14, min(gr.shape[0], 500)), sharey=True)\ngr[[\"durbase\", \"duropti\"]].plot.barh(ax=ax[0])\nax[0].set_title(\"Side by side duration\")\ngr[\"idx\"] += 1\ngr[[\"idx\"]].plot.barh(ax=ax[1])\nax[1].set_title(\"Side by side count\")\nfig.tight_layout()\nfig.savefig(\"plot_profiling_side_by_side.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## On CUDA\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if \"CUDAExecutionProvider\" in get_available_providers():\n    print(\"Profiling on CUDA\")\n    prof_base = ort_profile(\n        filename,\n        feeds,\n        repeat=6,\n        disable_optimization=True,\n        provider=[\"CUDAExecutionProvider\"],\n    )\n    prof_opti = ort_profile(\n        optimized,\n        feeds,\n        repeat=6,\n        disable_optimization=True,\n        provider=[\"CUDAExecutionProvider\"],\n    )\n\n    unique_op = set(prof_base[\"args_op_name\"])\n    fig, ax = plt.subplots(2, 2, figsize=(10, len(unique_op)), sharex=\"col\")\n    plot_profile(prof_base, ax[0, 0], ax[0, 1], title=\"baseline\")\n    plot_profile(prof_opt, ax[1, 0], ax[1, 1], title=\"optimized\")\n    fig.save(\"plot_profiling_cuda.png\")\nelse:\n    print(f\"CUDA not available in {get_available_providers()}\")\n    fig, ax = None, None\n\nax"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}