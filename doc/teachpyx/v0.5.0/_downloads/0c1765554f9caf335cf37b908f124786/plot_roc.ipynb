{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Receiver Operating Characteristic (ROC)\n\nUn probl\u00e8me de classification binaire consiste \u00e0 trouver\nun moyen de s\u00e9parer deux nuages de points\n(voir [classification](https://sdpython.github.io/doc/mlstatpy/dev/c_ml/rn/rn_3_clas.html))\net on \u00e9value le plus souvent sa pertinence \u00e0 l'aide d'une courbe\n:epkg:`ROC`. Cet exemple montre diff\u00e9rente repr\u00e9sentation de la m\u00eame\ninformation.\n\n## Classification binaire\n\nOn commence par g\u00e9n\u00e9rer un nuage de points artificiel.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy\nfrom sklearn.metrics import (\n    f1_score,\n    precision_recall_curve,\n    roc_curve,\n    confusion_matrix,\n)\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import make_classification\nimport matplotlib.pyplot as plt\nfrom teachpyx.ext_test_case import unit_test_going\n\nX, Y = make_classification(\n    n_samples=10000 if unit_test_going() else 100,\n    n_features=2,\n    n_classes=2,\n    n_repeated=0,\n    n_redundant=0,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On repr\u00e9sente ces donn\u00e9es.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(5, 5))\nax = plt.subplot()\nax.plot(X[Y == 0, 0], X[Y == 0, 1], \".b\")\nax.plot(X[Y == 1, 0], X[Y == 1, 1], \".r\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On d\u00e9coupe en train / test.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On apprend sur la base d'apprentissage.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "logreg = LogisticRegression()\nlogreg.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Et on pr\u00e9dit sur la base de test.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "y_pred = logreg.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On calcule la :epkg:`matrice de confusion`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "conf = confusion_matrix(y_test, y_pred)\nprint(conf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Trois courbes\n\nLa courbe :epkg:`ROC` s'applique toujours \u00e0 un probl\u00e8me\nde classification binaire qu'on peut scinder en trois questions :\n\n* Le mod\u00e8le a bien class\u00e9 un exemple dans la classe 0.\n* Le mod\u00e8le a bien class\u00e9 un exemple dans la classe 1.\n* Le mod\u00e8le a bien class\u00e9 un exemple, que ce soit dans la\n  classe 0 ou la classe 1.\n  Ce probl\u00e8me suppose implicitement que le m\u00eame seuil est\n  utilis\u00e9 sur chacun des classes.\n  C'est-\u00e0-dire qu'on pr\u00e9dit la classe 1 si le score pour la\n  classe 1 est sup\u00e9rieur \u00e0\n  \u00e0 celui obtenu pour la classe 0 mais aussi qu'on valide la r\u00e9ponse\n  si le score de la classe 1 ou celui de la classe 0\n  est sup\u00e9rieur au m\u00eame seuil *s*,\n  ce qui n'est pas n\u00e9cessairement le meilleur choix.\n\nSi les r\u00e9ponses sont li\u00e9es, le mod\u00e8le peut r\u00e9pondre de mani\u00e8re\nplus ou moins efficace \u00e0 ces trois questions.\nOn calcule les courbes :epkg:`ROC` \u00e0 ces trois questions.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fpr_cl = dict()\ntpr_cl = dict()\n\ny_pred = logreg.predict(X_test)\ny_proba = logreg.predict_proba(X_test)\n\nfpr_cl[\"classe 0\"], tpr_cl[\"classe 0\"], _ = roc_curve(\n    y_test == 0, y_proba[:, 0].ravel()\n)\nfpr_cl[\"classe 1\"], tpr_cl[\"classe 1\"], _ = roc_curve(\n    y_test, y_proba[:, 1].ravel()\n)  # y_test == 1\n\nprob_pred = numpy.array([y_proba[i, 1 if c else 0] for i, c in enumerate(y_pred)])\nfpr_cl[\"tout\"], tpr_cl[\"tout\"], _ = roc_curve((y_pred == y_test).ravel(), prob_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Et on les repr\u00e9sente.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure()\nfor key in fpr_cl:\n    plt.plot(fpr_cl[key], tpr_cl[key], label=key)\n\nlw = 2\nplt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel(\"Proportion mal class\u00e9e\")\nplt.ylabel(\"Proportion bien class\u00e9e\")\nplt.title(\"ROC(s) avec predict_proba\")\nplt.legend(loc=\"lower right\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## predict_proba ou decision_function\n\nLe fait que la courbe :epkg:`ROC` pour la derni\u00e8re question,\nles deux classes \u00e0 la fois, sugg\u00e8re que les seuils optimaux seront\ndiff\u00e9rents pour les deux premi\u00e8res questions.\nLa courbe :epkg:`ROC` ne change pas qu'on prenne la fonction\n[predict_proba](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#\nsklearn.linear_model.LogisticRegression.predict_proba)\nou [decision_function](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#\nsklearn.linear_model.LogisticRegression.decision_function)\ncar ces deux scores\nsont li\u00e9s par une fonction monotone.\nOn recommence avec la seconde fonction.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "y_pred = logreg.predict(X_test)\ny_proba = logreg.decision_function(X_test)\ny_proba = numpy.vstack([-y_proba, y_proba]).T\n\nfpr_cl[\"classe 0\"], tpr_cl[\"classe 0\"], _ = roc_curve(\n    y_test == 0, y_proba[:, 0].ravel()\n)\nfpr_cl[\"classe 1\"], tpr_cl[\"classe 1\"], _ = roc_curve(\n    y_test, y_proba[:, 1].ravel()\n)  # y_test == 1\nprob_pred = numpy.array([y_proba[i, 1 if c else 0] for i, c in enumerate(y_pred)])\nfpr_cl[\"tout\"], tpr_cl[\"tout\"], _ = roc_curve((y_pred == y_test).ravel(), prob_pred)\n\nplt.figure()\nfor key in fpr_cl:\n    plt.plot(fpr_cl[key], tpr_cl[key], label=key)\n\nlw = 2\nplt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel(\"Proportion mal class\u00e9e\")\nplt.ylabel(\"Proportion bien class\u00e9e\")\nplt.title(\"ROC(s) avec decision_function\")\nplt.legend(loc=\"lower right\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Precision Rappel\n\nEn ce qui me concerne, je n'arrive jamais \u00e0 retenir la\nd\u00e9finition de False Positive Rate (FPR) and True Positive Rate (TPR).\nJe lui pr\u00e9f\u00e8re la pr\u00e9cision et le rappel.\nPour un seuil donn\u00e9, le rappel\nest l'ensemble de ces documents dont le score est sup\u00e9rieur \u00e0 un seuil *s*,\nla pr\u00e9cision est l'ensemble des documents bien class\u00e9 parmi ceux-ci.\nOn utilise la fonction\n[precision_recall_curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html#\nsklearn.metrics.precision_recall_curve).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "y_pred = logreg.predict(X_test)\ny_proba = logreg.predict_proba(X_test)\n\n\nprec = dict()\nrapp = dict()\n\nprec[\"classe 0\"], rapp[\"classe 0\"], _ = precision_recall_curve(\n    y_test == 0, y_proba[:, 0].ravel()\n)\nprec[\"classe 1\"], rapp[\"classe 1\"], _ = precision_recall_curve(\n    y_test, y_proba[:, 1].ravel()\n)  # y_test == 1\nprob_pred = numpy.array([y_proba[i, 1 if c else 0] for i, c in enumerate(y_pred)])\nprec[\"tout\"], rapp[\"tout\"], _ = precision_recall_curve(\n    (y_pred == y_test).ravel(), prob_pred\n)\n\nplt.figure()\nfor key in fpr_cl:\n    plt.plot(prec[key], rapp[key], label=key)\n\nplt.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\nplt.xlabel(\"Pr\u00e9cision\")\nplt.ylabel(\"Rappel\")\nplt.title(\"Courbe Pr\u00e9cision / Rappel\")\nplt.legend(loc=\"lower right\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## M\u00e9trique F1\n\nLa courbe *Pr\u00e9cision / Rappel* ne montre pas les\nscores m\u00eame s'il intervient dans\nchaque point de la courbe. Pour le faire appara\u00eetre, on utilise un graphe\no\u00f9 il est en abscisse.\nLa m\u00e9trique [F1](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)\npropose une pond\u00e9ration entre les deux :\n$F1 = 2 \\frac{precision * rappel}{precision + rappel}$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "y_pred = logreg.predict(X_test)\ny_proba = logreg.predict_proba(X_test)\nprec, rapp, seuil = precision_recall_curve(y_test == 1, y_proba[:, 1].ravel())\nf1 = [\n    f1_score(y_test[y_proba[:, 1] >= s].ravel(), y_pred[y_proba[:, 1] >= s])\n    for s in seuil.ravel()\n]\n\ny_score = logreg.decision_function(X_test)\nprecd, rappd, seuild = precision_recall_curve(y_test == 1, y_score.ravel())\nf1d = [\n    f1_score(y_test[y_score >= s].ravel(), y_pred[y_score >= s]) for s in seuil.ravel()\n]\n\nfig, ax = plt.subplots(1, 2, figsize=(12, 4))\nax[0].plot(seuil, prec[1:], label=\"Pr\u00e9cision\")\nax[0].plot(seuil, rapp[1:], label=\"Rappel\")\nax[0].plot(seuil, f1, label=\"F1\")\nax[0].set_title(\"predict_proba\")\nax[0].legend()\n\nax[1].plot(seuild, precd[1:], label=\"Pr\u00e9cision\")\nax[1].plot(seuild, rappd[1:], label=\"Rappel\")\nax[1].plot(seuild, f1d, label=\"F1\")\nax[1].set_title(\"decision_function\")\nax[1].legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pourquoi ROC alors ?\n\nOn peut se demander pourquoi on utilise la courbe :epkg:`ROC`\nsi d'autres graphiques sont plus compr\u00e9hensibles.\nC'est parce que l'aire sous la courbe\n([AUC](https://en.wikipedia.org/wiki/\nReceiver_operating_characteristic#Area_under_the_curve))\nest reli\u00e9 \u00e0 un r\u00e9sultat important :\n$\\mathbb{P}(S_F < S_T)$ o\u00f9\n$S_F$ repr\u00e9sente la variable al\u00e9atoire\n*score pour une observation mal class\u00e9e*\net $S_T$ la variable al\u00e9atoire\n*score pour une observation bien class\u00e9e*\n(voir [ROC](https://sdpython.github.io/doc/mlstatpy/dev/c_metric/roc.html)).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "y_pred = logreg.predict(X_test)\ny_proba = logreg.predict_proba(X_test)\ny_score = logreg.decision_function(X_test)\n\n\nfix, ax = plt.subplots(1, 2, figsize=(12, 4))\nax[0].hist(y_proba[y_test == 0, 1], color=\"r\", label=\"proba -\", alpha=0.5, bins=20)\nax[0].hist(y_proba[y_test == 1, 1], color=\"b\", label=\"proba +\", alpha=0.5, bins=20)\nax[0].set_title(\"predict_proba\")\nax[0].plot([0.8, 0.8], [0, 600], \"--\")\nax[0].legend()\nax[1].hist(y_score[y_test == 0], color=\"r\", label=\"score -\", alpha=0.5, bins=20)\nax[1].hist(y_score[y_test == 1], color=\"b\", label=\"score +\", alpha=0.5, bins=20)\nax[1].set_title(\"decision_function\")\nax[1].plot([1, 1], [0, 250], \"--\")\nax[1].legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La ligne en pointill\u00e9s d\u00e9limit\u00e9 la zone \u00e0 partir de laquelle le mod\u00e8le\nest s\u00fbr de sa d\u00e9cision. Elle est ajust\u00e9 en fonction des besoins\nselon qu'on a besoin de plus de rappel (seuil bas) ou plus\nde pr\u00e9cision (seuil haut).\nLe mod\u00e8le est performant si les deux histogrammes sont bien s\u00e9par\u00e9s.\nSi on note *T(s)* l'aire bleue apr\u00e8s la ligne en pointill\u00e9 et\n*E(s)* l'aire rouge toujours apr\u00e8s la ligne en pointill\u00e9.\nCes deux quantit\u00e9s sont reli\u00e9es \u00e0 la distribution du score\npour les bonnes et mauvaises pr\u00e9dictions.\nLa courbe :epkg:`ROC` est constitu\u00e9e des point $(1-T(s), 1-E(s))$\nlorsque le seuil *s* varie.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}